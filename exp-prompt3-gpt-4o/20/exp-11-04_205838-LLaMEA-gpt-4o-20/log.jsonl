{"id": "40f6100e-c71b-4f84-b5f2-9a02f9478116", "solution": "import numpy as np\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.scaling_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        \n        # Covariance matrix for learning\n        cov_matrix = np.eye(self.dim)\n\n        while num_evaluations < self.budget:\n            # Generate trial population via DE mutation and crossover\n            trial_population = np.empty_like(population)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + self.scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            # Evaluate trial population\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += self.population_size\n\n            # Replace if trial solution is better\n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            # Update best individual\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(best_individual):\n                best_individual = population[best_idx]\n\n            # Covariance Matrix Learning Update\n            if num_evaluations < self.budget:\n                sampled_indices = np.random.choice(self.population_size, 2, replace=False)\n                diff = population[sampled_indices[0]] - population[sampled_indices[1]]\n                cov_matrix = (1 - 1.0/self.dim) * cov_matrix + (1.0/self.dim) * np.outer(diff, diff)\n\n                # Adaptive adjustment of scaling factor\n                self.scaling_factor = self.adjust_scaling_factor(cov_matrix)\n\n        return best_individual\n\n    def adjust_scaling_factor(self, cov_matrix):\n        # Heuristic to adjust the scaling factor based on the covariance matrix\n        # Increasing exploration if covariance suggests high variance\n        variance_measure = np.sum(np.diag(cov_matrix))\n        return min(1.0, max(0.5, 0.8 * (1.0 + variance_measure)))\n\n# Usage example:\n# optimizer = HybridDifferentialEvolution(budget=10000, dim=10)\n# best_solution = optimizer(my_black_box_function)", "name": "HybridDifferentialEvolution", "description": "A hybrid metaheuristic combining Adaptive Differential Evolution with Covariance Matrix Learning for robust exploration and exploitation.", "configspace": "", "generation": 0, "fitness": 0.19849059076346692, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.19.", "error": "", "parent_id": null, "metadata": {"aucs": [0.45272615843287745, 0.430345016360813, 0.44907864610845327, 0.4930206069677423, 0.4950050215051335, 0.5526908044595907, 0.47606870667655454, 0.46375175797808965, 0.488332145469059, 0.18768345093944383, 0.1906735683577424, 0.19617009795385076, 0.158915731700506, 0.21952163888314236, 0.17864735965626788, 0.20321176879866654, 0.18434446701851293, 0.17951317614840823, 0.09867825623621085, 0.08993702520686042, 0.0872564184829071, 0.08798126308349785, 0.10161193461215845, 0.09806222651698848, 0.09646385207362018, 0.0907672501414154, 0.0868166095061671, 0.07237671145074598, 0.08356714095442908, 0.08240330887838043, 0.0777038066059218, 0.07828741803461203, 0.07573803834247572, 0.07584246765592328, 0.08509598534128637, 0.07968078376947285, 0.9415660712621833, 0.958791409788339, 0.9387046545440311, 0.9294964282062476, 0.9700416257841797, 0.9448411780398382, 0.9484390360997871, 0.954282542395495, 0.9304789863175471, 0.1814701789395201, 0.18208668589709998, 0.17646650172021927, 0.18607052524586698, 0.1798788967895656, 0.18865842131726573, 0.16621949259093693, 0.1826704980928986, 0.16876568081111276, 0.21264609583638971, 0.2262039285996319, 0.2217503243068154, 0.23785612514199406, 0.2989656748588574, 0.24221802637577317, 0.29498791114473843, 0.23988283209128092, 0.2603784572340021, 0.14355311162906403, 0.107479827449669, 0.11261281910678422, 0.1725599709858654, 0.1007247703828189, 0.1268631437716664, 0.11270189687632515, 0.10202283714247662, 0.11770901611064055, 0.00955053169718556, 0.11010522812137091, 0.04870867171321047, 0.09989913770470626, 0.08854990834944187, 0.10114757995181767, 0.0873122172996007, 0.11730184449411485, 0.07636452245759207, 0.03989946462988758, 0.022059690125084463, 0.016782631030095918, 0.0773039898896557, 0.045985995699381776, 0.02775377715041527, 0.017762960854202037, 0.025703638756142344, 0.04481871524405745, 0.12906456705320346, 0.14169522594936101, 0.16739537427778228, 0.12309138657921137, 0.11983271821051367, 0.1751622574523104, 0.17677049627831343, 0.167953114571882, 0.18488550655274283, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005982708172815876, 9.999999999998899e-05, 9.999999999998899e-05, 0.003123583750159753, 0.07805065920284471, 0.06894149559198537, 0.0760705501304807, 0.09740295416234712, 0.07680219359047225, 0.08744689021365992, 0.0799799965233009, 0.08611577690436045, 0.077107543144744, 0.3592835159323696, 0.36661542981259343, 0.3693893024672156, 0.3718607465161745, 0.37073059755375404, 0.39049385184738294, 0.3675384995255865, 0.36330904112097595, 0.33376071746443614, 0.08153741228003597, 0.07483466130588257, 0.0867677931868922, 0.08152596421516611, 0.07515164460888901, 0.07024546778774654, 0.07451004102536041, 0.060632605242954773, 0.07603076706913048, 0.1738157016282441, 0.14309204494705352, 0.1595617436967468, 0.14349778311352834, 0.12426666216778026, 0.13969782012105858, 0.20785994073913017, 0.14044745830572358, 0.13883481991153546, 0.20177245413434652, 0.21002413488984895, 0.2320998786322659, 0.2265517987715714, 0.20653288415909232, 0.2200273100375001, 0.2284861333544802, 0.23476633479457043, 0.22410723078671746, 0.1532958598315145, 0.16172999479753458, 0.1535042094242759, 0.14485185776684362, 0.15554925232708305, 0.14758574519889212, 0.16308055748922146, 0.178503415262518, 0.1548678142868779, 0.18534620737251917, 0.1701927213232437, 0.17170964256010812, 0.14797291864752427, 0.17611278512118655, 0.15556225391376288, 0.18591153152900586, 0.18904447518913303, 0.16347838838197526, 0.1626575190371905, 0.1811906973953975, 0.19315783343445447, 0.16075306146410206, 0.1655854174074073, 0.17600612487960587, 0.16185448763324695, 0.16553066728899268, 0.1830756456940259, 0.39551567058091996, 0.1708365332287165, 0.4993271995109735, 0.36150029645362824, 0.23379121933319558, 0.17242340856171345, 0.15897879670965032, 0.16361291474804673, 0.1729937376378281, 0.31129044878902834, 0.19387020519293863, 0.2761580894686335, 0.1682044973195973, 0.17148940257777134, 0.13761624199340372, 0.548584277150105, 0.2013824603838138, 0.20734994853907907, 0.19896280815670342, 0.1968808357610471, 0.18074440280958226, 0.1851510476806989, 0.17362330099592238, 0.16734796113852335, 0.19191442988506846, 0.19061322382452173, 0.18607184244046282, 0.07750716374688638, 0.07836124733493366, 0.06288229625967545, 0.06312484187204792, 0.06562100839414797, 0.078713740592951, 0.07057094921870721, 0.07276611945456057, 0.06719649003221295]}, "mutation_prompt": null}
{"id": "5b757515-14d4-448c-9fd2-b5ceb3cabf65", "solution": "import numpy as np\n\nclass EnhancedHybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.scaling_factor = 0.8\n        self.crossover_rate = 0.9\n        self.levy_alpha = 1.5\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        \n        # Covariance matrix for learning\n        cov_matrix = np.eye(self.dim)\n\n        while num_evaluations < self.budget:\n            # Generate trial population via DE mutation and crossover\n            trial_population = np.empty_like(population)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + self.scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n                \n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            # Evaluate trial population\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += self.population_size\n\n            # Replace if trial solution is better\n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            # Update best individual\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(best_individual):\n                best_individual = population[best_idx]\n\n            # Covariance Matrix Learning Update\n            if num_evaluations < self.budget:\n                sampled_indices = np.random.choice(self.population_size, 2, replace=False)\n                diff = population[sampled_indices[0]] - population[sampled_indices[1]]\n                cov_matrix = (1 - 1.0/self.dim) * cov_matrix + (1.0/self.dim) * np.outer(diff, diff)\n\n                # Adaptive adjustment of scaling factor\n                self.scaling_factor = self.adjust_scaling_factor(cov_matrix)\n\n            # Incorporate Lévy Flights for improved exploration\n            if np.random.rand() < 0.5:\n                levy_step = self.levy_flight()\n                population += levy_step\n\n        return best_individual\n\n    def adjust_scaling_factor(self, cov_matrix):\n        variance_measure = np.sum(np.diag(cov_matrix))\n        return min(1.0, max(0.5, 0.8 * (1.0 + variance_measure)))\n\n    def levy_flight(self):\n        u = np.random.normal(0, 1, size=(self.population_size, self.dim)) * self.levy_alpha\n        v = np.random.normal(0, 1, size=(self.population_size, self.dim))\n        step = u / np.power(np.abs(v), 1 / self.levy_alpha)\n        return step * (np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim)) - self.lower_bound)", "name": "EnhancedHybridDifferentialEvolution", "description": "Enhanced Adaptive Hybrid Differential Evolution integrating Lévy Flights for improved diversity and convergence.", "configspace": "", "generation": 1, "fitness": 0.08949209709340927, "feedback": "The algorithm EnhancedHybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.19.", "error": "", "parent_id": "40f6100e-c71b-4f84-b5f2-9a02f9478116", "metadata": {"aucs": [0.11869729595922507, 0.08108763387163931, 0.09635984205013481, 0.10423034337666981, 0.11121743383720384, 0.11042008850345264, 0.1307454773861526, 0.10315584038060299, 0.07923217871870403, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01467079663371329, 0.005375109906600173, 0.010643411704069683, 0.006592353378601756, 0.006669962766643223, 0.018248263482334326, 0.010620268230806307, 0.010674738340807233, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.980583550946776, 0.9814008217931464, 0.9776057508134771, 0.9832396402340664, 0.9856293782792468, 0.9722953799945363, 0.9883769299316015, 0.9820454172357486, 0.9883849202832202, 0.06274794416174423, 0.006722788589444861, 0.006375120346705843, 9.999999999998899e-05, 0.00031549654350837564, 9.999999999998899e-05, 9.999999999998899e-05, 0.011293333694524565, 0.01992190716119424, 0.10027683525177622, 0.08224659834595494, 0.06574337936155183, 0.0667108215001172, 0.07285119553694963, 0.017403908027459503, 0.041112457291881066, 0.05931056463008866, 0.05190693865505547, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.001856346769845696, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02136370173792035, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1337561755551575, 0.15756555760738078, 0.14838054695461433, 0.1235021381189354, 0.10274288241579344, 0.12272678648846036, 0.16112956940342849, 0.10114575877365928, 0.14537805367046874, 0.02059182110419444, 0.01719044384977897, 0.02198412468535549, 0.03266886175302153, 9.999999999998899e-05, 0.01759993274736349, 9.999999999998899e-05, 0.011482102244687709, 0.0267656688986897, 0.12084802562441743, 0.1153234654560551, 0.12157788619169119, 0.12111263918444204, 0.14363824699077776, 0.11630831941766706, 0.10601666686928801, 0.1257233508544714, 0.131569549078126, 0.11265542104757931, 0.10728910894071864, 0.1613932299901244, 0.13800672315110074, 0.12217020355492769, 0.13041201278595493, 0.12388912786285766, 0.17377774300845283, 0.11685924622648258, 0.05985564337097804, 0.05227113308086906, 0.08398582550377798, 0.056957211629895754, 0.06406947898089654, 0.06378766234381705, 0.0837317855149382, 0.0997711199450243, 0.06412526395900253, 0.11943364695601921, 0.09388200728521401, 0.13345086981233123, 0.11626100065663836, 0.10562886974803609, 0.13140593952447865, 0.12245976138762271, 0.0792033923440777, 0.1261963614278906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11402736788394319, 0.09704843372441518, 0.10312567773998504, 0.10842174462777854, 0.1207914665021157, 0.08008268075810887, 0.1070176662487543, 0.10511484148144368, 0.11030943035754659, 0.11040265245322212, 0.10267165755511809, 0.06932034027342138, 0.07600590412683728, 0.03738259240699027, 0.05918733137808507, 0.11322540357335076, 0.0770992102881235, 0.10733587871868222, 0.1531361908298179, 0.16712139072039844, 0.15851485136933718, 0.17153941665311578, 0.179298430635204, 0.1762209901436529, 0.15490944590727063, 0.1766617823601777, 0.17430498155641416, 0.015867823843805362, 0.027791165270856122, 0.031393493129599714, 0.027015293023570086, 0.03425093938292756, 0.032711848720711534, 0.016228383701229143, 0.03803354422653826, 0.017643830485487344]}, "mutation_prompt": null}
{"id": "7f3f5816-325a-455a-9358-a996b83fb942", "solution": "import numpy as np\n\nclass EnhancedHybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.scaling_factor = 0.8\n        self.crossover_rate = 0.9\n        self.inertia_weight = 0.7  # Added for swarm behavior\n        self.cognitive_component = 1.5  # Personal best influence\n        self.social_component = 1.5  # Global best influence\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        \n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))  # Initialize velocities\n        \n        cov_matrix = np.eye(self.dim)\n\n        while num_evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] + \n                                 self.cognitive_component * r1 * (personal_best[i] - population[i]) +\n                                 self.social_component * r2 * (best_individual - population[i]))\n                velocities[i] = np.clip(velocities[i], self.lower_bound, self.upper_bound)\n                \n                trial_vector = population[i] + velocities[i]\n                trial_vector = np.clip(trial_vector, self.lower_bound, self.upper_bound)\n                \n                if func(trial_vector) < personal_best_fitness[i]:\n                    personal_best[i] = trial_vector\n                    personal_best_fitness[i] = func(trial_vector)\n            \n            trial_fitness = np.array([func(ind) for ind in personal_best])\n            num_evaluations += self.population_size\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = personal_best[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            new_best_idx = np.argmin(fitness)\n            if fitness[new_best_idx] < func(best_individual):\n                best_individual = population[new_best_idx]\n\n            if num_evaluations < self.budget:\n                sampled_indices = np.random.choice(self.population_size, 2, replace=False)\n                diff = population[sampled_indices[0]] - population[sampled_indices[1]]\n                cov_matrix = (1 - 1.0/self.dim) * cov_matrix + (1.0/self.dim) * np.outer(diff, diff)\n\n                self.scaling_factor = self.adjust_scaling_factor(cov_matrix)\n\n        return best_individual\n\n    def adjust_scaling_factor(self, cov_matrix):\n        variance_measure = np.sum(np.diag(cov_matrix))\n        return min(1.0, max(0.5, 0.8 * (1.0 + variance_measure)))", "name": "EnhancedHybridDifferentialEvolution", "description": "Enhanced Hybrid-Particle Swarm Differential Evolution using adaptive exploration and exploitation balance through covariance-guided swarm behavior.", "configspace": "", "generation": 2, "fitness": 0.17753001603497484, "feedback": "The algorithm EnhancedHybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.21.", "error": "", "parent_id": "40f6100e-c71b-4f84-b5f2-9a02f9478116", "metadata": {"aucs": [0.5075577318632738, 0.4267827949485776, 0.4822494476466631, 0.48051398958517344, 0.520634562373597, 0.47929845056319365, 0.4784221946711529, 0.18037441893533201, 0.1784957889668698, 0.061873757048608424, 9.999999999998899e-05, 9.999999999998899e-05, 0.029422904845456288, 9.999999999998899e-05, 9.999999999998899e-05, 0.11622860443515348, 9.999999999998899e-05, 0.04787567137024673, 0.09847841354948705, 0.08367821688467525, 0.08086544564968712, 0.04566210071193566, 0.0384562777216122, 0.07608891004200957, 0.028808711786393548, 0.06797761642192568, 0.04742352288262097, 0.059015420220757564, 0.028489397530525595, 0.05012654812861672, 0.03732233803137874, 0.036000975615548714, 0.034433625517614974, 0.10217671256619743, 0.07430202712061984, 0.08110479763887246, 0.9640662471795062, 0.9543758967227669, 0.9654228644844968, 0.9410614669521926, 0.9546863290355021, 0.9304473690254842, 0.9555618437145798, 0.966237591558907, 0.9547073956001959, 0.19428364297342737, 0.08885172855704204, 0.055651389919825656, 0.10890614222730399, 0.12676165439406994, 0.12693237611384778, 0.11075095350553599, 0.0814856229927311, 0.11779523004796844, 0.33015591417095536, 0.2653617146850422, 0.21189109306074472, 0.1874686687231374, 0.20560502423772054, 0.3304879824947631, 0.06641496221173437, 0.12268862628202637, 0.20332370870832706, 0.12008579426755472, 0.09107191230352141, 0.12427296422532597, 9.999999999998899e-05, 0.15022004287247237, 0.231063895062114, 0.11254310214483776, 0.08944628064327387, 0.14655165836475081, 0.14414247897427013, 0.11602115523349621, 0.1347533687736936, 0.1166235157853458, 0.08939939690942633, 0.17717212354528888, 0.16148245049437537, 0.15219294667612304, 0.08518045534513019, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01642969438987818, 0.0762646712301619, 0.02359864579292703, 0.07157713220503192, 0.07255657981005592, 0.03747263775294141, 0.005745812728833677, 0.0494201487530892, 0.051116192244924474, 0.02733198312367291, 9.999999999998899e-05, 9.999999999998899e-05, 0.026228727104096294, 0.004760610238366825, 9.999999999998899e-05, 0.011701650708115685, 0.03478277627166315, 0.04229451702348519, 9.999999999998899e-05, 0.03680833318294552, 0.08123760748152675, 0.009469319213447847, 0.005141126760741299, 9.999999999998899e-05, 0.0050723415938999095, 0.04308293005239716, 0.041759586918404756, 0.0678710673855012, 0.39789670926604626, 0.38419498452777523, 0.3886413467839187, 0.4387156198069001, 0.3910654979379249, 0.39907096173263257, 0.4344783763986465, 0.3549353414142533, 0.4103762552678413, 0.06344275467519656, 0.05318319456615228, 0.05789756710680971, 0.09473991894904543, 0.06619171083713193, 0.06201044195338623, 0.06922018458017487, 0.053755168200649295, 0.043610509142552156, 0.15011378852128532, 0.15295616305133553, 0.15109152890164934, 0.1543354927072389, 0.1910079868652188, 0.14834433461283536, 0.15414491595797863, 0.1194544309652592, 0.14603804877698134, 0.19353035052276069, 0.21742015466136422, 0.1933929142001941, 0.17949147773696061, 0.20094007951101645, 0.16737312435297758, 0.24254504832415646, 0.24747448897229263, 0.26060115196967004, 0.1868139127807682, 0.14544814905055903, 0.19247571083073955, 0.189735438527057, 0.1763365452897413, 0.18342802422474547, 0.1292993164238736, 0.1563389329809235, 0.2064165635539834, 0.18181424162063253, 0.15352508021084488, 0.14870585920977408, 0.177378915699685, 0.1689366386342126, 0.19046734712741886, 0.20135849302667197, 0.1371132071838872, 0.1450143295208285, 0.18291791232464416, 0.17232549918300155, 0.19756599607740943, 0.16714774597835602, 0.1780379303883648, 0.1567882871349381, 0.16727677652427575, 0.18587388384284564, 0.16570094532684143, 0.10164797364447609, 0.15794722614465773, 0.1126098500793794, 0.5995390849725178, 0.19632604711523793, 0.19534768725773843, 0.11887518705475808, 0.15234483948987143, 0.7709564058221097, 0.49151709557900825, 0.20419499128142693, 0.38867196534729687, 0.10284450715333837, 0.16638322373849768, 0.10680116510283766, 0.19090371578758036, 0.10291793477127231, 0.2818159065519028, 0.1836945833336513, 0.190994861909076, 0.18517398336832447, 0.17398472254126884, 0.1967644028330422, 0.1952627003571904, 0.17760710897767273, 0.1741513655422443, 0.17520034349042546, 0.04756712805882035, 0.06413240266360898, 0.053700375217550445, 0.050130389406416564, 0.05479309858693049, 0.05704294038442881, 0.06444281333298152, 0.05806307731664129, 0.05683620446442217]}, "mutation_prompt": null}
{"id": "3c9286e9-d028-496d-b5ca-49f8434b711c", "solution": "# Description: Enhanced Differential Evolution with Adaptive Neighborhood-based Learning for Improved Convergence.\n# Code:\nimport numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.scaling_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        \n        cov_matrix = np.eye(self.dim)\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 4, replace=False)\n                x0, x1, x2, x3 = population[indices[:3]], population[indices[3]], population[best_idx]\n                mutant_vector = x0 + self.scaling_factor * (x1 - x2 + x3 - x0)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += self.population_size\n\n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(best_individual):\n                best_individual = population[best_idx]\n\n            if num_evaluations < self.budget:\n                sampled_indices = np.random.choice(self.population_size, 2, replace=False)\n                diff = population[sampled_indices[0]] - population[sampled_indices[1]]\n                cov_matrix = (1 - 1.0/self.dim) * cov_matrix + (1.0/self.dim) * np.outer(diff, diff)\n\n                self.scaling_factor = self.adjust_scaling_factor(cov_matrix)\n\n        return best_individual\n\n    def adjust_scaling_factor(self, cov_matrix):\n        variance_measure = np.sum(np.diag(cov_matrix))\n        return min(1.0, max(0.5, 0.8 * (1.0 + variance_measure)))", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with Adaptive Neighborhood-based Learning for Improved Convergence.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('not enough values to unpack (expected 4, got 3)').", "error": "ValueError('not enough values to unpack (expected 4, got 3)')", "parent_id": "40f6100e-c71b-4f84-b5f2-9a02f9478116", "metadata": {}, "mutation_prompt": null}
{"id": "35d583a4-b014-46dd-a1f1-788add07f48b", "solution": "import numpy as np\n\nclass HybridDifferentialEvolutionWithLevyFlight:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.scaling_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        \n        # Covariance matrix for learning\n        cov_matrix = np.eye(self.dim)\n\n        while num_evaluations < self.budget:\n            # Generate trial population via DE mutation and crossover\n            trial_population = np.empty_like(population)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + self.scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            # Evaluate trial population\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += self.population_size\n\n            # Replace if trial solution is better\n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            # Update best individual\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(best_individual):\n                best_individual = population[best_idx]\n\n            # Covariance Matrix Learning Update\n            if num_evaluations < self.budget:\n                sampled_indices = np.random.choice(self.population_size, 2, replace=False)\n                diff = population[sampled_indices[0]] - population[sampled_indices[1]]\n                cov_matrix = (1 - 1.0/self.dim) * cov_matrix + (1.0/self.dim) * np.outer(diff, diff)\n\n                # Adaptive adjustment of scaling factor\n                self.scaling_factor = self.adjust_scaling_factor(cov_matrix)\n\n            # Integrate Levy Flight for enhanced exploration\n            if num_evaluations < self.budget and np.random.rand() < 0.5:\n                levy_step = self.levy_flight(self.dim)\n                candidate = best_individual + levy_step * (population[best_idx] - np.mean(population, axis=0))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(best_individual):\n                    best_individual = candidate\n\n        return best_individual\n\n    def adjust_scaling_factor(self, cov_matrix):\n        variance_measure = np.sum(np.diag(cov_matrix))\n        return min(1.0, max(0.5, 0.8 * (1.0 + variance_measure)))\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                (np.math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, size=(dim,))\n        v = np.random.normal(0, 1, size=(dim,))\n        step = u / np.abs(v)**(1 / beta)\n        return step\n\n# Usage example:\n# optimizer = HybridDifferentialEvolutionWithLevyFlight(budget=10000, dim=10)\n# best_solution = optimizer(my_black_box_function)", "name": "HybridDifferentialEvolutionWithLevyFlight", "description": "A hybrid metaheuristic enhancing Adaptive Differential Evolution by integrating Lévy Flight for improved exploration and maintaining Covariance Matrix Learning for robust exploitation.", "configspace": "", "generation": 4, "fitness": 0.2005576323817953, "feedback": "The algorithm HybridDifferentialEvolutionWithLevyFlight got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.19.", "error": "", "parent_id": "40f6100e-c71b-4f84-b5f2-9a02f9478116", "metadata": {"aucs": [0.42587079215650114, 0.4835386611836542, 0.4150036812601192, 0.5095652736713823, 0.465147657052548, 0.500688741097981, 0.490254740344093, 0.4931537747538699, 0.5156778191401596, 0.18255302943766472, 0.1992904769819004, 0.18131399905330603, 0.17338385702656955, 0.2246335571280631, 0.1792749938578292, 0.1964610905273908, 0.20180342789094863, 0.2027033509866566, 0.09245429223906287, 0.09826653039756805, 0.08556195303410585, 0.08402511080523711, 0.09687022272905121, 0.09152152639539546, 0.09155007161830364, 0.09193813642600213, 0.11916473910878833, 0.0769182016815998, 0.08709813886175466, 0.06527375254130874, 0.08131006328597157, 0.08340851859527265, 0.08571496756334951, 0.08351506411666709, 0.07969753657078549, 0.09690692597450401, 0.9787117622675712, 0.9508531196436022, 0.9391167416745436, 0.9548387578213424, 0.976991324449504, 0.9478981011740596, 0.9514337477737757, 0.9714141391427334, 0.9414482543564563, 0.1994956596367642, 0.2108272716439632, 0.16714211891094688, 0.18210458407998842, 0.17127357329216863, 0.1801894156429693, 0.20180955847455395, 0.20483568875396385, 0.19400309400937088, 0.2309712273544261, 0.22906316651771486, 0.2529637874988637, 0.23703839753186617, 0.267659028636152, 0.2570582016755869, 0.26208588435498636, 0.2615460626109357, 0.2541916883753865, 0.11757180420102908, 0.11335030064991136, 0.12923841015639392, 0.1122006541029692, 0.0815468544873571, 0.10107319141722326, 0.11662278247546942, 0.1217412009615777, 0.12560404004877257, 0.10360089908423886, 0.022174382738669896, 0.029064091591312846, 0.11057833156906638, 0.1107805154985374, 0.11565817811630441, 0.0904154698277655, 0.09326827354450451, 0.1121387785554212, 0.02091162576903771, 0.03689335974125518, 0.03232212586960137, 0.04311042142406463, 0.04455739947102666, 0.04667587327053313, 0.03689732038877669, 0.04139335518402987, 0.033610043862037475, 0.1351353140898316, 0.11057405156321198, 0.11323225458398734, 0.11860926888594658, 0.1414274705423212, 0.1363192024553005, 0.16178714403519134, 0.1788910296086802, 0.19168846784427573, 9.999999999998899e-05, 9.999999999998899e-05, 0.0002069372954538462, 0.00011109490541272304, 9.999999999998899e-05, 9.999999999998899e-05, 0.0025638741506245344, 9.999999999998899e-05, 9.999999999998899e-05, 0.07723237754875367, 0.09541080189859841, 0.08918577582873144, 0.08634834440144201, 0.1093774186654829, 0.09584460042514242, 0.09437452795933454, 0.09301587367018238, 0.09126534912154727, 0.3758944732964412, 0.3524492145654542, 0.36564430466183695, 0.38901970123426666, 0.37027761292455474, 0.3763842374631391, 0.37696558568081107, 0.3564445630601769, 0.3459433050566376, 0.08764622755453999, 0.07533054808491779, 0.07695832480274911, 0.07126865694085904, 0.07426295269702876, 0.07829091424826551, 0.0816904699162464, 0.07015976802983825, 0.07453264644312474, 0.18227419261236477, 0.142741424545482, 0.16702403281974765, 0.15889182239112798, 0.17894045563473393, 0.21091358503786772, 0.17335755482899118, 0.16037666668844663, 0.16352839164810362, 0.2110342086002578, 0.2126153299304261, 0.2348696350555396, 0.20393527403192513, 0.20514417664905227, 0.21380391809038324, 0.23416661268410877, 0.22267023572016387, 0.23198909383816868, 0.1618957611794145, 0.16027526016829596, 0.1742414768932471, 0.1728625334177346, 0.14763504682130202, 0.1424444189602344, 0.1647773113746851, 0.18087967673501615, 0.1687070239508539, 0.16933902568004322, 0.15949009958684257, 0.16245649380171145, 0.16060394299874858, 0.20270633230382484, 0.18849090249729084, 0.17087071516649843, 0.17086873541414638, 0.17469742276580402, 0.16984446711006185, 0.17530393393489396, 0.17277602255530622, 0.15927419220185624, 0.18474794875301914, 0.17106948231085028, 0.15913788523438743, 0.17838089181513295, 0.17288895315899078, 0.35584087212862325, 0.1572685774735395, 0.5376736443463175, 0.3270096972530824, 0.17330070313157053, 0.16410830401890453, 0.19118388185483703, 0.3195149278248297, 0.1429182263564226, 0.1895078227489705, 0.2604962738756542, 0.295635638758031, 0.15125378429519154, 0.1731616045541119, 0.16045901804018903, 0.20289492367361994, 0.47741550024259893, 0.19996043060818425, 0.19485299119315946, 0.1849948202509265, 0.19775937066926186, 0.16897382545805795, 0.19052995832664188, 0.1883914829244332, 0.18505255474725013, 0.19154556830502822, 0.1763771692211662, 0.06378810302108417, 0.07771952434339002, 0.06980694868890225, 0.06048476783841583, 0.06577222886318723, 0.07094863984278732, 0.06959643546857441, 0.05956117664428273, 0.06590322693269046]}, "mutation_prompt": null}
{"id": "68a0aec0-c7fa-4be7-953f-985cd352aaea", "solution": "import numpy as np\n\nclass RefinedHybridDEWithLevyFlight:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.scaling_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        # Initialize population\n        population_size = self.initial_population_size\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        \n        # Covariance matrix for learning\n        cov_matrix = np.eye(self.dim)\n\n        while num_evaluations < self.budget:\n            # Dynamically adjust population size\n            if num_evaluations > self.budget * 0.5:\n                population_size = max(self.dim, population_size // 2)\n                population = population[:population_size]\n                fitness = fitness[:population_size]\n\n            # Generate trial population via DE mutation and crossover\n            trial_population = np.empty_like(population)\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + self.scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            # Evaluate trial population\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += population_size\n\n            # Replace if trial solution is better\n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            # Update best individual\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(best_individual):\n                best_individual = population[best_idx]\n\n            # Covariance Matrix Learning Update\n            if num_evaluations < self.budget:\n                sampled_indices = np.random.choice(population_size, 2, replace=False)\n                diff = population[sampled_indices[0]] - population[sampled_indices[1]]\n                cov_matrix = (1 - 1.0/self.dim) * cov_matrix + (1.0/self.dim) * np.outer(diff, diff)\n\n                # Adaptive adjustment of scaling factor\n                self.scaling_factor = self.adjust_scaling_factor(cov_matrix)\n\n            # Integrate Levy Flight for enhanced exploration\n            if num_evaluations < self.budget and np.random.rand() < 0.5:\n                levy_step = self.levy_flight(self.dim)\n                candidate = best_individual + levy_step * (population[best_idx] - np.mean(population, axis=0))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(best_individual):\n                    best_individual = candidate\n\n        return best_individual\n\n    def adjust_scaling_factor(self, cov_matrix):\n        variance_measure = np.sum(np.diag(cov_matrix))\n        return min(1.0, max(0.6, 0.8 * (1.0 + variance_measure)))\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                (np.math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, size=(dim,))\n        v = np.random.normal(0, 1, size=(dim,))\n        step = u / np.abs(v)**(1 / beta)\n        return step\n\n# Usage example:\n# optimizer = RefinedHybridDEWithLevyFlight(budget=10000, dim=10)\n# best_solution = optimizer(my_black_box_function)", "name": "RefinedHybridDEWithLevyFlight", "description": "A refined hybrid metaheuristic enhancing Adaptive Differential Evolution with Lévy Flight, incorporating dynamic scaling and adaptive population resizing for improved exploration and exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.19241049256220683, "feedback": "The algorithm RefinedHybridDEWithLevyFlight got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.19.", "error": "", "parent_id": "35d583a4-b014-46dd-a1f1-788add07f48b", "metadata": {"aucs": [0.36820350504585453, 0.43218497502661235, 0.4100761976142311, 0.4876809555263607, 0.4907562467652459, 0.44271376222642944, 0.5059217477008388, 0.49540899832013885, 0.6214474696549779, 0.2308248542101935, 0.1893904415459916, 0.21672892127820031, 0.13586194509610927, 0.2620316841040572, 0.18616679723311658, 0.16009371882228685, 0.14955410217806597, 0.44010625477597043, 0.09019244092005485, 0.09138249816548527, 0.08143032946908801, 0.09727002934428308, 0.09590178883115152, 0.0913856077664883, 0.10252850126459012, 0.08595001081850528, 0.13884050364190792, 0.05813061266299824, 0.0743154566918125, 0.0743796026678849, 0.07459232854975051, 0.0765299614379541, 0.08227844844236809, 0.07634996172347186, 0.07468540961459624, 0.09744677929352707, 0.9787117622675712, 0.9508531196436022, 0.9391167416745436, 0.9548387578213424, 0.976991324449504, 0.9478981011740596, 0.9514337477737757, 0.9714141391427334, 0.9414482543564563, 0.20140177126116943, 0.17891538272631702, 0.13981495260548493, 0.1479758472821724, 0.1486021489463143, 0.16243734254701647, 0.19032420557316054, 0.19590610255410157, 0.16483099552774838, 0.19564242822309974, 0.20514508936125753, 0.2517703526011732, 0.21400596633448743, 0.22291079211269182, 0.23247226471250604, 0.22807882898150156, 0.3017031896915464, 0.28440414930795255, 0.08654428408971848, 0.09515426276309225, 0.11234317552262074, 0.11500239919521171, 0.06938014934207404, 0.08479885407616294, 0.11816732079352099, 0.11784129518790831, 0.09988103738521714, 0.10354213306729054, 0.02217438503972624, 0.029064101844969437, 0.1033367274426149, 0.11592380957365078, 0.10580981206277107, 0.08719912251179263, 0.07420751088868038, 0.0936359034259554, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013042836885213016, 0.013847808451643906, 0.00579815009318585, 0.034691396188668344, 0.02934942018615183, 9.999999999998899e-05, 0.1042349049801301, 0.08107306688945815, 0.07852468434400273, 0.08500825167291737, 0.11602230333671992, 0.09809435037917669, 0.11970106852388385, 0.11108852570778471, 0.16599391511372397, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06797771690513421, 0.13062091762962447, 0.07033069234008638, 0.061375127982083, 0.08828634605420593, 0.09600165158247187, 0.07763405026713988, 0.07680843294851125, 0.08506950181949868, 0.3620752766368307, 0.3940574689793671, 0.3419244482766213, 0.36216178213282624, 0.38269151592870176, 0.4401837014712173, 0.35388116165118777, 0.3317623248815085, 0.32436604982035433, 0.08216115644233701, 0.0675318024454471, 0.07411782258159072, 0.0661190311381562, 0.0655698473864903, 0.07824820503661611, 0.0816904699162464, 0.07555696276040158, 0.07593731708656215, 0.1826183392024583, 0.142741424545482, 0.16702481058495144, 0.1588918223907374, 0.17894045563439775, 0.21091383611826076, 0.16719158382621846, 0.1366814608679532, 0.16360639813622124, 0.18718199172285155, 0.20234153403837407, 0.23874915266506014, 0.1829183113490811, 0.19372553623326716, 0.1920661749188748, 0.2229909905848111, 0.20174698081902553, 0.22561881450056043, 0.14908719759747746, 0.14146964649793625, 0.16689047663137302, 0.15398634700081515, 0.12730156719460772, 0.13548798262592376, 0.14906004643750947, 0.18409506083723415, 0.1671462495271926, 0.16933902568004322, 0.15598447252091607, 0.16384453808897048, 0.16060394299874858, 0.20270633230382484, 0.18849090249729084, 0.16923708101693502, 0.16391843371277914, 0.17101932787185758, 0.16814500455929793, 0.17517891677674957, 0.17025691366153495, 0.17551016690774246, 0.1774909537943482, 0.16950098890932608, 0.16727152130966227, 0.16996705459600092, 0.1712979398342499, 0.2710763964660444, 0.15726933207676463, 0.49733969537324474, 0.2369115719374557, 0.16810656926752798, 0.1886729215351669, 0.19093398322747823, 0.28546278534181, 0.13427886845123616, 0.15909239532940866, 0.1964128239740649, 0.24277390724815295, 0.1525212748251331, 0.17387766299192686, 0.14652610581493697, 0.20289517144857916, 0.4113049877559657, 0.19996045963801778, 0.19485298218553093, 0.1841081512692756, 0.19775937064628868, 0.16897382545803197, 0.19052995492534242, 0.1883914829244332, 0.18505255466406423, 0.1915455681616275, 0.17637716922215418, 0.06520090595845374, 0.0673467071285393, 0.06297661803070054, 0.05708764606867933, 0.06455770584306753, 0.07294701335500375, 0.06783725072848179, 0.05161710762761418, 0.0641414008567972]}, "mutation_prompt": null}
{"id": "d0d68d47-9efa-482d-8889-90464f4b9be7", "solution": "import numpy as np\n\nclass RefinedHybridDifferentialEvolutionWithLevyFlight:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.scaling_factor = 0.8\n        self.crossover_rate = 0.9\n        self.dynamic_population = True  # New flag for dynamic population\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        \n        # Covariance matrix for learning\n        cov_matrix = np.eye(self.dim)\n\n        while num_evaluations < self.budget:\n            # Dynamic population size based on evaluations\n            if self.dynamic_population:\n                effective_pop_size = int(self.population_size * (1 - num_evaluations/self.budget))\n                population = population[:effective_pop_size]\n                fitness = fitness[:effective_pop_size]\n\n            # Generate trial population via DE mutation and crossover\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + self.scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            # Evaluate trial population\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n\n            # Replace if trial solution is better\n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            # Update best individual\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(best_individual):\n                best_individual = population[best_idx]\n\n            # Covariance Matrix Learning Update\n            if num_evaluations < self.budget:\n                sampled_indices = np.random.choice(len(population), 2, replace=False)\n                diff = population[sampled_indices[0]] - population[sampled_indices[1]]\n                cov_matrix = (1 - 1.0/self.dim) * cov_matrix + (1.0/self.dim) * np.outer(diff, diff)\n\n                # Adaptive adjustment of scaling factor\n                self.scaling_factor = self.adjust_scaling_factor(cov_matrix)\n\n            # Fitness-based Levy Flight for enhanced exploration\n            if num_evaluations < self.budget and np.random.rand() < 0.5:\n                levy_step = self.levy_flight(self.dim) * (1 + np.abs(func(best_individual)) / np.min(fitness))\n                candidate = best_individual + levy_step * (population[best_idx] - np.mean(population, axis=0))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(best_individual):\n                    best_individual = candidate\n\n        return best_individual\n\n    def adjust_scaling_factor(self, cov_matrix):\n        variance_measure = np.sum(np.diag(cov_matrix))\n        return min(1.0, max(0.5, 0.8 * (1.0 + variance_measure)))\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                (np.math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, size=(dim,))\n        v = np.random.normal(0, 1, size=(dim,))\n        step = u / np.abs(v)**(1 / beta)\n        return step\n\n# Usage example:\n# optimizer = RefinedHybridDifferentialEvolutionWithLevyFlight(budget=10000, dim=10)\n# best_solution = optimizer(my_black_box_function)", "name": "RefinedHybridDifferentialEvolutionWithLevyFlight", "description": "A refined hybrid metaheuristic using enhanced differential evolution with dynamic population size and fitness-based Levy Flight for superior convergence.", "configspace": "", "generation": 6, "fitness": 0.2560963991725465, "feedback": "The algorithm RefinedHybridDifferentialEvolutionWithLevyFlight got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.21.", "error": "", "parent_id": "35d583a4-b014-46dd-a1f1-788add07f48b", "metadata": {"aucs": [0.5873329745570708, 0.5766683153896263, 0.5810852473486535, 0.6146045901315237, 0.6338448670661205, 0.6077175271847113, 0.6272225488108671, 0.580801760232481, 0.6141174937483708, 0.3646024378898993, 0.3823587738195654, 0.40496418734686057, 0.3645973928450147, 0.3411467085784662, 0.36618038070336434, 0.3648403843229553, 0.3922575361749815, 0.40832355509461016, 0.18948530213181358, 0.148273632213484, 0.12457699414270973, 0.20592518013363303, 0.11100620417585672, 0.11022256595036584, 0.263126679349751, 0.18777597899192855, 0.2438278006624568, 0.08994824196491757, 0.10622071892483231, 0.11898779767726098, 0.09024350214281385, 0.10482413835213067, 0.09499237568600105, 0.09794782093711218, 0.0924730149206815, 0.11065457705921711, 0.9516153820552921, 0.9387211083205091, 0.9373743608343545, 0.9752542145851033, 0.9531414952194442, 0.9264231711046182, 0.9681973388451661, 0.9622116581217779, 0.953320506111958, 0.2770499868181331, 0.2791423450868442, 0.29807008312333916, 0.3151857562684277, 0.28694291808345884, 0.2870835559978605, 0.3073270308702766, 0.33483891369686314, 0.3422860355870526, 0.4886578602267756, 0.449109760932786, 0.43556929456133786, 0.49295152582289115, 0.4421817945302894, 0.4174485480596529, 0.4311143828127937, 0.468314070630947, 0.44933159409549017, 0.24423607420130677, 0.25849846351776995, 0.20128760905700238, 0.2295541444096072, 0.16007589052533733, 0.15942478826869533, 0.23869638344214117, 0.2058085969294733, 0.1733232414309539, 0.16397366842110095, 0.04864588932191127, 0.009428752036368837, 0.21903795663174985, 0.23618218726599893, 0.165348348694893, 0.21937441317517292, 0.2010591978446049, 0.20259006862072415, 0.03996060103171806, 0.09373913002886636, 0.02652825984671703, 0.06678441636851817, 0.07774641525608006, 0.07011363092308798, 0.10070451237283251, 0.08586066420955518, 0.04394466831938992, 0.17036741662496502, 0.18006313068348623, 0.15476805938398852, 0.185226896084982, 0.16653065297106018, 0.1250658704718739, 0.24987861857008042, 0.2603879008578148, 0.20903676129395088, 0.0451754948156351, 0.022797450383955087, 0.03326170851351251, 0.0017987873629473627, 9.999999999998899e-05, 0.001605340812291245, 0.06054749945810112, 0.03794147723972252, 0.05463993369936815, 0.11582718922737056, 0.14047594493778193, 0.15996249757687642, 0.1218889597659194, 0.13967793590038002, 0.1936060519256967, 0.16456916615827466, 0.17767964006106285, 0.15439518601744961, 0.47822424157698074, 0.5006907103379632, 0.48325161940863204, 0.45870747602989637, 0.4706255659947143, 0.492233452038187, 0.5077960873551624, 0.4894031038557546, 0.510353958922021, 0.08516975018687645, 0.08237475472841072, 0.1000985911303407, 0.10323219473745482, 0.07689870152900091, 0.07811692078987198, 0.07584160690529318, 0.08941110826317367, 0.08699192947447554, 0.1594531250304464, 0.15382979007603226, 0.14732810028414478, 0.13691443630452282, 0.16379273793721294, 0.1322203954920298, 0.1502054075273278, 0.16045379540113736, 0.1467154277020878, 0.2599672970586834, 0.27663852073569684, 0.268901020602357, 0.2532935399522821, 0.2536948953651976, 0.23838540986154577, 0.2507234781453913, 0.26894191259152866, 0.2922437623037124, 0.21152669796834034, 0.19000316896060265, 0.19739878337905836, 0.1906022005345358, 0.20722321097789376, 0.14937133327723262, 0.16987871271223665, 0.18671074008157174, 0.21109431120213362, 0.16175920595510762, 0.1682847220769057, 0.17736677775974896, 0.16398881369593798, 0.1947945343649724, 0.17373989518774835, 0.1929362237119856, 0.15525793320681858, 0.18755887789089942, 0.18729296280025465, 0.17179210144385182, 0.17374691422064004, 0.1806789278898392, 0.17526746103046553, 0.18385603848497667, 0.19897091446570359, 0.17865372257902012, 0.17271437854107807, 0.17845475355713603, 0.6052039902959842, 0.182776796052454, 0.49640079518688796, 0.28244216649679854, 0.4798642542039233, 0.1707887545900767, 0.17382646405314317, 0.17437328004428387, 0.1856463414210443, 0.5318078027392263, 0.18751421916275524, 0.3149409597167475, 0.17292175156028788, 0.36689771042156094, 0.19946932511884485, 0.19224473130814024, 0.40586206881951126, 0.17239086675914328, 0.17426885774795975, 0.16899949577397622, 0.20463930722691182, 0.1713863850398657, 0.20674656362864652, 0.18443602154151273, 0.17403696062407104, 0.1837660737549618, 0.06619674486117177, 0.06316482172251381, 0.07524841743434685, 0.07313047411160456, 0.08461110536823713, 0.07288040829754117, 0.06035834917942573, 0.08080782464742953, 0.06147554675113731]}, "mutation_prompt": null}
{"id": "e95109a1-16e0-4231-b328-b689557d04a6", "solution": "import numpy as np\n\nclass EnhancedHybridDEWithCovarianceAndLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.scaling_factor = 0.9\n        self.crossover_rate = 0.85\n        self.dynamic_population = True\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        \n        cov_matrix = np.eye(self.dim)\n\n        while num_evaluations < self.budget:\n            if self.dynamic_population:\n                effective_pop_size = max(2, int(self.population_size * (1 - num_evaluations/self.budget)))\n                population = population[:effective_pop_size]\n                fitness = fitness[:effective_pop_size]\n\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + self.scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n\n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(best_individual):\n                best_individual = population[best_idx]\n\n            if num_evaluations < self.budget:\n                sampled_indices = np.random.choice(len(population), 2, replace=False)\n                diff = population[sampled_indices[0]] - population[sampled_indices[1]]\n                cov_matrix = 0.9 * cov_matrix + 0.1 * np.outer(diff, diff)\n\n                self.scaling_factor = self.adjust_scaling_factor(cov_matrix)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.5:\n                levy_step = self.levy_flight(self.dim) * (1 + np.abs(func(best_individual)) / np.min(fitness))\n                candidate = best_individual + levy_step * (best_individual - np.mean(population, axis=0))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(best_individual):\n                    best_individual = candidate\n\n        return best_individual\n\n    def adjust_scaling_factor(self, cov_matrix):\n        variance_measure = np.sum(np.diag(cov_matrix))\n        return min(1.0, max(0.6, 0.9 * (1.0 + variance_measure)))\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                (np.math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, size=(dim,))\n        v = np.random.normal(0, 1, size=(dim,))\n        step = u / np.abs(v)**(1 / beta)\n        return step\n\n# Usage example:\n# optimizer = EnhancedHybridDEWithCovarianceAndLevy(budget=10000, dim=10)\n# best_solution = optimizer(my_black_box_function)", "name": "EnhancedHybridDEWithCovarianceAndLevy", "description": "An enhanced hybrid metaheuristic that integrates dynamic differential evolution with stochastic covariance adaptation and fitness-biased Levy Flight for robust exploration and exploitation.", "configspace": "", "generation": 7, "fitness": 0.23536868511529488, "feedback": "The algorithm EnhancedHybridDEWithCovarianceAndLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.20.", "error": "", "parent_id": "d0d68d47-9efa-482d-8889-90464f4b9be7", "metadata": {"aucs": [0.5592806386442701, 0.5733086177099485, 0.5863249321418333, 0.6132344780138479, 0.610719308067593, 0.627235548236351, 0.6093845679367551, 0.580132108196804, 0.558926079985643, 0.37595067639908586, 0.37956607358216776, 0.42004410597206976, 0.4015393562374284, 0.35032255367039633, 0.36749513482366924, 0.3539438087697897, 0.3808271977882077, 0.37990550904327947, 0.186176695758428, 0.11773140923526404, 0.1632827789277591, 0.11222529984217178, 0.19583409913483452, 0.19990750058244544, 0.23012099834388733, 0.13506667438104958, 0.20768942670988544, 0.12584662672057179, 0.1374273792101116, 0.12328690150449895, 0.18136771489241632, 0.11099168132593074, 0.10446083806958273, 0.11513140422286128, 0.09550403651119999, 0.14085792051345014, 0.9638164340873588, 0.9425010774190372, 0.9523006356010412, 0.9669618007540188, 0.9343619699425424, 0.9153612578576651, 0.9583765893021405, 0.9432481266599184, 0.9450401299177585, 0.2653206145368232, 0.27558943962613736, 0.28115395382457686, 0.2462705139552831, 0.25475941450266104, 0.2821097581306442, 0.27010967139447717, 0.26736726640778874, 0.2741453984149774, 0.3777971766799385, 0.25140932748273215, 0.4329624835701962, 0.4368092202685032, 0.43039002086852907, 0.3974852002970026, 0.23571071708523983, 0.37279364038234064, 0.36758143726693304, 0.1612260166322772, 0.14770347890574287, 0.19436930127616647, 0.16537622375360295, 0.20256758888831705, 0.15805521881373774, 0.20845544498419233, 0.1321327762602783, 0.19402294209858195, 0.035802047715419616, 0.020865250174052608, 0.020337697071239003, 0.19862372201299328, 0.1684522355943756, 0.1843817909432789, 0.13420021183027642, 0.18654507824073518, 0.13075090658498467, 0.05242948484549903, 0.06304778280163081, 0.04665241298388523, 0.04694818207275786, 0.03265983467106848, 0.02585953237157168, 0.0376874684750339, 0.018887126451983427, 0.04067137758616668, 0.12022352232499556, 0.14642047577364026, 0.12501293227550214, 0.1307881169205335, 0.10871848771142956, 0.08576740851803966, 0.16933316146870547, 0.16661995351317183, 0.1727265655540139, 0.016441834682597967, 0.012436574268708367, 0.013828522955213862, 0.006092010108165735, 0.025860140134828513, 9.999999999998899e-05, 0.025615004174700196, 0.018130201400187618, 0.01301889649912713, 0.13031812131568388, 0.10974957384835904, 0.1236084151661273, 0.1256302139816542, 0.11754732347437058, 0.1427923420006869, 0.1310528191330037, 0.13838626844655133, 0.10298091919248764, 0.4484485293662802, 0.3990468190261982, 0.4292903099213179, 0.45144590749092217, 0.4251101281124644, 0.4447310927557121, 0.42918517314707794, 0.43195462272039564, 0.43074299620261336, 0.08909689408071375, 0.08512054248512124, 0.10201474695230317, 0.09335693678704171, 0.08004046565723677, 0.08715745303014277, 0.08515747870238499, 0.07732465555569779, 0.07522794422063439, 0.13869316287477762, 0.13306128679961782, 0.14107867842708888, 0.1820846170318975, 0.12511570805734085, 0.17843350570041472, 0.13252163615210488, 0.16880795538091609, 0.1498852792134987, 0.27580195545793373, 0.24711516432020575, 0.24740795936346216, 0.2195463457662037, 0.22052287103860346, 0.22119680094400795, 0.28445072928668735, 0.2919258423065566, 0.26413445466494745, 0.18091442574457406, 0.18988559257926618, 0.19371263353013246, 0.1569964544828053, 0.1799108800392072, 0.16514916882496233, 0.19406803556702046, 0.2049383387283732, 0.20489302651813757, 0.16546715742344498, 0.15626697205121232, 0.16544438838181008, 0.22620221195560375, 0.15206253759551214, 0.17664689666261746, 0.20087237489443532, 0.17198345270090865, 0.16086497744009742, 0.1969801994661634, 0.22081628602300274, 0.18863380730702073, 0.17458109228872198, 0.1694646932604451, 0.18614483838032936, 0.1763631532559462, 0.17480035392829085, 0.18281727014731108, 0.18782945333204204, 0.21221406064079373, 0.19689324781608386, 0.16245881238468296, 0.4644848688349641, 0.44526615695405025, 0.16535352767690714, 0.18088935901896908, 0.15754286722817212, 0.18916336693621927, 0.19029419619808685, 0.3002885302592867, 0.21510842306023903, 0.290122670539371, 0.29151755691792847, 0.18559173559262554, 0.20263961973230138, 0.18323764506165918, 0.19068392779232446, 0.17246202564315827, 0.17824273382618872, 0.1913191761583627, 0.17476411715687734, 0.1935467291863311, 0.2052904021005978, 0.18107705412561848, 0.19476033256486758, 0.07271881400369207, 0.06697039217604883, 0.06568585899099066, 0.05903334186880471, 0.05764616341173312, 0.07221874817339324, 0.063999870475699, 0.06509434653186907, 0.06941368813078608]}, "mutation_prompt": null}
{"id": "258c6dd7-988e-4e0b-b60a-ae033ddc30e7", "solution": "import numpy as np\n\nclass RefinedHybridDifferentialEvolutionWithMultiLevelStrategy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.scaling_factor = 0.8\n        self.crossover_rate = 0.9\n        self.multi_level_population = True  # New multi-level population strategy\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        \n        while num_evaluations < self.budget:\n            if self.multi_level_population:\n                levels = 2 + int(3 * (1 - num_evaluations/self.budget))\n                level_size = len(population) // levels\n                effective_pop = [population[i*level_size:(i+1)*level_size] for i in range(levels)]\n                effective_fit = [fitness[i*level_size:(i+1)*level_size] for i in range(levels)]\n            else:\n                effective_pop, effective_fit = [population], [fitness]\n\n            trial_population = np.empty_like(population)\n            for pop, fit in zip(effective_pop, effective_fit):\n                for i in range(len(pop)):\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x0, x1, x2 = pop[indices]\n                    mutant_vector = x0 + self.scaling_factor * (x1 - x2)\n                    mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                    cross_points = np.random.rand(self.dim) < self.crossover_rate\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n\n                    trial_vector = np.where(cross_points, mutant_vector, pop[i])\n                    trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n\n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(best_individual):\n                best_individual = population[best_idx]\n\n            if num_evaluations < self.budget:\n                if np.random.rand() < 0.5:\n                    perturbation = self.stochastic_levy_perturbation() * (1 + np.abs(func(best_individual)) / np.min(fitness))\n                    candidate = best_individual + perturbation * (population[best_idx] - np.mean(population, axis=0))\n                    candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                    candidate_fitness = func(candidate)\n                    num_evaluations += 1\n                    if candidate_fitness < func(best_individual):\n                        best_individual = candidate\n\n        return best_individual\n\n    def stochastic_levy_perturbation(self, dim_beta=1.5):\n        beta = dim_beta\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                (np.math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, size=(self.dim,))\n        v = np.random.normal(0, 1, size=(self.dim,))\n        step = u / np.abs(v)**(1 / beta)\n        return step\n\n# Usage example:\n# optimizer = RefinedHybridDifferentialEvolutionWithMultiLevelStrategy(budget=10000, dim=10)\n# best_solution = optimizer(my_black_box_function)", "name": "RefinedHybridDifferentialEvolutionWithMultiLevelStrategy", "description": "A refined hybrid metaheuristic using adaptive differential evolution with multi-level population strategy and stochastic Levy-like perturbation for enhanced convergence.", "configspace": "", "generation": 8, "fitness": 0.10349462914151915, "feedback": "The algorithm RefinedHybridDifferentialEvolutionWithMultiLevelStrategy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.15.", "error": "", "parent_id": "d0d68d47-9efa-482d-8889-90464f4b9be7", "metadata": {"aucs": [0.17670445584231742, 0.10486012755266039, 0.1592070403050173, 0.14407130491882636, 0.1474365195103905, 0.14726445776592367, 0.16998056041640264, 0.183706271933625, 0.10834367542022705, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02429254508560097, 0.022107115263346855, 0.018070899007489816, 0.05299057963172549, 0.025075815314680727, 0.03466534975526525, 0.02599393452896437, 0.031200817538306724, 0.032996706038174506, 0.011007520830053408, 0.014371657324226739, 9.999999999998899e-05, 0.026100930171997105, 0.011452832404733826, 0.03331864437266596, 0.03184296405593434, 0.010136672883209963, 0.010718937847930987, 0.6783566711980413, 0.3742050505574209, 0.7601769026125437, 0.5825597483579414, 0.9305273105323494, 0.9936301463662726, 0.6535187258954778, 0.8492592312352946, 0.2531077477804299, 0.07288009099910264, 0.02253877865391407, 0.011029969828290076, 0.0493193092711941, 0.05171877136601033, 0.06862159266615253, 0.040994144823375045, 0.06717833712394916, 0.05002477561270047, 0.11498460343944894, 0.088060504995776, 0.09897812757977176, 0.14635076252265133, 0.10177869829586217, 0.09105888319071198, 0.08911161527948774, 0.11160150691907433, 0.10409757113609963, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005921970363676365, 0.009008085932841858, 9.999999999998899e-05, 9.999999999998899e-05, 0.004826503999168397, 0.0023843169874977477, 0.058234098411887314, 0.058234098411887314, 0.058234098411887314, 0.058234098411887314, 0.058234098411887314, 0.058234098411887314, 0.058234098411887314, 0.06387835086792126, 0.058234098411887314, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.028017670814293516, 0.007193183265536751, 0.020994892325402748, 0.015597295760420793, 0.022862251113010656, 0.00584332446695246, 0.019698817923589518, 0.043823403872870426, 0.0014729520782963412, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.17869865854020694, 0.17507330723705417, 0.17999491905011678, 0.1887590716505787, 0.16585787968938037, 0.15184388470644772, 0.19048726494397916, 0.2849018948214108, 0.24944170257479303, 0.02898695661372619, 0.027959949911621873, 0.03990630322273869, 0.04192153074384897, 0.03255455688147102, 0.029287717872662156, 0.03092987317696183, 0.026109260020876324, 0.02887887181623794, 0.11919540119598859, 0.13811843603265772, 0.12177492029369363, 0.10729618842648148, 0.14723439640241598, 0.13204501168557803, 0.1500287829842124, 0.10793342577784093, 0.13737628778356337, 0.1488505348395338, 0.13124550429983006, 0.1613932299901244, 0.14894925862642028, 0.1524664371370278, 0.15037254861779037, 0.142083372884369, 0.17377774300845283, 0.15642035909694074, 0.08873382615642877, 0.0719840473332437, 0.11943774146681696, 0.08418854185718605, 0.09897128427030166, 0.08531796148553406, 0.097499492915751, 0.11282175029033648, 0.11367296421077677, 0.259193388104875, 0.2590855546970535, 0.259381082211959, 0.25916764417138105, 0.2590943350782643, 0.25918688167324755, 0.25936423902373795, 0.25905041173918053, 0.2593605887535223, 0.14264532336433733, 0.08577797880483629, 0.15000146278588722, 0.0, 0.014258767533987027, 0.08304328348782386, 0.11269446390715443, 0.03811785901468667, 0.1384597453566928, 0.15119490910795141, 0.09535655240423124, 0.09816988461949983, 0.11766123492020963, 0.12378519114797815, 0.09899518853775313, 0.1454070647327924, 0.1704495805976476, 0.11940903989451945, 0.13226917225120993, 0.1101912088550776, 0.10501473159977337, 0.10036109878240462, 0.12210131132791668, 0.08531567250011685, 0.09943366289364763, 0.12617810870169355, 0.08825188456347166, 0.14858725769460523, 0.14299618337200903, 0.15455142858640958, 0.16673131601515379, 0.15425689896026484, 0.16400790338145876, 0.16126370961074787, 0.16347586576531814, 0.16715406157583623, 0.027844102575774965, 0.016289817045954114, 0.031393493129599714, 0.03852475941227107, 0.055113827086051614, 0.057661371775254655, 0.03584296103610318, 0.04995441745313767, 0.045795239376637764]}, "mutation_prompt": null}
{"id": "386502ad-5675-49c9-b1ac-1234b1c3f70e", "solution": "import numpy as np\n\nclass EnhancedHybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim  # Reduced for more focused search\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.scaling_factor = 0.7  # Adjusted scaling factor\n        self.crossover_rate = 0.85  # Adjusted crossover rate\n        self.dynamic_population = False  # Removed dynamic population flag\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n\n        while num_evaluations < self.budget:\n            # Adaptive exploration strategy\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + self.scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            # Evaluate trial population\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n\n            # Replace if trial solution is better\n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            # Update best individual\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(best_individual):\n                best_individual = population[best_idx]\n\n            # Fitness-based exploration with informed search\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = best_individual + 0.1 * (population[best_idx] - np.mean(population, axis=0))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(best_individual):\n                    best_individual = candidate\n\n        return best_individual\n\n# Usage example:\n# optimizer = EnhancedHybridDifferentialEvolution(budget=10000, dim=10)\n# best_solution = optimizer(my_black_box_function)", "name": "EnhancedHybridDifferentialEvolution", "description": "An enhanced hybrid metaheuristic using improved differential evolution with adaptive strategies and informed search for robust convergence.", "configspace": "", "generation": 9, "fitness": 0.3030051724957605, "feedback": "The algorithm EnhancedHybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.23.", "error": "", "parent_id": "d0d68d47-9efa-482d-8889-90464f4b9be7", "metadata": {"aucs": [0.7201321155151885, 0.7209782482634396, 0.7224695081216899, 0.7285107530054211, 0.7497805787783252, 0.7360509779465715, 0.7354518726753858, 0.7249050173536324, 0.7127482652583693, 0.528185854033152, 0.5471447959560913, 0.507417905696298, 0.5227876691366351, 0.5311475415860135, 0.5279342390476274, 0.5216529840428596, 0.5491713634528339, 0.5295924831307228, 0.10598431462909552, 0.11275885017452147, 0.10954811861928915, 0.1278024839052927, 0.10393596765643265, 0.13336930544849657, 0.1122072987513586, 0.10981621397542529, 0.10053650588816276, 0.09987833892001541, 0.08952249916808708, 0.10574519719058573, 0.09964883365812216, 0.11005002993533652, 0.10487086273812984, 0.09259561843308817, 0.10270646191209032, 0.10667011322854669, 0.9337606596059351, 0.9664918196066554, 0.9398037202864228, 0.9406713480978092, 0.9189616455379384, 0.945652805806398, 0.9543095574419449, 0.9593635409866386, 0.9688711528284106, 0.3628183350989518, 0.34185268927054957, 0.3642583736435535, 0.38525176896312896, 0.3567721207463105, 0.364144019182546, 0.3540618286976073, 0.3916243916382721, 0.3343536957624348, 0.6490034467931274, 0.6355250807974432, 0.5954365899640937, 0.629738355143082, 0.6298111426810793, 0.7174620761792952, 0.6177662483715256, 0.6456209436152169, 0.6821211376745256, 0.2100771147710382, 0.1988448281942915, 0.2060845459196189, 0.2349155283619151, 0.22477275435601718, 0.2323858093051434, 0.2674701394149961, 0.23842386303711993, 0.25209325236080227, 0.2956712392103382, 0.14642101165541987, 0.16567385189841188, 0.29937960271689257, 0.26829285080537735, 0.21278236135892092, 0.18520814771077398, 0.18302031929421392, 0.2219301308782472, 0.13462317295987036, 0.14823473565751977, 0.18446027037696833, 0.13893157121650457, 0.20012047904846653, 0.17373268515092244, 0.1580356129076005, 0.13728149371984344, 0.17652159547212853, 0.3219589526148584, 0.3157663977835652, 0.2909970110932719, 0.2663133469711557, 0.3049879816886295, 0.2647218071763531, 0.30880186207260396, 0.3559700306551028, 0.33839632992894453, 0.08140538194003788, 0.06808058866503364, 0.053280593274207755, 0.07058509254936185, 0.07552847493892245, 0.05100952829267158, 0.06358549544007197, 0.07540330150005192, 0.03286284441576681, 0.18876125863789617, 0.20243606759477573, 0.1922007412730301, 0.20507061936145876, 0.1980561816967581, 0.1984962951946404, 0.1835424183463047, 0.18029622392483324, 0.1936619504974001, 0.5320093719147094, 0.5507843782581363, 0.5461863888017586, 0.5555547217691705, 0.5402532963026745, 0.5528058668540304, 0.57029922191839, 0.5460284401777427, 0.5306006852531318, 0.08783444590845191, 0.09200682723310694, 0.0979433918877961, 0.08695097670332341, 0.0959349030844533, 0.09331915593911566, 0.09163436011400494, 0.10005395809252171, 0.08856147600843, 0.16061389467306175, 0.14414139431968032, 0.14799581093690028, 0.2928075632620901, 0.17843450897066437, 0.14891263056098103, 0.14820652363705944, 0.16031079551079996, 0.15212201411890636, 0.34518751363111455, 0.3170909205475051, 0.30874004104784336, 0.3182346012211643, 0.3109823830622288, 0.30044570648132507, 0.33120810438947934, 0.3363320512743695, 0.32260877644762187, 0.2504594068158408, 0.23308271049195162, 0.2139911586463633, 0.23481909843750326, 0.22453026928473485, 0.23503291036269025, 0.25530898755309595, 0.26174399055043773, 0.2412404297810059, 0.1885042633665639, 0.17889429299943327, 0.1889478982574485, 0.17875430360044808, 0.17984123428766308, 0.171640419994186, 0.19483051964721243, 0.19523788606696013, 0.1841405544591268, 0.17827387688308305, 0.17637061621331285, 0.19074925974443813, 0.21034185148612483, 0.19752127454505441, 0.18320314760013057, 0.17602281122648944, 0.18594585428704435, 0.19337065064400705, 0.4239926380355946, 0.17734288924274044, 0.16237771669986578, 0.38352375152909945, 0.4179274318088593, 0.48330404717485853, 0.17756282396497114, 0.4228078306740929, 0.696252927405299, 0.569759820142413, 0.20052692602477196, 0.19635258062797634, 0.472430808735416, 0.19274102129876503, 0.4718123677775833, 0.20106441532183594, 0.12450527408948475, 0.20643806417356614, 0.17706368658841132, 0.20247486439961138, 0.20832378771237814, 0.18821916793603943, 0.17760474898606826, 0.18515801304564605, 0.18426497874396341, 0.1935729403917954, 0.17442417813376832, 0.07423195514862524, 0.07805878439217029, 0.08515745950989528, 0.07034374666956611, 0.0752436231266509, 0.07077416841888062, 0.08363918122636782, 0.07317221563904064, 0.07394621980179805]}, "mutation_prompt": null}
{"id": "0d22404c-0286-4e75-8b78-bef5c31151ce", "solution": "import numpy as np\n\nclass EnhancedHybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim  # Reduced for more focused search\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.scaling_factor = 0.7  # Adjusted scaling factor\n        self.crossover_rate = 0.85  # Adjusted crossover rate\n        self.dynamic_population = False  # Removed dynamic population flag\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n\n        while num_evaluations < self.budget:\n            # Adaptive exploration strategy\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + self.scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            # Evaluate trial population\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n\n            # Replace if trial solution is better\n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            # Update best individual\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(best_individual):\n                best_individual = population[best_idx]\n\n            # Fitness-based exploration with informed search\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = best_individual + 0.1 * (population[best_idx] - np.mean(population, axis=0))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(best_individual):\n                    best_individual = candidate\n\n        return best_individual\n\n# Usage example:\n# optimizer = EnhancedHybridDifferentialEvolution(budget=10000, dim=10)\n# best_solution = optimizer(my_black_box_function)", "name": "EnhancedHybridDifferentialEvolution", "description": "An enhanced hybrid metaheuristic using improved differential evolution with adaptive strategies and informed search for robust convergence.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "386502ad-5675-49c9-b1ac-1234b1c3f70e", "metadata": {"aucs": [0.7201321155151885, 0.7209782482634396, 0.7224695081216899, 0.7285107530054211, 0.7497805787783252, 0.7360509779465715, 0.7354518726753858, 0.7249050173536324, 0.7127482652583693, 0.528185854033152, 0.5471447959560913, 0.507417905696298, 0.5227876691366351, 0.5311475415860135, 0.5279342390476274, 0.5216529840428596, 0.5491713634528339, 0.5295924831307228, 0.10598431462909552, 0.11275885017452147, 0.10954811861928915, 0.1278024839052927, 0.10393596765643265, 0.13336930544849657, 0.1122072987513586, 0.10981621397542529, 0.10053650588816276, 0.09987833892001541, 0.08952249916808708, 0.10574519719058573, 0.09964883365812216, 0.11005002993533652, 0.10487086273812984, 0.09259561843308817, 0.10270646191209032, 0.10667011322854669, 0.9337606596059351, 0.9664918196066554, 0.9398037202864228, 0.9406713480978092, 0.9189616455379384, 0.945652805806398, 0.9543095574419449, 0.9593635409866386, 0.9688711528284106, 0.3628183350989518, 0.34185268927054957, 0.3642583736435535, 0.38525176896312896, 0.3567721207463105, 0.364144019182546, 0.3540618286976073, 0.3916243916382721, 0.3343536957624348, 0.6490034467931274, 0.6355250807974432, 0.5954365899640937, 0.629738355143082, 0.6298111426810793, 0.7174620761792952, 0.6177662483715256, 0.6456209436152169, 0.6821211376745256, 0.2100771147710382, 0.1988448281942915, 0.2060845459196189, 0.2349155283619151, 0.22477275435601718, 0.2323858093051434, 0.2674701394149961, 0.23842386303711993, 0.25209325236080227, 0.2956712392103382, 0.14642101165541987, 0.16567385189841188, 0.29937960271689257, 0.26829285080537735, 0.21278236135892092, 0.18520814771077398, 0.18302031929421392, 0.2219301308782472, 0.13462317295987036, 0.14823473565751977, 0.18446027037696833, 0.13893157121650457, 0.20012047904846653, 0.17373268515092244, 0.1580356129076005, 0.13728149371984344, 0.17652159547212853, 0.3219589526148584, 0.3157663977835652, 0.2909970110932719, 0.2663133469711557, 0.3049879816886295, 0.2647218071763531, 0.30880186207260396, 0.3559700306551028, 0.33839632992894453, 0.08140538194003788, 0.06808058866503364, 0.053280593274207755, 0.07058509254936185, 0.07552847493892245, 0.05100952829267158, 0.06358549544007197, 0.07540330150005192, 0.03286284441576681, 0.18876125863789617, 0.20243606759477573, 0.1922007412730301, 0.20507061936145876, 0.1980561816967581, 0.1984962951946404, 0.1835424183463047, 0.18029622392483324, 0.1936619504974001, 0.5320093719147094, 0.5507843782581363, 0.5461863888017586, 0.5555547217691705, 0.5402532963026745, 0.5528058668540304, 0.57029922191839, 0.5460284401777427, 0.5306006852531318, 0.08783444590845191, 0.09200682723310694, 0.0979433918877961, 0.08695097670332341, 0.0959349030844533, 0.09331915593911566, 0.09163436011400494, 0.10005395809252171, 0.08856147600843, 0.16061389467306175, 0.14414139431968032, 0.14799581093690028, 0.2928075632620901, 0.17843450897066437, 0.14891263056098103, 0.14820652363705944, 0.16031079551079996, 0.15212201411890636, 0.34518751363111455, 0.3170909205475051, 0.30874004104784336, 0.3182346012211643, 0.3109823830622288, 0.30044570648132507, 0.33120810438947934, 0.3363320512743695, 0.32260877644762187, 0.2504594068158408, 0.23308271049195162, 0.2139911586463633, 0.23481909843750326, 0.22453026928473485, 0.23503291036269025, 0.25530898755309595, 0.26174399055043773, 0.2412404297810059, 0.1885042633665639, 0.17889429299943327, 0.1889478982574485, 0.17875430360044808, 0.17984123428766308, 0.171640419994186, 0.19483051964721243, 0.19523788606696013, 0.1841405544591268, 0.17827387688308305, 0.17637061621331285, 0.19074925974443813, 0.21034185148612483, 0.19752127454505441, 0.18320314760013057, 0.17602281122648944, 0.18594585428704435, 0.19337065064400705, 0.4239926380355946, 0.17734288924274044, 0.16237771669986578, 0.38352375152909945, 0.4179274318088593, 0.48330404717485853, 0.17756282396497114, 0.4228078306740929, 0.696252927405299, 0.569759820142413, 0.20052692602477196, 0.19635258062797634, 0.472430808735416, 0.19274102129876503, 0.4718123677775833, 0.20106441532183594, 0.12450527408948475, 0.20643806417356614, 0.17706368658841132, 0.20247486439961138, 0.20832378771237814, 0.18821916793603943, 0.17760474898606826, 0.18515801304564605, 0.18426497874396341, 0.1935729403917954, 0.17442417813376832, 0.07423195514862524, 0.07805878439217029, 0.08515745950989528, 0.07034374666956611, 0.0752436231266509, 0.07077416841888062, 0.08363918122636782, 0.07317221563904064, 0.07394621980179805]}, "mutation_prompt": null}
{"id": "03e95e90-1065-4a9e-85fd-74febdde0ed2", "solution": "import numpy as np\n\nclass RefinedHybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.85\n        self.scaling_increase_step = 0.1\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            # Adaptive scaling strategy\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            # Evaluate trial population\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n\n            # Replace if trial solution is better\n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            # Update best individual\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(best_individual):\n                best_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)  # Dynamically adjust scaling factor\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            # Fitness-based exploration with dynamic mutation\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = best_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(best_individual):\n                    best_individual = candidate\n\n        return best_individual", "name": "RefinedHybridDifferentialEvolution", "description": "A refined hybrid differential evolution incorporating adaptive scaling and dynamic mutation strategies for enhanced optimization performance.", "configspace": "", "generation": 11, "fitness": 0.3705774549044961, "feedback": "The algorithm RefinedHybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.25.", "error": "", "parent_id": "386502ad-5675-49c9-b1ac-1234b1c3f70e", "metadata": {"aucs": [0.8087820136903694, 0.8338035058841731, 0.8202216459910905, 0.8330098296125253, 0.8091396124278063, 0.8314691669739005, 0.8249064299829703, 0.8217652928713688, 0.8274318117521443, 0.7333000360930888, 0.6868457533115828, 0.67493457239916, 0.6197188019049324, 0.7299013723834482, 0.6795332963050813, 0.6673573263972008, 0.6959762538831251, 0.7024979465729695, 0.43780045816910207, 0.17428341833465733, 0.15760312519001674, 0.36894148907138147, 0.4161919348522273, 0.5706964558788825, 0.5988725723814979, 0.17145329536743792, 0.45153841988127985, 0.13332742454087998, 0.14214234075884302, 0.14552708387236557, 0.40193153790312885, 0.13910450641022032, 0.16806398819723423, 0.13592338310876095, 0.14325213965449368, 0.13571511336858277, 0.9633092034191832, 0.9412974542777021, 0.9306463944264378, 0.9328708285204161, 0.8937571562927514, 0.934117358032048, 0.8824382896956977, 0.95908481290174, 0.9325078566988788, 0.40099136076941166, 0.4553719816930547, 0.42096241179462357, 0.4177571270028413, 0.44647905951716294, 0.444384489303583, 0.3529134285525045, 0.4219242329997178, 0.3378825685047747, 0.36026055147205494, 0.8106183841391171, 0.8195774643914098, 0.8287165174873945, 0.35187278741842354, 0.8095129096881248, 0.37762042083847247, 0.2844439522923482, 0.8286416882158372, 0.29905509713505496, 0.25242573665883494, 0.22192570403177336, 0.29087773965038344, 0.19632013240569446, 0.44644577882136494, 0.24296798422643062, 0.4199404317229595, 0.20164938990873094, 0.20952723372208004, 0.17229379009066947, 0.23251658068640002, 0.1822717917614618, 0.18460474322779907, 0.20068979139059318, 0.20463033372742268, 0.2561997884942636, 0.20247622032957535, 0.010023454263093479, 0.09446878382810464, 0.2100130227667094, 0.21008300579596273, 0.1326349175250583, 0.022249888351398295, 0.007706863853084389, 0.1374739879839013, 0.22000475062855684, 0.3176241738562443, 0.22280190489380702, 0.223019890236129, 0.20015618496304632, 0.11059319953924218, 0.2438179691189738, 0.3990004428726107, 0.22242930511634673, 0.15574054629234002, 0.05085229810844427, 0.06205015619345322, 0.15934921703989435, 0.07288279027081535, 0.07702549022891603, 0.23774165067761155, 0.16051031486044198, 0.19193085238419594, 0.18030345394786396, 0.24849382615036497, 0.3222977373066821, 0.32172118462395194, 0.19591024110974697, 0.3340519410172563, 0.3107001838992566, 0.27106218031123985, 0.29954669256712163, 0.09543126957024395, 0.7016176498859626, 0.6572797851516017, 0.5770417778278016, 0.5205838498267654, 0.5389001949372538, 0.5702762327526723, 0.7204709890992869, 0.5679025123370214, 0.5677225958409196, 0.11845463404491763, 0.13072060384597228, 0.15774064192457193, 0.12129617749644583, 0.12815448773366933, 0.14125805892632037, 0.13866557975082905, 0.13216049449942546, 0.12679552256844706, 0.2215828901465925, 0.17792219711858293, 0.15905109417621988, 0.250417005780292, 0.23982097178139916, 0.1819424875516874, 0.18014883426136907, 0.16825725358980237, 0.23831751234540677, 0.556515723151553, 0.4476653999080129, 0.5292253912853679, 0.5444135557613339, 0.577580625540244, 0.43019978630296374, 0.6007878372697256, 0.5647027662326155, 0.491356443782232, 0.41030336446927873, 0.34508575733790525, 0.39004353384948554, 0.37981397685478324, 0.3610976986677663, 0.3936660469185361, 0.31077201759970285, 0.522773741312568, 0.2999718988363482, 0.21471631501650168, 0.21453738114078258, 0.20982296058095384, 0.19937516609625328, 0.22377015499856834, 0.21629795361965076, 0.20666665180040933, 0.21492586808777003, 0.21403160766600338, 0.20454852285567848, 0.5355889106968705, 0.3903423083938432, 0.6561603600985069, 0.2204968888210852, 0.5078204398976442, 0.5758333269106188, 0.23360882329437815, 0.23594071770563196, 0.18433343309779837, 0.7721853677115202, 0.762340229657822, 0.19662536412896414, 0.16989804599781766, 0.7273499011334015, 0.8356949943538592, 0.8322836035511925, 0.8622551394682401, 0.5301135666074884, 0.2084303469616322, 0.733514728707537, 0.2019271743705392, 0.1647819856573708, 0.6069992888178872, 0.1111433423789171, 0.1662110753761341, 0.20790733150587482, 0.21024203232965932, 0.19134096908554987, 0.18619439716255626, 0.18763501424092954, 0.17718356330280927, 0.17984682359303283, 0.18794056356957567, 0.18940923220173067, 0.20044158327614037, 0.10543057643851173, 0.0878941380476872, 0.0898784791216587, 0.091675935563854, 0.08792931376270574, 0.08548892533640517, 0.09004509423205587, 0.0888172878434429, 0.08693336694880727]}, "mutation_prompt": null}
{"id": "3df4f220-3f37-4441-9616-ce8a1d86f864", "solution": "import numpy as np\n\nclass EnhancedHybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6\n        self.crossover_rate = 0.9\n        self.scaling_increase_step = 0.05\n\n    def __call__(self, func):\n        # Initialize population\n        population_size = self.initial_population_size\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget and population_size > 2:\n            # Adaptive scaling strategy\n            trial_population = np.empty_like(population)\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            # Evaluate trial population\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += population_size\n\n            # Replace if trial solution is better\n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            # Update best individual\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(best_individual):\n                best_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            # Adaptive population size reduction\n            if num_evaluations < self.budget and np.random.rand() < 0.2:\n                candidate = best_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(best_individual):\n                    best_individual = candidate\n                else:\n                    population_size = max(2, int(population_size * 0.95))  # Reduce population size gradually\n\n        return best_individual", "name": "EnhancedHybridDifferentialEvolution", "description": "Enhanced hybrid differential evolution with adaptive population size and mutation scaling to improve convergence.", "configspace": "", "generation": 12, "fitness": 0.2801341314630927, "feedback": "The algorithm EnhancedHybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.22.", "error": "", "parent_id": "03e95e90-1065-4a9e-85fd-74febdde0ed2", "metadata": {"aucs": [0.4772122455323624, 0.8361181308226978, 0.7182233333935293, 0.7180693548885015, 0.5967001494510369, 0.6912708842030916, 0.8106142759567397, 0.7337116020513474, 0.6010558115629959, 0.3276178959279261, 0.5058359234650789, 0.3845044904971535, 0.170321595361548, 0.6976599866957864, 0.5112124125261953, 0.26548520274648924, 0.5806743060484931, 0.6775915397631718, 0.11561229057728162, 0.16002053072349642, 0.17460461116638182, 0.1332585600048718, 0.1584651621249028, 0.14245977311020563, 0.1473109211830539, 0.12811543013693827, 0.11730711122998838, 0.1426850674090685, 0.12045006573943706, 0.12777763589757396, 0.17037217637135293, 0.15050124596569237, 0.16494190597271263, 0.13084526601552204, 0.12599352860035307, 0.10652924743624936, 0.9636484743187119, 0.9369936065212497, 0.9335413623325705, 0.9493826329242491, 0.9059163832571401, 0.9337068861260291, 0.9313115932804481, 0.929031732081681, 0.9360508518926774, 0.2161650936033025, 0.2833607668498318, 0.2846522955786843, 0.16385352697014754, 0.35192274149041947, 0.18618817147197952, 0.17201293314056676, 0.2872903052101461, 0.30792069311183334, 0.8758289158921005, 0.3608166517006385, 0.3398690301454793, 0.2771676967709169, 0.27117997384969095, 0.26819580782839325, 0.8402675463847009, 0.3058894657728233, 0.3614023515787467, 0.14393763424044004, 0.17857184880979549, 0.14192133745021218, 0.16558828177057217, 0.18786957024212592, 0.14096003261892986, 0.16342264846840082, 0.15872121143791373, 0.2819733628412331, 0.13039397228326743, 0.11668248096632228, 0.37675794557292397, 0.14514426042583073, 0.1538006387399331, 0.1522814307799012, 0.12965658406448133, 0.17236894884723697, 0.23744834100392076, 0.049282700139627544, 0.13110446646719176, 0.045421386137515785, 0.00619073113277957, 0.0, 0.01144614032818314, 0.018295349018675577, 0.13790726810075016, 0.106250887711832, 0.127198474424572, 0.13889611877858754, 0.20201304218965144, 0.16181970704649373, 0.18163955375515406, 0.1359208095382357, 0.22094529527295992, 0.250736241556645, 0.20078616110430014, 0.12778259123718616, 0.15801152711261535, 0.10268907422950835, 0.11622124947994361, 0.08722172572266751, 0.1810068049981165, 0.13531812650821262, 0.16378608805696437, 0.07957340777133648, 0.12170597441740005, 0.20023873847966323, 0.18777104436392256, 0.14491065556112193, 0.1800040079217874, 0.15891311502569883, 0.19649281541900454, 0.2062375135162925, 0.11064332151315248, 0.48986720044523935, 0.5420745001218106, 0.5252250692237561, 0.5300540762650484, 0.4608274130886647, 0.5569834101635189, 0.3988972669586719, 0.6748410295764093, 0.6033016431604548, 0.1408652358269863, 0.12885975501127755, 0.12760245682549864, 0.09270733779165108, 0.13185578854293434, 0.10833084633460699, 0.12731680924303113, 0.10287147235747685, 0.1053092756205799, 0.14242289615270365, 0.1558547608120614, 0.1511988489952235, 0.21625631517808053, 0.1817942798698332, 0.14039415128973565, 0.180817420474931, 0.1910068715934491, 0.21167405807086948, 0.3441824000291964, 0.36026592759548537, 0.3973562916799459, 0.26867996457747745, 0.3240644732646033, 0.3457845523732048, 0.392275972601003, 0.36271662330261034, 0.4320586906297079, 0.18430428167329704, 0.23413265012243845, 0.2975048879995651, 0.27154763630929735, 0.32194519636183594, 0.33549534689202265, 0.2687782824285341, 0.32068607803234706, 0.28378685870235365, 0.25112538297616593, 0.2487496688409363, 0.25212479113508435, 0.24872006293928972, 0.2495611158283052, 0.2504930154495907, 0.251509067828823, 0.24861725481430808, 0.24858029109947288, 0.1685719200893231, 0.1932418807448224, 0.1980178493969743, 0.21351270687514823, 0.3191271096775449, 0.3534309056280457, 0.1916751219796915, 0.19901823724985535, 0.20741554775244475, 0.1640411380295751, 0.8539321103842834, 0.18357980271214047, 0.539731712329804, 0.19640174880960903, 0.17658899166651676, 0.16752892247049056, 0.1867141546338047, 0.8560964933553248, 0.2769600917593511, 0.17673916526887057, 0.24914348219437998, 0.2047010675145403, 0.20148555706304705, 0.35491980014248425, 0.20731862653556365, 0.14663169454741076, 0.20434820480902938, 0.17534581302191654, 0.17211698333566816, 0.18231188537414367, 0.1794772422470443, 0.1790742442175619, 0.1880252134381526, 0.1700868909935267, 0.17767126556165636, 0.16549076280949115, 0.07150463959250886, 0.08451815298750731, 0.09371719309559379, 0.07880759453992336, 0.08050563356323559, 0.08951650512194576, 0.09324838732443896, 0.0808479700124195, 0.08499521544423483]}, "mutation_prompt": null}
{"id": "584eb295-bc5e-44a6-9735-92ad32d360b9", "solution": "import numpy as np\n\nclass RefinedHybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.85\n        self.scaling_increase_step = 0.1\n        self.reinit_threshold = 0.1  # New parameter for re-initialization\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            # Adaptive scaling strategy\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            # Evaluate trial population\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n\n            # Replace if trial solution is better\n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            # Update best individual\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(best_individual):\n                best_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            # Fitness-based exploration with dynamic mutation\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = best_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(best_individual):\n                    best_individual = candidate\n\n            # Strategic re-initialization for exploration\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.1), replace=False)\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return best_individual", "name": "RefinedHybridDifferentialEvolution", "description": "A refined hybrid differential evolution incorporating adaptive scaling and dynamic mutation strategies with fitness-based variation and strategic re-initialization for enhanced exploration.", "configspace": "", "generation": 13, "fitness": 0.37113706846278416, "feedback": "The algorithm RefinedHybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.26.", "error": "", "parent_id": "03e95e90-1065-4a9e-85fd-74febdde0ed2", "metadata": {"aucs": [0.8411062278720465, 0.7987842790562711, 0.8366503019811357, 0.8194439463360123, 0.7806321058767455, 0.8108983931680327, 0.8192949198463847, 0.8040755788038911, 0.8347839021508725, 0.6723807471435798, 0.6880416623940427, 0.7321461112734444, 0.6509077123182826, 0.696210322481025, 0.7428660688878517, 0.7040247133240041, 0.6552095164526199, 0.6676580243333674, 0.36063632176608984, 0.5302407200171448, 0.3780404428838334, 0.4785766552327434, 0.5130635327600674, 0.28829188226188374, 0.48841316666020496, 0.16258524624062642, 0.4857601464550828, 0.14371654904836018, 0.1112641574665647, 0.14371245750005623, 0.16280880329567937, 0.14460421561030068, 0.15976264712324884, 0.13851047218611334, 0.13433328681609125, 0.16171271236871598, 0.9317803325247606, 0.933133365811989, 0.9144202202091588, 0.9293006010056035, 0.9109266040831012, 0.9313631433678842, 0.930652502848545, 0.94804495888253, 0.9417067578390509, 0.5561620850302604, 0.39864491902885557, 0.34053265138016564, 0.2950045334217891, 0.3730662002375047, 0.39598172758395833, 0.372814515051222, 0.39045492045612573, 0.45716894807989084, 0.8102056932453244, 0.8029581691670793, 0.8109512319886416, 0.2729432073059239, 0.8309717914009129, 0.8399342717510869, 0.3724341646045992, 0.7943837980008255, 0.8226041230860409, 0.19122920770457152, 0.1744708067728612, 0.34832836364115405, 0.18531939817903575, 0.16329459128280321, 0.1706786874098647, 0.30737920952602504, 0.3973529385014697, 0.15322579288434535, 0.17496174013220678, 0.11345327240158909, 0.17868395846741003, 0.24325616465505973, 0.28102347042916054, 0.3238106512940394, 0.1855697037761641, 0.22397503340743974, 0.22543706543075548, 0.06398102531922445, 0.32684175039112906, 0.13669067537150825, 0.21964701987269042, 0.14128250086946936, 0.00530791755084703, 0.006097186530719445, 0.1674201453630123, 0.10165018977742124, 0.3543459483465513, 0.19555421432801368, 0.16592749848548716, 0.1990331623497864, 0.07324773712871191, 0.21574217750403968, 0.23927344174620846, 0.21198597422176146, 0.22096901701257665, 0.10942602984149485, 0.044868404193062594, 0.12271860028526738, 0.2692306797562162, 0.15454139125581345, 0.1422896710684619, 0.10269649715807194, 0.15145143142033413, 0.14439465291070286, 0.26477336737073875, 0.2413655114519434, 0.2899895600162308, 0.15145936758883183, 0.2970670973400237, 0.323392104620167, 0.30512825337856, 0.21868584443329675, 0.2820407551019716, 0.5375821378308574, 0.6138023456218558, 0.631008180316905, 0.5022361310107202, 0.565290128443665, 0.5557984041277473, 0.5659908651644878, 0.6892028282031388, 0.5359462713956109, 0.12144261529307765, 0.13999448438918882, 0.12847223090494064, 0.12533400407097872, 0.44352336874742126, 0.12941235515851568, 0.32262301388762527, 0.1494927654749939, 0.1364413267464173, 0.28737133874857324, 0.1850534159201408, 0.18445467098564194, 0.20345201917517475, 0.1712286972454925, 0.19712015328478116, 0.16677093092371686, 0.18529831486755333, 0.23529856082558254, 0.3264619286624897, 0.4677896650782255, 0.5727093311998377, 0.5446651963757131, 0.4523546494271986, 0.5332368649690863, 0.508643456290403, 0.5206385384446989, 0.6514821427336509, 0.3609126976102398, 0.28142600956327013, 0.3625638155103652, 0.4487963519939231, 0.28710116276480635, 0.46483436816311874, 0.3511701371971514, 0.3126985276178613, 0.40172567290989414, 0.21653501949655762, 0.21376389665069528, 0.1983212850667031, 0.22645118825614774, 0.24951211664142736, 0.21772694971685214, 0.2052718442066498, 0.18665337339876298, 0.22114750337159417, 0.23353517387156975, 0.23403460095198403, 0.21808585120640755, 0.6112723240511297, 0.23431976321527082, 0.21477211748192593, 0.21224355704976217, 0.23818026336002607, 0.22179835183397067, 0.1808003495585382, 0.7817034371031931, 0.15144421236295424, 0.8092302500111643, 0.8517929562702983, 0.8099848230527598, 0.8210153996287979, 0.733187886723585, 0.7832272307192822, 0.8251441943887977, 0.20995284202550624, 0.7736731723111598, 0.20703076742472726, 0.19552435498006904, 0.20532893384561535, 0.548113817123715, 0.1547511175954147, 0.2075522752592286, 0.1881872623504911, 0.1878379324580277, 0.18484640086787918, 0.17958579288723775, 0.18798952577017436, 0.1878071058567874, 0.17737598532303622, 0.18489991317125698, 0.18088336660758897, 0.08167265851852423, 0.08101624404042518, 0.09015729215738844, 0.08018806142992452, 0.08515559443885545, 0.09301232866195663, 0.0951934211617751, 0.08726883684201925, 0.09893354588749681]}, "mutation_prompt": null}
{"id": "4e07d6f0-7c14-4b39-b926-f8c96ef97f42", "solution": "import numpy as np\n\nclass RefinedHybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.85\n        self.scaling_increase_step = 0.1\n        self.reinit_threshold = 0.1  # New parameter for re-initialization\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            # Adaptive scaling strategy\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            # Evaluate trial population\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n\n            # Replace if trial solution is better\n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            # Update best individual\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(best_individual):\n                best_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            # Fitness-based exploration with dynamic mutation\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = best_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(best_individual):\n                    best_individual = candidate\n\n            # Strategic re-initialization for exploration\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.1), replace=False)\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return best_individual", "name": "RefinedHybridDifferentialEvolution", "description": "A refined hybrid differential evolution incorporating adaptive scaling and dynamic mutation strategies with fitness-based variation and strategic re-initialization for enhanced exploration.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "584eb295-bc5e-44a6-9735-92ad32d360b9", "metadata": {"aucs": [0.8411062278720465, 0.7987842790562711, 0.8366503019811357, 0.8194439463360123, 0.7806321058767455, 0.8108983931680327, 0.8192949198463847, 0.8040755788038911, 0.8347839021508725, 0.6723807471435798, 0.6880416623940427, 0.7321461112734444, 0.6509077123182826, 0.696210322481025, 0.7428660688878517, 0.7040247133240041, 0.6552095164526199, 0.6676580243333674, 0.36063632176608984, 0.5302407200171448, 0.3780404428838334, 0.4785766552327434, 0.5130635327600674, 0.28829188226188374, 0.48841316666020496, 0.16258524624062642, 0.4857601464550828, 0.14371654904836018, 0.1112641574665647, 0.14371245750005623, 0.16280880329567937, 0.14460421561030068, 0.15976264712324884, 0.13851047218611334, 0.13433328681609125, 0.16171271236871598, 0.9317803325247606, 0.933133365811989, 0.9144202202091588, 0.9293006010056035, 0.9109266040831012, 0.9313631433678842, 0.930652502848545, 0.94804495888253, 0.9417067578390509, 0.5561620850302604, 0.39864491902885557, 0.34053265138016564, 0.2950045334217891, 0.3730662002375047, 0.39598172758395833, 0.372814515051222, 0.39045492045612573, 0.45716894807989084, 0.8102056932453244, 0.8029581691670793, 0.8109512319886416, 0.2729432073059239, 0.8309717914009129, 0.8399342717510869, 0.3724341646045992, 0.7943837980008255, 0.8226041230860409, 0.19122920770457152, 0.1744708067728612, 0.34832836364115405, 0.18531939817903575, 0.16329459128280321, 0.1706786874098647, 0.30737920952602504, 0.3973529385014697, 0.15322579288434535, 0.17496174013220678, 0.11345327240158909, 0.17868395846741003, 0.24325616465505973, 0.28102347042916054, 0.3238106512940394, 0.1855697037761641, 0.22397503340743974, 0.22543706543075548, 0.06398102531922445, 0.32684175039112906, 0.13669067537150825, 0.21964701987269042, 0.14128250086946936, 0.00530791755084703, 0.006097186530719445, 0.1674201453630123, 0.10165018977742124, 0.3543459483465513, 0.19555421432801368, 0.16592749848548716, 0.1990331623497864, 0.07324773712871191, 0.21574217750403968, 0.23927344174620846, 0.21198597422176146, 0.22096901701257665, 0.10942602984149485, 0.044868404193062594, 0.12271860028526738, 0.2692306797562162, 0.15454139125581345, 0.1422896710684619, 0.10269649715807194, 0.15145143142033413, 0.14439465291070286, 0.26477336737073875, 0.2413655114519434, 0.2899895600162308, 0.15145936758883183, 0.2970670973400237, 0.323392104620167, 0.30512825337856, 0.21868584443329675, 0.2820407551019716, 0.5375821378308574, 0.6138023456218558, 0.631008180316905, 0.5022361310107202, 0.565290128443665, 0.5557984041277473, 0.5659908651644878, 0.6892028282031388, 0.5359462713956109, 0.12144261529307765, 0.13999448438918882, 0.12847223090494064, 0.12533400407097872, 0.44352336874742126, 0.12941235515851568, 0.32262301388762527, 0.1494927654749939, 0.1364413267464173, 0.28737133874857324, 0.1850534159201408, 0.18445467098564194, 0.20345201917517475, 0.1712286972454925, 0.19712015328478116, 0.16677093092371686, 0.18529831486755333, 0.23529856082558254, 0.3264619286624897, 0.4677896650782255, 0.5727093311998377, 0.5446651963757131, 0.4523546494271986, 0.5332368649690863, 0.508643456290403, 0.5206385384446989, 0.6514821427336509, 0.3609126976102398, 0.28142600956327013, 0.3625638155103652, 0.4487963519939231, 0.28710116276480635, 0.46483436816311874, 0.3511701371971514, 0.3126985276178613, 0.40172567290989414, 0.21653501949655762, 0.21376389665069528, 0.1983212850667031, 0.22645118825614774, 0.24951211664142736, 0.21772694971685214, 0.2052718442066498, 0.18665337339876298, 0.22114750337159417, 0.23353517387156975, 0.23403460095198403, 0.21808585120640755, 0.6112723240511297, 0.23431976321527082, 0.21477211748192593, 0.21224355704976217, 0.23818026336002607, 0.22179835183397067, 0.1808003495585382, 0.7817034371031931, 0.15144421236295424, 0.8092302500111643, 0.8517929562702983, 0.8099848230527598, 0.8210153996287979, 0.733187886723585, 0.7832272307192822, 0.8251441943887977, 0.20995284202550624, 0.7736731723111598, 0.20703076742472726, 0.19552435498006904, 0.20532893384561535, 0.548113817123715, 0.1547511175954147, 0.2075522752592286, 0.1881872623504911, 0.1878379324580277, 0.18484640086787918, 0.17958579288723775, 0.18798952577017436, 0.1878071058567874, 0.17737598532303622, 0.18489991317125698, 0.18088336660758897, 0.08167265851852423, 0.08101624404042518, 0.09015729215738844, 0.08018806142992452, 0.08515559443885545, 0.09301232866195663, 0.0951934211617751, 0.08726883684201925, 0.09893354588749681]}, "mutation_prompt": null}
{"id": "e304da72-e29c-4349-ab8e-f336f8930f39", "solution": "import numpy as np\n\nclass ModifiedHybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.85\n        self.scaling_increase_step = 0.1\n        self.reinit_threshold = 0.1\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            # Stochastic ranking for adaptive parameter control\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + np.random.uniform(0.4, 0.9) * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < np.random.uniform(0.6, 0.95)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            # Evaluate trial population\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n\n            # Replace if trial solution is better\n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            # Update best individual and parameters\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(best_individual):\n                best_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            # Fitness-based exploration with dynamic mutation\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = best_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(best_individual):\n                    best_individual = candidate\n\n            # Strategic re-initialization for exploration\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.1), replace=False)\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return best_individual", "name": "ModifiedHybridDifferentialEvolution", "description": "A hybrid differential evolution with stochastic ranking for adaptive parameter control, replacing static mutation and crossover rates to enhance exploration and convergence balance.", "configspace": "", "generation": 15, "fitness": 0.28852942919182417, "feedback": "The algorithm ModifiedHybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.23.", "error": "", "parent_id": "584eb295-bc5e-44a6-9735-92ad32d360b9", "metadata": {"aucs": [0.7401760734583516, 0.7388917864358322, 0.7424819418174191, 0.7595351725228349, 0.7601090980687253, 0.744971501027466, 0.7388633659805514, 0.7220363439425852, 0.7417083559625084, 0.5526325453305336, 0.46747993943150146, 0.5232875706312039, 0.5507763260582019, 0.5377380509494205, 0.5506505835244976, 0.5524324695586567, 0.5382104235970275, 0.5417564041653757, 0.10926235394310602, 0.11904880629433212, 0.12150490575798234, 0.1097417130334325, 0.12043205150950909, 0.11846641539582525, 0.11380840367674427, 0.129825585979234, 0.11569710033866376, 0.10469304603418172, 0.1070380720100198, 0.10426505955968901, 0.11292334354456257, 0.10964962619592966, 0.10224665745888128, 0.11470939851043582, 0.1220911292129584, 0.10488114040934782, 0.9593880906333598, 0.965345028695058, 0.9466543681885642, 0.9499996118107121, 0.9476037223256066, 0.9740444127164231, 0.9231022213165041, 0.9360383122383656, 0.9703837684648512, 0.36183807784445776, 0.3404606898902137, 0.32425283994728094, 0.3802222282433593, 0.3097232865778423, 0.3488268694987954, 0.30442917671930514, 0.3342033474244621, 0.3576545993253609, 0.5734928357951278, 0.5608054001168858, 0.6017134099400903, 0.677272304000405, 0.5932821798483143, 0.6178493272358613, 0.5097984159127376, 0.5934942905867802, 0.5497312120702379, 0.21281283663314354, 0.183065285081366, 0.20727507867525852, 0.22248194970073976, 0.1952448273074041, 0.23723174613522002, 0.20077009621326714, 0.18454006563441172, 0.16452165268959362, 0.20675674916524556, 0.18002390194842777, 0.11427618443132359, 0.21774754980897493, 0.18475066440610843, 0.225210114443553, 0.1751617723320995, 0.1841426178081894, 0.181157109641767, 0.09314319082947642, 0.092778758796635, 0.09849411912295059, 0.11839189803919603, 0.0996031924796984, 0.07257303713147722, 0.09474363838396604, 0.10708443516107413, 0.12142087885047514, 0.215575666736031, 0.17903082016189342, 0.21246373962186837, 0.212040614923531, 0.18972998937088958, 0.1965146335621175, 0.27456784992790306, 0.2347149995713066, 0.2235725763657248, 0.042597975479608974, 0.026555138649821286, 0.036967296577517295, 0.015560356098824002, 0.04934144141011365, 0.041786891614134625, 0.06812457310861031, 0.05158053546891839, 0.03750376939790678, 0.14920638847345213, 0.13868395137231782, 0.1556989928411744, 0.1702714151107313, 0.1579359157812269, 0.17955553388384482, 0.15721103394126434, 0.14720861216087455, 0.17723799099271653, 0.5291666294755556, 0.5335570058478112, 0.5174101119767887, 0.5615121620020773, 0.5113117829300491, 0.5550723737253626, 0.5071431523957517, 0.5299330681028986, 0.5318941563723394, 0.0883568211267477, 0.08691172523190982, 0.09374620626702368, 0.09453794456982445, 0.09314144499154953, 0.08473266063223306, 0.09275019559040865, 0.09663168052074544, 0.0825141744479766, 0.1560260390116025, 0.15344377550464872, 0.14927394894529877, 0.2226887952295712, 0.15328509320940442, 0.13679471459784787, 0.14892912675150582, 0.1560673012062389, 0.14656152287048785, 0.3111407677423319, 0.3110220370659027, 0.3116035578392987, 0.2987724300118615, 0.31984883852017665, 0.3025218354361642, 0.3418953174323548, 0.34702649955194376, 0.3202886958074156, 0.2501325115013471, 0.21798768202221253, 0.22097751064919624, 0.22105334068863636, 0.20085597684478185, 0.21938304387748386, 0.21874446609827547, 0.2454741046678951, 0.22894897447032825, 0.19834406519683134, 0.1946481303175006, 0.2001957332889367, 0.19839741782729825, 0.18882814445796126, 0.22453230092921816, 0.1947180451050926, 0.18065039795032822, 0.1878659447741945, 0.17745849235009592, 0.18255679106981793, 0.19987763069103914, 0.1794610726401472, 0.18600798940904384, 0.178300980510245, 0.18937166443036668, 0.19183647268125092, 0.18569741693986141, 0.5907662378826612, 0.17120610049369256, 0.1807184125626774, 0.4628116648071262, 0.176204002630861, 0.46128760986923834, 0.33759591057400185, 0.1885637491134916, 0.573614410687712, 0.19930560812470033, 0.20081550757767952, 0.1606985360095543, 0.4126006256064575, 0.2639810270761812, 0.36479620523609724, 0.5694632787136433, 0.15991746836606924, 0.5513757855326235, 0.1908503575060908, 0.17596840777454203, 0.1805051618103085, 0.2104095707825574, 0.1790714764807475, 0.18880645888991943, 0.2158728639944002, 0.18070191868653895, 0.18564759463555836, 0.06869982078068237, 0.0698515749074824, 0.07982621606885787, 0.07543732284501548, 0.07877695543952123, 0.0759351592774774, 0.07137299858744661, 0.08188859056450015, 0.07491737905754947]}, "mutation_prompt": null}
{"id": "6ff064fc-374a-4667-a8ab-582843855799", "solution": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedHybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.85\n        self.scaling_increase_step = 0.1\n        self.reinit_threshold = 0.1\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            # Cluster-based adaptive scaling strategy\n            kmeans = KMeans(n_clusters=3, n_init=5).fit(population)\n            cluster_centers = kmeans.cluster_centers_\n\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                cluster_id = kmeans.labels_[i]\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2) + 0.1 * (cluster_centers[cluster_id] - x0)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n\n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(best_individual):\n                best_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            # Local search around best individual\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = best_individual + 0.05 * np.random.randn(self.dim)\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(best_individual):\n                    best_individual = candidate\n\n            # Strategic re-initialization for exploration\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.1), replace=False)\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return best_individual", "name": "EnhancedHybridDifferentialEvolution", "description": "Enhanced hybrid differential evolution with adaptive clustering and local search to improve exploration and exploitation balance.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "An exception occurred: ModuleNotFoundError(\"No module named 'sklearn'\").", "error": "ModuleNotFoundError(\"No module named 'sklearn'\")", "parent_id": "584eb295-bc5e-44a6-9735-92ad32d360b9", "metadata": {}, "mutation_prompt": null}
{"id": "3b30536d-fe8a-446c-96d8-407939bdbc11", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.base_crossover_rate = 0.9\n        self.diversity_lower_bound = 0.3  # New parameter for diversity-based scaling\n        self.reinit_threshold = 0.2  # Adjusted re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                diversity = np.mean(np.std(population, axis=0))\n                crossover_rate = self.base_crossover_rate * (diversity / self.diversity_lower_bound)\n                cross_points = np.random.rand(self.dim) < min(1.0, crossover_rate)\n\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n\n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(best_individual):\n                best_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + 0.1)\n            else:\n                scaling_factor = max(0.2, scaling_factor - 0.05)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = best_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(best_individual):\n                    best_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.1), replace=False)\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return best_individual", "name": "EnhancedAdaptiveDifferentialEvolution", "description": "An enhanced adaptive differential evolution using a dynamic crossover rate and population scaling based on diversity metrics to improve convergence speed and solution quality.", "configspace": "", "generation": 17, "fitness": 0.3310234671429242, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.23.", "error": "", "parent_id": "584eb295-bc5e-44a6-9735-92ad32d360b9", "metadata": {"aucs": [0.7177507877325446, 0.7684405497096193, 0.6923884647615695, 0.770325074810738, 0.7625645662425433, 0.7619498545531058, 0.7788879428138684, 0.7426523433785903, 0.7552749939348018, 0.5920476742055568, 0.4574242368487462, 0.5057022531866908, 0.5673817368169356, 0.46548937437549576, 0.513822493941553, 0.5975607603956469, 0.5241479233362136, 0.5187934333709484, 0.1487230346887154, 0.43872150422501643, 0.12185725656322743, 0.14343027432456745, 0.15756394467220725, 0.14227255204021116, 0.3306626667822288, 0.1345075982149374, 0.16094961552684495, 0.12079586151095167, 0.14916241915701334, 0.14372785736481675, 0.10847886450350774, 0.10440653341489636, 0.11409723674136951, 0.1367503843302348, 0.12024557691404936, 0.13387448030435556, 0.9214484646586111, 0.96309276932729, 0.89085452137173, 0.9457334261848611, 0.9584477664486388, 0.9129992171639936, 0.9640973962438671, 0.8958350214548143, 0.9092310334663279, 0.3453605193689794, 0.3451332549830589, 0.31409629783506476, 0.2616011063737792, 0.39592455639644863, 0.33262592962361104, 0.30623946132485247, 0.27913581182053737, 0.30469509947858764, 0.21527324085217536, 0.2279605082260514, 0.7158559941074402, 0.7886631953209366, 0.7785509719278483, 0.7205313767773909, 0.792766001427212, 0.35482388097120343, 0.8283631545577386, 0.16543528626327264, 0.14057550370614558, 0.18015398202375288, 0.14357880352763353, 0.18578416958726385, 0.245459174773353, 0.18894854592421484, 0.19410020013115004, 0.24394408205161244, 0.1328988689720605, 0.1281489959100367, 0.16119217155032872, 0.13808153242508925, 0.20197935185549587, 0.13082581557221074, 0.1687739793151024, 0.16939991473113147, 0.1650336348267719, 0.2667498198801782, 0.28087492351410914, 0.21480036769663224, 0.3101895650573816, 0.23923275891603357, 0.29200716626337675, 0.2763217104190534, 0.254805349093169, 0.30501966157412086, 0.45093122853701184, 0.3409392243017202, 0.46581354076251713, 0.40759897468552164, 0.3660254944537108, 0.4030066825547679, 0.3335462651062677, 0.4369414685975035, 0.48153068618521677, 0.1333573462611124, 0.1370265662541813, 0.06679054090555414, 0.15564308485048128, 0.11967033747473343, 0.182842877168104, 0.10353597663274705, 0.09305116226451993, 0.14620864000500855, 0.2151695747154616, 0.2064059783149712, 0.1938254535286874, 0.21237584098411644, 0.24450026734913244, 0.14028606189819604, 0.30166900347604975, 0.21248813851932946, 0.21177700363259988, 0.5773454300280658, 0.5512892617402994, 0.5120697005465134, 0.5276403028339993, 0.47581634113598925, 0.5035562968188952, 0.498335905361329, 0.5266383699585806, 0.5279482818270753, 0.1374596335983661, 0.13412754256275716, 0.4248273626647008, 0.1293833314549977, 0.13237885921826475, 0.14297983943772619, 0.16074024616044658, 0.12109206878497192, 0.10635796040088641, 0.21901710505275696, 0.227294044554051, 0.4099018433173718, 0.2801252783743412, 0.3022060012024652, 0.25347398751131256, 0.2440875994421574, 0.20759318425375295, 0.16076336225210686, 0.39006228961754974, 0.3978872505258708, 0.4405453256329911, 0.4348692428724289, 0.3814561230013306, 0.39793214038111546, 0.4302278295744234, 0.3919883095146852, 0.411255605936932, 0.31652673945695997, 0.3182835393981355, 0.30471006663811473, 0.3486475509156165, 0.3047591342734822, 0.26269179631415107, 0.36954345567229385, 0.3322203071560158, 0.31300603942614325, 0.23381330590787586, 0.23041425034398466, 0.23670013922908806, 0.20156198453801433, 0.22918908525335868, 0.21131419940277074, 0.2185395399974689, 0.1938543284703954, 0.24342465588012563, 0.2131662720658264, 0.19699144058989437, 0.20584082192196396, 0.18509341027670267, 0.18382643329949055, 0.18880912306547415, 0.5192013540146717, 0.2124708396584446, 0.1840209025757119, 0.18257288054682774, 0.19601446769802655, 0.1779653303523211, 0.8227659305196182, 0.1881735489176758, 0.20249689518944058, 0.7923955763211827, 0.16845098778843315, 0.16834408834571712, 0.8380651111471793, 0.49972376902659066, 0.1625739006510588, 0.4112301554657122, 0.5781304346718017, 0.43805605756005117, 0.20783612833070852, 0.1614224442608727, 0.2091488030244676, 0.17588489060059076, 0.18446708626957842, 0.19635753081764884, 0.1881726643896917, 0.1846389449239264, 0.18771325918914394, 0.18620571778928174, 0.18789086685023715, 0.18791703602241572, 0.09075402025198731, 0.09376163581235541, 0.10158086675474587, 0.1541908792538519, 0.11052640123050439, 0.08720584281794075, 0.10130288005797972, 0.10447836152866097, 0.0839146768324408]}, "mutation_prompt": null}
{"id": "454b7038-ca0f-4150-a5c2-71a77406db7e", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.9  # Slightly increased for exploration\n        self.scaling_increase_step = 0.15  # Adjusted to enhance adaptability\n        self.diversity_threshold = 0.15  # New parameter for diversity management\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            # Evaluate trial population\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n\n            # Replace if trial solution is better\n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            # Update best individual\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(best_individual):\n                best_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.3, scaling_factor - self.scaling_increase_step)\n\n            # Diversity management and dynamic local search\n            diversity = np.std(population, axis=0).mean()\n            if diversity < self.diversity_threshold:\n                for idx in range(len(population)):\n                    perturb = np.random.uniform(-0.1, 0.1, self.dim)\n                    new_candidate = population[idx] + perturb\n                    new_candidate = np.clip(new_candidate, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_candidate)\n                    num_evaluations += 1\n                    if new_fitness < fitness[idx]:\n                        population[idx] = new_candidate\n                        fitness[idx] = new_fitness\n                    if num_evaluations >= self.budget:\n                        break\n\n        return best_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution incorporating adaptive diversity management with dynamic local search to improve convergence speed and solution quality.", "configspace": "", "generation": 18, "fitness": 0.3616566416077045, "feedback": "The algorithm EnhancedDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.24.", "error": "", "parent_id": "584eb295-bc5e-44a6-9735-92ad32d360b9", "metadata": {"aucs": [0.7577832665251047, 0.7512944384162178, 0.7776742872370441, 0.7574348222205417, 0.7377394679571464, 0.7513301983287417, 0.759548047939005, 0.7378930617236961, 0.7224254228069233, 0.5718571429285397, 0.5246269140229165, 0.5530821081243287, 0.5155303321470099, 0.5158539994162921, 0.5200135571155502, 0.5306486764699776, 0.5630597110665116, 0.6146664165633897, 0.15678337352813976, 0.15270948216910196, 0.21858927962542807, 0.1515723957073869, 0.20213570651645119, 0.16603027059648268, 0.2705329331442644, 0.1854510707992706, 0.14559730817539152, 0.12654162913486777, 0.12419967890059236, 0.11938131527070417, 0.15019571568322643, 0.1602201778164345, 0.10988056719600048, 0.13157807135382316, 0.14288721224340584, 0.13710776946787606, 0.9511120910075453, 0.9187910410032244, 0.9392661068017476, 0.9199552614781878, 0.923288161636635, 0.9576517699286494, 0.8755122259656891, 0.8987832046707396, 0.9586537527589308, 0.37248715262432164, 0.36367920824375044, 0.38715312321171813, 0.36278709533753173, 0.3803986510396449, 0.3851500851433054, 0.43204155284084544, 0.3714345063054706, 0.3630998916909526, 0.8277707453011225, 0.8318769971513766, 0.8193106433349244, 0.8488277381197583, 0.7945789798723071, 0.8614628301866597, 0.7617559254536067, 0.8232820972565364, 0.7596643244327517, 0.22237904004590447, 0.24177560150717547, 0.3817033491542887, 0.2318970713237002, 0.18228769432419067, 0.3050359288859108, 0.24251247474339865, 0.19182207146709174, 0.1884653047717494, 0.19666984750256278, 0.2946184678664727, 0.26222413083077933, 0.25066021989593334, 0.2134905342369653, 0.20927853823185738, 0.43596232224181486, 0.19583881878613207, 0.20019684745372257, 0.39130230436179336, 0.25739713362821526, 0.21202911188364593, 0.4380712042646322, 0.18939417175267093, 0.11634993324733856, 0.21168319194001006, 0.41273891024389187, 0.37328294312036725, 0.5514142661499262, 0.4782627578506107, 0.35299804143584146, 0.40919917544856, 0.20529663820810973, 0.18931554352889435, 0.48877934009740676, 0.4627460337391276, 0.47911566064828526, 0.2163322343309947, 0.20198366989479244, 0.12181400684103738, 0.1692079856482842, 0.17568601262620764, 0.11406263366781788, 0.11958621057662078, 0.15025090443448885, 0.1748190913559894, 0.24626309045537143, 0.2571480357224727, 0.23789617513007766, 0.29091871335739916, 0.2804643545667749, 0.26553179547610883, 0.25706710113824005, 0.28823769056391146, 0.2808364995973287, 0.5858332965729623, 0.6433163843415741, 0.6787926921577363, 0.6604061146860463, 0.6469865766741809, 0.6582030130152827, 0.6793301369910902, 0.6038699390986335, 0.6777649454587305, 0.11742372631366305, 0.1119519220614198, 0.13006243394009165, 0.15916019398273817, 0.1422996146054698, 0.10884800761781477, 0.12242793002597407, 0.12673952381912346, 0.1266819209529947, 0.23258319875916644, 0.17280077129171656, 0.1845596714672071, 0.2924277349263983, 0.1792905040678523, 0.1810779082564411, 0.23654800474665294, 0.1587400230168542, 0.29433143917136007, 0.3838454118631952, 0.4426073453533924, 0.4131645639260808, 0.4383914715481666, 0.398339410221794, 0.38418254939220065, 0.42441186423178656, 0.43433168561181323, 0.42731329857020217, 0.32574053371772893, 0.3513313184589161, 0.34744908518347106, 0.3445574201986946, 0.27019864328951104, 0.3350906724144218, 0.31538668277310344, 0.33233664632188753, 0.3665287355942318, 0.20426750638314395, 0.22788631138847382, 0.22034758240766927, 0.207338024565343, 0.20192062719423476, 0.22914161120813137, 0.20435715941270804, 0.1976795291581257, 0.21409915624282572, 0.2155024291996679, 0.3769136205787127, 0.20957607177999205, 0.22643372704007036, 0.21732047634255514, 0.2301300211419962, 0.39161205265363797, 0.23502868915060104, 0.5503890097904836, 0.7892984896101691, 0.841930332856068, 0.1658196636410435, 0.8070802578378463, 0.1680375626669809, 0.1895775399003985, 0.18111735259176553, 0.20828165208798277, 0.7441186427591879, 0.8071785624130761, 0.2100545648385631, 0.7143140146816814, 0.19941002809673825, 0.1987526352693474, 0.5270507335600427, 0.19512824145356378, 0.2049463175751075, 0.2088134881531739, 0.18072028744379787, 0.1872839674097997, 0.18909988932429123, 0.18147672158151018, 0.1786393877197574, 0.18980414301657778, 0.18116058592577633, 0.1925071625025605, 0.18260261300792902, 0.09848230982686768, 0.0805423395234911, 0.08704491278607873, 0.09026507725680344, 0.07958118494011412, 0.08262093365415091, 0.08066305357645764, 0.08337666579723513, 0.08551287831147425]}, "mutation_prompt": null}
{"id": "53f4deca-75c6-42eb-b84a-86c62ad7bb0e", "solution": "import numpy as np\n\nclass RefinedHybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.85\n        self.scaling_increase_step = 0.1\n        self.reinit_threshold = 0.1  # New parameter for re-initialization\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            # Adaptive scaling strategy\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            # Evaluate trial population\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n\n            # Replace if trial solution is better\n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            # Update best individual\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(best_individual):\n                best_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            # Fitness-based exploration with dynamic mutation\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = best_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(best_individual):\n                    best_individual = candidate\n\n            # Strategic re-initialization for exploration\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.1), replace=False)\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return best_individual", "name": "RefinedHybridDifferentialEvolution", "description": "A refined hybrid differential evolution incorporating adaptive scaling and dynamic mutation strategies with fitness-based variation and strategic re-initialization for enhanced exploration.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "584eb295-bc5e-44a6-9735-92ad32d360b9", "metadata": {"aucs": [0.8411062278720465, 0.7987842790562711, 0.8366503019811357, 0.8194439463360123, 0.7806321058767455, 0.8108983931680327, 0.8192949198463847, 0.8040755788038911, 0.8347839021508725, 0.6723807471435798, 0.6880416623940427, 0.7321461112734444, 0.6509077123182826, 0.696210322481025, 0.7428660688878517, 0.7040247133240041, 0.6552095164526199, 0.6676580243333674, 0.36063632176608984, 0.5302407200171448, 0.3780404428838334, 0.4785766552327434, 0.5130635327600674, 0.28829188226188374, 0.48841316666020496, 0.16258524624062642, 0.4857601464550828, 0.14371654904836018, 0.1112641574665647, 0.14371245750005623, 0.16280880329567937, 0.14460421561030068, 0.15976264712324884, 0.13851047218611334, 0.13433328681609125, 0.16171271236871598, 0.9317803325247606, 0.933133365811989, 0.9144202202091588, 0.9293006010056035, 0.9109266040831012, 0.9313631433678842, 0.930652502848545, 0.94804495888253, 0.9417067578390509, 0.5561620850302604, 0.39864491902885557, 0.34053265138016564, 0.2950045334217891, 0.3730662002375047, 0.39598172758395833, 0.372814515051222, 0.39045492045612573, 0.45716894807989084, 0.8102056932453244, 0.8029581691670793, 0.8109512319886416, 0.2729432073059239, 0.8309717914009129, 0.8399342717510869, 0.3724341646045992, 0.7943837980008255, 0.8226041230860409, 0.19122920770457152, 0.1744708067728612, 0.34832836364115405, 0.18531939817903575, 0.16329459128280321, 0.1706786874098647, 0.30737920952602504, 0.3973529385014697, 0.15322579288434535, 0.17496174013220678, 0.11345327240158909, 0.17868395846741003, 0.24325616465505973, 0.28102347042916054, 0.3238106512940394, 0.1855697037761641, 0.22397503340743974, 0.22543706543075548, 0.06398102531922445, 0.32684175039112906, 0.13669067537150825, 0.21964701987269042, 0.14128250086946936, 0.00530791755084703, 0.006097186530719445, 0.1674201453630123, 0.10165018977742124, 0.3543459483465513, 0.19555421432801368, 0.16592749848548716, 0.1990331623497864, 0.07324773712871191, 0.21574217750403968, 0.23927344174620846, 0.21198597422176146, 0.22096901701257665, 0.10942602984149485, 0.044868404193062594, 0.12271860028526738, 0.2692306797562162, 0.15454139125581345, 0.1422896710684619, 0.10269649715807194, 0.15145143142033413, 0.14439465291070286, 0.26477336737073875, 0.2413655114519434, 0.2899895600162308, 0.15145936758883183, 0.2970670973400237, 0.323392104620167, 0.30512825337856, 0.21868584443329675, 0.2820407551019716, 0.5375821378308574, 0.6138023456218558, 0.631008180316905, 0.5022361310107202, 0.565290128443665, 0.5557984041277473, 0.5659908651644878, 0.6892028282031388, 0.5359462713956109, 0.12144261529307765, 0.13999448438918882, 0.12847223090494064, 0.12533400407097872, 0.44352336874742126, 0.12941235515851568, 0.32262301388762527, 0.1494927654749939, 0.1364413267464173, 0.28737133874857324, 0.1850534159201408, 0.18445467098564194, 0.20345201917517475, 0.1712286972454925, 0.19712015328478116, 0.16677093092371686, 0.18529831486755333, 0.23529856082558254, 0.3264619286624897, 0.4677896650782255, 0.5727093311998377, 0.5446651963757131, 0.4523546494271986, 0.5332368649690863, 0.508643456290403, 0.5206385384446989, 0.6514821427336509, 0.3609126976102398, 0.28142600956327013, 0.3625638155103652, 0.4487963519939231, 0.28710116276480635, 0.46483436816311874, 0.3511701371971514, 0.3126985276178613, 0.40172567290989414, 0.21653501949655762, 0.21376389665069528, 0.1983212850667031, 0.22645118825614774, 0.24951211664142736, 0.21772694971685214, 0.2052718442066498, 0.18665337339876298, 0.22114750337159417, 0.23353517387156975, 0.23403460095198403, 0.21808585120640755, 0.6112723240511297, 0.23431976321527082, 0.21477211748192593, 0.21224355704976217, 0.23818026336002607, 0.22179835183397067, 0.1808003495585382, 0.7817034371031931, 0.15144421236295424, 0.8092302500111643, 0.8517929562702983, 0.8099848230527598, 0.8210153996287979, 0.733187886723585, 0.7832272307192822, 0.8251441943887977, 0.20995284202550624, 0.7736731723111598, 0.20703076742472726, 0.19552435498006904, 0.20532893384561535, 0.548113817123715, 0.1547511175954147, 0.2075522752592286, 0.1881872623504911, 0.1878379324580277, 0.18484640086787918, 0.17958579288723775, 0.18798952577017436, 0.1878071058567874, 0.17737598532303622, 0.18489991317125698, 0.18088336660758897, 0.08167265851852423, 0.08101624404042518, 0.09015729215738844, 0.08018806142992452, 0.08515559443885545, 0.09301232866195663, 0.0951934211617751, 0.08726883684201925, 0.09893354588749681]}, "mutation_prompt": null}
{"id": "0214f2b0-2d32-416d-99bd-ccf55aac4cbc", "solution": "import numpy as np\n\nclass EnhancedHybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.9  # Adjusted crossover rate\n        self.scaling_increase_step = 0.1\n        self.reinit_threshold = 0.2  # Adjusted reinit threshold\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            # Probabilistic adaptive scaling strategy\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                adaptive_scaling = scaling_factor if np.random.rand() < 0.5 else self.scaling_increase_step\n                mutant_vector = x0 + adaptive_scaling * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            # Evaluate trial population\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n\n            # Replace if trial solution is better\n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            # Update best individual\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(best_individual):\n                best_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            # Diversity-preserving exploration\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = best_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(best_individual):\n                    best_individual = candidate\n\n            # Strategic re-initialization for enhanced diversity\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.1), replace=False)\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return best_individual", "name": "EnhancedHybridDifferentialEvolution", "description": "An enhanced hybrid differential evolution using probabilistic selection for adaptive scaling factors and diversity-preserving reinitialization to balance exploration and exploitation.", "configspace": "", "generation": 20, "fitness": 0.32016507545126316, "feedback": "The algorithm EnhancedHybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.24.", "error": "", "parent_id": "584eb295-bc5e-44a6-9735-92ad32d360b9", "metadata": {"aucs": [0.8070127535822798, 0.7644833102064661, 0.8034373623723097, 0.8046024779861051, 0.7901681059927422, 0.8122945971682078, 0.735587805622283, 0.7865440864278895, 0.7686360089280286, 0.6502708792664795, 0.6922014086642918, 0.6077806790814964, 0.601867414973669, 0.5500668061422961, 0.6170050962459515, 0.6196348912178605, 0.6767417117579249, 0.7113256157890022, 0.1694367584756763, 0.571174238742002, 0.17843170014485554, 0.17439513683126628, 0.1707339494251311, 0.6667037498440498, 0.15572205710734255, 0.49327435352306304, 0.18938440706611892, 0.12323125871095564, 0.16228244440063444, 0.14153256718641383, 0.15958530998804232, 0.11556974387170138, 0.19945300843458813, 0.13294420903337212, 0.14038865449753135, 0.1465796350123163, 0.8603538530337094, 0.9508438012554506, 0.9267702577236592, 0.9535236206814257, 0.9362290691938969, 0.9281281894510682, 0.9297835167344333, 0.9418092157173439, 0.9341900696227311, 0.31597023490047926, 0.3469984128809209, 0.414312983189433, 0.4121143508090579, 0.24277759969221946, 0.48441947442009325, 0.34881674623586445, 0.2318105687637274, 0.42926475355668736, 0.2399887389959845, 0.7852086545014975, 0.20254729494440316, 0.21143522621596, 0.27038107294099445, 0.840415813532706, 0.32388897791143423, 0.21026147561226294, 0.23505119453289325, 0.2266145144008629, 0.14399847882830075, 0.12373439914827489, 0.1898025230089152, 0.14251440681093352, 0.3585443535404038, 0.25784234523368144, 0.1854315423115177, 0.19359268614108738, 0.18014442482237558, 0.12177496367187868, 0.11594293392281196, 0.3948938261817754, 0.17116642967576878, 0.14739165965675294, 0.206526089954999, 0.1518497095055592, 0.2067950850414284, 0.08285061545811079, 0.08343144429044314, 0.16314105916927546, 0.16542522694486161, 0.056326656549654186, 0.034904548788334044, 0.0727236469361684, 9.999999999998899e-05, 0.13245730728130334, 0.19662148239789534, 0.1691703204029663, 0.25219072435138645, 0.060753044790623933, 0.04750376466540762, 0.08163271779267323, 0.1784579885333516, 0.322274524782444, 0.29552468974735446, 0.11009471313423969, 0.1257400702530982, 0.08690343834712444, 0.12181215284354674, 0.06692170257957564, 0.0883131311144294, 0.14805284033644062, 0.08494727182762818, 0.13522086379982234, 0.15163814432982092, 0.11392506902089006, 0.2700610349827055, 0.39326782928466464, 0.07140476208512458, 0.20283353848964591, 0.16037979729623164, 0.15076456823389162, 0.1861079069315421, 0.4572110731772967, 0.5847746766110544, 0.5278686323326569, 0.4649395278244346, 0.5571748336079848, 0.5193281693798498, 0.5155044959294879, 0.4988438047085124, 0.5556176155536943, 0.10270288197575139, 0.11404097075514508, 0.15387862560779053, 0.11294794653835738, 0.10758748747427238, 0.15168633662168485, 0.14841931685561793, 0.13521790544593482, 0.10309912020977541, 0.41168908840517293, 0.2411404429277263, 0.27044088751553674, 0.24810875900639395, 0.1777120447982632, 0.18394672802856826, 0.4286046198818, 0.21939916203323806, 0.21795361103225386, 0.24971192473399717, 0.45700382825788066, 0.46484785704575915, 0.36926763729457834, 0.4293422289499055, 0.5616181889188742, 0.46887130001106336, 0.39125483250143533, 0.4202443032590406, 0.24566369326517856, 0.3031920285999651, 0.2786239910538054, 0.3065736069679732, 0.27645160907007105, 0.232497261725914, 0.30908212634380294, 0.2713524714641724, 0.25503464732949077, 0.21940583690607818, 0.19061425989242375, 0.22203027109295048, 0.23417817709721422, 0.20938938354080727, 0.2024685853689031, 0.22021446247214393, 0.22466808260114512, 0.2391718268268782, 0.6658311880763412, 0.19473484353325043, 0.2451030819128358, 0.19568670589277914, 0.2466538419950518, 0.20356144081136618, 0.24821517055728937, 0.209440173428745, 0.24276613972711525, 0.17492672744632287, 0.4395129429512573, 0.8475756684684307, 0.7300783649684605, 0.7497839641516343, 0.4384384193564269, 0.16033394520514144, 0.8394576005153295, 0.20801125803182108, 0.4692252261120132, 0.20443398118886935, 0.4036156400983719, 0.5323455877711855, 0.20676891252926044, 0.15031268135900278, 0.16274986427386118, 0.2081283826622934, 0.39876961496080754, 0.1843150012474738, 0.18704560677342275, 0.17499261406051314, 0.19487593959482152, 0.19577997631514832, 0.1837278010936615, 0.19958898266180136, 0.18577657178440077, 0.19366003609565496, 0.08618901301006576, 0.11527415539350494, 0.09001366836370361, 0.08515013215937561, 0.09261656529910745, 0.0924698059365413, 0.09279750920368457, 0.09205495270605402, 0.09003508055824916]}, "mutation_prompt": null}
{"id": "57928093-277f-42f9-9394-64ad7630eb40", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 21, "fitness": 0.372773547135134, "feedback": "The algorithm EnhancedDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.26.", "error": "", "parent_id": "584eb295-bc5e-44a6-9735-92ad32d360b9", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "111dfe54-6b25-4b4a-9e1b-851b740ee74d", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "2cd11d00-e3fc-4ffd-8f89-1ae568208e90", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "eb490415-ea5a-4a87-a849-1fe0986dc2db", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "4b5b0e2e-fdc3-4090-bcf1-caec8cf3e057", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "0668fdea-3de1-4d61-894e-1e914a06c3e3", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "2e58bb08-1fdd-4e3f-8fcd-a4501b163cce", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "72b31a3f-90b9-4c79-a07e-fa11c5196e23", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "0cae872f-21a9-4b31-b88b-8f573b68cee1", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6\n        self.crossover_rate = 0.9\n        self.scaling_increase_step = 0.05\n        self.reinit_threshold = 0.1  # Slightly increased re-initialization threshold\n        self.dynamic_shrinkage_factor = 0.95  # New shrinkage factor for dynamic population scaling\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        elite_individual = population[best_idx]\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                if i % 2 == 0:  # Selective mutation strategy\n                    mutant_vector = x0 + scaling_factor * (x1 - x2)\n                else:\n                    mutant_vector = x1 + scaling_factor * (x2 - x0)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.25:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                population_size_reduction = int(self.population_size * 0.1 * self.dynamic_shrinkage_factor)\n                random_indices = np.random.choice(len(population), population_size_reduction, replace=False)\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with dynamic population scaling and selective mutation for optimized convergence.", "configspace": "", "generation": 29, "fitness": 0.3561993199641638, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.25.", "error": "", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8281703190170583, 0.8097739701467597, 0.8131637299709739, 0.8232033811602469, 0.7961890941661853, 0.8038763675545015, 0.7860611820841571, 0.81071809089592, 0.8200833844241529, 0.6948523269579825, 0.671576255545602, 0.6761345493010102, 0.6476949390449025, 0.5219560824532494, 0.7267877182201696, 0.6503739526190871, 0.6836012955616594, 0.6068393709588347, 0.1326717970696345, 0.4792958605752141, 0.16783139295264426, 0.3025146313096365, 0.16539858136946217, 0.3793225895742798, 0.5276944159198519, 0.1762161621781061, 0.4817458314259284, 0.1238787156572464, 0.34665718071608953, 0.13604344540803837, 0.14393032723311971, 0.1640374046864197, 0.14795954911957854, 0.0923488188949595, 0.1463888858655249, 0.14600428780302865, 0.93546570022618, 0.9416594858862464, 0.9389939861670351, 0.9740788358278649, 0.9514469941563938, 0.9366399866699731, 0.9319372327266144, 0.9580954315916808, 0.9487148667907928, 0.23247082709151778, 0.3554994029163202, 0.40240904381125786, 0.2367380256134366, 0.45136895528386534, 0.471530683530076, 0.1652473537935859, 0.3203957286720812, 0.3356033911381261, 0.38413975875847817, 0.7988818415449703, 0.8344074736440681, 0.8623456356617203, 0.7986579331027008, 0.3211323451406606, 0.33190635213389197, 0.30978371132514504, 0.8065308763026087, 0.22260783292337072, 0.22506358142203298, 0.20567818422412154, 0.21148865122045812, 0.2875205725910521, 0.2353405635265613, 0.1287317451143012, 0.16723993851425856, 0.42031138765049614, 0.13823099463421584, 0.05077978868195365, 0.2796784691534413, 0.4029239199006367, 0.23529118921251646, 0.2947106841527827, 0.2907664738117989, 0.3491948529120743, 0.25620659324376116, 0.2702691760251804, 0.3362203292108531, 0.11254884645887864, 0.2271025068690914, 0.2027271817159072, 0.20335980690258204, 0.26127695407725837, 0.143148276553693, 0.1832484888745034, 0.2782308098837488, 0.1421251978993352, 0.2539636625249474, 0.10526037591100235, 0.21634687077490766, 0.08445008835273315, 0.4516553801607428, 0.26520620159443886, 0.213515147529724, 0.05181678805896861, 0.06288491254019135, 0.14559363767206046, 0.16236376769166783, 0.10798604602175221, 0.12024104582068007, 0.16816972678914777, 0.14437270596381735, 0.13145194058475973, 0.1899270538909137, 0.21414923472353886, 0.3712592982408357, 0.3137648124828534, 0.21851661538183975, 0.32980184203160834, 0.24191259618629068, 0.19393807395217166, 0.16038499738475243, 0.5913315144432238, 0.5688719340515744, 0.6329406128671151, 0.5565486999330909, 0.5795707073910555, 0.6417549177346888, 0.6977552678255455, 0.5640012989358039, 0.6641201220047714, 0.12954132675397922, 0.12908668767016374, 0.12111666837008928, 0.16010892944076094, 0.11726390750679527, 0.1353643801015818, 0.11890726679474706, 0.12159465078650389, 0.17129792699919688, 0.1784354633904166, 0.18021878938004243, 0.19230004251546184, 0.24085546352830622, 0.21109530805958943, 0.2789456223550446, 0.205666616124357, 0.22906998110468357, 0.20084667793299538, 0.36362570204077593, 0.4900342335473419, 0.2929596691564057, 0.5265577401631945, 0.47401568805812744, 0.43008698308216065, 0.5577171308224835, 0.5852179166726823, 0.5597797233592441, 0.4131207308226108, 0.34043716528849555, 0.2855313203514993, 0.3112553204357186, 0.47603070029792527, 0.37635278793000093, 0.4595466742471884, 0.248861154836597, 0.3221202638381946, 0.2308105697360855, 0.19126048948714547, 0.20898859574967887, 0.19993582194820148, 0.18980211569773597, 0.1967254219886858, 0.20977248609380517, 0.18949947471956263, 0.2276458099862232, 0.218251250950939, 0.20944243719189948, 0.2098207440482457, 0.19921055703056234, 0.21175679777083367, 0.23115480085171902, 0.2250652456701383, 0.578733023185222, 0.5848385150425548, 0.8537044855809697, 0.8527338878171797, 0.1783565361010202, 0.7850132041202109, 0.8573556328510016, 0.17377444277029663, 0.17443664418370008, 0.18484882548038972, 0.8357129044723717, 0.7903967605898228, 0.2060772059221767, 0.5297465699511802, 0.16357097667316356, 0.20380213062729413, 0.3758625778018211, 0.20556750444287386, 0.12468890820318246, 0.2072989657030634, 0.1929061568472903, 0.18803330576074428, 0.19888156778643262, 0.20776957680234298, 0.18437877543649794, 0.18533125397983918, 0.19046318278363628, 0.17675739378140276, 0.19072748527391636, 0.08380095137970889, 0.08920575410256004, 0.0943430065494204, 0.08041692019639723, 0.09145307609547748, 0.08985040666912969, 0.09563557469977191, 0.08930371057056397, 0.11423743717534418]}, "mutation_prompt": null}
{"id": "190f3593-f288-4bd0-9694-c02a083a663d", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "f3722896-5582-4d0e-8fa2-13289ee79d31", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "79825c36-7bf2-4816-b509-02083ba3e620", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "009e0806-2f00-42a3-899c-b1661a38884b", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6\n        self.crossover_rate = 0.9\n        self.scaling_increase_step = 0.05\n        self.reinit_threshold = 0.05\n        self.dynamic_crossover_rate = 0.1  # New dynamic crossover rate\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n                self.crossover_rate = min(1.0, self.crossover_rate + self.dynamic_crossover_rate)  # Dynamically adapt crossover rate\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection, edge population diversification, and dynamic crossover adaptation for fine-tuned convergence.", "configspace": "", "generation": 33, "fitness": 0.3446767934898967, "feedback": "The algorithm EnhancedDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.23.", "error": "", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.7290915719834048, 0.7237125063086026, 0.8143095559606673, 0.4556519972711287, 0.6852488431632624, 0.8283135483144514, 0.8013793442868868, 0.8064360817276623, 0.7811347327564152, 0.4924286779551251, 0.2671014006250554, 0.6017503789510669, 0.5472429583431531, 0.563989439604214, 0.47681969332867125, 0.3482398717581352, 0.38405639415027804, 0.5020849557109915, 0.1275788800896902, 0.11847166288016286, 0.11892568623913269, 0.10215819292209893, 0.14726214975230345, 0.11231104138474912, 0.11645279368455452, 0.127540778635035, 0.12723774177148084, 0.0822698338067348, 0.08588480692452505, 0.11146987795962193, 0.14010732337995468, 0.1307551890021077, 0.09947553800904807, 0.11524331420080636, 0.1414530707076348, 0.07139504840986188, 0.9045585989430516, 0.9774340949214105, 0.10947248094604944, 0.8831290012062469, 0.8811783640282642, 0.8774471101723113, 0.5334807836732426, 0.9505039785299583, 0.801420995672689, 0.15444137385191348, 0.11516977983207122, 0.26470314477779844, 0.11503920552392732, 0.11794356271969897, 0.10610813391735607, 0.14635130224237491, 0.40264857408763866, 0.22682848959507096, 0.8665471960979494, 0.220627896240562, 0.3881936400898862, 0.3504221864884336, 0.8672947769268375, 0.38550742207814626, 0.2276139348528865, 0.8813124322114716, 0.8578302731843066, 0.22996643835523345, 0.12343925307465542, 0.5010805563344995, 0.2511380777142156, 0.3310847908288218, 0.3091119972087897, 0.40129851203018474, 0.20248542715683104, 0.3399359213873848, 0.18308406548144684, 0.12621538383150088, 0.35646751291309164, 0.5848413906638383, 0.36070355210918736, 0.44491533902464386, 0.3067010747629303, 0.3376215664311797, 0.11771173830745174, 0.5665795904551211, 0.5263876242348471, 0.6628053680686954, 0.5322118585278568, 0.4737102269964837, 0.4651857731725424, 0.5308958110732268, 0.557823891289244, 0.39852834912159274, 0.4997248677193582, 0.6830674905556646, 0.7122732379412002, 0.5050959584862134, 0.4578034494472065, 0.6552944246173851, 0.6292403299716565, 0.48607683542133895, 0.7208352733057899, 0.10893082463823411, 0.2893724260296816, 0.20249441306379146, 0.11036499318545723, 0.05881345544483252, 0.32397941607903746, 0.24268442836146287, 0.27300125897895644, 0.14582554030328942, 0.30941928465510316, 0.20167092269909004, 0.317874085342406, 0.31196146055968577, 0.3216358408190162, 0.25783934465779157, 0.33778399186443253, 0.4260453213289097, 0.34355513655544667, 0.6124072270219183, 0.6878417597409852, 0.5992096240038958, 0.5506517800548618, 0.6241823907943317, 0.6023953685862392, 0.7346876007486395, 0.7255055607361032, 0.6584140499687308, 0.12317258142891119, 0.10385660588215795, 0.11457247937146764, 0.1277761433764465, 0.10483192745471748, 0.1242902595124522, 0.13322879238945096, 0.11808327746935343, 0.13788893195586183, 0.24953083424305633, 0.22475753108975938, 0.191438631811352, 0.2510711499501477, 0.1786661276217093, 0.2835968840936871, 0.3326908633410308, 0.18184173203511023, 0.2539431041562872, 0.2947792941609527, 0.2864807245410046, 0.27151804266260626, 0.38675920459554103, 0.39978372441802845, 0.2412432596170092, 0.3842894330717397, 0.34222645791090645, 0.42920034025208775, 0.30588851242004644, 0.3876220319568412, 0.2790349973180284, 0.3732342831409041, 0.3667123574644474, 0.2372415212948108, 0.2047083864196103, 0.3272029018686159, 0.3322837557488908, 0.21151699754987985, 0.22984500851399092, 0.21678177293109235, 0.24722273177741771, 0.2032389936047374, 0.22498823304020887, 0.25899767318721434, 0.2105781356745665, 0.22430882938988095, 0.20223407916894043, 0.1949726777476798, 0.18389232059915717, 0.2017935697497646, 0.23472703752192992, 0.18924973380982868, 0.20356047011606127, 0.1960450956566433, 0.21620411196423772, 0.7740480061803594, 0.22451688080124377, 0.1824420183934572, 0.19826574654635365, 0.6461099789860882, 0.17447665287198744, 0.18838072796049687, 0.8521720306786248, 0.8647876792494557, 0.6527922836375447, 0.1662910463039471, 0.4383809018763848, 0.20069727067276366, 0.16245004126792906, 0.19198937114291492, 0.20745819234668628, 0.15093866172995163, 0.16029029798841699, 0.1805345444346258, 0.20046080127315047, 0.18842122850607024, 0.18984527497599413, 0.18152599531942493, 0.195010671151421, 0.1848992349802937, 0.18032732480238245, 0.20492486641179075, 0.10445385418977515, 0.12657270393324127, 0.09343228644212376, 0.0828269602212478, 0.08307557680908906, 0.10556073553441425, 0.13768050410956711, 0.09879949632720397, 0.09165890869914184]}, "mutation_prompt": null}
{"id": "f47e3d35-8d09-43b3-9b73-eb20f1885a28", "solution": "import numpy as np\n\nclass ImprovedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6\n        self.crossover_rate = 0.9\n        self.scaling_increase_step = 0.05\n        self.reinit_threshold = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            # Dynamic population resizing\n            if num_evaluations % (self.population_size // 2) == 0 and np.random.rand() < 0.1:\n                num_to_replace = int(self.population_size * 0.2)\n                replacement_indices = np.random.choice(self.population_size, num_to_replace, replace=False)\n                for idx in replacement_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "ImprovedDifferentialEvolution", "description": "Improved Differential Evolution with adaptive mutation strategies and dynamic population resizing for enhanced exploration-exploitation balance.", "configspace": "", "generation": 34, "fitness": 0.3597430028961977, "feedback": "The algorithm ImprovedDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.25.", "error": "", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8200668914258723, 0.7941240015014196, 0.831097722000468, 0.8306308526709025, 0.7982078699457938, 0.8173608738747067, 0.7999789853165166, 0.8392217054539511, 0.8128970747489159, 0.6716834380066173, 0.6297573284583284, 0.6848804536750439, 0.5985842491100044, 0.6957194214586431, 0.7214577625832518, 0.6891328611713183, 0.7016076779057598, 0.6157995506426086, 0.3363614992171794, 0.14732562724627019, 0.20054587205176122, 0.29438916718954755, 0.5500434831282844, 0.36172273825557333, 0.4505351101054227, 0.3761106084325856, 0.14781386725329593, 0.40614903739362085, 0.13851617888550138, 0.13036059748019457, 0.1542820065697249, 0.1611636587518971, 0.15850264354951327, 0.14115489630486755, 0.12782363918138795, 0.1445984308384639, 0.9650612039015224, 0.9342780479387444, 0.9328966699187461, 0.9459070863581125, 0.9340672818513516, 0.9415071127799199, 0.9237422041930685, 0.9522448298902653, 0.9423104664301823, 0.35708706583582306, 0.32705070987032714, 0.39798782895210305, 0.17866490713776018, 0.37354028639149817, 0.3365580265752084, 0.19984223575185922, 0.37310673899678337, 0.2892271257366077, 0.8298273584718494, 0.8001333059887163, 0.8447707273661089, 0.351145239906277, 0.8249743296686889, 0.8043025451404603, 0.3697719341896395, 0.795026272202433, 0.8262780357453356, 0.24499955499094117, 0.17663716814397523, 0.4684006029216019, 0.36612120163857453, 0.2528403075349793, 0.16889227680169994, 0.22733594753969633, 0.2516918981687928, 0.18257193844656172, 0.14770188172286614, 0.18305876836493618, 0.260691679624782, 0.19411852432229493, 0.22385529485701072, 0.17612279722307345, 0.21438048218506855, 0.2718260533298734, 0.40477338379557515, 0.20381648816024522, 0.3764753243262827, 0.195254443671656, 0.07009175638083398, 0.18757648888686485, 0.0036290424380703845, 0.1264423787016633, 0.2534454838164667, 0.24542890057937805, 0.1654567811373321, 0.31698414762374694, 0.18967615592036136, 0.20830816045594602, 0.13262773916840376, 0.23483208745241368, 0.30706363738559395, 0.15890082989862153, 0.23448937700729688, 0.19160543959869314, 0.177005789730168, 0.10837584508754894, 0.16803479811017774, 0.14321742810000615, 0.23633243497245593, 0.25010233854869524, 0.1678359022837398, 0.21858071099527465, 0.25920863119599913, 0.22612623821838784, 0.1508177609166702, 0.36592220348129323, 0.183587735221026, 0.3655995623142133, 0.18465981257809272, 0.21430910592213637, 0.19510264167236868, 0.5211560886657376, 0.515208243754246, 0.6368455367303985, 0.4494572207065928, 0.5978520192357907, 0.6095512543746087, 0.594342249458304, 0.6061405421596937, 0.4871034724075979, 0.1420915775870777, 0.1694018486339346, 0.5585602831533287, 0.13439828516567554, 0.14464790492467383, 0.14692499557438277, 0.1125782272077257, 0.1495864172126854, 0.12528224578764768, 0.17839258143266457, 0.21501509741534253, 0.5141101958656229, 0.2862836834319755, 0.19362516210700598, 0.22389837459447615, 0.2823765494918591, 0.179013768015027, 0.19766885729100903, 0.4039041517107468, 0.4946963721356128, 0.30321592313286083, 0.43317677265897225, 0.3160901563661208, 0.35565323872665155, 0.488132159305692, 0.5904827514109048, 0.5016451618028324, 0.37092285674655756, 0.27653955595992774, 0.33627023725696703, 0.5142803153131058, 0.36498171505766175, 0.2677793367768295, 0.505558970531053, 0.37168811679775493, 0.414065859927379, 0.20382799552055275, 0.1970386488333029, 0.2129576769432392, 0.2042877339937479, 0.23057427898416127, 0.20380821626287982, 0.22903829770921524, 0.19625859672472845, 0.21396706935957144, 0.2304002243337555, 0.5469989070864132, 0.626387057337533, 0.20891223140473847, 0.6365559025559091, 0.23849624833378913, 0.5609737409924126, 0.23855695048668546, 0.5918187778964918, 0.18352355004505794, 0.1828098835042845, 0.1822909300420763, 0.1967315834573593, 0.1934266738859054, 0.1934553672102668, 0.16885991451057125, 0.8442712045002977, 0.8153904700039865, 0.2054759995308505, 0.2046924607733548, 0.6880111281755361, 0.19846936047346475, 0.19822003434955537, 0.2079938793274706, 0.7750577364706707, 0.20564148964272477, 0.15218583628885995, 0.17400188443914633, 0.19180473226205552, 0.193207630983651, 0.1868118569271623, 0.19932458924202523, 0.1814405567151287, 0.1822575423145113, 0.20446619664428822, 0.18261913332093116, 0.08401550682463799, 0.08962136512550845, 0.10023544464933709, 0.08596204215906111, 0.09075416718575924, 0.08596920293338173, 0.09484757980925862, 0.08197272285302859, 0.08335335769065899]}, "mutation_prompt": null}
{"id": "087e769a-a127-4f47-b464-581169fc88c5", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "c9e30778-de8f-43f0-a6b7-9ab60f9cba65", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "c06dfb2a-fcd6-469f-afdf-69bd8efe68af", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "d094355b-3265-4d75-8462-6b147d998bb9", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5  # Adjusted initial scaling factor\n        self.crossover_rate = 0.85  # Adjusted crossover rate\n        self.scaling_increase_step = 0.07  # Adjusted increment for adaptability\n        self.reinit_threshold = 0.08  # Adjusted re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Maintain elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n\n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                elite_candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                elite_candidate = np.clip(elite_candidate, self.lower_bound, self.upper_bound)\n                elite_candidate_fitness = func(elite_candidate)\n                num_evaluations += 1\n                if elite_candidate_fitness < func(elite_individual):\n                    elite_individual = elite_candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with dynamic scaling, elite-based exploitation, and stochastic crossovers for better adaptability and convergence.", "configspace": "", "generation": 38, "fitness": 0.3698014054878805, "feedback": "The algorithm EnhancedDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.26.", "error": "", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8208520976882889, 0.8276126355873651, 0.8263462160590799, 0.8161432906597931, 0.7935732300480531, 0.8410618381850539, 0.7757582199994912, 0.8284389326959185, 0.8374322212162895, 0.6677652634820874, 0.6869546935796703, 0.7344219618735179, 0.6726001052253161, 0.673298717852797, 0.7228994416976341, 0.672250979395829, 0.65637720088218, 0.7118164715186284, 0.43482170798681663, 0.5360085762741916, 0.5575456286508282, 0.14955156956759508, 0.1593350588528627, 0.5077942731803655, 0.4106245906220395, 0.25839508684117396, 0.24154495164115197, 0.2523776938834198, 0.2901586509526237, 0.14974545984743237, 0.12591194283235707, 0.13295215506158642, 0.1628905871070665, 0.1490629434457451, 0.1564767792024533, 0.15363124374294146, 0.9645182112968788, 0.9337572832497204, 0.9307104593829358, 0.9362772112865675, 0.9340739022345983, 0.9309040623099574, 0.9149363874054965, 0.9480167815897068, 0.9330359130159886, 0.30591807494977397, 0.3448241168697056, 0.44664625004655545, 0.2322297767195679, 0.31205874895606844, 0.3210013926632277, 0.2658941300964781, 0.30173252918060134, 0.47746724067515356, 0.7829764420944278, 0.3234075297341297, 0.8280578698239279, 0.27294429254970876, 0.8452489016233421, 0.8502127981729851, 0.6868903029122344, 0.7769196619115716, 0.34882173605705635, 0.27012609161047696, 0.15481991028398856, 0.2630006793899943, 0.1500835604997246, 0.30414134683390215, 0.2254911462820699, 0.19374277387058536, 0.12477717149799972, 0.15405657432256425, 0.20242514075731155, 0.13973029312960916, 0.21330616866535068, 0.26372781955593205, 0.1725080174401057, 0.18434090375108458, 0.2312120238876294, 0.18625135847525576, 0.21402417088921066, 0.21015757045695205, 0.11734706933561356, 0.00891544309151271, 0.17035886261112176, 0.03853918116048882, 0.05114104320023949, 0.18324237410722177, 0.011068559742918316, 0.16129400574002162, 0.28852300567133693, 0.25234986982872065, 0.15333976063041033, 0.23084445582511837, 0.12906127723405258, 0.17323894760431646, 0.19355861796546092, 0.33982941655549037, 0.19376357540547073, 0.08860870423875278, 0.1168216822604432, 0.12915509055023777, 0.1864330754401312, 0.08342561652761982, 0.08945011154845783, 0.1585373997070204, 0.10944474655917036, 0.09572135533667847, 0.14083918306555332, 0.13393834817607964, 0.398010704339252, 0.28558504208166513, 0.2035798666337516, 0.23118927559793734, 0.17264065557870323, 0.13689727834102428, 0.12375392150457187, 0.6066789006369799, 0.5484149952242998, 0.6734351244082035, 0.5647655419095561, 0.6467989495322961, 0.6773336619262775, 0.6162152885364425, 0.5142361937051483, 0.5781251864339617, 0.14095984628096758, 0.1448438670267922, 0.12787607414313829, 0.12662398206064385, 0.12358603821511827, 0.1445976716061036, 0.15381228013211423, 0.14808941124874186, 0.1144651225868194, 0.18638291759897097, 0.23745817591335094, 0.33176194868068054, 0.15697338311210296, 0.22011668705580767, 0.4068137047717434, 0.2729861563690379, 0.16206203913754147, 0.16737676177425476, 0.5319848147202592, 0.5760298809434141, 0.5131216436131063, 0.5154125061441837, 0.5365509728583613, 0.4731480657685804, 0.5422660026548273, 0.511588355088192, 0.5529087302039222, 0.33734267512138094, 0.37916120811976883, 0.24615093428028023, 0.2940418409720269, 0.3623833412126449, 0.4066781112780895, 0.472939219312249, 0.42101700007133236, 0.25302478547552043, 0.21590759058932985, 0.20834999646864227, 0.22632947142397708, 0.19517288916137043, 0.19824521162931663, 0.19878573550090395, 0.2537775380113064, 0.19342549266706388, 0.23327231009707838, 0.21687276832193314, 0.6992407210019602, 0.6171590149709096, 0.6034730326981342, 0.21010830215612208, 0.23054103520121705, 0.22536256734211368, 0.48550298738918474, 0.49663581020324477, 0.19494388323654988, 0.840195696687009, 0.5867178665953623, 0.8173042232517014, 0.7800801879910595, 0.706260923617364, 0.8068274595591307, 0.7844890142669884, 0.863217718351794, 0.84531425945967, 0.19957150344263241, 0.7247748314529382, 0.5944205263320415, 0.20690149349635634, 0.38607609686179545, 0.20739343750707773, 0.2029564322127757, 0.20735815759796528, 0.17697984274698664, 0.18187935077143313, 0.17680372977016612, 0.20839531674789313, 0.19645522345559574, 0.19192238030923425, 0.19721931355066713, 0.18765128619476346, 0.18485401396508983, 0.114652910307526, 0.08407865871493814, 0.0814373848000236, 0.09276116197159445, 0.08979984010147668, 0.08361373656354787, 0.09234465428629479, 0.08955983397725287, 0.08290409358412576]}, "mutation_prompt": null}
{"id": "fbfa0edc-6387-4068-a3f3-a924ab704083", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "fa861247-85e5-4f34-8374-6e92fbb67228", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "71e1553b-8df8-4baf-aa8d-3d5096fc3548", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6\n        self.crossover_rate = 0.9\n        self.scaling_decrease_step = 0.1  # Changed to decrease step for dynamic adjustment\n        self.reinit_threshold = 0.1  # Increased re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = max(0.2, scaling_factor - self.scaling_decrease_step)\n            else:\n                scaling_factor = min(1.0, scaling_factor + self.scaling_decrease_step)\n\n            if np.random.rand() < 0.4:  # Increased chance for elite perturbation\n                candidate = elite_individual + 0.2 * np.random.randn(self.dim)  # Perturb elite more aggressively\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.20), replace=False)  # More intense diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive dynamic scaling, elite perturbation, and improved population diversity for better exploration and convergence.", "configspace": "", "generation": 41, "fitness": 0.1912094355308633, "feedback": "The algorithm EnhancedDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.19.", "error": "", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.5953605456551481, 0.3612539340010005, 0.3956695114141643, 0.5956673979298175, 0.682094586523177, 0.41114060419915655, 0.459998214542791, 0.44571140357941685, 0.3949762993934741, 0.17294129355474375, 0.15717194609955476, 0.2194493608693069, 0.158033418875956, 0.1674972194144566, 0.17182798358623563, 0.26441971131977793, 0.17590150569805008, 0.15472760554714093, 0.10579773845436757, 0.07434584002632871, 0.08708500454108248, 0.08918611273976984, 0.08375849970039395, 0.09620284268766333, 0.08598448946461446, 0.10005244123052415, 0.08158045742631204, 0.078924129509934, 0.07525025546876951, 0.07596434591290357, 0.07750897726379913, 0.07414113708657155, 0.06637630461418542, 0.06753776467143702, 0.08915959569485643, 0.06906342737497961, 0.9473704498732971, 0.9481171044701101, 0.9256668257859045, 0.9466171445864182, 0.9055170910652498, 0.9039857559471922, 0.9460325065256161, 0.9703914057962576, 0.8695405050613962, 0.15556258333830175, 0.14129055691342218, 0.17299703812620593, 0.18357934939921783, 0.15704909676802759, 0.1796949162567062, 0.1968341640656689, 0.18952286059754175, 0.20376056819381028, 0.2666515323932661, 0.24492134708430457, 0.19590988763408612, 0.27197439734632667, 0.24487952259873813, 0.24103968598162073, 0.2381604983009623, 0.23053366745688564, 0.21880206211866404, 0.10493799733059095, 0.11650080990905665, 0.12414648653115123, 0.10987487677573649, 0.13326181604338472, 0.10172834734016978, 0.101898123668554, 0.10404474016737708, 0.08376144414809827, 0.16696109917193758, 0.1339380845707281, 0.12691390719193008, 0.10426951866399015, 0.13468989831129397, 0.09883549294934058, 0.12268514915883899, 0.10555261935563198, 0.10965527162068178, 9.999999999998899e-05, 0.0007466610597999246, 0.004077419202627275, 0.04753390758384923, 0.016902398398488505, 9.999999999998899e-05, 0.00045917780130599883, 0.0028501500441591165, 9.999999999998899e-05, 0.07913215559497455, 0.06408648740555678, 0.09627754722140813, 0.07745187115844387, 0.1073124904205568, 0.08324713347990853, 0.12643009575052677, 0.16088864746254417, 0.13164330553455494, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06888210917527737, 0.08864792405112254, 0.0697878447126572, 0.0713637292164776, 0.08345647313581994, 0.06356772575569625, 0.07688554489185395, 0.10948302481626648, 0.06519537999727032, 0.3538748387183688, 0.322885676331073, 0.3211666772544596, 0.3876038957549882, 0.3571220204366896, 0.3566437954905408, 0.42420040152004046, 0.37778732747918997, 0.3392217937119745, 0.06626848023211807, 0.08900646033817772, 0.07604288851146279, 0.07291422746798104, 0.0863490303214357, 0.08011181081112495, 0.07085964354272967, 0.06486329118991685, 0.06601634987058946, 0.1707856048291052, 0.13289419218257703, 0.230831643254375, 0.14739710773421433, 0.14021795131600012, 0.16923002169244517, 0.17404130622308, 0.16259550131914746, 0.14026690970242328, 0.2626219632652008, 0.21763190013907507, 0.2203051732726249, 0.21323293797221976, 0.22356036763698917, 0.20353437008548492, 0.23065615300754483, 0.2353390226576677, 0.23010569383360135, 0.14488720838085534, 0.1692583702820879, 0.14391129352909915, 0.15430312302747318, 0.15974663821937207, 0.14504013093999624, 0.1574535527089138, 0.1650405600805549, 0.1840452361291013, 0.16937728185256506, 0.18705362671157422, 0.17550703871775641, 0.15987706851248407, 0.16202692248379935, 0.16694771700724176, 0.16672374815167534, 0.1862935707893466, 0.1618055158857824, 0.17461877247076918, 0.17782352688056957, 0.16706951128885672, 0.1674882218345054, 0.16774391233103048, 0.17750807502667376, 0.2084689599482643, 0.17731706708197692, 0.17790367021187725, 0.17333331124926699, 0.18046234287744634, 0.16309952291104224, 0.20296654712776518, 0.35595543304787325, 0.266061804833457, 0.1682916683675203, 0.22231454679968654, 0.16625718796942635, 0.19547153058703526, 0.19793892591744255, 0.16055620291131323, 0.25076565872024326, 0.1917558927289621, 0.21247281065846302, 0.20246915903067397, 0.19986770753494787, 0.2072297990159111, 0.18360319343267895, 0.19064759302871714, 0.18406859078397553, 0.17687399118046343, 0.18983543177210394, 0.18388600684397483, 0.18150303671478207, 0.18931810391230186, 0.18397576841073082, 0.058354612907655756, 0.06532901938764735, 0.07507069177955095, 0.06849051981225929, 0.059268231882874, 0.07516699289201767, 0.05669163903602348, 0.08558479721713008, 0.06354373525556856]}, "mutation_prompt": null}
{"id": "f1df3c5c-1113-4588-8187-d3a9fadc1726", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "6b1d9f58-bc69-4897-a95f-7863a8126fba", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "b178535d-2dd8-4c8d-8e0b-4dc6f768ae4f", "solution": "import numpy as np\n\nclass AdaptivePopulationDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # Increased population size for diversity\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5  # Adjusted initial scaling factor\n        self.crossover_rate = 0.8  # Adjusted crossover rate for exploration\n        self.scaling_increase_step = 0.06  # Adjusted increment for adaptive tuning\n        self.reinit_threshold = 0.1  # Increased re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.1, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.2:\n                candidate = elite_individual + 0.15 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.20), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "AdaptivePopulationDifferentialEvolution", "description": "Adaptive Population-based Differential Evolution with elite-guided mutation and dynamic parameter tuning for enhanced global search.", "configspace": "", "generation": 44, "fitness": 0.3213699300330925, "feedback": "The algorithm AdaptivePopulationDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.24.", "error": "", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8051261542735162, 0.7928797568781136, 0.8038279879613693, 0.7700373582690822, 0.7323130005913572, 0.5620840740435412, 0.8043485192741384, 0.7206256120617299, 0.7358034602278334, 0.6033121887099302, 0.5312636160343134, 0.6009406447889294, 0.5823589650162775, 0.5732816537535346, 0.6393900187396508, 0.6460661991009612, 0.5282613168116053, 0.6085989267452727, 0.5076004281237061, 0.35824445853647624, 0.2732491983230019, 0.4310347788461403, 0.4738540772079829, 0.35887200387663465, 0.24859038387042343, 0.2781134007168228, 0.4565149028202081, 0.1595762094338996, 0.4129840122437115, 0.29495860606869206, 0.16736712186444624, 0.1576120276622912, 0.13796390365512756, 0.164380969728241, 0.1434309820495946, 0.16387087949118995, 0.9155997800555646, 0.9702442528655637, 0.9471017651256443, 0.9240870899958965, 0.9398757717445154, 0.9182556736584379, 0.9188000094393707, 0.9354705386880826, 0.9394845950322633, 0.3016066523015587, 0.31687799838838115, 0.2939415616955795, 0.2463413600985782, 0.2707083351801022, 0.3273709313163834, 0.3313541867879578, 0.26820494339843914, 0.32243849286594406, 0.7445948492797148, 0.3646308976918399, 0.3378066733890328, 0.8464296493269381, 0.2632214735068982, 0.7801441025382708, 0.22684640094471176, 0.6755362317522282, 0.6802581123682103, 0.3720626651257576, 0.2760505483955461, 0.1830878202322509, 0.1458216841733765, 0.16750211309983665, 0.14314953136425845, 0.20208844151686267, 0.1787595991848382, 0.2095202703419211, 0.20541994492751592, 0.11452815326290988, 0.09787145684282728, 0.1494079139598098, 0.1405650301776432, 0.160572941387213, 0.18049548517516578, 0.18169651230476624, 0.16081261279781667, 0.0821309784166413, 0.06324297448413241, 9.999999999998899e-05, 0.004882776088460217, 0.06840591136676322, 0.0289910464681572, 0.022322377585121456, 9.999999999998899e-05, 9.999999999998899e-05, 0.14695177743660404, 0.06506897995829508, 0.11574142616157546, 0.10465906895935873, 0.09769568468638079, 0.13412122297739792, 0.14863104538152871, 0.1878768911575145, 0.1065750813604307, 0.11396629831704663, 0.10952111720755142, 0.05211014308593598, 0.0701722475438914, 0.061173844492724117, 0.07630220168214541, 0.1148025935628657, 0.10000056601200447, 0.22192697261065897, 0.23309068520809073, 0.14145834378407274, 0.16309681504639606, 0.1520899568519397, 0.1613682524289587, 0.19069996991755556, 0.1843067044435477, 0.17510088203409013, 0.13650998677584214, 0.5118171660947661, 0.42694554677041663, 0.48638024050188877, 0.5644838513117652, 0.4872952978205354, 0.4608889042247858, 0.48110037985419307, 0.5269565860027505, 0.5207278951656591, 0.15516674999757019, 0.13950825744997475, 0.11516838948970431, 0.14297555120937488, 0.13940382988748168, 0.15552936379668714, 0.14360096390059085, 0.12750376138609731, 0.15051861643928077, 0.1734970512449907, 0.18241050916693347, 0.26291328650165646, 0.2785999001663837, 0.1690527125364777, 0.23961028267545148, 0.2080677352823025, 0.1723726169598716, 0.2260532316328927, 0.29843158727167474, 0.3573081942970504, 0.35422355788276694, 0.4711876360410664, 0.41075122896197236, 0.34150746634803975, 0.37583380044106784, 0.3972097707403882, 0.45655329935526057, 0.3182780488003285, 0.30670993497851684, 0.2830205338559163, 0.28185915655562777, 0.28742999924768964, 0.3074759431470606, 0.18684705466339513, 0.3133016879327465, 0.2758417832521294, 0.21299131099386814, 0.20210969607779072, 0.22155500274252105, 0.2081490413772924, 0.21671583966747232, 0.2161468782013114, 0.19218580295139898, 0.21736254890870643, 0.220596810270565, 0.23276861926286874, 0.23591059845763618, 0.23051050979256593, 0.5601404187180653, 0.5510606434969274, 0.5453637830563502, 0.1965693994060469, 0.20967635097291482, 0.39410100781256463, 0.7430691638726037, 0.8089780170273244, 0.20713571561834387, 0.7869060925147477, 0.5946916341445962, 0.7438466864220887, 0.15930449686993053, 0.16190871691904118, 0.6820847355852289, 0.5176890857677232, 0.3762458277402134, 0.32121879241268836, 0.20509241929660127, 0.20093148157280727, 0.37850678363085266, 0.46659637031798806, 0.35714415699835445, 0.19930368766081974, 0.18026990726239944, 0.18951193765583263, 0.18749777614568608, 0.1856053384884544, 0.19618798825487416, 0.1718898766406286, 0.17512535445453836, 0.17777561081290716, 0.19592092946580342, 0.07968575366498953, 0.08556462471586801, 0.08338357897450444, 0.08237721158276012, 0.0898731399197259, 0.08545663059262298, 0.08825895011486462, 0.0824201097406283, 0.09153500587905095]}, "mutation_prompt": null}
{"id": "b27a68fd-066a-4441-9c79-de65c009d675", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6\n        self.crossover_rate = 0.9\n        self.scaling_increase_step = 0.05\n        self.reinit_threshold = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                dynamic_crossover_rate = self.crossover_rate + 0.1 * (fitness[i] - fitness[best_idx]) / (np.max(fitness) - np.min(fitness))\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n\n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive mutation control and dynamic crossover to improve exploration and exploitation balance.", "configspace": "", "generation": 45, "fitness": 0.3608073924913512, "feedback": "The algorithm EnhancedDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.25.", "error": "", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8256610136966548, 0.8032469415537477, 0.8304216898561838, 0.8219925400728323, 0.7742483872321224, 0.8437579149142567, 0.8093288798326982, 0.8392595539544885, 0.8084842505908467, 0.7360057368473025, 0.6722139157842393, 0.6887275186330881, 0.6588877834562129, 0.6709181036460806, 0.7194936203344229, 0.5751722200616672, 0.6207671965538799, 0.5746107207872503, 0.13480116357093685, 0.13392020011901695, 0.1350722894645916, 0.14855815551574325, 0.14684014450425198, 0.5325232253153638, 0.17033132658371164, 0.1486508405880027, 0.16307076049025104, 0.14831031816214202, 0.12912425660149418, 0.10647598141573744, 0.1299620824864287, 0.17431931887408114, 0.14202695095192175, 0.14066894389667373, 0.14611827839131963, 0.16476979434168493, 0.9338241142552105, 0.933991876890087, 0.9116311552185594, 0.963017422259243, 0.9231404937270217, 0.9471507519670517, 0.9364375197978062, 0.9235946784832176, 0.9342186484013463, 0.36007480996249963, 0.3089345069788074, 0.4259875877425995, 0.42251734422226406, 0.32300469099253226, 0.14213196760436153, 0.3069584623516378, 0.3859797333532259, 0.3233427891898464, 0.3613525866249361, 0.8048675778929831, 0.8313189606582564, 0.8353384662723891, 0.8404562636389673, 0.269824232384005, 0.29444267084587483, 0.3407560202142802, 0.8232164536903996, 0.24487555278662299, 0.241293391427979, 0.28859014958301055, 0.28547808902884286, 0.12652242113137524, 0.1278657217277268, 0.47390924710919125, 0.1943042895967595, 0.24300263971349279, 0.20042882603776002, 0.1713775586966827, 0.07111262962732323, 0.3983988861782466, 0.40890264404408505, 0.5827422538355214, 0.6462672176563997, 0.36237078414630264, 0.46371169418576985, 0.033385478413245795, 0.27793556822115006, 0.2049574639808307, 0.07505882433031097, 0.1754643090948259, 0.4136857165819209, 0.1089971281245471, 0.40238664852819683, 0.3445396686631852, 0.37774773325113864, 0.1861396211538321, 0.14959986576723694, 0.4305827041430894, 0.3901510970535491, 0.3720394658074654, 0.5019970683645885, 0.4019423664333063, 0.326677499776594, 0.03933482711319358, 0.08271245328094756, 0.06479394013587347, 0.1737122586148342, 0.10340652045762322, 0.1489987596165372, 0.16477451518002395, 0.10877851432206631, 0.15562020313785974, 0.2310318020996459, 0.3654316779360005, 0.2611414810358137, 0.373314913275555, 0.2639879211014424, 0.3164920392671362, 0.27900663725050034, 0.2911337669131464, 0.18951929740095186, 0.5775160037520277, 0.5880265766187651, 0.727503870183766, 0.7520629473591101, 0.6056055368898036, 0.7316486485637281, 0.6757373144475316, 0.6240486932060083, 0.683918659422659, 0.14765552319306374, 0.12956070773848227, 0.12821193081317794, 0.1712300045810522, 0.12078734026689086, 0.16444450492818374, 0.13007425126405725, 0.1442488562794091, 0.13226360145319815, 0.19239437567058737, 0.17853296539130936, 0.19762952500694264, 0.3777964832566013, 0.27973761896148075, 0.27856171048055045, 0.21487902857618846, 0.2015017739205599, 0.1560734944340344, 0.3432666560843901, 0.4734722596472899, 0.45700071185882996, 0.412228203070264, 0.3428687349077274, 0.4300101690853936, 0.478255038396426, 0.3195040177219688, 0.5304818779100262, 0.28467622132431536, 0.2434967600280299, 0.3798805705306637, 0.2505423630840412, 0.2881083598145109, 0.3092951792927435, 0.25521157323679766, 0.2934936870215824, 0.3505464478835718, 0.20126339740035615, 0.2176154429096978, 0.24792827562857378, 0.2046641637265132, 0.2059142863245349, 0.20574049065912825, 0.20523407063959764, 0.21076233023570645, 0.19261025199465598, 0.1895167712773116, 0.2217062112744823, 0.21501215347241287, 0.21748917700815906, 0.2163104655962259, 0.2061222888907841, 0.2040692325398209, 0.24356641856830685, 0.23769883854340124, 0.1661851602071649, 0.18321281069206863, 0.1688631073704644, 0.8365332614462883, 0.6816083877107955, 0.808869868652237, 0.8171876398993013, 0.8700455336255503, 0.8006186024772874, 0.8482313094653767, 0.2034964362673095, 0.5542153695597263, 0.19746331436062858, 0.20043190291245638, 0.5403301978541527, 0.11130925000451242, 0.2067248522690961, 0.20760536769906257, 0.1866135503491494, 0.1861144135224867, 0.19846234093378534, 0.19792873133103572, 0.19242410817751077, 0.19381869754555303, 0.1892529295251586, 0.19452681954654094, 0.1895041865372904, 0.09591810775817922, 0.086727160828593, 0.09604430906985328, 0.08697353387142248, 0.09102738728918103, 0.08627732074162209, 0.08335707858917263, 0.0970207573002233, 0.08837037145221127]}, "mutation_prompt": null}
{"id": "c3eb0a12-9253-40aa-b492-6034719f376b", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "61bb6f52-f9ce-47c9-9dd5-b9f7a5d245ac", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "70e396ae-2899-4f8a-8c48-369d6a8c9569", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5  # Adjusted scaling factor\n        self.crossover_rate = 0.85  # Slightly reduced crossover rate\n        self.scaling_adjustment_rate = 0.1  # New dynamic scaling adjustment rate\n        self.reinit_threshold = 0.04  # Slightly reduced reinit threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n        memory = []\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_adjustment_rate * np.random.rand())\n                memory.append(elite_individual)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_adjustment_rate * np.random.rand())\n\n            if num_evaluations < self.budget and np.random.rand() < 0.25:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with dynamic learning rates and genetic memory for enhanced global exploration and local exploitation.", "configspace": "", "generation": 48, "fitness": 0.34896802144070543, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.25.", "error": "", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8054337346651449, 0.8268829912032274, 0.837378499684443, 0.8528301787932345, 0.8217420739627848, 0.7897598337189619, 0.837318430352939, 0.8162384566112357, 0.8221858760412428, 0.7166957733116155, 0.7033587948292438, 0.6998931780053401, 0.7395540186845555, 0.7268506488395754, 0.6994304457554992, 0.7025166011354596, 0.6775323616116349, 0.7466455878749898, 0.16024477494223444, 0.401790816040997, 0.3330060926321262, 0.41783769416190286, 0.4583415013272335, 0.14367522209803318, 0.14941840815744523, 0.5585891328039899, 0.15499209148636583, 0.13981137015723666, 0.4027512944462813, 0.13331506405816185, 0.13877069385873086, 0.15381753383971464, 0.3354137826484863, 0.14776937951910607, 0.14018338791019125, 0.15506428385569038, 0.9641491818339981, 0.9365072771296936, 0.8911547048423686, 0.9680701393910901, 0.9275724451991972, 0.9328434002610323, 0.943046208473382, 0.9523516572889749, 0.9395774187779629, 0.32021279315396334, 0.420136228324982, 0.19971993221092577, 0.14660797934301117, 0.4925383016825218, 0.35918532798905567, 0.38845975643634567, 0.2855023364803594, 0.44638097650830155, 0.3762376650109942, 0.8149161171849498, 0.86070073979649, 0.8136445385535227, 0.8467828303265379, 0.21155661237298184, 0.3863614580754594, 0.17934083090843267, 0.37536301263479566, 0.17662884870374096, 0.2995726230804254, 0.1559008570020094, 0.15505197478892518, 0.21312151535222956, 0.22999313014740996, 0.17960750062006048, 0.16043231008281822, 0.33634730726906203, 0.16097824072135758, 0.16121065685270675, 0.2019298922884103, 0.22862730735608927, 0.3822136879616186, 0.21948309633398388, 0.147771831413815, 0.17035325891442843, 0.16825243111386268, 0.10217146863284121, 0.19117988498119998, 0.13201394374490705, 0.3178540966186363, 0.07788894916597378, 0.008313534635446373, 0.1723403661020606, 0.003946907597750404, 0.05575175855717518, 0.40280360209399324, 0.3022898354210385, 0.11357876255161703, 0.20594020404818913, 0.1403055694965909, 0.12894274727329302, 0.22711237863293599, 0.1606882382534366, 0.21251876268539838, 0.1444417403095808, 0.12124668773448577, 0.13499912357949595, 0.10992862166845274, 0.09830766939529478, 0.25326435838107886, 0.2527556647588126, 0.23119943927550313, 0.09396857336376774, 0.14126052645485065, 0.29743679147355684, 0.265922014271867, 0.24065004409181823, 0.269972157379069, 0.21043738775972598, 0.1759042673762644, 0.2511046048776605, 0.18729594792226767, 0.6685991101574136, 0.5743497142282018, 0.5177635701673667, 0.6301298298469409, 0.6105602427265946, 0.5461193469933369, 0.6251996770666284, 0.6380394793198612, 0.5603903945409807, 0.1152510880855363, 0.12262775239422286, 0.12779972836619546, 0.15137185860933677, 0.16544248012547158, 0.12490216136487453, 0.5009795765020826, 0.12828652930917528, 0.11656455283113887, 0.15830912350229787, 0.23071418222263895, 0.20388903506618838, 0.1492550459816966, 0.3786445165687332, 0.17586929792658812, 0.19905857120248005, 0.16831561851893384, 0.2573273638475846, 0.49768364115877484, 0.5170880261425409, 0.3082450217125491, 0.5151698347845372, 0.4793720777904069, 0.4971754937102386, 0.5425130395075566, 0.459981763950134, 0.5345876013458459, 0.35247579340644974, 0.31963901277792406, 0.41108502651709977, 0.3515589477482356, 0.3163653420621575, 0.40492214901627954, 0.26067306846896754, 0.349368871678289, 0.3916364713005085, 0.22037251053891782, 0.22762566235638115, 0.1954982666949321, 0.21889964093178216, 0.23811726175091508, 0.1985471695373192, 0.23126907043837897, 0.2063347830543888, 0.22241475388061405, 0.24220171491117304, 0.20124391617796122, 0.45302874121610626, 0.5872284164814203, 0.22110093256603836, 0.6218876454840108, 0.23016704066687732, 0.6704796507900241, 0.233045824311354, 0.16671420545343385, 0.16972170096042283, 0.7073777687925236, 0.1760056632458129, 0.19702345973501556, 0.7094540360941077, 0.7580123410051949, 0.16990026097169997, 0.20378279355929285, 0.4762913685944583, 0.20993363452674074, 0.16379396046633887, 0.1629977047833594, 0.5676314956113514, 0.5360277695403471, 0.16194214296401566, 0.15153366549651204, 0.5158226900828771, 0.1744661249711097, 0.1889799028321929, 0.1844826012402797, 0.182700535502472, 0.1793073260778567, 0.1888615640751906, 0.1790101492415732, 0.17831799392683534, 0.19690663689663268, 0.11571057178786415, 0.09058031529642885, 0.10755365535157813, 0.09436928472134898, 0.07926870490946603, 0.08591377298798875, 0.09247642458670202, 0.08317680389694193, 0.08710658888143696]}, "mutation_prompt": null}
{"id": "b7f64d76-4a34-45da-974b-c37268fb8f83", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "665adf59-5f11-4b8a-a6dd-30cf04ba0c1d", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "d4be8dce-157c-48a8-9e70-5167670639d9", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "ae852074-7fd8-4b18-9f58-287780b60920", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "a8146be9-0974-49dd-869e-f8984ed4412e", "solution": "import numpy as np\n\nclass AdaptiveMemeticDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6\n        self.crossover_rate = 0.9\n        self.scaling_increase_step = 0.05\n        self.reinit_threshold = 0.05\n        self.local_search_prob = 0.2  # Introduced local search probability\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n        adaptive_scaling = scaling_factor * (1 - fitness / np.max(fitness))  # Fitness-based mutation rate\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            reduced_pop_size = max(4 * self.dim, int(self.population_size * (1 - num_evaluations / self.budget)))  # Adaptive population size\n            for i in range(len(population)):\n                indices = np.random.choice(reduced_pop_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + adaptive_scaling[i] * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < self.local_search_prob:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "AdaptiveMemeticDifferentialEvolution", "description": "Adaptive Memetic Differential Evolution with fitness-based mutation rate and adaptive population sizing for enhanced exploration and exploitation balance.", "configspace": "", "generation": 53, "fitness": 0.3204728986014964, "feedback": "The algorithm AdaptiveMemeticDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.24.", "error": "", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.45676000399265204, 0.647309682853599, 0.6228792545440407, 0.46857797682806523, 0.3747691098335778, 0.4414315357204398, 0.6227226115317283, 0.5997995040975446, 0.7475467552663407, 0.6769866515124453, 0.690094851844686, 0.6761720170006267, 0.6669882724492373, 0.7004539908065139, 0.6569207057070099, 0.6634897631290022, 0.6737799242769428, 0.6373023159117617, 0.10401863662745514, 0.09672123660720988, 0.09496893869114287, 0.11683570205965166, 0.12362084897473924, 0.1187081032450431, 0.13832955126421786, 0.14251667202729934, 0.14013329258652063, 0.09037594325746645, 0.10395836768064615, 0.1238067127430279, 0.10102003853720287, 0.1086198729068164, 0.11978379225442026, 0.1278736625370338, 0.11676100296248659, 0.13093924838267468, 0.9419891300366656, 0.9016506447844714, 0.8911773725002988, 0.9202477642886514, 0.9125108331116092, 0.785247791997011, 0.9412651110084552, 0.8680223165473089, 0.9164219722167652, 0.3510562299472545, 0.32098385918251815, 0.18585727641505034, 0.29381534906346785, 0.36515143122683047, 0.4775778121610389, 0.22327689990781452, 0.2034963375431632, 0.26166889239387836, 0.7931445245077403, 0.8188413509195184, 0.7921250156021761, 0.7697014132910149, 0.7694979704490066, 0.8025837099564926, 0.8369543936788689, 0.8084239956827368, 0.7732713214705933, 0.16619133075387404, 0.145459684498085, 0.14880189786174502, 0.1704636773977416, 0.14817163621188356, 0.15466198593489644, 0.18688216781726041, 0.12902248680768358, 0.15262418022950575, 0.16091302578105937, 0.1584020533611178, 0.17848825096878895, 0.20200602113069965, 0.18036453320843537, 0.21189333167706514, 0.15873707749199273, 0.21069259149027952, 0.1565231433286043, 0.26370608089320335, 0.10546371392773313, 0.32216736165549853, 0.41793674438397577, 0.26856435451494576, 0.17065259708953873, 0.15754162415667727, 0.1448991161466392, 0.21587761878321943, 0.4164715362407493, 0.35161369100809137, 0.4214511880997457, 0.43198494631421624, 0.25324926426517735, 0.5924743447876981, 0.5853402909429775, 0.5998177458131935, 0.6371758215970875, 0.11461897532434417, 0.15045530808902463, 0.08046335290564255, 0.1554381476486031, 0.20856483850263952, 0.13830199505220353, 0.15877085524739765, 0.14122464219442876, 0.15485667381704227, 0.117351871547406, 0.17472870951623987, 0.2078558569233968, 0.0905471339237296, 0.23523381851415215, 0.3179605146490594, 0.14716164373783502, 0.13427614275635746, 0.10735661440508881, 0.6497923030882737, 0.7212909435180559, 0.6896866433437774, 0.5744371702701321, 0.5911383496094675, 0.6458264069604449, 0.7504832173585617, 0.565402463728566, 0.5371232001554537, 0.1384244524950451, 0.11320459480289558, 0.13626659034354294, 0.16218020755610485, 0.1355916895820679, 0.12773067554912254, 0.13001657467165517, 0.12498713699718011, 0.13077262089341257, 0.28146345809513973, 0.13998902223400933, 0.1569249590665791, 0.17751823840503855, 0.14879582590561635, 0.3676891393551518, 0.19846473645312113, 0.1806151484335412, 0.39744521185310544, 0.43320282303832713, 0.41020343948226434, 0.3734208414269242, 0.5129435614011872, 0.4869845982690032, 0.4595350986945418, 0.36849309733866786, 0.38490551707302834, 0.32047641081761236, 0.3327655012289491, 0.326843401278034, 0.33589912029741575, 0.38665192299063056, 0.337792885157952, 0.3134745708785487, 0.3174814171494863, 0.5093448809376449, 0.2758006009866403, 0.16698055633012554, 0.18427513056361633, 0.1478069921147842, 0.20860150180127401, 0.21602109767645294, 0.22003395294207384, 0.21534075199939917, 0.22075461013139408, 0.19727862857861445, 0.24724304609749115, 0.24822963213187088, 0.20133418792412006, 0.21817048045182186, 0.3664554306565131, 0.3023917887886852, 0.22103803828132895, 0.2182402308366891, 0.19416219278238034, 0.15304993357721774, 0.1842501937983061, 0.26515170631136387, 0.19656815612960132, 0.19634045993150495, 0.59729966574676, 0.1404362599191631, 0.16126102590528157, 0.16296471404959734, 0.2726748461737847, 0.1373627594309499, 0.08626261883997699, 0.15448932784158698, 0.15689972920486672, 0.1042344528400646, 0.2069073880948139, 0.16343608221873962, 0.2443684241409103, 0.17670151872909667, 0.18836764492639846, 0.17801790005004547, 0.17925716841421524, 0.17398105051508794, 0.18805756281387487, 0.1874973346457507, 0.18885935508523066, 0.1920368967804661, 0.09672425125222439, 0.10756390287367779, 0.13154589489785262, 0.09190333016994812, 0.0912514368102405, 0.08481614231222534, 0.08593636633985857, 0.09602710276879534, 0.08501309325585449]}, "mutation_prompt": null}
{"id": "d759042c-aaef-4489-9376-1d8e27559c2b", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "c379342e-fc05-4b83-9d33-242b465b5d76", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "d4ad4ec6-e67a-402b-8098-21ba08913b02", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "dd86b072-471b-435e-aa71-4cda5175be21", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "31485aef-e422-466b-8780-7b65451785a4", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "80d2da1c-39e0-4e3d-92c5-413171002e71", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.scaling_factor = 0.5  # Initial scaling factor\n        self.crossover_rate = 0.9\n        self.scaling_decay_rate = 0.98  # Scaling factor decay over iterations\n        self.reinit_threshold = 0.1  # Modified re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + self.scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n\n            self.scaling_factor *= self.scaling_decay_rate  # Apply decay to scaling factor\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.2), replace=False)\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with dynamic scaling factor adjustment and diversity-driven reinitialization for robust search efficiency.", "configspace": "", "generation": 59, "fitness": 0.3036120738565091, "feedback": "The algorithm EnhancedDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.22.", "error": "", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.7147716439478082, 0.6975143459767812, 0.6624326559558535, 0.7094489014532415, 0.6163582900406026, 0.8122815647865411, 0.7302840224934342, 0.7786426426295409, 0.8123791426143382, 0.23026313836239665, 0.45262764229308206, 0.5394363076962487, 0.41344776897827173, 0.39304407950809583, 0.340674350959709, 0.30854692153915997, 0.29282922736034456, 0.5243332962499201, 0.3142750098787872, 0.3341549164895665, 0.3012890258938775, 0.4027169565843095, 0.15914909682288603, 0.290682283679947, 0.1612965025476738, 0.21874883731751804, 0.17022983585708806, 0.13982181908055502, 0.21699611469544788, 0.1406228723434353, 0.16079439636769133, 0.13193174595510226, 0.14066656631756758, 0.12234292877871611, 0.13215722985157385, 0.16067732247653044, 0.9558152869078664, 0.9028555322747662, 0.9154245611232551, 0.9327641861321401, 0.9317475906156393, 0.9146710689543117, 0.921874244277442, 0.9463714177152792, 0.9182019296813888, 0.2158595663066467, 0.23232978418392702, 0.1776454215517007, 0.2538118950056977, 0.26526819886167163, 0.2051124186302692, 0.21567124558524697, 0.16102532570503003, 0.2727037427841006, 0.8291660996062925, 0.40513242880507205, 0.8258310494141796, 0.8359644332334174, 0.274688067856642, 0.34070773676504607, 0.823166416140547, 0.8533497218899765, 0.8569796767638171, 0.20860931346928047, 0.1591160613707241, 0.13753034133565856, 0.12803107099772515, 0.13852889215698283, 0.16979024158324318, 0.1391169720633787, 0.22740127628323004, 0.31613084050994433, 0.13186820843695535, 0.11605662060244704, 0.14590610860852193, 0.20818941093138, 0.176791019953071, 0.32219415259409745, 0.14843094938835455, 0.1280095638526142, 0.14874955745264729, 0.12830649575836794, 0.17961548108258307, 0.09654464290136999, 0.048278890940233965, 0.1104487864912076, 0.0014551329822953818, 0.22902439586646228, 0.03732437317978621, 0.17003184374605584, 0.20609128460920545, 0.20613161269183322, 0.11632799471422672, 0.07439636664301941, 0.14382905526087375, 0.09482939802348322, 0.25293707365925944, 0.2781491041762205, 0.2495901994607358, 0.078997783388568, 0.10341647173933832, 0.100636281951897, 0.15773598179910275, 0.14481811419825663, 0.21762921102336363, 0.19026307893434147, 0.16346541715316876, 0.26958718571086193, 0.14531570910698943, 0.1384316350506184, 0.24739314861251227, 0.2492350520022264, 0.14464103284577212, 0.22734408287153818, 0.2341853232668517, 0.2367434907700825, 0.1903679667143915, 0.5121831238166612, 0.48779375761498434, 0.5808996998834013, 0.5091049185515302, 0.512290827506728, 0.4918980305939339, 0.5098834865956468, 0.4604147758210012, 0.557272091137918, 0.12920738147857702, 0.13821167096100195, 0.11079949149908519, 0.13249335536528595, 0.15441214235091028, 0.14238026457486708, 0.1212593501224204, 0.17211240392187088, 0.13510310464966058, 0.21062777904118335, 0.21999430863254055, 0.2517178827400064, 0.230868145287202, 0.22875850489283678, 0.17610731671591506, 0.2262943834000518, 0.29179471364095066, 0.23650829164874354, 0.3881848378211301, 0.35556612360140616, 0.35777467999076984, 0.33452327409977756, 0.39130001450918583, 0.3350247615053711, 0.42000986596221346, 0.38377271919716904, 0.361951514363409, 0.22842834034641657, 0.29576073118971935, 0.3279466979734691, 0.37031454919057394, 0.31898103627213703, 0.27711032733766916, 0.2558774848686304, 0.31380201156317944, 0.338425857462892, 0.24213432822228365, 0.22790031013051326, 0.20922968830489985, 0.2558580714625929, 0.21278670797394328, 0.22033948790902835, 0.21181604253058617, 0.21009213306094565, 0.2301887785743698, 0.1972343071314906, 0.2122683357215569, 0.3918439234198251, 0.20899651733694014, 0.23311163805860713, 0.33119140500088695, 0.1985357849715489, 0.22741149768476876, 0.2034285385532777, 0.18984315373535943, 0.6659235426298322, 0.1664332759876821, 0.19198665973500517, 0.1799421516352162, 0.36715539521768803, 0.18375429757458095, 0.5795599051742568, 0.2584349737438222, 0.4955710680819758, 0.20848941839319246, 0.34616789871559184, 0.25829612894577936, 0.205366256147554, 0.5486422175533641, 0.3693829220044631, 0.3429009806886336, 0.2086192484043785, 0.18120108434189908, 0.1771234346951509, 0.17910612030833395, 0.1748626103709222, 0.18840391487695685, 0.1826747912186395, 0.18775776580702963, 0.18528221437057246, 0.17160439314327414, 0.08983005367446972, 0.09969346835999149, 0.08962987459772953, 0.09136138713566921, 0.09292823414445905, 0.1017414473422037, 0.09310841864818409, 0.0930053975252868, 0.09893217085635209]}, "mutation_prompt": null}
{"id": "b90d10e3-a8cf-4065-b1fd-81323fa16787", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "d1cf5644-bf11-4915-9bd8-748573bbeaa5", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "1dcdcbab-5f62-4cb3-8652-9bb4ebf42627", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "0b518f45-0af4-4dd4-bf8d-f3285f22298b", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6\n        self.crossover_rate = 0.9\n        self.scaling_increase_step = 0.05\n        self.reinit_threshold = 0.05\n        self.mutation_factor_range = [0.5, 1.0]  # New mutation factor range\n        self.population_resize_step = 0.1  # Population resizing step\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                current_mutation_factor = np.random.uniform(*self.mutation_factor_range)  # Adaptive mutation control\n                mutant_vector = x0 + current_mutation_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n            if num_evaluations < self.budget and np.random.rand() < 0.1:  # Dynamic population resizing\n                resize_factor = 1 + np.random.uniform(-self.population_resize_step, self.population_resize_step)\n                new_population_size = int(max(4, self.population_size * resize_factor))\n                new_population_size = min(new_population_size, self.budget - num_evaluations)\n                self.population_size = new_population_size\n                population = np.resize(population, (self.population_size, self.dim))\n                fitness = np.resize(fitness, self.population_size)\n        \n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Introducing adaptive mutation control and dynamic population resizing for enhanced versatility and optimization efficiency.", "configspace": "", "generation": 63, "fitness": 0.3229750259687835, "feedback": "The algorithm EnhancedDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.23.", "error": "", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.6916341299434032, 0.6712936016117078, 0.7381701547305648, 0.6995909474650428, 0.730530280536019, 0.7488109044674167, 0.6798631522315421, 0.6962293354188156, 0.7523287887813742, 0.4828416435088214, 0.4828384848213886, 0.5510129998994036, 0.49626626513494465, 0.515652072927079, 0.565219065345336, 0.49575291942865174, 0.5093065217514416, 0.5607495825355692, 0.09507791700208068, 0.092146156763251, 0.1086432392170833, 0.10144765982051862, 0.10511546555454132, 0.1127441441553314, 0.10132979710035084, 0.09578216805201523, 0.09844682478575328, 0.09255384477296957, 0.08573927783741564, 0.09432175884236749, 0.09630846340635146, 0.09136637514697032, 0.0891945670900548, 0.08785512661090344, 0.08654763449472502, 0.08522193732716676, 0.9590257700349852, 0.9802670629511466, 0.9573669264382167, 0.9738031055149233, 0.9708591261207026, 0.964115384625647, 0.9317963855273048, 0.9425227290636513, 0.9469349269437718, 0.3593622941396011, 0.3850298738957908, 0.4356445881347353, 0.33455608991744756, 0.3340885481805774, 0.41640461065246703, 0.34903084968867837, 0.3779833513781703, 0.41655849870927797, 0.6130043664653687, 0.6168380267239135, 0.6616596575427198, 0.6401231392514991, 0.6178566485026045, 0.698055353971391, 0.66939964739112, 0.6143135523759988, 0.674116527991947, 0.2365779650062837, 0.2136806978665331, 0.298182367842343, 0.24060819838590342, 0.2514298010922885, 0.27520963961069544, 0.23401066393093362, 0.29126165972761386, 0.38265632443297426, 0.17182118855222184, 0.2620931529247821, 0.44037955943182094, 0.21359310562159184, 0.3224356480139917, 0.32445347426332527, 0.29599116385148305, 0.21636746494942272, 0.3608737209618028, 0.18593515996857624, 0.14032787309256223, 0.30233881656169226, 0.2382694893213526, 0.22071400258435503, 0.2859408327273856, 0.1937274133708896, 0.23497965405163113, 0.2935907680229838, 0.3704415497234097, 0.3575886951941206, 0.4662767962759814, 0.30751589921001443, 0.29543316221704585, 0.4642582460144318, 0.36276524582304126, 0.3411436844498106, 0.47780453185219796, 0.07384974854308168, 0.06403108657353473, 0.05449516491308426, 0.12282980854915315, 0.10789868528237967, 0.1445180243530616, 0.11211611190599069, 0.049393504083811046, 0.10708720787100068, 0.20403564567873256, 0.20207566419825396, 0.2605512191231478, 0.21896262703330016, 0.22006184505470117, 0.2700805502780612, 0.20683986780878094, 0.21509274861037075, 0.27079018471056626, 0.5430366114893492, 0.5629398482920244, 0.6494558614603274, 0.5449799620608834, 0.5731324357915666, 0.6464736649374956, 0.5384860463151342, 0.5291834981982598, 0.6396291804755141, 0.09494271549853706, 0.11857030286412695, 0.1203210202213768, 0.0902491385170211, 0.08851075389799046, 0.09863695199092049, 0.09011410362657701, 0.08440173722527056, 0.08147094829488966, 0.15713870764282512, 0.16507330373388174, 0.2571703073753261, 0.2705181914956495, 0.21468783155769633, 0.14779489423417802, 0.1746241776546409, 0.19304097983925694, 0.18142522335044264, 0.28393718832371173, 0.31845451295631577, 0.3368765516317157, 0.2896937097355735, 0.3260173794932283, 0.34924033923760633, 0.3209710174837175, 0.3363825796112776, 0.36767114012417246, 0.2320741054829326, 0.23845042959457086, 0.24232161643403205, 0.2203364718328361, 0.24405683385007315, 0.26332669368907413, 0.2570779095546625, 0.24090848178413793, 0.30271571459664803, 0.19218655405967489, 0.18862173309786512, 0.19475168646690377, 0.20648588890990238, 0.19690353862973764, 0.18846523224239242, 0.18238996323477097, 0.19173008185063778, 0.19296386022075362, 0.20571953385879937, 0.19261980860704297, 0.1929650491423751, 0.18254285768025114, 0.19587707550683076, 0.1845533665829986, 0.1691499261348106, 0.18768020022561982, 0.17853100677008116, 0.6192955579114718, 0.6500521362354293, 0.6690367879002421, 0.6079449062241952, 0.6184846910630822, 0.17057328203713873, 0.6150291636103116, 0.23483694251205411, 0.5946486357032956, 0.20093289422135663, 0.20061959106687544, 0.20003451634975922, 0.5056900807638659, 0.19230428444240322, 0.19398392393511843, 0.2002707849976758, 0.20547380642055646, 0.20813271466215333, 0.19216228047399841, 0.18553225026835496, 0.18575262410527327, 0.17408555787354674, 0.17331475815574904, 0.1841577841658476, 0.18298271464267846, 0.21768437224264825, 0.173026921019499, 0.07486353930407752, 0.06959779166691171, 0.06618156457114677, 0.07115508172408114, 0.07464502677823348, 0.06597027639507391, 0.08369987658908595, 0.06738996362369598, 0.07836252677091249]}, "mutation_prompt": null}
{"id": "8f2b3b53-e97e-4fad-ac03-d3f05883c1b0", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "bf3c4daa-c942-4929-b9d7-1df7df2e24c2", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6\n        self.crossover_rate = 0.9\n        self.scaling_increase_step = 0.05\n        self.reinit_threshold = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.2 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.20), replace=False)\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with dynamic adaptive scaling and elite preservation strategy for robust exploration-exploitation balance.", "configspace": "", "generation": 65, "fitness": 0.36326577398829374, "feedback": "The algorithm EnhancedDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.25.", "error": "", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8219834178505214, 0.8143123971727357, 0.8341418626413533, 0.8124650289454731, 0.7994258502495297, 0.8239185993109155, 0.7980273268947182, 0.7985910977564232, 0.8175958143953048, 0.6984032622635501, 0.6944283136134615, 0.6801925918990464, 0.6652411335959243, 0.6827701156268158, 0.5792276344812619, 0.6674726620549029, 0.7083758546633916, 0.6969440933216817, 0.42671042853368557, 0.1389563219349511, 0.15220522904449574, 0.4342427979666309, 0.31719709256226214, 0.16190783506109763, 0.49661733847109124, 0.17726087971451887, 0.17100691893800868, 0.14105882358272792, 0.1435454085526633, 0.11541868050516135, 0.1427614210718986, 0.4067973977932774, 0.16362638627739234, 0.15997228328803337, 0.14240342880930934, 0.1352136953637293, 0.9679317138184269, 0.9622038428109962, 0.9588201259093502, 0.9356602207554491, 0.9620398901236473, 0.9321333244449859, 0.954134450298256, 0.9620564773429305, 0.9350316481176004, 0.41350334669793265, 0.4324846577276579, 0.4277314948869212, 0.41334121286782743, 0.4478273740140535, 0.471327219856306, 0.43526954921611727, 0.40490339480976034, 0.3794743340557266, 0.30745045122662984, 0.3696987898448245, 0.24548322564871117, 0.878769605224061, 0.22732545684981653, 0.8061138228389371, 0.7729638576782839, 0.22841109703211726, 0.8262780357453356, 0.1894365328072053, 0.19477639748172082, 0.2914126066848123, 0.1494900239386292, 0.29033621165922385, 0.18718287873149653, 0.20805626635712882, 0.17480998349738308, 0.2125598676317938, 0.25480700292010183, 0.21475395072556935, 0.22675513632396893, 0.17196549200933675, 0.3715686392151013, 0.26150838200075244, 0.16150971649846435, 0.22374690478499637, 0.20767382565057002, 0.09471975741731564, 0.1380589871836282, 0.23127053597197023, 0.09073068081435087, 0.30838443863423437, 0.1891224605475701, 0.006974676884021758, 0.3744975872690972, 0.21353891553861826, 0.1329886022081389, 0.15638795738982314, 0.18755036331524566, 0.12615294440435787, 0.03844558689127631, 0.19052008524477626, 0.22959925959739425, 0.23222586533245482, 0.3717063817973091, 0.04260902977212189, 0.23933161676996995, 0.03928617512722943, 0.12785580775218863, 0.1126849089096229, 0.07957176362283336, 0.31903615056384893, 0.13138082233637838, 0.0833863098364429, 0.33709250954402337, 0.26868955778938186, 0.25544014868941123, 0.24252581326749179, 0.2844258966023653, 0.4871918781228446, 0.23462759720064597, 0.16334964389275297, 0.19651340948661677, 0.5405617716851603, 0.6868781106381248, 0.6729329732627287, 0.6538437178982428, 0.547780150029219, 0.591277893193183, 0.5513064818157243, 0.5248725810448431, 0.6749716765622429, 0.14221966652880624, 0.15855708956150505, 0.14480951322943003, 0.14591945592011835, 0.1274323783346517, 0.1458107980381168, 0.13341884117328995, 0.13349943400666175, 0.14277052637591492, 0.21312528901889438, 0.1999518050467879, 0.1908459837000498, 0.2961637317076755, 0.20144632258221595, 0.17636884200881908, 0.2457041621660334, 0.23240972846270047, 0.23678140067332976, 0.42909467065386175, 0.5620004357610601, 0.452132228683357, 0.48944112234626524, 0.4912644890321154, 0.5417693307293081, 0.4210948234192329, 0.5435053087561239, 0.4263642452370878, 0.3198366256412347, 0.283380929401544, 0.2847612695997602, 0.27444266420701846, 0.26791988381024323, 0.33650140014840335, 0.21696882227021463, 0.4006763358991666, 0.4330126411346158, 0.1946582545294998, 0.2032462704343283, 0.20716152484540062, 0.21766996693514618, 0.2315371491148447, 0.1951420808133113, 0.21133394684577023, 0.19695067119256604, 0.20345491516915493, 0.20829660156854757, 0.21397054710010832, 0.6190148691380304, 0.19406878593511567, 0.21751717415697458, 0.5712132123284938, 0.5637318230837722, 0.45453518244339186, 0.6020368280647417, 0.6934433908569615, 0.8500887886868861, 0.18243614960066257, 0.8740549998149438, 0.1938433480337035, 0.17742765418084094, 0.18588622287563816, 0.8307180433234199, 0.8449025191101253, 0.5264680748644419, 0.2053570882645872, 0.7248879310512435, 0.7289026278811033, 0.6635193224227798, 0.4949595761373182, 0.1644113328865584, 0.6277423930261489, 0.20475638414038944, 0.19446390741975828, 0.20033159511627463, 0.20354965490571553, 0.1768442225747564, 0.19260396778846312, 0.18193130965129944, 0.18203723989134968, 0.18342495377544732, 0.18263892482350497, 0.09533814502861537, 0.0877751055158793, 0.08538986804236337, 0.09090660611667478, 0.07943828341449721, 0.08321215022772799, 0.08128856000155882, 0.08697464949610423, 0.08307284673280158]}, "mutation_prompt": null}
{"id": "0800898a-ff28-4e66-bbb8-eb7b168c9136", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # Increased population size\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5  # Balance between exploration and exploitation\n        self.crossover_rate = 0.85  # Adjusted crossover rate\n        self.scaling_increase_step = 0.04  # Fine-tuned scaling adjustment\n        self.reinit_threshold = 0.1  # Increased re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.1, scaling_factor - self.scaling_increase_step)  # More aggressive scaling decrease\n\n            if num_evaluations < self.budget and np.random.rand() < 0.25:\n                candidate = elite_individual + 0.05 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))  # Adjusted candidate calculation\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.2), replace=False)  # More frequent diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with Dynamic Encoding and Gradient-based Local Search for Enhanced Convergence.", "configspace": "", "generation": 66, "fitness": 0.31800694198032486, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.24.", "error": "", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8253100826086066, 0.7927881640153953, 0.7908555043671552, 0.7509177644301263, 0.7764182950998391, 0.8010721574278921, 0.7906236980319334, 0.7780981687548252, 0.803247321253712, 0.5931792626453115, 0.6031700621219058, 0.5446494775294426, 0.5786008927810193, 0.6590604563827749, 0.6027993598348771, 0.5911349940973272, 0.617586468307958, 0.6751958861697109, 0.5180587839448074, 0.17653640965867712, 0.2509735387282308, 0.5046103715955446, 0.16763835663614624, 0.4482151796474212, 0.15203958739396095, 0.22935536918661859, 0.3685509201031638, 0.14687490587715024, 0.17230644015173968, 0.1418773187675697, 0.14481955238841915, 0.1460537660353871, 0.2803096527041061, 0.16717925215297091, 0.17010483856679826, 0.1567068089262721, 0.9154344556538657, 0.9501881517218742, 0.9197054546360823, 0.9180219274249304, 0.9387083046356142, 0.9029723554785238, 0.9461913321233247, 0.9671412131207201, 0.9316936535776712, 0.3599985701786209, 0.36644975212571784, 0.2843051060967867, 0.35887928271701464, 0.3670796825798591, 0.2682362110069506, 0.19043587169905218, 0.3390328967138979, 0.23533427115648997, 0.3566013663248103, 0.7922844936318516, 0.7304979099367199, 0.3707526712163879, 0.3388760946277257, 0.8097396265017921, 0.3289697475542134, 0.3634801950822435, 0.7066762232831703, 0.14761106754708941, 0.16075079600202768, 0.1794119392009621, 0.16614151522480913, 0.14416590158624398, 0.16285507204183536, 0.1705663107208033, 0.14428214947147333, 0.1853886915732833, 0.16157523838798293, 0.3556059233346136, 0.17304542562401326, 0.13980266691661614, 0.1254617115809188, 0.24034873792901112, 0.18750573086901778, 0.15444245874446205, 0.1250759514835994, 0.07445940061670231, 0.05887072000445692, 0.13217440743802578, 0.04665975048102011, 0.0029944846454525997, 0.1304192139079332, 0.00048486319622409457, 0.1286148488799549, 0.04234167352909968, 0.11058113949657922, 0.08364738190090615, 0.10924562238937574, 0.1276953390286797, 0.17805744395839918, 0.0760069662673113, 0.1810974546661922, 0.19589953611933908, 0.08124407959588786, 0.035369689544629046, 0.13254335931920214, 0.21822906493405259, 0.2716541806949575, 0.12428623124712102, 0.09746176514217963, 0.1614452486191229, 0.1583280862720038, 0.12855433140975414, 0.19923343412395234, 0.2896462669987131, 0.22499755380992115, 0.19225827077139057, 0.16082773355277802, 0.14196326792230052, 0.18826720354158188, 0.20140750312526934, 0.14608141672004038, 0.5447175799021062, 0.5429653929049649, 0.5327500190204822, 0.5136543250626884, 0.4990917406131883, 0.5063472352181873, 0.5203200023613533, 0.5189949964091858, 0.4962150023638008, 0.133332964578873, 0.13048530344689047, 0.13997955820168118, 0.1300429724512856, 0.12460267816154569, 0.11781379897914335, 0.10969468493393508, 0.15084010109692225, 0.1450802084866486, 0.20043131346424548, 0.24331815012501679, 0.19211076242088743, 0.2320914544131153, 0.21976026284508676, 0.2771437614869432, 0.183747905035749, 0.18083141965728966, 0.22659937395027896, 0.35325142216067595, 0.36998348643998247, 0.3440162828107117, 0.35496218560137727, 0.42827736247564707, 0.3685819393839914, 0.32705813039110665, 0.3024149029288721, 0.3475827418454128, 0.2641957900956461, 0.32057807539353056, 0.24730125368277878, 0.3212347148937533, 0.21371784494055612, 0.2690453869888696, 0.263369652350223, 0.2535579320627519, 0.21956596811604445, 0.22705285804514652, 0.2052570529466291, 0.21085033606518577, 0.21845265006719816, 0.20893643505374826, 0.21198295189991845, 0.23057890305750461, 0.20799920174123576, 0.22408223325843468, 0.23152358415905827, 0.23708151959839807, 0.20714649030942822, 0.20285671102834202, 0.6350999292870337, 0.21372436973123177, 0.4048768289871968, 0.20123410763950056, 0.20899121541403254, 0.6734517248392995, 0.5332032209243646, 0.18193890165391835, 0.1741347551749255, 0.7925550944466333, 0.842020790671681, 0.7426770349389886, 0.8139518113115093, 0.20553820522254762, 0.2907795995269744, 0.16636191435992587, 0.3660118014874043, 0.2048683449438473, 0.199067195855681, 0.5265599372800752, 0.38069969423612093, 0.20192043511232427, 0.20389005262015436, 0.20029090739392985, 0.17686325206815035, 0.1916677797831674, 0.17601900441547091, 0.20104548195619998, 0.16924555976660904, 0.18018590250329092, 0.18629661896751404, 0.17746630909087457, 0.11409144339446553, 0.09067002576716843, 0.0824384643168643, 0.0849121374328754, 0.09209429216897147, 0.10188949664759805, 0.09006329693395021, 0.08865006140487053, 0.08490138944918602]}, "mutation_prompt": null}
{"id": "2697eeca-029b-454d-bc38-d642c7e737e6", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "13354821-1169-4120-bc05-d7f55b00d8aa", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "35336625-077f-4b6d-8232-1f67d8eb60f2", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "1c640325-4fcf-4ee2-a62b-625f64413cab", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "68e5f6fe-0812-4775-a195-aabf0591392f", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4 * dim, 20)  # Dynamic population size adjustment\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6\n        self.crossover_rate = 0.9\n        self.scaling_increase_step = 0.05\n        self.reinit_threshold = 0.07  # Adjusted re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget:\n                candidate = elite_individual + 0.15 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Improved Enhanced Differential Evolution with dynamic population adjustment and stochastic perturbation for better exploration and exploitation balance.", "configspace": "", "generation": 71, "fitness": 0.30937199100667917, "feedback": "The algorithm EnhancedDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.25.", "error": "", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.7805680992417109, 0.8895515008273819, 0.8729661257789532, 0.8760510953149754, 0.8185627246216471, 0.894333079093032, 0.8363984934459828, 0.8369427551877131, 0.7610960719132666, 0.7338071419527159, 0.7445871826926173, 0.7515244332978337, 0.8076479242900041, 0.7956221323528588, 0.6397627989904784, 0.7093101957415098, 0.47409215759632206, 0.5721891285124087, 0.15353460094744276, 0.5091916205281322, 0.12893209251195725, 0.7152762398738257, 0.12299589584325055, 0.1578263898245521, 0.14050294704229604, 0.13187425996208024, 0.1553123574425901, 0.13048175368167358, 0.17811532094208704, 0.15687332655261466, 0.1663026660057496, 0.12207058946622673, 0.15753444014059237, 0.1516981879142233, 0.14597475111187852, 0.13085236750055051, 0.9801815208863587, 0.9755393840669871, 0.9762266279327695, 0.970713363221336, 0.9715513897667888, 0.9694138239975271, 0.9795935012392951, 0.9798562741182227, 0.9644043607853733, 0.42881919207468355, 0.38882396503118943, 0.16370921525531068, 0.44467534285770227, 0.24932277172889927, 0.6708641010956384, 0.37087033463380625, 0.30909861907094804, 0.42689937885911144, 0.21767608193785004, 0.2256615912692197, 0.2276017640880772, 0.21279867865133884, 0.27353647230551437, 0.2806395296863343, 0.23256573760288113, 0.17814990953081378, 0.23506427903652793, 0.15877737508058454, 0.1999120872875929, 0.1900572431164237, 0.13296043032555394, 0.3824928798439826, 0.2170483670094362, 0.1343563043461783, 0.27844337220632054, 0.23362335859804872, 0.23290612148319545, 0.1934515311023972, 0.3234610115450559, 0.4423204897334887, 0.26201603764835, 0.17523390595884625, 0.22437184640211705, 0.26715787362767063, 0.2207174854741415, 0.11101473924263972, 9.999999999998899e-05, 0.09349800055516133, 0.05461537470052702, 0.02435786202343948, 0.006219673383572655, 0.10376183341508627, 0.08693873003404695, 0.12735655590772899, 0.13218516584102402, 0.10104819119220443, 0.12172509697132428, 0.05284220385951299, 0.11696785605383009, 0.036099489337339086, 0.11592520602200873, 0.19176758115615178, 0.2154194727599571, 0.26300392665910144, 0.13188134149379982, 0.05216757715198761, 0.07825235263700703, 0.17439840006188367, 0.11351305752372032, 0.08840890696964876, 0.29326688145705726, 0.15639631930534925, 0.23269522037841084, 0.11851648213241284, 0.13869674165274481, 0.30574063868446255, 0.2716008940593756, 0.3007800092991283, 0.13441546709472152, 0.1757214510021955, 0.12485028563022826, 0.5839942627719819, 0.5060155789621865, 0.4907491799373179, 0.49288693211030443, 0.5547101031505208, 0.46902133019604186, 0.49958903651284614, 0.6058737246382315, 0.577726629240708, 0.18041228234266105, 0.15709321927131492, 0.16113443940716554, 0.1382054448401583, 0.12230521004878758, 0.1401413990550835, 0.10721851205530897, 0.08467289726407001, 0.13996863471528553, 0.411973545573427, 0.18550513146748893, 0.2315039730324533, 0.3162616621307408, 0.2799347082335709, 0.19514077400192142, 0.21256744659699867, 0.17889262880447154, 0.2192152764408204, 0.31316012939856097, 0.29898141592208605, 0.3229321443322615, 0.30891618643921204, 0.4254598065982992, 0.275285767418473, 0.35195622755226963, 0.293181871687347, 0.26737064602539196, 0.29074594354547256, 0.29257044038607494, 0.18968724238858947, 0.30473751837217267, 0.3562666119981728, 0.25485421263058416, 0.1725379005684874, 0.23584944025815258, 0.24877220675335499, 0.20305156583345352, 0.20110571820000445, 0.2426995709926829, 0.25365902277344976, 0.20368646002254132, 0.21288582015156676, 0.2208741660663167, 0.2647809993457013, 0.21431350228377832, 0.25173064352805863, 0.18854660587437977, 0.2032899748304302, 0.7678837197522692, 0.21922408786536884, 0.1842907229839399, 0.19829386151085582, 0.1842709062663601, 0.2242663465177508, 0.16958516296951764, 0.7765728788049202, 0.1646618959902435, 0.17717820264743367, 0.48065177294848294, 0.773068543624811, 0.147398850123589, 0.1855862139665596, 0.1606386944693169, 0.2026098878955056, 0.16933929911803425, 0.5119166313620931, 0.16771312685194684, 0.16420317038829435, 0.7513866899446066, 0.16663186143864261, 0.20470629264314588, 0.15556948557544115, 0.19928663916445133, 0.18627198943003342, 0.1826451517423252, 0.18939309837296936, 0.2011020652346288, 0.20822922589731319, 0.17948077609422586, 0.1755397131430202, 0.21451190431728495, 0.09284799089431839, 0.10488362132152051, 0.09763322364442739, 0.10988071881040973, 0.1192168895397725, 0.09239354437292113, 0.10943462606597476, 0.08811173139811945, 0.08915835204883171]}, "mutation_prompt": null}
{"id": "94f566de-3e36-4e68-a6c4-4da4104cb8d7", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "5d04079f-4f40-4eac-8d6b-b827b333f745", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "8a8a187e-4afe-4307-8ff1-980ed95b26c0", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "0b20ca9d-45a9-4241-87c2-e775f7f476a3", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.7  # Adjusted initial scaling factor\n        self.crossover_rate = 0.85  # Adjusted crossover rate\n        self.scaling_increase_step = 0.03  # Slightly reduced increment\n        self.reinit_threshold = 0.1  # Slightly increased re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.3, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.35:\n                candidate = elite_individual + 0.15 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.1), replace=False)\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with dynamic control parameters, elite learning, and enhanced mutation strategies for robust performance.", "configspace": "", "generation": 75, "fitness": 0.3499471960630071, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.25.", "error": "", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.7893852569854533, 0.7789502698291566, 0.8037138853439327, 0.8287726834372693, 0.8002224978144215, 0.8119916123884536, 0.8017178549009445, 0.803776423365725, 0.7933166543003396, 0.6991090605481982, 0.6793063462342421, 0.6196320802413895, 0.6392252944682012, 0.6862634285711642, 0.6750029131951218, 0.6676565670130066, 0.6273937201339171, 0.6806201893273636, 0.31328427629111844, 0.22345261571673924, 0.2522725803800918, 0.12859737828578832, 0.15990318954377158, 0.13006629976262318, 0.16156113391622762, 0.34012644197706754, 0.25978187095909333, 0.12688039647828242, 0.1390205995969045, 0.15017424586623962, 0.13488042272480238, 0.14036634742792609, 0.13545685261300733, 0.14796232269652787, 0.1511022698376231, 0.14023555907458252, 0.9604185000013564, 0.9549992665254085, 0.9601084187094859, 0.9553404446877598, 0.9385580761672951, 0.9391994639274881, 0.9506246265506537, 0.9558481772598048, 0.9612890770037291, 0.35533206751345536, 0.3670139035587897, 0.42230285754990504, 0.31794847697551765, 0.33195245884800306, 0.3494538020854657, 0.28848530157445973, 0.37712008721011303, 0.3496205710849789, 0.8045007260042265, 0.8109406105957088, 0.7726288582984289, 0.8501669453104752, 0.7878360637107363, 0.7207613323831357, 0.8081816735023915, 0.2249886698248813, 0.2319785197891241, 0.19265761897587763, 0.18576188658697812, 0.2297384361193514, 0.16616289148362562, 0.16120589585259004, 0.162455189032508, 0.2115384828463125, 0.16469153074780063, 0.3026675989131071, 0.16513005975368777, 0.13639735096916283, 0.20029691001189787, 0.20777595504137725, 0.1747192539371566, 0.1649067000090414, 0.14491392317205298, 0.161230415558684, 0.16601187888111346, 0.004288963321628425, 0.35120841032941996, 0.12534218165265543, 0.12449159452936132, 0.2677765063549745, 0.0730528199154653, 0.072809922250053, 0.341266407870906, 0.18444018141207552, 0.15062621011578226, 0.11286803715293392, 0.23675505465173396, 0.1690238036859728, 0.1982889562435075, 0.3484066710983752, 0.35691470241661705, 0.3855334153380574, 0.2604691717431066, 0.13393320885395166, 0.15033580115264833, 0.07751555311037084, 0.15180546255295446, 0.15864820090716603, 0.10266936014959205, 0.11988729272143939, 0.18523146775831, 0.09280572225036376, 0.18211404927985464, 0.24155229324374772, 0.2174656255813454, 0.29484592419309896, 0.27316438397464515, 0.3368074094947685, 0.2937352454211849, 0.31456049428379396, 0.10362778375537052, 0.5733121052745238, 0.6706708537952857, 0.5760490997428087, 0.5658291563212812, 0.6656421358596672, 0.6180332931521736, 0.6504912177529789, 0.7157260385051081, 0.6353538916378305, 0.11242508223305392, 0.12310067068963926, 0.11439057566549382, 0.11024877518306475, 0.2912114890843919, 0.1145645482119797, 0.11242945991020492, 0.09836885807064077, 0.12597799657640385, 0.16075440062346658, 0.1563900526125186, 0.1683873441543623, 0.1480034099543549, 0.17660690016792435, 0.14306577039381996, 0.1376645198584674, 0.24821090778808808, 0.14613721739384167, 0.43372303549428526, 0.5277724601993887, 0.47264334941116126, 0.5072800312495189, 0.45058418119327037, 0.46784275739253334, 0.5926525024874498, 0.5328467152365153, 0.5365010358199371, 0.39938549267829504, 0.3895263750188066, 0.2851265860856541, 0.41178354705739684, 0.1914255425079161, 0.37719908906747646, 0.3768606420585062, 0.4425920841429276, 0.38100148780753673, 0.21222303275375853, 0.21456665521351026, 0.2079929895660343, 0.24165823417692844, 0.18839631209124852, 0.19431737407577743, 0.2001355083205364, 0.21183828167955, 0.2093811679769224, 0.3501138225197743, 0.318497747472134, 0.20037940348440664, 0.34517435029156285, 0.4244830193112936, 0.20804556879330038, 0.5433900197055501, 0.2256153507018256, 0.5338231446847237, 0.713802465608282, 0.16458573540718313, 0.1626292798479515, 0.7655605577590545, 0.18392567133936066, 0.7245134036767114, 0.18173485837534553, 0.7914231714826064, 0.7275350180240527, 0.7026690250138967, 0.2050120473730952, 0.16453301922108077, 0.5328010260187628, 0.19018142604785704, 0.305941120757506, 0.20593145731696372, 0.3865413376177296, 0.20505575753161231, 0.18005150073488208, 0.19088845612937466, 0.19150764316698665, 0.18820250330887411, 0.18803619436212005, 0.19675993548196846, 0.1796880223418158, 0.1791581675782412, 0.20458619003346745, 0.07968011795445651, 0.0872705092541346, 0.0884787037472784, 0.07962011859837981, 0.0777971230957839, 0.09022709359251424, 0.07606999487234334, 0.08646412222682809, 0.08259612181118814]}, "mutation_prompt": null}
{"id": "7ec85a2f-33ab-4f2b-a138-01c58f2807c7", "solution": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.6  # Adjusted initial scaling factor\n        self.crossover_rate = 0.9  # Increased crossover rate\n        self.scaling_increase_step = 0.05  # Reduced increment for finer adjustment\n        self.reinit_threshold = 0.05  # Reduced re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual  # Introduce elite individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                indices = np.random.choice(len(population), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if num_evaluations < self.budget and np.random.rand() < 0.3:\n                candidate = elite_individual + 0.1 * (population[best_idx] - np.random.uniform(self.lower_bound, self.upper_bound, self.dim))\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_fitness = func(candidate)\n                num_evaluations += 1\n                if candidate_fitness < func(elite_individual):\n                    elite_individual = candidate\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.15), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n                    if num_evaluations >= self.budget:\n                        break\n\n        return elite_individual", "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive elite selection and edge population diversification for improved convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8395777311324466, 0.8236525128295802, 0.8341418626413533, 0.82618638527366, 0.783519109296537, 0.8239185993109155, 0.815647319158109, 0.8022162064273952, 0.8175958143953048, 0.7171623518877329, 0.7187900878658393, 0.6819952234197477, 0.6789669901589346, 0.6767091765234738, 0.5909116123992163, 0.6894833039907753, 0.6989815222383766, 0.6969616270920707, 0.4450361985317297, 0.5897960367875967, 0.145954587305122, 0.5502351756006072, 0.4650006858158723, 0.16635647493363726, 0.5822471692558955, 0.5095401661375447, 0.36317404961419, 0.16088579982260742, 0.1429037104385701, 0.11461622890163037, 0.14000229206152381, 0.15790036041708522, 0.16361685023880834, 0.15658932799112257, 0.13877320691901496, 0.13410018636797016, 0.9636484743187119, 0.9622314769526736, 0.9588108415579206, 0.9355848554675045, 0.9618178010137002, 0.9343758049438925, 0.9179347553559846, 0.9296909798421878, 0.9345288334565165, 0.4256453968359558, 0.46013546156930907, 0.4497772713758631, 0.3421780831868748, 0.37404656422722926, 0.4656217675968526, 0.3878642435088362, 0.22853773004031663, 0.4031838244149841, 0.22552301632869076, 0.8484997181004937, 0.24551061025627763, 0.8586123946922226, 0.8279881849027749, 0.8061238830607207, 0.8059512714325692, 0.22846895252202226, 0.8262780357453356, 0.23435158202422945, 0.17263361788790776, 0.32844315617177655, 0.46915595816926203, 0.2361248099137644, 0.18596623831073233, 0.20723102805315952, 0.19769944061386646, 0.21879161052061813, 0.260711717790286, 0.11170759431214994, 0.21749207502728662, 0.18355227384355954, 0.22808626888423178, 0.3210304284968095, 0.20806753808057543, 0.17593134229493013, 0.4175215625604016, 0.08994139038792814, 0.09441255293552042, 0.19424291290563, 0.06266543423410875, 0.20794678987000015, 0.1912690781093649, 0.05632900541769503, 0.35108500610741555, 0.14071070871263713, 0.1475825150184572, 0.1277577995358855, 0.18902820412825316, 0.10236011771587605, 0.19220132367488862, 0.1835740811250809, 0.26616243933452144, 0.3760151811225583, 0.3534690671672057, 0.19935036172909515, 0.21495241244275598, 0.12470381006369113, 0.11705295433957785, 0.13221707373403147, 0.07952418930252603, 0.15961821416503685, 0.13772554800056203, 0.08348283784005417, 0.17550522321122064, 0.3561047030079505, 0.23603752014483736, 0.3146273150046067, 0.2149955277998976, 0.486139531973631, 0.35329710537015013, 0.1549159122834548, 0.1951826728396876, 0.610475346134864, 0.5280495201835089, 0.6238926168386812, 0.5570594480997687, 0.5228524077679576, 0.6127069083570169, 0.574149165683401, 0.5719731507254404, 0.6892120664979932, 0.14520899961515643, 0.5175031294568353, 0.14480950504390044, 0.14119740803951808, 0.13258010810946252, 0.14606383411581814, 0.12021495300102147, 0.11699877801895076, 0.1427708329153482, 0.2202050867544686, 0.20013430515258757, 0.19109997410590673, 0.24338840667426997, 0.1418690230442069, 0.22401906571129926, 0.2729441194996507, 0.2250520017230957, 0.2358771184032009, 0.5006288377650352, 0.5080566388982711, 0.452056389092395, 0.42462025881865173, 0.5980550415684169, 0.5450066856325149, 0.5287607811721973, 0.6520361985376046, 0.5397685527069092, 0.30886788046409264, 0.2673194653537897, 0.285512264832086, 0.2634814172829004, 0.35507038084925213, 0.3361737189357309, 0.2237253503177069, 0.39112591387696016, 0.4257311367876869, 0.20592915877422568, 0.22102786334113678, 0.2191029253375273, 0.21518721377365968, 0.21725745679067276, 0.19654427864378177, 0.21364011757387547, 0.20732803933591182, 0.19344827613692794, 0.20770048941723007, 0.2310490882649453, 0.6239665673069693, 0.21593472465644326, 0.5190112543195278, 0.601420215689643, 0.5889667902072961, 0.21466981297327958, 0.5981264766686802, 0.2355535936847124, 0.7410739738335688, 0.18229093004091457, 0.8798122648749216, 0.19455377088514791, 0.17742765434517838, 0.17039709093091082, 0.8206544701646028, 0.8449541384466597, 0.6458824227800628, 0.20629917389418728, 0.7426315691897829, 0.2006277928250505, 0.4780431250908628, 0.4577696877772006, 0.1647045075588891, 0.727367518415238, 0.20476666130478927, 0.19446390741975828, 0.20644713472893572, 0.20376658867480546, 0.18639778340940094, 0.1790350228579145, 0.1814405567151287, 0.18745619531504365, 0.1770325906215925, 0.1826472581805607, 0.1010157194990774, 0.09205821582597962, 0.09170650015222581, 0.08817286004848213, 0.09311613263505403, 0.08596920293338173, 0.08500152533713468, 0.08808436072857895, 0.08344839868617071]}, "mutation_prompt": null}
{"id": "7b9efda3-d86b-4ec0-902e-979dde7c888c", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5  # Adjusted initial scaling factor\n        self.crossover_rate = 0.85  # Slightly lowered crossover rate\n        self.scaling_increase_step = 0.07  # Adjusted increment for variation\n        self.reinit_threshold = 0.1  # Adjusted re-initialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                tournament_indices = np.random.choice(len(population), 5, replace=False)  # Tournament selection\n                x0, x1, x2 = population[tournament_indices[np.argmin(fitness[tournament_indices[:3]])]], \\\n                             population[tournament_indices[3]], population[tournament_indices[4]]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.2), replace=False)  # Increased diversification\n                for idx in random_indices:\n                    if num_evaluations >= self.budget:\n                        break\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n\n        return elite_individual", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with dynamic scaling and tournament selection for enhanced robustness and exploration.", "configspace": "", "generation": 77, "fitness": 0.464282700194834, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.46 with standard deviation 0.27.", "error": "", "parent_id": "57928093-277f-42f9-9394-64ad7630eb40", "metadata": {"aucs": [0.8408670647795979, 0.8109515256555901, 0.867291738710327, 0.8569636658302596, 0.8465083740497411, 0.8365106805332144, 0.8137959652578275, 0.8626444581371662, 0.8357739339733654, 0.7802221977084337, 0.7016462980470748, 0.7411720467280425, 0.6867905106157829, 0.7757580458008138, 0.722963775947111, 0.7322683915771508, 0.8044779017250188, 0.737692877803495, 0.18964946413016337, 0.6456564279483096, 0.6571656973521827, 0.6016779117405253, 0.1495139558115952, 0.29634011791381987, 0.7303338611704489, 0.7195090169091252, 0.6858086635177383, 0.17633450063132527, 0.12622146430216707, 0.1472808320476684, 0.15379125421328677, 0.169581898031116, 0.13541073347874466, 0.13998172483933524, 0.5813822386927345, 0.15547118754220568, 0.9661752037678772, 0.9678104892576842, 0.9676337463719548, 0.9547357140444891, 0.9663886988091297, 0.9557257535062202, 0.9697507829066039, 0.9628680157161469, 0.970431868437265, 0.6324358279188464, 0.6734499892425196, 0.5796184440554466, 0.6771639614461749, 0.6691969961434233, 0.6758348434771704, 0.6088232907303278, 0.6731071834435163, 0.6491382750659397, 0.886451339755847, 0.8490368442385361, 0.8704745244512886, 0.8862437314597618, 0.8986979345517949, 0.890280013941154, 0.8646987634781461, 0.8703640070834855, 0.8634333553429984, 0.42504942360411924, 0.13198511251767509, 0.3918660660620803, 0.1282835883121346, 0.43663647040165066, 0.49152098962496904, 0.42374911199054655, 0.580785138895058, 0.48231709146532, 0.5248884824288508, 0.5639514448942071, 0.4584983508871663, 0.49533286770848084, 0.3759079090540913, 0.4521387665482347, 0.4756442158843667, 0.5325891282177717, 0.4995166136922262, 0.44554534155852066, 0.6627531723257789, 0.47428371321949536, 0.6893699013257433, 0.652190693381089, 0.5258872284076046, 0.4451306440066475, 0.5655653842786115, 0.5493437237411054, 0.4715771519446489, 0.5456319883696903, 0.5831792253171262, 0.6108671654407789, 0.48365108959528824, 0.41045130940117946, 0.4650560966479207, 0.5616618303103414, 0.7418420171923672, 0.301655236929278, 0.12230722640539282, 0.14823527011739002, 0.33275690187938856, 0.40263211350713146, 0.2966209497567248, 0.24542911131182665, 0.25246443975201494, 0.28433114561914685, 0.5558766739242061, 0.4755223324851954, 0.3695036311642923, 0.47453651841968036, 0.4609535837578287, 0.37468054139805285, 0.4032824134856682, 0.4656987709969729, 0.3536761778390426, 0.7801500095657634, 0.8189778739569843, 0.7353617409366175, 0.7865153625920362, 0.8116311741276576, 0.805041155212687, 0.832797667024182, 0.7565143100918195, 0.67999672647184, 0.13321537752591872, 0.17429071121401463, 0.13571901529245312, 0.11466428853967858, 0.13753046218487885, 0.12210855143965271, 0.1758967490750849, 0.1282077277571272, 0.13741255897273064, 0.17815655030970068, 0.27135313062071487, 0.37674314328717595, 0.25643385954933196, 0.1999882254308626, 0.25891864894800953, 0.284402905227194, 0.19358012962643056, 0.1734928219017282, 0.54909014088354, 0.37438790816530787, 0.6847170693189352, 0.422445311309971, 0.6850083697591505, 0.5327463439884847, 0.6165279162582117, 0.5898532354668665, 0.5436320505238281, 0.36581982312046135, 0.38469952815880426, 0.36269343031999857, 0.5022053826047342, 0.5210756100866343, 0.22823639919654692, 0.38756384147363776, 0.33447764790077605, 0.33916853257885016, 0.2124813749251654, 0.22368250088909492, 0.22652274105849002, 0.1970369622314816, 0.23356027399881385, 0.22317361141962888, 0.23280651686061982, 0.20184948789349555, 0.2642523843161544, 0.21695997863720662, 0.2132300088109661, 0.19997017422911845, 0.2253163735928161, 0.6548631134834586, 0.22358033596975835, 0.19927535390072748, 0.21855680032296332, 0.2038040691196964, 0.16238348532800906, 0.8333287628766073, 0.19711661033005268, 0.17492729857104727, 0.1998580299818402, 0.9205272454321585, 0.17716508567566658, 0.2073080611456073, 0.8233907708316737, 0.9115355927542894, 0.21080973114804336, 0.20516817033623513, 0.7737989373941994, 0.20303240203566864, 0.20919836266785619, 0.20786165677943036, 0.2073565989635101, 0.7274548793272672, 0.19088925221798358, 0.17491359565905817, 0.18475599145166488, 0.17994981444989278, 0.18598540254226759, 0.19339307926379756, 0.17637053275585057, 0.18272725897339737, 0.19261808666239832, 0.09191354092023973, 0.08479160003254615, 0.08528488481046903, 0.09524401723120968, 0.08849627005621385, 0.09909801417029851, 0.09363359860499199, 0.10110628384763354, 0.0871073680000296]}, "mutation_prompt": null}
{"id": "b7ae92dd-3b4b-4dd1-baf9-f38c70937821", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.85\n        self.scaling_increase_step = 0.07\n        self.reinit_threshold = 0.1\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                tournament_indices = np.random.choice(len(population), 5, replace=False)\n                x0, x1, x2 = population[tournament_indices[np.argmin(fitness[tournament_indices[:3]])]], \\\n                             population[tournament_indices[3]], population[tournament_indices[4]]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.1), replace=False)\n                for idx in random_indices:\n                    if num_evaluations >= self.budget:\n                        break\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n            \n            # Introduce local search intensification if stagnation is detected\n            if not np.any(improvement_mask) and num_evaluations < self.budget:\n                local_search_candidates = np.random.choice(len(population), 3, replace=False)\n                for idx in local_search_candidates:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    candidate = population[idx] + perturbation\n                    candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                    candidate_fitness = func(candidate)\n                    num_evaluations += 1\n                    if candidate_fitness < fitness[idx]:\n                        population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n\n        return elite_individual", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with local search intensification and dynamic population resizing for enhanced exploration and convergence.", "configspace": "", "generation": 78, "fitness": 0.469745295177563, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.47 with standard deviation 0.28.", "error": "", "parent_id": "7b9efda3-d86b-4ec0-902e-979dde7c888c", "metadata": {"aucs": [0.8959095845141078, 0.8706728681719863, 0.8634742302495477, 0.8677589685050268, 0.8763100818478078, 0.8176903532523165, 0.8661997985551829, 0.8455657851736222, 0.8340713345991272, 0.7419940977391046, 0.7103304816851959, 0.7318033805014978, 0.7432880064232975, 0.7729209562477807, 0.7583056343080935, 0.7992127706421387, 0.7583820484448669, 0.762789741911219, 0.5980832628744248, 0.24651269334005088, 0.5768304617262617, 0.13798023253748504, 0.1604648873916854, 0.6359418171180917, 0.4529014076284913, 0.1558916844692485, 0.18280728572872984, 0.15041661401218331, 0.13680054151340704, 0.1480972453120356, 0.1608879558121491, 0.12367616100828238, 0.17272203727145874, 0.16627824227621057, 0.15938799263427905, 0.15596526273930178, 0.9463282726616835, 0.9678104892576842, 0.9676337463719548, 0.9753332687780508, 0.9674111947376378, 0.9557257535062202, 0.9585428961902459, 0.9628809468394908, 0.970431868437265, 0.6914307644535669, 0.7117675484507409, 0.5998434278103093, 0.7036859127457056, 0.6812649795696288, 0.6472882207584278, 0.7165757958405723, 0.6834973516821774, 0.7076741969223651, 0.3547876690980055, 0.8930282975734247, 0.8652608698313159, 0.9001061618623605, 0.889326124993228, 0.8681246393591243, 0.8620901807927612, 0.8859580897770105, 0.8786138772501232, 0.4664039135318775, 0.563673782054998, 0.4533236068805725, 0.34756526098319007, 0.13125610199412763, 0.47092310612951815, 0.46186268273734954, 0.6204835246550295, 0.5636558890234213, 0.36633490907134203, 0.12941621016288496, 0.45011069165055306, 0.6332732169955632, 0.492567893440495, 0.4638423877286385, 0.5260742311592603, 0.4853030900729828, 0.5623988118652294, 0.3722394219021051, 0.5221746602220374, 0.2932839522432473, 0.5889609009609156, 0.4245936628621464, 0.5532048381027419, 0.3259182621233241, 0.5764079472096897, 0.45062748175838196, 0.711517148578356, 0.6729396786912615, 0.4961078950747826, 0.5863496866489182, 0.5137171032249905, 0.47534204812455627, 0.7772901187554886, 0.7283880627746829, 0.7160516284390054, 0.24586766790839387, 0.21349330899818275, 0.07123805942264427, 0.43497273393466507, 0.379382192456999, 0.3486357302340424, 0.20457309358624576, 0.2580033648750609, 0.1998934459717101, 0.41156894518877063, 0.3954095499794865, 0.42415377083384476, 0.447280845696168, 0.5641229033867792, 0.5382082917761077, 0.5193334291390775, 0.5040170767916672, 0.5423955683553915, 0.8386884148909358, 0.8079876807256721, 0.7505909105185335, 0.7516226058425888, 0.8025416445582052, 0.820786872184763, 0.8453031430650506, 0.7421109721425602, 0.7884659461834964, 0.15088767159727778, 0.14033161343778722, 0.1558288073048648, 0.1413576171187284, 0.1371666396259561, 0.12196285562941755, 0.11267072870796435, 0.1522425411205688, 0.1385469309723154, 0.2144002325407487, 0.15875718558617713, 0.40670023798166144, 0.3942775332035, 0.24573194487562555, 0.16632900433327158, 0.42917158254674237, 0.32812293272557413, 0.2135443997322405, 0.3271360634059238, 0.6606926256143755, 0.5429129143873321, 0.6200903651143682, 0.5842503559086694, 0.42561348213178185, 0.7423902335689301, 0.7318963166151539, 0.6160800401340978, 0.3639273385301198, 0.34185498728025177, 0.471866298176412, 0.4808835233662333, 0.5709583243000429, 0.24384714871223445, 0.2339088017965647, 0.5389947700427353, 0.2313877565126491, 0.20480295901128742, 0.20402310615699237, 0.251329500281392, 0.21933544915476277, 0.2293174392733769, 0.2186419556343464, 0.22275015543363885, 0.21047605652644474, 0.2418777824439855, 0.779192733383349, 0.7621790642677698, 0.2064743381155364, 0.2476980154346229, 0.21668933879473917, 0.22363697030525298, 0.20445088309591875, 0.22054426844225206, 0.20448734435197113, 0.8855392282007896, 0.20721557538767554, 0.19724204489956498, 0.8557573368055722, 0.19986965537492252, 0.9248942716328965, 0.533007970902579, 0.19409554473540336, 0.7915790729037218, 0.903950496486096, 0.2099910673545029, 0.2050916459451676, 0.1656664810277051, 0.20659540609230076, 0.20920182293610334, 0.527801824663537, 0.20732917339185297, 0.8293052315978671, 0.20002538957146765, 0.19774949029637534, 0.1931863158849989, 0.18535285217671793, 0.18845282807229546, 0.18339102590391387, 0.19217450286979176, 0.1756536378376271, 0.18573097224555812, 0.08781909190852877, 0.08837877125881255, 0.08953782189577175, 0.09310295852623984, 0.09214333502148697, 0.09438875399527147, 0.08584889458012945, 0.1010235862490767, 0.0972800847778732]}, "mutation_prompt": null}
{"id": "02ec7b42-77a9-43d4-9ee5-af159b2b131a", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.85\n        self.scaling_increase_step = 0.07\n        self.reinit_threshold = 0.1\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                tournament_indices = np.random.choice(len(population), 5, replace=False)\n                x0, x1, x2 = population[tournament_indices[np.argmin(fitness[tournament_indices[:3]])]], \\\n                             population[tournament_indices[3]], population[tournament_indices[4]]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.1), replace=False)\n                for idx in random_indices:\n                    if num_evaluations >= self.budget:\n                        break\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n            \n            # Introduce local search intensification if stagnation is detected\n            if not np.any(improvement_mask) and num_evaluations < self.budget:\n                local_search_candidates = np.random.choice(len(population), 3, replace=False)\n                for idx in local_search_candidates:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    candidate = population[idx] + perturbation\n                    candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                    candidate_fitness = func(candidate)\n                    num_evaluations += 1\n                    if candidate_fitness < fitness[idx]:\n                        population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n\n        return elite_individual", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with local search intensification and dynamic population resizing for enhanced exploration and convergence.", "configspace": "", "generation": 79, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b7ae92dd-3b4b-4dd1-baf9-f38c70937821", "metadata": {"aucs": [0.8959095845141078, 0.8706728681719863, 0.8634742302495477, 0.8677589685050268, 0.8763100818478078, 0.8176903532523165, 0.8661997985551829, 0.8455657851736222, 0.8340713345991272, 0.7419940977391046, 0.7103304816851959, 0.7318033805014978, 0.7432880064232975, 0.7729209562477807, 0.7583056343080935, 0.7992127706421387, 0.7583820484448669, 0.762789741911219, 0.5980832628744248, 0.24651269334005088, 0.5768304617262617, 0.13798023253748504, 0.1604648873916854, 0.6359418171180917, 0.4529014076284913, 0.1558916844692485, 0.18280728572872984, 0.15041661401218331, 0.13680054151340704, 0.1480972453120356, 0.1608879558121491, 0.12367616100828238, 0.17272203727145874, 0.16627824227621057, 0.15938799263427905, 0.15596526273930178, 0.9463282726616835, 0.9678104892576842, 0.9676337463719548, 0.9753332687780508, 0.9674111947376378, 0.9557257535062202, 0.9585428961902459, 0.9628809468394908, 0.970431868437265, 0.6914307644535669, 0.7117675484507409, 0.5998434278103093, 0.7036859127457056, 0.6812649795696288, 0.6472882207584278, 0.7165757958405723, 0.6834973516821774, 0.7076741969223651, 0.3547876690980055, 0.8930282975734247, 0.8652608698313159, 0.9001061618623605, 0.889326124993228, 0.8681246393591243, 0.8620901807927612, 0.8859580897770105, 0.8786138772501232, 0.4664039135318775, 0.563673782054998, 0.4533236068805725, 0.34756526098319007, 0.13125610199412763, 0.47092310612951815, 0.46186268273734954, 0.6204835246550295, 0.5636558890234213, 0.36633490907134203, 0.12941621016288496, 0.45011069165055306, 0.6332732169955632, 0.492567893440495, 0.4638423877286385, 0.5260742311592603, 0.4853030900729828, 0.5623988118652294, 0.3722394219021051, 0.5221746602220374, 0.2932839522432473, 0.5889609009609156, 0.4245936628621464, 0.5532048381027419, 0.3259182621233241, 0.5764079472096897, 0.45062748175838196, 0.711517148578356, 0.6729396786912615, 0.4961078950747826, 0.5863496866489182, 0.5137171032249905, 0.47534204812455627, 0.7772901187554886, 0.7283880627746829, 0.7160516284390054, 0.24586766790839387, 0.21349330899818275, 0.07123805942264427, 0.43497273393466507, 0.379382192456999, 0.3486357302340424, 0.20457309358624576, 0.2580033648750609, 0.1998934459717101, 0.41156894518877063, 0.3954095499794865, 0.42415377083384476, 0.447280845696168, 0.5641229033867792, 0.5382082917761077, 0.5193334291390775, 0.5040170767916672, 0.5423955683553915, 0.8386884148909358, 0.8079876807256721, 0.7505909105185335, 0.7516226058425888, 0.8025416445582052, 0.820786872184763, 0.8453031430650506, 0.7421109721425602, 0.7884659461834964, 0.15088767159727778, 0.14033161343778722, 0.1558288073048648, 0.1413576171187284, 0.1371666396259561, 0.12196285562941755, 0.11267072870796435, 0.1522425411205688, 0.1385469309723154, 0.2144002325407487, 0.15875718558617713, 0.40670023798166144, 0.3942775332035, 0.24573194487562555, 0.16632900433327158, 0.42917158254674237, 0.32812293272557413, 0.2135443997322405, 0.3271360634059238, 0.6606926256143755, 0.5429129143873321, 0.6200903651143682, 0.5842503559086694, 0.42561348213178185, 0.7423902335689301, 0.7318963166151539, 0.6160800401340978, 0.3639273385301198, 0.34185498728025177, 0.471866298176412, 0.4808835233662333, 0.5709583243000429, 0.24384714871223445, 0.2339088017965647, 0.5389947700427353, 0.2313877565126491, 0.20480295901128742, 0.20402310615699237, 0.251329500281392, 0.21933544915476277, 0.2293174392733769, 0.2186419556343464, 0.22275015543363885, 0.21047605652644474, 0.2418777824439855, 0.779192733383349, 0.7621790642677698, 0.2064743381155364, 0.2476980154346229, 0.21668933879473917, 0.22363697030525298, 0.20445088309591875, 0.22054426844225206, 0.20448734435197113, 0.8855392282007896, 0.20721557538767554, 0.19724204489956498, 0.8557573368055722, 0.19986965537492252, 0.9248942716328965, 0.533007970902579, 0.19409554473540336, 0.7915790729037218, 0.903950496486096, 0.2099910673545029, 0.2050916459451676, 0.1656664810277051, 0.20659540609230076, 0.20920182293610334, 0.527801824663537, 0.20732917339185297, 0.8293052315978671, 0.20002538957146765, 0.19774949029637534, 0.1931863158849989, 0.18535285217671793, 0.18845282807229546, 0.18339102590391387, 0.19217450286979176, 0.1756536378376271, 0.18573097224555812, 0.08781909190852877, 0.08837877125881255, 0.08953782189577175, 0.09310295852623984, 0.09214333502148697, 0.09438875399527147, 0.08584889458012945, 0.1010235862490767, 0.0972800847778732]}, "mutation_prompt": null}
{"id": "08577d13-8d92-4e5c-925e-2925efc59e27", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.85\n        self.scaling_increase_step = 0.07\n        self.reinit_threshold = 0.1\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                tournament_indices = np.random.choice(len(population), 5, replace=False)\n                x0, x1, x2 = population[tournament_indices[np.argmin(fitness[tournament_indices[:3]])]], \\\n                             population[tournament_indices[3]], population[tournament_indices[4]]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.1), replace=False)\n                for idx in random_indices:\n                    if num_evaluations >= self.budget:\n                        break\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n            \n            # Introduce local search intensification if stagnation is detected\n            if not np.any(improvement_mask) and num_evaluations < self.budget:\n                local_search_candidates = np.random.choice(len(population), 3, replace=False)\n                for idx in local_search_candidates:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    candidate = population[idx] + perturbation\n                    candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                    candidate_fitness = func(candidate)\n                    num_evaluations += 1\n                    if candidate_fitness < fitness[idx]:\n                        population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n\n        return elite_individual", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with local search intensification and dynamic population resizing for enhanced exploration and convergence.", "configspace": "", "generation": 79, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b7ae92dd-3b4b-4dd1-baf9-f38c70937821", "metadata": {"aucs": [0.8959095845141078, 0.8706728681719863, 0.8634742302495477, 0.8677589685050268, 0.8763100818478078, 0.8176903532523165, 0.8661997985551829, 0.8455657851736222, 0.8340713345991272, 0.7419940977391046, 0.7103304816851959, 0.7318033805014978, 0.7432880064232975, 0.7729209562477807, 0.7583056343080935, 0.7992127706421387, 0.7583820484448669, 0.762789741911219, 0.5980832628744248, 0.24651269334005088, 0.5768304617262617, 0.13798023253748504, 0.1604648873916854, 0.6359418171180917, 0.4529014076284913, 0.1558916844692485, 0.18280728572872984, 0.15041661401218331, 0.13680054151340704, 0.1480972453120356, 0.1608879558121491, 0.12367616100828238, 0.17272203727145874, 0.16627824227621057, 0.15938799263427905, 0.15596526273930178, 0.9463282726616835, 0.9678104892576842, 0.9676337463719548, 0.9753332687780508, 0.9674111947376378, 0.9557257535062202, 0.9585428961902459, 0.9628809468394908, 0.970431868437265, 0.6914307644535669, 0.7117675484507409, 0.5998434278103093, 0.7036859127457056, 0.6812649795696288, 0.6472882207584278, 0.7165757958405723, 0.6834973516821774, 0.7076741969223651, 0.3547876690980055, 0.8930282975734247, 0.8652608698313159, 0.9001061618623605, 0.889326124993228, 0.8681246393591243, 0.8620901807927612, 0.8859580897770105, 0.8786138772501232, 0.4664039135318775, 0.563673782054998, 0.4533236068805725, 0.34756526098319007, 0.13125610199412763, 0.47092310612951815, 0.46186268273734954, 0.6204835246550295, 0.5636558890234213, 0.36633490907134203, 0.12941621016288496, 0.45011069165055306, 0.6332732169955632, 0.492567893440495, 0.4638423877286385, 0.5260742311592603, 0.4853030900729828, 0.5623988118652294, 0.3722394219021051, 0.5221746602220374, 0.2932839522432473, 0.5889609009609156, 0.4245936628621464, 0.5532048381027419, 0.3259182621233241, 0.5764079472096897, 0.45062748175838196, 0.711517148578356, 0.6729396786912615, 0.4961078950747826, 0.5863496866489182, 0.5137171032249905, 0.47534204812455627, 0.7772901187554886, 0.7283880627746829, 0.7160516284390054, 0.24586766790839387, 0.21349330899818275, 0.07123805942264427, 0.43497273393466507, 0.379382192456999, 0.3486357302340424, 0.20457309358624576, 0.2580033648750609, 0.1998934459717101, 0.41156894518877063, 0.3954095499794865, 0.42415377083384476, 0.447280845696168, 0.5641229033867792, 0.5382082917761077, 0.5193334291390775, 0.5040170767916672, 0.5423955683553915, 0.8386884148909358, 0.8079876807256721, 0.7505909105185335, 0.7516226058425888, 0.8025416445582052, 0.820786872184763, 0.8453031430650506, 0.7421109721425602, 0.7884659461834964, 0.15088767159727778, 0.14033161343778722, 0.1558288073048648, 0.1413576171187284, 0.1371666396259561, 0.12196285562941755, 0.11267072870796435, 0.1522425411205688, 0.1385469309723154, 0.2144002325407487, 0.15875718558617713, 0.40670023798166144, 0.3942775332035, 0.24573194487562555, 0.16632900433327158, 0.42917158254674237, 0.32812293272557413, 0.2135443997322405, 0.3271360634059238, 0.6606926256143755, 0.5429129143873321, 0.6200903651143682, 0.5842503559086694, 0.42561348213178185, 0.7423902335689301, 0.7318963166151539, 0.6160800401340978, 0.3639273385301198, 0.34185498728025177, 0.471866298176412, 0.4808835233662333, 0.5709583243000429, 0.24384714871223445, 0.2339088017965647, 0.5389947700427353, 0.2313877565126491, 0.20480295901128742, 0.20402310615699237, 0.251329500281392, 0.21933544915476277, 0.2293174392733769, 0.2186419556343464, 0.22275015543363885, 0.21047605652644474, 0.2418777824439855, 0.779192733383349, 0.7621790642677698, 0.2064743381155364, 0.2476980154346229, 0.21668933879473917, 0.22363697030525298, 0.20445088309591875, 0.22054426844225206, 0.20448734435197113, 0.8855392282007896, 0.20721557538767554, 0.19724204489956498, 0.8557573368055722, 0.19986965537492252, 0.9248942716328965, 0.533007970902579, 0.19409554473540336, 0.7915790729037218, 0.903950496486096, 0.2099910673545029, 0.2050916459451676, 0.1656664810277051, 0.20659540609230076, 0.20920182293610334, 0.527801824663537, 0.20732917339185297, 0.8293052315978671, 0.20002538957146765, 0.19774949029637534, 0.1931863158849989, 0.18535285217671793, 0.18845282807229546, 0.18339102590391387, 0.19217450286979176, 0.1756536378376271, 0.18573097224555812, 0.08781909190852877, 0.08837877125881255, 0.08953782189577175, 0.09310295852623984, 0.09214333502148697, 0.09438875399527147, 0.08584889458012945, 0.1010235862490767, 0.0972800847778732]}, "mutation_prompt": null}
{"id": "c841a0cf-51dc-4510-840a-2bd817662884", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.85\n        self.scaling_increase_step = 0.07\n        self.reinit_threshold = 0.1\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                tournament_indices = np.random.choice(len(population), 5, replace=False)\n                x0, x1, x2 = population[tournament_indices[np.argmin(fitness[tournament_indices[:3]])]], \\\n                             population[tournament_indices[3]], population[tournament_indices[4]]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.1), replace=False)\n                for idx in random_indices:\n                    if num_evaluations >= self.budget:\n                        break\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n            \n            # Introduce local search intensification if stagnation is detected\n            if not np.any(improvement_mask) and num_evaluations < self.budget:\n                local_search_candidates = np.random.choice(len(population), 3, replace=False)\n                for idx in local_search_candidates:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    candidate = population[idx] + perturbation\n                    candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                    candidate_fitness = func(candidate)\n                    num_evaluations += 1\n                    if candidate_fitness < fitness[idx]:\n                        population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n\n        return elite_individual", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with local search intensification and dynamic population resizing for enhanced exploration and convergence.", "configspace": "", "generation": 79, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b7ae92dd-3b4b-4dd1-baf9-f38c70937821", "metadata": {"aucs": [0.8959095845141078, 0.8706728681719863, 0.8634742302495477, 0.8677589685050268, 0.8763100818478078, 0.8176903532523165, 0.8661997985551829, 0.8455657851736222, 0.8340713345991272, 0.7419940977391046, 0.7103304816851959, 0.7318033805014978, 0.7432880064232975, 0.7729209562477807, 0.7583056343080935, 0.7992127706421387, 0.7583820484448669, 0.762789741911219, 0.5980832628744248, 0.24651269334005088, 0.5768304617262617, 0.13798023253748504, 0.1604648873916854, 0.6359418171180917, 0.4529014076284913, 0.1558916844692485, 0.18280728572872984, 0.15041661401218331, 0.13680054151340704, 0.1480972453120356, 0.1608879558121491, 0.12367616100828238, 0.17272203727145874, 0.16627824227621057, 0.15938799263427905, 0.15596526273930178, 0.9463282726616835, 0.9678104892576842, 0.9676337463719548, 0.9753332687780508, 0.9674111947376378, 0.9557257535062202, 0.9585428961902459, 0.9628809468394908, 0.970431868437265, 0.6914307644535669, 0.7117675484507409, 0.5998434278103093, 0.7036859127457056, 0.6812649795696288, 0.6472882207584278, 0.7165757958405723, 0.6834973516821774, 0.7076741969223651, 0.3547876690980055, 0.8930282975734247, 0.8652608698313159, 0.9001061618623605, 0.889326124993228, 0.8681246393591243, 0.8620901807927612, 0.8859580897770105, 0.8786138772501232, 0.4664039135318775, 0.563673782054998, 0.4533236068805725, 0.34756526098319007, 0.13125610199412763, 0.47092310612951815, 0.46186268273734954, 0.6204835246550295, 0.5636558890234213, 0.36633490907134203, 0.12941621016288496, 0.45011069165055306, 0.6332732169955632, 0.492567893440495, 0.4638423877286385, 0.5260742311592603, 0.4853030900729828, 0.5623988118652294, 0.3722394219021051, 0.5221746602220374, 0.2932839522432473, 0.5889609009609156, 0.4245936628621464, 0.5532048381027419, 0.3259182621233241, 0.5764079472096897, 0.45062748175838196, 0.711517148578356, 0.6729396786912615, 0.4961078950747826, 0.5863496866489182, 0.5137171032249905, 0.47534204812455627, 0.7772901187554886, 0.7283880627746829, 0.7160516284390054, 0.24586766790839387, 0.21349330899818275, 0.07123805942264427, 0.43497273393466507, 0.379382192456999, 0.3486357302340424, 0.20457309358624576, 0.2580033648750609, 0.1998934459717101, 0.41156894518877063, 0.3954095499794865, 0.42415377083384476, 0.447280845696168, 0.5641229033867792, 0.5382082917761077, 0.5193334291390775, 0.5040170767916672, 0.5423955683553915, 0.8386884148909358, 0.8079876807256721, 0.7505909105185335, 0.7516226058425888, 0.8025416445582052, 0.820786872184763, 0.8453031430650506, 0.7421109721425602, 0.7884659461834964, 0.15088767159727778, 0.14033161343778722, 0.1558288073048648, 0.1413576171187284, 0.1371666396259561, 0.12196285562941755, 0.11267072870796435, 0.1522425411205688, 0.1385469309723154, 0.2144002325407487, 0.15875718558617713, 0.40670023798166144, 0.3942775332035, 0.24573194487562555, 0.16632900433327158, 0.42917158254674237, 0.32812293272557413, 0.2135443997322405, 0.3271360634059238, 0.6606926256143755, 0.5429129143873321, 0.6200903651143682, 0.5842503559086694, 0.42561348213178185, 0.7423902335689301, 0.7318963166151539, 0.6160800401340978, 0.3639273385301198, 0.34185498728025177, 0.471866298176412, 0.4808835233662333, 0.5709583243000429, 0.24384714871223445, 0.2339088017965647, 0.5389947700427353, 0.2313877565126491, 0.20480295901128742, 0.20402310615699237, 0.251329500281392, 0.21933544915476277, 0.2293174392733769, 0.2186419556343464, 0.22275015543363885, 0.21047605652644474, 0.2418777824439855, 0.779192733383349, 0.7621790642677698, 0.2064743381155364, 0.2476980154346229, 0.21668933879473917, 0.22363697030525298, 0.20445088309591875, 0.22054426844225206, 0.20448734435197113, 0.8855392282007896, 0.20721557538767554, 0.19724204489956498, 0.8557573368055722, 0.19986965537492252, 0.9248942716328965, 0.533007970902579, 0.19409554473540336, 0.7915790729037218, 0.903950496486096, 0.2099910673545029, 0.2050916459451676, 0.1656664810277051, 0.20659540609230076, 0.20920182293610334, 0.527801824663537, 0.20732917339185297, 0.8293052315978671, 0.20002538957146765, 0.19774949029637534, 0.1931863158849989, 0.18535285217671793, 0.18845282807229546, 0.18339102590391387, 0.19217450286979176, 0.1756536378376271, 0.18573097224555812, 0.08781909190852877, 0.08837877125881255, 0.08953782189577175, 0.09310295852623984, 0.09214333502148697, 0.09438875399527147, 0.08584889458012945, 0.1010235862490767, 0.0972800847778732]}, "mutation_prompt": null}
{"id": "45e96ebd-4df9-4c35-8e96-90bc97ece165", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.85\n        self.scaling_increase_step = 0.07\n        self.reinit_threshold = 0.1\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                tournament_indices = np.random.choice(len(population), 5, replace=False)\n                x0, x1, x2 = population[tournament_indices[np.argmin(fitness[tournament_indices[:3]])]], \\\n                             population[tournament_indices[3]], population[tournament_indices[4]]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.1), replace=False)\n                for idx in random_indices:\n                    if num_evaluations >= self.budget:\n                        break\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n            \n            # Introduce local search intensification if stagnation is detected\n            if not np.any(improvement_mask) and num_evaluations < self.budget:\n                local_search_candidates = np.random.choice(len(population), 3, replace=False)\n                for idx in local_search_candidates:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    candidate = population[idx] + perturbation\n                    candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                    candidate_fitness = func(candidate)\n                    num_evaluations += 1\n                    if candidate_fitness < fitness[idx]:\n                        population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n\n        return elite_individual", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with local search intensification and dynamic population resizing for enhanced exploration and convergence.", "configspace": "", "generation": 79, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b7ae92dd-3b4b-4dd1-baf9-f38c70937821", "metadata": {"aucs": [0.8959095845141078, 0.8706728681719863, 0.8634742302495477, 0.8677589685050268, 0.8763100818478078, 0.8176903532523165, 0.8661997985551829, 0.8455657851736222, 0.8340713345991272, 0.7419940977391046, 0.7103304816851959, 0.7318033805014978, 0.7432880064232975, 0.7729209562477807, 0.7583056343080935, 0.7992127706421387, 0.7583820484448669, 0.762789741911219, 0.5980832628744248, 0.24651269334005088, 0.5768304617262617, 0.13798023253748504, 0.1604648873916854, 0.6359418171180917, 0.4529014076284913, 0.1558916844692485, 0.18280728572872984, 0.15041661401218331, 0.13680054151340704, 0.1480972453120356, 0.1608879558121491, 0.12367616100828238, 0.17272203727145874, 0.16627824227621057, 0.15938799263427905, 0.15596526273930178, 0.9463282726616835, 0.9678104892576842, 0.9676337463719548, 0.9753332687780508, 0.9674111947376378, 0.9557257535062202, 0.9585428961902459, 0.9628809468394908, 0.970431868437265, 0.6914307644535669, 0.7117675484507409, 0.5998434278103093, 0.7036859127457056, 0.6812649795696288, 0.6472882207584278, 0.7165757958405723, 0.6834973516821774, 0.7076741969223651, 0.3547876690980055, 0.8930282975734247, 0.8652608698313159, 0.9001061618623605, 0.889326124993228, 0.8681246393591243, 0.8620901807927612, 0.8859580897770105, 0.8786138772501232, 0.4664039135318775, 0.563673782054998, 0.4533236068805725, 0.34756526098319007, 0.13125610199412763, 0.47092310612951815, 0.46186268273734954, 0.6204835246550295, 0.5636558890234213, 0.36633490907134203, 0.12941621016288496, 0.45011069165055306, 0.6332732169955632, 0.492567893440495, 0.4638423877286385, 0.5260742311592603, 0.4853030900729828, 0.5623988118652294, 0.3722394219021051, 0.5221746602220374, 0.2932839522432473, 0.5889609009609156, 0.4245936628621464, 0.5532048381027419, 0.3259182621233241, 0.5764079472096897, 0.45062748175838196, 0.711517148578356, 0.6729396786912615, 0.4961078950747826, 0.5863496866489182, 0.5137171032249905, 0.47534204812455627, 0.7772901187554886, 0.7283880627746829, 0.7160516284390054, 0.24586766790839387, 0.21349330899818275, 0.07123805942264427, 0.43497273393466507, 0.379382192456999, 0.3486357302340424, 0.20457309358624576, 0.2580033648750609, 0.1998934459717101, 0.41156894518877063, 0.3954095499794865, 0.42415377083384476, 0.447280845696168, 0.5641229033867792, 0.5382082917761077, 0.5193334291390775, 0.5040170767916672, 0.5423955683553915, 0.8386884148909358, 0.8079876807256721, 0.7505909105185335, 0.7516226058425888, 0.8025416445582052, 0.820786872184763, 0.8453031430650506, 0.7421109721425602, 0.7884659461834964, 0.15088767159727778, 0.14033161343778722, 0.1558288073048648, 0.1413576171187284, 0.1371666396259561, 0.12196285562941755, 0.11267072870796435, 0.1522425411205688, 0.1385469309723154, 0.2144002325407487, 0.15875718558617713, 0.40670023798166144, 0.3942775332035, 0.24573194487562555, 0.16632900433327158, 0.42917158254674237, 0.32812293272557413, 0.2135443997322405, 0.3271360634059238, 0.6606926256143755, 0.5429129143873321, 0.6200903651143682, 0.5842503559086694, 0.42561348213178185, 0.7423902335689301, 0.7318963166151539, 0.6160800401340978, 0.3639273385301198, 0.34185498728025177, 0.471866298176412, 0.4808835233662333, 0.5709583243000429, 0.24384714871223445, 0.2339088017965647, 0.5389947700427353, 0.2313877565126491, 0.20480295901128742, 0.20402310615699237, 0.251329500281392, 0.21933544915476277, 0.2293174392733769, 0.2186419556343464, 0.22275015543363885, 0.21047605652644474, 0.2418777824439855, 0.779192733383349, 0.7621790642677698, 0.2064743381155364, 0.2476980154346229, 0.21668933879473917, 0.22363697030525298, 0.20445088309591875, 0.22054426844225206, 0.20448734435197113, 0.8855392282007896, 0.20721557538767554, 0.19724204489956498, 0.8557573368055722, 0.19986965537492252, 0.9248942716328965, 0.533007970902579, 0.19409554473540336, 0.7915790729037218, 0.903950496486096, 0.2099910673545029, 0.2050916459451676, 0.1656664810277051, 0.20659540609230076, 0.20920182293610334, 0.527801824663537, 0.20732917339185297, 0.8293052315978671, 0.20002538957146765, 0.19774949029637534, 0.1931863158849989, 0.18535285217671793, 0.18845282807229546, 0.18339102590391387, 0.19217450286979176, 0.1756536378376271, 0.18573097224555812, 0.08781909190852877, 0.08837877125881255, 0.08953782189577175, 0.09310295852623984, 0.09214333502148697, 0.09438875399527147, 0.08584889458012945, 0.1010235862490767, 0.0972800847778732]}, "mutation_prompt": null}
{"id": "9f7d6fa4-b834-435b-8725-5cbf9e4bb78a", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.85\n        self.scaling_increase_step = 0.07\n        self.reinit_threshold = 0.1\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                tournament_indices = np.random.choice(len(population), 5, replace=False)\n                x0, x1, x2 = population[tournament_indices[np.argmin(fitness[tournament_indices[:3]])]], \\\n                             population[tournament_indices[3]], population[tournament_indices[4]]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.1), replace=False)\n                for idx in random_indices:\n                    if num_evaluations >= self.budget:\n                        break\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n            \n            # Introduce local search intensification if stagnation is detected\n            if not np.any(improvement_mask) and num_evaluations < self.budget:\n                local_search_candidates = np.random.choice(len(population), 3, replace=False)\n                for idx in local_search_candidates:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    candidate = population[idx] + perturbation\n                    candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                    candidate_fitness = func(candidate)\n                    num_evaluations += 1\n                    if candidate_fitness < fitness[idx]:\n                        population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n\n        return elite_individual", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with local search intensification and dynamic population resizing for enhanced exploration and convergence.", "configspace": "", "generation": 79, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b7ae92dd-3b4b-4dd1-baf9-f38c70937821", "metadata": {"aucs": [0.8959095845141078, 0.8706728681719863, 0.8634742302495477, 0.8677589685050268, 0.8763100818478078, 0.8176903532523165, 0.8661997985551829, 0.8455657851736222, 0.8340713345991272, 0.7419940977391046, 0.7103304816851959, 0.7318033805014978, 0.7432880064232975, 0.7729209562477807, 0.7583056343080935, 0.7992127706421387, 0.7583820484448669, 0.762789741911219, 0.5980832628744248, 0.24651269334005088, 0.5768304617262617, 0.13798023253748504, 0.1604648873916854, 0.6359418171180917, 0.4529014076284913, 0.1558916844692485, 0.18280728572872984, 0.15041661401218331, 0.13680054151340704, 0.1480972453120356, 0.1608879558121491, 0.12367616100828238, 0.17272203727145874, 0.16627824227621057, 0.15938799263427905, 0.15596526273930178, 0.9463282726616835, 0.9678104892576842, 0.9676337463719548, 0.9753332687780508, 0.9674111947376378, 0.9557257535062202, 0.9585428961902459, 0.9628809468394908, 0.970431868437265, 0.6914307644535669, 0.7117675484507409, 0.5998434278103093, 0.7036859127457056, 0.6812649795696288, 0.6472882207584278, 0.7165757958405723, 0.6834973516821774, 0.7076741969223651, 0.3547876690980055, 0.8930282975734247, 0.8652608698313159, 0.9001061618623605, 0.889326124993228, 0.8681246393591243, 0.8620901807927612, 0.8859580897770105, 0.8786138772501232, 0.4664039135318775, 0.563673782054998, 0.4533236068805725, 0.34756526098319007, 0.13125610199412763, 0.47092310612951815, 0.46186268273734954, 0.6204835246550295, 0.5636558890234213, 0.36633490907134203, 0.12941621016288496, 0.45011069165055306, 0.6332732169955632, 0.492567893440495, 0.4638423877286385, 0.5260742311592603, 0.4853030900729828, 0.5623988118652294, 0.3722394219021051, 0.5221746602220374, 0.2932839522432473, 0.5889609009609156, 0.4245936628621464, 0.5532048381027419, 0.3259182621233241, 0.5764079472096897, 0.45062748175838196, 0.711517148578356, 0.6729396786912615, 0.4961078950747826, 0.5863496866489182, 0.5137171032249905, 0.47534204812455627, 0.7772901187554886, 0.7283880627746829, 0.7160516284390054, 0.24586766790839387, 0.21349330899818275, 0.07123805942264427, 0.43497273393466507, 0.379382192456999, 0.3486357302340424, 0.20457309358624576, 0.2580033648750609, 0.1998934459717101, 0.41156894518877063, 0.3954095499794865, 0.42415377083384476, 0.447280845696168, 0.5641229033867792, 0.5382082917761077, 0.5193334291390775, 0.5040170767916672, 0.5423955683553915, 0.8386884148909358, 0.8079876807256721, 0.7505909105185335, 0.7516226058425888, 0.8025416445582052, 0.820786872184763, 0.8453031430650506, 0.7421109721425602, 0.7884659461834964, 0.15088767159727778, 0.14033161343778722, 0.1558288073048648, 0.1413576171187284, 0.1371666396259561, 0.12196285562941755, 0.11267072870796435, 0.1522425411205688, 0.1385469309723154, 0.2144002325407487, 0.15875718558617713, 0.40670023798166144, 0.3942775332035, 0.24573194487562555, 0.16632900433327158, 0.42917158254674237, 0.32812293272557413, 0.2135443997322405, 0.3271360634059238, 0.6606926256143755, 0.5429129143873321, 0.6200903651143682, 0.5842503559086694, 0.42561348213178185, 0.7423902335689301, 0.7318963166151539, 0.6160800401340978, 0.3639273385301198, 0.34185498728025177, 0.471866298176412, 0.4808835233662333, 0.5709583243000429, 0.24384714871223445, 0.2339088017965647, 0.5389947700427353, 0.2313877565126491, 0.20480295901128742, 0.20402310615699237, 0.251329500281392, 0.21933544915476277, 0.2293174392733769, 0.2186419556343464, 0.22275015543363885, 0.21047605652644474, 0.2418777824439855, 0.779192733383349, 0.7621790642677698, 0.2064743381155364, 0.2476980154346229, 0.21668933879473917, 0.22363697030525298, 0.20445088309591875, 0.22054426844225206, 0.20448734435197113, 0.8855392282007896, 0.20721557538767554, 0.19724204489956498, 0.8557573368055722, 0.19986965537492252, 0.9248942716328965, 0.533007970902579, 0.19409554473540336, 0.7915790729037218, 0.903950496486096, 0.2099910673545029, 0.2050916459451676, 0.1656664810277051, 0.20659540609230076, 0.20920182293610334, 0.527801824663537, 0.20732917339185297, 0.8293052315978671, 0.20002538957146765, 0.19774949029637534, 0.1931863158849989, 0.18535285217671793, 0.18845282807229546, 0.18339102590391387, 0.19217450286979176, 0.1756536378376271, 0.18573097224555812, 0.08781909190852877, 0.08837877125881255, 0.08953782189577175, 0.09310295852623984, 0.09214333502148697, 0.09438875399527147, 0.08584889458012945, 0.1010235862490767, 0.0972800847778732]}, "mutation_prompt": null}
{"id": "5d046db2-f6be-4b6b-8a64-52bb5a202c42", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.85\n        self.scaling_increase_step = 0.07\n        self.reinit_threshold = 0.1\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                tournament_indices = np.random.choice(len(population), 5, replace=False)\n                x0, x1, x2 = population[tournament_indices[np.argmin(fitness[tournament_indices[:3]])]], \\\n                             population[tournament_indices[3]], population[tournament_indices[4]]\n                mutant_vector = x0 + self.scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                # Adaptive crossover rate based on diversity\n                diversity = np.std(population, axis=0)\n                adaptive_crossover_rate = max(0.5, self.crossover_rate - 0.1 * np.mean(diversity))\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                self.scaling_factor = min(1.0, self.scaling_factor + self.scaling_increase_step)\n            else:\n                self.scaling_factor = max(0.2, self.scaling_factor - self.scaling_increase_step)\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.1), replace=False)\n                for idx in random_indices:\n                    if num_evaluations >= self.budget:\n                        break\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n            \n            # Enhanced diversity preservation\n            if np.std(fitness) < 1e-5 and num_evaluations < self.budget:\n                diversity_increase_idx = np.random.choice(len(population), int(self.population_size * 0.05), replace=False)\n                for idx in diversity_increase_idx:\n                    if num_evaluations >= self.budget:\n                        break\n                    random_vector = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    population[idx] = random_vector\n                    fitness[idx] = func(random_vector)\n                    num_evaluations += 1\n\n        return elite_individual", "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with dynamic scaling, diversity preservation, and adaptive crossover for improved exploration and convergence.", "configspace": "", "generation": 84, "fitness": 0.42154478528370637, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42 with standard deviation 0.27.", "error": "", "parent_id": "b7ae92dd-3b4b-4dd1-baf9-f38c70937821", "metadata": {"aucs": [0.8921384666769793, 0.8240769532600563, 0.8750048542693316, 0.8962835923985859, 0.8265591105345546, 0.8590966793750651, 0.8294639950537016, 0.8820625743798516, 0.8710016200181656, 0.7792751943681419, 0.7623339170778959, 0.7850300469354637, 0.7744793786423364, 0.7561330874837187, 0.7410104487492611, 0.791199893256685, 0.7304752139587214, 0.7717628129368019, 0.15436499602875942, 0.6908740270980838, 0.1757977949990409, 0.1667897587107804, 0.16819091879583625, 0.467252763330849, 0.17822416843782996, 0.6897329106466639, 0.431389255302408, 0.1609231601481621, 0.14558975211616676, 0.5053248318655572, 0.1723760698168455, 0.17526928091428307, 0.14594994735737343, 0.177216538007274, 0.14267400822700127, 0.13717627172732516, 0.9791660100920921, 0.957800810487295, 0.9245460921776405, 0.9578997431112706, 0.9733822519476808, 0.9525524073044372, 0.9677633594249216, 0.9637105108262033, 0.9810609278433973, 0.6729732688228534, 0.6431568769157935, 0.6233655167314867, 0.6578352913848756, 0.6745733440856108, 0.6082455568645919, 0.5748239101337855, 0.6436974478399098, 0.6546215120919032, 0.2876456377047901, 0.37601219001878305, 0.5428345938584427, 0.3538446211526217, 0.8558931348333321, 0.3695943869150893, 0.854656013907746, 0.8821700133650762, 0.8345515433832951, 0.623327434882882, 0.5209935037398421, 0.427805063017605, 0.6005706844964929, 0.131263801736759, 0.35017043158012084, 0.49321691538003165, 0.4869953390501812, 0.49151263822960023, 0.27224267950794556, 0.3693796076606244, 0.44456610935469765, 0.35153185859347913, 0.44099851740614837, 0.4299685094349489, 0.44342450640946895, 0.4975176653519535, 0.3643903198528067, 0.47197424056862525, 0.5266626377444341, 0.33651195532660694, 0.4735021687897031, 0.08498878012303779, 0.07156860338391413, 0.2567238326090606, 0.16643784594023114, 0.1668922720480226, 0.27603930135624466, 0.5824222444295204, 0.32589078266390925, 0.46783724969550144, 0.24864914428293572, 0.22106886851910434, 0.564826751050046, 0.509017853360756, 0.40129220545173483, 0.19963296210459025, 0.09618456272700882, 0.09801829557940933, 0.4052319993569292, 0.19216884166447612, 0.1795965052748748, 0.24116565241979948, 0.16512432747826133, 0.16047090907523476, 0.3353783137257682, 0.40504752982833125, 0.45611966074197186, 0.3466197122199275, 0.4936796950294432, 0.37484450690770355, 0.33129380456177926, 0.37527055963295275, 0.30369845906067383, 0.7671636551488707, 0.7775346027150078, 0.6695373904029416, 0.7065773958649395, 0.6807408670808244, 0.7515883266302218, 0.8140235812295018, 0.7953134281838212, 0.8578011755099753, 0.11858223322425543, 0.1383258079110803, 0.13787200075249761, 0.14771364493000383, 0.12433102918398276, 0.13793927240351134, 0.14635723267082779, 0.13112494680716114, 0.15821350457638017, 0.2440750943331259, 0.17200789547644513, 0.1535510513256766, 0.16903437579640634, 0.16800879865061247, 0.3244659192177022, 0.1780595181821214, 0.18285630395197816, 0.14705851850521723, 0.5994814651123467, 0.5605608281873373, 0.6825852946377515, 0.603546294029612, 0.40470380531519023, 0.2842741661199588, 0.6361403468392217, 0.6736739758197264, 0.6081481549500558, 0.24213675182126948, 0.4415102081425136, 0.2929560939092585, 0.5086958542247157, 0.2913547774445491, 0.32977102959057425, 0.20842280444172956, 0.2851154527515998, 0.3507219785874295, 0.2016979359070986, 0.2226268589479118, 0.2070351873248557, 0.19769775313092663, 0.20569994400040736, 0.20623703959079753, 0.22158282190182454, 0.23949969789262582, 0.4401265790681004, 0.22150278455838224, 0.24929124042994166, 0.6366646521827266, 0.23426654978565498, 0.24983098819706107, 0.20386898201024228, 0.5750318871978064, 0.24109576822575907, 0.22770858639401426, 0.2057142248476147, 0.18569164552766015, 0.19814429453225313, 0.8616424884045959, 0.19466493823534603, 0.909407357382797, 0.1676627477018836, 0.1668573911624318, 0.868043403760413, 0.883799848853526, 0.21033384536736477, 0.1656086335451351, 0.20376864891582558, 0.6219632003598354, 0.46909325495839715, 0.7132224635941293, 0.20913722721633177, 0.20719410150800266, 0.170696124906206, 0.17864323431136842, 0.1907588895789467, 0.18869257013595941, 0.18321537875228833, 0.17582139696265953, 0.1772174468171488, 0.20102850512985038, 0.17866538842698299, 0.10302605464109693, 0.08607541870103852, 0.09062184955392893, 0.09017487102678079, 0.09345524764543911, 0.0985144850884564, 0.08819495825242307, 0.08860128152569446, 0.0905888080661067]}, "mutation_prompt": null}
{"id": "8a65342e-6886-46d6-8492-f961baa5929f", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.initial_crossover_rate = 0.85\n        self.scaling_increase_step = 0.07\n        self.reinit_threshold = 0.1\n        self.crossover_decrease_step = 0.02\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n        crossover_rate = self.initial_crossover_rate\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                tournament_indices = np.random.choice(len(population), 5, replace=False)\n                x0, x1, x2 = population[tournament_indices[np.argmin(fitness[tournament_indices[:3]])]], \\\n                             population[tournament_indices[3]], population[tournament_indices[4]]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n                crossover_rate = min(1.0, crossover_rate + self.crossover_decrease_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n                crossover_rate = max(0.1, crossover_rate - self.crossover_decrease_step)\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.1), replace=False)\n                for idx in random_indices:\n                    if num_evaluations >= self.budget:\n                        break\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n            \n            # Introduce local search intensification if stagnation is detected\n            if not np.any(improvement_mask) and num_evaluations < self.budget:\n                local_search_candidates = np.random.choice(len(population), 3, replace=False)\n                for idx in local_search_candidates:\n                    perturbation = np.random.normal(0, 0.5, self.dim)  # Increased perturbation variance\n                    candidate = population[idx] + perturbation\n                    candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                    candidate_fitness = func(candidate)\n                    num_evaluations += 1\n                    if candidate_fitness < fitness[idx]:\n                        population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n\n        return elite_individual", "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with adaptive crossover rate and diverse perturbation strategy to improve exploration and convergence balance.", "configspace": "", "generation": 85, "fitness": 0.40798989328030355, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.29.", "error": "", "parent_id": "b7ae92dd-3b4b-4dd1-baf9-f38c70937821", "metadata": {"aucs": [0.8925282435871194, 0.8886545424929042, 0.8444677534422593, 0.8593363482262557, 0.8541883727592063, 0.8511037217479374, 0.8642586055629787, 0.8824700880073842, 0.8716948165976867, 0.789709381456029, 0.770902293361774, 0.7695989424189309, 0.757375377013655, 0.7938769054857846, 0.7412221868791382, 0.7597692711824774, 0.773032998701134, 0.8237513601357245, 0.6394341745946661, 0.6701997797486601, 0.6591206548008754, 0.7182044870271158, 0.3946019148003548, 0.707552942700352, 0.6595274174840311, 0.6546852899317739, 0.6748429345125957, 0.17409468790146498, 0.5873205554704521, 0.18017511663950536, 0.2559088914135774, 0.6902990895584163, 0.609687349084779, 0.16644705414235084, 0.30813613176054344, 0.6322797230031334, 0.9766062138775097, 0.9658995547433914, 0.9472066778805223, 0.96287946066437, 0.9789964813193364, 0.9553818085021611, 0.948453084758647, 0.9635941479202481, 0.9426658850281625, 0.4707159682566878, 0.7230497662447021, 0.5576040687199189, 0.6329260088575821, 0.6575534518421937, 0.6522845886468176, 0.712634182532252, 0.6587290684234581, 0.6837463103761549, 0.862015265703528, 0.22409706551210562, 0.8731423274863462, 0.8675937248967179, 0.8341022483752139, 0.8528201038954459, 0.8241632870797411, 0.7531695366379239, 0.3646777920751253, 0.1730069794906789, 0.21874024048661822, 0.5358568964872311, 0.47551419276467843, 0.20628153323937526, 0.19293708071250582, 0.3556807518123277, 0.5135870421843216, 0.5228102869050824, 0.13369273898886735, 0.44050369739322437, 0.5522563886284486, 0.6016169053748704, 0.4839857478581402, 0.15082779719095485, 0.5471450404846805, 0.4148153550362115, 0.4832774454958845, 9.999999999998899e-05, 0.11500694215686058, 9.999999999998899e-05, 9.999999999998899e-05, 0.049943542085362114, 0.0648464152124919, 0.07234910566621022, 9.999999999998899e-05, 0.22233420274687887, 0.16272696211627447, 0.10283656146932352, 0.1592162014891979, 0.08895570142164289, 0.067581050687608, 0.0719241700601071, 0.17664507225891957, 0.179273521224521, 0.1285107479143608, 0.10697799924168305, 0.07502962962610271, 0.058843065373365255, 0.07799323091271804, 0.053868856616074434, 0.11957948679203911, 0.15325148014174828, 0.14015839450507173, 0.12697240469449156, 0.3382614876131048, 0.22495016866253392, 0.20709749610244454, 0.2561092176309028, 0.1721877085741107, 0.2159696533342268, 0.3035548377022005, 0.19568055284618147, 0.23872364830927362, 0.7571908278622039, 0.5789667762521615, 0.574627118469939, 0.5449576273208666, 0.614393366392358, 0.5648722121132002, 0.6179841147401307, 0.6097621359281078, 0.5652529542981467, 0.13249710592618735, 0.1503068769286825, 0.1337751973694098, 0.12209719783953843, 0.13061509409901173, 0.13213958829374584, 0.128495104605031, 0.13431209097736851, 0.1205697445906142, 0.17214815240609127, 0.19251484725418422, 0.1540001552160808, 0.17283026328992002, 0.15437853548456026, 0.15090782990432927, 0.16502435779034352, 0.19258401185552554, 0.1303417030436318, 0.39470724615682573, 0.4774830344591037, 0.4473586918436866, 0.33377988623434707, 0.4612219277524512, 0.3568929421527428, 0.5271209825917946, 0.5676461770539578, 0.5741041876836712, 0.34862759144317956, 0.2758488245300972, 0.30644381399583, 0.26496307474482894, 0.29881485020892373, 0.2925590105060474, 0.32821714787309453, 0.2521677614709853, 0.29273535521932437, 0.2050193051559246, 0.2113046871588511, 0.19271407607029056, 0.2076794692175029, 0.2231002048726054, 0.2216539037536177, 0.2200697360433067, 0.19686461118705334, 0.21229429198214633, 0.5149953658274443, 0.6549061462894565, 0.24138900500585903, 0.20547764599939444, 0.3540887666895516, 0.5626473732816244, 0.24082261541573458, 0.396987797694473, 0.6347260419310692, 0.8786327756854402, 0.8369480401864062, 0.19707657715647342, 0.19786008444772218, 0.19890046788100368, 0.8982377863651291, 0.8799791316926804, 0.8514150359417332, 0.6290898709937082, 0.6089653414159905, 0.21189767883409039, 0.6389072542298976, 0.1641714287665974, 0.20469235805561015, 0.2092534929715978, 0.1670104784523363, 0.20865304147334973, 0.3488167997105467, 0.19707881984327646, 0.18405582755928485, 0.18397041794819669, 0.18985025239939346, 0.17240232414890178, 0.17539799384855437, 0.18454237622321468, 0.17389752937498248, 0.1919095826989079, 0.09648959712514604, 0.08967793190169726, 0.09045035813829727, 0.08169258772885768, 0.08201462859050557, 0.08554997343605752, 0.09616221653463086, 0.08727859909228286, 0.09044662833346406]}, "mutation_prompt": null}
{"id": "6f05c464-0faf-49da-a414-2a3fdb87bf46", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.85\n        self.scaling_increase_step = 0.07\n        self.reinit_threshold = 0.1\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                tournament_indices = np.random.choice(len(population), 5, replace=False)\n                x0, x1, x2 = population[tournament_indices[np.argmin(fitness[tournament_indices[:3]])]], \\\n                             population[tournament_indices[3]], population[tournament_indices[4]]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.1), replace=False)\n                for idx in random_indices:\n                    if num_evaluations >= self.budget:\n                        break\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n            \n            # Introduce local search intensification if stagnation is detected\n            if not np.any(improvement_mask) and num_evaluations < self.budget:\n                local_search_candidates = np.random.choice(len(population), 3, replace=False)\n                for idx in local_search_candidates:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    candidate = population[idx] + perturbation\n                    candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                    candidate_fitness = func(candidate)\n                    num_evaluations += 1\n                    if candidate_fitness < fitness[idx]:\n                        population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n\n        return elite_individual", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with local search intensification and dynamic population resizing for enhanced exploration and convergence.", "configspace": "", "generation": 79, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b7ae92dd-3b4b-4dd1-baf9-f38c70937821", "metadata": {"aucs": [0.8959095845141078, 0.8706728681719863, 0.8634742302495477, 0.8677589685050268, 0.8763100818478078, 0.8176903532523165, 0.8661997985551829, 0.8455657851736222, 0.8340713345991272, 0.7419940977391046, 0.7103304816851959, 0.7318033805014978, 0.7432880064232975, 0.7729209562477807, 0.7583056343080935, 0.7992127706421387, 0.7583820484448669, 0.762789741911219, 0.5980832628744248, 0.24651269334005088, 0.5768304617262617, 0.13798023253748504, 0.1604648873916854, 0.6359418171180917, 0.4529014076284913, 0.1558916844692485, 0.18280728572872984, 0.15041661401218331, 0.13680054151340704, 0.1480972453120356, 0.1608879558121491, 0.12367616100828238, 0.17272203727145874, 0.16627824227621057, 0.15938799263427905, 0.15596526273930178, 0.9463282726616835, 0.9678104892576842, 0.9676337463719548, 0.9753332687780508, 0.9674111947376378, 0.9557257535062202, 0.9585428961902459, 0.9628809468394908, 0.970431868437265, 0.6914307644535669, 0.7117675484507409, 0.5998434278103093, 0.7036859127457056, 0.6812649795696288, 0.6472882207584278, 0.7165757958405723, 0.6834973516821774, 0.7076741969223651, 0.3547876690980055, 0.8930282975734247, 0.8652608698313159, 0.9001061618623605, 0.889326124993228, 0.8681246393591243, 0.8620901807927612, 0.8859580897770105, 0.8786138772501232, 0.4664039135318775, 0.563673782054998, 0.4533236068805725, 0.34756526098319007, 0.13125610199412763, 0.47092310612951815, 0.46186268273734954, 0.6204835246550295, 0.5636558890234213, 0.36633490907134203, 0.12941621016288496, 0.45011069165055306, 0.6332732169955632, 0.492567893440495, 0.4638423877286385, 0.5260742311592603, 0.4853030900729828, 0.5623988118652294, 0.3722394219021051, 0.5221746602220374, 0.2932839522432473, 0.5889609009609156, 0.4245936628621464, 0.5532048381027419, 0.3259182621233241, 0.5764079472096897, 0.45062748175838196, 0.711517148578356, 0.6729396786912615, 0.4961078950747826, 0.5863496866489182, 0.5137171032249905, 0.47534204812455627, 0.7772901187554886, 0.7283880627746829, 0.7160516284390054, 0.24586766790839387, 0.21349330899818275, 0.07123805942264427, 0.43497273393466507, 0.379382192456999, 0.3486357302340424, 0.20457309358624576, 0.2580033648750609, 0.1998934459717101, 0.41156894518877063, 0.3954095499794865, 0.42415377083384476, 0.447280845696168, 0.5641229033867792, 0.5382082917761077, 0.5193334291390775, 0.5040170767916672, 0.5423955683553915, 0.8386884148909358, 0.8079876807256721, 0.7505909105185335, 0.7516226058425888, 0.8025416445582052, 0.820786872184763, 0.8453031430650506, 0.7421109721425602, 0.7884659461834964, 0.15088767159727778, 0.14033161343778722, 0.1558288073048648, 0.1413576171187284, 0.1371666396259561, 0.12196285562941755, 0.11267072870796435, 0.1522425411205688, 0.1385469309723154, 0.2144002325407487, 0.15875718558617713, 0.40670023798166144, 0.3942775332035, 0.24573194487562555, 0.16632900433327158, 0.42917158254674237, 0.32812293272557413, 0.2135443997322405, 0.3271360634059238, 0.6606926256143755, 0.5429129143873321, 0.6200903651143682, 0.5842503559086694, 0.42561348213178185, 0.7423902335689301, 0.7318963166151539, 0.6160800401340978, 0.3639273385301198, 0.34185498728025177, 0.471866298176412, 0.4808835233662333, 0.5709583243000429, 0.24384714871223445, 0.2339088017965647, 0.5389947700427353, 0.2313877565126491, 0.20480295901128742, 0.20402310615699237, 0.251329500281392, 0.21933544915476277, 0.2293174392733769, 0.2186419556343464, 0.22275015543363885, 0.21047605652644474, 0.2418777824439855, 0.779192733383349, 0.7621790642677698, 0.2064743381155364, 0.2476980154346229, 0.21668933879473917, 0.22363697030525298, 0.20445088309591875, 0.22054426844225206, 0.20448734435197113, 0.8855392282007896, 0.20721557538767554, 0.19724204489956498, 0.8557573368055722, 0.19986965537492252, 0.9248942716328965, 0.533007970902579, 0.19409554473540336, 0.7915790729037218, 0.903950496486096, 0.2099910673545029, 0.2050916459451676, 0.1656664810277051, 0.20659540609230076, 0.20920182293610334, 0.527801824663537, 0.20732917339185297, 0.8293052315978671, 0.20002538957146765, 0.19774949029637534, 0.1931863158849989, 0.18535285217671793, 0.18845282807229546, 0.18339102590391387, 0.19217450286979176, 0.1756536378376271, 0.18573097224555812, 0.08781909190852877, 0.08837877125881255, 0.08953782189577175, 0.09310295852623984, 0.09214333502148697, 0.09438875399527147, 0.08584889458012945, 0.1010235862490767, 0.0972800847778732]}, "mutation_prompt": null}
{"id": "d615843f-94be-4508-894e-d0dccee0bdab", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.85\n        self.scaling_increase_step = 0.07\n        self.reinit_threshold = 0.1\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                tournament_indices = np.random.choice(len(population), 5, replace=False)\n                x0, x1, x2 = population[tournament_indices[np.argmin(fitness[tournament_indices[:3]])]], \\\n                             population[tournament_indices[3]], population[tournament_indices[4]]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.1), replace=False)\n                for idx in random_indices:\n                    if num_evaluations >= self.budget:\n                        break\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n            \n            # Introduce local search intensification if stagnation is detected\n            if not np.any(improvement_mask) and num_evaluations < self.budget:\n                local_search_candidates = np.random.choice(len(population), 3, replace=False)\n                for idx in local_search_candidates:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    candidate = population[idx] + perturbation\n                    candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                    candidate_fitness = func(candidate)\n                    num_evaluations += 1\n                    if candidate_fitness < fitness[idx]:\n                        population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n\n        return elite_individual", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with local search intensification and dynamic population resizing for enhanced exploration and convergence.", "configspace": "", "generation": 79, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b7ae92dd-3b4b-4dd1-baf9-f38c70937821", "metadata": {"aucs": [0.8959095845141078, 0.8706728681719863, 0.8634742302495477, 0.8677589685050268, 0.8763100818478078, 0.8176903532523165, 0.8661997985551829, 0.8455657851736222, 0.8340713345991272, 0.7419940977391046, 0.7103304816851959, 0.7318033805014978, 0.7432880064232975, 0.7729209562477807, 0.7583056343080935, 0.7992127706421387, 0.7583820484448669, 0.762789741911219, 0.5980832628744248, 0.24651269334005088, 0.5768304617262617, 0.13798023253748504, 0.1604648873916854, 0.6359418171180917, 0.4529014076284913, 0.1558916844692485, 0.18280728572872984, 0.15041661401218331, 0.13680054151340704, 0.1480972453120356, 0.1608879558121491, 0.12367616100828238, 0.17272203727145874, 0.16627824227621057, 0.15938799263427905, 0.15596526273930178, 0.9463282726616835, 0.9678104892576842, 0.9676337463719548, 0.9753332687780508, 0.9674111947376378, 0.9557257535062202, 0.9585428961902459, 0.9628809468394908, 0.970431868437265, 0.6914307644535669, 0.7117675484507409, 0.5998434278103093, 0.7036859127457056, 0.6812649795696288, 0.6472882207584278, 0.7165757958405723, 0.6834973516821774, 0.7076741969223651, 0.3547876690980055, 0.8930282975734247, 0.8652608698313159, 0.9001061618623605, 0.889326124993228, 0.8681246393591243, 0.8620901807927612, 0.8859580897770105, 0.8786138772501232, 0.4664039135318775, 0.563673782054998, 0.4533236068805725, 0.34756526098319007, 0.13125610199412763, 0.47092310612951815, 0.46186268273734954, 0.6204835246550295, 0.5636558890234213, 0.36633490907134203, 0.12941621016288496, 0.45011069165055306, 0.6332732169955632, 0.492567893440495, 0.4638423877286385, 0.5260742311592603, 0.4853030900729828, 0.5623988118652294, 0.3722394219021051, 0.5221746602220374, 0.2932839522432473, 0.5889609009609156, 0.4245936628621464, 0.5532048381027419, 0.3259182621233241, 0.5764079472096897, 0.45062748175838196, 0.711517148578356, 0.6729396786912615, 0.4961078950747826, 0.5863496866489182, 0.5137171032249905, 0.47534204812455627, 0.7772901187554886, 0.7283880627746829, 0.7160516284390054, 0.24586766790839387, 0.21349330899818275, 0.07123805942264427, 0.43497273393466507, 0.379382192456999, 0.3486357302340424, 0.20457309358624576, 0.2580033648750609, 0.1998934459717101, 0.41156894518877063, 0.3954095499794865, 0.42415377083384476, 0.447280845696168, 0.5641229033867792, 0.5382082917761077, 0.5193334291390775, 0.5040170767916672, 0.5423955683553915, 0.8386884148909358, 0.8079876807256721, 0.7505909105185335, 0.7516226058425888, 0.8025416445582052, 0.820786872184763, 0.8453031430650506, 0.7421109721425602, 0.7884659461834964, 0.15088767159727778, 0.14033161343778722, 0.1558288073048648, 0.1413576171187284, 0.1371666396259561, 0.12196285562941755, 0.11267072870796435, 0.1522425411205688, 0.1385469309723154, 0.2144002325407487, 0.15875718558617713, 0.40670023798166144, 0.3942775332035, 0.24573194487562555, 0.16632900433327158, 0.42917158254674237, 0.32812293272557413, 0.2135443997322405, 0.3271360634059238, 0.6606926256143755, 0.5429129143873321, 0.6200903651143682, 0.5842503559086694, 0.42561348213178185, 0.7423902335689301, 0.7318963166151539, 0.6160800401340978, 0.3639273385301198, 0.34185498728025177, 0.471866298176412, 0.4808835233662333, 0.5709583243000429, 0.24384714871223445, 0.2339088017965647, 0.5389947700427353, 0.2313877565126491, 0.20480295901128742, 0.20402310615699237, 0.251329500281392, 0.21933544915476277, 0.2293174392733769, 0.2186419556343464, 0.22275015543363885, 0.21047605652644474, 0.2418777824439855, 0.779192733383349, 0.7621790642677698, 0.2064743381155364, 0.2476980154346229, 0.21668933879473917, 0.22363697030525298, 0.20445088309591875, 0.22054426844225206, 0.20448734435197113, 0.8855392282007896, 0.20721557538767554, 0.19724204489956498, 0.8557573368055722, 0.19986965537492252, 0.9248942716328965, 0.533007970902579, 0.19409554473540336, 0.7915790729037218, 0.903950496486096, 0.2099910673545029, 0.2050916459451676, 0.1656664810277051, 0.20659540609230076, 0.20920182293610334, 0.527801824663537, 0.20732917339185297, 0.8293052315978671, 0.20002538957146765, 0.19774949029637534, 0.1931863158849989, 0.18535285217671793, 0.18845282807229546, 0.18339102590391387, 0.19217450286979176, 0.1756536378376271, 0.18573097224555812, 0.08781909190852877, 0.08837877125881255, 0.08953782189577175, 0.09310295852623984, 0.09214333502148697, 0.09438875399527147, 0.08584889458012945, 0.1010235862490767, 0.0972800847778732]}, "mutation_prompt": null}
{"id": "756e5856-714d-4c07-81af-aaa2cbe4678d", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.85\n        self.scaling_increase_step = 0.07\n        self.reinit_threshold = 0.1\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                tournament_indices = np.random.choice(len(population), 5, replace=False)\n                x0, x1, x2 = population[tournament_indices[np.argmin(fitness[tournament_indices[:3]])]], \\\n                             population[tournament_indices[3]], population[tournament_indices[4]]\n                mutant_vector = x0 + scaling_factor * (x1 - x2 + (elite_individual - x0) * 0.5)  # Enhanced mutation strategy\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.1), replace=False)\n                for idx in random_indices:\n                    if num_evaluations >= self.budget:\n                        break\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n            \n            # Focused local search intensification if stagnation is detected\n            if not np.any(improvement_mask) and num_evaluations < self.budget:\n                local_search_candidates = np.random.choice(len(population), 4, replace=False)  # Increased candidates\n                for idx in local_search_candidates:\n                    perturbation = np.random.normal(0, 0.05, self.dim)  # Reduced perturbation scale\n                    candidate = population[idx] + perturbation\n                    candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                    candidate_fitness = func(candidate)\n                    num_evaluations += 1\n                    if candidate_fitness < fitness[idx]:\n                        population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n\n        return elite_individual", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with strategic mutation and focused local search enhancements for improved global exploration and convergence efficiency.", "configspace": "", "generation": 88, "fitness": 0.5136609025987041, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.51 with standard deviation 0.29.", "error": "", "parent_id": "b7ae92dd-3b4b-4dd1-baf9-f38c70937821", "metadata": {"aucs": [0.8897019492326745, 0.8800356139514375, 0.8806999954121832, 0.865296230570566, 0.8617805963319174, 0.8770039322882728, 0.8832763724139853, 0.8767676699727487, 0.881650511356954, 0.8515359102245665, 0.8514678185557721, 0.7440809740807814, 0.7676618899088409, 0.7837326814659813, 0.7717694427047063, 0.8246824969677182, 0.8220986054289889, 0.7799523578147053, 0.17605668463394963, 0.7781575083470108, 0.17481915059248931, 0.14189237447770198, 0.18594561066096593, 0.18439443653806975, 0.18246363556163236, 0.7888237446135083, 0.18445904384270506, 0.13369095291363553, 0.16188227619363715, 0.12752964384754106, 0.15985648225783988, 0.11097068672015487, 0.11632083244013469, 0.16116730781673994, 0.17904333153221708, 0.1612401280957524, 0.9767110735494459, 0.9769859501897222, 0.9627979126660765, 0.9809112693182923, 0.9601454158947701, 0.9333587668222346, 0.950557552542756, 0.9660821928674613, 0.9574816870165602, 0.7631731649157398, 0.7365905502563268, 0.7302105877996875, 0.6926416033042804, 0.7324611916550492, 0.7403389856969589, 0.7468144064579865, 0.7079114209533641, 0.706069978007074, 0.3652704042540883, 0.8924836936527777, 0.22658690353061095, 0.9269468274737938, 0.8651144875966059, 0.8394058564727074, 0.8876385948561123, 0.901054933121606, 0.9202643489773751, 0.5523044885767365, 0.6239309708874354, 0.645167384504044, 0.6304040478401296, 0.6181333417924803, 0.13192638421452774, 0.6631293902972498, 0.6103373781826373, 0.6968863550438322, 0.6493821882956583, 0.6416917151779827, 0.49133132405215596, 0.7135367581825216, 0.571277518784179, 0.6128773510963748, 0.5872370190080238, 0.5594977720004686, 0.6344746984508589, 0.525269672697814, 0.6893539543034322, 0.654401072217736, 0.5897993411951536, 0.6999719683965179, 0.6731168537817243, 0.68957420674933, 0.6825779126279512, 0.6923326351895895, 0.7476499822700746, 0.6797023760111064, 0.7682050456313015, 0.7127057467481216, 0.7778225362647903, 0.8076522032573554, 0.7413950374912761, 0.7314713607306229, 0.8078786032513208, 0.4750398765843422, 0.12673462492151288, 0.24226044123274493, 0.6817386676005208, 0.47001974602755336, 0.4520876426063025, 0.3019069794203586, 0.3617567888519645, 0.2968418421838901, 0.6267508919788797, 0.5747418389804764, 0.5502889990964468, 0.5807341245246709, 0.5858859587625465, 0.5517493458837457, 0.6066836094486443, 0.5809367275518161, 0.4682554304956694, 0.8191949155378896, 0.8226639385754547, 0.8201491986071159, 0.8393739970021963, 0.8084091562728297, 0.8256930057194525, 0.8492629360825141, 0.8616011415664881, 0.815562649079826, 0.1122655266867374, 0.1551345326204857, 0.13037277152528548, 0.10066149957001691, 0.15049444021270464, 0.14456218278885047, 0.15559897969634606, 0.16210871295568574, 0.14292166919712068, 0.16743278972332465, 0.6891341007635123, 0.41211160963825333, 0.7201803458718778, 0.4259301807091479, 0.6319151081163692, 0.22988870781228488, 0.3375742335842884, 0.2680687034213819, 0.5672952407318457, 0.7126565392666302, 0.42617949777767083, 0.7628907109222546, 0.6958118987469316, 0.4456305946574476, 0.5365933056345245, 0.654202734958188, 0.6173677064916292, 0.38493705635540354, 0.3390297658867728, 0.21892077795216658, 0.41537405182477205, 0.48157017226539334, 0.6580234393302296, 0.30703337555475096, 0.4513633309149446, 0.16061846310325179, 0.24111298970741546, 0.21889180141230613, 0.2680736039745215, 0.24296310640315688, 0.22447083601614426, 0.3807300393986274, 0.31952755214519835, 0.26282647052466923, 0.22238813161938775, 0.20982550820793588, 0.24827936268338424, 0.228520819373918, 0.8455514982504009, 0.21313223179469298, 0.1974534959194253, 0.2162450559933976, 0.22557131253869145, 0.2148198848604267, 0.8806922860984083, 0.18734294450406674, 0.1579548687090233, 0.8831819556393852, 0.20028586453718433, 0.9128215862717574, 0.9106495450753361, 0.16884676996873882, 0.16490864857168708, 0.9177849771310955, 0.21222614292522368, 0.20380641083758577, 0.850942914062171, 0.8209587153003804, 0.9075031577617014, 0.1665129896511648, 0.21135693193302252, 0.1562759892373342, 0.19466375436108607, 0.18071359458763459, 0.20048682860076805, 0.1749795377314094, 0.1889429997233446, 0.19801473939578385, 0.1911047159883098, 0.18776487553542742, 0.19277769785688292, 0.0889652964483385, 0.08879080156587082, 0.08830791413783023, 0.09020050414969172, 0.07926250965069337, 0.10140880769184568, 0.08526120816490235, 0.09512278745272618, 0.1090455225537702]}, "mutation_prompt": null}
{"id": "e74494bd-77b3-4f4d-890e-86c717bb6e8d", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.85\n        self.scaling_increase_step = 0.07\n        self.reinit_threshold = 0.1\n\n        # Dynamic population sizing based on budget and dimension\n        self.population_size = max(4 * dim, int(budget / 25))\n        self.elite_archive = []\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                tournament_indices = np.random.choice(len(population), 5, replace=False)\n                x0, x1, x2 = population[tournament_indices[np.argmin(fitness[tournament_indices[:3]])]], \\\n                             population[tournament_indices[3]], population[tournament_indices[4]]\n                mutant_vector = x0 + scaling_factor * (x1 - x2)  # Simplified mutation\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            current_best_individual = population[best_idx]\n            \n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = current_best_individual\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            # Archive elite individuals\n            if len(self.elite_archive) < 3 or fitness[best_idx] < np.max([func(ind) for ind in self.elite_archive]):\n                self.elite_archive.append(current_best_individual)\n                self.elite_archive = sorted(self.elite_archive, key=func)[:3]\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.1), replace=False)\n                for idx in random_indices:\n                    if num_evaluations >= self.budget:\n                        break\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n\n            # Introduce best from archive if stagnation is detected\n            if not np.any(improvement_mask) and num_evaluations < self.budget:\n                for elite in self.elite_archive:\n                    candidate = elite + np.random.normal(0, 0.01, self.dim)\n                    candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                    candidate_fitness = func(candidate)\n                    num_evaluations += 1\n                    if candidate_fitness < np.max(fitness):\n                        worst_idx = np.argmax(fitness)\n                        population[worst_idx] = candidate\n                        fitness[worst_idx] = candidate_fitness\n\n        return elite_individual", "name": "AdaptiveDifferentialEvolution", "description": "A refined Adaptive Differential Evolution that incorporates a dynamic population resizing and elite preservation strategy to enhance exploration and convergence.", "configspace": "", "generation": 89, "fitness": 0.16159830470340128, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.16.", "error": "", "parent_id": "756e5856-714d-4c07-81af-aaa2cbe4678d", "metadata": {"aucs": [0.3058945615348987, 0.28937520326270094, 0.31416828972576416, 0.33176050802691803, 0.2689861826599248, 0.28606277500629085, 0.2920087858460303, 0.2640412516557512, 0.33009407016399916, 0.02768488895116028, 0.0026169828327742284, 0.007204329445645308, 0.028852320730891168, 0.000513347769683925, 0.011642377287956918, 0.013051634880104968, 0.06609258446318178, 0.06029427712509805, 0.08400573711277559, 0.07206772750086221, 0.09094815613500906, 0.0808055944112599, 0.07933804302544212, 0.08561590437794786, 0.09563108629073669, 0.08172397536997034, 0.07343249779623184, 0.07575447128520829, 0.0682720184433383, 0.05526673073839905, 0.0858591822423519, 0.06978469260186726, 0.055178981625712, 0.062260483306239234, 0.057076784610387454, 0.05642048216921225, 0.7676927275171005, 0.737045591190174, 0.8121362748873192, 0.7890587314602537, 0.7886103852819424, 0.8477208345945167, 0.8714486990324188, 0.8011575227862763, 0.7593968535676383, 0.15674132530389595, 0.12023032302913506, 0.15005694690919014, 0.14923874922454305, 0.14998023774210145, 0.11021159110539047, 0.11372020521043213, 0.09724956692584019, 0.14912165236000952, 0.21294203943315526, 0.25179435647415693, 0.21882713869454173, 0.18991681794238569, 0.2163420630262025, 0.19277454287926699, 0.20220998258083378, 0.2840942154597502, 0.1955113755867528, 0.11445008250211464, 0.09632890989595266, 0.07548268660758617, 0.06210497663934256, 0.06032237100680271, 0.07559619775158621, 0.09485310918306755, 0.07120404017584225, 0.11238959603550125, 0.10585531141833981, 0.08053031238803454, 0.05757726631905247, 0.1042214796523655, 0.11551057042343438, 0.05052893671648073, 0.11510739913688972, 0.08071575593038616, 0.10051807326303919, 0.0033480037720408085, 0.0008288759566974502, 0.00849739647016945, 9.999999999998899e-05, 0.010300254339386306, 9.999999999998899e-05, 0.0047007355999723055, 0.0038308586450513937, 9.999999999998899e-05, 0.10422489962946235, 0.11958694078731391, 0.10115587201591225, 0.14920637529678427, 0.13593662982025378, 0.1033345487584969, 0.09643559100443344, 0.08544320820400242, 0.0886823806804008, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.026812277908590643, 0.02670262675112811, 0.0241494923143728, 0.020834965945388473, 0.022336058548629967, 0.046869168206211564, 0.04640932974272016, 0.03552535056389228, 0.022769955992760882, 0.2852144196353952, 0.2658742634931912, 0.2669267689281313, 0.31912154989706143, 0.2960697816539397, 0.31400941284417194, 0.28539277416848596, 0.2928516912336818, 0.25913376613490624, 0.08049148381345439, 0.0739127109985076, 0.0681136941085837, 0.07944136041480432, 0.08499708312578202, 0.07256671101770262, 0.06543433087417416, 0.08738262199736313, 0.07125789295504747, 0.1546599463400855, 0.14385959551541838, 0.16148645345607515, 0.16369921106736296, 0.14913191946515958, 0.15956268330654255, 0.14963138758589234, 0.138109006089998, 0.13161200787476846, 0.21947409743152602, 0.2068711308007195, 0.2097698636173051, 0.23531177188704822, 0.24016361960400334, 0.23894826738986363, 0.20254580644220654, 0.23806222005927757, 0.20858113053245775, 0.1579569875696678, 0.15469613248759018, 0.14991196757986358, 0.16954121462098737, 0.17123814077403932, 0.16338331560841268, 0.1545501076836061, 0.17590165184407447, 0.13947682372733594, 0.18254298126400292, 0.17877973315157836, 0.17950306209692768, 0.19338278989187363, 0.18692369965187106, 0.19475042458957847, 0.2076546517126423, 0.1823312382649519, 0.1931806341751222, 0.1587584920595615, 0.17254409294812667, 0.16179426713938405, 0.1555977359973948, 0.16913297647237557, 0.1637978777053526, 0.15855720981266308, 0.16820135014566417, 0.1779516560948976, 0.220392178831871, 0.20621642718040833, 0.27035898704978745, 0.272729262343512, 0.23613871252534513, 0.1639695599137504, 0.3008713330445135, 0.19505576711555372, 0.2807018519047527, 0.23920549120978607, 0.178971124777918, 0.22696489840602552, 0.17302931330583105, 0.16191409349891472, 0.14826439001072345, 0.20567770598315027, 0.22476164305226365, 0.1801135977028735, 0.18212218464006835, 0.19707269587646936, 0.22115123001678616, 0.1816528462726551, 0.1786120356542671, 0.1834208495892119, 0.1873751329635014, 0.17955922681668524, 0.18311479868738278, 0.07407025371971743, 0.08411666377752425, 0.06606296873242679, 0.07270992970245227, 0.07358859905838566, 0.08083423316422889, 0.07060204278964699, 0.06856121508115043, 0.06612037808864912]}, "mutation_prompt": null}
{"id": "b43dcc64-776f-4f57-af2c-d4e0c107f56b", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.85\n        self.scaling_increase_step = 0.07\n        self.reinit_threshold = 0.1\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                tournament_indices = np.random.choice(len(population), 5, replace=False)\n                x0, x1, x2 = population[tournament_indices[np.argmin(fitness[tournament_indices[:3]])]], \\\n                             population[tournament_indices[3]], population[tournament_indices[4]]\n                mutant_vector = x0 + scaling_factor * (x1 - x2 + (elite_individual - x0) * 0.5)  # Enhanced mutation strategy\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.1), replace=False)\n                for idx in random_indices:\n                    if num_evaluations >= self.budget:\n                        break\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n            \n            # Focused local search intensification if stagnation is detected\n            if not np.any(improvement_mask) and num_evaluations < self.budget:\n                local_search_candidates = np.random.choice(len(population), 4, replace=False)  # Increased candidates\n                for idx in local_search_candidates:\n                    perturbation = np.random.normal(0, 0.05, self.dim)  # Reduced perturbation scale\n                    candidate = population[idx] + perturbation\n                    candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                    candidate_fitness = func(candidate)\n                    num_evaluations += 1\n                    if candidate_fitness < fitness[idx]:\n                        population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n\n        return elite_individual", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with strategic mutation and focused local search enhancements for improved global exploration and convergence efficiency.", "configspace": "", "generation": 89, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "756e5856-714d-4c07-81af-aaa2cbe4678d", "metadata": {"aucs": [0.8897019492326745, 0.8800356139514375, 0.8806999954121832, 0.865296230570566, 0.8617805963319174, 0.8770039322882728, 0.8832763724139853, 0.8767676699727487, 0.881650511356954, 0.8515359102245665, 0.8514678185557721, 0.7440809740807814, 0.7676618899088409, 0.7837326814659813, 0.7717694427047063, 0.8246824969677182, 0.8220986054289889, 0.7799523578147053, 0.17605668463394963, 0.7781575083470108, 0.17481915059248931, 0.14189237447770198, 0.18594561066096593, 0.18439443653806975, 0.18246363556163236, 0.7888237446135083, 0.18445904384270506, 0.13369095291363553, 0.16188227619363715, 0.12752964384754106, 0.15985648225783988, 0.11097068672015487, 0.11632083244013469, 0.16116730781673994, 0.17904333153221708, 0.1612401280957524, 0.9767110735494459, 0.9769859501897222, 0.9627979126660765, 0.9809112693182923, 0.9601454158947701, 0.9333587668222346, 0.950557552542756, 0.9660821928674613, 0.9574816870165602, 0.7631731649157398, 0.7365905502563268, 0.7302105877996875, 0.6926416033042804, 0.7324611916550492, 0.7403389856969589, 0.7468144064579865, 0.7079114209533641, 0.706069978007074, 0.3652704042540883, 0.8924836936527777, 0.22658690353061095, 0.9269468274737938, 0.8651144875966059, 0.8394058564727074, 0.8876385948561123, 0.901054933121606, 0.9202643489773751, 0.5523044885767365, 0.6239309708874354, 0.645167384504044, 0.6304040478401296, 0.6181333417924803, 0.13192638421452774, 0.6631293902972498, 0.6103373781826373, 0.6968863550438322, 0.6493821882956583, 0.6416917151779827, 0.49133132405215596, 0.7135367581825216, 0.571277518784179, 0.6128773510963748, 0.5872370190080238, 0.5594977720004686, 0.6344746984508589, 0.525269672697814, 0.6893539543034322, 0.654401072217736, 0.5897993411951536, 0.6999719683965179, 0.6731168537817243, 0.68957420674933, 0.6825779126279512, 0.6923326351895895, 0.7476499822700746, 0.6797023760111064, 0.7682050456313015, 0.7127057467481216, 0.7778225362647903, 0.8076522032573554, 0.7413950374912761, 0.7314713607306229, 0.8078786032513208, 0.4750398765843422, 0.12673462492151288, 0.24226044123274493, 0.6817386676005208, 0.47001974602755336, 0.4520876426063025, 0.3019069794203586, 0.3617567888519645, 0.2968418421838901, 0.6267508919788797, 0.5747418389804764, 0.5502889990964468, 0.5807341245246709, 0.5858859587625465, 0.5517493458837457, 0.6066836094486443, 0.5809367275518161, 0.4682554304956694, 0.8191949155378896, 0.8226639385754547, 0.8201491986071159, 0.8393739970021963, 0.8084091562728297, 0.8256930057194525, 0.8492629360825141, 0.8616011415664881, 0.815562649079826, 0.1122655266867374, 0.1551345326204857, 0.13037277152528548, 0.10066149957001691, 0.15049444021270464, 0.14456218278885047, 0.15559897969634606, 0.16210871295568574, 0.14292166919712068, 0.16743278972332465, 0.6891341007635123, 0.41211160963825333, 0.7201803458718778, 0.4259301807091479, 0.6319151081163692, 0.22988870781228488, 0.3375742335842884, 0.2680687034213819, 0.5672952407318457, 0.7126565392666302, 0.42617949777767083, 0.7628907109222546, 0.6958118987469316, 0.4456305946574476, 0.5365933056345245, 0.654202734958188, 0.6173677064916292, 0.38493705635540354, 0.3390297658867728, 0.21892077795216658, 0.41537405182477205, 0.48157017226539334, 0.6580234393302296, 0.30703337555475096, 0.4513633309149446, 0.16061846310325179, 0.24111298970741546, 0.21889180141230613, 0.2680736039745215, 0.24296310640315688, 0.22447083601614426, 0.3807300393986274, 0.31952755214519835, 0.26282647052466923, 0.22238813161938775, 0.20982550820793588, 0.24827936268338424, 0.228520819373918, 0.8455514982504009, 0.21313223179469298, 0.1974534959194253, 0.2162450559933976, 0.22557131253869145, 0.2148198848604267, 0.8806922860984083, 0.18734294450406674, 0.1579548687090233, 0.8831819556393852, 0.20028586453718433, 0.9128215862717574, 0.9106495450753361, 0.16884676996873882, 0.16490864857168708, 0.9177849771310955, 0.21222614292522368, 0.20380641083758577, 0.850942914062171, 0.8209587153003804, 0.9075031577617014, 0.1665129896511648, 0.21135693193302252, 0.1562759892373342, 0.19466375436108607, 0.18071359458763459, 0.20048682860076805, 0.1749795377314094, 0.1889429997233446, 0.19801473939578385, 0.1911047159883098, 0.18776487553542742, 0.19277769785688292, 0.0889652964483385, 0.08879080156587082, 0.08830791413783023, 0.09020050414969172, 0.07926250965069337, 0.10140880769184568, 0.08526120816490235, 0.09512278745272618, 0.1090455225537702]}, "mutation_prompt": null}
{"id": "515c3129-44ba-4f16-95f3-6a1914a92e2d", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.85\n        self.scaling_increase_step = 0.07\n        self.reinit_threshold = 0.1\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                tournament_indices = np.random.choice(len(population), 5, replace=False)\n                x0, x1, x2 = population[tournament_indices[np.argmin(fitness[tournament_indices[:3]])]], \\\n                             population[tournament_indices[3]], population[tournament_indices[4]]\n                mutant_vector = x0 + scaling_factor * (x1 - x2 + (elite_individual - x0) * 0.5)  # Enhanced mutation strategy\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.1), replace=False)\n                for idx in random_indices:\n                    if num_evaluations >= self.budget:\n                        break\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n            \n            # Focused local search intensification if stagnation is detected\n            if not np.any(improvement_mask) and num_evaluations < self.budget:\n                local_search_candidates = np.random.choice(len(population), 4, replace=False)  # Increased candidates\n                for idx in local_search_candidates:\n                    perturbation = np.random.normal(0, 0.05, self.dim)  # Reduced perturbation scale\n                    candidate = population[idx] + perturbation\n                    candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                    candidate_fitness = func(candidate)\n                    num_evaluations += 1\n                    if candidate_fitness < fitness[idx]:\n                        population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n\n        return elite_individual", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with strategic mutation and focused local search enhancements for improved global exploration and convergence efficiency.", "configspace": "", "generation": 89, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "756e5856-714d-4c07-81af-aaa2cbe4678d", "metadata": {"aucs": [0.8897019492326745, 0.8800356139514375, 0.8806999954121832, 0.865296230570566, 0.8617805963319174, 0.8770039322882728, 0.8832763724139853, 0.8767676699727487, 0.881650511356954, 0.8515359102245665, 0.8514678185557721, 0.7440809740807814, 0.7676618899088409, 0.7837326814659813, 0.7717694427047063, 0.8246824969677182, 0.8220986054289889, 0.7799523578147053, 0.17605668463394963, 0.7781575083470108, 0.17481915059248931, 0.14189237447770198, 0.18594561066096593, 0.18439443653806975, 0.18246363556163236, 0.7888237446135083, 0.18445904384270506, 0.13369095291363553, 0.16188227619363715, 0.12752964384754106, 0.15985648225783988, 0.11097068672015487, 0.11632083244013469, 0.16116730781673994, 0.17904333153221708, 0.1612401280957524, 0.9767110735494459, 0.9769859501897222, 0.9627979126660765, 0.9809112693182923, 0.9601454158947701, 0.9333587668222346, 0.950557552542756, 0.9660821928674613, 0.9574816870165602, 0.7631731649157398, 0.7365905502563268, 0.7302105877996875, 0.6926416033042804, 0.7324611916550492, 0.7403389856969589, 0.7468144064579865, 0.7079114209533641, 0.706069978007074, 0.3652704042540883, 0.8924836936527777, 0.22658690353061095, 0.9269468274737938, 0.8651144875966059, 0.8394058564727074, 0.8876385948561123, 0.901054933121606, 0.9202643489773751, 0.5523044885767365, 0.6239309708874354, 0.645167384504044, 0.6304040478401296, 0.6181333417924803, 0.13192638421452774, 0.6631293902972498, 0.6103373781826373, 0.6968863550438322, 0.6493821882956583, 0.6416917151779827, 0.49133132405215596, 0.7135367581825216, 0.571277518784179, 0.6128773510963748, 0.5872370190080238, 0.5594977720004686, 0.6344746984508589, 0.525269672697814, 0.6893539543034322, 0.654401072217736, 0.5897993411951536, 0.6999719683965179, 0.6731168537817243, 0.68957420674933, 0.6825779126279512, 0.6923326351895895, 0.7476499822700746, 0.6797023760111064, 0.7682050456313015, 0.7127057467481216, 0.7778225362647903, 0.8076522032573554, 0.7413950374912761, 0.7314713607306229, 0.8078786032513208, 0.4750398765843422, 0.12673462492151288, 0.24226044123274493, 0.6817386676005208, 0.47001974602755336, 0.4520876426063025, 0.3019069794203586, 0.3617567888519645, 0.2968418421838901, 0.6267508919788797, 0.5747418389804764, 0.5502889990964468, 0.5807341245246709, 0.5858859587625465, 0.5517493458837457, 0.6066836094486443, 0.5809367275518161, 0.4682554304956694, 0.8191949155378896, 0.8226639385754547, 0.8201491986071159, 0.8393739970021963, 0.8084091562728297, 0.8256930057194525, 0.8492629360825141, 0.8616011415664881, 0.815562649079826, 0.1122655266867374, 0.1551345326204857, 0.13037277152528548, 0.10066149957001691, 0.15049444021270464, 0.14456218278885047, 0.15559897969634606, 0.16210871295568574, 0.14292166919712068, 0.16743278972332465, 0.6891341007635123, 0.41211160963825333, 0.7201803458718778, 0.4259301807091479, 0.6319151081163692, 0.22988870781228488, 0.3375742335842884, 0.2680687034213819, 0.5672952407318457, 0.7126565392666302, 0.42617949777767083, 0.7628907109222546, 0.6958118987469316, 0.4456305946574476, 0.5365933056345245, 0.654202734958188, 0.6173677064916292, 0.38493705635540354, 0.3390297658867728, 0.21892077795216658, 0.41537405182477205, 0.48157017226539334, 0.6580234393302296, 0.30703337555475096, 0.4513633309149446, 0.16061846310325179, 0.24111298970741546, 0.21889180141230613, 0.2680736039745215, 0.24296310640315688, 0.22447083601614426, 0.3807300393986274, 0.31952755214519835, 0.26282647052466923, 0.22238813161938775, 0.20982550820793588, 0.24827936268338424, 0.228520819373918, 0.8455514982504009, 0.21313223179469298, 0.1974534959194253, 0.2162450559933976, 0.22557131253869145, 0.2148198848604267, 0.8806922860984083, 0.18734294450406674, 0.1579548687090233, 0.8831819556393852, 0.20028586453718433, 0.9128215862717574, 0.9106495450753361, 0.16884676996873882, 0.16490864857168708, 0.9177849771310955, 0.21222614292522368, 0.20380641083758577, 0.850942914062171, 0.8209587153003804, 0.9075031577617014, 0.1665129896511648, 0.21135693193302252, 0.1562759892373342, 0.19466375436108607, 0.18071359458763459, 0.20048682860076805, 0.1749795377314094, 0.1889429997233446, 0.19801473939578385, 0.1911047159883098, 0.18776487553542742, 0.19277769785688292, 0.0889652964483385, 0.08879080156587082, 0.08830791413783023, 0.09020050414969172, 0.07926250965069337, 0.10140880769184568, 0.08526120816490235, 0.09512278745272618, 0.1090455225537702]}, "mutation_prompt": null}
{"id": "67a01e72-f79d-4ad9-8645-5d0a1df1f98d", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.85\n        self.scaling_increase_step = 0.07\n        self.reinit_threshold = 0.1\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                tournament_indices = np.random.choice(len(population), 5, replace=False)\n                x0, x1, x2 = population[tournament_indices[np.argmin(fitness[tournament_indices[:3]])]], \\\n                             population[tournament_indices[3]], population[tournament_indices[4]]\n                mutant_vector = x0 + scaling_factor * (x1 - x2 + (elite_individual - x0) * 0.5)  # Enhanced mutation strategy\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.1), replace=False)\n                for idx in random_indices:\n                    if num_evaluations >= self.budget:\n                        break\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n            \n            # Focused local search intensification if stagnation is detected\n            if not np.any(improvement_mask) and num_evaluations < self.budget:\n                local_search_candidates = np.random.choice(len(population), 4, replace=False)  # Increased candidates\n                for idx in local_search_candidates:\n                    perturbation = np.random.normal(0, 0.05, self.dim)  # Reduced perturbation scale\n                    candidate = population[idx] + perturbation\n                    candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                    candidate_fitness = func(candidate)\n                    num_evaluations += 1\n                    if candidate_fitness < fitness[idx]:\n                        population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n\n        return elite_individual", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with strategic mutation and focused local search enhancements for improved global exploration and convergence efficiency.", "configspace": "", "generation": 89, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "756e5856-714d-4c07-81af-aaa2cbe4678d", "metadata": {"aucs": [0.8897019492326745, 0.8800356139514375, 0.8806999954121832, 0.865296230570566, 0.8617805963319174, 0.8770039322882728, 0.8832763724139853, 0.8767676699727487, 0.881650511356954, 0.8515359102245665, 0.8514678185557721, 0.7440809740807814, 0.7676618899088409, 0.7837326814659813, 0.7717694427047063, 0.8246824969677182, 0.8220986054289889, 0.7799523578147053, 0.17605668463394963, 0.7781575083470108, 0.17481915059248931, 0.14189237447770198, 0.18594561066096593, 0.18439443653806975, 0.18246363556163236, 0.7888237446135083, 0.18445904384270506, 0.13369095291363553, 0.16188227619363715, 0.12752964384754106, 0.15985648225783988, 0.11097068672015487, 0.11632083244013469, 0.16116730781673994, 0.17904333153221708, 0.1612401280957524, 0.9767110735494459, 0.9769859501897222, 0.9627979126660765, 0.9809112693182923, 0.9601454158947701, 0.9333587668222346, 0.950557552542756, 0.9660821928674613, 0.9574816870165602, 0.7631731649157398, 0.7365905502563268, 0.7302105877996875, 0.6926416033042804, 0.7324611916550492, 0.7403389856969589, 0.7468144064579865, 0.7079114209533641, 0.706069978007074, 0.3652704042540883, 0.8924836936527777, 0.22658690353061095, 0.9269468274737938, 0.8651144875966059, 0.8394058564727074, 0.8876385948561123, 0.901054933121606, 0.9202643489773751, 0.5523044885767365, 0.6239309708874354, 0.645167384504044, 0.6304040478401296, 0.6181333417924803, 0.13192638421452774, 0.6631293902972498, 0.6103373781826373, 0.6968863550438322, 0.6493821882956583, 0.6416917151779827, 0.49133132405215596, 0.7135367581825216, 0.571277518784179, 0.6128773510963748, 0.5872370190080238, 0.5594977720004686, 0.6344746984508589, 0.525269672697814, 0.6893539543034322, 0.654401072217736, 0.5897993411951536, 0.6999719683965179, 0.6731168537817243, 0.68957420674933, 0.6825779126279512, 0.6923326351895895, 0.7476499822700746, 0.6797023760111064, 0.7682050456313015, 0.7127057467481216, 0.7778225362647903, 0.8076522032573554, 0.7413950374912761, 0.7314713607306229, 0.8078786032513208, 0.4750398765843422, 0.12673462492151288, 0.24226044123274493, 0.6817386676005208, 0.47001974602755336, 0.4520876426063025, 0.3019069794203586, 0.3617567888519645, 0.2968418421838901, 0.6267508919788797, 0.5747418389804764, 0.5502889990964468, 0.5807341245246709, 0.5858859587625465, 0.5517493458837457, 0.6066836094486443, 0.5809367275518161, 0.4682554304956694, 0.8191949155378896, 0.8226639385754547, 0.8201491986071159, 0.8393739970021963, 0.8084091562728297, 0.8256930057194525, 0.8492629360825141, 0.8616011415664881, 0.815562649079826, 0.1122655266867374, 0.1551345326204857, 0.13037277152528548, 0.10066149957001691, 0.15049444021270464, 0.14456218278885047, 0.15559897969634606, 0.16210871295568574, 0.14292166919712068, 0.16743278972332465, 0.6891341007635123, 0.41211160963825333, 0.7201803458718778, 0.4259301807091479, 0.6319151081163692, 0.22988870781228488, 0.3375742335842884, 0.2680687034213819, 0.5672952407318457, 0.7126565392666302, 0.42617949777767083, 0.7628907109222546, 0.6958118987469316, 0.4456305946574476, 0.5365933056345245, 0.654202734958188, 0.6173677064916292, 0.38493705635540354, 0.3390297658867728, 0.21892077795216658, 0.41537405182477205, 0.48157017226539334, 0.6580234393302296, 0.30703337555475096, 0.4513633309149446, 0.16061846310325179, 0.24111298970741546, 0.21889180141230613, 0.2680736039745215, 0.24296310640315688, 0.22447083601614426, 0.3807300393986274, 0.31952755214519835, 0.26282647052466923, 0.22238813161938775, 0.20982550820793588, 0.24827936268338424, 0.228520819373918, 0.8455514982504009, 0.21313223179469298, 0.1974534959194253, 0.2162450559933976, 0.22557131253869145, 0.2148198848604267, 0.8806922860984083, 0.18734294450406674, 0.1579548687090233, 0.8831819556393852, 0.20028586453718433, 0.9128215862717574, 0.9106495450753361, 0.16884676996873882, 0.16490864857168708, 0.9177849771310955, 0.21222614292522368, 0.20380641083758577, 0.850942914062171, 0.8209587153003804, 0.9075031577617014, 0.1665129896511648, 0.21135693193302252, 0.1562759892373342, 0.19466375436108607, 0.18071359458763459, 0.20048682860076805, 0.1749795377314094, 0.1889429997233446, 0.19801473939578385, 0.1911047159883098, 0.18776487553542742, 0.19277769785688292, 0.0889652964483385, 0.08879080156587082, 0.08830791413783023, 0.09020050414969172, 0.07926250965069337, 0.10140880769184568, 0.08526120816490235, 0.09512278745272618, 0.1090455225537702]}, "mutation_prompt": null}
{"id": "988739ac-545b-4d41-84f7-df5bfd8ff8f3", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.85\n        self.scaling_increase_step = 0.07\n        self.reinit_threshold = 0.1\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                tournament_indices = np.random.choice(len(population), 5, replace=False)\n                x0, x1, x2 = population[tournament_indices[np.argmin(fitness[tournament_indices[:3]])]], \\\n                             population[tournament_indices[3]], population[tournament_indices[4]]\n                mutant_vector = x0 + scaling_factor * (x1 - x2 + (elite_individual - x0) * 0.5)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                dynamic_crossover_rate = self.crossover_rate * (1 - num_evaluations / self.budget)\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.1), replace=False)\n                for idx in random_indices:\n                    if num_evaluations >= self.budget:\n                        break\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n            \n            if not np.any(improvement_mask) and num_evaluations < self.budget:\n                local_search_candidates = np.random.choice(len(population), 4, replace=False)\n                for idx in local_search_candidates:\n                    perturbation = np.random.normal(0, 0.05, self.dim)\n                    candidate = population[idx] + perturbation\n                    candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                    candidate_fitness = func(candidate)\n                    num_evaluations += 1\n                    if candidate_fitness < fitness[idx]:\n                        population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n\n        return elite_individual", "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with dynamic adaptation of mutation and crossover rates for improved convergence and exploration.", "configspace": "", "generation": 93, "fitness": 0.40374823138544436, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.29.", "error": "", "parent_id": "756e5856-714d-4c07-81af-aaa2cbe4678d", "metadata": {"aucs": [0.8855279875930938, 0.875776811905447, 0.8686130352989516, 0.8869516607916234, 0.8831519200092351, 0.8813961066150913, 0.8667737062147487, 0.8948827706237761, 0.8762082896944398, 0.8446770318145304, 0.8157116351165965, 0.7500314706911823, 0.775407134290393, 0.8063291164853328, 0.8051554125131153, 0.8058245888914266, 0.7343973851258514, 0.8031261211823549, 0.18376029956866458, 0.19481645320572216, 0.6802126363070786, 0.30754389054365394, 0.7636701604570488, 0.6928580152114483, 0.19912371416086017, 0.6158179331418343, 0.17720836861940903, 0.15521821382793655, 0.23042212608907098, 0.1527698952891533, 0.1469618387743563, 0.4918249803336201, 0.15527483841591982, 0.170387261700914, 0.18884483624941062, 0.1531992901690452, 0.9767206421473635, 0.9684399165473274, 0.9591756432230744, 0.9809112693182923, 0.9638973453209523, 0.9692152566439949, 0.9573518867404585, 0.9637214399300795, 0.9527648067881382, 0.6753246102217916, 0.6414027437910064, 0.6410792365282849, 0.644518519927751, 0.675308873899773, 0.7172331863422972, 0.5604952831406911, 0.5682659249760202, 0.6085145925616451, 0.8952370765763111, 0.8522113020743979, 0.8983096025606176, 0.8925188918375015, 0.890434500713654, 0.8860706673469404, 0.8566782028137258, 0.9276374031303463, 0.8906447475787961, 0.20105207193517538, 0.20391203550787218, 0.21236167870061495, 0.20459750283748324, 0.20067079565288293, 0.21459896439568615, 0.19688476981172176, 0.21095328923707557, 0.2278456433226136, 0.21189441847517276, 0.24417935808058855, 0.12983395339875226, 0.22236659139585624, 0.24505299624258015, 0.20015652023504515, 0.1992144869425122, 0.2376689682001566, 0.22284345332242517, 0.26310600357916314, 0.19986822368953672, 0.07287188236029885, 0.06574724559479983, 0.004965668236805998, 0.13963165908757824, 0.04241333583746054, 0.11687762484033648, 0.14270614416617333, 0.19569046752560704, 0.20800645789565708, 0.1303790448587313, 0.26210360840538893, 0.20710240121850387, 0.06804045900323852, 0.14603145249374005, 0.35555302410554546, 0.22447683214656788, 0.1210872961911107, 0.11309525468373505, 0.2760264811776597, 0.2669306562303023, 0.07962733970736136, 0.06827422884554413, 0.15866830596354908, 0.10693189767882172, 0.2220502319980897, 0.17621121975631182, 0.24338790734629412, 0.21419006563518805, 0.2506706623778111, 0.29725641067346475, 0.24148483742675597, 0.24279810871990537, 0.26368812077668957, 0.22286011053443877, 0.6546312918272523, 0.6756882893027834, 0.6744447119902128, 0.6377310322266063, 0.588890456756832, 0.5773427203394641, 0.5646730833615377, 0.6733983527670495, 0.6093186850567309, 0.1401692287012264, 0.11231980265479924, 0.18258417169935404, 0.131144167352922, 0.14117506405369262, 0.14401824815534814, 0.1344846108271711, 0.13057018328205483, 0.16546267309972684, 0.17762962104425373, 0.21215741577042768, 0.17554583223536646, 0.22383484481983118, 0.28019498065974024, 0.17176842601987097, 0.24939209453222, 0.16652532295155253, 0.3749525197678577, 0.5643138687714988, 0.6187438650411392, 0.4728586600874316, 0.5279419431996517, 0.6320879355361242, 0.4839419289427319, 0.6262123158714179, 0.7809099851920115, 0.518332955722977, 0.389109224268129, 0.34832244908823906, 0.4049581800586697, 0.3460056968206554, 0.3863937246417881, 0.45825793043378205, 0.559984597357494, 0.5122089952326867, 0.2233375404793665, 0.22796524525080164, 0.22664453360476577, 0.2266249569406129, 0.22644555473820116, 0.23447701754014993, 0.22813507078274353, 0.26769357690663964, 0.22366148564360178, 0.2403842039534806, 0.20092134469924539, 0.22088426274070871, 0.23140659007981734, 0.7810023622684651, 0.19154264530899612, 0.1949509314611887, 0.7898763496448113, 0.2272105038872363, 0.21896062230032454, 0.9106815527245697, 0.1874776351101496, 0.18470342673539497, 0.8565262070611803, 0.19949133382852546, 0.895886708546783, 0.900480329692737, 0.16888225348486086, 0.1649330967961269, 0.9113168882167874, 0.2127345633863631, 0.8421431242907129, 0.78466699332713, 0.42917484768159786, 0.20982073120182942, 0.16595693559742375, 0.21107155643720454, 0.16757484780614884, 0.18916716739157324, 0.17807366092879473, 0.17854976215289697, 0.17403742301919012, 0.17463998065246356, 0.18155237518831313, 0.18494325143139, 0.20261637609904914, 0.18464305373447565, 0.09605756160399526, 0.09383958851077456, 0.10113868668013415, 0.09653005233713807, 0.08949626227133267, 0.0923498099391089, 0.09123611599654158, 0.09215290809742915, 0.09147534747643982]}, "mutation_prompt": null}
{"id": "50f58d70-3c45-48de-8bd8-56136a1dbf3b", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.9  # Adjusted crossover rate for enhanced diversity\n        self.scaling_increase_step = 0.06  # Adjusted scaling step\n        self.reinit_threshold = 0.15  # Increased reinitialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                tournament_indices = np.random.choice(len(population), 5, replace=False)\n                x0, x1, x2 = population[tournament_indices[np.argmin(fitness[tournament_indices[:3]])]], \\\n                             population[tournament_indices[3]], population[tournament_indices[4]]\n                mutant_vector = x0 + scaling_factor * (x1 - x2 + (elite_individual - x0) * 0.5)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.2), replace=False)\n                for idx in random_indices:\n                    if num_evaluations >= self.budget:\n                        break\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n            \n            if not np.any(improvement_mask) and num_evaluations < self.budget:\n                local_search_candidates = np.random.choice(len(population), 4, replace=False)\n                for idx in local_search_candidates:\n                    perturbation = np.random.normal(0, 0.05, self.dim)\n                    candidate = population[idx] + perturbation\n                    candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                    candidate_fitness = func(candidate)\n                    num_evaluations += 1\n                    if candidate_fitness < fitness[idx]:\n                        population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n\n        return elite_individual", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with enhanced random reinitialization and scaled crossover rates for improved exploration and convergence.", "configspace": "", "generation": 94, "fitness": 0.5162258076197418, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.52 with standard deviation 0.28.", "error": "", "parent_id": "756e5856-714d-4c07-81af-aaa2cbe4678d", "metadata": {"aucs": [0.8593423729746816, 0.9057468107514379, 0.8668739502762368, 0.8790816329064916, 0.8710988217936837, 0.8911738030006642, 0.8701797303410281, 0.8836292429729342, 0.8657411678198396, 0.7552072795377129, 0.7956769194717775, 0.7654762410230063, 0.7453985309492883, 0.7656290847233713, 0.6590993972977179, 0.685934625587998, 0.7678488742960652, 0.7550349889696701, 0.1803146951382858, 0.715066589029471, 0.5600700134895767, 0.591650322481534, 0.16734916209028217, 0.6090422331001738, 0.16401815257759533, 0.14570039677895297, 0.26146826494033926, 0.1573760713014688, 0.15744467252929262, 0.1800473222759923, 0.14557220688226646, 0.14747882099900655, 0.14358619696698827, 0.137573908807194, 0.1363811728926574, 0.15174683790323384, 0.9827846371727441, 0.973522091805767, 0.956156014802765, 0.9657409748463979, 0.9812929803220655, 0.9479952265748385, 0.9723346744830218, 0.9591656084804429, 0.9753996614963524, 0.6690564011856827, 0.7352589318542434, 0.6862788644788966, 0.6786029007243772, 0.7006608743468983, 0.6315906804721194, 0.6914404122231459, 0.6771025516669442, 0.6986495718740129, 0.8790502094704524, 0.8870828226954187, 0.8809619782000438, 0.8766993540558786, 0.8806018310791397, 0.9054289985106068, 0.20966129796288047, 0.8705724451363317, 0.8794792355377118, 0.6167776484492116, 0.6098139389289987, 0.6150740771750687, 0.5315465039369813, 0.5048239588277508, 0.6172415973664273, 0.5990830641515661, 0.5985525138258301, 0.5360565139853831, 0.4839670415713312, 0.6318318387505399, 0.5933217671257061, 0.5281115734092896, 0.6638873739298954, 0.6610408456667255, 0.5867435363879949, 0.6295998068621151, 0.5963832505752709, 0.6598641416294599, 0.6645942780471215, 0.6667078529991259, 0.5969570267434937, 0.670104478167701, 0.5950400599462019, 0.6420576327700211, 0.7277848565432739, 0.635838720718124, 0.6602918851230146, 0.7762566494634435, 0.755701190261947, 0.6713569487936402, 0.6705304286326008, 0.6271750815311887, 0.6703400724947657, 0.7757895004709741, 0.8009788027938068, 0.1328150935245116, 0.3647404887037148, 0.45656360994430045, 0.5472388395912475, 0.47375065232836644, 0.22056763163564985, 0.18713544772423218, 0.2915404707252216, 0.21415612164869358, 0.5448604401320754, 0.5872436316845653, 0.5529011977792448, 0.4961908837411949, 0.6015500337691245, 0.5543349748510837, 0.520871575825749, 0.6612025839116988, 0.5539981216621002, 0.7237630735063048, 0.8489457806727663, 0.8796661723738236, 0.8536887265582561, 0.8114559472209627, 0.8380240615572419, 0.8239346633033804, 0.8319599058412511, 0.861769818889243, 0.15232525333332214, 0.13970961778501134, 0.7337287094438008, 0.15711751980207478, 0.14863238328409167, 0.11436420898518085, 0.1551787511578019, 0.1835037838807777, 0.18245002941824529, 0.3256442984015775, 0.20478936891808963, 0.19766709392325055, 0.2004180185429748, 0.8159931517972541, 0.2685890460402319, 0.3194220089685853, 0.5355474577753307, 0.3389671225894978, 0.5637150694289912, 0.7360657634880996, 0.7343708844388845, 0.5672478479292428, 0.566749350837605, 0.6974821348044259, 0.25933547914617006, 0.7899877450414775, 0.6662082280334927, 0.40821748254480916, 0.2670743817160147, 0.4163657113853869, 0.4670623117252932, 0.5125537016437982, 0.5393043559334497, 0.3942669697712664, 0.4697412223244034, 0.6902928926031933, 0.23428883092694952, 0.21542481411172487, 0.2559174478890358, 0.22426982664018902, 0.20238383444097752, 0.2176233740831477, 0.25163523425602785, 0.24761526512128462, 0.21905667540310036, 0.2166214333921027, 0.24635656887071344, 0.20782113265647095, 0.21217572700799836, 0.2133978287622138, 0.1968622235158376, 0.2023072828617697, 0.22110148778310745, 0.21528841552108868, 0.8831742909376673, 0.18519996107696057, 0.15373623788453583, 0.8449454455424851, 0.20026124803018797, 0.9035564234877899, 0.9011805927658554, 0.16798877918186772, 0.8654403831692562, 0.886296652406942, 0.21267776053577647, 0.8561185220077484, 0.15237055764291052, 0.8844245837513927, 0.8589713865320728, 0.8560716164006353, 0.20988375997197606, 0.20908922971315724, 0.18131638336331934, 0.18965417129143014, 0.20348393004566123, 0.18878515047826616, 0.1836570300967736, 0.19324423211744424, 0.1800979606209132, 0.17491379838012466, 0.1999029211324561, 0.09347513775229632, 0.09494418964208762, 0.09462129192835855, 0.09227990327051228, 0.09786399236926302, 0.09163613124627956, 0.09421984471503053, 0.1091487199043919, 0.09117731288446662]}, "mutation_prompt": null}
{"id": "5d35a280-b1fb-424d-b32f-3b1283e30cc7", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.9  # Adjusted crossover rate for enhanced diversity\n        self.scaling_increase_step = 0.06  # Adjusted scaling step\n        self.reinit_threshold = 0.15  # Increased reinitialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                tournament_indices = np.random.choice(len(population), 5, replace=False)\n                x0, x1, x2 = population[tournament_indices[np.argmin(fitness[tournament_indices[:3]])]], \\\n                             population[tournament_indices[3]], population[tournament_indices[4]]\n                mutant_vector = x0 + scaling_factor * (x1 - x2 + (elite_individual - x0) * 0.5)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.2), replace=False)\n                for idx in random_indices:\n                    if num_evaluations >= self.budget:\n                        break\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n            \n            if not np.any(improvement_mask) and num_evaluations < self.budget:\n                local_search_candidates = np.random.choice(len(population), 4, replace=False)\n                for idx in local_search_candidates:\n                    perturbation = np.random.normal(0, 0.05, self.dim)\n                    candidate = population[idx] + perturbation\n                    candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                    candidate_fitness = func(candidate)\n                    num_evaluations += 1\n                    if candidate_fitness < fitness[idx]:\n                        population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n\n        return elite_individual", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with enhanced random reinitialization and scaled crossover rates for improved exploration and convergence.", "configspace": "", "generation": 95, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "50f58d70-3c45-48de-8bd8-56136a1dbf3b", "metadata": {"aucs": [0.8593423729746816, 0.9057468107514379, 0.8668739502762368, 0.8790816329064916, 0.8710988217936837, 0.8911738030006642, 0.8701797303410281, 0.8836292429729342, 0.8657411678198396, 0.7552072795377129, 0.7956769194717775, 0.7654762410230063, 0.7453985309492883, 0.7656290847233713, 0.6590993972977179, 0.685934625587998, 0.7678488742960652, 0.7550349889696701, 0.1803146951382858, 0.715066589029471, 0.5600700134895767, 0.591650322481534, 0.16734916209028217, 0.6090422331001738, 0.16401815257759533, 0.14570039677895297, 0.26146826494033926, 0.1573760713014688, 0.15744467252929262, 0.1800473222759923, 0.14557220688226646, 0.14747882099900655, 0.14358619696698827, 0.137573908807194, 0.1363811728926574, 0.15174683790323384, 0.9827846371727441, 0.973522091805767, 0.956156014802765, 0.9657409748463979, 0.9812929803220655, 0.9479952265748385, 0.9723346744830218, 0.9591656084804429, 0.9753996614963524, 0.6690564011856827, 0.7352589318542434, 0.6862788644788966, 0.6786029007243772, 0.7006608743468983, 0.6315906804721194, 0.6914404122231459, 0.6771025516669442, 0.6986495718740129, 0.8790502094704524, 0.8870828226954187, 0.8809619782000438, 0.8766993540558786, 0.8806018310791397, 0.9054289985106068, 0.20966129796288047, 0.8705724451363317, 0.8794792355377118, 0.6167776484492116, 0.6098139389289987, 0.6150740771750687, 0.5315465039369813, 0.5048239588277508, 0.6172415973664273, 0.5990830641515661, 0.5985525138258301, 0.5360565139853831, 0.4839670415713312, 0.6318318387505399, 0.5933217671257061, 0.5281115734092896, 0.6638873739298954, 0.6610408456667255, 0.5867435363879949, 0.6295998068621151, 0.5963832505752709, 0.6598641416294599, 0.6645942780471215, 0.6667078529991259, 0.5969570267434937, 0.670104478167701, 0.5950400599462019, 0.6420576327700211, 0.7277848565432739, 0.635838720718124, 0.6602918851230146, 0.7762566494634435, 0.755701190261947, 0.6713569487936402, 0.6705304286326008, 0.6271750815311887, 0.6703400724947657, 0.7757895004709741, 0.8009788027938068, 0.1328150935245116, 0.3647404887037148, 0.45656360994430045, 0.5472388395912475, 0.47375065232836644, 0.22056763163564985, 0.18713544772423218, 0.2915404707252216, 0.21415612164869358, 0.5448604401320754, 0.5872436316845653, 0.5529011977792448, 0.4961908837411949, 0.6015500337691245, 0.5543349748510837, 0.520871575825749, 0.6612025839116988, 0.5539981216621002, 0.7237630735063048, 0.8489457806727663, 0.8796661723738236, 0.8536887265582561, 0.8114559472209627, 0.8380240615572419, 0.8239346633033804, 0.8319599058412511, 0.861769818889243, 0.15232525333332214, 0.13970961778501134, 0.7337287094438008, 0.15711751980207478, 0.14863238328409167, 0.11436420898518085, 0.1551787511578019, 0.1835037838807777, 0.18245002941824529, 0.3256442984015775, 0.20478936891808963, 0.19766709392325055, 0.2004180185429748, 0.8159931517972541, 0.2685890460402319, 0.3194220089685853, 0.5355474577753307, 0.3389671225894978, 0.5637150694289912, 0.7360657634880996, 0.7343708844388845, 0.5672478479292428, 0.566749350837605, 0.6974821348044259, 0.25933547914617006, 0.7899877450414775, 0.6662082280334927, 0.40821748254480916, 0.2670743817160147, 0.4163657113853869, 0.4670623117252932, 0.5125537016437982, 0.5393043559334497, 0.3942669697712664, 0.4697412223244034, 0.6902928926031933, 0.23428883092694952, 0.21542481411172487, 0.2559174478890358, 0.22426982664018902, 0.20238383444097752, 0.2176233740831477, 0.25163523425602785, 0.24761526512128462, 0.21905667540310036, 0.2166214333921027, 0.24635656887071344, 0.20782113265647095, 0.21217572700799836, 0.2133978287622138, 0.1968622235158376, 0.2023072828617697, 0.22110148778310745, 0.21528841552108868, 0.8831742909376673, 0.18519996107696057, 0.15373623788453583, 0.8449454455424851, 0.20026124803018797, 0.9035564234877899, 0.9011805927658554, 0.16798877918186772, 0.8654403831692562, 0.886296652406942, 0.21267776053577647, 0.8561185220077484, 0.15237055764291052, 0.8844245837513927, 0.8589713865320728, 0.8560716164006353, 0.20988375997197606, 0.20908922971315724, 0.18131638336331934, 0.18965417129143014, 0.20348393004566123, 0.18878515047826616, 0.1836570300967736, 0.19324423211744424, 0.1800979606209132, 0.17491379838012466, 0.1999029211324561, 0.09347513775229632, 0.09494418964208762, 0.09462129192835855, 0.09227990327051228, 0.09786399236926302, 0.09163613124627956, 0.09421984471503053, 0.1091487199043919, 0.09117731288446662]}, "mutation_prompt": null}
{"id": "9dd13cf6-969b-4234-9b82-421a930d4fda", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.9  # Adjusted crossover rate for enhanced diversity\n        self.scaling_increase_step = 0.06  # Adjusted scaling step\n        self.reinit_threshold = 0.15  # Increased reinitialization threshold\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                tournament_indices = np.random.choice(len(population), 5, replace=False)\n                x0, x1, x2 = population[tournament_indices[np.argmin(fitness[tournament_indices[:3]])]], \\\n                             population[tournament_indices[3]], population[tournament_indices[4]]\n                mutant_vector = x0 + scaling_factor * (x1 - x2 + (elite_individual - x0) * 0.5)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.2), replace=False)\n                for idx in random_indices:\n                    if num_evaluations >= self.budget:\n                        break\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n            \n            if not np.any(improvement_mask) and num_evaluations < self.budget:\n                local_search_candidates = np.random.choice(len(population), 4, replace=False)\n                for idx in local_search_candidates:\n                    perturbation = np.random.normal(0, 0.05, self.dim)\n                    candidate = population[idx] + perturbation\n                    candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                    candidate_fitness = func(candidate)\n                    num_evaluations += 1\n                    if candidate_fitness < fitness[idx]:\n                        population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n\n        return elite_individual", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with enhanced random reinitialization and scaled crossover rates for improved exploration and convergence.", "configspace": "", "generation": 95, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "50f58d70-3c45-48de-8bd8-56136a1dbf3b", "metadata": {"aucs": [0.8593423729746816, 0.9057468107514379, 0.8668739502762368, 0.8790816329064916, 0.8710988217936837, 0.8911738030006642, 0.8701797303410281, 0.8836292429729342, 0.8657411678198396, 0.7552072795377129, 0.7956769194717775, 0.7654762410230063, 0.7453985309492883, 0.7656290847233713, 0.6590993972977179, 0.685934625587998, 0.7678488742960652, 0.7550349889696701, 0.1803146951382858, 0.715066589029471, 0.5600700134895767, 0.591650322481534, 0.16734916209028217, 0.6090422331001738, 0.16401815257759533, 0.14570039677895297, 0.26146826494033926, 0.1573760713014688, 0.15744467252929262, 0.1800473222759923, 0.14557220688226646, 0.14747882099900655, 0.14358619696698827, 0.137573908807194, 0.1363811728926574, 0.15174683790323384, 0.9827846371727441, 0.973522091805767, 0.956156014802765, 0.9657409748463979, 0.9812929803220655, 0.9479952265748385, 0.9723346744830218, 0.9591656084804429, 0.9753996614963524, 0.6690564011856827, 0.7352589318542434, 0.6862788644788966, 0.6786029007243772, 0.7006608743468983, 0.6315906804721194, 0.6914404122231459, 0.6771025516669442, 0.6986495718740129, 0.8790502094704524, 0.8870828226954187, 0.8809619782000438, 0.8766993540558786, 0.8806018310791397, 0.9054289985106068, 0.20966129796288047, 0.8705724451363317, 0.8794792355377118, 0.6167776484492116, 0.6098139389289987, 0.6150740771750687, 0.5315465039369813, 0.5048239588277508, 0.6172415973664273, 0.5990830641515661, 0.5985525138258301, 0.5360565139853831, 0.4839670415713312, 0.6318318387505399, 0.5933217671257061, 0.5281115734092896, 0.6638873739298954, 0.6610408456667255, 0.5867435363879949, 0.6295998068621151, 0.5963832505752709, 0.6598641416294599, 0.6645942780471215, 0.6667078529991259, 0.5969570267434937, 0.670104478167701, 0.5950400599462019, 0.6420576327700211, 0.7277848565432739, 0.635838720718124, 0.6602918851230146, 0.7762566494634435, 0.755701190261947, 0.6713569487936402, 0.6705304286326008, 0.6271750815311887, 0.6703400724947657, 0.7757895004709741, 0.8009788027938068, 0.1328150935245116, 0.3647404887037148, 0.45656360994430045, 0.5472388395912475, 0.47375065232836644, 0.22056763163564985, 0.18713544772423218, 0.2915404707252216, 0.21415612164869358, 0.5448604401320754, 0.5872436316845653, 0.5529011977792448, 0.4961908837411949, 0.6015500337691245, 0.5543349748510837, 0.520871575825749, 0.6612025839116988, 0.5539981216621002, 0.7237630735063048, 0.8489457806727663, 0.8796661723738236, 0.8536887265582561, 0.8114559472209627, 0.8380240615572419, 0.8239346633033804, 0.8319599058412511, 0.861769818889243, 0.15232525333332214, 0.13970961778501134, 0.7337287094438008, 0.15711751980207478, 0.14863238328409167, 0.11436420898518085, 0.1551787511578019, 0.1835037838807777, 0.18245002941824529, 0.3256442984015775, 0.20478936891808963, 0.19766709392325055, 0.2004180185429748, 0.8159931517972541, 0.2685890460402319, 0.3194220089685853, 0.5355474577753307, 0.3389671225894978, 0.5637150694289912, 0.7360657634880996, 0.7343708844388845, 0.5672478479292428, 0.566749350837605, 0.6974821348044259, 0.25933547914617006, 0.7899877450414775, 0.6662082280334927, 0.40821748254480916, 0.2670743817160147, 0.4163657113853869, 0.4670623117252932, 0.5125537016437982, 0.5393043559334497, 0.3942669697712664, 0.4697412223244034, 0.6902928926031933, 0.23428883092694952, 0.21542481411172487, 0.2559174478890358, 0.22426982664018902, 0.20238383444097752, 0.2176233740831477, 0.25163523425602785, 0.24761526512128462, 0.21905667540310036, 0.2166214333921027, 0.24635656887071344, 0.20782113265647095, 0.21217572700799836, 0.2133978287622138, 0.1968622235158376, 0.2023072828617697, 0.22110148778310745, 0.21528841552108868, 0.8831742909376673, 0.18519996107696057, 0.15373623788453583, 0.8449454455424851, 0.20026124803018797, 0.9035564234877899, 0.9011805927658554, 0.16798877918186772, 0.8654403831692562, 0.886296652406942, 0.21267776053577647, 0.8561185220077484, 0.15237055764291052, 0.8844245837513927, 0.8589713865320728, 0.8560716164006353, 0.20988375997197606, 0.20908922971315724, 0.18131638336331934, 0.18965417129143014, 0.20348393004566123, 0.18878515047826616, 0.1836570300967736, 0.19324423211744424, 0.1800979606209132, 0.17491379838012466, 0.1999029211324561, 0.09347513775229632, 0.09494418964208762, 0.09462129192835855, 0.09227990327051228, 0.09786399236926302, 0.09163613124627956, 0.09421984471503053, 0.1091487199043919, 0.09117731288446662]}, "mutation_prompt": null}
{"id": "65ff4f09-3e12-42d8-bd40-45974a13b3ee", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.scaling_increase_step = 0.06\n        self.reinit_threshold = 0.1  # Adjusted reinitialization threshold\n        self.local_search_intensity = 0.1  # New intensity factor for local search\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                tournament_indices = np.random.choice(len(population), 5, replace=False)\n                x0, x1, x2 = population[tournament_indices[np.argmin(fitness[tournament_indices[:3]])]], \\\n                             population[tournament_indices[3]], population[tournament_indices[4]]\n                mutant_vector = x0 + scaling_factor * (x1 - x2 + (elite_individual - x0) * 0.5)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if np.random.rand() < self.reinit_threshold:\n                random_indices = np.random.choice(len(population), int(self.population_size * 0.2), replace=False)\n                for idx in random_indices:\n                    if num_evaluations >= self.budget:\n                        break\n                    population[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n            \n            if not np.any(improvement_mask) and num_evaluations < self.budget:\n                local_search_candidates = np.random.choice(len(population), int(self.population_size * self.local_search_intensity), replace=False)\n                for idx in local_search_candidates:\n                    perturbation = np.random.normal(0, 0.05, self.dim)\n                    candidate = population[idx] + perturbation\n                    candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                    candidate_fitness = func(candidate)\n                    num_evaluations += 1\n                    if candidate_fitness < fitness[idx]:\n                        population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n\n        return elite_individual", "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with dynamic local search intensity and adaptive reinitialization for improved exploration.", "configspace": "", "generation": 97, "fitness": 0.5355148045512492, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.54 with standard deviation 0.29.", "error": "", "parent_id": "50f58d70-3c45-48de-8bd8-56136a1dbf3b", "metadata": {"aucs": [0.8874311846096316, 0.8464925572725627, 0.8804059611705533, 0.8598514009131177, 0.9050382705827255, 0.8792532617484163, 0.8747446323443913, 0.9076178772570129, 0.8685076497440651, 0.8282060377224842, 0.7824610071816438, 0.7664785080887291, 0.7256502274572727, 0.776159535429428, 0.774340073600321, 0.7178589993365643, 0.7969972012148046, 0.777503886276268, 0.175522065980532, 0.6736136158778182, 0.6985236119534664, 0.1803095859641859, 0.2634369658949981, 0.18106834695392338, 0.7121195331638255, 0.1438588217762674, 0.1802316480879208, 0.13047603517784756, 0.1316823492318897, 0.15417197491252832, 0.12096025116212494, 0.1557170113865053, 0.11204025242878102, 0.13806503138413284, 0.16977739628153266, 0.0948852070628936, 0.9827846371727441, 0.9662506762365868, 0.956156014802765, 0.9576849506587533, 0.9812929803220655, 0.9479952265748385, 0.9558992255579031, 0.9609657578946027, 0.9753996614963524, 0.7505744531488101, 0.7095170644216848, 0.6934327060429681, 0.7558231204865862, 0.7782695063902704, 0.6797944910905656, 0.7724186928652305, 0.7034649317027888, 0.6880072347130142, 0.7129781259523167, 0.8927746379326084, 0.8883937313724712, 0.9256884187969043, 0.882843160596126, 0.9135410179485869, 0.8822296148988987, 0.915991546016816, 0.8803904238934374, 0.6978092031141159, 0.6774276841929219, 0.5712089856761748, 0.6059342530540641, 0.5976890668623827, 0.617058465316807, 0.6437089820517707, 0.617439348556615, 0.5942259474491576, 0.5923104734843565, 0.6286837708215851, 0.6349516237117887, 0.6650204977458825, 0.5779031723839445, 0.6499739946433503, 0.6187153304060855, 0.6715506441418183, 0.624916466624698, 0.7264239937906645, 0.6970157815997723, 0.7089505592232299, 0.7261085808399108, 0.7561580616362772, 0.5976305904616558, 0.6945139916117969, 0.6312016107140612, 0.7587587899224051, 0.7167964884221529, 0.8135298958229901, 0.7560595543616775, 0.741086086908338, 0.7818857784785826, 0.6228678666998415, 0.7173438385602382, 0.8026188777875242, 0.8341891488274309, 0.15992283834283694, 0.3554852143722623, 0.5448959641401203, 0.6327969897625996, 0.49324527624327963, 0.24561001420501194, 0.42818838521830693, 0.1865155110711404, 0.31761025252165687, 0.5681562631938555, 0.6703659592361191, 0.5632410986094407, 0.5963049873183086, 0.6521816276580183, 0.644629451991036, 0.5888585239562371, 0.6808147167746655, 0.5599320332468664, 0.8434628053023657, 0.8553967171845045, 0.87626355808503, 0.8103341229562082, 0.8612429423187268, 0.8498587648963335, 0.8450248474230476, 0.8010513151987313, 0.8742985801130012, 0.14185639040220122, 0.1528106242368602, 0.7702654391134375, 0.18389222272171524, 0.17785884707023125, 0.1432795048675345, 0.15946100992862267, 0.1588502313979676, 0.15586793053950565, 0.2657499468051585, 0.41218440784903354, 0.22836763128084703, 0.1793826731913859, 0.8135614522798178, 0.2302880361547196, 0.8050515250202486, 0.272806919396692, 0.6962259238237364, 0.3632318802217829, 0.5064972923170085, 0.7117447752451405, 0.7745507089184557, 0.7581582360352154, 0.4451616463680853, 0.5488377177748097, 0.757131746677939, 0.4520157825973583, 0.5030682055263254, 0.3899174880401176, 0.37940078422417334, 0.48324170032469715, 0.3538034397633528, 0.3901162255797619, 0.34613939119537573, 0.5802374049843246, 0.45147008597268834, 0.2185339964822146, 0.27169394541384284, 0.25061272656022093, 0.23180298565731894, 0.47970038713374774, 0.21820750642638465, 0.268827233762295, 0.22517436813128933, 0.4186637420431525, 0.1891433663815809, 0.20990390110939305, 0.2189411865549611, 0.2282952905473259, 0.20914463716596088, 0.1971015068953087, 0.19560671073046532, 0.22486092929935753, 0.22756749153877742, 0.9065070638037029, 0.18520280814695722, 0.15375141852804064, 0.9201027889908306, 0.20024980344541787, 0.9144804451961914, 0.17198552090855723, 0.1762462799304414, 0.8173512359871082, 0.8994558326486586, 0.21274967573533088, 0.8914415278892889, 0.9067544839537557, 0.8765429720586903, 0.8511043567004944, 0.761463407317692, 0.21046080998720595, 0.20932478346585115, 0.19338592887117123, 0.18791384434323233, 0.17762108099012808, 0.18975701172072323, 0.18651815728959031, 0.17989962361960365, 0.17840860862434382, 0.18624414784983778, 0.17673172729755937, 0.08207775389093619, 0.09259863880874108, 0.09502442493768792, 0.09290912372016069, 0.10402655483386392, 0.1074232046047624, 0.094371683825207, 0.1018220518081373, 0.0956457087963869]}, "mutation_prompt": null}
{"id": "ccf15d48-146c-4025-be03-87850695e33e", "solution": "import numpy as np\n\nclass DynamicGradientInformedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.scaling_increase_step = 0.06\n        self.reinit_threshold = 0.1\n        self.local_search_intensity = 0.1\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                tournament_indices = np.random.choice(len(population), 5, replace=False)\n                x0, x1, x2 = population[tournament_indices[np.argmin(fitness[tournament_indices[:3]])]], \\\n                             population[tournament_indices[3]], population[tournament_indices[4]]\n                gradient_vector = (elite_individual - x0) * np.random.uniform(0.3, 0.7)\n                mutant_vector = x0 + scaling_factor * (x1 - x2 + gradient_vector)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if np.random.rand() < self.reinit_threshold:\n                std_dev = np.std(population, axis=0)\n                reinit_candidates = np.random.choice(len(population), int(self.population_size * 0.1), replace=False)\n                for idx in reinit_candidates:\n                    if num_evaluations >= self.budget:\n                        break\n                    population[idx] = np.random.normal(loc=elite_individual, scale=std_dev)\n                    population[idx] = np.clip(population[idx], self.lower_bound, self.upper_bound)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n            \n            if not np.any(improvement_mask) and num_evaluations < self.budget:\n                local_search_candidates = np.random.choice(len(population), int(self.population_size * self.local_search_intensity), replace=False)\n                for idx in local_search_candidates:\n                    perturbation = np.random.normal(0, 0.05, self.dim)\n                    candidate = population[idx] + perturbation\n                    candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                    candidate_fitness = func(candidate)\n                    num_evaluations += 1\n                    if candidate_fitness < fitness[idx]:\n                        population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n\n        return elite_individual", "name": "DynamicGradientInformedDifferentialEvolution", "description": "Dynamic Gradient-Informed Differential Evolution with adaptive step size and selective reinitialization for enhanced balance between exploration and exploitation.", "configspace": "", "generation": 98, "fitness": 0.5421008102465813, "feedback": "The algorithm DynamicGradientInformedDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.54 with standard deviation 0.30.", "error": "", "parent_id": "65ff4f09-3e12-42d8-bd40-45974a13b3ee", "metadata": {"aucs": [0.8713720696284867, 0.8952942315382544, 0.9025674789293957, 0.883608760348504, 0.8829577185210807, 0.895251002233406, 0.8961111918995872, 0.8924640623305158, 0.8802270840151516, 0.8291870617537482, 0.8091208536122887, 0.8094589207801243, 0.7852628984934276, 0.7815837647999291, 0.7474447722683664, 0.7091562986728328, 0.7912632620443844, 0.7264049541814863, 0.18710301518817807, 0.16007301115621797, 0.17402276321425347, 0.1731015052565803, 0.7373047657103586, 0.18083614835953277, 0.18354348135148357, 0.15744520684892482, 0.17997518916278765, 0.13308362286669384, 0.1421907919554557, 0.12355798909893934, 0.1584094903294243, 0.1396934295533402, 0.09021909526440564, 0.12289074584692972, 0.12269777010821858, 0.15336733564592508, 0.9632026433882885, 0.9643361198378526, 0.9508563881423054, 0.9776009308992055, 0.976522136911361, 0.9604964956248112, 0.9429264605278472, 0.9479369978079097, 0.986946842304603, 0.7632102137448029, 0.7445945277902173, 0.7367786550398963, 0.7469225717484749, 0.7327746592989042, 0.7788062703094987, 0.7305997289151333, 0.7360577490407494, 0.7824391785070296, 0.9167802663200894, 0.8767183401807966, 0.8979810451700314, 0.9263245921025884, 0.9250249413446229, 0.8637225015162437, 0.9030380433780781, 0.9048617904242262, 0.9037946719746421, 0.6718725423404008, 0.6898653553395637, 0.6779309786878234, 0.13266355354003867, 0.6722345327009618, 0.639898214382469, 0.7569748462045767, 0.6606714621455079, 0.6742930966502216, 0.6728218628608633, 0.6142092597624759, 0.7231167360867425, 0.6680834542741072, 0.6891266531153224, 0.6265785130561041, 0.6469341014110206, 0.6900361658845975, 0.6189642994636828, 0.6528841915319875, 0.6827423487215246, 0.7045966562593353, 0.6204429501617656, 0.6684645185835574, 0.693610176440167, 0.7591533760966129, 0.7311235386195315, 0.7305708507617186, 0.7286546018798812, 0.6841586805210738, 0.8079725087966839, 0.7682806293222695, 0.7363217516619855, 0.7534086457513072, 0.8610433649024725, 0.7362159750811204, 0.7850628477285825, 0.15634307720627838, 0.4390661825686858, 0.49365945140877643, 0.591728402729069, 0.5711713397821921, 0.3817946772058083, 0.45998846607910815, 0.33618061451646863, 0.2592796077919278, 0.6072376200048744, 0.615295932579118, 0.6657956805120047, 0.6632381862554313, 0.6894693183850791, 0.6927112467335232, 0.6734348425717506, 0.66845543778234, 0.6870011031175389, 0.8354652768379005, 0.8635800439664172, 0.8667704066666461, 0.8479165803690625, 0.8343225516467854, 0.7880075560410875, 0.8581598029172972, 0.8634213777088147, 0.8437921133161324, 0.15290873364555368, 0.15369809436108683, 0.13250387090697768, 0.12442356498316443, 0.13122166380572076, 0.18324159862788114, 0.1593105655583733, 0.1429121643646003, 0.1419682122476159, 0.8304976489088969, 0.2420385090161149, 0.23466804353319426, 0.35100784151681863, 0.23176869299419955, 0.2964960124722458, 0.7857972328791345, 0.7529380686832331, 0.7775162658093954, 0.5212315554510755, 0.7263447938187488, 0.5648593837701938, 0.5764026224323091, 0.5880884036429346, 0.7602106876967587, 0.8065126174900366, 0.6026478980716032, 0.4897308258508992, 0.23995139099325447, 0.5801674658966152, 0.4498486707886624, 0.6791169200445164, 0.3322594665259384, 0.4384499354563457, 0.22568404607993076, 0.39298021710707887, 0.29087748174529815, 0.24278970884046802, 0.4741374836862615, 0.25422284343925694, 0.22272977328264765, 0.4892548142656661, 0.21936767989219097, 0.2307840642775837, 0.23105279053485994, 0.2646770490193572, 0.22924627395605213, 0.21619083296924824, 0.2226962745055978, 0.2508873686313382, 0.7783981904428593, 0.19241734943308197, 0.24607183116420506, 0.24673255293337792, 0.1955465186984271, 0.181446620283794, 0.9204077089267363, 0.15379929213771426, 0.9132726627894598, 0.19936696419006117, 0.9274876137508171, 0.1762875370184156, 0.9247341079483843, 0.9212814522699441, 0.9324893938737111, 0.21183639439599056, 0.8932422639482401, 0.9095717539738034, 0.16563017919742795, 0.16796206669593972, 0.21209250957706283, 0.8416197746286159, 0.8778862386054436, 0.175976566824821, 0.18378415733817421, 0.18857256254282861, 0.18016459647973604, 0.18527811553237294, 0.17556965289586624, 0.19174213539235052, 0.18592039320346587, 0.17764766649136254, 0.08708310220335969, 0.1046496802664516, 0.09176407330403913, 0.0959187606057349, 0.09935643015357631, 0.09006765621534274, 0.09731388517915762, 0.08681155145844988, 0.13447828316702215]}, "mutation_prompt": null}
{"id": "5f55ddf3-1eaa-4d00-827e-7f625110d07e", "solution": "import numpy as np\n\nclass EnhancedGradientInformedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.scaling_increase_step = 0.06\n        self.reinit_threshold = 0.1\n        self.local_search_intensity = 0.1\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        num_evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        elite_individual = best_individual\n        scaling_factor = self.initial_scaling_factor\n\n        while num_evaluations < self.budget:\n            trial_population = np.empty_like(population)\n            for i in range(len(population)):\n                tournament_size = np.random.randint(3, 6)  # Dynamic tournament size\n                tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n                sorted_indices = tournament_indices[np.argsort(fitness[tournament_indices])]\n                x0, x1, x2 = population[sorted_indices[0]], population[sorted_indices[1]], population[sorted_indices[2]]\n                gradient_vector = (elite_individual - x0) * np.random.uniform(0.3, 0.7)\n                mutant_vector = x0 + scaling_factor * (x1 - x2 + gradient_vector)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                adaptive_crossover_rate = self.crossover_rate * (1 - np.exp(-num_evaluations / self.budget))\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                trial_population[i] = trial_vector\n\n            trial_fitness = np.array([func(ind) for ind in trial_population])\n            num_evaluations += len(trial_population)\n            \n            improvement_mask = trial_fitness < fitness\n            population[improvement_mask] = trial_population[improvement_mask]\n            fitness[improvement_mask] = trial_fitness[improvement_mask]\n\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(elite_individual):\n                elite_individual = population[best_idx]\n                scaling_factor = min(1.0, scaling_factor + self.scaling_increase_step)\n            else:\n                scaling_factor = max(0.2, scaling_factor - self.scaling_increase_step)\n\n            if np.random.rand() < self.reinit_threshold:\n                std_dev = np.std(population, axis=0)\n                reinit_candidates = np.random.choice(len(population), int(self.population_size * 0.1), replace=False)\n                for idx in reinit_candidates:\n                    if num_evaluations >= self.budget:\n                        break\n                    population[idx] = np.random.normal(loc=elite_individual, scale=std_dev)\n                    population[idx] = np.clip(population[idx], self.lower_bound, self.upper_bound)\n                    fitness[idx] = func(population[idx])\n                    num_evaluations += 1\n            \n            if not np.any(improvement_mask) and num_evaluations < self.budget:\n                local_search_candidates = np.random.choice(len(population), int(self.population_size * self.local_search_intensity), replace=False)\n                for idx in local_search_candidates:\n                    perturbation = np.random.normal(0, 0.05, self.dim)\n                    candidate = population[idx] + perturbation\n                    candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                    candidate_fitness = func(candidate)\n                    num_evaluations += 1\n                    if candidate_fitness < fitness[idx]:\n                        population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n\n        return elite_individual", "name": "EnhancedGradientInformedDifferentialEvolution", "description": "Enhanced Gradient-Informed Differential Evolution with dynamic tournament selection and adaptive crossover strategy for improved convergence and robustness.", "configspace": "", "generation": 99, "fitness": 0.36713422883493413, "feedback": "The algorithm EnhancedGradientInformedDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.27.", "error": "", "parent_id": "ccf15d48-146c-4025-be03-87850695e33e", "metadata": {"aucs": [0.8746752884285772, 0.8656720004615398, 0.8469628515079808, 0.8365333120136662, 0.8581693380145976, 0.8534892739782047, 0.8623642592880041, 0.8634732503766582, 0.8775915936504668, 0.7758535643718436, 0.7526675487118004, 0.7701366152004246, 0.7574223174020667, 0.764403894817646, 0.7708083171542586, 0.7631625269767122, 0.7745018787057351, 0.7709480943100027, 0.7206089679677761, 0.18017568612502655, 0.711218047445408, 0.7224141758548421, 0.7119257193477895, 0.6719438350816009, 0.733832990769359, 0.7168316289774851, 0.6726174571955477, 0.6675106569493042, 0.6809928800299256, 0.17968583740488753, 0.6766389980203049, 0.6580035271206451, 0.6415347596783709, 0.6424888635740255, 0.6762047012520771, 0.6720505258276072, 0.9569874538129514, 0.9459940040874505, 0.9537986880711831, 0.9359263538508779, 0.9537731835430415, 0.9666372623171967, 0.9604012029498767, 0.9478660844764047, 0.9670473064345654, 0.41108204161683903, 0.41793419005196253, 0.3685566983832519, 0.41231135727711654, 0.413819617982059, 0.3748442100468202, 0.32681667015971405, 0.3123627497546573, 0.32005685251195093, 0.4388807434033326, 0.4026488639412452, 0.37678175234105515, 0.6477226276767334, 0.41073933238997895, 0.5432452571140733, 0.5522800123274553, 0.6739395867866678, 0.592375179995235, 0.17802535741843917, 0.1858275996791443, 0.35722360972495193, 0.11939572800507225, 0.1834790553030563, 0.20017169601175655, 0.18467975780775192, 0.17100128053838815, 0.24769587908272672, 0.160946182020266, 0.17140845520509085, 0.13784160996573647, 0.16953397958721284, 0.17094413583106738, 0.1570074562066749, 0.17193243743933473, 0.1708231972493004, 0.1590000658481313, 0.0247183911452441, 0.00020013305325961017, 0.009455242071392367, 0.022761475734257686, 0.016712821740993422, 0.009684835358839572, 0.03692660528655323, 0.0005526317917776691, 0.031932628308876665, 0.11661183796826535, 0.08656448746439815, 0.10192055022364965, 0.07903753537781044, 0.058317672930457976, 0.09740488085363208, 0.12625310141422375, 0.1573182333107438, 0.104411928230559, 0.0742185128804782, 0.10961316764661444, 0.06498012079030246, 0.06983195164696476, 0.0592818177374278, 0.0504786509778784, 0.10064562829668355, 0.11177717787419406, 0.14131062378864068, 0.21988254956900333, 0.13078832156793962, 0.14707230912549296, 0.16243065183869843, 0.14903378335328998, 0.19806450104184625, 0.13559044884888116, 0.20433562284393547, 0.13837795030905597, 0.5105701767703112, 0.5362514534415337, 0.5048630089135533, 0.5271411112998998, 0.5011880731168423, 0.5120169786795269, 0.5288074442355488, 0.555993641626351, 0.5237765708096487, 0.12270603853296302, 0.11813622959385917, 0.12114421148444598, 0.14048881695992554, 0.11268333314556933, 0.13049670420647963, 0.10896224800087217, 0.16499065397700574, 0.10022972891659487, 0.1773603879297425, 0.17384494390309013, 0.15945845616892496, 0.1664032763006429, 0.1666739449225515, 0.15309106799144157, 0.17074044544493605, 0.19745937601313512, 0.18099675514128544, 0.38931977106957083, 0.3934107659001911, 0.37257989470823616, 0.45612325951328536, 0.3798538664304061, 0.4574471914103071, 0.44325791566846307, 0.49793093454272885, 0.49644960639469804, 0.1981102205827825, 0.20129570421655596, 0.25277332831934196, 0.26161729483233775, 0.27864649142657905, 0.19739448631608825, 0.26293228548671765, 0.30530876396684137, 0.22984077255624047, 0.19473375198946274, 0.2135477220854316, 0.19846771777071182, 0.21613157461736765, 0.20817470706726515, 0.23168049380557765, 0.2164981894117004, 0.2183972479663585, 0.2009419512158609, 0.242490955013291, 0.592084257371215, 0.5163624558596683, 0.6061420560466699, 0.23982757196148408, 0.5677374527026364, 0.6685743694291677, 0.5764300607732092, 0.2378551655667419, 0.5418321820990859, 0.7075672292647723, 0.47457899474677023, 0.7203380387344427, 0.5974682101244515, 0.7100326380470743, 0.6537642312375977, 0.4321305820930239, 0.16152110971872025, 0.5181300242074061, 0.16853772673744627, 0.36374325306473343, 0.21887281287743732, 0.2027163437919608, 0.15689982144954007, 0.35930397044534756, 0.5085218571934613, 0.5422878639901045, 0.19991162563756593, 0.19404060371588194, 0.17567540819576266, 0.184338318010973, 0.18764375056193416, 0.1961031034943016, 0.18839469049251945, 0.1743967978362425, 0.18260022561081068, 0.09455463980604362, 0.08229772625116583, 0.08117129210169127, 0.09391158712776015, 0.08552135090439983, 0.09988664415418735, 0.08617128594298407, 0.08230365202425549, 0.08119777250981552]}, "mutation_prompt": null}

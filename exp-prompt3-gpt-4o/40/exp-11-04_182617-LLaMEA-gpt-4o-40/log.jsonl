{"id": "bfcdd831-1929-4e34-8d24-db3ef07a9df0", "solution": "import numpy as np\n\nclass HybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temp = 100\n        self.final_temp = 0.1\n        self.alpha = 0.9\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n\n    def differential_evolution(self, population, fitness):\n        F = 0.8\n        CR = 0.9\n        new_population = np.copy(population)\n\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant = np.clip(population[a] + F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial_fitness = fitness(trial)\n            self.eval_count += 1\n\n            if trial_fitness < fitness(population[i]):\n                new_population[i] = trial\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial\n\n        return new_population\n\n    def simulated_annealing(self, solution, fitness):\n        current_solution = np.copy(solution)\n        current_fitness = fitness(current_solution)\n        temp = self.initial_temp\n\n        while temp > self.final_temp and self.eval_count < self.budget:\n            new_solution = np.clip(current_solution + np.random.uniform(-0.1, 0.1, self.dim), self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_solution)\n            self.eval_count += 1\n\n            if new_fitness < current_fitness or np.exp((current_fitness - new_fitness) / temp) > np.random.rand():\n                current_solution = new_solution\n                current_fitness = new_fitness\n\n                if current_fitness < self.best_fitness:\n                    self.best_fitness = current_fitness\n                    self.best_solution = current_solution\n\n            temp *= self.alpha\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        \n        while self.eval_count < self.budget:\n            # Apply Differential Evolution\n            population = self.differential_evolution(population, func)\n\n            # Apply Simulated Annealing on the best solution found so far\n            self.simulated_annealing(self.best_solution, func)\n\n        return self.best_solution", "name": "HybridOpt", "description": "Hybrid Optimization Algorithm combining Differential Evolution and Simulated Annealing to efficiently explore and exploit the search space.", "configspace": "", "generation": 0, "fitness": 0.1909624351770447, "feedback": "The algorithm HybridOpt got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.16.", "error": "", "parent_id": null, "metadata": {"aucs": [0.3964858773849391, 0.3640465803351147, 0.3444891768528039, 0.42270033203488266, 0.3831354456834781, 0.35713656670774496, 0.3970950343922113, 0.36131568399628433, 0.3847585768922033, 0.036309102772794755, 0.05044036695075904, 0.02162899811212904, 0.03864572951580414, 0.04557129434643192, 0.03914229994019913, 0.058227653033924964, 0.039080122531747086, 0.07097968181751801, 0.11269348954180636, 0.07906514063966041, 0.07400708454946903, 0.11439090055563794, 0.10094358808678594, 0.09880190295481284, 0.09310986887258155, 0.08341626342332298, 0.08741505419789641, 0.09792207046344104, 0.1002084939782737, 0.06397631306954954, 0.09690816996305418, 0.08504108788620701, 0.11136083579819822, 0.05926864434133983, 0.06640707148372826, 0.07075528612350845, 0.6820411775706903, 0.897334599062181, 0.6053460671757189, 0.8724579209364467, 0.8808811010774106, 0.8091900108200433, 0.855147511162606, 0.6873621749326642, 0.8065922285429874, 0.296555288286271, 0.2688222180491895, 0.2490255881521224, 0.24022758770421937, 0.28798722959677636, 0.22062920349987658, 0.240990509037188, 0.2759775069479228, 0.30412917219246716, 0.20626717529091865, 0.2172436140444346, 0.20379959692968863, 0.24414522232611424, 0.23305967667092808, 0.2034260064676353, 0.20407584209493512, 0.3146798402961778, 0.2139108466900037, 0.18107424723207954, 0.17109482466801418, 0.12846865664068696, 0.18115462301465146, 0.17904651621589218, 0.18781917413207772, 0.19676567073630435, 0.18817025491861528, 0.16429685252899195, 0.18616177357360786, 0.2194441670695575, 0.14192930705591966, 0.12935240653298297, 0.18105888984197405, 0.20548909672516336, 0.1609822646827992, 0.13324912287243473, 0.16523786708984756, 0.017512745214090297, 0.030848092606357236, 9.999999999998899e-05, 0.005655769916225628, 0.0024425576771464064, 0.02731074367194486, 0.12379199884834291, 0.005773293210429964, 9.999999999998899e-05, 0.09297015721938029, 0.10862930377609936, 0.08091461082450047, 0.1082989009417673, 0.0732222697132282, 0.05159383050341915, 0.13031799135314304, 0.07998854341104489, 0.09488556922797253, 0.008419362412300013, 9.999999999998899e-05, 9.999999999998899e-05, 0.020801628104494707, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09836463390707995, 0.07379041560437893, 0.08976510649769154, 0.11622081318712496, 0.09552050489050257, 0.12630138132943125, 0.12332910522806217, 0.10808242955240943, 0.11293162477864294, 0.3286588026078392, 0.39691715969900043, 0.35656014306487827, 0.34591997506154293, 0.3637803847171368, 0.34467276928684154, 0.33854792759590124, 0.32397097036991696, 0.33830476704891854, 0.08550061690054322, 0.0983050316094981, 0.0996534117201281, 0.09285129820382065, 0.10773378863519023, 0.10171848604044065, 0.06790476609671237, 0.10798385755053819, 0.09165214571078972, 0.21348837456377656, 0.1608199389081585, 0.17987670748925788, 0.1724867418981445, 0.17885897410551932, 0.2310842915231266, 0.16384940618740107, 0.270302785455366, 0.16377941509116412, 0.2618136474427828, 0.2432864709895215, 0.21289064034337246, 0.27112296574055705, 0.20474484745347998, 0.23495718134211585, 0.22906276813472182, 0.20968723793657573, 0.23424779884520108, 0.13411664803641976, 0.1776132473597123, 0.1618293035892424, 0.1402363973861609, 0.1853924777018, 0.14296732659096323, 0.15893888184335225, 0.17622542128744312, 0.1509809368662658, 0.1856569265692436, 0.1909922143142142, 0.17536589395591562, 0.19055544916984968, 0.18831309092070914, 0.16505775026160752, 0.1864805096290525, 0.24348446441730498, 0.20110402175121833, 0.18143734329819416, 0.1802647075113022, 0.2067243594620619, 0.1934350065385051, 0.1983391964404827, 0.19978772571470005, 0.18183217143723118, 0.19621636343130122, 0.19755126147375146, 0.17509910805134188, 0.29976022843142924, 0.1498154658949088, 0.1800208275020102, 0.1768973720654139, 0.17192286954446823, 0.17281874840230282, 0.2061085264017274, 0.19835470776632025, 0.176441856103968, 0.29448915806240006, 0.20488212913909432, 0.4715939239864947, 0.5432712936411621, 0.21217510683948382, 0.19885525099673884, 0.20681120984405232, 0.19993528739100475, 0.1716454425144257, 0.18259539352478005, 0.1883027115144419, 0.17589300582287926, 0.18973715296461158, 0.19444329401969795, 0.17574462370211819, 0.1701825668872663, 0.18113215443623443, 0.07341008078837807, 0.06903351691623849, 0.07532915627306358, 0.06200499711354346, 0.06520352989812905, 0.07744084943549112, 0.06857789814774384, 0.0538759529143108, 0.0786212050494236]}, "mutation_prompt": null}
{"id": "7ce8237b-40d7-469a-9bcc-6449a76ce19f", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temp = 100\n        self.final_temp = 0.1\n        self.alpha = 0.9\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.dynamic_alpha = 0.98  # Start with a slightly higher value\n        self.F = 0.5 + (0.9 - 0.5) * np.random.rand(self.population_size)  # Randomize F for diversity\n        self.CR = 0.7 + (0.95 - 0.7) * np.random.rand(self.population_size)  # Randomize CR\n\n    def adaptive_differential_evolution(self, population, fitness):\n        new_population = np.copy(population)\n\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant = np.clip(population[a] + self.F[i] * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n            cross_points = np.random.rand(self.dim) < self.CR[i]\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial_fitness = fitness(trial)\n            self.eval_count += 1\n\n            if trial_fitness < fitness(population[i]):\n                new_population[i] = trial\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial\n\n        return new_population\n\n    def dynamic_simulated_annealing(self, solution, fitness):\n        current_solution = np.copy(solution)\n        current_fitness = fitness(current_solution)\n        temp = self.initial_temp\n\n        while temp > self.final_temp and self.eval_count < self.budget:\n            new_solution = np.clip(current_solution + np.random.uniform(-0.2, 0.2, self.dim), self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_solution)\n            self.eval_count += 1\n\n            if new_fitness < current_fitness or np.exp((current_fitness - new_fitness) / temp) > np.random.rand():\n                current_solution = new_solution\n                current_fitness = new_fitness\n\n                if current_fitness < self.best_fitness:\n                    self.best_fitness = current_fitness\n                    self.best_solution = current_solution\n\n            temp *= self.dynamic_alpha  # Utilize dynamic alpha for more control over cooling\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        \n        while self.eval_count < self.budget:\n            # Apply Adaptive Differential Evolution\n            population = self.adaptive_differential_evolution(population, func)\n\n            # Apply Dynamic Simulated Annealing on the best solution found so far\n            self.dynamic_simulated_annealing(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Differential Evolution and Dynamic Simulated Annealing for improved convergence and diversity management.", "configspace": "", "generation": 1, "fitness": 0.18093722340970034, "feedback": "The algorithm EnhancedHybridOpt got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.14.", "error": "", "parent_id": "bfcdd831-1929-4e34-8d24-db3ef07a9df0", "metadata": {"aucs": [0.3470618836881473, 0.3493946461065318, 0.3420086569893498, 0.3609172122896762, 0.33884409750597955, 0.36581929348403963, 0.3411581529377439, 0.36032642289516126, 0.37446747817161297, 0.02951359757190819, 0.02350285914170458, 9.999999999998899e-05, 0.038970391330438, 0.00020450778743685838, 0.041386798237816436, 0.0001459209934200345, 0.030927123307416537, 0.036003808225023914, 0.10689395222756926, 0.09364962014968092, 0.10083921734129675, 0.08006353985448544, 0.088657999549831, 0.07438585378747353, 0.08107069578114534, 0.11173632857366989, 0.09002454574141339, 0.03949104603212017, 0.09512338974873003, 0.09286535934777163, 0.050915841171138676, 0.0590988426900787, 0.09482538941036656, 0.09001150685191184, 0.10111356044791042, 0.07680122633867958, 0.8169116332737205, 0.589561628182629, 0.8162851263431774, 0.6631905910956346, 0.21579763541075359, 0.8916264200352267, 0.5374947906173593, 0.5940395787836348, 0.6569399010613302, 0.26356419546161547, 0.3000706784551579, 0.24251640275366648, 0.2606944824685521, 0.2826619288417592, 0.28052034610013876, 0.24525485454659457, 0.26774247480009694, 0.2448168051273657, 0.19860187280629837, 0.3002710638920034, 0.20683047688704637, 0.25697355856180315, 0.28084273962038, 0.26106030600891017, 0.23491151992656756, 0.2320402785791651, 0.25899872853569805, 0.1838131677141841, 0.13284658706736974, 0.18805508505544188, 0.15660704425151384, 0.1992725486205491, 0.1840746422195917, 0.20038550443136605, 0.19654248763773907, 0.22070028615876314, 0.17546162684604605, 0.20242090653032063, 0.19765541659206787, 0.16712660492156717, 0.16972410450366182, 0.22077821559007849, 0.16665286366134857, 0.14562206815551948, 0.20615200165353098, 9.999999999998899e-05, 0.005742397667096388, 0.09084402246290846, 0.06728499337857574, 0.0028183799450384184, 0.002493148689618141, 9.999999999998899e-05, 0.018075907030188465, 0.003027871098777335, 0.06793763206615, 0.10361660505805248, 0.09231910453714953, 0.014262320437660847, 0.12631173196172674, 0.050076511324413375, 0.07247420734148513, 0.08482659239157742, 0.06721586674083169, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09573336804016508, 0.10135757560094538, 0.11420825928064382, 0.10940483062247985, 0.0856475694904506, 0.10100503845164677, 0.11205230968592861, 0.09990378530663657, 0.10362214090182953, 0.35032914472158005, 0.3148071451096316, 0.28681247639448526, 0.3511685589053387, 0.3135615155005057, 0.324761489157552, 0.31808430465726956, 0.29163483517435473, 0.3075502987903286, 0.08370265701211066, 0.14791744537476914, 0.06658476864727036, 0.08216869455719245, 0.07589357094242699, 0.07752123929108534, 0.0986188769466313, 0.089655551969963, 0.0844425448974846, 0.2659594606559327, 0.2015945837466191, 0.18878579220083225, 0.20787313773117577, 0.16538861449416908, 0.20857566796406335, 0.2229343571922182, 0.18746699086465402, 0.21802803208190003, 0.1826838238756452, 0.24904367646890546, 0.20966812618927844, 0.1935729572376117, 0.2219990112402519, 0.2072678294611413, 0.23389751718402219, 0.19375338965440114, 0.20819058174701632, 0.16067928420125843, 0.15350777520101933, 0.17845480368110256, 0.16207638139313207, 0.17409752580683657, 0.1585027171881176, 0.19790682875990184, 0.1841854757674518, 0.13922970707431592, 0.1815125444876745, 0.17840367516555833, 0.1703824260220066, 0.1814869165094608, 0.18420533611980583, 0.1949562861474835, 0.16968005684948984, 0.1666394232955949, 0.20661387717177881, 0.19208142064738443, 0.21016306390604345, 0.18911966045141249, 0.19038473662086186, 0.1927370944021446, 0.19040963049709103, 0.20114020089870221, 0.1825219187650865, 0.18791829236084423, 0.1443161811220276, 0.17682914069289057, 0.16455792505296818, 0.4193081923639279, 0.3610578098411784, 0.17282239547597633, 0.1988499060249821, 0.12702992787919642, 0.12416432820711254, 0.1912276708609879, 0.16015138954832442, 0.22578962958154225, 0.4220111024718023, 0.20617280016385475, 0.168799274594583, 0.1842208302862427, 0.4424535249866416, 0.17751204812282284, 0.19302889752501207, 0.17593410960809508, 0.18449249581793825, 0.19294136972713727, 0.1774955070777694, 0.18389789667302914, 0.18743234248234975, 0.1940237138869546, 0.18383115502042546, 0.06181680518344801, 0.06872127947710083, 0.0659598260663371, 0.06398880925297457, 0.08395028048215714, 0.06042351353983866, 0.07773452469562558, 0.069486141803901, 0.06331766845913822]}, "mutation_prompt": null}
{"id": "c7225b5d-83e5-4c93-b5c1-aa253e9373a5", "solution": "import numpy as np\n\nclass HybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temp = 100\n        self.final_temp = 0.1\n        self.alpha = 0.9\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n\n    def differential_evolution(self, population, fitness):\n        F = 0.8\n        CR = 0.9\n        new_population = np.copy(population)\n\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant = np.clip(population[a] + F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial_fitness = fitness(trial)\n            self.eval_count += 1\n\n            if trial_fitness < fitness(population[i]):\n                new_population[i] = trial\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial\n\n        return new_population\n\n    def simulated_annealing(self, solution, fitness):\n        current_solution = np.copy(solution)\n        current_fitness = fitness(current_solution)\n        temp = self.initial_temp\n\n        while temp > self.final_temp and self.eval_count < self.budget:\n            new_solution = np.clip(current_solution + np.random.uniform(-0.1, 0.1, self.dim), self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_solution)\n            self.eval_count += 1\n\n            if new_fitness < current_fitness or np.exp((current_fitness - new_fitness) / temp) > np.random.rand():\n                current_solution = new_solution\n                current_fitness = new_fitness\n\n                if current_fitness < self.best_fitness:\n                    self.best_fitness = current_fitness\n                    self.best_solution = current_solution\n\n            temp *= self.alpha\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        \n        while self.eval_count < self.budget:\n            # Apply Differential Evolution\n            population = self.differential_evolution(population, func)\n\n            # Apply Simulated Annealing on the best solution found so far\n            self.simulated_annealing(self.best_solution, func)\n\n        return self.best_solution", "name": "HybridOpt", "description": "Hybrid Optimization Algorithm combining Differential Evolution and Simulated Annealing to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "bfcdd831-1929-4e34-8d24-db3ef07a9df0", "metadata": {"aucs": [0.3964858773849391, 0.3640465803351147, 0.3444891768528039, 0.42270033203488266, 0.3831354456834781, 0.35713656670774496, 0.3970950343922113, 0.36131568399628433, 0.3847585768922033, 0.036309102772794755, 0.05044036695075904, 0.02162899811212904, 0.03864572951580414, 0.04557129434643192, 0.03914229994019913, 0.058227653033924964, 0.039080122531747086, 0.07097968181751801, 0.11269348954180636, 0.07906514063966041, 0.07400708454946903, 0.11439090055563794, 0.10094358808678594, 0.09880190295481284, 0.09310986887258155, 0.08341626342332298, 0.08741505419789641, 0.09792207046344104, 0.1002084939782737, 0.06397631306954954, 0.09690816996305418, 0.08504108788620701, 0.11136083579819822, 0.05926864434133983, 0.06640707148372826, 0.07075528612350845, 0.6820411775706903, 0.897334599062181, 0.6053460671757189, 0.8724579209364467, 0.8808811010774106, 0.8091900108200433, 0.855147511162606, 0.6873621749326642, 0.8065922285429874, 0.296555288286271, 0.2688222180491895, 0.2490255881521224, 0.24022758770421937, 0.28798722959677636, 0.22062920349987658, 0.240990509037188, 0.2759775069479228, 0.30412917219246716, 0.20626717529091865, 0.2172436140444346, 0.20379959692968863, 0.24414522232611424, 0.23305967667092808, 0.2034260064676353, 0.20407584209493512, 0.3146798402961778, 0.2139108466900037, 0.18107424723207954, 0.17109482466801418, 0.12846865664068696, 0.18115462301465146, 0.17904651621589218, 0.18781917413207772, 0.19676567073630435, 0.18817025491861528, 0.16429685252899195, 0.18616177357360786, 0.2194441670695575, 0.14192930705591966, 0.12935240653298297, 0.18105888984197405, 0.20548909672516336, 0.1609822646827992, 0.13324912287243473, 0.16523786708984756, 0.017512745214090297, 0.030848092606357236, 9.999999999998899e-05, 0.005655769916225628, 0.0024425576771464064, 0.02731074367194486, 0.12379199884834291, 0.005773293210429964, 9.999999999998899e-05, 0.09297015721938029, 0.10862930377609936, 0.08091461082450047, 0.1082989009417673, 0.0732222697132282, 0.05159383050341915, 0.13031799135314304, 0.07998854341104489, 0.09488556922797253, 0.008419362412300013, 9.999999999998899e-05, 9.999999999998899e-05, 0.020801628104494707, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09836463390707995, 0.07379041560437893, 0.08976510649769154, 0.11622081318712496, 0.09552050489050257, 0.12630138132943125, 0.12332910522806217, 0.10808242955240943, 0.11293162477864294, 0.3286588026078392, 0.39691715969900043, 0.35656014306487827, 0.34591997506154293, 0.3637803847171368, 0.34467276928684154, 0.33854792759590124, 0.32397097036991696, 0.33830476704891854, 0.08550061690054322, 0.0983050316094981, 0.0996534117201281, 0.09285129820382065, 0.10773378863519023, 0.10171848604044065, 0.06790476609671237, 0.10798385755053819, 0.09165214571078972, 0.21348837456377656, 0.1608199389081585, 0.17987670748925788, 0.1724867418981445, 0.17885897410551932, 0.2310842915231266, 0.16384940618740107, 0.270302785455366, 0.16377941509116412, 0.2618136474427828, 0.2432864709895215, 0.21289064034337246, 0.27112296574055705, 0.20474484745347998, 0.23495718134211585, 0.22906276813472182, 0.20968723793657573, 0.23424779884520108, 0.13411664803641976, 0.1776132473597123, 0.1618293035892424, 0.1402363973861609, 0.1853924777018, 0.14296732659096323, 0.15893888184335225, 0.17622542128744312, 0.1509809368662658, 0.1856569265692436, 0.1909922143142142, 0.17536589395591562, 0.19055544916984968, 0.18831309092070914, 0.16505775026160752, 0.1864805096290525, 0.24348446441730498, 0.20110402175121833, 0.18143734329819416, 0.1802647075113022, 0.2067243594620619, 0.1934350065385051, 0.1983391964404827, 0.19978772571470005, 0.18183217143723118, 0.19621636343130122, 0.19755126147375146, 0.17509910805134188, 0.29976022843142924, 0.1498154658949088, 0.1800208275020102, 0.1768973720654139, 0.17192286954446823, 0.17281874840230282, 0.2061085264017274, 0.19835470776632025, 0.176441856103968, 0.29448915806240006, 0.20488212913909432, 0.4715939239864947, 0.5432712936411621, 0.21217510683948382, 0.19885525099673884, 0.20681120984405232, 0.19993528739100475, 0.1716454425144257, 0.18259539352478005, 0.1883027115144419, 0.17589300582287926, 0.18973715296461158, 0.19444329401969795, 0.17574462370211819, 0.1701825668872663, 0.18113215443623443, 0.07341008078837807, 0.06903351691623849, 0.07532915627306358, 0.06200499711354346, 0.06520352989812905, 0.07744084943549112, 0.06857789814774384, 0.0538759529143108, 0.0786212050494236]}, "mutation_prompt": null}
{"id": "c87b4129-54fd-41e9-81f2-f865a839f310", "solution": "import numpy as np\n\nclass HybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temp = 100\n        self.final_temp = 0.1\n        self.alpha = 0.9\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n\n    def differential_evolution(self, population, fitness):\n        F = 0.8\n        CR = 0.9\n        new_population = np.copy(population)\n\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant = np.clip(population[a] + F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial_fitness = fitness(trial)\n            self.eval_count += 1\n\n            if trial_fitness < fitness(population[i]):\n                new_population[i] = trial\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial\n\n        return new_population\n\n    def simulated_annealing(self, solution, fitness):\n        current_solution = np.copy(solution)\n        current_fitness = fitness(current_solution)\n        temp = self.initial_temp\n\n        while temp > self.final_temp and self.eval_count < self.budget:\n            new_solution = np.clip(current_solution + np.random.uniform(-0.1, 0.1, self.dim), self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_solution)\n            self.eval_count += 1\n\n            if new_fitness < current_fitness or np.exp((current_fitness - new_fitness) / temp) > np.random.rand():\n                current_solution = new_solution\n                current_fitness = new_fitness\n\n                if current_fitness < self.best_fitness:\n                    self.best_fitness = current_fitness\n                    self.best_solution = current_solution\n\n            temp *= self.alpha\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        \n        while self.eval_count < self.budget:\n            # Apply Differential Evolution\n            population = self.differential_evolution(population, func)\n\n            # Apply Simulated Annealing on the best solution found so far\n            self.simulated_annealing(self.best_solution, func)\n\n        return self.best_solution", "name": "HybridOpt", "description": "Hybrid Optimization Algorithm combining Differential Evolution and Simulated Annealing to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "bfcdd831-1929-4e34-8d24-db3ef07a9df0", "metadata": {"aucs": [0.3964858773849391, 0.3640465803351147, 0.3444891768528039, 0.42270033203488266, 0.3831354456834781, 0.35713656670774496, 0.3970950343922113, 0.36131568399628433, 0.3847585768922033, 0.036309102772794755, 0.05044036695075904, 0.02162899811212904, 0.03864572951580414, 0.04557129434643192, 0.03914229994019913, 0.058227653033924964, 0.039080122531747086, 0.07097968181751801, 0.11269348954180636, 0.07906514063966041, 0.07400708454946903, 0.11439090055563794, 0.10094358808678594, 0.09880190295481284, 0.09310986887258155, 0.08341626342332298, 0.08741505419789641, 0.09792207046344104, 0.1002084939782737, 0.06397631306954954, 0.09690816996305418, 0.08504108788620701, 0.11136083579819822, 0.05926864434133983, 0.06640707148372826, 0.07075528612350845, 0.6820411775706903, 0.897334599062181, 0.6053460671757189, 0.8724579209364467, 0.8808811010774106, 0.8091900108200433, 0.855147511162606, 0.6873621749326642, 0.8065922285429874, 0.296555288286271, 0.2688222180491895, 0.2490255881521224, 0.24022758770421937, 0.28798722959677636, 0.22062920349987658, 0.240990509037188, 0.2759775069479228, 0.30412917219246716, 0.20626717529091865, 0.2172436140444346, 0.20379959692968863, 0.24414522232611424, 0.23305967667092808, 0.2034260064676353, 0.20407584209493512, 0.3146798402961778, 0.2139108466900037, 0.18107424723207954, 0.17109482466801418, 0.12846865664068696, 0.18115462301465146, 0.17904651621589218, 0.18781917413207772, 0.19676567073630435, 0.18817025491861528, 0.16429685252899195, 0.18616177357360786, 0.2194441670695575, 0.14192930705591966, 0.12935240653298297, 0.18105888984197405, 0.20548909672516336, 0.1609822646827992, 0.13324912287243473, 0.16523786708984756, 0.017512745214090297, 0.030848092606357236, 9.999999999998899e-05, 0.005655769916225628, 0.0024425576771464064, 0.02731074367194486, 0.12379199884834291, 0.005773293210429964, 9.999999999998899e-05, 0.09297015721938029, 0.10862930377609936, 0.08091461082450047, 0.1082989009417673, 0.0732222697132282, 0.05159383050341915, 0.13031799135314304, 0.07998854341104489, 0.09488556922797253, 0.008419362412300013, 9.999999999998899e-05, 9.999999999998899e-05, 0.020801628104494707, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09836463390707995, 0.07379041560437893, 0.08976510649769154, 0.11622081318712496, 0.09552050489050257, 0.12630138132943125, 0.12332910522806217, 0.10808242955240943, 0.11293162477864294, 0.3286588026078392, 0.39691715969900043, 0.35656014306487827, 0.34591997506154293, 0.3637803847171368, 0.34467276928684154, 0.33854792759590124, 0.32397097036991696, 0.33830476704891854, 0.08550061690054322, 0.0983050316094981, 0.0996534117201281, 0.09285129820382065, 0.10773378863519023, 0.10171848604044065, 0.06790476609671237, 0.10798385755053819, 0.09165214571078972, 0.21348837456377656, 0.1608199389081585, 0.17987670748925788, 0.1724867418981445, 0.17885897410551932, 0.2310842915231266, 0.16384940618740107, 0.270302785455366, 0.16377941509116412, 0.2618136474427828, 0.2432864709895215, 0.21289064034337246, 0.27112296574055705, 0.20474484745347998, 0.23495718134211585, 0.22906276813472182, 0.20968723793657573, 0.23424779884520108, 0.13411664803641976, 0.1776132473597123, 0.1618293035892424, 0.1402363973861609, 0.1853924777018, 0.14296732659096323, 0.15893888184335225, 0.17622542128744312, 0.1509809368662658, 0.1856569265692436, 0.1909922143142142, 0.17536589395591562, 0.19055544916984968, 0.18831309092070914, 0.16505775026160752, 0.1864805096290525, 0.24348446441730498, 0.20110402175121833, 0.18143734329819416, 0.1802647075113022, 0.2067243594620619, 0.1934350065385051, 0.1983391964404827, 0.19978772571470005, 0.18183217143723118, 0.19621636343130122, 0.19755126147375146, 0.17509910805134188, 0.29976022843142924, 0.1498154658949088, 0.1800208275020102, 0.1768973720654139, 0.17192286954446823, 0.17281874840230282, 0.2061085264017274, 0.19835470776632025, 0.176441856103968, 0.29448915806240006, 0.20488212913909432, 0.4715939239864947, 0.5432712936411621, 0.21217510683948382, 0.19885525099673884, 0.20681120984405232, 0.19993528739100475, 0.1716454425144257, 0.18259539352478005, 0.1883027115144419, 0.17589300582287926, 0.18973715296461158, 0.19444329401969795, 0.17574462370211819, 0.1701825668872663, 0.18113215443623443, 0.07341008078837807, 0.06903351691623849, 0.07532915627306358, 0.06200499711354346, 0.06520352989812905, 0.07744084943549112, 0.06857789814774384, 0.0538759529143108, 0.0786212050494236]}, "mutation_prompt": null}
{"id": "0726f3e1-e7ff-40a3-8d48-b1b57a727a25", "solution": "import numpy as np\n\nclass HybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temp = 100\n        self.final_temp = 0.1\n        self.alpha = 0.9\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n\n    def differential_evolution(self, population, fitness):\n        F = 0.8\n        CR = 0.9\n        new_population = np.copy(population)\n\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant = np.clip(population[a] + F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial_fitness = fitness(trial)\n            self.eval_count += 1\n\n            if trial_fitness < fitness(population[i]):\n                new_population[i] = trial\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial\n\n        return new_population\n\n    def simulated_annealing(self, solution, fitness):\n        current_solution = np.copy(solution)\n        current_fitness = fitness(current_solution)\n        temp = self.initial_temp\n\n        while temp > self.final_temp and self.eval_count < self.budget:\n            new_solution = np.clip(current_solution + np.random.uniform(-0.1, 0.1, self.dim), self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_solution)\n            self.eval_count += 1\n\n            if new_fitness < current_fitness or np.exp((current_fitness - new_fitness) / temp) > np.random.rand():\n                current_solution = new_solution\n                current_fitness = new_fitness\n\n                if current_fitness < self.best_fitness:\n                    self.best_fitness = current_fitness\n                    self.best_solution = current_solution\n\n            temp *= self.alpha\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        \n        while self.eval_count < self.budget:\n            # Apply Differential Evolution\n            population = self.differential_evolution(population, func)\n\n            # Apply Simulated Annealing on the best solution found so far\n            self.simulated_annealing(self.best_solution, func)\n\n        return self.best_solution", "name": "HybridOpt", "description": "Hybrid Optimization Algorithm combining Differential Evolution and Simulated Annealing to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "bfcdd831-1929-4e34-8d24-db3ef07a9df0", "metadata": {"aucs": [0.3964858773849391, 0.3640465803351147, 0.3444891768528039, 0.42270033203488266, 0.3831354456834781, 0.35713656670774496, 0.3970950343922113, 0.36131568399628433, 0.3847585768922033, 0.036309102772794755, 0.05044036695075904, 0.02162899811212904, 0.03864572951580414, 0.04557129434643192, 0.03914229994019913, 0.058227653033924964, 0.039080122531747086, 0.07097968181751801, 0.11269348954180636, 0.07906514063966041, 0.07400708454946903, 0.11439090055563794, 0.10094358808678594, 0.09880190295481284, 0.09310986887258155, 0.08341626342332298, 0.08741505419789641, 0.09792207046344104, 0.1002084939782737, 0.06397631306954954, 0.09690816996305418, 0.08504108788620701, 0.11136083579819822, 0.05926864434133983, 0.06640707148372826, 0.07075528612350845, 0.6820411775706903, 0.897334599062181, 0.6053460671757189, 0.8724579209364467, 0.8808811010774106, 0.8091900108200433, 0.855147511162606, 0.6873621749326642, 0.8065922285429874, 0.296555288286271, 0.2688222180491895, 0.2490255881521224, 0.24022758770421937, 0.28798722959677636, 0.22062920349987658, 0.240990509037188, 0.2759775069479228, 0.30412917219246716, 0.20626717529091865, 0.2172436140444346, 0.20379959692968863, 0.24414522232611424, 0.23305967667092808, 0.2034260064676353, 0.20407584209493512, 0.3146798402961778, 0.2139108466900037, 0.18107424723207954, 0.17109482466801418, 0.12846865664068696, 0.18115462301465146, 0.17904651621589218, 0.18781917413207772, 0.19676567073630435, 0.18817025491861528, 0.16429685252899195, 0.18616177357360786, 0.2194441670695575, 0.14192930705591966, 0.12935240653298297, 0.18105888984197405, 0.20548909672516336, 0.1609822646827992, 0.13324912287243473, 0.16523786708984756, 0.017512745214090297, 0.030848092606357236, 9.999999999998899e-05, 0.005655769916225628, 0.0024425576771464064, 0.02731074367194486, 0.12379199884834291, 0.005773293210429964, 9.999999999998899e-05, 0.09297015721938029, 0.10862930377609936, 0.08091461082450047, 0.1082989009417673, 0.0732222697132282, 0.05159383050341915, 0.13031799135314304, 0.07998854341104489, 0.09488556922797253, 0.008419362412300013, 9.999999999998899e-05, 9.999999999998899e-05, 0.020801628104494707, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09836463390707995, 0.07379041560437893, 0.08976510649769154, 0.11622081318712496, 0.09552050489050257, 0.12630138132943125, 0.12332910522806217, 0.10808242955240943, 0.11293162477864294, 0.3286588026078392, 0.39691715969900043, 0.35656014306487827, 0.34591997506154293, 0.3637803847171368, 0.34467276928684154, 0.33854792759590124, 0.32397097036991696, 0.33830476704891854, 0.08550061690054322, 0.0983050316094981, 0.0996534117201281, 0.09285129820382065, 0.10773378863519023, 0.10171848604044065, 0.06790476609671237, 0.10798385755053819, 0.09165214571078972, 0.21348837456377656, 0.1608199389081585, 0.17987670748925788, 0.1724867418981445, 0.17885897410551932, 0.2310842915231266, 0.16384940618740107, 0.270302785455366, 0.16377941509116412, 0.2618136474427828, 0.2432864709895215, 0.21289064034337246, 0.27112296574055705, 0.20474484745347998, 0.23495718134211585, 0.22906276813472182, 0.20968723793657573, 0.23424779884520108, 0.13411664803641976, 0.1776132473597123, 0.1618293035892424, 0.1402363973861609, 0.1853924777018, 0.14296732659096323, 0.15893888184335225, 0.17622542128744312, 0.1509809368662658, 0.1856569265692436, 0.1909922143142142, 0.17536589395591562, 0.19055544916984968, 0.18831309092070914, 0.16505775026160752, 0.1864805096290525, 0.24348446441730498, 0.20110402175121833, 0.18143734329819416, 0.1802647075113022, 0.2067243594620619, 0.1934350065385051, 0.1983391964404827, 0.19978772571470005, 0.18183217143723118, 0.19621636343130122, 0.19755126147375146, 0.17509910805134188, 0.29976022843142924, 0.1498154658949088, 0.1800208275020102, 0.1768973720654139, 0.17192286954446823, 0.17281874840230282, 0.2061085264017274, 0.19835470776632025, 0.176441856103968, 0.29448915806240006, 0.20488212913909432, 0.4715939239864947, 0.5432712936411621, 0.21217510683948382, 0.19885525099673884, 0.20681120984405232, 0.19993528739100475, 0.1716454425144257, 0.18259539352478005, 0.1883027115144419, 0.17589300582287926, 0.18973715296461158, 0.19444329401969795, 0.17574462370211819, 0.1701825668872663, 0.18113215443623443, 0.07341008078837807, 0.06903351691623849, 0.07532915627306358, 0.06200499711354346, 0.06520352989812905, 0.07744084943549112, 0.06857789814774384, 0.0538759529143108, 0.0786212050494236]}, "mutation_prompt": null}
{"id": "3f0b937d-7bb8-47b3-827e-656b150beec3", "solution": "import numpy as np\n\nclass HybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temp = 100\n        self.final_temp = 0.1\n        self.alpha = 0.9\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n\n    def differential_evolution(self, population, fitness):\n        F = 0.8\n        CR = 0.9\n        new_population = np.copy(population)\n\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant = np.clip(population[a] + F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial_fitness = fitness(trial)\n            self.eval_count += 1\n\n            if trial_fitness < fitness(population[i]):\n                new_population[i] = trial\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial\n\n        return new_population\n\n    def simulated_annealing(self, solution, fitness):\n        current_solution = np.copy(solution)\n        current_fitness = fitness(current_solution)\n        temp = self.initial_temp\n\n        while temp > self.final_temp and self.eval_count < self.budget:\n            new_solution = np.clip(current_solution + np.random.uniform(-0.1, 0.1, self.dim), self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_solution)\n            self.eval_count += 1\n\n            if new_fitness < current_fitness or np.exp((current_fitness - new_fitness) / temp) > np.random.rand():\n                current_solution = new_solution\n                current_fitness = new_fitness\n\n                if current_fitness < self.best_fitness:\n                    self.best_fitness = current_fitness\n                    self.best_solution = current_solution\n\n            temp *= self.alpha\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        \n        while self.eval_count < self.budget:\n            # Apply Differential Evolution\n            population = self.differential_evolution(population, func)\n\n            # Apply Simulated Annealing on the best solution found so far\n            self.simulated_annealing(self.best_solution, func)\n\n        return self.best_solution", "name": "HybridOpt", "description": "Hybrid Optimization Algorithm combining Differential Evolution and Simulated Annealing to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "bfcdd831-1929-4e34-8d24-db3ef07a9df0", "metadata": {"aucs": [0.3964858773849391, 0.3640465803351147, 0.3444891768528039, 0.42270033203488266, 0.3831354456834781, 0.35713656670774496, 0.3970950343922113, 0.36131568399628433, 0.3847585768922033, 0.036309102772794755, 0.05044036695075904, 0.02162899811212904, 0.03864572951580414, 0.04557129434643192, 0.03914229994019913, 0.058227653033924964, 0.039080122531747086, 0.07097968181751801, 0.11269348954180636, 0.07906514063966041, 0.07400708454946903, 0.11439090055563794, 0.10094358808678594, 0.09880190295481284, 0.09310986887258155, 0.08341626342332298, 0.08741505419789641, 0.09792207046344104, 0.1002084939782737, 0.06397631306954954, 0.09690816996305418, 0.08504108788620701, 0.11136083579819822, 0.05926864434133983, 0.06640707148372826, 0.07075528612350845, 0.6820411775706903, 0.897334599062181, 0.6053460671757189, 0.8724579209364467, 0.8808811010774106, 0.8091900108200433, 0.855147511162606, 0.6873621749326642, 0.8065922285429874, 0.296555288286271, 0.2688222180491895, 0.2490255881521224, 0.24022758770421937, 0.28798722959677636, 0.22062920349987658, 0.240990509037188, 0.2759775069479228, 0.30412917219246716, 0.20626717529091865, 0.2172436140444346, 0.20379959692968863, 0.24414522232611424, 0.23305967667092808, 0.2034260064676353, 0.20407584209493512, 0.3146798402961778, 0.2139108466900037, 0.18107424723207954, 0.17109482466801418, 0.12846865664068696, 0.18115462301465146, 0.17904651621589218, 0.18781917413207772, 0.19676567073630435, 0.18817025491861528, 0.16429685252899195, 0.18616177357360786, 0.2194441670695575, 0.14192930705591966, 0.12935240653298297, 0.18105888984197405, 0.20548909672516336, 0.1609822646827992, 0.13324912287243473, 0.16523786708984756, 0.017512745214090297, 0.030848092606357236, 9.999999999998899e-05, 0.005655769916225628, 0.0024425576771464064, 0.02731074367194486, 0.12379199884834291, 0.005773293210429964, 9.999999999998899e-05, 0.09297015721938029, 0.10862930377609936, 0.08091461082450047, 0.1082989009417673, 0.0732222697132282, 0.05159383050341915, 0.13031799135314304, 0.07998854341104489, 0.09488556922797253, 0.008419362412300013, 9.999999999998899e-05, 9.999999999998899e-05, 0.020801628104494707, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09836463390707995, 0.07379041560437893, 0.08976510649769154, 0.11622081318712496, 0.09552050489050257, 0.12630138132943125, 0.12332910522806217, 0.10808242955240943, 0.11293162477864294, 0.3286588026078392, 0.39691715969900043, 0.35656014306487827, 0.34591997506154293, 0.3637803847171368, 0.34467276928684154, 0.33854792759590124, 0.32397097036991696, 0.33830476704891854, 0.08550061690054322, 0.0983050316094981, 0.0996534117201281, 0.09285129820382065, 0.10773378863519023, 0.10171848604044065, 0.06790476609671237, 0.10798385755053819, 0.09165214571078972, 0.21348837456377656, 0.1608199389081585, 0.17987670748925788, 0.1724867418981445, 0.17885897410551932, 0.2310842915231266, 0.16384940618740107, 0.270302785455366, 0.16377941509116412, 0.2618136474427828, 0.2432864709895215, 0.21289064034337246, 0.27112296574055705, 0.20474484745347998, 0.23495718134211585, 0.22906276813472182, 0.20968723793657573, 0.23424779884520108, 0.13411664803641976, 0.1776132473597123, 0.1618293035892424, 0.1402363973861609, 0.1853924777018, 0.14296732659096323, 0.15893888184335225, 0.17622542128744312, 0.1509809368662658, 0.1856569265692436, 0.1909922143142142, 0.17536589395591562, 0.19055544916984968, 0.18831309092070914, 0.16505775026160752, 0.1864805096290525, 0.24348446441730498, 0.20110402175121833, 0.18143734329819416, 0.1802647075113022, 0.2067243594620619, 0.1934350065385051, 0.1983391964404827, 0.19978772571470005, 0.18183217143723118, 0.19621636343130122, 0.19755126147375146, 0.17509910805134188, 0.29976022843142924, 0.1498154658949088, 0.1800208275020102, 0.1768973720654139, 0.17192286954446823, 0.17281874840230282, 0.2061085264017274, 0.19835470776632025, 0.176441856103968, 0.29448915806240006, 0.20488212913909432, 0.4715939239864947, 0.5432712936411621, 0.21217510683948382, 0.19885525099673884, 0.20681120984405232, 0.19993528739100475, 0.1716454425144257, 0.18259539352478005, 0.1883027115144419, 0.17589300582287926, 0.18973715296461158, 0.19444329401969795, 0.17574462370211819, 0.1701825668872663, 0.18113215443623443, 0.07341008078837807, 0.06903351691623849, 0.07532915627306358, 0.06200499711354346, 0.06520352989812905, 0.07744084943549112, 0.06857789814774384, 0.0538759529143108, 0.0786212050494236]}, "mutation_prompt": null}
{"id": "60ecf498-9059-48b5-9027-fff52d68a3fc", "solution": "import numpy as np\n\nclass HybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temp = 100\n        self.final_temp = 0.1\n        self.alpha = 0.9\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n\n    def differential_evolution(self, population, fitness):\n        F = 0.8\n        CR = 0.9\n        new_population = np.copy(population)\n\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant = np.clip(population[a] + F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial_fitness = fitness(trial)\n            self.eval_count += 1\n\n            if trial_fitness < fitness(population[i]):\n                new_population[i] = trial\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial\n\n        return new_population\n\n    def simulated_annealing(self, solution, fitness):\n        current_solution = np.copy(solution)\n        current_fitness = fitness(current_solution)\n        temp = self.initial_temp\n\n        while temp > self.final_temp and self.eval_count < self.budget:\n            new_solution = np.clip(current_solution + np.random.uniform(-0.1, 0.1, self.dim), self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_solution)\n            self.eval_count += 1\n\n            if new_fitness < current_fitness or np.exp((current_fitness - new_fitness) / temp) > np.random.rand():\n                current_solution = new_solution\n                current_fitness = new_fitness\n\n                if current_fitness < self.best_fitness:\n                    self.best_fitness = current_fitness\n                    self.best_solution = current_solution\n\n            temp *= self.alpha\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        \n        while self.eval_count < self.budget:\n            # Apply Differential Evolution\n            population = self.differential_evolution(population, func)\n\n            # Apply Simulated Annealing on the best solution found so far\n            self.simulated_annealing(self.best_solution, func)\n\n        return self.best_solution", "name": "HybridOpt", "description": "Hybrid Optimization Algorithm combining Differential Evolution and Simulated Annealing to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "bfcdd831-1929-4e34-8d24-db3ef07a9df0", "metadata": {"aucs": [0.3964858773849391, 0.3640465803351147, 0.3444891768528039, 0.42270033203488266, 0.3831354456834781, 0.35713656670774496, 0.3970950343922113, 0.36131568399628433, 0.3847585768922033, 0.036309102772794755, 0.05044036695075904, 0.02162899811212904, 0.03864572951580414, 0.04557129434643192, 0.03914229994019913, 0.058227653033924964, 0.039080122531747086, 0.07097968181751801, 0.11269348954180636, 0.07906514063966041, 0.07400708454946903, 0.11439090055563794, 0.10094358808678594, 0.09880190295481284, 0.09310986887258155, 0.08341626342332298, 0.08741505419789641, 0.09792207046344104, 0.1002084939782737, 0.06397631306954954, 0.09690816996305418, 0.08504108788620701, 0.11136083579819822, 0.05926864434133983, 0.06640707148372826, 0.07075528612350845, 0.6820411775706903, 0.897334599062181, 0.6053460671757189, 0.8724579209364467, 0.8808811010774106, 0.8091900108200433, 0.855147511162606, 0.6873621749326642, 0.8065922285429874, 0.296555288286271, 0.2688222180491895, 0.2490255881521224, 0.24022758770421937, 0.28798722959677636, 0.22062920349987658, 0.240990509037188, 0.2759775069479228, 0.30412917219246716, 0.20626717529091865, 0.2172436140444346, 0.20379959692968863, 0.24414522232611424, 0.23305967667092808, 0.2034260064676353, 0.20407584209493512, 0.3146798402961778, 0.2139108466900037, 0.18107424723207954, 0.17109482466801418, 0.12846865664068696, 0.18115462301465146, 0.17904651621589218, 0.18781917413207772, 0.19676567073630435, 0.18817025491861528, 0.16429685252899195, 0.18616177357360786, 0.2194441670695575, 0.14192930705591966, 0.12935240653298297, 0.18105888984197405, 0.20548909672516336, 0.1609822646827992, 0.13324912287243473, 0.16523786708984756, 0.017512745214090297, 0.030848092606357236, 9.999999999998899e-05, 0.005655769916225628, 0.0024425576771464064, 0.02731074367194486, 0.12379199884834291, 0.005773293210429964, 9.999999999998899e-05, 0.09297015721938029, 0.10862930377609936, 0.08091461082450047, 0.1082989009417673, 0.0732222697132282, 0.05159383050341915, 0.13031799135314304, 0.07998854341104489, 0.09488556922797253, 0.008419362412300013, 9.999999999998899e-05, 9.999999999998899e-05, 0.020801628104494707, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09836463390707995, 0.07379041560437893, 0.08976510649769154, 0.11622081318712496, 0.09552050489050257, 0.12630138132943125, 0.12332910522806217, 0.10808242955240943, 0.11293162477864294, 0.3286588026078392, 0.39691715969900043, 0.35656014306487827, 0.34591997506154293, 0.3637803847171368, 0.34467276928684154, 0.33854792759590124, 0.32397097036991696, 0.33830476704891854, 0.08550061690054322, 0.0983050316094981, 0.0996534117201281, 0.09285129820382065, 0.10773378863519023, 0.10171848604044065, 0.06790476609671237, 0.10798385755053819, 0.09165214571078972, 0.21348837456377656, 0.1608199389081585, 0.17987670748925788, 0.1724867418981445, 0.17885897410551932, 0.2310842915231266, 0.16384940618740107, 0.270302785455366, 0.16377941509116412, 0.2618136474427828, 0.2432864709895215, 0.21289064034337246, 0.27112296574055705, 0.20474484745347998, 0.23495718134211585, 0.22906276813472182, 0.20968723793657573, 0.23424779884520108, 0.13411664803641976, 0.1776132473597123, 0.1618293035892424, 0.1402363973861609, 0.1853924777018, 0.14296732659096323, 0.15893888184335225, 0.17622542128744312, 0.1509809368662658, 0.1856569265692436, 0.1909922143142142, 0.17536589395591562, 0.19055544916984968, 0.18831309092070914, 0.16505775026160752, 0.1864805096290525, 0.24348446441730498, 0.20110402175121833, 0.18143734329819416, 0.1802647075113022, 0.2067243594620619, 0.1934350065385051, 0.1983391964404827, 0.19978772571470005, 0.18183217143723118, 0.19621636343130122, 0.19755126147375146, 0.17509910805134188, 0.29976022843142924, 0.1498154658949088, 0.1800208275020102, 0.1768973720654139, 0.17192286954446823, 0.17281874840230282, 0.2061085264017274, 0.19835470776632025, 0.176441856103968, 0.29448915806240006, 0.20488212913909432, 0.4715939239864947, 0.5432712936411621, 0.21217510683948382, 0.19885525099673884, 0.20681120984405232, 0.19993528739100475, 0.1716454425144257, 0.18259539352478005, 0.1883027115144419, 0.17589300582287926, 0.18973715296461158, 0.19444329401969795, 0.17574462370211819, 0.1701825668872663, 0.18113215443623443, 0.07341008078837807, 0.06903351691623849, 0.07532915627306358, 0.06200499711354346, 0.06520352989812905, 0.07744084943549112, 0.06857789814774384, 0.0538759529143108, 0.0786212050494236]}, "mutation_prompt": null}
{"id": "62f94f1f-8e5e-4c66-a93a-0c6713095edd", "solution": "import numpy as np\n\nclass HybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temp = 100\n        self.final_temp = 0.1\n        self.alpha = 0.9\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n\n    def differential_evolution(self, population, fitness):\n        F = 0.8\n        CR = 0.9\n        new_population = np.copy(population)\n\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant = np.clip(population[a] + F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial_fitness = fitness(trial)\n            self.eval_count += 1\n\n            if trial_fitness < fitness(population[i]):\n                new_population[i] = trial\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial\n\n        return new_population\n\n    def simulated_annealing(self, solution, fitness):\n        current_solution = np.copy(solution)\n        current_fitness = fitness(current_solution)\n        temp = self.initial_temp\n\n        while temp > self.final_temp and self.eval_count < self.budget:\n            new_solution = np.clip(current_solution + np.random.uniform(-0.1, 0.1, self.dim), self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_solution)\n            self.eval_count += 1\n\n            if new_fitness < current_fitness or np.exp((current_fitness - new_fitness) / temp) > np.random.rand():\n                current_solution = new_solution\n                current_fitness = new_fitness\n\n                if current_fitness < self.best_fitness:\n                    self.best_fitness = current_fitness\n                    self.best_solution = current_solution\n\n            temp *= self.alpha\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        \n        while self.eval_count < self.budget:\n            # Apply Differential Evolution\n            population = self.differential_evolution(population, func)\n\n            # Apply Simulated Annealing on the best solution found so far\n            self.simulated_annealing(self.best_solution, func)\n\n        return self.best_solution", "name": "HybridOpt", "description": "Hybrid Optimization Algorithm combining Differential Evolution and Simulated Annealing to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "bfcdd831-1929-4e34-8d24-db3ef07a9df0", "metadata": {"aucs": [0.3964858773849391, 0.3640465803351147, 0.3444891768528039, 0.42270033203488266, 0.3831354456834781, 0.35713656670774496, 0.3970950343922113, 0.36131568399628433, 0.3847585768922033, 0.036309102772794755, 0.05044036695075904, 0.02162899811212904, 0.03864572951580414, 0.04557129434643192, 0.03914229994019913, 0.058227653033924964, 0.039080122531747086, 0.07097968181751801, 0.11269348954180636, 0.07906514063966041, 0.07400708454946903, 0.11439090055563794, 0.10094358808678594, 0.09880190295481284, 0.09310986887258155, 0.08341626342332298, 0.08741505419789641, 0.09792207046344104, 0.1002084939782737, 0.06397631306954954, 0.09690816996305418, 0.08504108788620701, 0.11136083579819822, 0.05926864434133983, 0.06640707148372826, 0.07075528612350845, 0.6820411775706903, 0.897334599062181, 0.6053460671757189, 0.8724579209364467, 0.8808811010774106, 0.8091900108200433, 0.855147511162606, 0.6873621749326642, 0.8065922285429874, 0.296555288286271, 0.2688222180491895, 0.2490255881521224, 0.24022758770421937, 0.28798722959677636, 0.22062920349987658, 0.240990509037188, 0.2759775069479228, 0.30412917219246716, 0.20626717529091865, 0.2172436140444346, 0.20379959692968863, 0.24414522232611424, 0.23305967667092808, 0.2034260064676353, 0.20407584209493512, 0.3146798402961778, 0.2139108466900037, 0.18107424723207954, 0.17109482466801418, 0.12846865664068696, 0.18115462301465146, 0.17904651621589218, 0.18781917413207772, 0.19676567073630435, 0.18817025491861528, 0.16429685252899195, 0.18616177357360786, 0.2194441670695575, 0.14192930705591966, 0.12935240653298297, 0.18105888984197405, 0.20548909672516336, 0.1609822646827992, 0.13324912287243473, 0.16523786708984756, 0.017512745214090297, 0.030848092606357236, 9.999999999998899e-05, 0.005655769916225628, 0.0024425576771464064, 0.02731074367194486, 0.12379199884834291, 0.005773293210429964, 9.999999999998899e-05, 0.09297015721938029, 0.10862930377609936, 0.08091461082450047, 0.1082989009417673, 0.0732222697132282, 0.05159383050341915, 0.13031799135314304, 0.07998854341104489, 0.09488556922797253, 0.008419362412300013, 9.999999999998899e-05, 9.999999999998899e-05, 0.020801628104494707, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09836463390707995, 0.07379041560437893, 0.08976510649769154, 0.11622081318712496, 0.09552050489050257, 0.12630138132943125, 0.12332910522806217, 0.10808242955240943, 0.11293162477864294, 0.3286588026078392, 0.39691715969900043, 0.35656014306487827, 0.34591997506154293, 0.3637803847171368, 0.34467276928684154, 0.33854792759590124, 0.32397097036991696, 0.33830476704891854, 0.08550061690054322, 0.0983050316094981, 0.0996534117201281, 0.09285129820382065, 0.10773378863519023, 0.10171848604044065, 0.06790476609671237, 0.10798385755053819, 0.09165214571078972, 0.21348837456377656, 0.1608199389081585, 0.17987670748925788, 0.1724867418981445, 0.17885897410551932, 0.2310842915231266, 0.16384940618740107, 0.270302785455366, 0.16377941509116412, 0.2618136474427828, 0.2432864709895215, 0.21289064034337246, 0.27112296574055705, 0.20474484745347998, 0.23495718134211585, 0.22906276813472182, 0.20968723793657573, 0.23424779884520108, 0.13411664803641976, 0.1776132473597123, 0.1618293035892424, 0.1402363973861609, 0.1853924777018, 0.14296732659096323, 0.15893888184335225, 0.17622542128744312, 0.1509809368662658, 0.1856569265692436, 0.1909922143142142, 0.17536589395591562, 0.19055544916984968, 0.18831309092070914, 0.16505775026160752, 0.1864805096290525, 0.24348446441730498, 0.20110402175121833, 0.18143734329819416, 0.1802647075113022, 0.2067243594620619, 0.1934350065385051, 0.1983391964404827, 0.19978772571470005, 0.18183217143723118, 0.19621636343130122, 0.19755126147375146, 0.17509910805134188, 0.29976022843142924, 0.1498154658949088, 0.1800208275020102, 0.1768973720654139, 0.17192286954446823, 0.17281874840230282, 0.2061085264017274, 0.19835470776632025, 0.176441856103968, 0.29448915806240006, 0.20488212913909432, 0.4715939239864947, 0.5432712936411621, 0.21217510683948382, 0.19885525099673884, 0.20681120984405232, 0.19993528739100475, 0.1716454425144257, 0.18259539352478005, 0.1883027115144419, 0.17589300582287926, 0.18973715296461158, 0.19444329401969795, 0.17574462370211819, 0.1701825668872663, 0.18113215443623443, 0.07341008078837807, 0.06903351691623849, 0.07532915627306358, 0.06200499711354346, 0.06520352989812905, 0.07744084943549112, 0.06857789814774384, 0.0538759529143108, 0.0786212050494236]}, "mutation_prompt": null}
{"id": "c9b11695-1980-414a-ad8d-9990d8d29943", "solution": "import numpy as np\n\nclass HybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temp = 100\n        self.final_temp = 0.1\n        self.alpha = 0.9\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n\n    def differential_evolution(self, population, fitness):\n        F = 0.8\n        CR = 0.9\n        new_population = np.copy(population)\n\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant = np.clip(population[a] + F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial_fitness = fitness(trial)\n            self.eval_count += 1\n\n            if trial_fitness < fitness(population[i]):\n                new_population[i] = trial\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial\n\n        return new_population\n\n    def simulated_annealing(self, solution, fitness):\n        current_solution = np.copy(solution)\n        current_fitness = fitness(current_solution)\n        temp = self.initial_temp\n\n        while temp > self.final_temp and self.eval_count < self.budget:\n            new_solution = np.clip(current_solution + np.random.uniform(-0.1, 0.1, self.dim), self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_solution)\n            self.eval_count += 1\n\n            if new_fitness < current_fitness or np.exp((current_fitness - new_fitness) / temp) > np.random.rand():\n                current_solution = new_solution\n                current_fitness = new_fitness\n\n                if current_fitness < self.best_fitness:\n                    self.best_fitness = current_fitness\n                    self.best_solution = current_solution\n\n            temp *= self.alpha\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        \n        while self.eval_count < self.budget:\n            # Apply Differential Evolution\n            population = self.differential_evolution(population, func)\n\n            # Apply Simulated Annealing on the best solution found so far\n            self.simulated_annealing(self.best_solution, func)\n\n        return self.best_solution", "name": "HybridOpt", "description": "Hybrid Optimization Algorithm combining Differential Evolution and Simulated Annealing to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "bfcdd831-1929-4e34-8d24-db3ef07a9df0", "metadata": {"aucs": [0.3964858773849391, 0.3640465803351147, 0.3444891768528039, 0.42270033203488266, 0.3831354456834781, 0.35713656670774496, 0.3970950343922113, 0.36131568399628433, 0.3847585768922033, 0.036309102772794755, 0.05044036695075904, 0.02162899811212904, 0.03864572951580414, 0.04557129434643192, 0.03914229994019913, 0.058227653033924964, 0.039080122531747086, 0.07097968181751801, 0.11269348954180636, 0.07906514063966041, 0.07400708454946903, 0.11439090055563794, 0.10094358808678594, 0.09880190295481284, 0.09310986887258155, 0.08341626342332298, 0.08741505419789641, 0.09792207046344104, 0.1002084939782737, 0.06397631306954954, 0.09690816996305418, 0.08504108788620701, 0.11136083579819822, 0.05926864434133983, 0.06640707148372826, 0.07075528612350845, 0.6820411775706903, 0.897334599062181, 0.6053460671757189, 0.8724579209364467, 0.8808811010774106, 0.8091900108200433, 0.855147511162606, 0.6873621749326642, 0.8065922285429874, 0.296555288286271, 0.2688222180491895, 0.2490255881521224, 0.24022758770421937, 0.28798722959677636, 0.22062920349987658, 0.240990509037188, 0.2759775069479228, 0.30412917219246716, 0.20626717529091865, 0.2172436140444346, 0.20379959692968863, 0.24414522232611424, 0.23305967667092808, 0.2034260064676353, 0.20407584209493512, 0.3146798402961778, 0.2139108466900037, 0.18107424723207954, 0.17109482466801418, 0.12846865664068696, 0.18115462301465146, 0.17904651621589218, 0.18781917413207772, 0.19676567073630435, 0.18817025491861528, 0.16429685252899195, 0.18616177357360786, 0.2194441670695575, 0.14192930705591966, 0.12935240653298297, 0.18105888984197405, 0.20548909672516336, 0.1609822646827992, 0.13324912287243473, 0.16523786708984756, 0.017512745214090297, 0.030848092606357236, 9.999999999998899e-05, 0.005655769916225628, 0.0024425576771464064, 0.02731074367194486, 0.12379199884834291, 0.005773293210429964, 9.999999999998899e-05, 0.09297015721938029, 0.10862930377609936, 0.08091461082450047, 0.1082989009417673, 0.0732222697132282, 0.05159383050341915, 0.13031799135314304, 0.07998854341104489, 0.09488556922797253, 0.008419362412300013, 9.999999999998899e-05, 9.999999999998899e-05, 0.020801628104494707, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09836463390707995, 0.07379041560437893, 0.08976510649769154, 0.11622081318712496, 0.09552050489050257, 0.12630138132943125, 0.12332910522806217, 0.10808242955240943, 0.11293162477864294, 0.3286588026078392, 0.39691715969900043, 0.35656014306487827, 0.34591997506154293, 0.3637803847171368, 0.34467276928684154, 0.33854792759590124, 0.32397097036991696, 0.33830476704891854, 0.08550061690054322, 0.0983050316094981, 0.0996534117201281, 0.09285129820382065, 0.10773378863519023, 0.10171848604044065, 0.06790476609671237, 0.10798385755053819, 0.09165214571078972, 0.21348837456377656, 0.1608199389081585, 0.17987670748925788, 0.1724867418981445, 0.17885897410551932, 0.2310842915231266, 0.16384940618740107, 0.270302785455366, 0.16377941509116412, 0.2618136474427828, 0.2432864709895215, 0.21289064034337246, 0.27112296574055705, 0.20474484745347998, 0.23495718134211585, 0.22906276813472182, 0.20968723793657573, 0.23424779884520108, 0.13411664803641976, 0.1776132473597123, 0.1618293035892424, 0.1402363973861609, 0.1853924777018, 0.14296732659096323, 0.15893888184335225, 0.17622542128744312, 0.1509809368662658, 0.1856569265692436, 0.1909922143142142, 0.17536589395591562, 0.19055544916984968, 0.18831309092070914, 0.16505775026160752, 0.1864805096290525, 0.24348446441730498, 0.20110402175121833, 0.18143734329819416, 0.1802647075113022, 0.2067243594620619, 0.1934350065385051, 0.1983391964404827, 0.19978772571470005, 0.18183217143723118, 0.19621636343130122, 0.19755126147375146, 0.17509910805134188, 0.29976022843142924, 0.1498154658949088, 0.1800208275020102, 0.1768973720654139, 0.17192286954446823, 0.17281874840230282, 0.2061085264017274, 0.19835470776632025, 0.176441856103968, 0.29448915806240006, 0.20488212913909432, 0.4715939239864947, 0.5432712936411621, 0.21217510683948382, 0.19885525099673884, 0.20681120984405232, 0.19993528739100475, 0.1716454425144257, 0.18259539352478005, 0.1883027115144419, 0.17589300582287926, 0.18973715296461158, 0.19444329401969795, 0.17574462370211819, 0.1701825668872663, 0.18113215443623443, 0.07341008078837807, 0.06903351691623849, 0.07532915627306358, 0.06200499711354346, 0.06520352989812905, 0.07744084943549112, 0.06857789814774384, 0.0538759529143108, 0.0786212050494236]}, "mutation_prompt": null}
{"id": "31ec0635-4073-4f9b-bad7-08454461b6fe", "solution": "import numpy as np\n\nclass HybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temp = 100\n        self.final_temp = 0.1\n        self.alpha = 0.9\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n\n    def differential_evolution(self, population, fitness):\n        F = 0.8\n        CR = 0.9\n        new_population = np.copy(population)\n\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant = np.clip(population[a] + F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial_fitness = fitness(trial)\n            self.eval_count += 1\n\n            if trial_fitness < fitness(population[i]):\n                new_population[i] = trial\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial\n\n        return new_population\n\n    def simulated_annealing(self, solution, fitness):\n        current_solution = np.copy(solution)\n        current_fitness = fitness(current_solution)\n        temp = self.initial_temp\n\n        while temp > self.final_temp and self.eval_count < self.budget:\n            new_solution = np.clip(current_solution + np.random.uniform(-0.1, 0.1, self.dim), self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_solution)\n            self.eval_count += 1\n\n            if new_fitness < current_fitness or np.exp((current_fitness - new_fitness) / temp) > np.random.rand():\n                current_solution = new_solution\n                current_fitness = new_fitness\n\n                if current_fitness < self.best_fitness:\n                    self.best_fitness = current_fitness\n                    self.best_solution = current_solution\n\n            temp *= self.alpha\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        \n        while self.eval_count < self.budget:\n            # Apply Differential Evolution\n            population = self.differential_evolution(population, func)\n\n            # Apply Simulated Annealing on the best solution found so far\n            self.simulated_annealing(self.best_solution, func)\n\n        return self.best_solution", "name": "HybridOpt", "description": "Hybrid Optimization Algorithm combining Differential Evolution and Simulated Annealing to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "bfcdd831-1929-4e34-8d24-db3ef07a9df0", "metadata": {"aucs": [0.3964858773849391, 0.3640465803351147, 0.3444891768528039, 0.42270033203488266, 0.3831354456834781, 0.35713656670774496, 0.3970950343922113, 0.36131568399628433, 0.3847585768922033, 0.036309102772794755, 0.05044036695075904, 0.02162899811212904, 0.03864572951580414, 0.04557129434643192, 0.03914229994019913, 0.058227653033924964, 0.039080122531747086, 0.07097968181751801, 0.11269348954180636, 0.07906514063966041, 0.07400708454946903, 0.11439090055563794, 0.10094358808678594, 0.09880190295481284, 0.09310986887258155, 0.08341626342332298, 0.08741505419789641, 0.09792207046344104, 0.1002084939782737, 0.06397631306954954, 0.09690816996305418, 0.08504108788620701, 0.11136083579819822, 0.05926864434133983, 0.06640707148372826, 0.07075528612350845, 0.6820411775706903, 0.897334599062181, 0.6053460671757189, 0.8724579209364467, 0.8808811010774106, 0.8091900108200433, 0.855147511162606, 0.6873621749326642, 0.8065922285429874, 0.296555288286271, 0.2688222180491895, 0.2490255881521224, 0.24022758770421937, 0.28798722959677636, 0.22062920349987658, 0.240990509037188, 0.2759775069479228, 0.30412917219246716, 0.20626717529091865, 0.2172436140444346, 0.20379959692968863, 0.24414522232611424, 0.23305967667092808, 0.2034260064676353, 0.20407584209493512, 0.3146798402961778, 0.2139108466900037, 0.18107424723207954, 0.17109482466801418, 0.12846865664068696, 0.18115462301465146, 0.17904651621589218, 0.18781917413207772, 0.19676567073630435, 0.18817025491861528, 0.16429685252899195, 0.18616177357360786, 0.2194441670695575, 0.14192930705591966, 0.12935240653298297, 0.18105888984197405, 0.20548909672516336, 0.1609822646827992, 0.13324912287243473, 0.16523786708984756, 0.017512745214090297, 0.030848092606357236, 9.999999999998899e-05, 0.005655769916225628, 0.0024425576771464064, 0.02731074367194486, 0.12379199884834291, 0.005773293210429964, 9.999999999998899e-05, 0.09297015721938029, 0.10862930377609936, 0.08091461082450047, 0.1082989009417673, 0.0732222697132282, 0.05159383050341915, 0.13031799135314304, 0.07998854341104489, 0.09488556922797253, 0.008419362412300013, 9.999999999998899e-05, 9.999999999998899e-05, 0.020801628104494707, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09836463390707995, 0.07379041560437893, 0.08976510649769154, 0.11622081318712496, 0.09552050489050257, 0.12630138132943125, 0.12332910522806217, 0.10808242955240943, 0.11293162477864294, 0.3286588026078392, 0.39691715969900043, 0.35656014306487827, 0.34591997506154293, 0.3637803847171368, 0.34467276928684154, 0.33854792759590124, 0.32397097036991696, 0.33830476704891854, 0.08550061690054322, 0.0983050316094981, 0.0996534117201281, 0.09285129820382065, 0.10773378863519023, 0.10171848604044065, 0.06790476609671237, 0.10798385755053819, 0.09165214571078972, 0.21348837456377656, 0.1608199389081585, 0.17987670748925788, 0.1724867418981445, 0.17885897410551932, 0.2310842915231266, 0.16384940618740107, 0.270302785455366, 0.16377941509116412, 0.2618136474427828, 0.2432864709895215, 0.21289064034337246, 0.27112296574055705, 0.20474484745347998, 0.23495718134211585, 0.22906276813472182, 0.20968723793657573, 0.23424779884520108, 0.13411664803641976, 0.1776132473597123, 0.1618293035892424, 0.1402363973861609, 0.1853924777018, 0.14296732659096323, 0.15893888184335225, 0.17622542128744312, 0.1509809368662658, 0.1856569265692436, 0.1909922143142142, 0.17536589395591562, 0.19055544916984968, 0.18831309092070914, 0.16505775026160752, 0.1864805096290525, 0.24348446441730498, 0.20110402175121833, 0.18143734329819416, 0.1802647075113022, 0.2067243594620619, 0.1934350065385051, 0.1983391964404827, 0.19978772571470005, 0.18183217143723118, 0.19621636343130122, 0.19755126147375146, 0.17509910805134188, 0.29976022843142924, 0.1498154658949088, 0.1800208275020102, 0.1768973720654139, 0.17192286954446823, 0.17281874840230282, 0.2061085264017274, 0.19835470776632025, 0.176441856103968, 0.29448915806240006, 0.20488212913909432, 0.4715939239864947, 0.5432712936411621, 0.21217510683948382, 0.19885525099673884, 0.20681120984405232, 0.19993528739100475, 0.1716454425144257, 0.18259539352478005, 0.1883027115144419, 0.17589300582287926, 0.18973715296461158, 0.19444329401969795, 0.17574462370211819, 0.1701825668872663, 0.18113215443623443, 0.07341008078837807, 0.06903351691623849, 0.07532915627306358, 0.06200499711354346, 0.06520352989812905, 0.07744084943549112, 0.06857789814774384, 0.0538759529143108, 0.0786212050494236]}, "mutation_prompt": null}
{"id": "146f2ef3-a0a5-4d1f-8db5-0e9e04d0b984", "solution": "import numpy as np\n\nclass HybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temp = 100\n        self.final_temp = 0.1\n        self.alpha = 0.9\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n\n    def differential_evolution(self, population, fitness):\n        F = 0.8\n        CR = 0.9\n        new_population = np.copy(population)\n\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant = np.clip(population[a] + F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial_fitness = fitness(trial)\n            self.eval_count += 1\n\n            if trial_fitness < fitness(population[i]):\n                new_population[i] = trial\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial\n\n        return new_population\n\n    def simulated_annealing(self, solution, fitness):\n        current_solution = np.copy(solution)\n        current_fitness = fitness(current_solution)\n        temp = self.initial_temp\n\n        while temp > self.final_temp and self.eval_count < self.budget:\n            new_solution = np.clip(current_solution + np.random.uniform(-0.1, 0.1, self.dim), self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_solution)\n            self.eval_count += 1\n\n            if new_fitness < current_fitness or np.exp((current_fitness - new_fitness) / temp) > np.random.rand():\n                current_solution = new_solution\n                current_fitness = new_fitness\n\n                if current_fitness < self.best_fitness:\n                    self.best_fitness = current_fitness\n                    self.best_solution = current_solution\n\n            temp *= self.alpha\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        \n        while self.eval_count < self.budget:\n            # Apply Differential Evolution\n            population = self.differential_evolution(population, func)\n\n            # Apply Simulated Annealing on the best solution found so far\n            self.simulated_annealing(self.best_solution, func)\n\n        return self.best_solution", "name": "HybridOpt", "description": "Hybrid Optimization Algorithm combining Differential Evolution and Simulated Annealing to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "bfcdd831-1929-4e34-8d24-db3ef07a9df0", "metadata": {"aucs": [0.3964858773849391, 0.3640465803351147, 0.3444891768528039, 0.42270033203488266, 0.3831354456834781, 0.35713656670774496, 0.3970950343922113, 0.36131568399628433, 0.3847585768922033, 0.036309102772794755, 0.05044036695075904, 0.02162899811212904, 0.03864572951580414, 0.04557129434643192, 0.03914229994019913, 0.058227653033924964, 0.039080122531747086, 0.07097968181751801, 0.11269348954180636, 0.07906514063966041, 0.07400708454946903, 0.11439090055563794, 0.10094358808678594, 0.09880190295481284, 0.09310986887258155, 0.08341626342332298, 0.08741505419789641, 0.09792207046344104, 0.1002084939782737, 0.06397631306954954, 0.09690816996305418, 0.08504108788620701, 0.11136083579819822, 0.05926864434133983, 0.06640707148372826, 0.07075528612350845, 0.6820411775706903, 0.897334599062181, 0.6053460671757189, 0.8724579209364467, 0.8808811010774106, 0.8091900108200433, 0.855147511162606, 0.6873621749326642, 0.8065922285429874, 0.296555288286271, 0.2688222180491895, 0.2490255881521224, 0.24022758770421937, 0.28798722959677636, 0.22062920349987658, 0.240990509037188, 0.2759775069479228, 0.30412917219246716, 0.20626717529091865, 0.2172436140444346, 0.20379959692968863, 0.24414522232611424, 0.23305967667092808, 0.2034260064676353, 0.20407584209493512, 0.3146798402961778, 0.2139108466900037, 0.18107424723207954, 0.17109482466801418, 0.12846865664068696, 0.18115462301465146, 0.17904651621589218, 0.18781917413207772, 0.19676567073630435, 0.18817025491861528, 0.16429685252899195, 0.18616177357360786, 0.2194441670695575, 0.14192930705591966, 0.12935240653298297, 0.18105888984197405, 0.20548909672516336, 0.1609822646827992, 0.13324912287243473, 0.16523786708984756, 0.017512745214090297, 0.030848092606357236, 9.999999999998899e-05, 0.005655769916225628, 0.0024425576771464064, 0.02731074367194486, 0.12379199884834291, 0.005773293210429964, 9.999999999998899e-05, 0.09297015721938029, 0.10862930377609936, 0.08091461082450047, 0.1082989009417673, 0.0732222697132282, 0.05159383050341915, 0.13031799135314304, 0.07998854341104489, 0.09488556922797253, 0.008419362412300013, 9.999999999998899e-05, 9.999999999998899e-05, 0.020801628104494707, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09836463390707995, 0.07379041560437893, 0.08976510649769154, 0.11622081318712496, 0.09552050489050257, 0.12630138132943125, 0.12332910522806217, 0.10808242955240943, 0.11293162477864294, 0.3286588026078392, 0.39691715969900043, 0.35656014306487827, 0.34591997506154293, 0.3637803847171368, 0.34467276928684154, 0.33854792759590124, 0.32397097036991696, 0.33830476704891854, 0.08550061690054322, 0.0983050316094981, 0.0996534117201281, 0.09285129820382065, 0.10773378863519023, 0.10171848604044065, 0.06790476609671237, 0.10798385755053819, 0.09165214571078972, 0.21348837456377656, 0.1608199389081585, 0.17987670748925788, 0.1724867418981445, 0.17885897410551932, 0.2310842915231266, 0.16384940618740107, 0.270302785455366, 0.16377941509116412, 0.2618136474427828, 0.2432864709895215, 0.21289064034337246, 0.27112296574055705, 0.20474484745347998, 0.23495718134211585, 0.22906276813472182, 0.20968723793657573, 0.23424779884520108, 0.13411664803641976, 0.1776132473597123, 0.1618293035892424, 0.1402363973861609, 0.1853924777018, 0.14296732659096323, 0.15893888184335225, 0.17622542128744312, 0.1509809368662658, 0.1856569265692436, 0.1909922143142142, 0.17536589395591562, 0.19055544916984968, 0.18831309092070914, 0.16505775026160752, 0.1864805096290525, 0.24348446441730498, 0.20110402175121833, 0.18143734329819416, 0.1802647075113022, 0.2067243594620619, 0.1934350065385051, 0.1983391964404827, 0.19978772571470005, 0.18183217143723118, 0.19621636343130122, 0.19755126147375146, 0.17509910805134188, 0.29976022843142924, 0.1498154658949088, 0.1800208275020102, 0.1768973720654139, 0.17192286954446823, 0.17281874840230282, 0.2061085264017274, 0.19835470776632025, 0.176441856103968, 0.29448915806240006, 0.20488212913909432, 0.4715939239864947, 0.5432712936411621, 0.21217510683948382, 0.19885525099673884, 0.20681120984405232, 0.19993528739100475, 0.1716454425144257, 0.18259539352478005, 0.1883027115144419, 0.17589300582287926, 0.18973715296461158, 0.19444329401969795, 0.17574462370211819, 0.1701825668872663, 0.18113215443623443, 0.07341008078837807, 0.06903351691623849, 0.07532915627306358, 0.06200499711354346, 0.06520352989812905, 0.07744084943549112, 0.06857789814774384, 0.0538759529143108, 0.0786212050494236]}, "mutation_prompt": null}
{"id": "7189a646-db2c-47fb-9238-b6768783cb5c", "solution": "import numpy as np\n\nclass HybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temp = 100\n        self.final_temp = 0.1\n        self.alpha = 0.9\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n\n    def differential_evolution(self, population, fitness):\n        F = 0.8\n        CR = 0.9\n        new_population = np.copy(population)\n\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant = np.clip(population[a] + F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial_fitness = fitness(trial)\n            self.eval_count += 1\n\n            if trial_fitness < fitness(population[i]):\n                new_population[i] = trial\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial\n\n        return new_population\n\n    def simulated_annealing(self, solution, fitness):\n        current_solution = np.copy(solution)\n        current_fitness = fitness(current_solution)\n        temp = self.initial_temp\n\n        while temp > self.final_temp and self.eval_count < self.budget:\n            new_solution = np.clip(current_solution + np.random.uniform(-0.1, 0.1, self.dim), self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_solution)\n            self.eval_count += 1\n\n            if new_fitness < current_fitness or np.exp((current_fitness - new_fitness) / temp) > np.random.rand():\n                current_solution = new_solution\n                current_fitness = new_fitness\n\n                if current_fitness < self.best_fitness:\n                    self.best_fitness = current_fitness\n                    self.best_solution = current_solution\n\n            temp *= self.alpha\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        \n        while self.eval_count < self.budget:\n            # Apply Differential Evolution\n            population = self.differential_evolution(population, func)\n\n            # Apply Simulated Annealing on the best solution found so far\n            self.simulated_annealing(self.best_solution, func)\n\n        return self.best_solution", "name": "HybridOpt", "description": "Hybrid Optimization Algorithm combining Differential Evolution and Simulated Annealing to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "bfcdd831-1929-4e34-8d24-db3ef07a9df0", "metadata": {"aucs": [0.3964858773849391, 0.3640465803351147, 0.3444891768528039, 0.42270033203488266, 0.3831354456834781, 0.35713656670774496, 0.3970950343922113, 0.36131568399628433, 0.3847585768922033, 0.036309102772794755, 0.05044036695075904, 0.02162899811212904, 0.03864572951580414, 0.04557129434643192, 0.03914229994019913, 0.058227653033924964, 0.039080122531747086, 0.07097968181751801, 0.11269348954180636, 0.07906514063966041, 0.07400708454946903, 0.11439090055563794, 0.10094358808678594, 0.09880190295481284, 0.09310986887258155, 0.08341626342332298, 0.08741505419789641, 0.09792207046344104, 0.1002084939782737, 0.06397631306954954, 0.09690816996305418, 0.08504108788620701, 0.11136083579819822, 0.05926864434133983, 0.06640707148372826, 0.07075528612350845, 0.6820411775706903, 0.897334599062181, 0.6053460671757189, 0.8724579209364467, 0.8808811010774106, 0.8091900108200433, 0.855147511162606, 0.6873621749326642, 0.8065922285429874, 0.296555288286271, 0.2688222180491895, 0.2490255881521224, 0.24022758770421937, 0.28798722959677636, 0.22062920349987658, 0.240990509037188, 0.2759775069479228, 0.30412917219246716, 0.20626717529091865, 0.2172436140444346, 0.20379959692968863, 0.24414522232611424, 0.23305967667092808, 0.2034260064676353, 0.20407584209493512, 0.3146798402961778, 0.2139108466900037, 0.18107424723207954, 0.17109482466801418, 0.12846865664068696, 0.18115462301465146, 0.17904651621589218, 0.18781917413207772, 0.19676567073630435, 0.18817025491861528, 0.16429685252899195, 0.18616177357360786, 0.2194441670695575, 0.14192930705591966, 0.12935240653298297, 0.18105888984197405, 0.20548909672516336, 0.1609822646827992, 0.13324912287243473, 0.16523786708984756, 0.017512745214090297, 0.030848092606357236, 9.999999999998899e-05, 0.005655769916225628, 0.0024425576771464064, 0.02731074367194486, 0.12379199884834291, 0.005773293210429964, 9.999999999998899e-05, 0.09297015721938029, 0.10862930377609936, 0.08091461082450047, 0.1082989009417673, 0.0732222697132282, 0.05159383050341915, 0.13031799135314304, 0.07998854341104489, 0.09488556922797253, 0.008419362412300013, 9.999999999998899e-05, 9.999999999998899e-05, 0.020801628104494707, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09836463390707995, 0.07379041560437893, 0.08976510649769154, 0.11622081318712496, 0.09552050489050257, 0.12630138132943125, 0.12332910522806217, 0.10808242955240943, 0.11293162477864294, 0.3286588026078392, 0.39691715969900043, 0.35656014306487827, 0.34591997506154293, 0.3637803847171368, 0.34467276928684154, 0.33854792759590124, 0.32397097036991696, 0.33830476704891854, 0.08550061690054322, 0.0983050316094981, 0.0996534117201281, 0.09285129820382065, 0.10773378863519023, 0.10171848604044065, 0.06790476609671237, 0.10798385755053819, 0.09165214571078972, 0.21348837456377656, 0.1608199389081585, 0.17987670748925788, 0.1724867418981445, 0.17885897410551932, 0.2310842915231266, 0.16384940618740107, 0.270302785455366, 0.16377941509116412, 0.2618136474427828, 0.2432864709895215, 0.21289064034337246, 0.27112296574055705, 0.20474484745347998, 0.23495718134211585, 0.22906276813472182, 0.20968723793657573, 0.23424779884520108, 0.13411664803641976, 0.1776132473597123, 0.1618293035892424, 0.1402363973861609, 0.1853924777018, 0.14296732659096323, 0.15893888184335225, 0.17622542128744312, 0.1509809368662658, 0.1856569265692436, 0.1909922143142142, 0.17536589395591562, 0.19055544916984968, 0.18831309092070914, 0.16505775026160752, 0.1864805096290525, 0.24348446441730498, 0.20110402175121833, 0.18143734329819416, 0.1802647075113022, 0.2067243594620619, 0.1934350065385051, 0.1983391964404827, 0.19978772571470005, 0.18183217143723118, 0.19621636343130122, 0.19755126147375146, 0.17509910805134188, 0.29976022843142924, 0.1498154658949088, 0.1800208275020102, 0.1768973720654139, 0.17192286954446823, 0.17281874840230282, 0.2061085264017274, 0.19835470776632025, 0.176441856103968, 0.29448915806240006, 0.20488212913909432, 0.4715939239864947, 0.5432712936411621, 0.21217510683948382, 0.19885525099673884, 0.20681120984405232, 0.19993528739100475, 0.1716454425144257, 0.18259539352478005, 0.1883027115144419, 0.17589300582287926, 0.18973715296461158, 0.19444329401969795, 0.17574462370211819, 0.1701825668872663, 0.18113215443623443, 0.07341008078837807, 0.06903351691623849, 0.07532915627306358, 0.06200499711354346, 0.06520352989812905, 0.07744084943549112, 0.06857789814774384, 0.0538759529143108, 0.0786212050494236]}, "mutation_prompt": null}
{"id": "9c8c1115-b8ed-4c08-8235-9e0b707eb33c", "solution": "import numpy as np\n\nclass HybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temp = 100\n        self.final_temp = 0.1\n        self.alpha = 0.9\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n\n    def differential_evolution(self, population, fitness):\n        F = 0.8\n        CR = 0.9\n        new_population = np.copy(population)\n\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant = np.clip(population[a] + F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial_fitness = fitness(trial)\n            self.eval_count += 1\n\n            if trial_fitness < fitness(population[i]):\n                new_population[i] = trial\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial\n\n        return new_population\n\n    def simulated_annealing(self, solution, fitness):\n        current_solution = np.copy(solution)\n        current_fitness = fitness(current_solution)\n        temp = self.initial_temp\n\n        while temp > self.final_temp and self.eval_count < self.budget:\n            new_solution = np.clip(current_solution + np.random.uniform(-0.1, 0.1, self.dim), self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_solution)\n            self.eval_count += 1\n\n            if new_fitness < current_fitness or np.exp((current_fitness - new_fitness) / temp) > np.random.rand():\n                current_solution = new_solution\n                current_fitness = new_fitness\n\n                if current_fitness < self.best_fitness:\n                    self.best_fitness = current_fitness\n                    self.best_solution = current_solution\n\n            temp *= self.alpha\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        \n        while self.eval_count < self.budget:\n            # Apply Differential Evolution\n            population = self.differential_evolution(population, func)\n\n            # Apply Simulated Annealing on the best solution found so far\n            self.simulated_annealing(self.best_solution, func)\n\n        return self.best_solution", "name": "HybridOpt", "description": "Hybrid Optimization Algorithm combining Differential Evolution and Simulated Annealing to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "bfcdd831-1929-4e34-8d24-db3ef07a9df0", "metadata": {"aucs": [0.3964858773849391, 0.3640465803351147, 0.3444891768528039, 0.42270033203488266, 0.3831354456834781, 0.35713656670774496, 0.3970950343922113, 0.36131568399628433, 0.3847585768922033, 0.036309102772794755, 0.05044036695075904, 0.02162899811212904, 0.03864572951580414, 0.04557129434643192, 0.03914229994019913, 0.058227653033924964, 0.039080122531747086, 0.07097968181751801, 0.11269348954180636, 0.07906514063966041, 0.07400708454946903, 0.11439090055563794, 0.10094358808678594, 0.09880190295481284, 0.09310986887258155, 0.08341626342332298, 0.08741505419789641, 0.09792207046344104, 0.1002084939782737, 0.06397631306954954, 0.09690816996305418, 0.08504108788620701, 0.11136083579819822, 0.05926864434133983, 0.06640707148372826, 0.07075528612350845, 0.6820411775706903, 0.897334599062181, 0.6053460671757189, 0.8724579209364467, 0.8808811010774106, 0.8091900108200433, 0.855147511162606, 0.6873621749326642, 0.8065922285429874, 0.296555288286271, 0.2688222180491895, 0.2490255881521224, 0.24022758770421937, 0.28798722959677636, 0.22062920349987658, 0.240990509037188, 0.2759775069479228, 0.30412917219246716, 0.20626717529091865, 0.2172436140444346, 0.20379959692968863, 0.24414522232611424, 0.23305967667092808, 0.2034260064676353, 0.20407584209493512, 0.3146798402961778, 0.2139108466900037, 0.18107424723207954, 0.17109482466801418, 0.12846865664068696, 0.18115462301465146, 0.17904651621589218, 0.18781917413207772, 0.19676567073630435, 0.18817025491861528, 0.16429685252899195, 0.18616177357360786, 0.2194441670695575, 0.14192930705591966, 0.12935240653298297, 0.18105888984197405, 0.20548909672516336, 0.1609822646827992, 0.13324912287243473, 0.16523786708984756, 0.017512745214090297, 0.030848092606357236, 9.999999999998899e-05, 0.005655769916225628, 0.0024425576771464064, 0.02731074367194486, 0.12379199884834291, 0.005773293210429964, 9.999999999998899e-05, 0.09297015721938029, 0.10862930377609936, 0.08091461082450047, 0.1082989009417673, 0.0732222697132282, 0.05159383050341915, 0.13031799135314304, 0.07998854341104489, 0.09488556922797253, 0.008419362412300013, 9.999999999998899e-05, 9.999999999998899e-05, 0.020801628104494707, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09836463390707995, 0.07379041560437893, 0.08976510649769154, 0.11622081318712496, 0.09552050489050257, 0.12630138132943125, 0.12332910522806217, 0.10808242955240943, 0.11293162477864294, 0.3286588026078392, 0.39691715969900043, 0.35656014306487827, 0.34591997506154293, 0.3637803847171368, 0.34467276928684154, 0.33854792759590124, 0.32397097036991696, 0.33830476704891854, 0.08550061690054322, 0.0983050316094981, 0.0996534117201281, 0.09285129820382065, 0.10773378863519023, 0.10171848604044065, 0.06790476609671237, 0.10798385755053819, 0.09165214571078972, 0.21348837456377656, 0.1608199389081585, 0.17987670748925788, 0.1724867418981445, 0.17885897410551932, 0.2310842915231266, 0.16384940618740107, 0.270302785455366, 0.16377941509116412, 0.2618136474427828, 0.2432864709895215, 0.21289064034337246, 0.27112296574055705, 0.20474484745347998, 0.23495718134211585, 0.22906276813472182, 0.20968723793657573, 0.23424779884520108, 0.13411664803641976, 0.1776132473597123, 0.1618293035892424, 0.1402363973861609, 0.1853924777018, 0.14296732659096323, 0.15893888184335225, 0.17622542128744312, 0.1509809368662658, 0.1856569265692436, 0.1909922143142142, 0.17536589395591562, 0.19055544916984968, 0.18831309092070914, 0.16505775026160752, 0.1864805096290525, 0.24348446441730498, 0.20110402175121833, 0.18143734329819416, 0.1802647075113022, 0.2067243594620619, 0.1934350065385051, 0.1983391964404827, 0.19978772571470005, 0.18183217143723118, 0.19621636343130122, 0.19755126147375146, 0.17509910805134188, 0.29976022843142924, 0.1498154658949088, 0.1800208275020102, 0.1768973720654139, 0.17192286954446823, 0.17281874840230282, 0.2061085264017274, 0.19835470776632025, 0.176441856103968, 0.29448915806240006, 0.20488212913909432, 0.4715939239864947, 0.5432712936411621, 0.21217510683948382, 0.19885525099673884, 0.20681120984405232, 0.19993528739100475, 0.1716454425144257, 0.18259539352478005, 0.1883027115144419, 0.17589300582287926, 0.18973715296461158, 0.19444329401969795, 0.17574462370211819, 0.1701825668872663, 0.18113215443623443, 0.07341008078837807, 0.06903351691623849, 0.07532915627306358, 0.06200499711354346, 0.06520352989812905, 0.07744084943549112, 0.06857789814774384, 0.0538759529143108, 0.0786212050494236]}, "mutation_prompt": null}
{"id": "a6577a59-e006-453a-ac51-9460f73dc7ec", "solution": "import numpy as np\n\nclass HybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temp = 100\n        self.final_temp = 0.1\n        self.alpha = 0.9\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n\n    def differential_evolution(self, population, fitness):\n        F = 0.8\n        CR = 0.9\n        new_population = np.copy(population)\n\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant = np.clip(population[a] + F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial_fitness = fitness(trial)\n            self.eval_count += 1\n\n            if trial_fitness < fitness(population[i]):\n                new_population[i] = trial\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial\n\n        return new_population\n\n    def simulated_annealing(self, solution, fitness):\n        current_solution = np.copy(solution)\n        current_fitness = fitness(current_solution)\n        temp = self.initial_temp\n\n        while temp > self.final_temp and self.eval_count < self.budget:\n            new_solution = np.clip(current_solution + np.random.uniform(-0.1, 0.1, self.dim), self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_solution)\n            self.eval_count += 1\n\n            if new_fitness < current_fitness or np.exp((current_fitness - new_fitness) / temp) > np.random.rand():\n                current_solution = new_solution\n                current_fitness = new_fitness\n\n                if current_fitness < self.best_fitness:\n                    self.best_fitness = current_fitness\n                    self.best_solution = current_solution\n\n            temp *= self.alpha\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        \n        while self.eval_count < self.budget:\n            # Apply Differential Evolution\n            population = self.differential_evolution(population, func)\n\n            # Apply Simulated Annealing on the best solution found so far\n            self.simulated_annealing(self.best_solution, func)\n\n        return self.best_solution", "name": "HybridOpt", "description": "Hybrid Optimization Algorithm combining Differential Evolution and Simulated Annealing to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "bfcdd831-1929-4e34-8d24-db3ef07a9df0", "metadata": {"aucs": [0.3964858773849391, 0.3640465803351147, 0.3444891768528039, 0.42270033203488266, 0.3831354456834781, 0.35713656670774496, 0.3970950343922113, 0.36131568399628433, 0.3847585768922033, 0.036309102772794755, 0.05044036695075904, 0.02162899811212904, 0.03864572951580414, 0.04557129434643192, 0.03914229994019913, 0.058227653033924964, 0.039080122531747086, 0.07097968181751801, 0.11269348954180636, 0.07906514063966041, 0.07400708454946903, 0.11439090055563794, 0.10094358808678594, 0.09880190295481284, 0.09310986887258155, 0.08341626342332298, 0.08741505419789641, 0.09792207046344104, 0.1002084939782737, 0.06397631306954954, 0.09690816996305418, 0.08504108788620701, 0.11136083579819822, 0.05926864434133983, 0.06640707148372826, 0.07075528612350845, 0.6820411775706903, 0.897334599062181, 0.6053460671757189, 0.8724579209364467, 0.8808811010774106, 0.8091900108200433, 0.855147511162606, 0.6873621749326642, 0.8065922285429874, 0.296555288286271, 0.2688222180491895, 0.2490255881521224, 0.24022758770421937, 0.28798722959677636, 0.22062920349987658, 0.240990509037188, 0.2759775069479228, 0.30412917219246716, 0.20626717529091865, 0.2172436140444346, 0.20379959692968863, 0.24414522232611424, 0.23305967667092808, 0.2034260064676353, 0.20407584209493512, 0.3146798402961778, 0.2139108466900037, 0.18107424723207954, 0.17109482466801418, 0.12846865664068696, 0.18115462301465146, 0.17904651621589218, 0.18781917413207772, 0.19676567073630435, 0.18817025491861528, 0.16429685252899195, 0.18616177357360786, 0.2194441670695575, 0.14192930705591966, 0.12935240653298297, 0.18105888984197405, 0.20548909672516336, 0.1609822646827992, 0.13324912287243473, 0.16523786708984756, 0.017512745214090297, 0.030848092606357236, 9.999999999998899e-05, 0.005655769916225628, 0.0024425576771464064, 0.02731074367194486, 0.12379199884834291, 0.005773293210429964, 9.999999999998899e-05, 0.09297015721938029, 0.10862930377609936, 0.08091461082450047, 0.1082989009417673, 0.0732222697132282, 0.05159383050341915, 0.13031799135314304, 0.07998854341104489, 0.09488556922797253, 0.008419362412300013, 9.999999999998899e-05, 9.999999999998899e-05, 0.020801628104494707, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09836463390707995, 0.07379041560437893, 0.08976510649769154, 0.11622081318712496, 0.09552050489050257, 0.12630138132943125, 0.12332910522806217, 0.10808242955240943, 0.11293162477864294, 0.3286588026078392, 0.39691715969900043, 0.35656014306487827, 0.34591997506154293, 0.3637803847171368, 0.34467276928684154, 0.33854792759590124, 0.32397097036991696, 0.33830476704891854, 0.08550061690054322, 0.0983050316094981, 0.0996534117201281, 0.09285129820382065, 0.10773378863519023, 0.10171848604044065, 0.06790476609671237, 0.10798385755053819, 0.09165214571078972, 0.21348837456377656, 0.1608199389081585, 0.17987670748925788, 0.1724867418981445, 0.17885897410551932, 0.2310842915231266, 0.16384940618740107, 0.270302785455366, 0.16377941509116412, 0.2618136474427828, 0.2432864709895215, 0.21289064034337246, 0.27112296574055705, 0.20474484745347998, 0.23495718134211585, 0.22906276813472182, 0.20968723793657573, 0.23424779884520108, 0.13411664803641976, 0.1776132473597123, 0.1618293035892424, 0.1402363973861609, 0.1853924777018, 0.14296732659096323, 0.15893888184335225, 0.17622542128744312, 0.1509809368662658, 0.1856569265692436, 0.1909922143142142, 0.17536589395591562, 0.19055544916984968, 0.18831309092070914, 0.16505775026160752, 0.1864805096290525, 0.24348446441730498, 0.20110402175121833, 0.18143734329819416, 0.1802647075113022, 0.2067243594620619, 0.1934350065385051, 0.1983391964404827, 0.19978772571470005, 0.18183217143723118, 0.19621636343130122, 0.19755126147375146, 0.17509910805134188, 0.29976022843142924, 0.1498154658949088, 0.1800208275020102, 0.1768973720654139, 0.17192286954446823, 0.17281874840230282, 0.2061085264017274, 0.19835470776632025, 0.176441856103968, 0.29448915806240006, 0.20488212913909432, 0.4715939239864947, 0.5432712936411621, 0.21217510683948382, 0.19885525099673884, 0.20681120984405232, 0.19993528739100475, 0.1716454425144257, 0.18259539352478005, 0.1883027115144419, 0.17589300582287926, 0.18973715296461158, 0.19444329401969795, 0.17574462370211819, 0.1701825668872663, 0.18113215443623443, 0.07341008078837807, 0.06903351691623849, 0.07532915627306358, 0.06200499711354346, 0.06520352989812905, 0.07744084943549112, 0.06857789814774384, 0.0538759529143108, 0.0786212050494236]}, "mutation_prompt": null}
{"id": "edcc3b7f-c917-4615-8405-5b3776028a1e", "solution": "import numpy as np\n\nclass HybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temp = 100\n        self.final_temp = 0.1\n        self.alpha = 0.9\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n\n    def differential_evolution(self, population, fitness):\n        F = 0.8\n        CR = 0.9\n        new_population = np.copy(population)\n\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant = np.clip(population[a] + F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial_fitness = fitness(trial)\n            self.eval_count += 1\n\n            if trial_fitness < fitness(population[i]):\n                new_population[i] = trial\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial\n\n        return new_population\n\n    def simulated_annealing(self, solution, fitness):\n        current_solution = np.copy(solution)\n        current_fitness = fitness(current_solution)\n        temp = self.initial_temp\n\n        while temp > self.final_temp and self.eval_count < self.budget:\n            new_solution = np.clip(current_solution + np.random.uniform(-0.1, 0.1, self.dim), self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_solution)\n            self.eval_count += 1\n\n            if new_fitness < current_fitness or np.exp((current_fitness - new_fitness) / temp) > np.random.rand():\n                current_solution = new_solution\n                current_fitness = new_fitness\n\n                if current_fitness < self.best_fitness:\n                    self.best_fitness = current_fitness\n                    self.best_solution = current_solution\n\n            temp *= self.alpha\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        \n        while self.eval_count < self.budget:\n            # Apply Differential Evolution\n            population = self.differential_evolution(population, func)\n\n            # Apply Simulated Annealing on the best solution found so far\n            self.simulated_annealing(self.best_solution, func)\n\n        return self.best_solution", "name": "HybridOpt", "description": "Hybrid Optimization Algorithm combining Differential Evolution and Simulated Annealing to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "bfcdd831-1929-4e34-8d24-db3ef07a9df0", "metadata": {"aucs": [0.3964858773849391, 0.3640465803351147, 0.3444891768528039, 0.42270033203488266, 0.3831354456834781, 0.35713656670774496, 0.3970950343922113, 0.36131568399628433, 0.3847585768922033, 0.036309102772794755, 0.05044036695075904, 0.02162899811212904, 0.03864572951580414, 0.04557129434643192, 0.03914229994019913, 0.058227653033924964, 0.039080122531747086, 0.07097968181751801, 0.11269348954180636, 0.07906514063966041, 0.07400708454946903, 0.11439090055563794, 0.10094358808678594, 0.09880190295481284, 0.09310986887258155, 0.08341626342332298, 0.08741505419789641, 0.09792207046344104, 0.1002084939782737, 0.06397631306954954, 0.09690816996305418, 0.08504108788620701, 0.11136083579819822, 0.05926864434133983, 0.06640707148372826, 0.07075528612350845, 0.6820411775706903, 0.897334599062181, 0.6053460671757189, 0.8724579209364467, 0.8808811010774106, 0.8091900108200433, 0.855147511162606, 0.6873621749326642, 0.8065922285429874, 0.296555288286271, 0.2688222180491895, 0.2490255881521224, 0.24022758770421937, 0.28798722959677636, 0.22062920349987658, 0.240990509037188, 0.2759775069479228, 0.30412917219246716, 0.20626717529091865, 0.2172436140444346, 0.20379959692968863, 0.24414522232611424, 0.23305967667092808, 0.2034260064676353, 0.20407584209493512, 0.3146798402961778, 0.2139108466900037, 0.18107424723207954, 0.17109482466801418, 0.12846865664068696, 0.18115462301465146, 0.17904651621589218, 0.18781917413207772, 0.19676567073630435, 0.18817025491861528, 0.16429685252899195, 0.18616177357360786, 0.2194441670695575, 0.14192930705591966, 0.12935240653298297, 0.18105888984197405, 0.20548909672516336, 0.1609822646827992, 0.13324912287243473, 0.16523786708984756, 0.017512745214090297, 0.030848092606357236, 9.999999999998899e-05, 0.005655769916225628, 0.0024425576771464064, 0.02731074367194486, 0.12379199884834291, 0.005773293210429964, 9.999999999998899e-05, 0.09297015721938029, 0.10862930377609936, 0.08091461082450047, 0.1082989009417673, 0.0732222697132282, 0.05159383050341915, 0.13031799135314304, 0.07998854341104489, 0.09488556922797253, 0.008419362412300013, 9.999999999998899e-05, 9.999999999998899e-05, 0.020801628104494707, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09836463390707995, 0.07379041560437893, 0.08976510649769154, 0.11622081318712496, 0.09552050489050257, 0.12630138132943125, 0.12332910522806217, 0.10808242955240943, 0.11293162477864294, 0.3286588026078392, 0.39691715969900043, 0.35656014306487827, 0.34591997506154293, 0.3637803847171368, 0.34467276928684154, 0.33854792759590124, 0.32397097036991696, 0.33830476704891854, 0.08550061690054322, 0.0983050316094981, 0.0996534117201281, 0.09285129820382065, 0.10773378863519023, 0.10171848604044065, 0.06790476609671237, 0.10798385755053819, 0.09165214571078972, 0.21348837456377656, 0.1608199389081585, 0.17987670748925788, 0.1724867418981445, 0.17885897410551932, 0.2310842915231266, 0.16384940618740107, 0.270302785455366, 0.16377941509116412, 0.2618136474427828, 0.2432864709895215, 0.21289064034337246, 0.27112296574055705, 0.20474484745347998, 0.23495718134211585, 0.22906276813472182, 0.20968723793657573, 0.23424779884520108, 0.13411664803641976, 0.1776132473597123, 0.1618293035892424, 0.1402363973861609, 0.1853924777018, 0.14296732659096323, 0.15893888184335225, 0.17622542128744312, 0.1509809368662658, 0.1856569265692436, 0.1909922143142142, 0.17536589395591562, 0.19055544916984968, 0.18831309092070914, 0.16505775026160752, 0.1864805096290525, 0.24348446441730498, 0.20110402175121833, 0.18143734329819416, 0.1802647075113022, 0.2067243594620619, 0.1934350065385051, 0.1983391964404827, 0.19978772571470005, 0.18183217143723118, 0.19621636343130122, 0.19755126147375146, 0.17509910805134188, 0.29976022843142924, 0.1498154658949088, 0.1800208275020102, 0.1768973720654139, 0.17192286954446823, 0.17281874840230282, 0.2061085264017274, 0.19835470776632025, 0.176441856103968, 0.29448915806240006, 0.20488212913909432, 0.4715939239864947, 0.5432712936411621, 0.21217510683948382, 0.19885525099673884, 0.20681120984405232, 0.19993528739100475, 0.1716454425144257, 0.18259539352478005, 0.1883027115144419, 0.17589300582287926, 0.18973715296461158, 0.19444329401969795, 0.17574462370211819, 0.1701825668872663, 0.18113215443623443, 0.07341008078837807, 0.06903351691623849, 0.07532915627306358, 0.06200499711354346, 0.06520352989812905, 0.07744084943549112, 0.06857789814774384, 0.0538759529143108, 0.0786212050494236]}, "mutation_prompt": null}
{"id": "62dd85c4-75c9-4faa-af34-ce2c1d2b9aa9", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.local_search_intensity = 0.1\n        self.beta = 0.85\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n\n    def differential_evolution(self, population, fitness):\n        F = 0.7\n        CR = 0.85\n        new_population = np.copy(population)\n\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant = np.clip(population[a] + F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial_fitness = fitness(trial)\n            self.eval_count += 1\n\n            if trial_fitness < fitness(population[i]):\n                new_population[i] = trial\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial\n\n        return new_population\n\n    def local_search(self, solution, fitness):\n        candidate_solution = np.copy(solution)\n        candidate_fitness = fitness(candidate_solution)\n        \n        for _ in range(int(self.local_search_intensity * self.dim)):\n            perturbed_solution = np.clip(candidate_solution + np.random.normal(0, 0.1, self.dim), self.lower_bound, self.upper_bound)\n            perturbed_fitness = fitness(perturbed_solution)\n            self.eval_count += 1\n\n            if perturbed_fitness < candidate_fitness:\n                candidate_solution = perturbed_solution\n                candidate_fitness = perturbed_fitness\n\n                if candidate_fitness < self.best_fitness:\n                    self.best_fitness = candidate_fitness\n                    self.best_solution = candidate_solution\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        \n        while self.eval_count < self.budget:\n            # Apply Differential Evolution\n            population = self.differential_evolution(population, func)\n\n            # Apply Local Search on the best solution found so far\n            self.local_search(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Memetic Strategies integrating Differential Evolution and Local Search to improve convergence and solution accuracy.", "configspace": "", "generation": 15, "fitness": 0.18541709222123834, "feedback": "The algorithm EnhancedHybridOpt got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.17.", "error": "", "parent_id": "bfcdd831-1929-4e34-8d24-db3ef07a9df0", "metadata": {"aucs": [0.411458081045748, 0.4340245221640826, 0.3974925493741148, 0.4332365390799946, 0.4566728091061113, 0.45696520966228404, 0.4581400594444347, 0.418846445377383, 0.42874789934357005, 0.1447561466614936, 0.16619955784140072, 0.15566746099603512, 0.15450117545718545, 0.1400361672574827, 0.14065991199052985, 0.18556795156331807, 0.14197347771619406, 0.193611755636508, 0.08770191701851504, 0.08659491718773549, 0.09402190193765547, 0.08759767333317137, 0.10980272484822784, 0.07504425767323553, 0.08851005699546077, 0.06905819652471112, 0.09795859960654274, 0.07172480579897733, 0.07781303922628213, 0.0799743480359808, 0.06893732566992472, 0.07408228706374487, 0.06684828727096648, 0.06859137340162558, 0.06786214016659631, 0.07798735104405918, 0.828665156687912, 0.9197131820449691, 0.8552178381179456, 0.8146882159277617, 0.9081913877295338, 0.9048072107858723, 0.8874356820118438, 0.8115132365779023, 0.8806044904373038, 0.16931640958349947, 0.1495109146363668, 0.16693766386188236, 0.1755997417287667, 0.16176971803967388, 0.15655419950229332, 0.1793172191234922, 0.19673374970071622, 0.17357100473214726, 0.22480269259793695, 0.20759403973284885, 0.21233945355021377, 0.23932373298088794, 0.29984360063306126, 0.2573349055324645, 0.24762135571533117, 0.253935817984848, 0.22776164673427268, 0.11634866005674938, 0.12718580264216595, 0.09794336172361129, 0.11936274832802118, 0.11000605840833555, 0.10122456637660215, 0.12514431921575675, 0.11332915543401667, 0.11652672870849856, 0.1005612248022153, 0.07392193730906316, 0.098589488508389, 0.11969647659810778, 0.11307606895065814, 0.11465732684586605, 0.10517369928099818, 0.10077869116422333, 0.11825337980212558, 0.009798280169079798, 0.00950609475027342, 0.03440357628374391, 0.021785158226974688, 0.019531874393800552, 0.020262673777576845, 0.018165958795959836, 0.012815488725993252, 0.013670778287165009, 0.1026061683991849, 0.14910153483799482, 0.14306121778441905, 0.09601451772031233, 0.10101525232158637, 0.0937688576753184, 0.11573734862868945, 0.14095368784373585, 0.15208114779436743, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005305692675896534, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07880448150470731, 0.0781281673821802, 0.07183159947673379, 0.06452158729181867, 0.06733301802467828, 0.09583408166700869, 0.08229263205897586, 0.0856959685537837, 0.07730394421175368, 0.3635856943425927, 0.3683487674110141, 0.3469265488147688, 0.3650598154270833, 0.3695456389323587, 0.3756164085238851, 0.3425326565883623, 0.36103116012238756, 0.3584534561199768, 0.07880321342446583, 0.07934058952354606, 0.07533122195023223, 0.07013890650924781, 0.06633522769018141, 0.07167534766566763, 0.07954085476483197, 0.0716152858124115, 0.10914085679258112, 0.13395070380751817, 0.12993493146777857, 0.13453223870428488, 0.1253014908565392, 0.1690340261511012, 0.14240257458095418, 0.12516340156444772, 0.15222654165423066, 0.1290697077149291, 0.23331523510192187, 0.22351503901191994, 0.21933130864963868, 0.20516945301040312, 0.22257202974555246, 0.2070860390460969, 0.22984350599441739, 0.23813186351295346, 0.2461518307781897, 0.1547952543135085, 0.18043173903806342, 0.1741902515221735, 0.14315539993851578, 0.16106868531105611, 0.1508646669087964, 0.1657659172083591, 0.1594458652018882, 0.16670881673905058, 0.1905304715699193, 0.1735003867355288, 0.17957357694928433, 0.16567146428218493, 0.16019987499456656, 0.1654781398548394, 0.18436933968666136, 0.16936757971652117, 0.1794803587333561, 0.16073236586938966, 0.1653781610242162, 0.18402867965777947, 0.16163149015416256, 0.1705910340224558, 0.17803618783731345, 0.1678771623632308, 0.17169912751855188, 0.15579914416588614, 0.3493448386142757, 0.18339089582073476, 0.27628681945456035, 0.2606369191471821, 0.19856014152475687, 0.2746927409580934, 0.13782756398592777, 0.16868988654562822, 0.22163919338457383, 0.226088889812056, 0.19791019105347396, 0.15917391873291653, 0.24578414961031392, 0.14959702412429454, 0.15889181859320411, 0.19933530466015403, 0.22618086501299217, 0.19670291812801377, 0.18083838101340666, 0.2053832492380131, 0.18024140475018924, 0.18287793004451636, 0.17710722612021013, 0.17868740248088566, 0.16833897081891736, 0.18745674222268294, 0.2092099210763616, 0.052858316573099695, 0.06937035505845213, 0.06392432440958196, 0.0714355205583832, 0.07029330125878208, 0.06592078237349164, 0.06624809718958935, 0.06200422187930943, 0.05852843124888896]}, "mutation_prompt": null}
{"id": "11c0d777-7f16-46ce-859e-6ddbb81166d3", "solution": "import numpy as np\n\nclass HybridAdaptiveOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim  # Adjusted size for better exploration\n        self.initial_temp = 100\n        self.final_temp = 0.1\n        self.alpha = 0.85  # Slightly altered for adaptive cooling\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.05  # Inspired by SGD\n\n    def differential_evolution(self, population, fitness):\n        F = 0.7  # Modified to enhance exploitation\n        CR = 0.85\n        new_population = np.copy(population)\n\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant = np.clip(population[a] + F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial_fitness = fitness(trial)\n            self.eval_count += 1\n\n            if trial_fitness < fitness(population[i]):\n                new_population[i] = trial\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial\n\n        return new_population\n\n    def stochastic_gradient_adjustment(self, solution, fitness):\n        gradient_steps = np.random.uniform(-1.0, 1.0, self.dim)\n        adjusted_solution = np.clip(solution + self.learning_rate * gradient_steps, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def simulated_annealing(self, solution, fitness):\n        current_solution = np.copy(solution)\n        current_fitness = fitness(current_solution)\n        temp = self.initial_temp\n\n        while temp > self.final_temp and self.eval_count < self.budget:\n            new_solution = np.clip(current_solution + np.random.uniform(-0.1, 0.1, self.dim), self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_solution)\n            self.eval_count += 1\n\n            if new_fitness < current_fitness or np.exp((current_fitness - new_fitness) / temp) > np.random.rand():\n                current_solution = new_solution\n                current_fitness = new_fitness\n\n                if current_fitness < self.best_fitness:\n                    self.best_fitness = current_fitness\n                    self.best_solution = current_solution\n\n            temp *= self.alpha\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        \n        while self.eval_count < self.budget:\n            # Apply Differential Evolution\n            population = self.differential_evolution(population, func)\n\n            # Apply Stochastic Gradient Adjustment on the best solution found so far\n            self.stochastic_gradient_adjustment(self.best_solution, func)\n\n            # Apply Simulated Annealing on the best solution found so far\n            self.simulated_annealing(self.best_solution, func)\n\n        return self.best_solution", "name": "HybridAdaptiveOpt", "description": "Hybrid Adaptive Strategy integrating Differential Evolution with Stochastic Gradient Descent-inspired adjustments and Simulated Annealing for dynamic exploration and exploitation.", "configspace": "", "generation": 16, "fitness": 0.19936687521305127, "feedback": "The algorithm HybridAdaptiveOpt got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.17.", "error": "", "parent_id": "bfcdd831-1929-4e34-8d24-db3ef07a9df0", "metadata": {"aucs": [0.42445327247576947, 0.3841508664863471, 0.3997328334780921, 0.4656636691668542, 0.3876475013748957, 0.41177432357825194, 0.3951724895944644, 0.40169254918710817, 0.4111093269535512, 0.07396133108145753, 0.06744837805775117, 0.07224657739264384, 0.052302673990393456, 0.05138700289964182, 0.08134799792290437, 0.05291688243851145, 0.06980191544410541, 0.06308275785454176, 0.08155636241237241, 0.08336033991602199, 0.08426863637042625, 0.09473708368620826, 0.12205679525593371, 0.0905619274907582, 0.09516611316613854, 0.09124521353362436, 0.09707962687961502, 0.1047468946688841, 0.08220017902914256, 0.09751746154132723, 0.09140656877500264, 0.10729807949857639, 0.1014486771799118, 0.08747389104176673, 0.07498474001216127, 0.08974211423598444, 0.81175893080925, 0.8344254353473006, 0.7775673485000132, 0.8087615176665763, 0.7337028661733479, 0.9210121005444003, 0.7015791035265029, 0.8975609016071071, 0.8505253781651699, 0.26933983979347864, 0.25737512611519375, 0.26259125095643987, 0.2772464263143999, 0.23596340762921808, 0.254127391433535, 0.2463860530627664, 0.2752482633140174, 0.2400626529419181, 0.2759668102207773, 0.26922942481023115, 0.2181974512016045, 0.30439846351778, 0.2667967879165881, 0.24900201012544243, 0.23020065224377284, 0.2378679027558327, 0.2139177246608106, 0.11992211494814686, 0.15639171495752346, 0.1274407972663254, 0.16691673163850285, 0.1470336500527214, 0.12392096035788258, 0.1341279420130842, 0.17272441736817257, 0.18872776595227247, 0.15390372170414834, 0.1421125723606036, 0.1980134666363268, 0.16364408876625547, 0.15085513892791258, 0.2285548478145023, 0.12214748421578425, 0.14090419609089966, 0.22788278574300425, 0.027315839007384213, 9.999999999998899e-05, 0.08736267042251167, 0.009903306749139862, 0.007043664401237715, 0.011881861168676178, 0.016669244315250076, 0.0029969925146288157, 0.007469679584958477, 0.07429362001531914, 0.08863405260373469, 0.09596797852190297, 0.10342262895621257, 0.08808650195415013, 0.06495388453836226, 0.09580421285620122, 0.0856380965430944, 0.0843356485635437, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0015633339087571807, 9.999999999998899e-05, 9.999999999998899e-05, 0.0014158654378582103, 9.999999999998899e-05, 0.062222088246479346, 0.07210139041390962, 0.11707537991072348, 0.11367676932346038, 0.08029629457495735, 0.13329019142331688, 0.11186493034477696, 0.10289444612058363, 0.1112674773420782, 0.33711195960321905, 0.3124106950783959, 0.36645990272354045, 0.35664612493621295, 0.37065020960467454, 0.3468362049127308, 0.3983489670073578, 0.36704368637814155, 0.35613004831735906, 0.12615372499025956, 0.11348211218644899, 0.10852595624556671, 0.11308214404512473, 0.08523287369159316, 0.09547836595441928, 0.08394354527533832, 0.08203502436943655, 0.09879157202262445, 0.15062183752146951, 0.3039671157575782, 0.2905250513842814, 0.18795563479729094, 0.15569922545809856, 0.21717105471475173, 0.20051255588261774, 0.15444101973486335, 0.15173188843620977, 0.2466420900475803, 0.21369413809460158, 0.20318495636921352, 0.25873276629991804, 0.24167378029842923, 0.193012122105794, 0.2088675370024382, 0.2314340424884186, 0.2333453457811111, 0.16133392003104252, 0.16875150809892803, 0.16963843054167627, 0.19404473251945564, 0.1364600054636801, 0.14718688219870457, 0.17215455367054255, 0.17226923982899156, 0.17336381232426135, 0.19911752253663562, 0.19398533060481582, 0.19452501479237594, 0.17583807697040443, 0.23611298179664753, 0.22822600810461213, 0.19541485212864074, 0.188351531891367, 0.21577014758861646, 0.19384931185410303, 0.1707077644193865, 0.18745115659636824, 0.22349955794423693, 0.18616531280884174, 0.17475272406884867, 0.1798508892694476, 0.18830631253438912, 0.21696754418216402, 0.16795305220432488, 0.46015206562987887, 0.5985926406402934, 0.21778063357863053, 0.18894836069856935, 0.1657732248475684, 0.4461718274305183, 0.1696161613014463, 0.5905643797730764, 0.4433960705613843, 0.16371247819710766, 0.18564680936490252, 0.20692663833037617, 0.2756513473762009, 0.2745203548120466, 0.26543313118208234, 0.21100151924803678, 0.2015918614825133, 0.18814279454935845, 0.1765144929475384, 0.17331913571561197, 0.16811507572787943, 0.17732441520966225, 0.18058121276603256, 0.1805677054040934, 0.1758294081645938, 0.17232993050343992, 0.07057613494853776, 0.07070679769495125, 0.07139073061366419, 0.06191961845139138, 0.06547122211823209, 0.06154806739751062, 0.06719454077655118, 0.09962728118723041, 0.07395679889565343]}, "mutation_prompt": null}
{"id": "30556237-b78d-4864-beec-def5b7e8fe69", "solution": "import numpy as np\n\nclass HybridAdaptiveOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim  # Adjusted size for better exploration\n        self.initial_temp = 100\n        self.final_temp = 0.1\n        self.alpha = 0.85  # Slightly altered for adaptive cooling\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.05  # Inspired by SGD\n\n    def differential_evolution(self, population, fitness):\n        F = 0.7  # Modified to enhance exploitation\n        CR = 0.85\n        new_population = np.copy(population)\n\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant = np.clip(population[a] + F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial_fitness = fitness(trial)\n            self.eval_count += 1\n\n            if trial_fitness < fitness(population[i]):\n                new_population[i] = trial\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial\n\n        return new_population\n\n    def stochastic_gradient_adjustment(self, solution, fitness):\n        gradient_steps = np.random.uniform(-1.0, 1.0, self.dim)\n        adjusted_solution = np.clip(solution + self.learning_rate * gradient_steps, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def simulated_annealing(self, solution, fitness):\n        current_solution = np.copy(solution)\n        current_fitness = fitness(current_solution)\n        temp = self.initial_temp\n\n        while temp > self.final_temp and self.eval_count < self.budget:\n            new_solution = np.clip(current_solution + np.random.uniform(-0.1, 0.1, self.dim), self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_solution)\n            self.eval_count += 1\n\n            if new_fitness < current_fitness or np.exp((current_fitness - new_fitness) / temp) > np.random.rand():\n                current_solution = new_solution\n                current_fitness = new_fitness\n\n                if current_fitness < self.best_fitness:\n                    self.best_fitness = current_fitness\n                    self.best_solution = current_solution\n\n            temp *= self.alpha\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        \n        while self.eval_count < self.budget:\n            # Apply Differential Evolution\n            population = self.differential_evolution(population, func)\n\n            # Apply Stochastic Gradient Adjustment on the best solution found so far\n            self.stochastic_gradient_adjustment(self.best_solution, func)\n\n            # Apply Simulated Annealing on the best solution found so far\n            self.simulated_annealing(self.best_solution, func)\n\n        return self.best_solution", "name": "HybridAdaptiveOpt", "description": "Hybrid Adaptive Strategy integrating Differential Evolution with Stochastic Gradient Descent-inspired adjustments and Simulated Annealing for dynamic exploration and exploitation.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "11c0d777-7f16-46ce-859e-6ddbb81166d3", "metadata": {"aucs": [0.42445327247576947, 0.3841508664863471, 0.3997328334780921, 0.4656636691668542, 0.3876475013748957, 0.41177432357825194, 0.3951724895944644, 0.40169254918710817, 0.4111093269535512, 0.07396133108145753, 0.06744837805775117, 0.07224657739264384, 0.052302673990393456, 0.05138700289964182, 0.08134799792290437, 0.05291688243851145, 0.06980191544410541, 0.06308275785454176, 0.08155636241237241, 0.08336033991602199, 0.08426863637042625, 0.09473708368620826, 0.12205679525593371, 0.0905619274907582, 0.09516611316613854, 0.09124521353362436, 0.09707962687961502, 0.1047468946688841, 0.08220017902914256, 0.09751746154132723, 0.09140656877500264, 0.10729807949857639, 0.1014486771799118, 0.08747389104176673, 0.07498474001216127, 0.08974211423598444, 0.81175893080925, 0.8344254353473006, 0.7775673485000132, 0.8087615176665763, 0.7337028661733479, 0.9210121005444003, 0.7015791035265029, 0.8975609016071071, 0.8505253781651699, 0.26933983979347864, 0.25737512611519375, 0.26259125095643987, 0.2772464263143999, 0.23596340762921808, 0.254127391433535, 0.2463860530627664, 0.2752482633140174, 0.2400626529419181, 0.2759668102207773, 0.26922942481023115, 0.2181974512016045, 0.30439846351778, 0.2667967879165881, 0.24900201012544243, 0.23020065224377284, 0.2378679027558327, 0.2139177246608106, 0.11992211494814686, 0.15639171495752346, 0.1274407972663254, 0.16691673163850285, 0.1470336500527214, 0.12392096035788258, 0.1341279420130842, 0.17272441736817257, 0.18872776595227247, 0.15390372170414834, 0.1421125723606036, 0.1980134666363268, 0.16364408876625547, 0.15085513892791258, 0.2285548478145023, 0.12214748421578425, 0.14090419609089966, 0.22788278574300425, 0.027315839007384213, 9.999999999998899e-05, 0.08736267042251167, 0.009903306749139862, 0.007043664401237715, 0.011881861168676178, 0.016669244315250076, 0.0029969925146288157, 0.007469679584958477, 0.07429362001531914, 0.08863405260373469, 0.09596797852190297, 0.10342262895621257, 0.08808650195415013, 0.06495388453836226, 0.09580421285620122, 0.0856380965430944, 0.0843356485635437, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0015633339087571807, 9.999999999998899e-05, 9.999999999998899e-05, 0.0014158654378582103, 9.999999999998899e-05, 0.062222088246479346, 0.07210139041390962, 0.11707537991072348, 0.11367676932346038, 0.08029629457495735, 0.13329019142331688, 0.11186493034477696, 0.10289444612058363, 0.1112674773420782, 0.33711195960321905, 0.3124106950783959, 0.36645990272354045, 0.35664612493621295, 0.37065020960467454, 0.3468362049127308, 0.3983489670073578, 0.36704368637814155, 0.35613004831735906, 0.12615372499025956, 0.11348211218644899, 0.10852595624556671, 0.11308214404512473, 0.08523287369159316, 0.09547836595441928, 0.08394354527533832, 0.08203502436943655, 0.09879157202262445, 0.15062183752146951, 0.3039671157575782, 0.2905250513842814, 0.18795563479729094, 0.15569922545809856, 0.21717105471475173, 0.20051255588261774, 0.15444101973486335, 0.15173188843620977, 0.2466420900475803, 0.21369413809460158, 0.20318495636921352, 0.25873276629991804, 0.24167378029842923, 0.193012122105794, 0.2088675370024382, 0.2314340424884186, 0.2333453457811111, 0.16133392003104252, 0.16875150809892803, 0.16963843054167627, 0.19404473251945564, 0.1364600054636801, 0.14718688219870457, 0.17215455367054255, 0.17226923982899156, 0.17336381232426135, 0.19911752253663562, 0.19398533060481582, 0.19452501479237594, 0.17583807697040443, 0.23611298179664753, 0.22822600810461213, 0.19541485212864074, 0.188351531891367, 0.21577014758861646, 0.19384931185410303, 0.1707077644193865, 0.18745115659636824, 0.22349955794423693, 0.18616531280884174, 0.17475272406884867, 0.1798508892694476, 0.18830631253438912, 0.21696754418216402, 0.16795305220432488, 0.46015206562987887, 0.5985926406402934, 0.21778063357863053, 0.18894836069856935, 0.1657732248475684, 0.4461718274305183, 0.1696161613014463, 0.5905643797730764, 0.4433960705613843, 0.16371247819710766, 0.18564680936490252, 0.20692663833037617, 0.2756513473762009, 0.2745203548120466, 0.26543313118208234, 0.21100151924803678, 0.2015918614825133, 0.18814279454935845, 0.1765144929475384, 0.17331913571561197, 0.16811507572787943, 0.17732441520966225, 0.18058121276603256, 0.1805677054040934, 0.1758294081645938, 0.17232993050343992, 0.07057613494853776, 0.07070679769495125, 0.07139073061366419, 0.06191961845139138, 0.06547122211823209, 0.06154806739751062, 0.06719454077655118, 0.09962728118723041, 0.07395679889565343]}, "mutation_prompt": null}
{"id": "ca8869be-3bda-4672-bcf9-b83541a00d90", "solution": "import numpy as np\n\nclass HybridAdaptiveOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim  # Adjusted size for better exploration\n        self.initial_temp = 100\n        self.final_temp = 0.1\n        self.alpha = 0.85  # Slightly altered for adaptive cooling\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.05  # Inspired by SGD\n\n    def differential_evolution(self, population, fitness):\n        F = 0.7  # Modified to enhance exploitation\n        CR = 0.85\n        new_population = np.copy(population)\n\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant = np.clip(population[a] + F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial_fitness = fitness(trial)\n            self.eval_count += 1\n\n            if trial_fitness < fitness(population[i]):\n                new_population[i] = trial\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial\n\n        return new_population\n\n    def stochastic_gradient_adjustment(self, solution, fitness):\n        gradient_steps = np.random.uniform(-1.0, 1.0, self.dim)\n        adjusted_solution = np.clip(solution + self.learning_rate * gradient_steps, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def simulated_annealing(self, solution, fitness):\n        current_solution = np.copy(solution)\n        current_fitness = fitness(current_solution)\n        temp = self.initial_temp\n\n        while temp > self.final_temp and self.eval_count < self.budget:\n            new_solution = np.clip(current_solution + np.random.uniform(-0.1, 0.1, self.dim), self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_solution)\n            self.eval_count += 1\n\n            if new_fitness < current_fitness or np.exp((current_fitness - new_fitness) / temp) > np.random.rand():\n                current_solution = new_solution\n                current_fitness = new_fitness\n\n                if current_fitness < self.best_fitness:\n                    self.best_fitness = current_fitness\n                    self.best_solution = current_solution\n\n            temp *= self.alpha\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        \n        while self.eval_count < self.budget:\n            # Apply Differential Evolution\n            population = self.differential_evolution(population, func)\n\n            # Apply Stochastic Gradient Adjustment on the best solution found so far\n            self.stochastic_gradient_adjustment(self.best_solution, func)\n\n            # Apply Simulated Annealing on the best solution found so far\n            self.simulated_annealing(self.best_solution, func)\n\n        return self.best_solution", "name": "HybridAdaptiveOpt", "description": "Hybrid Adaptive Strategy integrating Differential Evolution with Stochastic Gradient Descent-inspired adjustments and Simulated Annealing for dynamic exploration and exploitation.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "11c0d777-7f16-46ce-859e-6ddbb81166d3", "metadata": {"aucs": [0.42445327247576947, 0.3841508664863471, 0.3997328334780921, 0.4656636691668542, 0.3876475013748957, 0.41177432357825194, 0.3951724895944644, 0.40169254918710817, 0.4111093269535512, 0.07396133108145753, 0.06744837805775117, 0.07224657739264384, 0.052302673990393456, 0.05138700289964182, 0.08134799792290437, 0.05291688243851145, 0.06980191544410541, 0.06308275785454176, 0.08155636241237241, 0.08336033991602199, 0.08426863637042625, 0.09473708368620826, 0.12205679525593371, 0.0905619274907582, 0.09516611316613854, 0.09124521353362436, 0.09707962687961502, 0.1047468946688841, 0.08220017902914256, 0.09751746154132723, 0.09140656877500264, 0.10729807949857639, 0.1014486771799118, 0.08747389104176673, 0.07498474001216127, 0.08974211423598444, 0.81175893080925, 0.8344254353473006, 0.7775673485000132, 0.8087615176665763, 0.7337028661733479, 0.9210121005444003, 0.7015791035265029, 0.8975609016071071, 0.8505253781651699, 0.26933983979347864, 0.25737512611519375, 0.26259125095643987, 0.2772464263143999, 0.23596340762921808, 0.254127391433535, 0.2463860530627664, 0.2752482633140174, 0.2400626529419181, 0.2759668102207773, 0.26922942481023115, 0.2181974512016045, 0.30439846351778, 0.2667967879165881, 0.24900201012544243, 0.23020065224377284, 0.2378679027558327, 0.2139177246608106, 0.11992211494814686, 0.15639171495752346, 0.1274407972663254, 0.16691673163850285, 0.1470336500527214, 0.12392096035788258, 0.1341279420130842, 0.17272441736817257, 0.18872776595227247, 0.15390372170414834, 0.1421125723606036, 0.1980134666363268, 0.16364408876625547, 0.15085513892791258, 0.2285548478145023, 0.12214748421578425, 0.14090419609089966, 0.22788278574300425, 0.027315839007384213, 9.999999999998899e-05, 0.08736267042251167, 0.009903306749139862, 0.007043664401237715, 0.011881861168676178, 0.016669244315250076, 0.0029969925146288157, 0.007469679584958477, 0.07429362001531914, 0.08863405260373469, 0.09596797852190297, 0.10342262895621257, 0.08808650195415013, 0.06495388453836226, 0.09580421285620122, 0.0856380965430944, 0.0843356485635437, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0015633339087571807, 9.999999999998899e-05, 9.999999999998899e-05, 0.0014158654378582103, 9.999999999998899e-05, 0.062222088246479346, 0.07210139041390962, 0.11707537991072348, 0.11367676932346038, 0.08029629457495735, 0.13329019142331688, 0.11186493034477696, 0.10289444612058363, 0.1112674773420782, 0.33711195960321905, 0.3124106950783959, 0.36645990272354045, 0.35664612493621295, 0.37065020960467454, 0.3468362049127308, 0.3983489670073578, 0.36704368637814155, 0.35613004831735906, 0.12615372499025956, 0.11348211218644899, 0.10852595624556671, 0.11308214404512473, 0.08523287369159316, 0.09547836595441928, 0.08394354527533832, 0.08203502436943655, 0.09879157202262445, 0.15062183752146951, 0.3039671157575782, 0.2905250513842814, 0.18795563479729094, 0.15569922545809856, 0.21717105471475173, 0.20051255588261774, 0.15444101973486335, 0.15173188843620977, 0.2466420900475803, 0.21369413809460158, 0.20318495636921352, 0.25873276629991804, 0.24167378029842923, 0.193012122105794, 0.2088675370024382, 0.2314340424884186, 0.2333453457811111, 0.16133392003104252, 0.16875150809892803, 0.16963843054167627, 0.19404473251945564, 0.1364600054636801, 0.14718688219870457, 0.17215455367054255, 0.17226923982899156, 0.17336381232426135, 0.19911752253663562, 0.19398533060481582, 0.19452501479237594, 0.17583807697040443, 0.23611298179664753, 0.22822600810461213, 0.19541485212864074, 0.188351531891367, 0.21577014758861646, 0.19384931185410303, 0.1707077644193865, 0.18745115659636824, 0.22349955794423693, 0.18616531280884174, 0.17475272406884867, 0.1798508892694476, 0.18830631253438912, 0.21696754418216402, 0.16795305220432488, 0.46015206562987887, 0.5985926406402934, 0.21778063357863053, 0.18894836069856935, 0.1657732248475684, 0.4461718274305183, 0.1696161613014463, 0.5905643797730764, 0.4433960705613843, 0.16371247819710766, 0.18564680936490252, 0.20692663833037617, 0.2756513473762009, 0.2745203548120466, 0.26543313118208234, 0.21100151924803678, 0.2015918614825133, 0.18814279454935845, 0.1765144929475384, 0.17331913571561197, 0.16811507572787943, 0.17732441520966225, 0.18058121276603256, 0.1805677054040934, 0.1758294081645938, 0.17232993050343992, 0.07057613494853776, 0.07070679769495125, 0.07139073061366419, 0.06191961845139138, 0.06547122211823209, 0.06154806739751062, 0.06719454077655118, 0.09962728118723041, 0.07395679889565343]}, "mutation_prompt": null}
{"id": "b861eaf9-2d02-4b4d-a4ad-8ddb14e0d928", "solution": "import numpy as np\n\nclass HybridAdaptiveOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim  # Adjusted size for better exploration\n        self.initial_temp = 100\n        self.final_temp = 0.1\n        self.alpha = 0.85  # Slightly altered for adaptive cooling\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.05  # Inspired by SGD\n\n    def differential_evolution(self, population, fitness):\n        F = 0.7  # Modified to enhance exploitation\n        CR = 0.85\n        new_population = np.copy(population)\n\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant = np.clip(population[a] + F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial_fitness = fitness(trial)\n            self.eval_count += 1\n\n            if trial_fitness < fitness(population[i]):\n                new_population[i] = trial\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial\n\n        return new_population\n\n    def stochastic_gradient_adjustment(self, solution, fitness):\n        gradient_steps = np.random.uniform(-1.0, 1.0, self.dim)\n        adjusted_solution = np.clip(solution + self.learning_rate * gradient_steps, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def simulated_annealing(self, solution, fitness):\n        current_solution = np.copy(solution)\n        current_fitness = fitness(current_solution)\n        temp = self.initial_temp\n\n        while temp > self.final_temp and self.eval_count < self.budget:\n            new_solution = np.clip(current_solution + np.random.uniform(-0.1, 0.1, self.dim), self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_solution)\n            self.eval_count += 1\n\n            if new_fitness < current_fitness or np.exp((current_fitness - new_fitness) / temp) > np.random.rand():\n                current_solution = new_solution\n                current_fitness = new_fitness\n\n                if current_fitness < self.best_fitness:\n                    self.best_fitness = current_fitness\n                    self.best_solution = current_solution\n\n            temp *= self.alpha\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        \n        while self.eval_count < self.budget:\n            # Apply Differential Evolution\n            population = self.differential_evolution(population, func)\n\n            # Apply Stochastic Gradient Adjustment on the best solution found so far\n            self.stochastic_gradient_adjustment(self.best_solution, func)\n\n            # Apply Simulated Annealing on the best solution found so far\n            self.simulated_annealing(self.best_solution, func)\n\n        return self.best_solution", "name": "HybridAdaptiveOpt", "description": "Hybrid Adaptive Strategy integrating Differential Evolution with Stochastic Gradient Descent-inspired adjustments and Simulated Annealing for dynamic exploration and exploitation.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "11c0d777-7f16-46ce-859e-6ddbb81166d3", "metadata": {"aucs": [0.42445327247576947, 0.3841508664863471, 0.3997328334780921, 0.4656636691668542, 0.3876475013748957, 0.41177432357825194, 0.3951724895944644, 0.40169254918710817, 0.4111093269535512, 0.07396133108145753, 0.06744837805775117, 0.07224657739264384, 0.052302673990393456, 0.05138700289964182, 0.08134799792290437, 0.05291688243851145, 0.06980191544410541, 0.06308275785454176, 0.08155636241237241, 0.08336033991602199, 0.08426863637042625, 0.09473708368620826, 0.12205679525593371, 0.0905619274907582, 0.09516611316613854, 0.09124521353362436, 0.09707962687961502, 0.1047468946688841, 0.08220017902914256, 0.09751746154132723, 0.09140656877500264, 0.10729807949857639, 0.1014486771799118, 0.08747389104176673, 0.07498474001216127, 0.08974211423598444, 0.81175893080925, 0.8344254353473006, 0.7775673485000132, 0.8087615176665763, 0.7337028661733479, 0.9210121005444003, 0.7015791035265029, 0.8975609016071071, 0.8505253781651699, 0.26933983979347864, 0.25737512611519375, 0.26259125095643987, 0.2772464263143999, 0.23596340762921808, 0.254127391433535, 0.2463860530627664, 0.2752482633140174, 0.2400626529419181, 0.2759668102207773, 0.26922942481023115, 0.2181974512016045, 0.30439846351778, 0.2667967879165881, 0.24900201012544243, 0.23020065224377284, 0.2378679027558327, 0.2139177246608106, 0.11992211494814686, 0.15639171495752346, 0.1274407972663254, 0.16691673163850285, 0.1470336500527214, 0.12392096035788258, 0.1341279420130842, 0.17272441736817257, 0.18872776595227247, 0.15390372170414834, 0.1421125723606036, 0.1980134666363268, 0.16364408876625547, 0.15085513892791258, 0.2285548478145023, 0.12214748421578425, 0.14090419609089966, 0.22788278574300425, 0.027315839007384213, 9.999999999998899e-05, 0.08736267042251167, 0.009903306749139862, 0.007043664401237715, 0.011881861168676178, 0.016669244315250076, 0.0029969925146288157, 0.007469679584958477, 0.07429362001531914, 0.08863405260373469, 0.09596797852190297, 0.10342262895621257, 0.08808650195415013, 0.06495388453836226, 0.09580421285620122, 0.0856380965430944, 0.0843356485635437, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0015633339087571807, 9.999999999998899e-05, 9.999999999998899e-05, 0.0014158654378582103, 9.999999999998899e-05, 0.062222088246479346, 0.07210139041390962, 0.11707537991072348, 0.11367676932346038, 0.08029629457495735, 0.13329019142331688, 0.11186493034477696, 0.10289444612058363, 0.1112674773420782, 0.33711195960321905, 0.3124106950783959, 0.36645990272354045, 0.35664612493621295, 0.37065020960467454, 0.3468362049127308, 0.3983489670073578, 0.36704368637814155, 0.35613004831735906, 0.12615372499025956, 0.11348211218644899, 0.10852595624556671, 0.11308214404512473, 0.08523287369159316, 0.09547836595441928, 0.08394354527533832, 0.08203502436943655, 0.09879157202262445, 0.15062183752146951, 0.3039671157575782, 0.2905250513842814, 0.18795563479729094, 0.15569922545809856, 0.21717105471475173, 0.20051255588261774, 0.15444101973486335, 0.15173188843620977, 0.2466420900475803, 0.21369413809460158, 0.20318495636921352, 0.25873276629991804, 0.24167378029842923, 0.193012122105794, 0.2088675370024382, 0.2314340424884186, 0.2333453457811111, 0.16133392003104252, 0.16875150809892803, 0.16963843054167627, 0.19404473251945564, 0.1364600054636801, 0.14718688219870457, 0.17215455367054255, 0.17226923982899156, 0.17336381232426135, 0.19911752253663562, 0.19398533060481582, 0.19452501479237594, 0.17583807697040443, 0.23611298179664753, 0.22822600810461213, 0.19541485212864074, 0.188351531891367, 0.21577014758861646, 0.19384931185410303, 0.1707077644193865, 0.18745115659636824, 0.22349955794423693, 0.18616531280884174, 0.17475272406884867, 0.1798508892694476, 0.18830631253438912, 0.21696754418216402, 0.16795305220432488, 0.46015206562987887, 0.5985926406402934, 0.21778063357863053, 0.18894836069856935, 0.1657732248475684, 0.4461718274305183, 0.1696161613014463, 0.5905643797730764, 0.4433960705613843, 0.16371247819710766, 0.18564680936490252, 0.20692663833037617, 0.2756513473762009, 0.2745203548120466, 0.26543313118208234, 0.21100151924803678, 0.2015918614825133, 0.18814279454935845, 0.1765144929475384, 0.17331913571561197, 0.16811507572787943, 0.17732441520966225, 0.18058121276603256, 0.1805677054040934, 0.1758294081645938, 0.17232993050343992, 0.07057613494853776, 0.07070679769495125, 0.07139073061366419, 0.06191961845139138, 0.06547122211823209, 0.06154806739751062, 0.06719454077655118, 0.09962728118723041, 0.07395679889565343]}, "mutation_prompt": null}
{"id": "d3253559-5cfd-431e-ba3b-7cac77ddaacd", "solution": "import numpy as np\n\nclass HybridAdaptiveOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim  # Adjusted size for better exploration\n        self.initial_temp = 100\n        self.final_temp = 0.1\n        self.alpha = 0.85  # Slightly altered for adaptive cooling\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.05  # Inspired by SGD\n\n    def differential_evolution(self, population, fitness):\n        F = 0.7  # Modified to enhance exploitation\n        CR = 0.85\n        new_population = np.copy(population)\n\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant = np.clip(population[a] + F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial_fitness = fitness(trial)\n            self.eval_count += 1\n\n            if trial_fitness < fitness(population[i]):\n                new_population[i] = trial\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial\n\n        return new_population\n\n    def stochastic_gradient_adjustment(self, solution, fitness):\n        gradient_steps = np.random.uniform(-1.0, 1.0, self.dim)\n        adjusted_solution = np.clip(solution + self.learning_rate * gradient_steps, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def simulated_annealing(self, solution, fitness):\n        current_solution = np.copy(solution)\n        current_fitness = fitness(current_solution)\n        temp = self.initial_temp\n\n        while temp > self.final_temp and self.eval_count < self.budget:\n            new_solution = np.clip(current_solution + np.random.uniform(-0.1, 0.1, self.dim), self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_solution)\n            self.eval_count += 1\n\n            if new_fitness < current_fitness or np.exp((current_fitness - new_fitness) / temp) > np.random.rand():\n                current_solution = new_solution\n                current_fitness = new_fitness\n\n                if current_fitness < self.best_fitness:\n                    self.best_fitness = current_fitness\n                    self.best_solution = current_solution\n\n            temp *= self.alpha\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        \n        while self.eval_count < self.budget:\n            # Apply Differential Evolution\n            population = self.differential_evolution(population, func)\n\n            # Apply Stochastic Gradient Adjustment on the best solution found so far\n            self.stochastic_gradient_adjustment(self.best_solution, func)\n\n            # Apply Simulated Annealing on the best solution found so far\n            self.simulated_annealing(self.best_solution, func)\n\n        return self.best_solution", "name": "HybridAdaptiveOpt", "description": "Hybrid Adaptive Strategy integrating Differential Evolution with Stochastic Gradient Descent-inspired adjustments and Simulated Annealing for dynamic exploration and exploitation.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "11c0d777-7f16-46ce-859e-6ddbb81166d3", "metadata": {"aucs": [0.42445327247576947, 0.3841508664863471, 0.3997328334780921, 0.4656636691668542, 0.3876475013748957, 0.41177432357825194, 0.3951724895944644, 0.40169254918710817, 0.4111093269535512, 0.07396133108145753, 0.06744837805775117, 0.07224657739264384, 0.052302673990393456, 0.05138700289964182, 0.08134799792290437, 0.05291688243851145, 0.06980191544410541, 0.06308275785454176, 0.08155636241237241, 0.08336033991602199, 0.08426863637042625, 0.09473708368620826, 0.12205679525593371, 0.0905619274907582, 0.09516611316613854, 0.09124521353362436, 0.09707962687961502, 0.1047468946688841, 0.08220017902914256, 0.09751746154132723, 0.09140656877500264, 0.10729807949857639, 0.1014486771799118, 0.08747389104176673, 0.07498474001216127, 0.08974211423598444, 0.81175893080925, 0.8344254353473006, 0.7775673485000132, 0.8087615176665763, 0.7337028661733479, 0.9210121005444003, 0.7015791035265029, 0.8975609016071071, 0.8505253781651699, 0.26933983979347864, 0.25737512611519375, 0.26259125095643987, 0.2772464263143999, 0.23596340762921808, 0.254127391433535, 0.2463860530627664, 0.2752482633140174, 0.2400626529419181, 0.2759668102207773, 0.26922942481023115, 0.2181974512016045, 0.30439846351778, 0.2667967879165881, 0.24900201012544243, 0.23020065224377284, 0.2378679027558327, 0.2139177246608106, 0.11992211494814686, 0.15639171495752346, 0.1274407972663254, 0.16691673163850285, 0.1470336500527214, 0.12392096035788258, 0.1341279420130842, 0.17272441736817257, 0.18872776595227247, 0.15390372170414834, 0.1421125723606036, 0.1980134666363268, 0.16364408876625547, 0.15085513892791258, 0.2285548478145023, 0.12214748421578425, 0.14090419609089966, 0.22788278574300425, 0.027315839007384213, 9.999999999998899e-05, 0.08736267042251167, 0.009903306749139862, 0.007043664401237715, 0.011881861168676178, 0.016669244315250076, 0.0029969925146288157, 0.007469679584958477, 0.07429362001531914, 0.08863405260373469, 0.09596797852190297, 0.10342262895621257, 0.08808650195415013, 0.06495388453836226, 0.09580421285620122, 0.0856380965430944, 0.0843356485635437, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0015633339087571807, 9.999999999998899e-05, 9.999999999998899e-05, 0.0014158654378582103, 9.999999999998899e-05, 0.062222088246479346, 0.07210139041390962, 0.11707537991072348, 0.11367676932346038, 0.08029629457495735, 0.13329019142331688, 0.11186493034477696, 0.10289444612058363, 0.1112674773420782, 0.33711195960321905, 0.3124106950783959, 0.36645990272354045, 0.35664612493621295, 0.37065020960467454, 0.3468362049127308, 0.3983489670073578, 0.36704368637814155, 0.35613004831735906, 0.12615372499025956, 0.11348211218644899, 0.10852595624556671, 0.11308214404512473, 0.08523287369159316, 0.09547836595441928, 0.08394354527533832, 0.08203502436943655, 0.09879157202262445, 0.15062183752146951, 0.3039671157575782, 0.2905250513842814, 0.18795563479729094, 0.15569922545809856, 0.21717105471475173, 0.20051255588261774, 0.15444101973486335, 0.15173188843620977, 0.2466420900475803, 0.21369413809460158, 0.20318495636921352, 0.25873276629991804, 0.24167378029842923, 0.193012122105794, 0.2088675370024382, 0.2314340424884186, 0.2333453457811111, 0.16133392003104252, 0.16875150809892803, 0.16963843054167627, 0.19404473251945564, 0.1364600054636801, 0.14718688219870457, 0.17215455367054255, 0.17226923982899156, 0.17336381232426135, 0.19911752253663562, 0.19398533060481582, 0.19452501479237594, 0.17583807697040443, 0.23611298179664753, 0.22822600810461213, 0.19541485212864074, 0.188351531891367, 0.21577014758861646, 0.19384931185410303, 0.1707077644193865, 0.18745115659636824, 0.22349955794423693, 0.18616531280884174, 0.17475272406884867, 0.1798508892694476, 0.18830631253438912, 0.21696754418216402, 0.16795305220432488, 0.46015206562987887, 0.5985926406402934, 0.21778063357863053, 0.18894836069856935, 0.1657732248475684, 0.4461718274305183, 0.1696161613014463, 0.5905643797730764, 0.4433960705613843, 0.16371247819710766, 0.18564680936490252, 0.20692663833037617, 0.2756513473762009, 0.2745203548120466, 0.26543313118208234, 0.21100151924803678, 0.2015918614825133, 0.18814279454935845, 0.1765144929475384, 0.17331913571561197, 0.16811507572787943, 0.17732441520966225, 0.18058121276603256, 0.1805677054040934, 0.1758294081645938, 0.17232993050343992, 0.07057613494853776, 0.07070679769495125, 0.07139073061366419, 0.06191961845139138, 0.06547122211823209, 0.06154806739751062, 0.06719454077655118, 0.09962728118723041, 0.07395679889565343]}, "mutation_prompt": null}
{"id": "895b155f-9161-4ee4-bde9-a462c42dddec", "solution": "import numpy as np\n\nclass HybridAdaptiveOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim  # Adjusted size for better exploration\n        self.initial_temp = 100\n        self.final_temp = 0.1\n        self.alpha = 0.85  # Slightly altered for adaptive cooling\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.05  # Inspired by SGD\n\n    def differential_evolution(self, population, fitness):\n        F = 0.7  # Modified to enhance exploitation\n        CR = 0.85\n        new_population = np.copy(population)\n\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant = np.clip(population[a] + F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial_fitness = fitness(trial)\n            self.eval_count += 1\n\n            if trial_fitness < fitness(population[i]):\n                new_population[i] = trial\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial\n\n        return new_population\n\n    def stochastic_gradient_adjustment(self, solution, fitness):\n        gradient_steps = np.random.uniform(-1.0, 1.0, self.dim)\n        adjusted_solution = np.clip(solution + self.learning_rate * gradient_steps, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def simulated_annealing(self, solution, fitness):\n        current_solution = np.copy(solution)\n        current_fitness = fitness(current_solution)\n        temp = self.initial_temp\n\n        while temp > self.final_temp and self.eval_count < self.budget:\n            new_solution = np.clip(current_solution + np.random.uniform(-0.1, 0.1, self.dim), self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_solution)\n            self.eval_count += 1\n\n            if new_fitness < current_fitness or np.exp((current_fitness - new_fitness) / temp) > np.random.rand():\n                current_solution = new_solution\n                current_fitness = new_fitness\n\n                if current_fitness < self.best_fitness:\n                    self.best_fitness = current_fitness\n                    self.best_solution = current_solution\n\n            temp *= self.alpha\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        \n        while self.eval_count < self.budget:\n            # Apply Differential Evolution\n            population = self.differential_evolution(population, func)\n\n            # Apply Stochastic Gradient Adjustment on the best solution found so far\n            self.stochastic_gradient_adjustment(self.best_solution, func)\n\n            # Apply Simulated Annealing on the best solution found so far\n            self.simulated_annealing(self.best_solution, func)\n\n        return self.best_solution", "name": "HybridAdaptiveOpt", "description": "Hybrid Adaptive Strategy integrating Differential Evolution with Stochastic Gradient Descent-inspired adjustments and Simulated Annealing for dynamic exploration and exploitation.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "11c0d777-7f16-46ce-859e-6ddbb81166d3", "metadata": {"aucs": [0.42445327247576947, 0.3841508664863471, 0.3997328334780921, 0.4656636691668542, 0.3876475013748957, 0.41177432357825194, 0.3951724895944644, 0.40169254918710817, 0.4111093269535512, 0.07396133108145753, 0.06744837805775117, 0.07224657739264384, 0.052302673990393456, 0.05138700289964182, 0.08134799792290437, 0.05291688243851145, 0.06980191544410541, 0.06308275785454176, 0.08155636241237241, 0.08336033991602199, 0.08426863637042625, 0.09473708368620826, 0.12205679525593371, 0.0905619274907582, 0.09516611316613854, 0.09124521353362436, 0.09707962687961502, 0.1047468946688841, 0.08220017902914256, 0.09751746154132723, 0.09140656877500264, 0.10729807949857639, 0.1014486771799118, 0.08747389104176673, 0.07498474001216127, 0.08974211423598444, 0.81175893080925, 0.8344254353473006, 0.7775673485000132, 0.8087615176665763, 0.7337028661733479, 0.9210121005444003, 0.7015791035265029, 0.8975609016071071, 0.8505253781651699, 0.26933983979347864, 0.25737512611519375, 0.26259125095643987, 0.2772464263143999, 0.23596340762921808, 0.254127391433535, 0.2463860530627664, 0.2752482633140174, 0.2400626529419181, 0.2759668102207773, 0.26922942481023115, 0.2181974512016045, 0.30439846351778, 0.2667967879165881, 0.24900201012544243, 0.23020065224377284, 0.2378679027558327, 0.2139177246608106, 0.11992211494814686, 0.15639171495752346, 0.1274407972663254, 0.16691673163850285, 0.1470336500527214, 0.12392096035788258, 0.1341279420130842, 0.17272441736817257, 0.18872776595227247, 0.15390372170414834, 0.1421125723606036, 0.1980134666363268, 0.16364408876625547, 0.15085513892791258, 0.2285548478145023, 0.12214748421578425, 0.14090419609089966, 0.22788278574300425, 0.027315839007384213, 9.999999999998899e-05, 0.08736267042251167, 0.009903306749139862, 0.007043664401237715, 0.011881861168676178, 0.016669244315250076, 0.0029969925146288157, 0.007469679584958477, 0.07429362001531914, 0.08863405260373469, 0.09596797852190297, 0.10342262895621257, 0.08808650195415013, 0.06495388453836226, 0.09580421285620122, 0.0856380965430944, 0.0843356485635437, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0015633339087571807, 9.999999999998899e-05, 9.999999999998899e-05, 0.0014158654378582103, 9.999999999998899e-05, 0.062222088246479346, 0.07210139041390962, 0.11707537991072348, 0.11367676932346038, 0.08029629457495735, 0.13329019142331688, 0.11186493034477696, 0.10289444612058363, 0.1112674773420782, 0.33711195960321905, 0.3124106950783959, 0.36645990272354045, 0.35664612493621295, 0.37065020960467454, 0.3468362049127308, 0.3983489670073578, 0.36704368637814155, 0.35613004831735906, 0.12615372499025956, 0.11348211218644899, 0.10852595624556671, 0.11308214404512473, 0.08523287369159316, 0.09547836595441928, 0.08394354527533832, 0.08203502436943655, 0.09879157202262445, 0.15062183752146951, 0.3039671157575782, 0.2905250513842814, 0.18795563479729094, 0.15569922545809856, 0.21717105471475173, 0.20051255588261774, 0.15444101973486335, 0.15173188843620977, 0.2466420900475803, 0.21369413809460158, 0.20318495636921352, 0.25873276629991804, 0.24167378029842923, 0.193012122105794, 0.2088675370024382, 0.2314340424884186, 0.2333453457811111, 0.16133392003104252, 0.16875150809892803, 0.16963843054167627, 0.19404473251945564, 0.1364600054636801, 0.14718688219870457, 0.17215455367054255, 0.17226923982899156, 0.17336381232426135, 0.19911752253663562, 0.19398533060481582, 0.19452501479237594, 0.17583807697040443, 0.23611298179664753, 0.22822600810461213, 0.19541485212864074, 0.188351531891367, 0.21577014758861646, 0.19384931185410303, 0.1707077644193865, 0.18745115659636824, 0.22349955794423693, 0.18616531280884174, 0.17475272406884867, 0.1798508892694476, 0.18830631253438912, 0.21696754418216402, 0.16795305220432488, 0.46015206562987887, 0.5985926406402934, 0.21778063357863053, 0.18894836069856935, 0.1657732248475684, 0.4461718274305183, 0.1696161613014463, 0.5905643797730764, 0.4433960705613843, 0.16371247819710766, 0.18564680936490252, 0.20692663833037617, 0.2756513473762009, 0.2745203548120466, 0.26543313118208234, 0.21100151924803678, 0.2015918614825133, 0.18814279454935845, 0.1765144929475384, 0.17331913571561197, 0.16811507572787943, 0.17732441520966225, 0.18058121276603256, 0.1805677054040934, 0.1758294081645938, 0.17232993050343992, 0.07057613494853776, 0.07070679769495125, 0.07139073061366419, 0.06191961845139138, 0.06547122211823209, 0.06154806739751062, 0.06719454077655118, 0.09962728118723041, 0.07395679889565343]}, "mutation_prompt": null}
{"id": "3d8ee278-a1cf-4e8f-9506-99eb3540f304", "solution": "import numpy as np\n\nclass HybridAdaptiveOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim  # Adjusted size for better exploration\n        self.initial_temp = 100\n        self.final_temp = 0.1\n        self.alpha = 0.85  # Slightly altered for adaptive cooling\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.05  # Inspired by SGD\n\n    def differential_evolution(self, population, fitness):\n        F = 0.7  # Modified to enhance exploitation\n        CR = 0.85\n        new_population = np.copy(population)\n\n        for i in range(self.population_size):\n            if self.eval_count >= self.budget:\n                break\n\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant = np.clip(population[a] + F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial_fitness = fitness(trial)\n            self.eval_count += 1\n\n            if trial_fitness < fitness(population[i]):\n                new_population[i] = trial\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial\n\n        return new_population\n\n    def stochastic_gradient_adjustment(self, solution, fitness):\n        gradient_steps = np.random.uniform(-1.0, 1.0, self.dim)\n        adjusted_solution = np.clip(solution + self.learning_rate * gradient_steps, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def simulated_annealing(self, solution, fitness):\n        current_solution = np.copy(solution)\n        current_fitness = fitness(current_solution)\n        temp = self.initial_temp\n\n        while temp > self.final_temp and self.eval_count < self.budget:\n            new_solution = np.clip(current_solution + np.random.uniform(-0.1, 0.1, self.dim), self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_solution)\n            self.eval_count += 1\n\n            if new_fitness < current_fitness or np.exp((current_fitness - new_fitness) / temp) > np.random.rand():\n                current_solution = new_solution\n                current_fitness = new_fitness\n\n                if current_fitness < self.best_fitness:\n                    self.best_fitness = current_fitness\n                    self.best_solution = current_solution\n\n            temp *= self.alpha\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        \n        while self.eval_count < self.budget:\n            # Apply Differential Evolution\n            population = self.differential_evolution(population, func)\n\n            # Apply Stochastic Gradient Adjustment on the best solution found so far\n            self.stochastic_gradient_adjustment(self.best_solution, func)\n\n            # Apply Simulated Annealing on the best solution found so far\n            self.simulated_annealing(self.best_solution, func)\n\n        return self.best_solution", "name": "HybridAdaptiveOpt", "description": "Hybrid Adaptive Strategy integrating Differential Evolution with Stochastic Gradient Descent-inspired adjustments and Simulated Annealing for dynamic exploration and exploitation.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "11c0d777-7f16-46ce-859e-6ddbb81166d3", "metadata": {"aucs": [0.42445327247576947, 0.3841508664863471, 0.3997328334780921, 0.4656636691668542, 0.3876475013748957, 0.41177432357825194, 0.3951724895944644, 0.40169254918710817, 0.4111093269535512, 0.07396133108145753, 0.06744837805775117, 0.07224657739264384, 0.052302673990393456, 0.05138700289964182, 0.08134799792290437, 0.05291688243851145, 0.06980191544410541, 0.06308275785454176, 0.08155636241237241, 0.08336033991602199, 0.08426863637042625, 0.09473708368620826, 0.12205679525593371, 0.0905619274907582, 0.09516611316613854, 0.09124521353362436, 0.09707962687961502, 0.1047468946688841, 0.08220017902914256, 0.09751746154132723, 0.09140656877500264, 0.10729807949857639, 0.1014486771799118, 0.08747389104176673, 0.07498474001216127, 0.08974211423598444, 0.81175893080925, 0.8344254353473006, 0.7775673485000132, 0.8087615176665763, 0.7337028661733479, 0.9210121005444003, 0.7015791035265029, 0.8975609016071071, 0.8505253781651699, 0.26933983979347864, 0.25737512611519375, 0.26259125095643987, 0.2772464263143999, 0.23596340762921808, 0.254127391433535, 0.2463860530627664, 0.2752482633140174, 0.2400626529419181, 0.2759668102207773, 0.26922942481023115, 0.2181974512016045, 0.30439846351778, 0.2667967879165881, 0.24900201012544243, 0.23020065224377284, 0.2378679027558327, 0.2139177246608106, 0.11992211494814686, 0.15639171495752346, 0.1274407972663254, 0.16691673163850285, 0.1470336500527214, 0.12392096035788258, 0.1341279420130842, 0.17272441736817257, 0.18872776595227247, 0.15390372170414834, 0.1421125723606036, 0.1980134666363268, 0.16364408876625547, 0.15085513892791258, 0.2285548478145023, 0.12214748421578425, 0.14090419609089966, 0.22788278574300425, 0.027315839007384213, 9.999999999998899e-05, 0.08736267042251167, 0.009903306749139862, 0.007043664401237715, 0.011881861168676178, 0.016669244315250076, 0.0029969925146288157, 0.007469679584958477, 0.07429362001531914, 0.08863405260373469, 0.09596797852190297, 0.10342262895621257, 0.08808650195415013, 0.06495388453836226, 0.09580421285620122, 0.0856380965430944, 0.0843356485635437, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0015633339087571807, 9.999999999998899e-05, 9.999999999998899e-05, 0.0014158654378582103, 9.999999999998899e-05, 0.062222088246479346, 0.07210139041390962, 0.11707537991072348, 0.11367676932346038, 0.08029629457495735, 0.13329019142331688, 0.11186493034477696, 0.10289444612058363, 0.1112674773420782, 0.33711195960321905, 0.3124106950783959, 0.36645990272354045, 0.35664612493621295, 0.37065020960467454, 0.3468362049127308, 0.3983489670073578, 0.36704368637814155, 0.35613004831735906, 0.12615372499025956, 0.11348211218644899, 0.10852595624556671, 0.11308214404512473, 0.08523287369159316, 0.09547836595441928, 0.08394354527533832, 0.08203502436943655, 0.09879157202262445, 0.15062183752146951, 0.3039671157575782, 0.2905250513842814, 0.18795563479729094, 0.15569922545809856, 0.21717105471475173, 0.20051255588261774, 0.15444101973486335, 0.15173188843620977, 0.2466420900475803, 0.21369413809460158, 0.20318495636921352, 0.25873276629991804, 0.24167378029842923, 0.193012122105794, 0.2088675370024382, 0.2314340424884186, 0.2333453457811111, 0.16133392003104252, 0.16875150809892803, 0.16963843054167627, 0.19404473251945564, 0.1364600054636801, 0.14718688219870457, 0.17215455367054255, 0.17226923982899156, 0.17336381232426135, 0.19911752253663562, 0.19398533060481582, 0.19452501479237594, 0.17583807697040443, 0.23611298179664753, 0.22822600810461213, 0.19541485212864074, 0.188351531891367, 0.21577014758861646, 0.19384931185410303, 0.1707077644193865, 0.18745115659636824, 0.22349955794423693, 0.18616531280884174, 0.17475272406884867, 0.1798508892694476, 0.18830631253438912, 0.21696754418216402, 0.16795305220432488, 0.46015206562987887, 0.5985926406402934, 0.21778063357863053, 0.18894836069856935, 0.1657732248475684, 0.4461718274305183, 0.1696161613014463, 0.5905643797730764, 0.4433960705613843, 0.16371247819710766, 0.18564680936490252, 0.20692663833037617, 0.2756513473762009, 0.2745203548120466, 0.26543313118208234, 0.21100151924803678, 0.2015918614825133, 0.18814279454935845, 0.1765144929475384, 0.17331913571561197, 0.16811507572787943, 0.17732441520966225, 0.18058121276603256, 0.1805677054040934, 0.1758294081645938, 0.17232993050343992, 0.07057613494853776, 0.07070679769495125, 0.07139073061366419, 0.06191961845139138, 0.06547122211823209, 0.06154806739751062, 0.06719454077655118, 0.09962728118723041, 0.07395679889565343]}, "mutation_prompt": null}
{"id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 23, "fitness": 0.33457847424200887, "feedback": "The algorithm EnhancedHybridOpt got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.27.", "error": "", "parent_id": "11c0d777-7f16-46ce-859e-6ddbb81166d3", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "ed1048e5-96ab-40a0-a11a-9b0b98dcd546", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "3acc4d5e-1f65-41dc-a10b-2ecc38657f83", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "c7b6bfd7-d2b7-4712-92c5-a5f7360707a9", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "1532ea95-40a1-419c-a38e-1f7fa1c4296f", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "c204255f-57f9-44a0-8d43-6efca62c3e9e", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "56c3d983-d132-420c-bc85-dd63d289fe31", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "e0e86f21-a776-4418-897b-0a01f3a4725e", "solution": "import numpy as np\n\nclass HybridParticleGaussianOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Adjusted for efficiency\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.05  # Reduced learning rate\n        self.inertia_weight = 0.6  # Adjusted inertia weight\n        self.cognitive_const = 1.4  # Adjusted cognitive component\n        self.social_const = 1.6  # Adjusted social component\n        self.mutation_rate = 0.1  # New mutation rate\n\n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities with mutation\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            # Apply Gaussian mutation\n            if np.random.rand() < self.mutation_rate:\n                mutation = np.random.normal(0, 1, self.dim)\n                new_population[i] = np.clip(new_population[i] + mutation, self.lower_bound, self.upper_bound)\n            \n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "HybridParticleGaussianOpt", "description": "Hybrid Particle-Gaussian Optimization incorporating a novel dynamic mutation strategy to enhance solution diversity and convergence speed.", "configspace": "", "generation": 30, "fitness": 0.2692711033067128, "feedback": "The algorithm HybridParticleGaussianOpt got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.24.", "error": "", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.7814963481423506, 0.7164419784391751, 0.6925089653410146, 0.6868783470720184, 0.6984036259880522, 0.7692128868085133, 0.6760415892406342, 0.6707483500610691, 0.7063257491659799, 0.000782553797068597, 0.07207785184163162, 0.10101700685074388, 0.11523919839040375, 0.03973089216002823, 0.10645331313690243, 0.038168572797761424, 0.07457692900118473, 0.0404281037721399, 0.07563731633204529, 0.16023603632887806, 0.08375259331663387, 0.09227834040723337, 0.10876015312694376, 0.0717197423632242, 0.06674008776192109, 0.1266791005177409, 0.18328688297461315, 0.13028228675865172, 0.10753693961462374, 0.07148495587720571, 0.07966961083924218, 0.07665681342184394, 0.09314212771218977, 0.09370044044934878, 0.05677977860014105, 0.09684633768513051, 0.9943257267153037, 0.9935805256514773, 0.9947855647026984, 0.9733667572334268, 0.975738534254624, 0.9710683806397515, 0.9924262681937792, 0.9938211400036575, 0.9877565660166865, 0.474260401426841, 0.4117499783706443, 0.43290722673370174, 0.4472273847209737, 0.4027243423892394, 0.5163295464097875, 0.3906542292711107, 0.4213678193563616, 0.43225585989662163, 0.3996773509517352, 0.37842490273059104, 0.29882416944546153, 0.267193243393267, 0.21016780030832094, 0.21549092616989285, 0.16543927603147568, 0.23274268720936697, 0.3757942265584935, 0.24331084039480133, 0.18854131723006184, 0.23103861540185944, 0.21761468868041411, 0.38312366045742396, 0.11852139033034748, 0.22057676418979288, 0.1985470628527788, 0.20906108035198845, 0.1324858687551811, 0.20905331544839756, 0.12694302830382698, 0.1359732806159718, 0.2099822647538656, 0.13601892515157799, 0.2296179294593268, 0.2071512621599465, 0.23948327608290176, 0.038251184979090413, 0.0262048886768127, 0.06139814562211321, 0.04822796049782552, 0.030844315524631405, 0.015303037736906888, 0.008019949586968833, 0.03256522223377323, 0.14348153324395885, 0.1308255531027699, 0.11488989360009105, 0.06475503643064418, 0.12048709681589098, 0.021848484494704112, 0.017590989348208463, 0.13260002569729823, 0.12498512036689713, 0.09116079470466343, 0.11114634131056012, 0.06866470121588442, 0.17967585548638565, 0.11312517299788105, 0.08832798223990357, 0.07800626732204852, 0.08679110206167484, 0.09805739130844482, 0.11328532005696657, 0.14546469400253115, 0.1309708977197077, 0.12454901514970407, 0.23776653572947115, 0.1557614511047457, 0.1067767561038272, 0.0851984396029355, 0.11562007649645822, 0.08283366872733078, 0.4803505767883708, 0.4891840844857337, 0.4623745530939587, 0.5013395376856276, 0.542597888861001, 0.5338286799401664, 0.5108729615314738, 0.5503811888310597, 0.5581341501753224, 0.09551117121360131, 0.1920641801747227, 0.0725623707590507, 0.11910052396873139, 0.13181955045417926, 0.09335727784911718, 0.1395229858974102, 0.12848428357909525, 0.1278593382912453, 0.2535736079101819, 0.2656468349574663, 0.1787586358046125, 0.3644643818837908, 0.24973317323905808, 0.2018670262190927, 0.22887922554876017, 0.20130252895849, 0.3623531865305295, 0.2381439061335222, 0.38611234321369237, 0.2695417543980094, 0.3466870959054468, 0.271959792276126, 0.3881285680010098, 0.2636094693278014, 0.26620055578491764, 0.21089659558780327, 0.2380927390604055, 0.17961085228464013, 0.22375234205895667, 0.2441699849479898, 0.21156851780183228, 0.2742794705533703, 0.162011185323658, 0.20770895138923762, 0.23029816886517196, 0.21150711259239308, 0.21111065359967573, 0.23813013711105957, 0.23451800331772277, 0.1940643292423534, 0.22221139734774475, 0.2404054131049701, 0.2019191144653134, 0.22035623878381416, 0.19161893243863648, 0.20073889805781142, 0.20085426879409718, 0.22008769987866494, 0.1900314197916274, 0.1916587122447344, 0.19217393092404556, 0.20843401135477657, 0.2104313200589747, 0.9059387007021381, 0.1778956945950202, 0.1547260849875609, 0.9195115308415776, 0.2021609591327459, 0.20171700349456834, 0.14324023787137352, 0.17047830125593733, 0.9210810148500095, 0.7806616751117614, 0.21347604286108557, 0.8123596350441966, 0.21255589555460375, 0.1694861875087621, 0.15566896619750203, 0.8673840467349505, 0.21344559792068918, 0.7437672850758623, 0.19425858609235347, 0.185763661768926, 0.20043015233166928, 0.2217015086817915, 0.21514201598734772, 0.18792101216629142, 0.22879776885721392, 0.20418219638282364, 0.2065753508507835, 0.07858158111029279, 0.10194984040676736, 0.08608141833333971, 0.09252815624287869, 0.0910958338895147, 0.08936786808867869, 0.09316181290635672, 0.09533035612484086, 0.10085843083414714]}, "mutation_prompt": null}
{"id": "8a6dc0f9-98a2-4855-8ae1-2c33831558f8", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "242119a4-97c9-4f97-ac80-6750a5268c1f", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "cddd391a-bd33-42d5-b50f-b8b64706481f", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "b98879af-14ad-40ff-afa3-ef2638495206", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "372d67bb-370d-4a6a-a283-81b8d8d0fde3", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "5f40cadb-02d4-468f-b722-3f978a88d034", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim  # Increased population size\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.05  # Reduced learning rate for finer updates\n        self.inertia_weight = 0.6  # Adjusted inertia for improved convergence\n        self.cognitive_const = 2.0  # Enhanced cognitive component\n        self.social_const = 2.0  # Enhanced social component\n\n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def stochastic_perturbation(self):\n        perturbation = np.random.normal(0, 0.1, self.dim)  # Gaussian perturbation\n        perturbed_solution = np.clip(self.best_solution + perturbation, self.lower_bound, self.upper_bound)\n        return perturbed_solution\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Use stochastic perturbation to explore the neighborhood of the best solution\n            perturbed_solution = self.stochastic_perturbation()\n            perturbed_fitness = func(perturbed_solution)\n            self.eval_count += 1\n\n            if perturbed_fitness < self.best_fitness:\n                self.best_fitness = perturbed_fitness\n                self.best_solution = perturbed_solution\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization using Adaptive Particle Swarm and Stochastic Perturbation for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": 0.324939381066521, "feedback": "The algorithm EnhancedHybridOpt got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.26.", "error": "", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.820675303946934, 0.8126139337437133, 0.8152277128530392, 0.8152065196868787, 0.793251294389163, 0.8169283967634762, 0.8174248747185482, 0.8118859421389504, 0.803131678081036, 0.35686494270227354, 0.2613422619027529, 0.41700071773368497, 0.2507125374256274, 0.40904711944285266, 0.29515687865636886, 0.438151531167674, 0.48817565036559496, 0.43204679705208215, 0.14208051043486325, 0.10980893444392881, 0.09307598141686213, 0.12581832222710765, 0.11661232569296609, 0.13380778860847697, 0.12135237835884272, 0.0868220487141933, 0.153667247566731, 0.10765121155343982, 0.08155882683947568, 0.08447726456224258, 0.11179988433920007, 0.1522713644546495, 0.06732743766767058, 0.10772104205215838, 0.08854046789233383, 0.09070544799117963, 0.9904030306198229, 0.9927215571017909, 0.9914412461045075, 0.9414771839345494, 0.988515510240657, 0.9898644500059526, 0.992476045248129, 0.9924801307096134, 0.9887649328943516, 0.595948917716852, 0.5151661649853738, 0.4169916926544418, 0.534087988491015, 0.5371140068515625, 0.38427690394968794, 0.46060636802446775, 0.4707031188560026, 0.5086168717013055, 0.17167769644847575, 0.8386353252176176, 0.7331698672272015, 0.19312567200907182, 0.2676355536156959, 0.19167764405360577, 0.7991615474747724, 0.2199873976182335, 0.18060456825743076, 0.12465312218879376, 0.48886124486619087, 0.47482465240656624, 0.43894659125092006, 0.36660171194378566, 0.5523816841727299, 0.505260112263096, 0.43995664792842304, 0.47303577584703393, 0.5908008745479891, 0.4801905253725215, 0.1349029549936429, 0.13470991405472799, 0.3308672721502629, 0.5863314692694199, 0.5356222048287484, 0.37998604625473476, 0.34194133951065264, 0.052622161636779685, 0.13619171535290386, 0.07156729258964045, 0.40345812314537555, 0.0003578894621188988, 0.27360256401578886, 0.24346935670524394, 0.05453521955543461, 0.007772005908490476, 0.15233971762805654, 0.15712095679874205, 0.2786541086960237, 0.2997282396667652, 0.2636396722200186, 0.19042590985683294, 0.017045083879562717, 0.21023044157665782, 0.1797938018207289, 0.13912511669007377, 0.1621286700173432, 0.04446042031683062, 0.1801791929630996, 0.22787769476792985, 0.2421059473066577, 0.08959857547055616, 0.09293920451316551, 0.26497338846331653, 0.2120553442592139, 0.192031181955018, 0.19484985333658944, 0.14199416753060234, 0.11967338450331921, 0.08289414896299563, 0.2407724781279359, 0.2713253957690146, 0.07971595880079041, 0.6247449507418155, 0.6771515949893833, 0.650618517807519, 0.6179383708776203, 0.6463095572080328, 0.6124558359731275, 0.6863200730654486, 0.6460555164330912, 0.6640988169211133, 0.0972831003801029, 0.12270368481761107, 0.07814517932770848, 0.11486691936650173, 0.11817211559238916, 0.13756774515195136, 0.11399823115661878, 0.07064169911546525, 0.0796902031240545, 0.18006583017188404, 0.18080763069058137, 0.44247604928135775, 0.1965514518085273, 0.35190828038016486, 0.2242406858319187, 0.2273710247473979, 0.1665481641274169, 0.15808770291389063, 0.4317025020046297, 0.35030018735126045, 0.37461627949448095, 0.27212292973400365, 0.33192521580349743, 0.4819078808129268, 0.2715711671534794, 0.24156970332409833, 0.2576135019936905, 0.24852485186476903, 0.09828082053580234, 0.2614317404284351, 0.22784121224569853, 0.2549486535532669, 0.18664217166434038, 0.230439327739981, 0.16962996421301502, 0.16310529815596497, 0.28757898183505204, 0.18654943537945068, 0.1929395271368779, 0.2178710387296252, 0.19348702055186873, 0.21017722743724576, 0.26829802219739296, 0.22361354084659124, 0.23852210256204875, 0.21248423727518706, 0.17923918871476385, 0.19851564304674052, 0.19635934066039895, 0.18138690640885557, 0.1972427462572115, 0.18979366775971052, 0.18974079603854, 0.19596570752799103, 0.18592423404836544, 0.18854421280300215, 0.18845463920982375, 0.8718668271389174, 0.20070005584298667, 0.16895287322572206, 0.14291515357244622, 0.16311699639549238, 0.9005658347705128, 0.8850218361701645, 0.21329505702697737, 0.6920357250892251, 0.8255440810628727, 0.1694333499897258, 0.15302432363608165, 0.16871190759340038, 0.1127812008327328, 0.8671746814615784, 0.19305696006032658, 0.21362380396463176, 0.19576856854229663, 0.21536169163970675, 0.2268224137511483, 0.24523601732458755, 0.22816250303966257, 0.22343961654464983, 0.2008319642998193, 0.09668616288938936, 0.07746896145544901, 0.07411949667240225, 0.09299057266109667, 0.0939696623663856, 0.07283289547135241, 0.0781077989307738, 0.09199328811219198, 0.09921097461201611]}, "mutation_prompt": null}
{"id": "f1db26a7-2ec8-4348-9d89-58a77de51d75", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "de49a73c-b6d5-4c40-807f-d1a53f2ee33f", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "ab3c8691-3da7-4b54-bf87-585c78d3dad4", "solution": "import numpy as np\n\nclass OptimizedAdaptiveHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Adjusted population size for exploration\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.05  # Adjusted learning rate for stability\n        self.inertia_weight = 0.6  # Refined inertia for balance\n        self.cognitive_const = 1.7  # Enhanced cognitive component\n        self.social_const = 1.4  # Balanced social component\n        self.mutation_factor = 0.8  # Differential Evolution mutation factor\n        self.crossover_rate = 0.9  # Differential Evolution crossover rate\n    \n    def differential_evolution(self, population, fitness):\n        new_population = np.copy(population)\n\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            x1, x2, x3 = population[indices]\n            mutant_vector = np.clip(x1 + self.mutation_factor * (x2 - x3), self.lower_bound, self.upper_bound)\n            trial_vector = np.copy(new_population[i])\n\n            for j in range(self.dim):\n                if np.random.rand() < self.crossover_rate:\n                    trial_vector[j] = mutant_vector[j]\n            \n            trial_fitness = fitness(trial_vector)\n            self.eval_count += 1\n\n            if trial_fitness < fitness(new_population[i]):\n                new_population[i] = trial_vector\n\n            if trial_fitness < self.best_fitness:\n                self.best_fitness = trial_fitness\n                self.best_solution = trial_vector\n\n        return new_population\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness_values = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n\n        for i in range(self.population_size):\n            if fitness_values[i] < self.best_fitness:\n                self.best_fitness = fitness_values[i]\n                self.best_solution = population[i]\n\n        while self.eval_count < self.budget:\n            population = self.differential_evolution(population, func)\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "OptimizedAdaptiveHybrid", "description": "Optimized Adaptive Hybrid Algorithm using Differential Evolution for enhanced exploration and dynamic parameter tuning to improve convergence efficiency.", "configspace": "", "generation": 39, "fitness": 0.19652789189894898, "feedback": "The algorithm OptimizedAdaptiveHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.18.", "error": "", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.4046450163694604, 0.39362812354611654, 0.4420871012905748, 0.4461054793532906, 0.4319501071487357, 0.4468344620068615, 0.4362531068051808, 0.44154645139525306, 0.3993899544524523, 0.1682063249815554, 0.16967688254150093, 0.15089740573337662, 0.13759262561971575, 0.15865941509842318, 0.13718185698605667, 0.14718907178060947, 0.1513245584864158, 0.16044152335761774, 0.09709472378263417, 0.10897706486779046, 0.1326590671084925, 0.10434665789667363, 0.07429251376440194, 0.12380258927338506, 0.0955425579411342, 0.09814379824075625, 0.10648169137730656, 0.08057943981519844, 0.08335446475453867, 0.09140383735929447, 0.07154866242183067, 0.08787254776920561, 0.08129331288285124, 0.07218513029081697, 0.07721616209105608, 0.0795758790779384, 0.9785273570722104, 0.9118239870481407, 0.8172031632960755, 0.8748908081680513, 0.881601827796176, 0.9077971010322554, 0.9020052687515908, 0.9549118281191431, 0.9186003520372197, 0.18006393405166965, 0.18352352785095205, 0.17887513844063818, 0.1777453891480042, 0.17522227919990674, 0.20981463520589683, 0.21237103472960306, 0.1857132712735825, 0.1816637337592486, 0.214010070428719, 0.23758005741835064, 0.23064829489849914, 0.3924892888505832, 0.2558697877454912, 0.3351156368395789, 0.26565549264708543, 0.4108699993945364, 0.3191436004326932, 0.14946261710769815, 0.10172317051708157, 0.13648855064596077, 0.10647097407868, 0.10617053666466525, 0.11436483015873833, 0.10072202623734317, 0.11412344857847379, 0.1276419332273916, 0.09946780556847445, 0.1600841080763139, 0.15920588414123193, 0.10926956433720625, 0.1222541819556856, 0.1196052004883219, 0.1067922930944536, 0.09149401854057482, 0.11170242072421421, 0.03665970261351026, 0.03903173674740956, 0.050894489023192935, 0.059698607614356636, 0.017890847567756052, 0.02950201070348979, 0.03311077074742552, 0.03291379947226836, 0.03544462378404445, 0.15413234256810737, 0.1915210380072313, 0.13743687157064555, 0.13758311303407933, 0.14158401110643848, 0.1319565288625899, 0.15515759720354294, 0.19543242054529752, 0.1383392876141033, 0.000322757694473097, 0.00019138734419554826, 0.00647725064495519, 0.00953564960074349, 9.999999999998899e-05, 0.0028061521277815693, 0.01719368493559814, 0.0023782845048911927, 0.003973324528786737, 0.09259408517296164, 0.06984901589867099, 0.08686681572754917, 0.08947062546509366, 0.08976787696060307, 0.08578376089424777, 0.09255023622852454, 0.09394572689158576, 0.08662586085922797, 0.3534940213950417, 0.38326577330745915, 0.3780735679529349, 0.3639915535803496, 0.3821186321873907, 0.3820843638909439, 0.37580641086898137, 0.36508582703873516, 0.3762053686176564, 0.08349207902888356, 0.09666341528324407, 0.0949393082933988, 0.08045240528333708, 0.09655504760246136, 0.10234134849996446, 0.10751476274149208, 0.1074309662136711, 0.09531868133714394, 0.18825478238091287, 0.20015764448003037, 0.16083034974161325, 0.1729348053286649, 0.1576703097584259, 0.18369574582816528, 0.15049026478302474, 0.2038037623363106, 0.16611689090965798, 0.245408859040805, 0.23864936676117976, 0.2308990312023287, 0.21323215609175306, 0.21025621000184003, 0.2281211987449946, 0.2508416981483397, 0.2551103813573754, 0.24768809782386247, 0.16717609691971225, 0.16820943407562883, 0.1672838450858073, 0.15544317381489492, 0.194090298712564, 0.17296486074627992, 0.17753051796833985, 0.16547321227972245, 0.1850808438550583, 0.18943933601514384, 0.17342635352524027, 0.18268023168519398, 0.1672412612478612, 0.1697929877627785, 0.1649031780846022, 0.17861963548177096, 0.18447428726378967, 0.19010940312114766, 0.1738398894263602, 0.15658203293765016, 0.1636798111647345, 0.17104348941652003, 0.1979776552837168, 0.18198273732060033, 0.1895903597416312, 0.1799814467146762, 0.1587865254697577, 0.15398144498048283, 0.21183390535612479, 0.20276699015934196, 0.15968320004097836, 0.1709851468696948, 0.15571482744580767, 0.1657584631096506, 0.18944139611941546, 0.16475594290620588, 0.23281860440958813, 0.2618441359766742, 0.27766094449687284, 0.16544842214146682, 0.18336891645893905, 0.206514911639752, 0.18689719160378016, 0.19565357018269536, 0.184543737193269, 0.18761552460018027, 0.1909578232209821, 0.1825893877907835, 0.17480649770837353, 0.1776964115394618, 0.1783130357732754, 0.19668067408161682, 0.17815502656198845, 0.18112323312482326, 0.06145216190504488, 0.06476337033173074, 0.06759336144662442, 0.07039208077118841, 0.059477713838459345, 0.08117596425612206, 0.06269318593336826, 0.06349201084503386, 0.07549515067733015]}, "mutation_prompt": null}
{"id": "45911744-93d4-4674-b5ad-27cba7e58db1", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "bebe8c5f-fdf0-44c3-a04b-f3f25416ac42", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "ffce70e6-ebc0-4fe3-91c5-525200ffff1d", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "452dbcad-415d-4c24-a409-9bfb926cf512", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "543c8deb-5389-4fdf-81dd-48360e5946ef", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "e3d7a2f1-69f9-46fe-bd1f-dbae50634e19", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "94e21689-e83f-4dce-9830-3922a3f1c02d", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "3b33bac4-4355-4205-9659-7aab98103efb", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "e37cd835-5b6f-426c-b9ac-54a8157f39ee", "solution": "import numpy as np\n\nclass QuantumAdaptiveHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim  # Slightly larger for increased diversity\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.2  # Enhanced learning rate\n        self.quantum_gate_angle = 0.05  # Rotation angle for quantum-inspired update\n        self.cognitive_const = 1.4  # Adjusted PSO cognitive component\n        self.social_const = 1.6  # Adjusted PSO social component\n\n    def quantum_rotation_update(self, population, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n\n        for i in range(self.population_size):\n            rotation_matrix = np.array([[np.cos(self.quantum_gate_angle), -np.sin(self.quantum_gate_angle)],\n                                        [np.sin(self.quantum_gate_angle), np.cos(self.quantum_gate_angle)]])\n            rotation_vector = np.random.uniform(-1.0, 1.0, self.dim)\n            rotated_vector = np.dot(rotation_matrix, rotation_vector)\n            new_population[i] = np.clip(population[i] + rotated_vector, self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, personal_best_positions, personal_best_scores\n\n    def dynamic_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * np.exp(-self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            population, personal_best_positions, personal_best_scores = self.quantum_rotation_update(\n                population, personal_best_positions, personal_best_scores, func\n            )\n            \n            self.dynamic_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "QuantumAdaptiveHybridOpt", "description": "Quantum-inspired Adaptive Hybrid Optimization algorithm using a Quantum Rotation Gate update mechanism for enhanced exploration and dynamic gradient scaling for efficient exploitation.", "configspace": "", "generation": 48, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('shapes (2,2) and (5,) not aligned: 2 (dim 1) != 5 (dim 0)').", "error": "ValueError('shapes (2,2) and (5,) not aligned: 2 (dim 1) != 5 (dim 0)')", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {}, "mutation_prompt": null}
{"id": "ae00538a-4577-46b3-82d3-9d8cbff78d18", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "4d80fabb-7b6c-4996-b5ca-9cc3e85b5bbc", "solution": "import numpy as np\n\nclass EnhancedHybridOptV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Adjusted for efficiency\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.05  # Adjusted learning rate\n        self.inertia_weight = 0.6  # Modified inertia for better control\n        self.cognitive_const = 1.2  # Reduced cognitive component\n        self.social_const = 1.7  # Increased social component\n        self.memory_factor = 0.5  # New memory factor for adaptive memory\n\n    def dynamic_control_update(self, velocities, memory):\n        dynamic_factor = np.sin(np.pi * self.eval_count / self.budget)\n        return velocities * (1 - self.memory_factor) + dynamic_factor * memory\n\n    def adaptive_memory_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        memory = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities with dynamic control\n            velocities[i] = self.dynamic_control_update(velocities[i], memory[i])\n            \n            # Update velocities with Particle Swarm-like behavior\n            velocities[i] += (\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, velocities, personal_best_positions, personal_best_scores\n\n    def refined_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - np.cos(self.eval_count * np.pi / (2 * self.budget)))\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Adaptive Memory Update\n            population, velocities, personal_best_positions, personal_best_scores = self.adaptive_memory_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Refined Gradient Update on the best solution found so far\n            self.refined_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOptV2", "description": "Enhanced Metaheuristic Optimization using Adaptive Memory and Dynamic Control to balance diversification and intensification effectively.", "configspace": "", "generation": 50, "fitness": 0.24046750419845117, "feedback": "The algorithm EnhancedHybridOptV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.23.", "error": "", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.6598093684128626, 0.6553498442060515, 0.6805042025530388, 0.5749694675755228, 0.5884804546018075, 0.6771775406551317, 0.7032997701601296, 0.6362771284580016, 0.6549335097796722, 9.999999999998899e-05, 9.999999999998899e-05, 0.09857643711286124, 0.04731088550953633, 9.999999999998899e-05, 0.0872540396437409, 9.999999999998899e-05, 0.07618920175760868, 0.010767189514694464, 0.10672649589732941, 0.04943325167810175, 0.1445242240688538, 0.06201236728718795, 0.13102871521405446, 0.042896533564766304, 0.08613542655108541, 0.12025018571035939, 0.13973656151138258, 0.06482769509467834, 0.09722922602861672, 0.09421309442098846, 0.09406545459015103, 0.08296399429714307, 0.08048724146168518, 0.06007450133420367, 0.06146216535983384, 0.08031822135126876, 0.9939623053265197, 0.9951689510963776, 0.9951476758719883, 0.809974960326485, 0.8408197133728615, 0.8988388295531966, 0.9933467101533815, 0.9940969691651723, 0.9856881217538099, 0.36065890757206187, 0.359578767252826, 0.15865192367137548, 0.30787043570430284, 0.16004694950602716, 0.15901211644144664, 0.3507432348717122, 0.31175413122289597, 0.3672135211177152, 0.1722740631833276, 0.22578440291027735, 0.21657216134294222, 0.2230132745190856, 0.21273394808785773, 0.19255005050662843, 0.12639413006557976, 0.13165745627083725, 0.8833093316579961, 0.25005209384966554, 0.1360173266560576, 0.15624828063257556, 0.14097983869446817, 0.14263761637787997, 0.15839131917971538, 0.31450518117516, 0.2341820032231391, 0.24501896347096774, 0.18399848483826442, 0.15890305459418885, 0.22622993365026367, 0.21195663923136543, 0.17923725453966777, 0.13552432872112263, 0.15711581942017805, 0.2137959810038189, 0.11573767879522656, 9.999999999998899e-05, 9.999999999998899e-05, 0.0017264837575629022, 0.08782765357858624, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07803208508722692, 0.14357091201498773, 0.022352313644159016, 0.07251592218064884, 0.08097685047773662, 0.12927988725315442, 0.09618897622116729, 0.06557329730704786, 0.05811894199883261, 0.03606977504649145, 0.0482424769520039, 0.07856168691598031, 0.15361491973923147, 0.0875215638978929, 0.07122675588290639, 0.08015278496586509, 0.08557452800461851, 0.07143541333682768, 0.11724363051868736, 0.08830848796120394, 0.1328676732909977, 0.0991406856698559, 0.006955048886188475, 0.1184536664159932, 0.1330274057518943, 0.08343216353457994, 0.22833012651070328, 0.08410029104977113, 0.5309680435175335, 0.49010319583649475, 0.47518333455096406, 0.4540127341656247, 0.48281384493812707, 0.4283093117231671, 0.5020585470031291, 0.4590238396338766, 0.4825571987440779, 0.07502759305656781, 0.0968256911716433, 0.08137335624727038, 0.11837043172653416, 0.09667928001282433, 0.10025164450235757, 0.19097380625883909, 0.14325404460009028, 0.10646286870684962, 0.27002303980112363, 0.14877620183615836, 0.18550199396485145, 0.31043491589964256, 0.2674449471992574, 0.1882209552621127, 0.19982693145674935, 0.2188365907634564, 0.14392251368582198, 0.24985428033081214, 0.30190230834774534, 0.35598809947281074, 0.26927190656001443, 0.3073324471942456, 0.23563437408139254, 0.20706866013227576, 0.25077623512737757, 0.21897977517345069, 0.19428560795807703, 0.15949876042210198, 0.3077294627096965, 0.21940971806732446, 0.1880322419430671, 0.20109231506939795, 0.2286523715058082, 0.2687621417373607, 0.18172688348248123, 0.22027573459054905, 0.18281906490388256, 0.2137509934634605, 0.2122617762522273, 0.1895687737786942, 0.23168539490297158, 0.2483624975055433, 0.19243707199254756, 0.2078012562758238, 0.1975258797293502, 0.18230099292210766, 0.1866683946007497, 0.17549051131580273, 0.23176786601835986, 0.19998519402110515, 0.1818609154225731, 0.1872523628352737, 0.17616726490614232, 0.8935910526454584, 0.12716409562602315, 0.15464510866307324, 0.943788490086272, 0.20232996344426457, 0.20135697369181538, 0.1430909585829062, 0.1707514998433296, 0.9371935836017647, 0.39620099837224454, 0.21369416363973537, 0.7861277618137328, 0.20524000510791218, 0.16860221030888856, 0.15563326572079372, 0.16357381152751427, 0.17075033787248872, 0.899209348807639, 0.20320426079077147, 0.21252848999082585, 0.21029318421157095, 0.19640929165010934, 0.19519955943843625, 0.2496628134565666, 0.22205718102669858, 0.1924552946535154, 0.18389404560239264, 0.08083748241786093, 0.0828181407140115, 0.08890183167034138, 0.08976302404150316, 0.0985813873718665, 0.08417886435568289, 0.08197240526182181, 0.06013489207272127, 0.08582709397158617]}, "mutation_prompt": null}
{"id": "95c69296-69da-4690-af23-fdb632c9d55f", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "ad3f92c0-6acf-4456-b2f1-a0bb12db52f4", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n        self.temperature = 1.0  # Simulated annealing component\n\n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def simulated_annealing_update(self, solution, fitness):\n        perturbation = np.random.uniform(-1.0, 1.0, self.dim)\n        step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        proposal_solution = np.clip(solution + step_size * perturbation, self.lower_bound, self.upper_bound)\n        proposal_fitness = fitness(proposal_solution)\n        self.eval_count += 1\n\n        if proposal_fitness < self.best_fitness or np.random.rand() < np.exp((self.best_fitness - proposal_fitness) / self.temperature):\n            self.best_fitness = proposal_fitness\n            self.best_solution = proposal_solution\n\n        # Update temperature\n        self.temperature *= 0.99\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            self.simulated_annealing_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms using Particle Swarm Dynamics and a Novel Simulated Annealing-inspired Update for improved convergence by balancing exploration and exploitation.", "configspace": "", "generation": 52, "fitness": 0.32946582516244916, "feedback": "The algorithm EnhancedHybridOpt got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.25.", "error": "", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.609640917879259, 0.6086243970284828, 0.610491178440578, 0.5952601572962302, 0.6091151161160411, 0.6168696164983767, 0.6212570987320865, 0.6143714515490497, 0.5748744321037046, 0.32842363108861305, 0.03797371616484635, 0.3920209080045868, 0.29120201546515767, 0.3961881129524345, 0.5584129673464775, 0.03675619571709998, 0.053251314120948745, 0.052868945946665025, 0.10972969886765571, 0.093762491965667, 0.12672564399673625, 0.09420417978840412, 0.07795200860663554, 0.0974883943955982, 0.07458527786342661, 0.0882977856393321, 0.09323373483085029, 0.08534301152354196, 0.07880708374608403, 0.04764304971389266, 0.1010454689915361, 0.07972515828882953, 0.054403144938854675, 0.07215776999734103, 0.11604758054227438, 0.053906408379549076, 0.9786731845202343, 0.9094079809966698, 0.9930740360392971, 0.8759948865087955, 0.9895108245750818, 0.9372568574942481, 0.9933033214389472, 0.9886413877789293, 0.9909125550031948, 0.6646733724969446, 0.6780515111709517, 0.6609406976088592, 0.6313286341283366, 0.6157594666188765, 0.6076306882274563, 0.6453856506207702, 0.6509475653217618, 0.5861936879334877, 0.5407400310423229, 0.8661731586092618, 0.20948920248289216, 0.4917846256930286, 0.88086179572921, 0.20953653269566497, 0.1395444258928512, 0.19483106355911084, 0.5084026729901987, 0.7016338582953745, 0.33757143933825196, 0.5848037950341354, 0.357064035435645, 0.1340364657622033, 0.1265941764175479, 0.7216799232324191, 0.7128110514554143, 0.6048720177779406, 0.6861824549135531, 0.5989752784540685, 0.13492568532023852, 0.13527456224657675, 0.6034061345216253, 0.6106258177097537, 0.5270449057143584, 0.6028630954913985, 0.1310645036284308, 0.26434503105696683, 0.2565184677888057, 0.05502125221792609, 0.0006684340970377622, 0.19596625568305204, 0.33890924685327595, 0.23280001415294405, 0.3835368716417009, 0.5210362710917056, 0.35278316542089927, 0.2743096620401859, 0.34649025857094085, 0.3126579462375346, 0.3243517007397727, 0.0352783513602839, 0.17728103343533785, 0.4520034080259945, 0.5054635028248105, 0.045756004607288014, 0.03436240400006185, 0.1119218764235217, 0.27994073038549283, 0.3074473914395226, 0.3486630938471038, 0.22351431618446194, 0.15384168193387338, 0.31303458499480163, 0.11726159276051462, 0.22192886072645512, 0.1202077028916918, 0.20933976753841166, 0.16596603614306282, 0.29706748696819407, 0.16662723649326017, 0.2708503316246672, 0.08143587885823467, 0.5237341591364135, 0.5223688437159559, 0.536551306230359, 0.5106168960855455, 0.5275713562676805, 0.5022119406319443, 0.5399631220660104, 0.524419426318433, 0.5357352786036249, 0.09619095871602845, 0.08089449641916124, 0.06889262004824792, 0.1315643590975476, 0.10800755807034002, 0.11167114872574457, 0.11440213764249496, 0.1607798662554547, 0.06416137655633158, 0.21835104139863937, 0.2875662976870037, 0.24067116005071432, 0.29265017459755027, 0.17581775555999835, 0.5347199872645452, 0.3161165139196622, 0.22360683008386728, 0.20294669382130037, 0.34814863405735097, 0.36679829854969825, 0.3740453371276573, 0.34866504327069325, 0.2716878569174772, 0.3458776622264855, 0.35880568757391906, 0.37128372810271837, 0.2661153040671834, 0.19747398314934217, 0.24298940360756183, 0.34969491973587163, 0.19541030036568652, 0.24330610433050737, 0.2684740087798234, 0.25704758104144876, 0.3044292422753788, 0.27423052222977407, 0.24145076432699553, 0.19734816445919634, 0.1865009183593601, 0.23512588741299645, 0.2158192635114642, 0.2502001028718319, 0.22508779623069297, 0.2826859672359311, 0.240168108601023, 0.240973766300854, 0.21726005056671016, 0.19351406205091737, 0.20003867919441853, 0.198664280101979, 0.17547118949353613, 0.18233433335996307, 0.24672828544144854, 0.24995968909044786, 0.18756649339197085, 0.16710873746251853, 0.1545622549135558, 0.9034980848617185, 0.2016206314915202, 0.20145560909670734, 0.14298096122083948, 0.1643720245742628, 0.9068573532496355, 0.8755263120252506, 0.21381539731178556, 0.07360432295764863, 0.7947103546066745, 0.1696574306076034, 0.15381496741429423, 0.802559894768651, 0.21140203292386983, 0.16503870556966593, 0.24507427827456418, 0.20127693360474097, 0.21392811316920257, 0.20352223291038996, 0.20276743945993903, 0.19739777928041913, 0.22581253846701244, 0.23254384608222678, 0.20258525208918932, 0.05965407868332151, 0.11559624438623628, 0.09152230150521878, 0.09198670286474775, 0.0902962129457221, 0.08390348602446907, 0.09236292063345886, 0.0954788689110797, 0.1110322728470059]}, "mutation_prompt": null}
{"id": "2ca2ffbb-a44b-4beb-89c9-762061b91d44", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "ff0a4ce6-e096-4547-95be-e57fd0b30844", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "7be9a6d3-4662-4716-945c-8af289e01cc7", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "860c5d08-79a3-4066-8504-8b023456cd6b", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "65bcd3cb-6699-4f14-b52f-9d94c7c6084d", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "4d27b9ec-1841-4ff9-93c9-20c1ac728e7f", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "cf5846f0-1e66-495f-b27d-0289e3e1837f", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "1806941e-cd42-456d-9926-420a0076a321", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "c5b4521e-0da5-4e0e-bb72-4e524428b2c6", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "30521375-c9fd-489f-b09b-8dd4bb4c931c", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  \n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.initial_learning_rate = 0.1\n        self.inertia_weight_max = 0.9\n        self.inertia_weight_min = 0.4  \n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n        self.learning_rate = self.initial_learning_rate\n\n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n        inertia_weight = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (self.eval_count / self.budget)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            new_velocities[i] = (\n                inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.normal(0.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n        self.learning_rate *= 0.99  \n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim)) * ((1 + np.random.normal(0, 0.1, (self.population_size, self.dim))))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Stochastic Gradient-based Hybrid Optimization leveraging adaptive learning rates, low-discrepancy sequences for initialization, and dynamic inertia weight for improved balance between exploration and exploitation.", "configspace": "", "generation": 62, "fitness": 0.3105586332575811, "feedback": "The algorithm EnhancedHybridOpt got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.25.", "error": "", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.7819422466845225, 0.7866712920103801, 0.795282271863075, 0.7829002986853251, 0.7792282470377668, 0.791895710119224, 0.7548005168783591, 0.7661297519453903, 0.7780635853855334, 0.09070505612604263, 0.027825291200150426, 0.057437984464553504, 0.2523664481529332, 0.335391498002401, 0.3155928563727469, 0.4638417066536563, 0.26082129001168886, 0.4204165105916453, 0.14990675159047007, 0.09170216509360585, 0.056470081916390136, 0.08988996530874971, 0.10848253899384386, 0.1283467554296822, 0.08196120583751276, 0.11920473010955579, 0.12552745568688528, 0.0535264338602901, 0.1508346161586136, 0.09254104664786755, 0.09825516127666667, 0.08351193263228573, 0.06106895356115494, 0.11194506170769636, 0.06570692412247281, 0.10573416938526914, 0.9880049781901735, 0.9922034389392742, 0.9917778111751547, 0.9521710161968825, 0.9889306863876379, 0.9802185752087428, 0.9932339414044972, 0.9876497660167733, 0.9900826940710215, 0.5558876176022136, 0.5681239035161025, 0.5550752405985137, 0.5063317096945649, 0.4893714615035808, 0.5508096928392595, 0.5782723731444959, 0.6045028487259251, 0.49335822477731606, 0.22691333745712006, 0.7016659901728053, 0.22462257579675915, 0.19532495922705861, 0.1943203589928486, 0.2703510480992787, 0.1262099178560011, 0.2325048680854659, 0.6542841687541736, 0.39195355744818206, 0.10958819593562952, 0.4139965499926639, 0.4134421991766709, 0.5276500212065034, 0.1114036943295389, 0.49181511823397395, 0.13218688550337843, 0.5528239260086723, 0.6098515415036551, 0.5193877417053054, 0.5314073070245718, 0.527604036883391, 0.522783616136224, 0.5703391407062558, 0.5212755502232707, 0.4665046289351855, 0.4926201248890464, 0.34270689309865177, 0.05705945095327003, 0.33448739080231493, 0.0005638265981541268, 0.16944373054432094, 0.26127351041600777, 0.3268061517839448, 0.3649079035641234, 0.3888547017345272, 0.3233660785999042, 0.3552598266537772, 0.1453776870382617, 0.2851615649373255, 0.03420519769633468, 0.0927356326656591, 0.33335185300483783, 0.09531521059241255, 0.31444669465227104, 0.07207023816976021, 0.06198463387632369, 0.039226229274432756, 0.11316243025439487, 0.06530979734221598, 0.16529199053071075, 0.08856106509858164, 0.10360341471002665, 0.10757175823666754, 0.15813066494990524, 0.22735531104165707, 0.14488589153428233, 0.12740424562353236, 0.16195957346441192, 0.13459388268916916, 0.07717589822703974, 0.05179761812892192, 0.08109163964753696, 0.6539537135583453, 0.6242177527144497, 0.6604576559889032, 0.6425995787848164, 0.64933462157197, 0.6015877479420175, 0.6102269934635156, 0.6458917672061397, 0.619605948750129, 0.11608884249957152, 0.07390060390894682, 0.10270186383110391, 0.15301483762336898, 0.06976781345395122, 0.08904887837914599, 0.1262123208281819, 0.1083027404460668, 0.06261958334560169, 0.1652426939833882, 0.1710787874231271, 0.14695774403154716, 0.36690554690381927, 0.43379503367190564, 0.20833467455511356, 0.21334772230086396, 0.21006685320943974, 0.20636039080039292, 0.25411494557214565, 0.3320484089416835, 0.41241420456408984, 0.25020875598850734, 0.2112272065121341, 0.31245059604567804, 0.27767528206006775, 0.32153401895925116, 0.3542098473676141, 0.16396209591453592, 0.20281312614943814, 0.2896023403632797, 0.20171224675254518, 0.12132422936839737, 0.31607282718886576, 0.16651111884061376, 0.2969446350548899, 0.2663575661058353, 0.24260556106292042, 0.20175958710905428, 0.22638453366793532, 0.19315970225884382, 0.23992275025388277, 0.1859970382009627, 0.23757837344177402, 0.18968982177985383, 0.18851375018658412, 0.1783755922083754, 0.1991528543927661, 0.19038843981522457, 0.20126029897084585, 0.18744976382601786, 0.17034977292677866, 0.18062524641436362, 0.18902252976492306, 0.17354932653320543, 0.16397842776256732, 0.18838302911620153, 0.1675965675922907, 0.13205346767650317, 0.20090803887410935, 0.20059182093524008, 0.14320096379507763, 0.1699078719827879, 0.8498550945101943, 0.8109035629685863, 0.6593203331609961, 0.199834687804339, 0.2084769302739451, 0.16783492690193147, 0.20963029824522927, 0.1536339967792314, 0.7863632746474984, 0.1666811181261595, 0.1863291205180465, 0.20924183121962647, 0.22680933513918067, 0.19927021381809074, 0.21537986399025355, 0.19525578984236847, 0.2045213174137921, 0.20861489866746674, 0.20122934498415646, 0.14422028433324008, 0.09134727277929411, 0.09540429604621514, 0.08339561795970862, 0.08229994352930103, 0.10274811807981243, 0.08904930396458821, 0.09075042427367641, 0.09578715027026952]}, "mutation_prompt": null}
{"id": "2955fb9a-72e2-40fe-921e-6ec4aa991542", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "1eca7ecd-4940-4ee4-9ae8-e28c2343f625", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "16009a5f-46ad-4ac2-b711-551884f4440d", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "9427c2a2-8ea6-4393-a577-a735ebfb8e3c", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "6f2b5f9d-c480-4752-b616-9380255831ea", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "7a06ec12-8b07-4920-8ad4-f4e4003baaac", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "a899f638-1121-4e62-a018-3a145e16610e", "solution": "import numpy as np\n\nclass AdaptiveSwarmEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.05  # Reduced learning rate for finer adjustments\n        self.inertia_weight_max = 0.9  # Dynamic inertia weight\n        self.inertia_weight_min = 0.4\n        self.cognitive_const = 2.0  # Increased cognitive component\n        self.social_const = 2.0  # Increased social component\n        self.memory_factor = 0.3  # Adding memory factor for gradient correction\n\n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        inertia_weight = self.inertia_weight_max - ((self.inertia_weight_max - self.inertia_weight_min) * (self.eval_count / self.budget))\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities with dynamic inertia\n            new_velocities[i] = (\n                inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        memory_adjustment = self.memory_factor * gradient_direction\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * (gradient_direction + memory_adjustment), self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "AdaptiveSwarmEvolution", "description": "Adaptive Swarm Evolution (ASE) integrates a dynamic inertia weight with a memory-based gradient correction to enhance convergence speed and accuracy in diverse optimization landscapes.", "configspace": "", "generation": 69, "fitness": 0.2719822537962723, "feedback": "The algorithm AdaptiveSwarmEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.23.", "error": "", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.6860265546089006, 0.7165050709887943, 0.717746382623097, 0.726931111222951, 0.7081790984356213, 0.7185157634681967, 0.6994252290935326, 0.6943136523677126, 0.6902196215492473, 0.023964286078778207, 0.17850253473071298, 0.23956544147337322, 0.20329792501340038, 0.3163054563485249, 0.015925939148371815, 0.03238734916043229, 0.25806966258926556, 0.0308579275049502, 0.10110208571909174, 0.05105103118409682, 0.11922373112917761, 0.08936203269481835, 0.09926650953635507, 0.11261735082981505, 0.08913026430910109, 0.13864999626036245, 0.13156328136383677, 0.09754351236751391, 0.10083967183272946, 0.1159615319665076, 0.10572214656562406, 0.04029541415293625, 0.05936167998065378, 0.13471310832702077, 0.1004910185636152, 0.07251738214961811, 0.986634749471615, 0.8963362956888747, 0.9939168611001645, 0.9164938918885442, 0.992111300318357, 0.8622873391765571, 0.9946377746205446, 0.9843119735350986, 0.9925909473801804, 0.420861517913505, 0.38829306288270393, 0.318833376187612, 0.4002335789642121, 0.36728748657908483, 0.3547620577642172, 0.3740938074171384, 0.4021372852773717, 0.33057427413670704, 0.644107836728687, 0.17177369690826105, 0.34997589575582677, 0.1815294257400093, 0.6983112752499829, 0.20933256694212388, 0.2318884417569802, 0.5673284831906856, 0.18486495698235672, 0.3422853643565412, 0.3401722643454598, 0.22954284602106168, 0.11176545803309068, 0.1219777432255329, 0.24249287056342306, 0.4084827107169684, 0.46906495587102004, 0.3556117366813256, 0.5013554791299121, 0.27401431331023096, 0.43783386861206175, 0.34662850791948596, 0.2749762469347411, 0.2378359818623813, 0.43716599351784025, 0.12409102912431769, 0.11854093988460679, 9.999999999998899e-05, 0.04462159576083413, 0.13608893891462903, 0.0004390587705547233, 0.0011846339340987333, 0.07388804939898364, 0.2213919972550884, 0.292893940134201, 0.022007392836272954, 0.07941292599187777, 0.11145552065166175, 0.1740585264572504, 0.38375888496023947, 0.0001816891725604508, 0.015380066324819919, 0.04181240046179968, 0.13570829779487836, 0.09622958035337781, 0.07243107295099616, 0.1446797736386365, 0.07533032167794063, 0.16737011167176874, 0.12615796838908777, 0.09800553078191476, 0.07379300041681403, 0.08996457199117192, 0.11079065178807612, 0.19359460565392683, 0.13122762512030262, 0.11302370509785908, 0.1444163494658407, 0.20776117303464303, 0.09595867556416837, 0.1423414219543282, 0.09333489722423716, 0.07732213298048063, 0.5599303926672582, 0.536810343913657, 0.5386575974154197, 0.5505297406096032, 0.5805623722464901, 0.49636896151396837, 0.6292882465592206, 0.5756138103704933, 0.5526156575412922, 0.06349774364191507, 0.07341832294916206, 0.06053101238927305, 0.08869174929092571, 0.09372505167338874, 0.12870500240825644, 0.09081101268493907, 0.1250188509868001, 0.11566676687419897, 0.24534440690627257, 0.18210638350288477, 0.20607093200726545, 0.23480610465306295, 0.26897015462206264, 0.2664407909696842, 0.3615423280472292, 0.1650553126011084, 0.20240063272094744, 0.3491416944275261, 0.2835680860005967, 0.32932775884903476, 0.3098447729455521, 0.3458725648196337, 0.2621086720087462, 0.31303295247877916, 0.30758176289426253, 0.27163431431250606, 0.18826670231190534, 0.2665595860881629, 0.20465821907400472, 0.29136783228686347, 0.20419509799893132, 0.1817487039935386, 0.20910570033544362, 0.2534386412300421, 0.2209601394934596, 0.2351926296372866, 0.19113998198231452, 0.19384881850141245, 0.2194837113266862, 0.2015643778995907, 0.22186668100557394, 0.22804018815296279, 0.2530058771592878, 0.20522432667424562, 0.18163038700531664, 0.18354717941972754, 0.2256185154439463, 0.19846635005688995, 0.1716533543276968, 0.1922846334080267, 0.18726309079751458, 0.23824192666244282, 0.18014712940379418, 0.18842156221739126, 0.16964879168107216, 0.15421987278444593, 0.8592427918320201, 0.2003181586999323, 0.19731120623472664, 0.1419393668744784, 0.16188003928880113, 0.7924379490102066, 0.7451567887263209, 0.21108593710041146, 0.5786589259066471, 0.16540425809649262, 0.3647149592567521, 0.1508835941814567, 0.21081438247404582, 0.2089651885894337, 0.16539720590603935, 0.20393753903248246, 0.1846113515366865, 0.1969778524635899, 0.1985066874259903, 0.19091572931325396, 0.19917239091523387, 0.2032983047820327, 0.19952237227977243, 0.20903279850793588, 0.09372106865380414, 0.07825082722219301, 0.08078014744187445, 0.09137983119250748, 0.0825718131617601, 0.09104617301600881, 0.09673717130359205, 0.0946976464871504, 0.09907778063631756]}, "mutation_prompt": null}
{"id": "9baa1cf5-4b7e-440c-9a5f-0112c7d1165a", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "ccde6dd1-34db-4435-a6a1-a4d7c92ee3c8", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "4e612045-7d03-425a-8ab4-2ceb8bcc889d", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "d91c290f-8da4-424b-95c0-7083f5690366", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "1d79508c-44fc-4032-bbe7-987e3a40c58b", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "842f934b-32af-483d-ac3a-21e33cdd97b8", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "cf349059-7511-4fc8-adc0-a1bac2e5537e", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "e53d0735-f8ff-40b4-8935-eb42311a5bc7", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "6d4a8278-3183-4211-b41c-7a6381e5d189", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "282374f1-d4ac-4573-826f-9c9904251a56", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "95711a4f-ab45-4204-ae87-f7b7bfc48ecc", "solution": "import numpy as np\n\nclass EnhancedDynamicHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim  # Increased for better exploration\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.05  # Adjusted learning rate for adaptive cooling\n        self.inertia_weight = 0.8  # Dynamic inertia inspired by PSO\n        self.cognitive_const = 1.7  # Enhanced cognitive component\n        self.social_const = 1.3  # Reduced social component for stability\n    \n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions with Levy flight perturbation\n            perturbation = self.levy_flight()\n            new_population[i] = np.clip(population[i] + new_velocities[i] + perturbation, self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * np.exp(-self.eval_count / self.budget)  # Adaptive cooling\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update with Levy Flight\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update with cooling\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedDynamicHybridOpt", "description": "Enhanced Dynamic Hybrid Optimization with Adaptive Cooling Mechanism and Stochastic Levy Flight Perturbations for diversified exploration and precise convergence.", "configspace": "", "generation": 80, "fitness": 0.24058337042585198, "feedback": "The algorithm EnhancedDynamicHybridOpt got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.22.", "error": "", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.5397491631101077, 0.5633887527896702, 0.5432157054559361, 0.5425359078678633, 0.5287661364815692, 0.5251902656595085, 0.535246377120195, 0.5618020162163644, 0.5395385456456303, 0.028819354498141325, 0.032719354570849846, 0.026404274916468573, 0.07096621357707422, 0.03508751820019407, 0.03932935697933648, 0.08812960877402509, 0.06023705745431074, 0.05025631272169362, 0.09735040480955814, 0.09505937884811066, 0.1129819016245649, 0.1290511693359565, 0.11386599774490447, 0.08780594664671826, 0.15158771189486453, 0.10611255191095692, 0.07769821819685352, 0.08434835845506528, 0.08804904101238387, 0.07329630887208693, 0.07820405502638861, 0.052897916662849265, 0.07996470190385607, 0.08886800801700845, 0.1115856680314824, 0.08204358861878258, 0.9852862038136949, 0.902928777818526, 0.9883848289038788, 0.8685732296892607, 0.9808586009795072, 0.8657327560603472, 0.9878276812464395, 0.990538861749192, 0.9891260882801549, 0.3594656375926668, 0.3528451462144617, 0.3477497171908459, 0.3329630976190999, 0.3570440053192844, 0.340414264568065, 0.38652720643746186, 0.3469691145817011, 0.33078051662120356, 0.5582557882568735, 0.7563085990733228, 0.2343852627803158, 0.19399337318541887, 0.269044713286965, 0.20719211738549392, 0.3261628557090229, 0.23057606968257882, 0.8576875304391863, 0.20551849668811562, 0.10342785458287285, 0.22147484189891542, 0.17791209256105645, 0.12819978959534672, 0.10761499527067553, 0.190248272967519, 0.13347153549411395, 0.2460851212214602, 0.18103204963475206, 0.13041516995052205, 0.127092085497864, 0.19164695660153586, 0.19775394562296278, 0.13386105971761986, 0.20272259814338078, 0.2029912000856945, 0.19926531383538526, 9.999999999998899e-05, 0.03629198281994028, 0.026649633548551765, 0.009293411726409628, 0.010409504602615582, 9.999999999998899e-05, 0.0227201657380961, 0.019082967949055618, 0.002446185701865611, 0.16261682748247897, 0.10338476533086227, 0.10424799154308073, 0.1091816345197667, 0.14798060912702882, 0.029320897457090767, 0.05873024455974318, 0.059850048688475765, 0.12654284421224982, 0.0021029826962239984, 0.006731896938091841, 0.011161247831097731, 0.036053599550233795, 0.008853146127011824, 0.012209146227149192, 0.026597220991005033, 0.050171078361606836, 0.04540467778066681, 0.13082360604391507, 0.10436408277627784, 0.13993868549235033, 0.13892265230901335, 0.0772215104136772, 0.10410501258796989, 0.07760582709763197, 0.1336001793642052, 0.07534398729091696, 0.4595511932499997, 0.47298932768364865, 0.4750475856448497, 0.4831857444472193, 0.4648956945655768, 0.4865466814191223, 0.4883800791428612, 0.4447475601516905, 0.4670047041088502, 0.14269841502381875, 0.11006505932570765, 0.10542023271887979, 0.0913748863674737, 0.07471703935880958, 0.0866780958452571, 0.0858915314491624, 0.13049029183466587, 0.09661188243064645, 0.15566667850506988, 0.2263162858647696, 0.20171621004873574, 0.29655842559842993, 0.32665790479247436, 0.3285789051329795, 0.3622520056645081, 0.19741863041187435, 0.2058906166696879, 0.19866821004469926, 0.2812152932261093, 0.3339126840780712, 0.24551045447457032, 0.23361689358411164, 0.27373750548978126, 0.28753236092592316, 0.26812356155834194, 0.266044597656213, 0.18603118458851886, 0.17220290486289724, 0.22289224531406449, 0.2683605674448575, 0.24675235545460228, 0.20502576286842666, 0.18767622895035352, 0.2523806337656259, 0.19163119092353964, 0.20236442825641499, 0.22327964935579359, 0.23377974683862857, 0.20786751086934763, 0.20849355985386764, 0.24617324140251862, 0.21378137256036112, 0.21567309908922783, 0.20340637590150767, 0.19243844200799687, 0.18243428872305345, 0.18282449569917347, 0.18958403958187175, 0.2122732880934982, 0.19195125268032176, 0.1928926518687062, 0.22618385405260788, 0.20746302602553224, 0.16294827429482206, 0.1892152558285517, 0.18897435660256234, 0.8322837302761616, 0.2008309200341064, 0.19971395220255783, 0.14321590873857093, 0.1657809835267906, 0.20981922934067165, 0.7814467866411277, 0.21101883111821496, 0.6388696156129432, 0.6462952482096915, 0.16908210140172975, 0.14899944999510972, 0.6557419019203099, 0.10533438022033204, 0.6641002295824459, 0.1745864479911815, 0.18738477762496608, 0.17642633949198028, 0.18183982894684214, 0.18353664340743414, 0.2114075764093557, 0.18750275652442738, 0.1965829693956368, 0.18223792204174438, 0.08442806902360356, 0.07760817631042882, 0.08485189836828644, 0.07478086663308292, 0.08608637775640293, 0.09820931873738104, 0.11299558155055378, 0.08587975464846276, 0.08379239765521052]}, "mutation_prompt": null}
{"id": "a25d84c3-758c-48dc-876e-e9f40192ba67", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "9ef6a343-9f12-4212-a40b-8ef34a480a7c", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "32591a9f-4553-4247-87df-db46f8b9d572", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "b8bff8da-6877-4810-8c71-e3f3d6a77f2d", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "5e97ba61-5ff6-497f-9160-dfc0e3a124ad", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "be6ce9b1-d638-40d1-a615-c2c9a481cd27", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "629aba2b-bc14-4dd1-850a-0b40b186c822", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "8eab9505-3c0f-4c63-9718-c7afead1d6f0", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "1bee680e-584c-4137-8072-a84b76aee661", "solution": "import numpy as np\n\nclass EnhancedHybridOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Optimized for balance\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1  # Enhanced learning rate\n        self.inertia_weight = 0.7  # PSO-inspired inertia\n        self.cognitive_const = 1.5  # PSO cognitive component\n        self.social_const = 1.5  # PSO social component\n    \n    def particle_swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_gradient_update(self, solution, fitness):\n        gradient_direction = np.random.uniform(-1.0, 1.0, self.dim)\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        adjusted_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n        adjusted_fitness = fitness(adjusted_solution)\n        self.eval_count += 1\n\n        if adjusted_fitness < self.best_fitness:\n            self.best_fitness = adjusted_fitness\n            self.best_solution = adjusted_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(self.population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Particle Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.particle_swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Gradient Update on the best solution found so far\n            self.adaptive_gradient_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedHybridOpt", "description": "Enhanced Hybrid Optimization with Adaptive Mechanisms incorporating Particle Swarm Dynamics and a Novel Gradient-based Update for improved balance between exploration and exploitation.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8671053012260932, 0.8552526013166108, 0.8569903825488138, 0.8430209336826623, 0.8581459181171747, 0.8531277765568055, 0.8613634794981547, 0.8717902344963996, 0.868232391193496, 0.49106493427930753, 0.31775433095470695, 0.019566298344984023, 0.4498584888898004, 0.4180465597659271, 0.6087394448495936, 0.5357408586966895, 0.4912849783379547, 0.5414110840675133, 0.11015709680816088, 0.11782096939143427, 0.08998389226604908, 0.08239485576704753, 0.13946057362560438, 0.08489750427244458, 0.07461378199021529, 0.09252890450425844, 0.0894683084446457, 0.07714703900235287, 0.10076105331411422, 0.08653785996425778, 0.09113460864384015, 0.12197105643752093, 0.09879539252199321, 0.09545063900983841, 0.09624179230107688, 0.11493456607972508, 0.9829664674203573, 0.9056271628902832, 0.9930740360392971, 0.929439692535545, 0.9904212966083132, 0.8784633230511248, 0.9933033214389472, 0.986675734132886, 0.9909125550031948, 0.6481020744486388, 0.6828391547815589, 0.4980752154431668, 0.6484835510494306, 0.6060087407774419, 0.5737434883620738, 0.6161189228834522, 0.6416417707565034, 0.6672778952776699, 0.24344748514894277, 0.7473938233846384, 0.15132423648697313, 0.19575095470725123, 0.38235959005559017, 0.20819610809580902, 0.10370319464230904, 0.23533551263860386, 0.1750449086964878, 0.7109376757225989, 0.12629888710612303, 0.6721992789333331, 0.5604268562913977, 0.13097907249502894, 0.13185752886990665, 0.6130518293941861, 0.7216015533008007, 0.5584863134500947, 0.6508031030749377, 0.1347709044048162, 0.1363841948456529, 0.13587929262147513, 0.13276671351664138, 0.13569347990573877, 0.6291851234334898, 0.6004957722924713, 0.13229197759453037, 0.001172231466854634, 0.46731127234532877, 0.422560627906992, 0.0009615116616281671, 0.15024734469235268, 0.20953914776297555, 0.44667867040645715, 0.37318111635064855, 0.43887147099374346, 0.4360487818843791, 0.31699986763125465, 0.39636245020515726, 0.2943202299012081, 0.1881595258244576, 0.2945599715198285, 0.08693170210868562, 0.33895663793212494, 0.21432169932855671, 0.22518736630357494, 0.07474274820506666, 0.13517402241955223, 0.3262229487247247, 0.32414775517060956, 0.4027274530377284, 0.19110986878190706, 0.27191240336573574, 0.2962761525164048, 0.10004320313880344, 0.14513645358955996, 0.11958174277837696, 0.006556384661558279, 0.16038808372016977, 0.10397898572898978, 0.24553326276306509, 0.4819326165532114, 0.08231277120104985, 0.741102082898998, 0.7079393183730852, 0.7130111710949834, 0.6752094100831445, 0.7215437170500671, 0.7610234010544489, 0.6964979929269164, 0.7575554705228362, 0.7425230861449781, 0.07809961065735183, 0.07697201194413306, 0.07801013585118777, 0.06634336558721332, 0.04925834799157491, 0.1095174831438559, 0.0751481355752408, 0.1038660817532514, 0.10858378998124751, 0.41661623797751723, 0.27127090066155646, 0.21296767319085497, 0.2164925783903936, 0.48562838939962494, 0.20120368399480437, 0.19709988000067846, 0.1561579148104294, 0.24332600239601132, 0.2714896092648047, 0.35016882342757694, 0.2645376182978243, 0.4112377302415321, 0.24197727371524858, 0.2719661451680787, 0.4663190922036565, 0.23134362633539318, 0.41014000389968186, 0.20814455421352973, 0.3222217378285872, 0.2027846675389796, 0.1441320682877536, 0.1807867301575974, 0.27587234120050563, 0.21393606885639016, 0.3323581648330105, 0.34075231686474605, 0.3155685287146375, 0.2648547157740677, 0.21579754320086408, 0.23696646038277602, 0.21973388733395527, 0.2468317616289264, 0.27317776043305253, 0.19875912551056152, 0.2784827547258446, 0.21197949153294726, 0.16927104846506735, 0.1707712112465093, 0.1967212780357731, 0.18306320944756393, 0.1730409396819328, 0.22369783709513247, 0.20920319969229373, 0.1919964737357156, 0.18845233704543252, 0.12738546280636454, 0.15476667231117736, 0.9140701077760285, 0.20149413451960385, 0.201536847339426, 0.14291123945436413, 0.16401589310928488, 0.913767668394766, 0.8408528066076499, 0.213954767701652, 0.07362845140946361, 0.10410189483460164, 0.1694529972044605, 0.15578466031685034, 0.2129323054124066, 0.10468953264338776, 0.1668685130029791, 0.19565907496541202, 0.19015930492494582, 0.1998426771355346, 0.20254069879387848, 0.1958811140997564, 0.20968297019121485, 0.19395337887005415, 0.2142079470540994, 0.26021573030439127, 0.08749177010366971, 0.0902259234412428, 0.07190590090761029, 0.11291043769842413, 0.10024805843198059, 0.09182382452537641, 0.09334576312714926, 0.08556454500527522, 0.10678720461538582]}, "mutation_prompt": null}
{"id": "a87dd215-8dd2-4e98-8ddb-9b7c7d4df4bb", "solution": "import numpy as np\n\nclass EnhancedSwarmGradientOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, 10 * dim)  # Dynamic population sizing\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1\n        self.inertia_weight = 0.5  # Reduced inertia for quicker convergence\n        self.cognitive_const = 2.0  # Adjusted cognitive component\n        self.social_const = 2.0  # Adjusted social component\n    \n    def swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(len(population)):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_update(self, solution, fitness):\n        gradient_direction = np.random.normal(0, 1, self.dim)  # Gaussian perturbations\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        for _ in range(3):  # Multiple trial updates\n            candidate_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n            candidate_fitness = fitness(candidate_solution)\n            self.eval_count += 1\n\n            if candidate_fitness < self.best_fitness:\n                self.best_fitness = candidate_fitness\n                self.best_solution = candidate_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population_size = self.initial_population_size\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        velocities = np.zeros((population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Update on the best solution found so far\n            self.adaptive_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedSwarmGradientOpt", "description": "Enhanced Swarm-Gradient Optimization with Dynamic Population Sizing and Adaptive Update Mechanisms for Balanced Exploration and Exploitation.", "configspace": "", "generation": 90, "fitness": 0.362421915967271, "feedback": "The algorithm EnhancedSwarmGradientOpt got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.28.", "error": "", "parent_id": "c84096c0-17bc-4e18-ac73-3229c4d66bfa", "metadata": {"aucs": [0.8854105288041776, 0.8794177814810371, 0.8937062065987564, 0.8827963384025219, 0.8757450806226722, 0.887758919266219, 0.873494116403716, 0.8798563203418784, 0.8952429255881322, 0.5089909047148589, 0.4969806267843291, 0.5359446853320798, 0.6359567130854025, 0.40292067934979703, 0.6799091935316717, 0.6435166315702612, 0.6884034022451118, 0.6572545804098411, 0.08186244722061042, 0.07195772166741832, 0.11756712855706974, 0.1178863852814317, 0.08448436129970183, 0.07511639891018274, 0.08657042463021358, 0.11903169733856067, 0.12470741629497983, 0.10296653791264287, 0.09243753031734048, 0.12011566189592449, 0.09737028990998187, 0.0951835316602212, 0.044672524637929034, 0.11680650505337054, 0.0918557325623397, 0.06374944954851214, 0.9847384852030742, 0.9605171639268267, 0.9939168611001645, 0.9499844409542871, 0.992111300318357, 0.9454331158007493, 0.9946377746205446, 0.9844771079270034, 0.9925909473801804, 0.6354335171638059, 0.46836632969750125, 0.5682419500809521, 0.42386111375649194, 0.5825040945605872, 0.5209930683392665, 0.33959930275599537, 0.5854979673798766, 0.7045663030766955, 0.25332753777626127, 0.21059288469975013, 0.21633018431655548, 0.2073835447747152, 0.19264335727383664, 0.21412351568461196, 0.177360438153501, 0.17631819378000202, 0.17461884312011844, 0.13391486884458959, 0.13313064298994504, 0.1305210296745417, 0.5721203186857072, 0.5464377538193956, 0.4389549019568538, 0.7263130114672249, 0.5815816186152449, 0.13472047721531888, 0.7882835842307953, 0.7112854125662198, 0.7633392600068252, 0.5960747964734356, 0.1330606678074091, 0.1340235375773252, 0.6786845617924688, 0.7797395844971702, 0.13158696142974058, 0.46975419699148446, 0.6179934888132239, 0.05146963450959552, 0.47813866295031837, 0.5484946352236076, 0.47013300017604365, 0.42802022496299763, 0.6425043782540554, 0.5405244924284592, 0.08605317601044205, 0.5699558763662805, 0.6585016840991822, 0.43979917731930496, 0.10361012404630787, 0.15400928354720722, 0.07116138805293049, 0.5370370496057975, 0.5125666505180002, 0.25739148440731174, 0.35585677768835344, 0.1480899117947604, 0.573577348976858, 0.07874570083259025, 0.3997287078479145, 0.09829290591936957, 0.218137059378679, 0.3261663391960615, 0.19156570138110907, 0.11399166012001039, 0.1370966596056683, 0.0941786583603802, 0.3294321052816349, 0.4463536538326973, 0.11542756780926988, 0.11058474490193637, 0.08313575112166649, 0.7954921003252177, 0.7813678432635888, 0.8370348633153718, 0.7767647249312547, 0.798719553044893, 0.7745942002447156, 0.781348265611792, 0.795828541137361, 0.8098345306724717, 0.12457639933059128, 0.05277251331684585, 0.051907487342345626, 0.05150185753612546, 0.10996542009483279, 0.1180078835847369, 0.14412547143730847, 0.09996246435148992, 0.09676643185197775, 0.24734831769606203, 0.22925615155786006, 0.1799069226523543, 0.6624719140384895, 0.3742921928248335, 0.40662426788091666, 0.2834648366318069, 0.29176663856743945, 0.21534063053151553, 0.29744068185655403, 0.31538097031132517, 0.46052105638402796, 0.2526492828515122, 0.264646203180822, 0.26334814723063293, 0.2792899361277065, 0.30434521132663694, 0.2256588780456128, 0.13702163369962106, 0.12872612648560866, 0.22926102181285057, 0.3588465482383979, 0.1887290738684103, 0.28149845328755496, 0.19806384717190806, 0.2558142174867324, 0.3087212511073193, 0.2708247843156536, 0.2345779104496173, 0.21717700037876397, 0.20828929514263206, 0.27656056663621587, 0.20923833924946156, 0.2918763460541073, 0.220389022654495, 0.2675682244149774, 0.17941999811547027, 0.1771356261011553, 0.1662531178132005, 0.18868565266631276, 0.1987443619745718, 0.17646782423813234, 0.219278238647303, 0.18907463658563872, 0.18318728849784238, 0.18707947893812837, 0.1687055963086761, 0.1544318381527291, 0.9372538650886245, 0.20116557171208616, 0.20113473123630032, 0.14269795935370244, 0.165157756677623, 0.9312048209688474, 0.9014395485312783, 0.21367145833153978, 0.0736195883765347, 0.8286233768004228, 0.16914334840859424, 0.1550607912135611, 0.2127010845515388, 0.21017916603881304, 0.16687312546030042, 0.2144245644236793, 0.20010403023162648, 0.19707372701949966, 0.21220801754729068, 0.18484565269910558, 0.21098997765619465, 0.20475817992190737, 0.19535465232713545, 0.20617580316331008, 0.07453166160808211, 0.11101053772867053, 0.10121678326189487, 0.10760599507723778, 0.09905073827136135, 0.15888193452237598, 0.10674180020031543, 0.11053806353153228, 0.1226558505727191]}, "mutation_prompt": null}
{"id": "cc6e601a-9f25-44c0-bc42-a095fcea107c", "solution": "import numpy as np\n\nclass EnhancedSwarmGradientOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, 10 * dim)  # Dynamic population sizing\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1\n        self.inertia_weight = 0.5  # Reduced inertia for quicker convergence\n        self.cognitive_const = 2.0  # Adjusted cognitive component\n        self.social_const = 2.0  # Adjusted social component\n    \n    def swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(len(population)):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_update(self, solution, fitness):\n        gradient_direction = np.random.normal(0, 1, self.dim)  # Gaussian perturbations\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        for _ in range(3):  # Multiple trial updates\n            candidate_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n            candidate_fitness = fitness(candidate_solution)\n            self.eval_count += 1\n\n            if candidate_fitness < self.best_fitness:\n                self.best_fitness = candidate_fitness\n                self.best_solution = candidate_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population_size = self.initial_population_size\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        velocities = np.zeros((population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Update on the best solution found so far\n            self.adaptive_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedSwarmGradientOpt", "description": "Enhanced Swarm-Gradient Optimization with Dynamic Population Sizing and Adaptive Update Mechanisms for Balanced Exploration and Exploitation.", "configspace": "", "generation": 91, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a87dd215-8dd2-4e98-8ddb-9b7c7d4df4bb", "metadata": {"aucs": [0.8854105288041776, 0.8794177814810371, 0.8937062065987564, 0.8827963384025219, 0.8757450806226722, 0.887758919266219, 0.873494116403716, 0.8798563203418784, 0.8952429255881322, 0.5089909047148589, 0.4969806267843291, 0.5359446853320798, 0.6359567130854025, 0.40292067934979703, 0.6799091935316717, 0.6435166315702612, 0.6884034022451118, 0.6572545804098411, 0.08186244722061042, 0.07195772166741832, 0.11756712855706974, 0.1178863852814317, 0.08448436129970183, 0.07511639891018274, 0.08657042463021358, 0.11903169733856067, 0.12470741629497983, 0.10296653791264287, 0.09243753031734048, 0.12011566189592449, 0.09737028990998187, 0.0951835316602212, 0.044672524637929034, 0.11680650505337054, 0.0918557325623397, 0.06374944954851214, 0.9847384852030742, 0.9605171639268267, 0.9939168611001645, 0.9499844409542871, 0.992111300318357, 0.9454331158007493, 0.9946377746205446, 0.9844771079270034, 0.9925909473801804, 0.6354335171638059, 0.46836632969750125, 0.5682419500809521, 0.42386111375649194, 0.5825040945605872, 0.5209930683392665, 0.33959930275599537, 0.5854979673798766, 0.7045663030766955, 0.25332753777626127, 0.21059288469975013, 0.21633018431655548, 0.2073835447747152, 0.19264335727383664, 0.21412351568461196, 0.177360438153501, 0.17631819378000202, 0.17461884312011844, 0.13391486884458959, 0.13313064298994504, 0.1305210296745417, 0.5721203186857072, 0.5464377538193956, 0.4389549019568538, 0.7263130114672249, 0.5815816186152449, 0.13472047721531888, 0.7882835842307953, 0.7112854125662198, 0.7633392600068252, 0.5960747964734356, 0.1330606678074091, 0.1340235375773252, 0.6786845617924688, 0.7797395844971702, 0.13158696142974058, 0.46975419699148446, 0.6179934888132239, 0.05146963450959552, 0.47813866295031837, 0.5484946352236076, 0.47013300017604365, 0.42802022496299763, 0.6425043782540554, 0.5405244924284592, 0.08605317601044205, 0.5699558763662805, 0.6585016840991822, 0.43979917731930496, 0.10361012404630787, 0.15400928354720722, 0.07116138805293049, 0.5370370496057975, 0.5125666505180002, 0.25739148440731174, 0.35585677768835344, 0.1480899117947604, 0.573577348976858, 0.07874570083259025, 0.3997287078479145, 0.09829290591936957, 0.218137059378679, 0.3261663391960615, 0.19156570138110907, 0.11399166012001039, 0.1370966596056683, 0.0941786583603802, 0.3294321052816349, 0.4463536538326973, 0.11542756780926988, 0.11058474490193637, 0.08313575112166649, 0.7954921003252177, 0.7813678432635888, 0.8370348633153718, 0.7767647249312547, 0.798719553044893, 0.7745942002447156, 0.781348265611792, 0.795828541137361, 0.8098345306724717, 0.12457639933059128, 0.05277251331684585, 0.051907487342345626, 0.05150185753612546, 0.10996542009483279, 0.1180078835847369, 0.14412547143730847, 0.09996246435148992, 0.09676643185197775, 0.24734831769606203, 0.22925615155786006, 0.1799069226523543, 0.6624719140384895, 0.3742921928248335, 0.40662426788091666, 0.2834648366318069, 0.29176663856743945, 0.21534063053151553, 0.29744068185655403, 0.31538097031132517, 0.46052105638402796, 0.2526492828515122, 0.264646203180822, 0.26334814723063293, 0.2792899361277065, 0.30434521132663694, 0.2256588780456128, 0.13702163369962106, 0.12872612648560866, 0.22926102181285057, 0.3588465482383979, 0.1887290738684103, 0.28149845328755496, 0.19806384717190806, 0.2558142174867324, 0.3087212511073193, 0.2708247843156536, 0.2345779104496173, 0.21717700037876397, 0.20828929514263206, 0.27656056663621587, 0.20923833924946156, 0.2918763460541073, 0.220389022654495, 0.2675682244149774, 0.17941999811547027, 0.1771356261011553, 0.1662531178132005, 0.18868565266631276, 0.1987443619745718, 0.17646782423813234, 0.219278238647303, 0.18907463658563872, 0.18318728849784238, 0.18707947893812837, 0.1687055963086761, 0.1544318381527291, 0.9372538650886245, 0.20116557171208616, 0.20113473123630032, 0.14269795935370244, 0.165157756677623, 0.9312048209688474, 0.9014395485312783, 0.21367145833153978, 0.0736195883765347, 0.8286233768004228, 0.16914334840859424, 0.1550607912135611, 0.2127010845515388, 0.21017916603881304, 0.16687312546030042, 0.2144245644236793, 0.20010403023162648, 0.19707372701949966, 0.21220801754729068, 0.18484565269910558, 0.21098997765619465, 0.20475817992190737, 0.19535465232713545, 0.20617580316331008, 0.07453166160808211, 0.11101053772867053, 0.10121678326189487, 0.10760599507723778, 0.09905073827136135, 0.15888193452237598, 0.10674180020031543, 0.11053806353153228, 0.1226558505727191]}, "mutation_prompt": null}
{"id": "20ec8e78-7932-4bdb-bccb-6817258f4412", "solution": "import numpy as np\n\nclass EnhancedSwarmGradientOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, 10 * dim)  # Dynamic population sizing\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1\n        self.inertia_weight = 0.5  # Reduced inertia for quicker convergence\n        self.cognitive_const = 2.0  # Adjusted cognitive component\n        self.social_const = 2.0  # Adjusted social component\n    \n    def swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(len(population)):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_update(self, solution, fitness):\n        gradient_direction = np.random.normal(0, 1, self.dim)  # Gaussian perturbations\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        for _ in range(3):  # Multiple trial updates\n            candidate_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n            candidate_fitness = fitness(candidate_solution)\n            self.eval_count += 1\n\n            if candidate_fitness < self.best_fitness:\n                self.best_fitness = candidate_fitness\n                self.best_solution = candidate_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population_size = self.initial_population_size\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        velocities = np.zeros((population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Update on the best solution found so far\n            self.adaptive_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedSwarmGradientOpt", "description": "Enhanced Swarm-Gradient Optimization with Dynamic Population Sizing and Adaptive Update Mechanisms for Balanced Exploration and Exploitation.", "configspace": "", "generation": 91, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a87dd215-8dd2-4e98-8ddb-9b7c7d4df4bb", "metadata": {"aucs": [0.8854105288041776, 0.8794177814810371, 0.8937062065987564, 0.8827963384025219, 0.8757450806226722, 0.887758919266219, 0.873494116403716, 0.8798563203418784, 0.8952429255881322, 0.5089909047148589, 0.4969806267843291, 0.5359446853320798, 0.6359567130854025, 0.40292067934979703, 0.6799091935316717, 0.6435166315702612, 0.6884034022451118, 0.6572545804098411, 0.08186244722061042, 0.07195772166741832, 0.11756712855706974, 0.1178863852814317, 0.08448436129970183, 0.07511639891018274, 0.08657042463021358, 0.11903169733856067, 0.12470741629497983, 0.10296653791264287, 0.09243753031734048, 0.12011566189592449, 0.09737028990998187, 0.0951835316602212, 0.044672524637929034, 0.11680650505337054, 0.0918557325623397, 0.06374944954851214, 0.9847384852030742, 0.9605171639268267, 0.9939168611001645, 0.9499844409542871, 0.992111300318357, 0.9454331158007493, 0.9946377746205446, 0.9844771079270034, 0.9925909473801804, 0.6354335171638059, 0.46836632969750125, 0.5682419500809521, 0.42386111375649194, 0.5825040945605872, 0.5209930683392665, 0.33959930275599537, 0.5854979673798766, 0.7045663030766955, 0.25332753777626127, 0.21059288469975013, 0.21633018431655548, 0.2073835447747152, 0.19264335727383664, 0.21412351568461196, 0.177360438153501, 0.17631819378000202, 0.17461884312011844, 0.13391486884458959, 0.13313064298994504, 0.1305210296745417, 0.5721203186857072, 0.5464377538193956, 0.4389549019568538, 0.7263130114672249, 0.5815816186152449, 0.13472047721531888, 0.7882835842307953, 0.7112854125662198, 0.7633392600068252, 0.5960747964734356, 0.1330606678074091, 0.1340235375773252, 0.6786845617924688, 0.7797395844971702, 0.13158696142974058, 0.46975419699148446, 0.6179934888132239, 0.05146963450959552, 0.47813866295031837, 0.5484946352236076, 0.47013300017604365, 0.42802022496299763, 0.6425043782540554, 0.5405244924284592, 0.08605317601044205, 0.5699558763662805, 0.6585016840991822, 0.43979917731930496, 0.10361012404630787, 0.15400928354720722, 0.07116138805293049, 0.5370370496057975, 0.5125666505180002, 0.25739148440731174, 0.35585677768835344, 0.1480899117947604, 0.573577348976858, 0.07874570083259025, 0.3997287078479145, 0.09829290591936957, 0.218137059378679, 0.3261663391960615, 0.19156570138110907, 0.11399166012001039, 0.1370966596056683, 0.0941786583603802, 0.3294321052816349, 0.4463536538326973, 0.11542756780926988, 0.11058474490193637, 0.08313575112166649, 0.7954921003252177, 0.7813678432635888, 0.8370348633153718, 0.7767647249312547, 0.798719553044893, 0.7745942002447156, 0.781348265611792, 0.795828541137361, 0.8098345306724717, 0.12457639933059128, 0.05277251331684585, 0.051907487342345626, 0.05150185753612546, 0.10996542009483279, 0.1180078835847369, 0.14412547143730847, 0.09996246435148992, 0.09676643185197775, 0.24734831769606203, 0.22925615155786006, 0.1799069226523543, 0.6624719140384895, 0.3742921928248335, 0.40662426788091666, 0.2834648366318069, 0.29176663856743945, 0.21534063053151553, 0.29744068185655403, 0.31538097031132517, 0.46052105638402796, 0.2526492828515122, 0.264646203180822, 0.26334814723063293, 0.2792899361277065, 0.30434521132663694, 0.2256588780456128, 0.13702163369962106, 0.12872612648560866, 0.22926102181285057, 0.3588465482383979, 0.1887290738684103, 0.28149845328755496, 0.19806384717190806, 0.2558142174867324, 0.3087212511073193, 0.2708247843156536, 0.2345779104496173, 0.21717700037876397, 0.20828929514263206, 0.27656056663621587, 0.20923833924946156, 0.2918763460541073, 0.220389022654495, 0.2675682244149774, 0.17941999811547027, 0.1771356261011553, 0.1662531178132005, 0.18868565266631276, 0.1987443619745718, 0.17646782423813234, 0.219278238647303, 0.18907463658563872, 0.18318728849784238, 0.18707947893812837, 0.1687055963086761, 0.1544318381527291, 0.9372538650886245, 0.20116557171208616, 0.20113473123630032, 0.14269795935370244, 0.165157756677623, 0.9312048209688474, 0.9014395485312783, 0.21367145833153978, 0.0736195883765347, 0.8286233768004228, 0.16914334840859424, 0.1550607912135611, 0.2127010845515388, 0.21017916603881304, 0.16687312546030042, 0.2144245644236793, 0.20010403023162648, 0.19707372701949966, 0.21220801754729068, 0.18484565269910558, 0.21098997765619465, 0.20475817992190737, 0.19535465232713545, 0.20617580316331008, 0.07453166160808211, 0.11101053772867053, 0.10121678326189487, 0.10760599507723778, 0.09905073827136135, 0.15888193452237598, 0.10674180020031543, 0.11053806353153228, 0.1226558505727191]}, "mutation_prompt": null}
{"id": "ed1adf10-3c4f-4ed9-90de-1d0b0c441b80", "solution": "import numpy as np\n\nclass EnhancedSwarmGradientOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, 10 * dim)  # Dynamic population sizing\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1\n        self.inertia_weight = 0.5  # Reduced inertia for quicker convergence\n        self.cognitive_const = 2.0  # Adjusted cognitive component\n        self.social_const = 2.0  # Adjusted social component\n    \n    def swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(len(population)):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_update(self, solution, fitness):\n        gradient_direction = np.random.normal(0, 1, self.dim)  # Gaussian perturbations\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        for _ in range(3):  # Multiple trial updates\n            candidate_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n            candidate_fitness = fitness(candidate_solution)\n            self.eval_count += 1\n\n            if candidate_fitness < self.best_fitness:\n                self.best_fitness = candidate_fitness\n                self.best_solution = candidate_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population_size = self.initial_population_size\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        velocities = np.zeros((population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Update on the best solution found so far\n            self.adaptive_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedSwarmGradientOpt", "description": "Enhanced Swarm-Gradient Optimization with Dynamic Population Sizing and Adaptive Update Mechanisms for Balanced Exploration and Exploitation.", "configspace": "", "generation": 91, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a87dd215-8dd2-4e98-8ddb-9b7c7d4df4bb", "metadata": {"aucs": [0.8854105288041776, 0.8794177814810371, 0.8937062065987564, 0.8827963384025219, 0.8757450806226722, 0.887758919266219, 0.873494116403716, 0.8798563203418784, 0.8952429255881322, 0.5089909047148589, 0.4969806267843291, 0.5359446853320798, 0.6359567130854025, 0.40292067934979703, 0.6799091935316717, 0.6435166315702612, 0.6884034022451118, 0.6572545804098411, 0.08186244722061042, 0.07195772166741832, 0.11756712855706974, 0.1178863852814317, 0.08448436129970183, 0.07511639891018274, 0.08657042463021358, 0.11903169733856067, 0.12470741629497983, 0.10296653791264287, 0.09243753031734048, 0.12011566189592449, 0.09737028990998187, 0.0951835316602212, 0.044672524637929034, 0.11680650505337054, 0.0918557325623397, 0.06374944954851214, 0.9847384852030742, 0.9605171639268267, 0.9939168611001645, 0.9499844409542871, 0.992111300318357, 0.9454331158007493, 0.9946377746205446, 0.9844771079270034, 0.9925909473801804, 0.6354335171638059, 0.46836632969750125, 0.5682419500809521, 0.42386111375649194, 0.5825040945605872, 0.5209930683392665, 0.33959930275599537, 0.5854979673798766, 0.7045663030766955, 0.25332753777626127, 0.21059288469975013, 0.21633018431655548, 0.2073835447747152, 0.19264335727383664, 0.21412351568461196, 0.177360438153501, 0.17631819378000202, 0.17461884312011844, 0.13391486884458959, 0.13313064298994504, 0.1305210296745417, 0.5721203186857072, 0.5464377538193956, 0.4389549019568538, 0.7263130114672249, 0.5815816186152449, 0.13472047721531888, 0.7882835842307953, 0.7112854125662198, 0.7633392600068252, 0.5960747964734356, 0.1330606678074091, 0.1340235375773252, 0.6786845617924688, 0.7797395844971702, 0.13158696142974058, 0.46975419699148446, 0.6179934888132239, 0.05146963450959552, 0.47813866295031837, 0.5484946352236076, 0.47013300017604365, 0.42802022496299763, 0.6425043782540554, 0.5405244924284592, 0.08605317601044205, 0.5699558763662805, 0.6585016840991822, 0.43979917731930496, 0.10361012404630787, 0.15400928354720722, 0.07116138805293049, 0.5370370496057975, 0.5125666505180002, 0.25739148440731174, 0.35585677768835344, 0.1480899117947604, 0.573577348976858, 0.07874570083259025, 0.3997287078479145, 0.09829290591936957, 0.218137059378679, 0.3261663391960615, 0.19156570138110907, 0.11399166012001039, 0.1370966596056683, 0.0941786583603802, 0.3294321052816349, 0.4463536538326973, 0.11542756780926988, 0.11058474490193637, 0.08313575112166649, 0.7954921003252177, 0.7813678432635888, 0.8370348633153718, 0.7767647249312547, 0.798719553044893, 0.7745942002447156, 0.781348265611792, 0.795828541137361, 0.8098345306724717, 0.12457639933059128, 0.05277251331684585, 0.051907487342345626, 0.05150185753612546, 0.10996542009483279, 0.1180078835847369, 0.14412547143730847, 0.09996246435148992, 0.09676643185197775, 0.24734831769606203, 0.22925615155786006, 0.1799069226523543, 0.6624719140384895, 0.3742921928248335, 0.40662426788091666, 0.2834648366318069, 0.29176663856743945, 0.21534063053151553, 0.29744068185655403, 0.31538097031132517, 0.46052105638402796, 0.2526492828515122, 0.264646203180822, 0.26334814723063293, 0.2792899361277065, 0.30434521132663694, 0.2256588780456128, 0.13702163369962106, 0.12872612648560866, 0.22926102181285057, 0.3588465482383979, 0.1887290738684103, 0.28149845328755496, 0.19806384717190806, 0.2558142174867324, 0.3087212511073193, 0.2708247843156536, 0.2345779104496173, 0.21717700037876397, 0.20828929514263206, 0.27656056663621587, 0.20923833924946156, 0.2918763460541073, 0.220389022654495, 0.2675682244149774, 0.17941999811547027, 0.1771356261011553, 0.1662531178132005, 0.18868565266631276, 0.1987443619745718, 0.17646782423813234, 0.219278238647303, 0.18907463658563872, 0.18318728849784238, 0.18707947893812837, 0.1687055963086761, 0.1544318381527291, 0.9372538650886245, 0.20116557171208616, 0.20113473123630032, 0.14269795935370244, 0.165157756677623, 0.9312048209688474, 0.9014395485312783, 0.21367145833153978, 0.0736195883765347, 0.8286233768004228, 0.16914334840859424, 0.1550607912135611, 0.2127010845515388, 0.21017916603881304, 0.16687312546030042, 0.2144245644236793, 0.20010403023162648, 0.19707372701949966, 0.21220801754729068, 0.18484565269910558, 0.21098997765619465, 0.20475817992190737, 0.19535465232713545, 0.20617580316331008, 0.07453166160808211, 0.11101053772867053, 0.10121678326189487, 0.10760599507723778, 0.09905073827136135, 0.15888193452237598, 0.10674180020031543, 0.11053806353153228, 0.1226558505727191]}, "mutation_prompt": null}
{"id": "aa309fbb-522d-4085-8dfe-54df64dd5bd8", "solution": "import numpy as np\n\nclass EnhancedSwarmGradientOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, 10 * dim)  # Dynamic population sizing\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1\n        self.inertia_weight = 0.5  # Reduced inertia for quicker convergence\n        self.cognitive_const = 2.0  # Adjusted cognitive component\n        self.social_const = 2.0  # Adjusted social component\n    \n    def swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(len(population)):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_update(self, solution, fitness):\n        gradient_direction = np.random.normal(0, 1, self.dim)  # Gaussian perturbations\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        for _ in range(3):  # Multiple trial updates\n            candidate_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n            candidate_fitness = fitness(candidate_solution)\n            self.eval_count += 1\n\n            if candidate_fitness < self.best_fitness:\n                self.best_fitness = candidate_fitness\n                self.best_solution = candidate_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population_size = self.initial_population_size\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        velocities = np.zeros((population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Update on the best solution found so far\n            self.adaptive_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedSwarmGradientOpt", "description": "Enhanced Swarm-Gradient Optimization with Dynamic Population Sizing and Adaptive Update Mechanisms for Balanced Exploration and Exploitation.", "configspace": "", "generation": 91, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a87dd215-8dd2-4e98-8ddb-9b7c7d4df4bb", "metadata": {"aucs": [0.8854105288041776, 0.8794177814810371, 0.8937062065987564, 0.8827963384025219, 0.8757450806226722, 0.887758919266219, 0.873494116403716, 0.8798563203418784, 0.8952429255881322, 0.5089909047148589, 0.4969806267843291, 0.5359446853320798, 0.6359567130854025, 0.40292067934979703, 0.6799091935316717, 0.6435166315702612, 0.6884034022451118, 0.6572545804098411, 0.08186244722061042, 0.07195772166741832, 0.11756712855706974, 0.1178863852814317, 0.08448436129970183, 0.07511639891018274, 0.08657042463021358, 0.11903169733856067, 0.12470741629497983, 0.10296653791264287, 0.09243753031734048, 0.12011566189592449, 0.09737028990998187, 0.0951835316602212, 0.044672524637929034, 0.11680650505337054, 0.0918557325623397, 0.06374944954851214, 0.9847384852030742, 0.9605171639268267, 0.9939168611001645, 0.9499844409542871, 0.992111300318357, 0.9454331158007493, 0.9946377746205446, 0.9844771079270034, 0.9925909473801804, 0.6354335171638059, 0.46836632969750125, 0.5682419500809521, 0.42386111375649194, 0.5825040945605872, 0.5209930683392665, 0.33959930275599537, 0.5854979673798766, 0.7045663030766955, 0.25332753777626127, 0.21059288469975013, 0.21633018431655548, 0.2073835447747152, 0.19264335727383664, 0.21412351568461196, 0.177360438153501, 0.17631819378000202, 0.17461884312011844, 0.13391486884458959, 0.13313064298994504, 0.1305210296745417, 0.5721203186857072, 0.5464377538193956, 0.4389549019568538, 0.7263130114672249, 0.5815816186152449, 0.13472047721531888, 0.7882835842307953, 0.7112854125662198, 0.7633392600068252, 0.5960747964734356, 0.1330606678074091, 0.1340235375773252, 0.6786845617924688, 0.7797395844971702, 0.13158696142974058, 0.46975419699148446, 0.6179934888132239, 0.05146963450959552, 0.47813866295031837, 0.5484946352236076, 0.47013300017604365, 0.42802022496299763, 0.6425043782540554, 0.5405244924284592, 0.08605317601044205, 0.5699558763662805, 0.6585016840991822, 0.43979917731930496, 0.10361012404630787, 0.15400928354720722, 0.07116138805293049, 0.5370370496057975, 0.5125666505180002, 0.25739148440731174, 0.35585677768835344, 0.1480899117947604, 0.573577348976858, 0.07874570083259025, 0.3997287078479145, 0.09829290591936957, 0.218137059378679, 0.3261663391960615, 0.19156570138110907, 0.11399166012001039, 0.1370966596056683, 0.0941786583603802, 0.3294321052816349, 0.4463536538326973, 0.11542756780926988, 0.11058474490193637, 0.08313575112166649, 0.7954921003252177, 0.7813678432635888, 0.8370348633153718, 0.7767647249312547, 0.798719553044893, 0.7745942002447156, 0.781348265611792, 0.795828541137361, 0.8098345306724717, 0.12457639933059128, 0.05277251331684585, 0.051907487342345626, 0.05150185753612546, 0.10996542009483279, 0.1180078835847369, 0.14412547143730847, 0.09996246435148992, 0.09676643185197775, 0.24734831769606203, 0.22925615155786006, 0.1799069226523543, 0.6624719140384895, 0.3742921928248335, 0.40662426788091666, 0.2834648366318069, 0.29176663856743945, 0.21534063053151553, 0.29744068185655403, 0.31538097031132517, 0.46052105638402796, 0.2526492828515122, 0.264646203180822, 0.26334814723063293, 0.2792899361277065, 0.30434521132663694, 0.2256588780456128, 0.13702163369962106, 0.12872612648560866, 0.22926102181285057, 0.3588465482383979, 0.1887290738684103, 0.28149845328755496, 0.19806384717190806, 0.2558142174867324, 0.3087212511073193, 0.2708247843156536, 0.2345779104496173, 0.21717700037876397, 0.20828929514263206, 0.27656056663621587, 0.20923833924946156, 0.2918763460541073, 0.220389022654495, 0.2675682244149774, 0.17941999811547027, 0.1771356261011553, 0.1662531178132005, 0.18868565266631276, 0.1987443619745718, 0.17646782423813234, 0.219278238647303, 0.18907463658563872, 0.18318728849784238, 0.18707947893812837, 0.1687055963086761, 0.1544318381527291, 0.9372538650886245, 0.20116557171208616, 0.20113473123630032, 0.14269795935370244, 0.165157756677623, 0.9312048209688474, 0.9014395485312783, 0.21367145833153978, 0.0736195883765347, 0.8286233768004228, 0.16914334840859424, 0.1550607912135611, 0.2127010845515388, 0.21017916603881304, 0.16687312546030042, 0.2144245644236793, 0.20010403023162648, 0.19707372701949966, 0.21220801754729068, 0.18484565269910558, 0.21098997765619465, 0.20475817992190737, 0.19535465232713545, 0.20617580316331008, 0.07453166160808211, 0.11101053772867053, 0.10121678326189487, 0.10760599507723778, 0.09905073827136135, 0.15888193452237598, 0.10674180020031543, 0.11053806353153228, 0.1226558505727191]}, "mutation_prompt": null}
{"id": "b06080a3-c976-47a2-b8f0-37118b5993f7", "solution": "import numpy as np\n\nclass EnhancedSwarmGradientOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, 10 * dim)  # Dynamic population sizing\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1\n        self.inertia_weight = 0.5  # Reduced inertia for quicker convergence\n        self.cognitive_const = 2.0  # Adjusted cognitive component\n        self.social_const = 2.0  # Adjusted social component\n    \n    def swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(len(population)):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_update(self, solution, fitness):\n        gradient_direction = np.random.normal(0, 1, self.dim)  # Gaussian perturbations\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        for _ in range(3):  # Multiple trial updates\n            candidate_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n            candidate_fitness = fitness(candidate_solution)\n            self.eval_count += 1\n\n            if candidate_fitness < self.best_fitness:\n                self.best_fitness = candidate_fitness\n                self.best_solution = candidate_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population_size = self.initial_population_size\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        velocities = np.zeros((population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Update on the best solution found so far\n            self.adaptive_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedSwarmGradientOpt", "description": "Enhanced Swarm-Gradient Optimization with Dynamic Population Sizing and Adaptive Update Mechanisms for Balanced Exploration and Exploitation.", "configspace": "", "generation": 91, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a87dd215-8dd2-4e98-8ddb-9b7c7d4df4bb", "metadata": {"aucs": [0.8854105288041776, 0.8794177814810371, 0.8937062065987564, 0.8827963384025219, 0.8757450806226722, 0.887758919266219, 0.873494116403716, 0.8798563203418784, 0.8952429255881322, 0.5089909047148589, 0.4969806267843291, 0.5359446853320798, 0.6359567130854025, 0.40292067934979703, 0.6799091935316717, 0.6435166315702612, 0.6884034022451118, 0.6572545804098411, 0.08186244722061042, 0.07195772166741832, 0.11756712855706974, 0.1178863852814317, 0.08448436129970183, 0.07511639891018274, 0.08657042463021358, 0.11903169733856067, 0.12470741629497983, 0.10296653791264287, 0.09243753031734048, 0.12011566189592449, 0.09737028990998187, 0.0951835316602212, 0.044672524637929034, 0.11680650505337054, 0.0918557325623397, 0.06374944954851214, 0.9847384852030742, 0.9605171639268267, 0.9939168611001645, 0.9499844409542871, 0.992111300318357, 0.9454331158007493, 0.9946377746205446, 0.9844771079270034, 0.9925909473801804, 0.6354335171638059, 0.46836632969750125, 0.5682419500809521, 0.42386111375649194, 0.5825040945605872, 0.5209930683392665, 0.33959930275599537, 0.5854979673798766, 0.7045663030766955, 0.25332753777626127, 0.21059288469975013, 0.21633018431655548, 0.2073835447747152, 0.19264335727383664, 0.21412351568461196, 0.177360438153501, 0.17631819378000202, 0.17461884312011844, 0.13391486884458959, 0.13313064298994504, 0.1305210296745417, 0.5721203186857072, 0.5464377538193956, 0.4389549019568538, 0.7263130114672249, 0.5815816186152449, 0.13472047721531888, 0.7882835842307953, 0.7112854125662198, 0.7633392600068252, 0.5960747964734356, 0.1330606678074091, 0.1340235375773252, 0.6786845617924688, 0.7797395844971702, 0.13158696142974058, 0.46975419699148446, 0.6179934888132239, 0.05146963450959552, 0.47813866295031837, 0.5484946352236076, 0.47013300017604365, 0.42802022496299763, 0.6425043782540554, 0.5405244924284592, 0.08605317601044205, 0.5699558763662805, 0.6585016840991822, 0.43979917731930496, 0.10361012404630787, 0.15400928354720722, 0.07116138805293049, 0.5370370496057975, 0.5125666505180002, 0.25739148440731174, 0.35585677768835344, 0.1480899117947604, 0.573577348976858, 0.07874570083259025, 0.3997287078479145, 0.09829290591936957, 0.218137059378679, 0.3261663391960615, 0.19156570138110907, 0.11399166012001039, 0.1370966596056683, 0.0941786583603802, 0.3294321052816349, 0.4463536538326973, 0.11542756780926988, 0.11058474490193637, 0.08313575112166649, 0.7954921003252177, 0.7813678432635888, 0.8370348633153718, 0.7767647249312547, 0.798719553044893, 0.7745942002447156, 0.781348265611792, 0.795828541137361, 0.8098345306724717, 0.12457639933059128, 0.05277251331684585, 0.051907487342345626, 0.05150185753612546, 0.10996542009483279, 0.1180078835847369, 0.14412547143730847, 0.09996246435148992, 0.09676643185197775, 0.24734831769606203, 0.22925615155786006, 0.1799069226523543, 0.6624719140384895, 0.3742921928248335, 0.40662426788091666, 0.2834648366318069, 0.29176663856743945, 0.21534063053151553, 0.29744068185655403, 0.31538097031132517, 0.46052105638402796, 0.2526492828515122, 0.264646203180822, 0.26334814723063293, 0.2792899361277065, 0.30434521132663694, 0.2256588780456128, 0.13702163369962106, 0.12872612648560866, 0.22926102181285057, 0.3588465482383979, 0.1887290738684103, 0.28149845328755496, 0.19806384717190806, 0.2558142174867324, 0.3087212511073193, 0.2708247843156536, 0.2345779104496173, 0.21717700037876397, 0.20828929514263206, 0.27656056663621587, 0.20923833924946156, 0.2918763460541073, 0.220389022654495, 0.2675682244149774, 0.17941999811547027, 0.1771356261011553, 0.1662531178132005, 0.18868565266631276, 0.1987443619745718, 0.17646782423813234, 0.219278238647303, 0.18907463658563872, 0.18318728849784238, 0.18707947893812837, 0.1687055963086761, 0.1544318381527291, 0.9372538650886245, 0.20116557171208616, 0.20113473123630032, 0.14269795935370244, 0.165157756677623, 0.9312048209688474, 0.9014395485312783, 0.21367145833153978, 0.0736195883765347, 0.8286233768004228, 0.16914334840859424, 0.1550607912135611, 0.2127010845515388, 0.21017916603881304, 0.16687312546030042, 0.2144245644236793, 0.20010403023162648, 0.19707372701949966, 0.21220801754729068, 0.18484565269910558, 0.21098997765619465, 0.20475817992190737, 0.19535465232713545, 0.20617580316331008, 0.07453166160808211, 0.11101053772867053, 0.10121678326189487, 0.10760599507723778, 0.09905073827136135, 0.15888193452237598, 0.10674180020031543, 0.11053806353153228, 0.1226558505727191]}, "mutation_prompt": null}
{"id": "2d95996b-5f0d-4e3c-8955-6071f3afb5b4", "solution": "import numpy as np\n\nclass EnhancedSwarmGradientOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, 10 * dim)  # Dynamic population sizing\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1\n        self.inertia_weight = 0.5  # Reduced inertia for quicker convergence\n        self.cognitive_const = 2.0  # Adjusted cognitive component\n        self.social_const = 2.0  # Adjusted social component\n    \n    def swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(len(population)):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_update(self, solution, fitness):\n        gradient_direction = np.random.normal(0, 1, self.dim)  # Gaussian perturbations\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        for _ in range(3):  # Multiple trial updates\n            candidate_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n            candidate_fitness = fitness(candidate_solution)\n            self.eval_count += 1\n\n            if candidate_fitness < self.best_fitness:\n                self.best_fitness = candidate_fitness\n                self.best_solution = candidate_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population_size = self.initial_population_size\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        velocities = np.zeros((population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Update on the best solution found so far\n            self.adaptive_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedSwarmGradientOpt", "description": "Enhanced Swarm-Gradient Optimization with Dynamic Population Sizing and Adaptive Update Mechanisms for Balanced Exploration and Exploitation.", "configspace": "", "generation": 91, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a87dd215-8dd2-4e98-8ddb-9b7c7d4df4bb", "metadata": {"aucs": [0.8854105288041776, 0.8794177814810371, 0.8937062065987564, 0.8827963384025219, 0.8757450806226722, 0.887758919266219, 0.873494116403716, 0.8798563203418784, 0.8952429255881322, 0.5089909047148589, 0.4969806267843291, 0.5359446853320798, 0.6359567130854025, 0.40292067934979703, 0.6799091935316717, 0.6435166315702612, 0.6884034022451118, 0.6572545804098411, 0.08186244722061042, 0.07195772166741832, 0.11756712855706974, 0.1178863852814317, 0.08448436129970183, 0.07511639891018274, 0.08657042463021358, 0.11903169733856067, 0.12470741629497983, 0.10296653791264287, 0.09243753031734048, 0.12011566189592449, 0.09737028990998187, 0.0951835316602212, 0.044672524637929034, 0.11680650505337054, 0.0918557325623397, 0.06374944954851214, 0.9847384852030742, 0.9605171639268267, 0.9939168611001645, 0.9499844409542871, 0.992111300318357, 0.9454331158007493, 0.9946377746205446, 0.9844771079270034, 0.9925909473801804, 0.6354335171638059, 0.46836632969750125, 0.5682419500809521, 0.42386111375649194, 0.5825040945605872, 0.5209930683392665, 0.33959930275599537, 0.5854979673798766, 0.7045663030766955, 0.25332753777626127, 0.21059288469975013, 0.21633018431655548, 0.2073835447747152, 0.19264335727383664, 0.21412351568461196, 0.177360438153501, 0.17631819378000202, 0.17461884312011844, 0.13391486884458959, 0.13313064298994504, 0.1305210296745417, 0.5721203186857072, 0.5464377538193956, 0.4389549019568538, 0.7263130114672249, 0.5815816186152449, 0.13472047721531888, 0.7882835842307953, 0.7112854125662198, 0.7633392600068252, 0.5960747964734356, 0.1330606678074091, 0.1340235375773252, 0.6786845617924688, 0.7797395844971702, 0.13158696142974058, 0.46975419699148446, 0.6179934888132239, 0.05146963450959552, 0.47813866295031837, 0.5484946352236076, 0.47013300017604365, 0.42802022496299763, 0.6425043782540554, 0.5405244924284592, 0.08605317601044205, 0.5699558763662805, 0.6585016840991822, 0.43979917731930496, 0.10361012404630787, 0.15400928354720722, 0.07116138805293049, 0.5370370496057975, 0.5125666505180002, 0.25739148440731174, 0.35585677768835344, 0.1480899117947604, 0.573577348976858, 0.07874570083259025, 0.3997287078479145, 0.09829290591936957, 0.218137059378679, 0.3261663391960615, 0.19156570138110907, 0.11399166012001039, 0.1370966596056683, 0.0941786583603802, 0.3294321052816349, 0.4463536538326973, 0.11542756780926988, 0.11058474490193637, 0.08313575112166649, 0.7954921003252177, 0.7813678432635888, 0.8370348633153718, 0.7767647249312547, 0.798719553044893, 0.7745942002447156, 0.781348265611792, 0.795828541137361, 0.8098345306724717, 0.12457639933059128, 0.05277251331684585, 0.051907487342345626, 0.05150185753612546, 0.10996542009483279, 0.1180078835847369, 0.14412547143730847, 0.09996246435148992, 0.09676643185197775, 0.24734831769606203, 0.22925615155786006, 0.1799069226523543, 0.6624719140384895, 0.3742921928248335, 0.40662426788091666, 0.2834648366318069, 0.29176663856743945, 0.21534063053151553, 0.29744068185655403, 0.31538097031132517, 0.46052105638402796, 0.2526492828515122, 0.264646203180822, 0.26334814723063293, 0.2792899361277065, 0.30434521132663694, 0.2256588780456128, 0.13702163369962106, 0.12872612648560866, 0.22926102181285057, 0.3588465482383979, 0.1887290738684103, 0.28149845328755496, 0.19806384717190806, 0.2558142174867324, 0.3087212511073193, 0.2708247843156536, 0.2345779104496173, 0.21717700037876397, 0.20828929514263206, 0.27656056663621587, 0.20923833924946156, 0.2918763460541073, 0.220389022654495, 0.2675682244149774, 0.17941999811547027, 0.1771356261011553, 0.1662531178132005, 0.18868565266631276, 0.1987443619745718, 0.17646782423813234, 0.219278238647303, 0.18907463658563872, 0.18318728849784238, 0.18707947893812837, 0.1687055963086761, 0.1544318381527291, 0.9372538650886245, 0.20116557171208616, 0.20113473123630032, 0.14269795935370244, 0.165157756677623, 0.9312048209688474, 0.9014395485312783, 0.21367145833153978, 0.0736195883765347, 0.8286233768004228, 0.16914334840859424, 0.1550607912135611, 0.2127010845515388, 0.21017916603881304, 0.16687312546030042, 0.2144245644236793, 0.20010403023162648, 0.19707372701949966, 0.21220801754729068, 0.18484565269910558, 0.21098997765619465, 0.20475817992190737, 0.19535465232713545, 0.20617580316331008, 0.07453166160808211, 0.11101053772867053, 0.10121678326189487, 0.10760599507723778, 0.09905073827136135, 0.15888193452237598, 0.10674180020031543, 0.11053806353153228, 0.1226558505727191]}, "mutation_prompt": null}
{"id": "1957d528-7099-4285-9852-a218f3805d33", "solution": "import numpy as np\n\nclass EnhancedSwarmGradientOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, 10 * dim)  # Dynamic population sizing\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1\n        self.inertia_weight = 0.5  # Reduced inertia for quicker convergence\n        self.cognitive_const = 2.0  # Adjusted cognitive component\n        self.social_const = 2.0  # Adjusted social component\n    \n    def swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(len(population)):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_update(self, solution, fitness):\n        gradient_direction = np.random.normal(0, 1, self.dim)  # Gaussian perturbations\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        for _ in range(3):  # Multiple trial updates\n            candidate_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n            candidate_fitness = fitness(candidate_solution)\n            self.eval_count += 1\n\n            if candidate_fitness < self.best_fitness:\n                self.best_fitness = candidate_fitness\n                self.best_solution = candidate_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population_size = self.initial_population_size\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        velocities = np.zeros((population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Update on the best solution found so far\n            self.adaptive_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedSwarmGradientOpt", "description": "Enhanced Swarm-Gradient Optimization with Dynamic Population Sizing and Adaptive Update Mechanisms for Balanced Exploration and Exploitation.", "configspace": "", "generation": 91, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a87dd215-8dd2-4e98-8ddb-9b7c7d4df4bb", "metadata": {"aucs": [0.8854105288041776, 0.8794177814810371, 0.8937062065987564, 0.8827963384025219, 0.8757450806226722, 0.887758919266219, 0.873494116403716, 0.8798563203418784, 0.8952429255881322, 0.5089909047148589, 0.4969806267843291, 0.5359446853320798, 0.6359567130854025, 0.40292067934979703, 0.6799091935316717, 0.6435166315702612, 0.6884034022451118, 0.6572545804098411, 0.08186244722061042, 0.07195772166741832, 0.11756712855706974, 0.1178863852814317, 0.08448436129970183, 0.07511639891018274, 0.08657042463021358, 0.11903169733856067, 0.12470741629497983, 0.10296653791264287, 0.09243753031734048, 0.12011566189592449, 0.09737028990998187, 0.0951835316602212, 0.044672524637929034, 0.11680650505337054, 0.0918557325623397, 0.06374944954851214, 0.9847384852030742, 0.9605171639268267, 0.9939168611001645, 0.9499844409542871, 0.992111300318357, 0.9454331158007493, 0.9946377746205446, 0.9844771079270034, 0.9925909473801804, 0.6354335171638059, 0.46836632969750125, 0.5682419500809521, 0.42386111375649194, 0.5825040945605872, 0.5209930683392665, 0.33959930275599537, 0.5854979673798766, 0.7045663030766955, 0.25332753777626127, 0.21059288469975013, 0.21633018431655548, 0.2073835447747152, 0.19264335727383664, 0.21412351568461196, 0.177360438153501, 0.17631819378000202, 0.17461884312011844, 0.13391486884458959, 0.13313064298994504, 0.1305210296745417, 0.5721203186857072, 0.5464377538193956, 0.4389549019568538, 0.7263130114672249, 0.5815816186152449, 0.13472047721531888, 0.7882835842307953, 0.7112854125662198, 0.7633392600068252, 0.5960747964734356, 0.1330606678074091, 0.1340235375773252, 0.6786845617924688, 0.7797395844971702, 0.13158696142974058, 0.46975419699148446, 0.6179934888132239, 0.05146963450959552, 0.47813866295031837, 0.5484946352236076, 0.47013300017604365, 0.42802022496299763, 0.6425043782540554, 0.5405244924284592, 0.08605317601044205, 0.5699558763662805, 0.6585016840991822, 0.43979917731930496, 0.10361012404630787, 0.15400928354720722, 0.07116138805293049, 0.5370370496057975, 0.5125666505180002, 0.25739148440731174, 0.35585677768835344, 0.1480899117947604, 0.573577348976858, 0.07874570083259025, 0.3997287078479145, 0.09829290591936957, 0.218137059378679, 0.3261663391960615, 0.19156570138110907, 0.11399166012001039, 0.1370966596056683, 0.0941786583603802, 0.3294321052816349, 0.4463536538326973, 0.11542756780926988, 0.11058474490193637, 0.08313575112166649, 0.7954921003252177, 0.7813678432635888, 0.8370348633153718, 0.7767647249312547, 0.798719553044893, 0.7745942002447156, 0.781348265611792, 0.795828541137361, 0.8098345306724717, 0.12457639933059128, 0.05277251331684585, 0.051907487342345626, 0.05150185753612546, 0.10996542009483279, 0.1180078835847369, 0.14412547143730847, 0.09996246435148992, 0.09676643185197775, 0.24734831769606203, 0.22925615155786006, 0.1799069226523543, 0.6624719140384895, 0.3742921928248335, 0.40662426788091666, 0.2834648366318069, 0.29176663856743945, 0.21534063053151553, 0.29744068185655403, 0.31538097031132517, 0.46052105638402796, 0.2526492828515122, 0.264646203180822, 0.26334814723063293, 0.2792899361277065, 0.30434521132663694, 0.2256588780456128, 0.13702163369962106, 0.12872612648560866, 0.22926102181285057, 0.3588465482383979, 0.1887290738684103, 0.28149845328755496, 0.19806384717190806, 0.2558142174867324, 0.3087212511073193, 0.2708247843156536, 0.2345779104496173, 0.21717700037876397, 0.20828929514263206, 0.27656056663621587, 0.20923833924946156, 0.2918763460541073, 0.220389022654495, 0.2675682244149774, 0.17941999811547027, 0.1771356261011553, 0.1662531178132005, 0.18868565266631276, 0.1987443619745718, 0.17646782423813234, 0.219278238647303, 0.18907463658563872, 0.18318728849784238, 0.18707947893812837, 0.1687055963086761, 0.1544318381527291, 0.9372538650886245, 0.20116557171208616, 0.20113473123630032, 0.14269795935370244, 0.165157756677623, 0.9312048209688474, 0.9014395485312783, 0.21367145833153978, 0.0736195883765347, 0.8286233768004228, 0.16914334840859424, 0.1550607912135611, 0.2127010845515388, 0.21017916603881304, 0.16687312546030042, 0.2144245644236793, 0.20010403023162648, 0.19707372701949966, 0.21220801754729068, 0.18484565269910558, 0.21098997765619465, 0.20475817992190737, 0.19535465232713545, 0.20617580316331008, 0.07453166160808211, 0.11101053772867053, 0.10121678326189487, 0.10760599507723778, 0.09905073827136135, 0.15888193452237598, 0.10674180020031543, 0.11053806353153228, 0.1226558505727191]}, "mutation_prompt": null}
{"id": "e743a889-920a-4019-9fcc-f795227cef7a", "solution": "import numpy as np\n\nclass EnhancedSwarmGradientOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, 10 * dim)  # Dynamic population sizing\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1\n        self.inertia_weight = 0.5  # Reduced inertia for quicker convergence\n        self.cognitive_const = 2.0  # Adjusted cognitive component\n        self.social_const = 2.0  # Adjusted social component\n    \n    def swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(len(population)):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_update(self, solution, fitness):\n        gradient_direction = np.random.normal(0, 1, self.dim)  # Gaussian perturbations\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        for _ in range(3):  # Multiple trial updates\n            candidate_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n            candidate_fitness = fitness(candidate_solution)\n            self.eval_count += 1\n\n            if candidate_fitness < self.best_fitness:\n                self.best_fitness = candidate_fitness\n                self.best_solution = candidate_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population_size = self.initial_population_size\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        velocities = np.zeros((population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Update on the best solution found so far\n            self.adaptive_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedSwarmGradientOpt", "description": "Enhanced Swarm-Gradient Optimization with Dynamic Population Sizing and Adaptive Update Mechanisms for Balanced Exploration and Exploitation.", "configspace": "", "generation": 91, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a87dd215-8dd2-4e98-8ddb-9b7c7d4df4bb", "metadata": {"aucs": [0.8854105288041776, 0.8794177814810371, 0.8937062065987564, 0.8827963384025219, 0.8757450806226722, 0.887758919266219, 0.873494116403716, 0.8798563203418784, 0.8952429255881322, 0.5089909047148589, 0.4969806267843291, 0.5359446853320798, 0.6359567130854025, 0.40292067934979703, 0.6799091935316717, 0.6435166315702612, 0.6884034022451118, 0.6572545804098411, 0.08186244722061042, 0.07195772166741832, 0.11756712855706974, 0.1178863852814317, 0.08448436129970183, 0.07511639891018274, 0.08657042463021358, 0.11903169733856067, 0.12470741629497983, 0.10296653791264287, 0.09243753031734048, 0.12011566189592449, 0.09737028990998187, 0.0951835316602212, 0.044672524637929034, 0.11680650505337054, 0.0918557325623397, 0.06374944954851214, 0.9847384852030742, 0.9605171639268267, 0.9939168611001645, 0.9499844409542871, 0.992111300318357, 0.9454331158007493, 0.9946377746205446, 0.9844771079270034, 0.9925909473801804, 0.6354335171638059, 0.46836632969750125, 0.5682419500809521, 0.42386111375649194, 0.5825040945605872, 0.5209930683392665, 0.33959930275599537, 0.5854979673798766, 0.7045663030766955, 0.25332753777626127, 0.21059288469975013, 0.21633018431655548, 0.2073835447747152, 0.19264335727383664, 0.21412351568461196, 0.177360438153501, 0.17631819378000202, 0.17461884312011844, 0.13391486884458959, 0.13313064298994504, 0.1305210296745417, 0.5721203186857072, 0.5464377538193956, 0.4389549019568538, 0.7263130114672249, 0.5815816186152449, 0.13472047721531888, 0.7882835842307953, 0.7112854125662198, 0.7633392600068252, 0.5960747964734356, 0.1330606678074091, 0.1340235375773252, 0.6786845617924688, 0.7797395844971702, 0.13158696142974058, 0.46975419699148446, 0.6179934888132239, 0.05146963450959552, 0.47813866295031837, 0.5484946352236076, 0.47013300017604365, 0.42802022496299763, 0.6425043782540554, 0.5405244924284592, 0.08605317601044205, 0.5699558763662805, 0.6585016840991822, 0.43979917731930496, 0.10361012404630787, 0.15400928354720722, 0.07116138805293049, 0.5370370496057975, 0.5125666505180002, 0.25739148440731174, 0.35585677768835344, 0.1480899117947604, 0.573577348976858, 0.07874570083259025, 0.3997287078479145, 0.09829290591936957, 0.218137059378679, 0.3261663391960615, 0.19156570138110907, 0.11399166012001039, 0.1370966596056683, 0.0941786583603802, 0.3294321052816349, 0.4463536538326973, 0.11542756780926988, 0.11058474490193637, 0.08313575112166649, 0.7954921003252177, 0.7813678432635888, 0.8370348633153718, 0.7767647249312547, 0.798719553044893, 0.7745942002447156, 0.781348265611792, 0.795828541137361, 0.8098345306724717, 0.12457639933059128, 0.05277251331684585, 0.051907487342345626, 0.05150185753612546, 0.10996542009483279, 0.1180078835847369, 0.14412547143730847, 0.09996246435148992, 0.09676643185197775, 0.24734831769606203, 0.22925615155786006, 0.1799069226523543, 0.6624719140384895, 0.3742921928248335, 0.40662426788091666, 0.2834648366318069, 0.29176663856743945, 0.21534063053151553, 0.29744068185655403, 0.31538097031132517, 0.46052105638402796, 0.2526492828515122, 0.264646203180822, 0.26334814723063293, 0.2792899361277065, 0.30434521132663694, 0.2256588780456128, 0.13702163369962106, 0.12872612648560866, 0.22926102181285057, 0.3588465482383979, 0.1887290738684103, 0.28149845328755496, 0.19806384717190806, 0.2558142174867324, 0.3087212511073193, 0.2708247843156536, 0.2345779104496173, 0.21717700037876397, 0.20828929514263206, 0.27656056663621587, 0.20923833924946156, 0.2918763460541073, 0.220389022654495, 0.2675682244149774, 0.17941999811547027, 0.1771356261011553, 0.1662531178132005, 0.18868565266631276, 0.1987443619745718, 0.17646782423813234, 0.219278238647303, 0.18907463658563872, 0.18318728849784238, 0.18707947893812837, 0.1687055963086761, 0.1544318381527291, 0.9372538650886245, 0.20116557171208616, 0.20113473123630032, 0.14269795935370244, 0.165157756677623, 0.9312048209688474, 0.9014395485312783, 0.21367145833153978, 0.0736195883765347, 0.8286233768004228, 0.16914334840859424, 0.1550607912135611, 0.2127010845515388, 0.21017916603881304, 0.16687312546030042, 0.2144245644236793, 0.20010403023162648, 0.19707372701949966, 0.21220801754729068, 0.18484565269910558, 0.21098997765619465, 0.20475817992190737, 0.19535465232713545, 0.20617580316331008, 0.07453166160808211, 0.11101053772867053, 0.10121678326189487, 0.10760599507723778, 0.09905073827136135, 0.15888193452237598, 0.10674180020031543, 0.11053806353153228, 0.1226558505727191]}, "mutation_prompt": null}
{"id": "4f4bdd71-7e4c-4b95-8d3a-ef1bdb11131c", "solution": "import numpy as np\n\nclass EnhancedSwarmGradientOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, 10 * dim)  # Dynamic population sizing\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.learning_rate = 0.1\n        self.inertia_weight = 0.5  # Reduced inertia for quicker convergence\n        self.cognitive_const = 2.0  # Adjusted cognitive component\n        self.social_const = 2.0  # Adjusted social component\n    \n    def swarm_update(self, population, velocities, personal_best_positions, personal_best_scores, fitness):\n        new_population = np.copy(population)\n        new_velocities = np.copy(velocities)\n\n        for i in range(len(population)):\n            r1, r2 = np.random.rand(2)\n            \n            # Update velocities\n            new_velocities[i] = (\n                self.inertia_weight * velocities[i] +\n                self.cognitive_const * r1 * (personal_best_positions[i] - population[i]) +\n                self.social_const * r2 * (self.best_solution - population[i])\n            )\n            \n            # Update positions\n            new_population[i] = np.clip(population[i] + new_velocities[i], self.lower_bound, self.upper_bound)\n            new_fitness = fitness(new_population[i])\n            self.eval_count += 1\n\n            # Update personal bests\n            if new_fitness < personal_best_scores[i]:\n                personal_best_positions[i] = new_population[i]\n                personal_best_scores[i] = new_fitness\n\n            # Update global best\n            if new_fitness < self.best_fitness:\n                self.best_fitness = new_fitness\n                self.best_solution = new_population[i]\n\n        return new_population, new_velocities, personal_best_positions, personal_best_scores\n\n    def adaptive_update(self, solution, fitness):\n        gradient_direction = np.random.normal(0, 1, self.dim)  # Gaussian perturbations\n        gradient_step_size = self.learning_rate * (1 - self.eval_count / self.budget)\n        for _ in range(3):  # Multiple trial updates\n            candidate_solution = np.clip(solution + gradient_step_size * gradient_direction, self.lower_bound, self.upper_bound)\n            candidate_fitness = fitness(candidate_solution)\n            self.eval_count += 1\n\n            if candidate_fitness < self.best_fitness:\n                self.best_fitness = candidate_fitness\n                self.best_solution = candidate_solution\n\n    def __call__(self, func):\n        # Initialize population and velocities\n        population_size = self.initial_population_size\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        velocities = np.zeros((population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(population_size, float('inf'))\n\n        # Evaluate initial population\n        for i in range(population_size):\n            fitness_value = func(population[i])\n            self.eval_count += 1\n\n            if fitness_value < self.best_fitness:\n                self.best_fitness = fitness_value\n                self.best_solution = population[i]\n\n            personal_best_positions[i] = population[i]\n            personal_best_scores[i] = fitness_value\n\n        while self.eval_count < self.budget:\n            # Apply Swarm Update\n            population, velocities, personal_best_positions, personal_best_scores = self.swarm_update(\n                population, velocities, personal_best_positions, personal_best_scores, func\n            )\n\n            # Apply Adaptive Update on the best solution found so far\n            self.adaptive_update(self.best_solution, func)\n\n        return self.best_solution", "name": "EnhancedSwarmGradientOpt", "description": "Enhanced Swarm-Gradient Optimization with Dynamic Population Sizing and Adaptive Update Mechanisms for Balanced Exploration and Exploitation.", "configspace": "", "generation": 91, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a87dd215-8dd2-4e98-8ddb-9b7c7d4df4bb", "metadata": {"aucs": [0.8854105288041776, 0.8794177814810371, 0.8937062065987564, 0.8827963384025219, 0.8757450806226722, 0.887758919266219, 0.873494116403716, 0.8798563203418784, 0.8952429255881322, 0.5089909047148589, 0.4969806267843291, 0.5359446853320798, 0.6359567130854025, 0.40292067934979703, 0.6799091935316717, 0.6435166315702612, 0.6884034022451118, 0.6572545804098411, 0.08186244722061042, 0.07195772166741832, 0.11756712855706974, 0.1178863852814317, 0.08448436129970183, 0.07511639891018274, 0.08657042463021358, 0.11903169733856067, 0.12470741629497983, 0.10296653791264287, 0.09243753031734048, 0.12011566189592449, 0.09737028990998187, 0.0951835316602212, 0.044672524637929034, 0.11680650505337054, 0.0918557325623397, 0.06374944954851214, 0.9847384852030742, 0.9605171639268267, 0.9939168611001645, 0.9499844409542871, 0.992111300318357, 0.9454331158007493, 0.9946377746205446, 0.9844771079270034, 0.9925909473801804, 0.6354335171638059, 0.46836632969750125, 0.5682419500809521, 0.42386111375649194, 0.5825040945605872, 0.5209930683392665, 0.33959930275599537, 0.5854979673798766, 0.7045663030766955, 0.25332753777626127, 0.21059288469975013, 0.21633018431655548, 0.2073835447747152, 0.19264335727383664, 0.21412351568461196, 0.177360438153501, 0.17631819378000202, 0.17461884312011844, 0.13391486884458959, 0.13313064298994504, 0.1305210296745417, 0.5721203186857072, 0.5464377538193956, 0.4389549019568538, 0.7263130114672249, 0.5815816186152449, 0.13472047721531888, 0.7882835842307953, 0.7112854125662198, 0.7633392600068252, 0.5960747964734356, 0.1330606678074091, 0.1340235375773252, 0.6786845617924688, 0.7797395844971702, 0.13158696142974058, 0.46975419699148446, 0.6179934888132239, 0.05146963450959552, 0.47813866295031837, 0.5484946352236076, 0.47013300017604365, 0.42802022496299763, 0.6425043782540554, 0.5405244924284592, 0.08605317601044205, 0.5699558763662805, 0.6585016840991822, 0.43979917731930496, 0.10361012404630787, 0.15400928354720722, 0.07116138805293049, 0.5370370496057975, 0.5125666505180002, 0.25739148440731174, 0.35585677768835344, 0.1480899117947604, 0.573577348976858, 0.07874570083259025, 0.3997287078479145, 0.09829290591936957, 0.218137059378679, 0.3261663391960615, 0.19156570138110907, 0.11399166012001039, 0.1370966596056683, 0.0941786583603802, 0.3294321052816349, 0.4463536538326973, 0.11542756780926988, 0.11058474490193637, 0.08313575112166649, 0.7954921003252177, 0.7813678432635888, 0.8370348633153718, 0.7767647249312547, 0.798719553044893, 0.7745942002447156, 0.781348265611792, 0.795828541137361, 0.8098345306724717, 0.12457639933059128, 0.05277251331684585, 0.051907487342345626, 0.05150185753612546, 0.10996542009483279, 0.1180078835847369, 0.14412547143730847, 0.09996246435148992, 0.09676643185197775, 0.24734831769606203, 0.22925615155786006, 0.1799069226523543, 0.6624719140384895, 0.3742921928248335, 0.40662426788091666, 0.2834648366318069, 0.29176663856743945, 0.21534063053151553, 0.29744068185655403, 0.31538097031132517, 0.46052105638402796, 0.2526492828515122, 0.264646203180822, 0.26334814723063293, 0.2792899361277065, 0.30434521132663694, 0.2256588780456128, 0.13702163369962106, 0.12872612648560866, 0.22926102181285057, 0.3588465482383979, 0.1887290738684103, 0.28149845328755496, 0.19806384717190806, 0.2558142174867324, 0.3087212511073193, 0.2708247843156536, 0.2345779104496173, 0.21717700037876397, 0.20828929514263206, 0.27656056663621587, 0.20923833924946156, 0.2918763460541073, 0.220389022654495, 0.2675682244149774, 0.17941999811547027, 0.1771356261011553, 0.1662531178132005, 0.18868565266631276, 0.1987443619745718, 0.17646782423813234, 0.219278238647303, 0.18907463658563872, 0.18318728849784238, 0.18707947893812837, 0.1687055963086761, 0.1544318381527291, 0.9372538650886245, 0.20116557171208616, 0.20113473123630032, 0.14269795935370244, 0.165157756677623, 0.9312048209688474, 0.9014395485312783, 0.21367145833153978, 0.0736195883765347, 0.8286233768004228, 0.16914334840859424, 0.1550607912135611, 0.2127010845515388, 0.21017916603881304, 0.16687312546030042, 0.2144245644236793, 0.20010403023162648, 0.19707372701949966, 0.21220801754729068, 0.18484565269910558, 0.21098997765619465, 0.20475817992190737, 0.19535465232713545, 0.20617580316331008, 0.07453166160808211, 0.11101053772867053, 0.10121678326189487, 0.10760599507723778, 0.09905073827136135, 0.15888193452237598, 0.10674180020031543, 0.11053806353153228, 0.1226558505727191]}, "mutation_prompt": null}

{"id": "f6b28311-d8b6-4482-aeff-b6cb8bd54fd7", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Transformative Swarms - A hybrid approach combining swarm intelligence and adaptive local search for versatile black-box optimization.", "configspace": "", "generation": 0, "fitness": 0.15941353208796963, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.01.", "error": "", "parent_id": null, "metadata": {"aucs": [0.14151076724085931, 0.1649842042332602, 0.1717456247897894]}, "mutation_prompt": null}
{"id": "fb7462de-4ab3-494f-9167-f1f34a6fd41f", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Dynamic inertia adjustment\n            self.inertia = 0.9 - 0.5 * (eval_count / self.budget)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Transformative Swarms with Dynamic Inertia - Adjust the inertia coefficient dynamically to improve convergence speed and exploration.", "configspace": "", "generation": 1, "fitness": 0.14310957439129868, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.01.", "error": "", "parent_id": "f6b28311-d8b6-4482-aeff-b6cb8bd54fd7", "metadata": {"aucs": [0.16092409479007752, 0.12725044375309458, 0.14115418463072393]}, "mutation_prompt": null}
{"id": "99638a89-d472-4079-a075-e10130c0a8e6", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = np.random.uniform(0.5, 0.9)  # Change: Introduce random inertia\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Transformative Swarms - Introduce random inertia for velocity updates to enhance exploration and avoid local optima.", "configspace": "", "generation": 2, "fitness": 0.1440550225738401, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.02.", "error": "", "parent_id": "f6b28311-d8b6-4482-aeff-b6cb8bd54fd7", "metadata": {"aucs": [0.1701013651393617, 0.1248408754667466, 0.137222827115412]}, "mutation_prompt": null}
{"id": "35d4b703-a078-46de-b1bf-193d0b6199a3", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Update inertia dynamically based on progress\n            self.inertia = 0.7 - 0.5 * (eval_count / self.budget)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Enhance the algorithm by dynamically adjusting the inertia weight based on the evaluation progress to improve exploration and exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.1614780598949526, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.02.", "error": "", "parent_id": "f6b28311-d8b6-4482-aeff-b6cb8bd54fd7", "metadata": {"aucs": [0.14334013633905984, 0.15838581041066446, 0.1827082329351335]}, "mutation_prompt": null}
{"id": "01725c5c-a193-4a9d-a201-950f22de44ce", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 - 0.5 * (eval_count / self.budget)\n            # Change: Update social coefficient dynamically based on progress\n            self.social_coef = 1.5 + 0.5 * (eval_count / self.budget)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a dynamic adaptation of the social coefficient based on progress to balance exploration and exploitation.", "configspace": "", "generation": 4, "fitness": 0.15294936974329942, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.03.", "error": "", "parent_id": "35d4b703-a078-46de-b1bf-193d0b6199a3", "metadata": {"aucs": [0.18470168631823147, 0.11901455756851931, 0.1551318653431475]}, "mutation_prompt": null}
{"id": "12d7a382-1860-42f2-914f-cec422fb4118", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 - 0.5 * (eval_count / self.budget)\n            # Change: Dynamic adjustment of population size\n            self.population_size = int(20 + 10 * (eval_count / self.budget))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a dynamic adjustment to the population size based on the evaluation progress to enhance exploration and exploitation.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "35d4b703-a078-46de-b1bf-193d0b6199a3", "metadata": {}, "mutation_prompt": null}
{"id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Incorporate a nonlinear inertia weight decay function to better balance exploration and exploitation.", "configspace": "", "generation": 6, "fitness": 0.17186566763227584, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.01.", "error": "", "parent_id": "35d4b703-a078-46de-b1bf-193d0b6199a3", "metadata": {"aucs": [0.16682253995399743, 0.16326954220862655, 0.18550492073420355]}, "mutation_prompt": null}
{"id": "668f0aac-9ff6-45c0-b904-4108442d931b", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Adaptive social coefficient\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce adaptive social coefficient to enhance global convergence by controlling social influence dynamically.", "configspace": "", "generation": 7, "fitness": 0.13711313812216908, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.04.", "error": "", "parent_id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "metadata": {"aucs": [0.19596556180081148, 0.11785654217563435, 0.0975173103900614]}, "mutation_prompt": null}
{"id": "ca850f0b-2a40-4352-9d23-90ea9eae61cc", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 + 0.5 * np.sin(2 * np.pi * eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce dynamic adjustment of the local search probability to enhance adaptation over iterations.", "configspace": "", "generation": 8, "fitness": 0.14667794527412462, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.03.", "error": "", "parent_id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "metadata": {"aucs": [0.19299435906104756, 0.12977319967280376, 0.11726627708852255]}, "mutation_prompt": null}
{"id": "af15faeb-104e-445f-95e6-422562a6af20", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n\n            # Dynamic adjustment of cognitive and social coefficients\n            self.cognitive_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            self.social_coef = 1.5 * (1 + np.cos(eval_count / self.budget * np.pi))\n\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce dynamic cognitive and social coefficients to enhance adaptability in swarm behavior.", "configspace": "", "generation": 9, "fitness": 0.14028625738678313, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.01.", "error": "", "parent_id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "metadata": {"aucs": [0.12706045580038094, 0.15519762434594742, 0.13860069201402103]}, "mutation_prompt": null}
{"id": "1f0c1fcf-e3f4-403c-b593-3f932ac60775", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Use a dynamic social coefficient\n            self.social_coef = 0.5 + 2.5 * (eval_count / self.budget)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a dynamic social coefficient to adaptively enhance convergence speed.", "configspace": "", "generation": 10, "fitness": 0.13886484659080658, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.01.", "error": "", "parent_id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "metadata": {"aucs": [0.13722606357740752, 0.14604869546691468, 0.13331978072809758]}, "mutation_prompt": null}
{"id": "ce2b15e5-5cc6-49d1-8030-b39161ece37d", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for cognitive and social coefficients\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            self.cognitive_coef = 1.5 * (1 - (eval_count / self.budget) ** 2)\n            self.social_coef = 1.5 * (1 - (eval_count / self.budget) ** 2)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a nonlinear decay for cognitive and social coefficients in addition to inertia for improved convergence.", "configspace": "", "generation": 11, "fitness": 0.14421589991653075, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.03.", "error": "", "parent_id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "metadata": {"aucs": [0.18527134823990132, 0.12974703352132955, 0.1176293179883614]}, "mutation_prompt": null}
{"id": "b853d327-0d9e-40bf-b7eb-00e9a7340db8", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Introduce diversity-based cognitive_coef variation\n            diversity = np.mean(np.std(position, axis=0))\n            self.cognitive_coef = 1.5 + 0.5 * diversity\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a dynamic personal learning coefficient influenced by swarm diversity to enhance individual learning.", "configspace": "", "generation": 12, "fitness": 0.11113539931787075, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.02.", "error": "", "parent_id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "metadata": {"aucs": [0.1375196498680692, 0.10606582060090142, 0.08982072748464165]}, "mutation_prompt": null}
{"id": "eacf2529-bc1d-48c8-bc33-40303a106143", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            self.social_coef = 1.5 + 0.5 * (eval_count / self.budget)  # Change: Variable social coefficient\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a variable social coefficient that linearly increases to improve convergence towards the global best.", "configspace": "", "generation": 13, "fitness": 0.15658195820517154, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.03.", "error": "", "parent_id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "metadata": {"aucs": [0.20508346912465658, 0.12923823600759776, 0.1354241694832603]}, "mutation_prompt": null}
{"id": "8202c992-f5d2-4de8-b468-0332370cffdf", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Dynamic cognitive coefficient adjustment based on diversity\n            self.cognitive_coef = 1.5 + 0.5 * np.std(position, axis=0).mean() / np.ptp(position, axis=0).mean()\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a dynamic cognitive coefficient to enhance adaptability based on the swarm's diversity.", "configspace": "", "generation": 14, "fitness": 0.14798775384656296, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.02.", "error": "", "parent_id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "metadata": {"aucs": [0.16377537124115993, 0.1275411288390571, 0.15264676145947187]}, "mutation_prompt": null}
{"id": "aa9520a1-c78f-4a5b-9112-109f9e88e32f", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            self.social_coef = 2 * (1 - (eval_count / self.budget))  # Time-varying social coefficient\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Implement a time-varying social coefficient to dynamically adjust the influence of the global best solution.", "configspace": "", "generation": 15, "fitness": 0.11275379834422945, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.02.", "error": "", "parent_id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "metadata": {"aucs": [0.11764312044089376, 0.13266422679101209, 0.08795404780078253]}, "mutation_prompt": null}
{"id": "2df43a07-bea1-427e-b8ab-852de10094a5", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            self.social_coef = 1.5 * (1 - (eval_count / self.budget) ** 0.5)  # Nonlinear decay for social coefficient\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a nonlinear decay for the social coefficient to enhance convergence dynamics.", "configspace": "", "generation": 16, "fitness": 0.11780648426249159, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.03.", "error": "", "parent_id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "metadata": {"aucs": [0.1561134730194258, 0.10867357507289443, 0.08863240469515454]}, "mutation_prompt": null}
{"id": "2df5cf3c-1b6c-45b7-bdde-5b7aea8ec6bf", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for cognitive and social coefficients\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            self.cognitive_coef = 1.5 * (1 - (eval_count / self.budget) ** 2)\n            self.social_coef = 1.5 * (1 - (eval_count / self.budget) ** 2)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Integrate a nonlinear decay for cognitive and social coefficients to dynamically enhance convergence.", "configspace": "", "generation": 17, "fitness": 0.14421589991653075, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.03.", "error": "", "parent_id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "metadata": {"aucs": [0.18527134823990132, 0.12974703352132955, 0.1176293179883614]}, "mutation_prompt": null}
{"id": "370fbfbb-838b-47ee-a52a-5100182d0137", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            self.social_coef = 1.5 * (1 - (eval_count / self.budget))  # Dynamic adjustment of the social coefficient\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a dynamic adjustment to the social coefficient for improved convergence by making it inversely proportional to the remaining budget.", "configspace": "", "generation": 18, "fitness": 0.12914076504662628, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.02.", "error": "", "parent_id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "metadata": {"aucs": [0.16331873070342984, 0.10887561958176961, 0.11522794485467935]}, "mutation_prompt": null}
{"id": "467c9907-47c7-44d0-abff-c802be07b223", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Incorporate a nonlinear inertia weight decay function to better balance exploration and exploitation.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "metadata": {"aucs": [0.16682253995399743, 0.16326954220862655, 0.18550492073420355]}, "mutation_prompt": null}
{"id": "cda414a2-6cdb-4218-88ba-4ff4229da6f3", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Dynamically adjust coefficients\n            self.cognitive_coef = 1.5 + 0.5 * (eval_count / self.budget)\n            self.social_coef = 1.5 - 0.5 * (eval_count / self.budget)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Enhance exploration by dynamically adjusting cognitive and social coefficients based on evaluation progress.", "configspace": "", "generation": 20, "fitness": 0.14568975545541699, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.03.", "error": "", "parent_id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "metadata": {"aucs": [0.11565240503107554, 0.19380744820329665, 0.1276094131318788]}, "mutation_prompt": null}
{"id": "901ed75f-8ae0-4e45-a607-4c9bbe918f6d", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia, cognitive, and social coefficients\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            self.cognitive_coef = 1.5 * (1 - (eval_count / self.budget) ** 0.5)\n            self.social_coef = 1.5 * (1 - (eval_count / self.budget) ** 0.5)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Integrate a nonlinear decay for cognitive and social coefficients to enhance adaptability during the optimization process.", "configspace": "", "generation": 21, "fitness": 0.12065181231825439, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.03.", "error": "", "parent_id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "metadata": {"aucs": [0.16034925892164253, 0.11522267480017434, 0.0863835032329463]}, "mutation_prompt": null}
{"id": "b884cc56-593c-490b-bc45-186da95bdcb6", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - eval_count / self.budget)  # Change: Dynamic local search probability\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a dynamic local search probability based on the evaluation count to intensify exploration during early iterations.", "configspace": "", "generation": 22, "fitness": 0.1451297525846331, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.03.", "error": "", "parent_id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "metadata": {"aucs": [0.18916024294806222, 0.1293561343947066, 0.11687288041113042]}, "mutation_prompt": null}
{"id": "2ff1d4ad-fbea-4013-a827-44c413e0b5d0", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Introduce a dynamic social coefficient\n            self.social_coef = 1.5 * (1 + (eval_count / self.budget) ** 0.5)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a dynamic social coefficient to enhance adaptability in social exploration.", "configspace": "", "generation": 23, "fitness": 0.13753075946268958, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.00.", "error": "", "parent_id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "metadata": {"aucs": [0.1423275658342794, 0.13113293249346925, 0.13913178006032012]}, "mutation_prompt": null}
{"id": "93c89fa9-f264-4133-9b04-361a2ad99e32", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Exponential decay for social coefficient\n            social_decay = np.exp(-eval_count / self.budget)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        (self.social_coef * social_decay) * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Incorporate an exponential decay for social coefficient to refine exploration and exploitation balance.", "configspace": "", "generation": 24, "fitness": 0.13861023999473795, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.03.", "error": "", "parent_id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "metadata": {"aucs": [0.17444544745344914, 0.10891955246642948, 0.1324657200643352]}, "mutation_prompt": null}
{"id": "93d56f0d-91b4-4f66-8e9b-2fbbdf031461", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Dynamic adjustment of cognitive and social coefficients\n            self.cognitive_coef = 1.5 + 0.5 * np.sin(eval_count / self.budget * np.pi)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce dynamic cognitive and social coefficients to enhance adaptability during optimization.", "configspace": "", "generation": 25, "fitness": 0.15361818683944695, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.02.", "error": "", "parent_id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "metadata": {"aucs": [0.1739996757012371, 0.12992128837905825, 0.1569335964380455]}, "mutation_prompt": null}
{"id": "292a2236-e29b-4947-9d60-a39ea312219a", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            self.social_coef = 1.5 + 0.5 * (eval_count / self.budget)  # Dynamic social coefficient\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a dynamic social coefficient to enhance convergence speed.", "configspace": "", "generation": 26, "fitness": 0.15658195820517154, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.03.", "error": "", "parent_id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "metadata": {"aucs": [0.20508346912465658, 0.12923823600759776, 0.1354241694832603]}, "mutation_prompt": null}
{"id": "15aea827-aeaf-477f-9574-65e7c1c389a3", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Adjust cognitive and social coefficients with nonlinear decay\n            self.cognitive_coef = 1.5 * (1 - (eval_count / self.budget) ** 2)\n            self.social_coef = 1.5 * (1 - (eval_count / self.budget) ** 2)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Use nonlinear decay for social and cognitive coefficients to enhance convergence.", "configspace": "", "generation": 27, "fitness": 0.14421589991653075, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.03.", "error": "", "parent_id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "metadata": {"aucs": [0.18527134823990132, 0.12974703352132955, 0.1176293179883614]}, "mutation_prompt": null}
{"id": "911a75f2-0d82-4329-ad42-e82df083ac78", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Integrate a chaotic sequence (logistic map) into inertia\n            z = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            self.inertia = z * (3.999 * self.inertia * (1 - self.inertia))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Integrate a chaotic sequence into the inertia weight formula for enhanced global search capability.", "configspace": "", "generation": 28, "fitness": 0.16096449379366232, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.04.", "error": "", "parent_id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "metadata": {"aucs": [0.21132552984656616, 0.1292903832801765, 0.1422775682542443]}, "mutation_prompt": null}
{"id": "369f937b-9a98-4b33-b6b9-81a659e0486b", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for cognitive coefficient\n            self.cognitive_coef = 1.5 * (1 - (eval_count / self.budget) ** 2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a nonlinear decay for the cognitive coefficient to enhance adaptability in dynamic environments.", "configspace": "", "generation": 29, "fitness": 0.14137460169725155, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.03.", "error": "", "parent_id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "metadata": {"aucs": [0.17705146805669958, 0.1299238885695868, 0.11714844846546824]}, "mutation_prompt": null}
{"id": "43b74e8c-e365-4f73-96df-f1eb6b1e01f0", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            # Line changed: Clamp velocity to prevent excessive step sizes\n            velocity = np.clip(velocity, -0.1 * (ub - lb), 0.1 * (ub - lb))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Integrate velocity clamping to prevent excessive step sizes and enhance convergence stability.", "configspace": "", "generation": 30, "fitness": 0.15437573479354036, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.01.", "error": "", "parent_id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "metadata": {"aucs": [0.1681920467187028, 0.15073011225556088, 0.14420504540635737]}, "mutation_prompt": null}
{"id": "97794cdc-be15-4726-b947-37e371909ae9", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Introduce random variation to inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2) * np.random.uniform(0.9, 1.1)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a random inertia variation to enhance dynamic adaptability in the exploration-exploitation balance.", "configspace": "", "generation": 31, "fitness": 0.15628410677698268, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.03.", "error": "", "parent_id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "metadata": {"aucs": [0.19928506985879824, 0.1271499265257744, 0.1424173239463754]}, "mutation_prompt": null}
{"id": "7f2831c4-7291-494c-ad98-b874a85d4eff", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Adjust the local search probability based on the iteration progress to enhance exploration when necessary.", "configspace": "", "generation": 32, "fitness": 0.18619676461773518, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.01.", "error": "", "parent_id": "ca37238f-9d00-4b14-bfed-6b431f48997d", "metadata": {"aucs": [0.17437144120439085, 0.19131743388201028, 0.19290141876680444]}, "mutation_prompt": null}
{"id": "7c7c5bdf-6921-474a-829b-e0d93d3f15e1", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(2)\n            # Change: Use nonlinear decay for both inertia and cognitive coefficient\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            self.cognitive_coef = 1.5 * (1 - (eval_count / self.budget) ** 2)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce nonlinear adaptive cognitive coefficient decay to enhance convergence towards personal bests.", "configspace": "", "generation": 33, "fitness": 0.1374562765071571, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.01.", "error": "", "parent_id": "7f2831c4-7291-494c-ad98-b874a85d4eff", "metadata": {"aucs": [0.1257080256422889, 0.1308456776402075, 0.15581512623897498]}, "mutation_prompt": null}
{"id": "5b894154-e2ce-4788-affd-f088eb5be15f", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Dynamically adjust cognitive coefficient\n            self.cognitive_coef = 1.5 + 0.5 * (eval_count / self.budget)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a dynamic cognitive coefficient that increases as iterations progress to enhance local exploitation.", "configspace": "", "generation": 34, "fitness": 0.13091918288844095, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7f2831c4-7291-494c-ad98-b874a85d4eff", "metadata": {"aucs": [0.1323079376009082, 0.13337820321257732, 0.12707140785183735]}, "mutation_prompt": null}
{"id": "0ee84002-76e6-49cb-80bb-fcafc2ea2a14", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Adapt cognitive_coef based on improvement rate\n            self.cognitive_coef = 1.5 + 0.5 * (1 - (np.mean(new_values < personal_best_value)))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a dynamic cognitive coefficient adjustment based on the success of personal best updates to enhance convergence.", "configspace": "", "generation": 35, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'new_values' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'new_values' referenced before assignment\")", "parent_id": "7f2831c4-7291-494c-ad98-b874a85d4eff", "metadata": {}, "mutation_prompt": null}
{"id": "3d5bab33-2a1a-4fcb-bde3-0ee9cafa1e41", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n        self.mutation_factor = 0.8  # New parameter for mutation\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            mutant_indices = np.random.choice(self.population_size, 3, replace=False)  # New mutation step\n            mutant_vector = position[mutant_indices[0]] + self.mutation_factor * (\n                position[mutant_indices[1]] - position[mutant_indices[2]])\n            mutant_vector = np.clip(mutant_vector, lb, ub)\n            position[-1] = mutant_vector  # Replace last position with mutant\n\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce differential evolution-inspired mutation to enhance diversity and exploration.", "configspace": "", "generation": 36, "fitness": 0.13113188936885187, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.02.", "error": "", "parent_id": "7f2831c4-7291-494c-ad98-b874a85d4eff", "metadata": {"aucs": [0.12981607198455458, 0.10326701539419492, 0.16031258072780608]}, "mutation_prompt": null}
{"id": "f558d06d-7e2b-481b-873e-c64681a0d65f", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Dynamically adjust cognitive and social coefficients\n            self.cognitive_coef = 1.5 * (1 + (eval_count / self.budget))\n            self.social_coef = 1.5 * (1 - (eval_count / self.budget))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a dynamic adjustment of cognitive and social coefficients to enhance convergence in later stages.", "configspace": "", "generation": 37, "fitness": 0.10061568600545916, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_id": "7f2831c4-7291-494c-ad98-b874a85d4eff", "metadata": {"aucs": [0.11551038122344248, 0.0951217972972005, 0.09121487949573448]}, "mutation_prompt": null}
{"id": "66ecdaf9-e0f4-41f0-a06f-3f7e767d3866", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            damping_factor = 0.9 ** (eval_count / self.budget)  # 1st line change\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += damping_factor * velocity  # 2nd line change\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a velocity damping factor that decreases over time to enhance convergence speed in later stages.", "configspace": "", "generation": 38, "fitness": 0.13514732196527346, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.01.", "error": "", "parent_id": "7f2831c4-7291-494c-ad98-b874a85d4eff", "metadata": {"aucs": [0.12517628938391223, 0.12867538073309237, 0.15159029577881578]}, "mutation_prompt": null}
{"id": "8cb54721-4432-4ade-88bc-a936bc539d6a", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            self.cognitive_coef = 1.5 * (1 - (eval_count / self.budget))  # Adaptive cognitive coefficient\n            self.social_coef = 1.5 * (1 + (eval_count / self.budget))  # Adaptive social coefficient\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce adaptive social and cognitive coefficients to improve convergence speed and performance.", "configspace": "", "generation": 39, "fitness": 0.1354633223705126, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.01.", "error": "", "parent_id": "7f2831c4-7291-494c-ad98-b874a85d4eff", "metadata": {"aucs": [0.12226048068560935, 0.1431465683090345, 0.1409829181168939]}, "mutation_prompt": null}
{"id": "33825483-bfdc-4277-bc7f-f59cbf89ebb1", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Adjust cognitive and social coefficients\n            self.cognitive_coef = 1.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.5 + 0.5 * (eval_count / self.budget)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a dynamic strategy for adjusting social and cognitive coefficients based on progress to improve balance between exploration and exploitation.", "configspace": "", "generation": 40, "fitness": 0.14185212745683715, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.01.", "error": "", "parent_id": "7f2831c4-7291-494c-ad98-b874a85d4eff", "metadata": {"aucs": [0.12851910406767764, 0.14757918484744792, 0.14945809345538585]}, "mutation_prompt": null}
{"id": "9e9e54a8-3dd7-4a2e-bc29-03649616209b", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Use a nonlinear decay for coefficients\n            self.cognitive_coef = 1.5 * (1 - (eval_count / self.budget) ** 2)\n            self.social_coef = 1.5 * (1 - (eval_count / self.budget) ** 2)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a nonlinear decay for cognitive and social coefficients to balance exploration and exploitation dynamically.", "configspace": "", "generation": 41, "fitness": 0.1306547279940664, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.01.", "error": "", "parent_id": "7f2831c4-7291-494c-ad98-b874a85d4eff", "metadata": {"aucs": [0.12406674376630111, 0.12509793984252726, 0.14279950037337086]}, "mutation_prompt": null}
{"id": "a6bcb4bd-92b9-46a3-8ada-e3a9ec609ed5", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Update: Dynamic coefficients\n            self.cognitive_coef = 1.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.5 * (eval_count / self.budget)\n\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce dynamic social and cognitive coefficients based on budget usage to adaptively control convergence.", "configspace": "", "generation": 42, "fitness": 0.15900738572703113, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.05.", "error": "", "parent_id": "7f2831c4-7291-494c-ad98-b874a85d4eff", "metadata": {"aucs": [0.11416326180430103, 0.12737164382321797, 0.23548725155357442]}, "mutation_prompt": null}
{"id": "38e5cbb0-6eaa-4724-9c05-8fb0c9a2cca0", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            self.cognitive_coef = 1.5 * (1 - (eval_count / self.budget) ** 0.5)  # Change 1\n            self.social_coef = 1.5 * (1 - (eval_count / self.budget) ** 0.5)     # Change 2\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce nonlinear scaling to the cognitive and social coefficients to enhance convergence speed and precision.", "configspace": "", "generation": 43, "fitness": 0.11328931868806025, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.02.", "error": "", "parent_id": "7f2831c4-7291-494c-ad98-b874a85d4eff", "metadata": {"aucs": [0.10801256824528638, 0.08826421292535847, 0.1435911748935359]}, "mutation_prompt": null}
{"id": "72cd3e92-4493-4e15-be0b-91a87d18d4b8", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            self.social_coef = 1.2 + 0.5 * (eval_count / self.budget)  # Change: Adaptive social coefficient\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce an adaptive social coefficient based on iteration progress to refine swarm dynamics.", "configspace": "", "generation": 44, "fitness": 0.1816963826960639, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.04.", "error": "", "parent_id": "7f2831c4-7291-494c-ad98-b874a85d4eff", "metadata": {"aucs": [0.1425861277032745, 0.1719253236397421, 0.23057769674517503]}, "mutation_prompt": null}
{"id": "fcac5a0d-3b96-443c-981b-adb376de5f03", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use nonlinear decay for inertia, cognitive and social coefficients\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            self.cognitive_coef = 1.5 * (1 - (eval_count / self.budget) ** 2)\n            self.social_coef = 1.5 * (1 - (eval_count / self.budget) ** 2)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Incorporate a nonlinear decay for cognitive and social coefficients to improve convergence dynamics.", "configspace": "", "generation": 45, "fitness": 0.1306547279940664, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.01.", "error": "", "parent_id": "7f2831c4-7291-494c-ad98-b874a85d4eff", "metadata": {"aucs": [0.12406674376630111, 0.12509793984252726, 0.14279950037337086]}, "mutation_prompt": null}
{"id": "08763e2b-d490-4723-9835-a6d90fede0ee", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Nonlinear decay for cognitive and social coefficients\n            self.cognitive_coef = 1.5 * (1 - (eval_count / self.budget) ** 2)\n            self.social_coef = 1.5 * (1 - (eval_count / self.budget) ** 2)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce nonlinear cognitive and social coefficients for improved convergence balance.", "configspace": "", "generation": 46, "fitness": 0.1306547279940664, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.01.", "error": "", "parent_id": "7f2831c4-7291-494c-ad98-b874a85d4eff", "metadata": {"aucs": [0.12406674376630111, 0.12509793984252726, 0.14279950037337086]}, "mutation_prompt": null}
{"id": "bbf22c1d-c62e-404b-95fb-b1b989f1efd4", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n        self.momentum = 0.9  # New momentum component\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Incorporate momentum into velocity update\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position) +\n                        self.momentum * velocity)  # Add momentum effect\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a momentum component to enhance the velocity update and improve convergence.", "configspace": "", "generation": 47, "fitness": 0.08968642609409638, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.02.", "error": "", "parent_id": "7f2831c4-7291-494c-ad98-b874a85d4eff", "metadata": {"aucs": [0.07685749011785825, 0.07691781218966764, 0.11528397597476325]}, "mutation_prompt": null}
{"id": "87d689d4-ebff-465d-a572-45d6e75bc7bf", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Adaptive cognitive coefficient\n            self.cognitive_coef = 1.5 * (1 - (eval_count / self.budget))\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce an adaptive cognitive coefficient that decreases over time to enhance convergence in later stages.", "configspace": "", "generation": 48, "fitness": 0.13431316520143777, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.01.", "error": "", "parent_id": "7f2831c4-7291-494c-ad98-b874a85d4eff", "metadata": {"aucs": [0.12544551566339512, 0.13682112326085083, 0.14067285668006735]}, "mutation_prompt": null}
{"id": "8ef6edc8-4116-48bc-a73e-1b5508b4c42d", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Incorporate lb and ub in velocity update dynamically\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position) +\n                        0.2 * np.random.rand(self.population_size, self.dim) * (ub - lb))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Incorporate a dynamic boundary adaptation to the velocity update for enhanced exploitation.", "configspace": "", "generation": 49, "fitness": 0.1242933113800034, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.00.", "error": "", "parent_id": "7f2831c4-7291-494c-ad98-b874a85d4eff", "metadata": {"aucs": [0.12756872149405152, 0.123654628365507, 0.12165658428045167]}, "mutation_prompt": null}
{"id": "96d73f23-41f2-4d85-ab2f-20b489a2d4c2", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.num_swarms = 3  # Split population into multiple swarms\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        \n        eval_count = self.population_size\n        iterations = 0\n\n        while eval_count < self.budget:\n            for swarm_index in range(self.num_swarms):\n                # Select swarm-specific indices\n                swarm_indices = np.array_split(np.arange(self.population_size), self.num_swarms)[swarm_index]\n                r1, r2 = np.random.rand(2)\n                # Dynamic learning coefficients\n                self.cognitive_coef = 1.5 + 0.5 * np.random.rand()\n                self.social_coef = 1.5 + 0.5 * np.random.rand()\n                \n                # Update velocity and position for the swarm\n                velocity[swarm_indices] = (self.inertia * velocity[swarm_indices] +\n                                           self.cognitive_coef * r1 * (personal_best_position[swarm_indices] - position[swarm_indices]) +\n                                           self.social_coef * r2 * (global_best_position - position[swarm_indices]))\n                position[swarm_indices] += velocity[swarm_indices]\n                position[swarm_indices] = np.clip(position[swarm_indices], lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_position = personal_best_position[np.argmin(personal_best_value)]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n            \n            # Periodic swarm merging\n            if iterations % 10 == 0:\n                global_best_position = position[np.argmin([func(ind) for ind in position])]\n\n            iterations += 1\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Enhance diversity and convergence by introducing a multi-swarm strategy with periodic merging and dynamic learning coefficients.", "configspace": "", "generation": 50, "fitness": 0.11227718317966155, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.01.", "error": "", "parent_id": "7f2831c4-7291-494c-ad98-b874a85d4eff", "metadata": {"aucs": [0.10133976890845076, 0.12758207075046357, 0.10790970988007031]}, "mutation_prompt": null}
{"id": "b0fa08fd-2003-4d9a-9e79-9bd6d2a3ceb9", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Adaptive adjustment of cognitive and social coefficients\n            self.cognitive_coef = 1.5 * (1 - (eval_count / self.budget))\n            self.social_coef = 1.5 * (eval_count / self.budget)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Implement adaptive parameter tuning for cognitive and social coefficients to balance exploration and exploitation dynamically.", "configspace": "", "generation": 51, "fitness": 0.13166657537228402, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.02.", "error": "", "parent_id": "7f2831c4-7291-494c-ad98-b874a85d4eff", "metadata": {"aucs": [0.11147555643305718, 0.13276494370831804, 0.15075922597547686]}, "mutation_prompt": null}
{"id": "c740f148-d479-4c2b-8122-643ad1b24bc8", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Adapt cognitive and social coefficients\n            self.cognitive_coef = 1.5 * (1 - (eval_count / self.budget))\n            self.social_coef = 1.5 * (eval_count / self.budget)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce dynamic adaptation of cognitive and social coefficients based on evaluation progress to balance exploration and exploitation.", "configspace": "", "generation": 52, "fitness": 0.15900738572703113, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.05.", "error": "", "parent_id": "7f2831c4-7291-494c-ad98-b874a85d4eff", "metadata": {"aucs": [0.11416326180430103, 0.12737164382321797, 0.23548725155357442]}, "mutation_prompt": null}
{"id": "fcf29aff-8fee-4b69-935d-36dbc32097b1", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            adaptive_cognitive = self.cognitive_coef * (0.5 + 0.5 * eval_count / self.budget)\n            adaptive_social = self.social_coef * (1.5 - 0.5 * eval_count / self.budget)\n            velocity = (self.inertia * velocity +\n                        adaptive_cognitive * r1 * (personal_best_position - position) +\n                        adaptive_social * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Refine velocity update with momentum and adaptive component scaling for improved convergence.", "configspace": "", "generation": 53, "fitness": 0.10957261762470365, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.03.", "error": "", "parent_id": "7f2831c4-7291-494c-ad98-b874a85d4eff", "metadata": {"aucs": [0.09439785284553259, 0.08489118079157698, 0.14942881923700135]}, "mutation_prompt": null}
{"id": "7cbf89a5-c087-4575-b759-211dfaabce16", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Adjust cognitive coefficient dynamically\n            self.cognitive_coef = 1.5 * (1 - eval_count / self.budget)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a dynamic cognitive coefficient adjustment for enhanced convergence by updating it proportionally to the remaining budget.", "configspace": "", "generation": 54, "fitness": 0.13431316520143777, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.01.", "error": "", "parent_id": "7f2831c4-7291-494c-ad98-b874a85d4eff", "metadata": {"aucs": [0.12544551566339512, 0.13682112326085083, 0.14067285668006735]}, "mutation_prompt": null}
{"id": "1076dd3f-91e2-438c-a892-1b0a03256037", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a nonlinear decay for inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * np.random.rand() * (personal_best_position - position) +  # Changed\n                        self.social_coef * np.random.rand() * (global_best_position - position))  # Changed\n            position += velocity\n            # Clamp position to bounds\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Incorporate a time-varying inertia factor and randomize cognitive and social coefficients for balanced exploration-exploitation.", "configspace": "", "generation": 55, "fitness": 0.14448882041737535, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.06.", "error": "", "parent_id": "7f2831c4-7291-494c-ad98-b874a85d4eff", "metadata": {"aucs": [0.09405975405259204, 0.11813827288616363, 0.2212684343133704]}, "mutation_prompt": null}
{"id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Use a nonlinear function for social coefficient\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introducing a nonlinear social coefficient to improve convergence by enhancing group coherence and adaptability.", "configspace": "", "generation": 56, "fitness": 0.20777130684875209, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.04.", "error": "", "parent_id": "7f2831c4-7291-494c-ad98-b874a85d4eff", "metadata": {"aucs": [0.17025655863417255, 0.25458929261286356, 0.19846806929922012]}, "mutation_prompt": null}
{"id": "b059b36c-d1e6-45aa-bdca-ca8b0ae71078", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Use a nonlinear function for social coefficient\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            # Change: Dynamic adaptation of cognitive coefficient\n            self.cognitive_coef = 1.5 + 0.5 * np.cos(eval_count / self.budget * np.pi)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Enhancing convergence by employing dynamic adaptation of the cognitive coefficient based on exploration progress.", "configspace": "", "generation": 57, "fitness": 0.15379297691324698, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.01.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.14434785478566226, 0.17260249061674193, 0.1444285853373367]}, "mutation_prompt": null}
{"id": "2d07e3fc-eeef-486d-bd0e-865028965715", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            # Change: Use a dynamic function for cognitive coefficient\n            self.cognitive_coef = 1.5 * (1 - np.cos(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introducing a dynamic cognitive coefficient to balance exploration and exploitation for improved convergence.", "configspace": "", "generation": 58, "fitness": 0.1137014701274121, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.02.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.12928215036314727, 0.09241459634591853, 0.11940766367317046]}, "mutation_prompt": null}
{"id": "6fb345c2-7ee5-437a-9d8b-092296aa1890", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a chaotic function for inertia\n            self.inertia = 0.9 - 0.7 * np.abs(np.sin(10 * np.pi * eval_count / self.budget))\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce chaotic inertial weight to enhance exploration capabilities and avoid local optima.", "configspace": "", "generation": 59, "fitness": 0.14166794465218294, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.01.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.12694747328129963, 0.15207541683696046, 0.14598094383828875]}, "mutation_prompt": null}
{"id": "8563946e-1e08-4606-a4e6-5acba5db9063", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change 1: Use a nonlinear function for cognitive coefficient\n            self.cognitive_coef = 1.5 * (1 + np.cos(eval_count / self.budget * np.pi))\n            # Change 2: Use a nonlinear function for social coefficient\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Enhance convergence by dynamically adjusting the cognitive coefficient based on a cosine function of the evaluation count.", "configspace": "", "generation": 60, "fitness": 0.11715610385194893, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.02.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.11601463518602306, 0.08973414731529561, 0.14571952905452812]}, "mutation_prompt": null}
{"id": "dfca7b37-dfca-4a55-b576-e5da86ce3644", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            self.cognitive_coef = 1.5 * (1 + np.cos(eval_count / self.budget * np.pi))  # Change 1\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Enhance convergence by dynamically adjusting cognitive and social coefficients based on evaluation progress.", "configspace": "", "generation": 61, "fitness": 0.11715610385194893, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.02.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.11601463518602306, 0.08973414731529561, 0.14571952905452812]}, "mutation_prompt": null}
{"id": "63a293af-979b-4a28-b6dc-06951cd1582b", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Introduce dynamic cognitive and social coefficients\n            self.cognitive_coef = 1.5 * (1 + np.cos(eval_count / self.budget * np.pi))\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Enhance convergence by introducing dynamic adaptation of cognitive and social coefficients based on the success of personal and global best updates.", "configspace": "", "generation": 62, "fitness": 0.11715610385194893, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.02.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.11601463518602306, 0.08973414731529561, 0.14571952905452812]}, "mutation_prompt": null}
{"id": "b6d5452d-93ad-451f-b8fc-25c41f431b4a", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.9 - 0.8 * (eval_count / self.budget)  # Change: Adaptive inertia\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Utilizing adaptive inertia to improve exploration and exploitation balance in PSO.", "configspace": "", "generation": 63, "fitness": 0.11917091716120305, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.01.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.12307438421758887, 0.10626203180399296, 0.12817633546202734]}, "mutation_prompt": null}
{"id": "b1581e76-9301-482c-8a9e-2ba5996ec69d", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Dynamically adjust cognitive coefficient\n            self.cognitive_coef = 1.5 * (1 + np.cos(eval_count / self.budget * np.pi))\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Enhanced exploration by dynamically adjusting the cognitive coefficient based on the evaluation budget.", "configspace": "", "generation": 64, "fitness": 0.11715610385194893, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.02.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.11601463518602306, 0.08973414731529561, 0.14571952905452812]}, "mutation_prompt": null}
{"id": "6181d384-0f52-4b89-bd16-915d83d874e6", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Use a nonlinear function for cognitive coefficient\n            self.cognitive_coef = 1.5 * (1 + np.cos(eval_count / self.budget * np.pi))\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Enhance the algorithm by introducing a nonlinear cognitive coefficient to balance exploration and exploitation.", "configspace": "", "generation": 65, "fitness": 0.11715610385194893, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.02.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.11601463518602306, 0.08973414731529561, 0.14571952905452812]}, "mutation_prompt": null}
{"id": "809bd869-5bd5-45d4-b6ce-bcbdda402856", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Use a nonlinear function for social and cognitive coefficients\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            self.cognitive_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi / 2))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Enhance nonlinear adaptation in social and cognitive coefficients to improve balance between exploration and exploitation.", "configspace": "", "generation": 66, "fitness": 0.1381757428995607, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.01.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.1200993719292468, 0.1483771049884679, 0.14605075178096738]}, "mutation_prompt": null}
{"id": "e3c868fe-902a-4e3f-88f6-72d06e8ce356", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * np.cos(eval_count / self.budget * np.pi / 2)  # Change: Using cosine function for inertia\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Refining the inertia adjustment to enhance convergence by making the search more dynamic and adaptive.", "configspace": "", "generation": 67, "fitness": 0.13002411667009509, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.01.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.11895327679720114, 0.13737666220986922, 0.13374241100321493]}, "mutation_prompt": null}
{"id": "1061759b-471e-4e56-aa85-4c17f1a1bf2c", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            # Change: Use an adaptive function for cognitive coefficient\n            self.cognitive_coef = 1.5 * (0.5 + 0.5 * np.cos(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introducing adaptive cognitive coefficients to enhance individual exploration based on dynamic feedback.", "configspace": "", "generation": 68, "fitness": 0.149103501142449, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.02.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.12045490786303137, 0.1701296407724321, 0.15672595479188356]}, "mutation_prompt": null}
{"id": "adcdff57-6818-42d6-a500-29303c688d47", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            self.cognitive_coef = 1.5 * (1 + 0.5 * np.cos(eval_count / self.budget * np.pi))  # Change 1\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1 + 0.05 * np.cos(eval_count / self.budget * np.pi), self.dim)  # Change 2\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Enhance convergence by dynamically adjusting the cognitive coefficient and introducing stochastic perturbations.", "configspace": "", "generation": 69, "fitness": 0.1434659378254706, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.01.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.1327173429920202, 0.14651962168760502, 0.1511608487967866]}, "mutation_prompt": null}
{"id": "49b1da68-d105-4311-a840-ebe6999538f7", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Use a refined nonlinear function for social coefficient\n            self.social_coef = 1.5 * (1 + np.cos(eval_count / self.budget * np.pi / 2))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                # Change: Adjust perturbation range for local search\n                perturbation = np.random.normal(0, 0.05, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Fine-tuning the social coefficient dynamics and local search perturbation for better convergence precision.", "configspace": "", "generation": 70, "fitness": 0.10513467645300827, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.03.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.09580276021367928, 0.07711910774293773, 0.14248216140240777]}, "mutation_prompt": null}
{"id": "957ba330-895a-4c73-9903-9672484dac04", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Dynamic cognitive coefficient adjustment\n            self.cognitive_coef = 1.5 * (1 + np.cos(eval_count / self.budget * np.pi))\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Enhance convergence by dynamically adjusting the cognitive coefficient based on the iteration progress.", "configspace": "", "generation": 71, "fitness": 0.11715610385194893, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.02.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.11601463518602306, 0.08973414731529561, 0.14571952905452812]}, "mutation_prompt": null}
{"id": "43605c8e-7b47-4435-b9fd-dae5cef73c8f", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 0.5)  # Change: Nonlinear inertia coefficient\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a nonlinear inertia coefficient to enhance exploration-exploitation balance.", "configspace": "", "generation": 72, "fitness": 0.13823999016883579, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.01.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.14074455921510953, 0.13066724014921516, 0.14330817114218264]}, "mutation_prompt": null}
{"id": "d8c2824b-e34d-471c-9bb7-d76ff92c7776", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Use a nonlinear function for social coefficient\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            self.cognitive_coef = 1.5 * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Changed line\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Enhance convergence speed and accuracy by dynamically adjusting the cognitive coefficient based on iteration progress.", "configspace": "", "generation": 73, "fitness": 0.14910350114244994, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.02.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.12045490786303137, 0.17012964077243486, 0.15672595479188356]}, "mutation_prompt": null}
{"id": "79cbe086-b77b-4058-b243-0bd708371832", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (np.sin(eval_count / self.budget * np.pi) ** 2))\n            # Change: Use a nonlinear function for social coefficient\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Enhance the swarm's adaptability by adding nonlinearity to both inertia and social coefficients.", "configspace": "", "generation": 74, "fitness": 0.13355463587179126, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.13968438274417772, 0.1295941006605834, 0.1313854242106126]}, "mutation_prompt": null}
{"id": "ecd37c85-6ba4-46b2-ba2b-acf71ac3688c", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Introduce decay factor for cognitive and social coefficients\n            decay_factor = 1.0 - (eval_count / self.budget)\n            self.cognitive_coef *= decay_factor\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introducing a decay factor to balance the influence of cognitive and social coefficients dynamically.", "configspace": "", "generation": 75, "fitness": 0.12562545280192824, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.01.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.11422692650788036, 0.1382078190847812, 0.12444161281312316]}, "mutation_prompt": null}
{"id": "97466d35-1dee-4511-b7f2-94ba074556e6", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            self.cognitive_coef = 1.5 * (1 + np.cos(eval_count / self.budget * np.pi))  # Change: dynamic cognitive coefficient\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, np.abs(ub - lb) * 0.05, self.dim)  # Change: refined perturbation\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a dynamic cognitive coefficient and refine local search perturbation to enhance exploration and exploitation balance.", "configspace": "", "generation": 76, "fitness": 0.1243444911344221, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.01.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.11717676704972757, 0.1331342173066885, 0.12272248904685024]}, "mutation_prompt": null}
{"id": "63957e4a-e724-4dd3-b058-56d13f234094", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Use a nonlinear function for social coefficient\n            self.social_coef = 1.5 * (1 + 0.5 * np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Enhanced social coefficient adaptivity for improved convergence by varying sinusoidal amplitude.", "configspace": "", "generation": 77, "fitness": 0.14881309705226772, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.02.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.12269679991173132, 0.1603035429159918, 0.16343894832908]}, "mutation_prompt": null}
{"id": "159e9298-6ed5-431c-a8a7-3693284789e4", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Adapt cognitive coefficient\n            self.cognitive_coef = 1.5 * (1 - np.cos(eval_count / self.budget * np.pi))\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introducing an adaptive cognitive coefficient for improved balance between exploration and exploitation.", "configspace": "", "generation": 78, "fitness": 0.1137014701274121, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.02.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.12928215036314727, 0.09241459634591853, 0.11940766367317046]}, "mutation_prompt": null}
{"id": "7bbfd1e3-2412-4221-ac54-21bf94f49932", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Introduce sinusoidal modulation to inertia\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2) * (1 + 0.1 * np.sin(eval_count / self.budget * np.pi))\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a sinusoidal modulation to the inertia weight to enhance exploration and exploitation balance.", "configspace": "", "generation": 79, "fitness": 0.1458720464377403, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.02.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.1237077088639078, 0.14615587495754845, 0.1677525554917646]}, "mutation_prompt": null}
{"id": "cc76e8e4-3d98-407a-9849-069f2dc26269", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Use an adaptive function for cognitive coefficient\n            self.cognitive_coef = 1.5 * (1 + (eval_count / self.budget))\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introducing an adaptive cognitive coefficient to balance exploration and exploitation dynamically.", "configspace": "", "generation": 80, "fitness": 0.1463688856953337, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.02.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.12400565256947371, 0.14311685588597678, 0.17198414863055067]}, "mutation_prompt": null}
{"id": "4f15e364-9625-49fc-b5eb-e0a53cc68b32", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - np.cos(eval_count / self.budget * np.pi))  # Updated line\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Enhance adaptation by introducing a cyclical inertia weight to balance exploration and exploitation dynamically.", "configspace": "", "generation": 81, "fitness": 0.08382928770442237, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.00.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.08026849383162626, 0.08468081979638142, 0.08653854948525941]}, "mutation_prompt": null}
{"id": "8b032402-0cf5-431f-a43f-c0716e90db05", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Use a nonlinear function for social coefficient\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            # Change: Adaptive cognitive coefficient\n            self.cognitive_coef = 1.5 * (1 - np.cos(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.05, self.dim)  # Changed standard deviation\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce adaptive cognitive coefficients and enhanced perturbation strategy for improved exploration-exploitation balance.", "configspace": "", "generation": 82, "fitness": 0.11635760331698675, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.02.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.1434860511463808, 0.08750948663911917, 0.11807727216546027]}, "mutation_prompt": null}
{"id": "d77b5049-228d-413d-ad2b-55ab9cdc868a", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            self.cognitive_coef = 1.5 * (1 + np.cos(eval_count / self.budget * np.pi))  # Change: Use a nonlinear function for cognitive coefficient\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introducing a nonlinear cognitive coefficient to enhance individual exploration and balance convergence. ", "configspace": "", "generation": 83, "fitness": 0.11715610385194893, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.02.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.11601463518602306, 0.08973414731529561, 0.14571952905452812]}, "mutation_prompt": null}
{"id": "9ed8f35a-2f9c-4a3b-bba2-e47ecce056fa", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update population size dynamically\n            self.population_size = 10 + int(10 * (1 - eval_count / self.budget))\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introducing dynamic particle count to balance exploration and exploitation over the optimization process.", "configspace": "", "generation": 84, "fitness": 0.1368562003019317, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.02.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.11983621796240063, 0.1341749060216213, 0.15655747692177324]}, "mutation_prompt": null}
{"id": "8354045c-43b1-4c68-8b62-2f9f770b78f0", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Use a nonlinear function for social coefficient\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            self.cognitive_coef = 1.5 * (1 + np.cos(eval_count / self.budget * np.pi))  # Changed line\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a cosine-based adaptive cognitive coefficient to enhance personal best exploration.", "configspace": "", "generation": 85, "fitness": 0.13191389839454584, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.02.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.13928174174352326, 0.15280344912041888, 0.10365650431969542]}, "mutation_prompt": null}
{"id": "80a4bf33-ec68-467d-9319-1f450ddb691a", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a cyclic function for inertia weight adjustment\n            self.inertia = 0.7 + 0.2 * np.sin(2 * np.pi * eval_count / self.budget)\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introducing a cyclic inertia weight adjustment to balance exploration and exploitation dynamically.", "configspace": "", "generation": 86, "fitness": 0.13912221671509706, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.01.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.12217300098389738, 0.14918557355320672, 0.14600807560818707]}, "mutation_prompt": null}
{"id": "c4920ba1-3d0a-46b7-9756-526f5f8d230f", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.9 - 0.4 * (eval_count / self.budget)  # Change: refined inertia variation\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Refining inertia variation to improve convergence by enhancing exploration-exploitation balance.", "configspace": "", "generation": 87, "fitness": 0.14104208477948768, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.02.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.16723638040283229, 0.11424789967157967, 0.14164197426405112]}, "mutation_prompt": null}
{"id": "ee6145a2-e46c-4864-8c05-43887f8a94be", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            self.cognitive_coef = 1.5 * (1 + np.cos(eval_count / self.budget * np.pi))  # Change: Adaptive cognitive coefficient\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce an adaptive cognitive coefficient based on the remaining budget to improve convergence by balancing exploration and exploitation.", "configspace": "", "generation": 88, "fitness": 0.11715610385194893, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.02.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.11601463518602306, 0.08973414731529561, 0.14571952905452812]}, "mutation_prompt": null}
{"id": "d663b8fb-2025-4f76-a3f3-f9eef4e5f70a", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Dynamic inertia adjustment\n            self.inertia = 0.9 - 0.5 * (eval_count / self.budget)\n            # Change: More aggressive social coefficient adjustment\n            self.social_coef = 0.5 + 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introducing a dynamic inertia weight adjustment strategy to balance exploration and exploitation effectively.", "configspace": "", "generation": 89, "fitness": 0.10044220648285196, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.09400843907327239, 0.08663041172557462, 0.12068776864970887]}, "mutation_prompt": null}
{"id": "bfa1a24b-4769-4cf2-bc91-e1b0b64796f3", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Use a nonlinear function for social coefficient\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            # Change: Introduce dynamic cognitive coefficient\n            self.cognitive_coef = 1.5 * np.exp(-eval_count / self.budget)\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introduce a dynamic cognitive coefficient to enhance exploration capabilities early in the search process.", "configspace": "", "generation": 90, "fitness": 0.13712675563930643, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.00.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.13904961976840757, 0.13199583021634875, 0.14033481693316296]}, "mutation_prompt": null}
{"id": "1c48b018-4e60-402a-98cd-fbf29ee60aca", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Use a nonlinear function for cognitive coefficient\n            self.cognitive_coef = 1.5 * (1 + np.cos(eval_count / self.budget * np.pi))\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Incorporate a nonlinear cognitive coefficient to foster individual exploration and prevent premature convergence.", "configspace": "", "generation": 91, "fitness": 0.11715610385194893, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.02.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.11601463518602306, 0.08973414731529561, 0.14571952905452812]}, "mutation_prompt": null}
{"id": "acc1c7e8-e2d9-4ece-953d-5e882e968528", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Use a smoothed nonlinear function for social coefficient\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi / 2))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introducing curvature correction to the social coefficient for smoother convergence trajectories and enhanced exploitation.", "configspace": "", "generation": 92, "fitness": 0.1502685385965972, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.02.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.12563705831002958, 0.1743146120889828, 0.15085394539077923]}, "mutation_prompt": null}
{"id": "c1a6fb65-36ba-4260-a121-e72ba5a02df4", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            # Change: Use a cosine function for inertia\n            self.inertia = 0.7 * (1 - np.cos((eval_count / self.budget) * np.pi / 2))\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introducing a cosine-based inertia decay to enhance exploration and exploitation balance.", "configspace": "", "generation": 93, "fitness": 0.08565979124101786, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.00.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.08395973454580496, 0.08663914019202379, 0.08638049898522482]}, "mutation_prompt": null}
{"id": "b91dde08-256d-4254-9305-fc9f9bc01ef8", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Use a nonlinear function for social coefficient\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            # Change: Dynamic cognitive coefficient adjustment\n            self.cognitive_coef = 1.5 * (1 + np.cos(eval_count / self.budget * np.pi / 2))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            # Change: Enhance local search by incorporating diversity measure\n            diversity = np.mean(np.std(position, axis=0))\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget) * diversity)\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Dynamically adjust the cognitive coefficient and enhance local search using a diversity measure for improved exploration and exploitation balance.", "configspace": "", "generation": 94, "fitness": 0.11738025144923958, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.02.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.11762029088280135, 0.08995753536177697, 0.14456292810314042]}, "mutation_prompt": null}
{"id": "d527e32a-8695-4cb9-8723-1d4a5c2a7362", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 1.5)  # Adjusted power for inertia\n            # Change: Use a nonlinear function for social coefficient\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introducing an adaptive inertia mechanism that dynamically adjusts based on current performance to improve convergence stability.", "configspace": "", "generation": 95, "fitness": 0.14932317122005226, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.03.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.11160954872466833, 0.17480795162329654, 0.16155201331219193]}, "mutation_prompt": null}
{"id": "aafcf0bd-c566-46d4-8abc-36b25013dc05", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Use a nonlinear function for cognitive coefficient\n            self.cognitive_coef = 1.5 * (1 + np.cos(eval_count / self.budget * np.pi))\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Refining velocity update by incorporating a nonlinear cognitive coefficient for enhanced exploration-exploitation balance.", "configspace": "", "generation": 96, "fitness": 0.11715610385194893, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.02.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.11601463518602306, 0.08973414731529561, 0.14571952905452812]}, "mutation_prompt": null}
{"id": "a18dda09-d2bc-4fae-aad3-3e270229ef0e", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n            # Dynamic population scaling based on progress\n            self.population_size = max(10, 20 - int(10 * (eval_count / self.budget)))\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introducing dynamic population scaling to enhance exploration capabilities.", "configspace": "", "generation": 97, "fitness": 0.12881491896182629, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.01.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.11655714918070592, 0.13484598775016476, 0.13504161995460817]}, "mutation_prompt": null}
{"id": "485689bb-2e0d-4178-a807-0e3a88829eee", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Use a nonlinear function for social coefficient\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            # Change: Adaptive cognitive coefficient\n            self.cognitive_coef = 1.5 * (1 + np.cos(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Introducing an adaptive cognitive coefficient to further enhance individual exploration and convergence.", "configspace": "", "generation": 98, "fitness": 0.1672290176531496, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.04.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.11892708314635914, 0.20817800334333458, 0.1745819664697551]}, "mutation_prompt": null}
{"id": "862d55ed-6e43-437d-af77-19fa951f6d4e", "solution": "import numpy as np\n\nclass TransformativeSwarms:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.local_search_prob = 0.3\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        velocity = np.zeros((self.population_size, self.dim))\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        personal_best_position = np.copy(position)\n        personal_best_value = np.array([func(ind) for ind in position])\n        global_best_index = np.argmin(personal_best_value)\n        global_best_position = personal_best_position[global_best_index]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Update velocity and position\n            r1, r2 = np.random.rand(2)\n            self.inertia = 0.7 * (1 - (eval_count / self.budget) ** 2)\n            # Change: Use a nonlinear function for social coefficient\n            self.social_coef = 1.5 * (1 + np.sin(eval_count / self.budget * np.pi))\n            # Change: Adapt cognitive coefficient dynamically\n            self.cognitive_coef = 1.5 * (1 + np.cos(eval_count / self.budget * np.pi))\n            velocity = (self.inertia * velocity +\n                        self.cognitive_coef * r1 * (personal_best_position - position) +\n                        self.social_coef * r2 * (global_best_position - position))\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new positions\n            new_values = np.array([func(ind) for ind in position])\n            eval_count += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if new_values[i] < personal_best_value[i]:\n                    personal_best_value[i] = new_values[i]\n                    personal_best_position[i] = position[i]\n            global_best_index = np.argmin(personal_best_value)\n            if personal_best_value[global_best_index] < func(global_best_position):\n                global_best_position = personal_best_position[global_best_index]\n\n            # Adaptive local search\n            self.local_search_prob = 0.3 * (1 - (eval_count / self.budget))\n            if np.random.rand() < self.local_search_prob:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                for i in range(self.population_size):\n                    candidate = position[i] + perturbation\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    eval_count += 1\n                    if candidate_value < personal_best_value[i]:\n                        personal_best_value[i] = candidate_value\n                        personal_best_position[i] = candidate\n\n        return global_best_position, func(global_best_position)", "name": "TransformativeSwarms", "description": "Enhance convergence by incorporating a dynamic cognitive coefficient that adapts with the evaluation count.  ", "configspace": "", "generation": 99, "fitness": 0.11715610385194893, "feedback": "The algorithm TransformativeSwarms got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.02.", "error": "", "parent_id": "2215deea-e2e6-4165-9c86-518d9bc36e7c", "metadata": {"aucs": [0.11601463518602306, 0.08973414731529561, 0.14571952905452812]}, "mutation_prompt": null}

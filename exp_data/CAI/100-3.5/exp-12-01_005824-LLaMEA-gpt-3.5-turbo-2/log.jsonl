{"id": "bb2febd2-2e87-48fe-a3b5-d707fab40340", "solution": "import numpy as np\n\nclass DE_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        def mutated_vector(pop, f):\n            idx = np.random.choice(len(pop), 3, replace=False)\n            v = pop[idx[0]] + f * (pop[idx[1]] - pop[idx[2]])\n            return np.clip(v, self.lb, self.ub)\n\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(self.lb, self.ub, (pop_size, self.dim))\n        fitness = np.array([func(p) for p in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        f = 0.5\n        cr = 0.9\n        T = 1.0\n        alpha = 0.95\n\n        for _ in range(self.budget):\n            new_pop = np.zeros_like(pop)\n            for i in range(pop_size):\n                trial = pop[i]\n                idxs = np.random.choice(pop_size, 3, replace=False)\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == np.random.randint(0, self.dim):\n                        trial[j] = pop[idxs[0], j] + f * (pop[idxs[1], j] - pop[idxs[2], j])\n                trial = np.clip(trial, self.lb, self.ub)\n                trial_fit = func(trial)\n                if trial_fit < fitness[i]:\n                    new_pop[i] = trial\n                    fitness[i] = trial_fit\n                    if trial_fit < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n                else:\n                    new_pop[i] = pop[i]\n            pop = new_pop\n\n            T *= alpha\n            T = max(T, 1e-10)\n            for i in range(self.dim):\n                diff = np.random.uniform(-0.5, 0.5)\n                best[i] += diff\n            best = np.clip(best, self.lb, self.ub)\n\n        return best", "name": "DE_SA_Optimizer", "description": "A novel metaheuristic algorithm combining Differential Evolution and Simulated Annealing for black box optimization.", "configspace": "", "generation": 0, "fitness": 0.09336171438996413, "feedback": "", "error": "", "parent_id": null, "metadata": {"aucs": [0.11869729595922507, 0.1298465856046871, 0.12409020339413857, 0.10490754823301429, 0.10750000009520266, 0.14033086257499894, 0.14304851059159085, 0.11262438091706539, 0.1052393541922545, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01800792116810701, 0.01467079663371329, 0.011343495548386096, 0.053443920870359984, 0.006592353378601756, 0.01889675139423108, 0.018248263482334326, 0.010568915803125911, 0.0168153167570696, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.007295148278382624, 9.999999999998899e-05, 0.014763392921912755, 0.011122334420502922, 9.999999999998899e-05, 0.9417548761091405, 0.9381075415814871, 0.9734377655925756, 0.9278229429152218, 0.929137769156902, 0.9295994547712189, 0.929477929266945, 0.9622099854798806, 0.9538708944597826, 0.06274794416174423, 0.03517185874499407, 0.01854735570608923, 0.020370791420354917, 0.00031549654350837564, 0.004715164052311205, 9.999999999998899e-05, 0.019027370819872158, 0.013502662907276863, 0.10027683525177622, 0.08224659834595494, 0.07731716991952875, 0.0667108215001172, 0.07285119553694963, 0.019955469917090185, 0.05895181229057489, 0.06454845572970191, 0.05658339298628068, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.025494789161176423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11797504866677266, 0.03566620381782837, 9.999999999998899e-05, 0.005866039351650754, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12510711453381596, 0.15853679216580463, 0.14838054695461433, 0.14006887564385218, 0.10274288241579344, 0.11563537713653149, 0.16269266894668322, 0.10789896016916878, 0.13956064678838864, 0.026839752686909968, 0.02170335439284732, 0.02198412468535549, 0.03266886175302153, 0.008546681902463549, 0.01759993274736349, 0.012745004268489901, 9.999999999998899e-05, 0.046108292987283694, 0.10167018036541864, 0.1365780218556496, 0.12146160590164856, 0.14716181655148453, 0.10955855208565057, 0.11363118843479647, 0.11983031616240492, 0.11047595775328822, 0.10482855072227826, 0.1330012341683129, 0.11955585942338953, 0.1613932299901244, 0.15103414963616923, 0.15285811103894975, 0.12776747127915333, 0.12533441300333015, 0.17377774300845283, 0.1223538989027384, 0.08158119108668338, 0.06765877623775252, 0.08398582550377798, 0.09103836581697466, 0.06406947898089654, 0.063885061806359, 0.0995957404652501, 0.0997711199450243, 0.1053735531966471, 0.11943364695601921, 0.10490356625092356, 0.13345086981233123, 0.12660703575522914, 0.09127925845314844, 0.11742062533349984, 0.12245976138762271, 0.0992790175597078, 0.1261963614278906, 0.14407695028516376, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12357092637913414, 9.999999999998899e-05, 9.999999999998899e-05, 0.13749006448140277, 0.08924138919047364, 0.09308080705401867, 0.10422900121341994, 0.1207914665021157, 0.09323003666907825, 0.12382803199116899, 0.10511484148144368, 0.07661518612714158, 0.11040265245322212, 0.10267165755511809, 0.08745207297453672, 0.06888028084665898, 0.06778750199173356, 0.06901873829408578, 0.09108932256270585, 0.1406390697996086, 0.11087955783622916, 0.1799060434306271, 0.19757750767214766, 0.16094140691394354, 0.17747958377502238, 0.18157202383484317, 0.17353431558484933, 0.16098139246078025, 0.1631563939127394, 0.16461313918993925, 0.041456822470361976, 0.01668912313364146, 0.031393493129599714, 0.027015293023570086, 0.03425093938292756, 0.020045516730027746, 0.017811219196668393, 0.03938502504247299, 0.039935377262259486]}, "mutation_prompt": null}
{"id": "5542ae47-a26a-448d-82d4-53c89fe62e16", "solution": "import numpy as np\n\nclass DE_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n\n    def __call__(self, func):\n        def mutated_vector(pop, f):\n            idx = np.random.choice(len(pop), 3, replace=False)\n            v = pop[idx[0]] + f * (pop[idx[1]] - pop[idx[2]])\n            return np.clip(v, self.lb, self.ub)\n\n        pop_size = 10 * self.dim\n        pop = np.random.uniform(self.lb, self.ub, (pop_size, self.dim))\n        fitness = np.array([func(p) for p in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        f = 0.5\n        cr = 0.9\n        T = 1.0\n        alpha = 0.95\n\n        for _ in range(self.budget):\n            new_pop = np.zeros_like(pop)\n            for i in range(pop_size):\n                trial = pop[i]\n                idxs = np.random.choice(pop_size, 3, replace=False)\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == np.random.randint(0, self.dim):\n                        trial[j] = pop[idxs[0], j] + f * (pop[idxs[1], j] - pop[idxs[2], j])\n                trial = np.clip(trial, self.lb, self.ub)\n                trial_fit = func(trial)\n                if trial_fit < fitness[i]:\n                    new_pop[i] = trial\n                    fitness[i] = trial_fit\n                    if trial_fit < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n                else:\n                    new_pop[i] = pop[i]\n            pop = new_pop\n\n            T *= alpha\n            T = max(T, 1e-10)\n            for i in range(self.dim):\n                diff = np.random.uniform(-0.5, 0.5)\n                best[i] += diff\n            best = np.clip(best, self.lb, self.ub)\n\n        return best", "name": "DE_SA_Optimizer", "description": "A novel metaheuristic algorithm combining Differential Evolution and Simulated Annealing for black box optimization.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "bb2febd2-2e87-48fe-a3b5-d707fab40340", "metadata": {"aucs": [0.11869729595922507, 0.1298465856046871, 0.12409020339413857, 0.10490754823301429, 0.10750000009520266, 0.14033086257499894, 0.14304851059159085, 0.11262438091706539, 0.1052393541922545, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01800792116810701, 0.01467079663371329, 0.011343495548386096, 0.053443920870359984, 0.006592353378601756, 0.01889675139423108, 0.018248263482334326, 0.010568915803125911, 0.0168153167570696, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.007295148278382624, 9.999999999998899e-05, 0.014763392921912755, 0.011122334420502922, 9.999999999998899e-05, 0.9417548761091405, 0.9381075415814871, 0.9734377655925756, 0.9278229429152218, 0.929137769156902, 0.9295994547712189, 0.929477929266945, 0.9622099854798806, 0.9538708944597826, 0.06274794416174423, 0.03517185874499407, 0.01854735570608923, 0.020370791420354917, 0.00031549654350837564, 0.004715164052311205, 9.999999999998899e-05, 0.019027370819872158, 0.013502662907276863, 0.10027683525177622, 0.08224659834595494, 0.07731716991952875, 0.0667108215001172, 0.07285119553694963, 0.019955469917090185, 0.05895181229057489, 0.06454845572970191, 0.05658339298628068, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.025494789161176423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11797504866677266, 0.03566620381782837, 9.999999999998899e-05, 0.005866039351650754, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12510711453381596, 0.15853679216580463, 0.14838054695461433, 0.14006887564385218, 0.10274288241579344, 0.11563537713653149, 0.16269266894668322, 0.10789896016916878, 0.13956064678838864, 0.026839752686909968, 0.02170335439284732, 0.02198412468535549, 0.03266886175302153, 0.008546681902463549, 0.01759993274736349, 0.012745004268489901, 9.999999999998899e-05, 0.046108292987283694, 0.10167018036541864, 0.1365780218556496, 0.12146160590164856, 0.14716181655148453, 0.10955855208565057, 0.11363118843479647, 0.11983031616240492, 0.11047595775328822, 0.10482855072227826, 0.1330012341683129, 0.11955585942338953, 0.1613932299901244, 0.15103414963616923, 0.15285811103894975, 0.12776747127915333, 0.12533441300333015, 0.17377774300845283, 0.1223538989027384, 0.08158119108668338, 0.06765877623775252, 0.08398582550377798, 0.09103836581697466, 0.06406947898089654, 0.063885061806359, 0.0995957404652501, 0.0997711199450243, 0.1053735531966471, 0.11943364695601921, 0.10490356625092356, 0.13345086981233123, 0.12660703575522914, 0.09127925845314844, 0.11742062533349984, 0.12245976138762271, 0.0992790175597078, 0.1261963614278906, 0.14407695028516376, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12357092637913414, 9.999999999998899e-05, 9.999999999998899e-05, 0.13749006448140277, 0.08924138919047364, 0.09308080705401867, 0.10422900121341994, 0.1207914665021157, 0.09323003666907825, 0.12382803199116899, 0.10511484148144368, 0.07661518612714158, 0.11040265245322212, 0.10267165755511809, 0.08745207297453672, 0.06888028084665898, 0.06778750199173356, 0.06901873829408578, 0.09108932256270585, 0.1406390697996086, 0.11087955783622916, 0.1799060434306271, 0.19757750767214766, 0.16094140691394354, 0.17747958377502238, 0.18157202383484317, 0.17353431558484933, 0.16098139246078025, 0.1631563939127394, 0.16461313918993925, 0.041456822470361976, 0.01668912313364146, 0.031393493129599714, 0.027015293023570086, 0.03425093938292756, 0.020045516730027746, 0.017811219196668393, 0.03938502504247299, 0.039935377262259486]}, "mutation_prompt": null}

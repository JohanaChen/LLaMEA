{"id": "dce2afcd-ff54-4b00-ab56-5c1f7c2630db", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n        \n        for _ in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n        \n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Adaptive Particle Swarm Optimization with Simulated Annealing (APSO-SA) that balances exploration and exploitation using temperature-based dynamics.", "configspace": "", "generation": 0, "fitness": 0.11121633870258814, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.111 with standard deviation 0.004. And the mean value of best solutions found was 0.122 (0. is the best).", "error": "", "parent_id": null, "metadata": {"aucs": [0.10723945177604366, 0.11603552479455159, 0.11037403953716918], "final_y": [0.12342659535700895, 0.11326457911246646, 0.12809132907051357]}, "mutation_prompt": null}
{"id": "c466dd73-afba-4aea-a91f-c46b1fcab3f0", "solution": "import numpy as np\n\nclass EPSOSA_AL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.w_min, self.w_max = 0.4, 0.9  # adaptive inertia weights\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 2.5\n\n    def adaptive_learning_rate(self, iteration):\n        fraction = iteration / self.iterations\n        w = self.w_max - (self.w_max - self.w_min) * fraction\n        c1 = self.c1_max - (self.c1_max - self.c1_min) * fraction\n        c2 = self.c2_min + (self.c2_max - self.c2_min) * fraction\n        return w, c1, c2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n        \n        for iter in range(self.iterations):\n            w, c1, c2 = self.adaptive_learning_rate(iter)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n            \n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "EPSOSA_AL", "description": "Enhanced Particle Swarm Optimization with Simulated Annealing and Adaptive Learning (EPSOSA-AL) incorporates adaptive parameters and neighborhood learning strategies to dynamically balance exploration and exploitation.", "configspace": "", "generation": 1, "fitness": 0.10972820466894229, "feedback": "The algorithm EPSOSA_AL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.110 with standard deviation 0.002. And the mean value of best solutions found was 0.121 (0. is the best).", "error": "", "parent_id": "dce2afcd-ff54-4b00-ab56-5c1f7c2630db", "metadata": {"aucs": [0.1089804602039608, 0.11208624605455797, 0.1081179077483081], "final_y": [0.11895017317582834, 0.11857837773939939, 0.1264132113712495]}, "mutation_prompt": null}
{"id": "8f282e49-1bcf-4054-ad74-b3d963059174", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.9  # inertia weight (changed from 0.5 to 0.9 initially)\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n        \n        for iter in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.w = 0.9 - (0.5 * (iter / self.iterations))  # dynamic inertia weight adaptation\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n        \n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhanced APSO-SA with dynamic inertia weight adaptation for improved convergence.", "configspace": "", "generation": 2, "fitness": 0.10667661378889182, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.107 with standard deviation 0.003. And the mean value of best solutions found was 0.130 (0. is the best).", "error": "", "parent_id": "dce2afcd-ff54-4b00-ab56-5c1f7c2630db", "metadata": {"aucs": [0.10305223522530027, 0.10757010313558724, 0.10940750300578794], "final_y": [0.13300417874178327, 0.1295417642889204, 0.12767031175502908]}, "mutation_prompt": null}
{"id": "6cb6b55e-232c-493b-8a19-dcaaadee9be1", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.9  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n        \n        for iteration in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.w = 0.9 - iteration * ((0.9 - 0.4) / self.iterations)  # Dynamic inertia weight\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n        \n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "APSOSA with dynamic inertia weight adjustment to enhance the balance between exploration and exploitation.", "configspace": "", "generation": 3, "fitness": 0.10667661378889182, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.107 with standard deviation 0.003. And the mean value of best solutions found was 0.130 (0. is the best).", "error": "", "parent_id": "dce2afcd-ff54-4b00-ab56-5c1f7c2630db", "metadata": {"aucs": [0.10305223522530027, 0.10757010313558724, 0.10940750300578794], "final_y": [0.13300417874178327, 0.12954176428892006, 0.12767031175502896]}, "mutation_prompt": null}
{"id": "2acdd798-3efa-4b36-89f3-7923bc54a11d", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.9  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.97  # adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n        \n        for _ in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * (1 - evals / self.budget)  # adaptive inertia weight\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n        \n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Improved APSO-SA by introducing adaptive inertia weight and a dynamic cooling schedule to enhance convergence.", "configspace": "", "generation": 4, "fitness": 0.10601474373647968, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.106 with standard deviation 0.003. And the mean value of best solutions found was 0.131 (0. is the best).", "error": "", "parent_id": "dce2afcd-ff54-4b00-ab56-5c1f7c2630db", "metadata": {"aucs": [0.10201461446581817, 0.10887356493396272, 0.10715605180965815], "final_y": [0.13845780247746042, 0.12056145254609174, 0.1341024621002872]}, "mutation_prompt": null}
{"id": "2d08d1de-61b8-4519-921e-dab0ef6999a8", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.9  # initial inertia weight\n        self.w_min = 0.4  # minimum inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iteration in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.w = self.w_min + (0.9 - self.w_min) * (1 - iteration / self.iterations)  # linearly decreasing inertia weight\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n\n            # Differential Evolution mutation\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                mutant = personal_best_positions[indices[0]] + 0.8 * (personal_best_positions[indices[1]] - personal_best_positions[indices[2]])\n                mutant = np.clip(mutant, lb, ub)\n                if func(mutant) < personal_best_scores[i]:\n                    positions[i] = mutant\n\n            positions = np.clip(positions + velocities, lb, ub)\n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhanced APSO-SA with Self-Adaptive Inertia Weight and Differential Evolution Mutations to improve convergence and exploration.", "configspace": "", "generation": 5, "fitness": 0.10379505533789923, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.104 with standard deviation 0.003. And the mean value of best solutions found was 0.138 (0. is the best).", "error": "", "parent_id": "dce2afcd-ff54-4b00-ab56-5c1f7c2630db", "metadata": {"aucs": [0.10056602467041198, 0.10846058448743723, 0.10235855685584849], "final_y": [0.14528652681486087, 0.12219761485377845, 0.14607802737316433]}, "mutation_prompt": null}
{"id": "d5d685e4-1664-41b9-8f1c-f0485036a542", "solution": "import numpy as np\n\nclass EnhancedAPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.initial_population_size = 30\n        self.max_population_size = 50\n        self.min_population_size = 20\n        self.w_max = 0.9  # maximum inertia weight\n        self.w_min = 0.4  # minimum inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.98  # slightly faster cooling\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        positions = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = population_size\n        \n        for iter in range(self.iterations):\n            w = self.w_max - ((self.w_max - self.w_min) * (iter / self.iterations))\n            r1, r2 = np.random.rand(2, population_size, self.dim)\n            velocities = (w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += population_size\n\n            for i in range(population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            self.temp *= self.cooling_rate\n            \n            population_size = int(self.min_population_size + (self.max_population_size - self.min_population_size) * (1 - iter / self.iterations))\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "EnhancedAPSOSA", "description": "Enhanced APSOSA with adaptive inertia weight and a dynamic population size strategy for improved convergence and diversity.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (50,10) (30,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (50,10) (30,10) ')", "parent_id": "dce2afcd-ff54-4b00-ab56-5c1f7c2630db", "metadata": {}, "mutation_prompt": null}
{"id": "9ebe42d6-f7ae-4ea5-961d-a0395d88e4e8", "solution": "import numpy as np\n\nclass QiEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.qubits = np.random.uniform(-np.pi, np.pi, (self.population_size, self.dim))\n        self.mutation_rate = 0.05\n        self.crossover_rate = 0.7\n        self.evals = 0\n\n    def _quantum_to_classical(self, qubits):\n        \"\"\"Convert qubits to classical representation using probability amplitudes.\"\"\"\n        positions = np.sin(qubits) ** 2\n        return positions\n\n    def _evaluate_population(self, func, positions):\n        \"\"\"Evaluate the population by converting the positions.\"\"\"\n        scores = np.array([func(positions[i]) for i in range(self.population_size)])\n        self.evals += self.population_size\n        return scores\n\n    def _selection(self, positions, scores):\n        \"\"\"Select parents based on their scores using tournament selection.\"\"\"\n        selected = []\n        for _ in range(self.population_size):\n            i, j = np.random.choice(self.population_size, 2, replace=False)\n            if scores[i] < scores[j]:\n                selected.append(positions[i])\n            else:\n                selected.append(positions[j])\n        return np.array(selected)\n\n    def _crossover(self, parent1, parent2):\n        \"\"\"Perform crossover with a defined probability.\"\"\"\n        if np.random.rand() < self.crossover_rate:\n            point = np.random.randint(1, self.dim - 1)\n            child = np.concatenate([parent1[:point], parent2[point:]])\n            return child\n        return parent1 if np.random.rand() < 0.5 else parent2\n\n    def _mutate(self, qubit):\n        \"\"\"Mutate qubit angles with a defined probability.\"\"\"\n        if np.random.rand() < self.mutation_rate:\n            qubit += np.random.uniform(-0.1, 0.1, size=self.dim)\n        return qubit\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        while self.evals < self.budget:\n            positions = np.clip(self._quantum_to_classical(self.qubits) * (ub - lb) + lb, lb, ub)\n            scores = self._evaluate_population(func, positions)\n            parents = self._selection(self.qubits, scores)\n            \n            new_qubits = []\n            for i in range(0, self.population_size, 2):\n                parent1, parent2 = parents[i], parents[i + 1]\n                child1 = self._crossover(parent1, parent2)\n                child2 = self._crossover(parent2, parent1)\n                new_qubits.extend([self._mutate(child1), self._mutate(child2)])\n            \n            self.qubits = np.array(new_qubits)\n\n            if self.evals >= self.budget:\n                break\n\n        best_index = np.argmin(scores)\n        best_position = positions[best_index]\n        best_score = scores[best_index]\n\n        return best_position, best_score", "name": "QiEA", "description": "Quantum-inspired Evolutionary Algorithm (QiEA) integrating quantum superposition and genetic operators for enhanced exploration and exploitation in optimization.", "configspace": "", "generation": 7, "fitness": 0.10728770435639667, "feedback": "The algorithm QiEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.107 with standard deviation 0.005. And the mean value of best solutions found was 0.133 (0. is the best).", "error": "", "parent_id": "dce2afcd-ff54-4b00-ab56-5c1f7c2630db", "metadata": {"aucs": [0.10617124564552793, 0.11399041912230379, 0.1017014483013583], "final_y": [0.13063763207700507, 0.11880899736280026, 0.15027218461294212]}, "mutation_prompt": null}
{"id": "fa9f6c0a-8616-4b39-87ac-1d5dee7359fa", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n        \n        for _ in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= 0.985  # Adjusted cooling rate\n        \n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhanced APSO-SA with dynamic cooling to improve convergence and performance stability.", "configspace": "", "generation": 8, "fitness": 0.11121633870258814, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.111 with standard deviation 0.004. And the mean value of best solutions found was 0.122 (0. is the best).", "error": "", "parent_id": "dce2afcd-ff54-4b00-ab56-5c1f7c2630db", "metadata": {"aucs": [0.10723945177604366, 0.11603552479455159, 0.11037403953716918], "final_y": [0.12342659535700895, 0.11326457911246646, 0.12809132907051357]}, "mutation_prompt": null}
{"id": "6d706052-00ad-4ba2-bec6-dab8d4ddcc14", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n        \n        for i in range(self.iterations):\n            # Dynamic inertia weight update\n            self.w = 0.9 - 0.5 * (i / self.iterations)  # Change made here\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n        \n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Introducing dynamic inertia weight adjustment in APSOSA to enhance convergence.", "configspace": "", "generation": 9, "fitness": 0.10667661378889182, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.107 with standard deviation 0.003. And the mean value of best solutions found was 0.130 (0. is the best).", "error": "", "parent_id": "dce2afcd-ff54-4b00-ab56-5c1f7c2630db", "metadata": {"aucs": [0.10305223522530027, 0.10757010313558724, 0.10940750300578794], "final_y": [0.13300417874178327, 0.1295417642889204, 0.12767031175502908]}, "mutation_prompt": null}
{"id": "749f42ae-1645-44dd-a22c-212460fafa82", "solution": "import numpy as np\n\nclass HybridAPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.de_F = 0.8  # differential evolution scaling factor\n        self.de_CR = 0.9  # crossover probability\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n        \n        for _ in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n            \n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = positions[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.de_F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.de_CR\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                \n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n\n                # Simulated Annealing acceptance criterion\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n        \n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "HybridAPSO_DE", "description": "Hybrid Adaptive Particle Swarm Optimization with Differential Evolution that dynamically adjusts parameters for enhanced exploration and exploitation.", "configspace": "", "generation": 10, "fitness": 0.10578826265525536, "feedback": "The algorithm HybridAPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.106 with standard deviation 0.003. And the mean value of best solutions found was 0.138 (0. is the best).", "error": "", "parent_id": "dce2afcd-ff54-4b00-ab56-5c1f7c2630db", "metadata": {"aucs": [0.10158600178247401, 0.11005993629301114, 0.10571884989028091], "final_y": [0.14863129448326207, 0.1275371018376713, 0.13839144966427752]}, "mutation_prompt": null}
{"id": "4d395157-a999-4410-874b-d42928108f71", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n        \n        for _ in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * (evals / self.budget)  # dynamic inertia weight\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n        \n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Improved APSO-SA by adjusting inertia weight dynamically to enhance adaptability and convergence.", "configspace": "", "generation": 11, "fitness": 0.10970050234893376, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.110 with standard deviation 0.003. And the mean value of best solutions found was 0.125 (0. is the best).", "error": "", "parent_id": "dce2afcd-ff54-4b00-ab56-5c1f7c2630db", "metadata": {"aucs": [0.10608161072210098, 0.11015181762089654, 0.11286807870380378], "final_y": [0.1265273290263237, 0.12957432552495962, 0.11949786680562857]}, "mutation_prompt": null}
{"id": "be22eb0b-e73e-4b36-af0c-96ce73b4f6b6", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n        \n        for _ in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions) * np.exp(-0.001 * _)) # Slight modification here\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Improved APSO-SA by enhancing velocity update for dynamic exploration and exploitation balance, yielding better convergence.", "configspace": "", "generation": 12, "fitness": 0.11308619286545656, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.003. And the mean value of best solutions found was 0.119 (0. is the best).", "error": "", "parent_id": "dce2afcd-ff54-4b00-ab56-5c1f7c2630db", "metadata": {"aucs": [0.11178807751700504, 0.11706237302967537, 0.11040812804968925], "final_y": [0.1160414794949467, 0.11202510818943368, 0.12809098970697752]}, "mutation_prompt": null}
{"id": "b432b106-2a2b-4071-b5d8-1b1d957b0ad4", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w_max = 0.9  # maximum inertia weight\n        self.w_min = 0.4  # minimum inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for t in range(self.iterations):\n            # Adaptive inertia weight\n            self.w = self.w_max - (self.w_max - self.w_min) * (t / self.iterations)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions) * np.exp(-0.001 * t))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Elite selection: retaining the best solution found\n            elite_index = np.argmin(scores)\n            if scores[elite_index] < global_best_score:\n                global_best_position = positions[elite_index]\n                global_best_score = scores[elite_index]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Refined APSOSA by integrating adaptive inertia weight and elite selection mechanism to enhance convergence without increasing complexity.", "configspace": "", "generation": 13, "fitness": 0.10844885897669461, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.108 with standard deviation 0.001. And the mean value of best solutions found was 0.123 (0. is the best).", "error": "", "parent_id": "be22eb0b-e73e-4b36-af0c-96ce73b4f6b6", "metadata": {"aucs": [0.10707518609734523, 0.10890645746756, 0.10936493336517861], "final_y": [0.12161596172995215, 0.12819303507356405, 0.11909143799733635]}, "mutation_prompt": null}
{"id": "fac1f8e9-7f38-4b40-bbd6-0b210cacf2f5", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.9  # adaptive inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.98  # enhanced cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n        \n        for t in range(self.iterations):\n            self.w = 0.9 - (0.5 * (t / self.iterations))  # Adaptive inertia weight adjustment\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions) * np.exp(-0.001 * t))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Improved APSO-SA by introducing adaptive inertia weight and enhanced cooling schedule for better convergence control.", "configspace": "", "generation": 14, "fitness": 0.10844885897669461, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.108 with standard deviation 0.001. And the mean value of best solutions found was 0.123 (0. is the best).", "error": "", "parent_id": "be22eb0b-e73e-4b36-af0c-96ce73b4f6b6", "metadata": {"aucs": [0.10707518609734523, 0.10890645746756, 0.10936493336517861], "final_y": [0.12161596172995215, 0.12819303507356405, 0.11909143799733635]}, "mutation_prompt": null}
{"id": "0a8472ca-c098-499e-b8f0-cbe4fd8fc0bc", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n        \n        for _ in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions) * np.exp(-0.001 * _)) # Slight modification here\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp) * (0.5 + 0.5 * np.random.rand())  # Modified line\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhanced global best update using stochastic acceptance to refine convergence precision.", "configspace": "", "generation": 15, "fitness": 0.11155689925491515, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.002. And the mean value of best solutions found was 0.122 (0. is the best).", "error": "", "parent_id": "be22eb0b-e73e-4b36-af0c-96ce73b4f6b6", "metadata": {"aucs": [0.11057602080995577, 0.11367715889682195, 0.11041751805796773], "final_y": [0.12551544824325322, 0.11933278768499622, 0.12076077437497024]}, "mutation_prompt": null}
{"id": "adb8ba63-12e8-419c-9272-82ac6de01733", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n        \n        for _ in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions) * np.exp(-0.001 * _)) # Slight modification here\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Refined APSOSA by modifying social coefficient adjustment to enhance adaptability in dynamic environments.", "configspace": "", "generation": 16, "fitness": 0.11308619286545656, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.003. And the mean value of best solutions found was 0.119 (0. is the best).", "error": "", "parent_id": "be22eb0b-e73e-4b36-af0c-96ce73b4f6b6", "metadata": {"aucs": [0.11178807751700504, 0.11706237302967537, 0.11040812804968925], "final_y": [0.1160414794949467, 0.11202510818943368, 0.12809098970697752]}, "mutation_prompt": null}
{"id": "71e1287e-b667-416a-b5b9-ad1c1836c1f0", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n        \n        for iteration in range(self.iterations):\n            # Adaptive inertia weight modification\n            self.w = 0.9 - (0.5 * (iteration / self.iterations))  # Adaptive inertia weight\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions) * np.exp(-0.001 * iteration))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Introduced adaptive inertia weight strategy for enhanced convergence in dynamic environments.", "configspace": "", "generation": 17, "fitness": 0.10844885897669461, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.108 with standard deviation 0.001. And the mean value of best solutions found was 0.123 (0. is the best).", "error": "", "parent_id": "be22eb0b-e73e-4b36-af0c-96ce73b4f6b6", "metadata": {"aucs": [0.10707518609734523, 0.10890645746756, 0.10936493336517861], "final_y": [0.12161596172995215, 0.12819303507356405, 0.11909143799733635]}, "mutation_prompt": null}
{"id": "2eb460b2-8e20-45b8-a877-d8b8adb64178", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n        \n        for t in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.w = 0.9 - (0.5 * (t / self.iterations))  # Adaptive inertia weight\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions) * np.exp(-0.001 * t))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhancing APSOSA by implementing adaptive inertia weight for improved convergence speed and solution precision.", "configspace": "", "generation": 18, "fitness": 0.10844885897669461, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.108 with standard deviation 0.001. And the mean value of best solutions found was 0.123 (0. is the best).", "error": "", "parent_id": "be22eb0b-e73e-4b36-af0c-96ce73b4f6b6", "metadata": {"aucs": [0.10707518609734523, 0.10890645746756, 0.10936493336517861], "final_y": [0.12161596172995215, 0.12819303507356405, 0.11909143799733635]}, "mutation_prompt": null}
{"id": "89d90869-2ae8-4610-a9a8-c9379f3bb34d", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w_max = 0.9  # max inertia weight\n        self.w_min = 0.4  # min inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n        \n        for iter_count in range(self.iterations):\n            # Adaptive inertia weight\n            self.w = self.w_max - iter_count * ((self.w_max - self.w_min) / self.iterations)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions) * np.exp(-0.001 * iter_count))\n            \n            # Differential Evolution-inspired crossover\n            rand_indices = np.random.randint(0, self.dim, self.dim)\n            crossover_mask = np.random.rand(self.population_size, self.dim) < 0.5\n            mutant_positions = positions[rand_indices] + velocities\n            trial_positions = np.where(crossover_mask, mutant_positions, positions)\n            positions = np.clip(trial_positions, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhanced APSOSA with adaptive inertia weight and differential evolution-inspired crossover for better exploration and exploitation.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (10,10) (30,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (10,10) (30,10) ')", "parent_id": "be22eb0b-e73e-4b36-af0c-96ce73b4f6b6", "metadata": {}, "mutation_prompt": null}
{"id": "4ab3ba5d-d8c1-4fab-91cc-030ad6d9deb8", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n        \n        for t in range(self.iterations):\n            # Adaptive inertia weight modification\n            self.w = 0.9 - t * ((0.9 - 0.4) / self.iterations)\n            \n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions) * np.exp(-0.001 * t)) # Slight modification here\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Introduced adaptive inertia weight for enhanced exploration and exploitation balance in APSOSA.", "configspace": "", "generation": 20, "fitness": 0.10844885897669461, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.108 with standard deviation 0.001. And the mean value of best solutions found was 0.123 (0. is the best).", "error": "", "parent_id": "be22eb0b-e73e-4b36-af0c-96ce73b4f6b6", "metadata": {"aucs": [0.10707518609734523, 0.10890645746756, 0.10936493336517861], "final_y": [0.12161596172995237, 0.1281930350735644, 0.11909143799733635]}, "mutation_prompt": null}
{"id": "a291c14e-4ae5-46d2-bb9a-795bf462106f", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.98  # changed from 0.99 to 0.98\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n        \n        for _ in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions) * np.exp(-0.001 * _)) # Slight modification here\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Slightly adjusted the cooling rate to enhance adaptive balance between exploration and exploitation.", "configspace": "", "generation": 21, "fitness": 0.11308619286545656, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.003. And the mean value of best solutions found was 0.119 (0. is the best).", "error": "", "parent_id": "be22eb0b-e73e-4b36-af0c-96ce73b4f6b6", "metadata": {"aucs": [0.11178807751700504, 0.11706237302967537, 0.11040812804968925], "final_y": [0.1160414794949467, 0.11202510818943368, 0.12809098970697752]}, "mutation_prompt": null}
{"id": "e33e2724-ce7e-4f39-b82b-9d69ebfc2ec1", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n        \n        for i in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.w = 0.4 + (0.9 - 0.4) * (1 - (i / self.iterations)) ** 2  # Adaptive inertia weight\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions) * np.exp(-0.001 * i))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            for j in range(self.population_size):\n                if scores[j] < personal_best_scores[j]:\n                    personal_best_positions[j] = positions[j]\n                    personal_best_scores[j] = scores[j]\n                    if scores[j] < global_best_score:\n                        delta = scores[j] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[j]\n                            global_best_score = scores[j]\n\n            # Non-linear cooling schedule\n            self.temp *= (1 / (1 + self.cooling_rate * np.log(1 + i)))\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhanced APSO-SA by incorporating a non-linear dynamic cooling schedule and adaptive inertia weight for improved convergence.", "configspace": "", "generation": 22, "fitness": 0.10831095293157227, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.108 with standard deviation 0.001. And the mean value of best solutions found was 0.124 (0. is the best).", "error": "", "parent_id": "be22eb0b-e73e-4b36-af0c-96ce73b4f6b6", "metadata": {"aucs": [0.10659033367680437, 0.10899797933054534, 0.10934454578736708], "final_y": [0.1215303012602269, 0.12498457361177617, 0.12494997224098514]}, "mutation_prompt": null}
{"id": "b6f45728-f498-4e46-9478-bffda5010b5d", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.9  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n        \n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.w = 0.9 - (0.5 * iter_num / self.iterations)  # dynamically adjust inertia weight\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions) * np.exp(-0.001 * iter_num))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhanced APSOSA by adjusting inertia weight dynamically for improved exploration and exploitation balance.", "configspace": "", "generation": 23, "fitness": 0.10844885897669461, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.108 with standard deviation 0.001. And the mean value of best solutions found was 0.123 (0. is the best).", "error": "", "parent_id": "be22eb0b-e73e-4b36-af0c-96ce73b4f6b6", "metadata": {"aucs": [0.10707518609734523, 0.10890645746756, 0.10936493336517861], "final_y": [0.12161596172995215, 0.12819303507356405, 0.11909143799733635]}, "mutation_prompt": null}
{"id": "67faf02d-c3d6-4d29-bd3c-223351ff351f", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.9  # Changed: adaptive inertia weight start\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n        \n        for i in range(self.iterations):\n            self.w = 0.9 - (0.5 * i / self.iterations)  # Changed: adaptive inertia weight decrease\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions) * np.exp(-0.001 * i)) # Slight modification here\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            for j in range(self.population_size):\n                if scores[j] < personal_best_scores[j]:\n                    personal_best_positions[j] = positions[j]\n                    personal_best_scores[j] = scores[j]\n                    if scores[j] < global_best_score:\n                        delta = scores[j] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[j]\n                            global_best_score = scores[j]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhanced APSOSA with adaptive inertia weight and improved velocity update for better convergence and exploration-exploitation balance.", "configspace": "", "generation": 24, "fitness": 0.10844885897669461, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.108 with standard deviation 0.001. And the mean value of best solutions found was 0.123 (0. is the best).", "error": "", "parent_id": "be22eb0b-e73e-4b36-af0c-96ce73b4f6b6", "metadata": {"aucs": [0.10707518609734523, 0.10890645746756, 0.10936493336517861], "final_y": [0.12161596172995215, 0.12819303507356405, 0.11909143799733635]}, "mutation_prompt": null}
{"id": "a11b59a8-750a-4388-91fb-101aeda7029b", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n        \n        for iteration in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.w = 0.5 + 0.4 * (1 - iteration / self.iterations)  # Dynamic inertia weight update\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions) * np.exp(-0.001 * iteration))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Introduce a dynamic inertia weight update to balance exploration and exploitation.", "configspace": "", "generation": 25, "fitness": 0.10628984990403674, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.106 with standard deviation 0.002. And the mean value of best solutions found was 0.130 (0. is the best).", "error": "", "parent_id": "be22eb0b-e73e-4b36-af0c-96ce73b4f6b6", "metadata": {"aucs": [0.10315033077503388, 0.10745675262489895, 0.1082624663121774], "final_y": [0.12956109915118208, 0.13328379740383678, 0.12754421378219827]}, "mutation_prompt": null}
{"id": "04aff84a-c269-44b7-b956-43c5ef9a0946", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.9  # inertia weight (changed from 0.5)\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.98  # cooling rate (changed from 0.99)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n        \n        for i in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions) * np.exp(-0.001 * i))\n            self.w *= 0.99  # Adaptive inertia weight (new line)\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Improved APSO-SA by introducing adaptive inertia and dynamic cooling to balance exploration and exploitation efficiently.", "configspace": "", "generation": 26, "fitness": 0.10651993163951216, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.107 with standard deviation 0.003. And the mean value of best solutions found was 0.129 (0. is the best).", "error": "", "parent_id": "be22eb0b-e73e-4b36-af0c-96ce73b4f6b6", "metadata": {"aucs": [0.10273707333532822, 0.10940955899219984, 0.10741316259100842], "final_y": [0.12487008001140132, 0.12769376187232873, 0.13375341320442014]}, "mutation_prompt": null}
{"id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhanced APSOSA with adaptive inertia, strategically updating velocities and leveraging elite-based criterion to improve convergence.", "configspace": "", "generation": 27, "fitness": 0.11422441158007568, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.000. And the mean value of best solutions found was 0.114 (0. is the best).", "error": "", "parent_id": "be22eb0b-e73e-4b36-af0c-96ce73b4f6b6", "metadata": {"aucs": [0.11388665747692484, 0.11418899207379218, 0.11459758518951002], "final_y": [0.11547117159345976, 0.11653569147733811, 0.11096526253767414]}, "mutation_prompt": null}
{"id": "4bc61c27-f499-43cb-b82a-350db29e6944", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.95  # adjusted cooling rate\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Improved APSOSA by adjusting the cooling rate to enhance exploration-exploitation balance.", "configspace": "", "generation": 28, "fitness": 0.11422441158007568, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.000. And the mean value of best solutions found was 0.114 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11388665747692484, 0.11418899207379218, 0.11459758518951002], "final_y": [0.11547117159345976, 0.11653569147733811, 0.11096526253767414]}, "mutation_prompt": null}
{"id": "97e9912e-7e63-4e6a-9d10-15fe582e84ff", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.10  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Introduce a slight increase in the cognitive coefficient `c1` to enhance individual exploration within the APSOSA algorithm.", "configspace": "", "generation": 29, "fitness": 0.11238266276167197, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.117 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11257662159530413, 0.11312417095670191, 0.11144719573300987], "final_y": [0.11801804766118107, 0.1181213108161725, 0.11631488978240745]}, "mutation_prompt": null}
{"id": "dddbb689-bb59-498e-a055-ecd2ed712e22", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 1.5  # cognitive coefficient, reduced for more exploration\n        self.c2 = 2.5  # social coefficient, increased for better convergence\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.98  # slightly modified cooling rate\n        self.elite_percentage = 0.2  # increased elite percentage for better global search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Improved APSOSA with modified elite-based strategy and adaptive learning rates for enhanced exploration and convergence.", "configspace": "", "generation": 30, "fitness": 0.11172304204175398, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.003. And the mean value of best solutions found was 0.122 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11525217405061916, 0.10834361704842621, 0.11157333502621658], "final_y": [0.11380303701052241, 0.1338148361449648, 0.11801895227073445]}, "mutation_prompt": null}
{"id": "879ad654-8ae8-4d49-8fc5-b8a4fbe92b24", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Dynamic elite percentage based on iteration\n            dynamic_elite_percentage = self.elite_percentage * (1 + iter_num / self.iterations)\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(dynamic_elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Improved APSOSA with dynamic elite percentage and stochastic velocity adjustment to enhance exploration and exploitation balance.", "configspace": "", "generation": 31, "fitness": 0.11422441158007568, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.000. And the mean value of best solutions found was 0.114 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11388665747692484, 0.11418899207379218, 0.11459758518951002], "final_y": [0.11547117159345976, 0.11653569147733811, 0.11096526253767414]}, "mutation_prompt": null}
{"id": "1fea10b6-d489-4cf1-b4b4-9ecfc09bbf61", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.97  # refined cooling rate\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            # Stochastic perturbation for exploration\n            perturbation = np.random.normal(0, 0.1, positions.shape)\n            positions += perturbation\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Refined APSOSA with adaptive cooling and stochastic perturbation, enhancing convergence in complex search landscapes.", "configspace": "", "generation": 32, "fitness": 0.11209384128744244, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.003. And the mean value of best solutions found was 0.120 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11624863340675862, 0.1110966605910223, 0.10893622986454643], "final_y": [0.11160156570740443, 0.12310369006195576, 0.1259025965690701]}, "mutation_prompt": null}
{"id": "501b8927-5f92-4f9c-83b9-b0a4dc891af2", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.1  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Modify the cognitive coefficient to enhance the balance between exploration and exploitation.", "configspace": "", "generation": 33, "fitness": 0.11238266276167197, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.117 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11257662159530413, 0.11312417095670191, 0.11144719573300987], "final_y": [0.11801804766118107, 0.1181213108161725, 0.11631488978240745]}, "mutation_prompt": null}
{"id": "c36f7581-f428-41da-8fac-1a64ba0c07ea", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.1  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Slightly increased the cognitive coefficient (c1) to 2.1 for enhancing local exploration in APSOSA.", "configspace": "", "generation": 34, "fitness": 0.11238266276167197, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.117 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11257662159530413, 0.11312417095670191, 0.11144719573300987], "final_y": [0.11801804766118107, 0.1181213108161725, 0.11631488978240745]}, "mutation_prompt": null}
{"id": "96631ebe-701c-4378-bb3e-f6b283bc18e7", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n        self.quorum_factor = 0.2  # added quorum factor for selection\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            velocities = np.clip(velocities, -0.5, 0.5)  # dynamic velocity capping\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Quorum-based and Simulated Annealing acceptance criterion\n            quorum_count = int(self.quorum_factor * self.population_size)\n            for i in range(quorum_count):  # applying quorum criterion\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Introduced a quorum-based selection mechanism with dynamic velocity capping to balance exploration and exploitation, enhancing APSOSA's convergence.", "configspace": "", "generation": 35, "fitness": 0.09504866676837727, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.095 with standard deviation 0.005. And the mean value of best solutions found was 0.172 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.08835388139566192, 0.09666053607664626, 0.10013158283282364], "final_y": [0.19213000909556865, 0.1694356726745122, 0.15420248356927446]}, "mutation_prompt": null}
{"id": "477d980d-9dfb-466e-8469-a9b46dcef02a", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n            # Replace worst elite with global best if it's better\n            if scores[sorted_indices[-1]] > global_best_score:  \n                positions[sorted_indices[-1]] = global_best_position\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Introduce an elite replacement mechanism to enhance global best updating in APSOSA.", "configspace": "", "generation": 36, "fitness": 0.11330483649223551, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.118 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11384447833492473, 0.1140900370532889, 0.1119799940884929], "final_y": [0.11440559664607697, 0.11700153820720904, 0.1212308892490026]}, "mutation_prompt": null}
{"id": "e503c7d0-aef1-4a68-a718-3fe5862ba614", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.1  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.15  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Refinement of APSOSA by enhancing cognitive coefficient and elite selection for improved convergence.", "configspace": "", "generation": 37, "fitness": 0.11366150423251409, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.001. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11366684244133274, 0.11261731472505332, 0.1147003555311562], "final_y": [0.11543920501735316, 0.11943535052807597, 0.1135394068789497]}, "mutation_prompt": null}
{"id": "5cb02c81-0304-4e89-9795-4801d572b284", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int((self.elite_percentage + 0.05 * (iter_num / self.iterations)) * self.population_size))  # adaptive elite percentage\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Improved APSOSA with adaptive elite percentage for enhanced convergence.", "configspace": "", "generation": 38, "fitness": 0.11422441158007568, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.000. And the mean value of best solutions found was 0.114 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11388665747692484, 0.11418899207379218, 0.11459758518951002], "final_y": [0.11547117159345976, 0.11653569147733811, 0.11096526253767414]}, "mutation_prompt": null}
{"id": "d93aa1d6-72ba-448c-9ae7-f647f889c467", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i] + np.random.uniform(-0.1, 0.1, self.dim)\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Improved global best update strategy by introducing randomness for better exploration and convergence.", "configspace": "", "generation": 39, "fitness": 0.11035667843339288, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.110 with standard deviation 0.001. And the mean value of best solutions found was 0.124 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.10878138166144424, 0.11015500503656694, 0.11213364860216746], "final_y": [0.12682183444804962, 0.1267226154908596, 0.11837933802538525]}, "mutation_prompt": null}
{"id": "1f28d7d0-d2c6-4597-a4ca-3ee79ca132f6", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.97  # adjusted cooling rate\n        self.elite_percentage = 0.15  # increased elite percentage for criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            dynamic_c2 = self.c2 * (0.5 + 0.5 * np.sin(iter_num / 10))  # dynamic social coefficient\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          dynamic_c2 * r2 * (global_best_position - positions))\n            stochastic_reset = np.random.rand(self.population_size, self.dim) < 0.01\n            velocities[stochastic_reset] = np.random.uniform(-1, 1, (np.sum(stochastic_reset), self.dim))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhanced APSOSA with dynamic social coefficient, stochastic velocity reset, and adaptive elite criterion for improved convergence.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "An exception occurred: TypeError('NumPy boolean array indexing assignment requires a 0 or 1-dimensional input, input has 2 dimensions').", "error": "TypeError('NumPy boolean array indexing assignment requires a 0 or 1-dimensional input, input has 2 dimensions')", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {}, "mutation_prompt": null}
{"id": "897edb85-c01e-4751-8b3b-cddcdce69263", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Dynamically adjust elite percentage based on convergence\n            self.elite_percentage = 0.1 + 0.4 * (1 - iter_num / self.iterations)\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhanced APSOSA with dynamic elite percentage based on convergence to improve exploration and exploitation balance.", "configspace": "", "generation": 41, "fitness": 0.11360988156085013, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.001. And the mean value of best solutions found was 0.117 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11264415238111991, 0.114856521745472, 0.11332897055595847], "final_y": [0.11646671367578931, 0.11543409615697653, 0.11857237242716412]}, "mutation_prompt": null}
{"id": "5410830a-0b26-49a0-ad35-9d1ee67d1eff", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.initial_population_size = 30\n        self.final_population_size = 10\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.initial_temp = 100  # initial temperature for simulated annealing\n        self.final_temp = 1  # final temperature\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        temp = self.initial_temp\n        positions = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = population_size\n\n        for iter_num in range(self.iterations):\n            # Dynamic population size\n            population_size = int(self.initial_population_size - \n                                  (self.initial_population_size - self.final_population_size) * \n                                  (iter_num / self.iterations))\n            r1, r2 = np.random.rand(2, population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Adaptive cooling\n            temp = self.initial_temp * (self.final_temp / self.initial_temp) ** (iter_num / self.iterations)\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Refined APSOSA introduces a dynamic population size and adaptive cooling rate to enhance exploration and convergence balance.", "configspace": "", "generation": 42, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (29,10) (30,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (29,10) (30,10) ')", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {}, "mutation_prompt": null}
{"id": "de8447e6-3b4c-49ab-b5ea-632343f45693", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.temp = 100\n        self.cooling_rate = 0.95  # Adjusted cooling rate\n        self.elite_percentage = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Dynamic neighborhood search\n            for i in range(self.population_size):\n                neighbors = np.random.choice(range(self.population_size), size=5, replace=False)\n                best_neighbor = min(neighbors, key=lambda x: personal_best_scores[x])\n                if personal_best_scores[best_neighbor] < personal_best_scores[i]:\n                    personal_best_positions[i] = personal_best_positions[best_neighbor]\n                    personal_best_scores[i] = personal_best_scores[best_neighbor]\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Refined APSOSA with dynamic population size and enhanced local exploration using dynamic neighborhood search.", "configspace": "", "generation": 43, "fitness": 0.10855678255074049, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.109 with standard deviation 0.008. And the mean value of best solutions found was 0.134 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.09703709959454199, 0.11546789546949765, 0.11316535258818183], "final_y": [0.16477603453767298, 0.11633571555766109, 0.119674524907461]}, "mutation_prompt": null}
{"id": "9e765afa-6897-4692-873a-3eb3626a5705", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.98  # Adjusted cooling rate\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Improved APSOSA by adjusting the cooling rate for simulated annealing to enhance exploration and convergence.", "configspace": "", "generation": 44, "fitness": 0.11422441158007568, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.000. And the mean value of best solutions found was 0.114 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11388665747692484, 0.11418899207379218, 0.11459758518951002], "final_y": [0.11547117159345976, 0.11653569147733811, 0.11096526253767414]}, "mutation_prompt": null}
{"id": "aa427941-23de-4c90-8dbc-1ade61308641", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * np.exp(-iter_num / self.iterations)  # change 1: adjusted inertia decay\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count // 2]:  # change 2: refine elite update by considering half elites\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Tweaked inertia weight decay and elite-based update to enhance exploration-exploitation balance in APSOSA.", "configspace": "", "generation": 45, "fitness": 0.11040045185134269, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.110 with standard deviation 0.002. And the mean value of best solutions found was 0.123 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.1127959569204322, 0.10835359835427816, 0.11005180027931771], "final_y": [0.11186132403358673, 0.13231390163873402, 0.12467345078775505]}, "mutation_prompt": null}
{"id": "f72df6be-4a96-4900-a657-81c8a0365f79", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n\n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            if iter_num > self.iterations // 2:  # Dynamic elite percentage adjustment\n                elite_count = max(1, int(0.2 * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Refined APSOSA with dynamic elite percentage and enhanced exploitation.", "configspace": "", "generation": 46, "fitness": 0.11422441158007568, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.000. And the mean value of best solutions found was 0.114 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11388665747692484, 0.11418899207379218, 0.11459758518951002], "final_y": [0.11547117159345976, 0.11653569147733811, 0.11096526253767414]}, "mutation_prompt": null}
{"id": "24faffbb-a1b3-47a7-b9dd-a0b689a0c84d", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            self.elite_percentage = 0.1 + 0.1 * (iter_num / self.iterations)  # dynamically adjust elite percentage\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhanced APSOSA with dynamic elite percentage to improve convergence rate by allowing more exploration or exploitation based on progress.", "configspace": "", "generation": 47, "fitness": 0.11422441158007568, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.000. And the mean value of best solutions found was 0.114 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11388665747692484, 0.11418899207379218, 0.11459758518951002], "final_y": [0.11547117159345976, 0.11653569147733811, 0.11096526253767414]}, "mutation_prompt": null}
{"id": "7a744b17-f699-41b0-b3ba-b0e3019e1bf3", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.98  # line changed from 0.99 to 0.98\n        self.elite_percentage = 0.2  # line changed from 0.1 to 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = 0.9 - 0.7 * (iter_num / self.iterations)  # line changed for dynamic inertia\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / (self.temp * (iter_num / self.iterations + 1)))  # line changed for dynamic temperature scaling\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Improved APSOSA by adjusting inertia, introducing dynamic temperature scaling, and enhancing elite-based selection to boost convergence and exploration.", "configspace": "", "generation": 48, "fitness": 0.10836111591455684, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.108 with standard deviation 0.000. And the mean value of best solutions found was 0.122 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.10853555086601907, 0.10817105795092952, 0.10837673892672195], "final_y": [0.12533958783106136, 0.12271958233518188, 0.11723707589708754]}, "mutation_prompt": null}
{"id": "c4e1185a-2239-4127-b318-71bdddae0e99", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Dynamic population size adjustment\n            self.population_size = max(10, int(30 * (1 - iter_num / self.iterations)))\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Improved APSOSA with dynamic population size adjustment to enhance exploration and convergence balance.", "configspace": "", "generation": 49, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (29,10) (30,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (29,10) (30,10) ')", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {}, "mutation_prompt": null}
{"id": "2ae3806c-e9d8-41e4-8b0f-1efdffd40b82", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.95  # Modified cooling rate\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Improved APSOSA by optimizing the cooling rate for enhanced convergence.", "configspace": "", "generation": 50, "fitness": 0.11422441158007568, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.000. And the mean value of best solutions found was 0.114 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11388665747692484, 0.11418899207379218, 0.11459758518951002], "final_y": [0.11547117159345976, 0.11653569147733811, 0.11096526253767414]}, "mutation_prompt": null}
{"id": "58e6383f-4d65-4220-8df9-876216295c8c", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1_initial = 2.05  # initial cognitive coefficient\n        self.c2_initial = 2.05  # initial social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            c1 = self.c1_initial * (1 - iter_num / self.iterations)  # dynamic cognitive coefficient\n            c2 = self.c2_initial * (iter_num / self.iterations)  # dynamic social coefficient\n            velocities = (adaptive_w * velocities +\n                          c1 * r1 * (personal_best_positions - positions) +\n                          c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhanced APSOSA with dynamic cognitive and social coefficients based on iteration progress to improve convergence.", "configspace": "", "generation": 51, "fitness": 0.10002155284534087, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.100 with standard deviation 0.003. And the mean value of best solutions found was 0.145 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.09620618299717443, 0.10154377141652215, 0.10231470412232602], "final_y": [0.139103800411418, 0.1497232153466037, 0.14504244354716367]}, "mutation_prompt": null}
{"id": "07bf18ec-602f-46ae-982e-c033bbd3d3cc", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.95  # changed from 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / (self.temp + iter_num))  # added dynamic scaling\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhanced APSOSA with adaptive inertia and dynamic temperature scaling for improved convergence and exploration.", "configspace": "", "generation": 52, "fitness": 0.11422441158007568, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.000. And the mean value of best solutions found was 0.114 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11388665747692484, 0.11418899207379218, 0.11459758518951002], "final_y": [0.11547117159345976, 0.11653569147733811, 0.11096526253767414]}, "mutation_prompt": null}
{"id": "e9f352da-96cc-4b13-bf17-8682f176db52", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n        self.learning_rate_decay = 0.995  # adaptive learning rate decay\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]: \n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i] * self.learning_rate_decay  # decay applied\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n                        else:\n                            personal_best_positions[i] = positions[i]  # reset if not improving\n\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Improved APSOSA with adaptive learning rates and personal-best history reset for enhanced exploration and exploitation balance.", "configspace": "", "generation": 53, "fitness": 0.1132862875327882, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.000. And the mean value of best solutions found was 0.117 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.1133534117988585, 0.11277568673805083, 0.1137297640614553], "final_y": [0.11593994236452942, 0.11721086984138285, 0.11657855614547397]}, "mutation_prompt": null}
{"id": "acf2a8d5-5802-4da9-9d25-f3f3e47ac012", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            # Chaotic sequence for enhanced exploration\n            chaotic_sequence = np.sin(iter_num * np.pi * (1 / self.iterations))\n            velocities += chaotic_sequence * np.random.uniform(-1, 1, (self.population_size, self.dim))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Refined APSOSA with enhanced exploration via chaotic sequences to improve solution diversity.", "configspace": "", "generation": 54, "fitness": 0.11187550490524804, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.119 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11103032212279806, 0.11121128271320979, 0.11338490987973626], "final_y": [0.12053178077308135, 0.12128661739926827, 0.1149562119942178]}, "mutation_prompt": null}
{"id": "e1eddf6a-b38d-4469-bb95-d0871d652349", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-2, 2, (self.population_size, self.dim))  # changed line\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Improved exploration by initializing velocities with a larger range to enhance search space coverage.", "configspace": "", "generation": 55, "fitness": 0.1135047471482089, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.001. And the mean value of best solutions found was 0.115 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11221201488069676, 0.11463714847140838, 0.11366507809252158], "final_y": [0.1164784626834725, 0.11684000036993236, 0.11266903995910216]}, "mutation_prompt": null}
{"id": "732eb810-c0f7-42e8-ba3c-36180de146fd", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.98  # modified cooling rate\n        self.elite_percentage = 0.15  # modified elite percentage\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Modified Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]: \n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / (self.temp + np.random.rand()))  # stochastic element added\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Adaptive cooling based on iterations\n            self.temp *= self.cooling_rate + 0.01 * (iter_num / self.iterations)\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Introducing Adaptive Cooling and Stochastic Elite Selection in APSOSA to enhance exploration and exploitation balance.", "configspace": "", "generation": 56, "fitness": 0.11313359726834049, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.002. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.1139191265684637, 0.11102566024770988, 0.11445600498884789], "final_y": [0.1108986871760197, 0.12531451236011648, 0.11277947187152526]}, "mutation_prompt": null}
{"id": "c9601a9b-5364-49ad-8bf6-ac18d7a13834", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.98  # slightly increased cooling rate\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhanced APSOSA with adaptive inertia and dynamic cooling rate, leveraging elite-based criterion for improved global search.", "configspace": "", "generation": 57, "fitness": 0.11422441158007568, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.000. And the mean value of best solutions found was 0.114 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11388665747692484, 0.11418899207379218, 0.11459758518951002], "final_y": [0.11547117159345976, 0.11653569147733811, 0.11096526253767414]}, "mutation_prompt": null}
{"id": "9d1b54b4-6da3-470d-bc6a-6b1ac2117665", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.995  # changed cooling rate for slower cooling\n        self.elite_percentage = 0.15  # increased elite percentage for better exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Introduced a dynamic cooling schedule and adjusted elite acceptance to enhance global exploration and convergence reliability.", "configspace": "", "generation": 58, "fitness": 0.11280112103284756, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.118 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11337203293919185, 0.11318270724720225, 0.11184862291214859], "final_y": [0.11618317244560239, 0.11641275893063063, 0.12043713671734968]}, "mutation_prompt": null}
{"id": "476055ac-1139-4994-8b1b-b6e3c97b52fd", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            adaptive_c1 = self.c1 * (1 - iter_num / self.iterations)  # dynamic cognitive coefficient\n            adaptive_c2 = self.c2 * (1 + iter_num / self.iterations)  # dynamic social coefficient\n            velocities = (adaptive_w * velocities +\n                          adaptive_c1 * r1 * (personal_best_positions - positions) +\n                          adaptive_c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Incorporate dynamic cognitive and social coefficients to enhance exploration and exploitation balance.", "configspace": "", "generation": 59, "fitness": 0.11325141829130696, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.117 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11420935625182094, 0.11303297481086594, 0.11251192381123398], "final_y": [0.11288476926485658, 0.11827410484845513, 0.11884593060228965]}, "mutation_prompt": null}
{"id": "cad34ac9-5e5f-46d6-913f-757a252be0cb", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.98  # slightly increased cooling rate\n        self.elite_percentage = 0.15  # increased elite percentage\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * np.cos(iter_num / self.iterations * np.pi / 2)  # nonlinear inertia update\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhanced APSOSA with adaptive elitism and nonlinear inertia update to balance exploration and exploitation.", "configspace": "", "generation": 60, "fitness": 0.11230048979177558, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.117 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11116671590848803, 0.11413877182998311, 0.11159598163685558], "final_y": [0.11656720600445947, 0.11643536508361352, 0.11889902372840544]}, "mutation_prompt": null}
{"id": "a0a15477-0193-4962-8fbd-21f409f454b5", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # initial cognitive coefficient\n        self.c2 = 2.05  # initial social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            adaptive_c1 = self.c1 * (1 - iter_num / self.iterations)  # adaptive cognitive coefficient\n            adaptive_c2 = self.c2 * (iter_num / self.iterations)  # adaptive social coefficient\n            velocities = (adaptive_w * velocities +\n                          adaptive_c1 * r1 * (personal_best_positions - positions) +\n                          adaptive_c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            # Dynamic population resizing\n            if iter_num % 10 == 0 and self.population_size > 10: \n                self.population_size = max(10, self.population_size - 5)\n                positions = positions[:self.population_size]\n                velocities = velocities[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Improved APSOSA by introducing adaptive cognitive and social coefficients, and integrating dynamic population resizing to enhance convergence efficiency.", "configspace": "", "generation": 61, "fitness": 0.10328750587054662, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.103 with standard deviation 0.002. And the mean value of best solutions found was 0.123 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.10027677376817135, 0.10529158297940922, 0.1042941608640593], "final_y": [0.12764029053804182, 0.12258538496243632, 0.11795001207588973]}, "mutation_prompt": null}
{"id": "60293ace-b802-4c58-ba16-d87261766775", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.15  # changed elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = np.clip(adaptive_w * velocities +\n                                 self.c1 * r1 * (personal_best_positions - positions) +\n                                 self.c2 * r2 * (global_best_position - positions), -0.5, 0.5)  # dynamic velocity bounds\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhanced APSOSA with adaptive exploration and exploitation through dynamic velocity bounds and improved elite selection.", "configspace": "", "generation": 62, "fitness": 0.09469663641436998, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.095 with standard deviation 0.005. And the mean value of best solutions found was 0.171 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.08839756318926806, 0.09666053607664626, 0.09903180997719563], "final_y": [0.18360783719661888, 0.1694356726745122, 0.15961638913783138]}, "mutation_prompt": null}
{"id": "7a1497d2-a09a-467b-a5c9-0305342268f5", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / (self.temp * np.log(iter_num + 2)))  # Changed line\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhanced APSOSA with a refined elite-based criterion using logarithmic cooling for improved exploitation-exploration balance.", "configspace": "", "generation": 63, "fitness": 0.11422441158007568, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.000. And the mean value of best solutions found was 0.114 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11388665747692484, 0.11418899207379218, 0.11459758518951002], "final_y": [0.11547117159345976, 0.11653569147733811, 0.11096526253767414]}, "mutation_prompt": null}
{"id": "9ab9a86b-55de-4ad2-b234-c3c4b20bc369", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.initial_population_size = 30\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n\n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Adaptive local search\n            elite_indices = np.argsort(scores)[:int(self.elite_percentage * self.population_size)]\n            for i in elite_indices:\n                local_search_position = positions[i] + 0.1 * np.random.randn(self.dim)\n                local_search_position = np.clip(local_search_position, lb, ub)\n                local_search_score = func(local_search_position)\n                evals += 1\n                if local_search_score < scores[i]:\n                    positions[i] = local_search_position\n                    scores[i] = local_search_score\n\n            # Simulated Annealing acceptance criterion\n            for i in elite_indices:\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Dyn. population resizing\n            if iter_num % 10 == 0 and self.population_size > 5:\n                self.population_size -= 1\n                positions = positions[:self.population_size]\n                velocities = velocities[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Improved APSOSA with adaptive local search and dynamic population resizing, enhancing exploration and exploitation balance.", "configspace": "", "generation": 64, "fitness": 0.11220658230029505, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.121 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11170123456402037, 0.11093892046332066, 0.11397959187354412], "final_y": [0.1200001549158386, 0.12388948877466532, 0.11908159877073776]}, "mutation_prompt": null}
{"id": "3ce2db2d-d3ab-403b-9fb9-78a050626965", "solution": "import numpy as np\n\nclass HybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.levy_scale = 0.1  # scale for Lévy flight\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / abs(v) ** (1 / beta)\n        return step * self.levy_scale\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            # Apply Lévy flight mutation to enhance exploration\n            mutation_mask = np.random.rand(self.population_size, self.dim) < 0.1\n            levy_steps = self.levy_flight((self.population_size, self.dim))\n            positions += mutation_mask * levy_steps\n            positions = np.clip(positions, lb, ub)\n\n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = scores[i]\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "HybridPSOLevy", "description": "Hybrid Particle Swarm Optimization with Lévy Flight Mutation, introducing random jumps to escape local minima and enhance exploration capabilities.", "configspace": "", "generation": 65, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {}, "mutation_prompt": null}
{"id": "77444490-01f3-43df-ad48-f5ea156ebf62", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.10  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Improve convergence by slightly increasing the cognitive coefficient.", "configspace": "", "generation": 66, "fitness": 0.11238266276167197, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.117 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11257662159530413, 0.11312417095670191, 0.11144719573300987], "final_y": [0.11801804766118107, 0.1181213108161725, 0.11631488978240745]}, "mutation_prompt": null}
{"id": "d9ba4240-28dd-45ff-99f9-1ed28a095ade", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.97  # adjusted cooling rate\n        self.elite_percentage = 0.15  # adjusted elite percentage\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Improved APSOSA by fine-tuning elite percentage and decay rates for enhanced convergence performance.", "configspace": "", "generation": 67, "fitness": 0.11280112103284756, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.118 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11337203293919185, 0.11318270724720225, 0.11184862291214859], "final_y": [0.11618317244560239, 0.11641275893063063, 0.12043713671734968]}, "mutation_prompt": null}
{"id": "ed19a65c-962f-481a-95a3-a68d8684912f", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.1  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Improved APSOSA by slightly increasing the cognitive coefficient to enhance individual exploration.", "configspace": "", "generation": 68, "fitness": 0.11238266276167197, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.117 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11257662159530413, 0.11312417095670191, 0.11144719573300987], "final_y": [0.11801804766118107, 0.1181213108161725, 0.11631488978240745]}, "mutation_prompt": null}
{"id": "cae193dc-f5e3-4969-901e-9d9b20060ead", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.97  # changed cooling rate\n        self.elite_percentage = 0.05  # reduced elite percentage\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            sorted_indices = np.argsort(scores)\n            dynamic_elite_count = max(1, int((self.elite_percentage + iter_num/self.iterations * 0.05) * self.population_size))\n            for i in sorted_indices[:dynamic_elite_count]:  # apply acceptance to dynamic elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhanced APSOSA with dynamic elite selection and nonlinear cooling strategy to improve exploration and convergence.", "configspace": "", "generation": 69, "fitness": 0.10993209360759774, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.110 with standard deviation 0.001. And the mean value of best solutions found was 0.125 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11145317373224817, 0.1083699588038135, 0.10997314828673155], "final_y": [0.11862483037151106, 0.1318579717480547, 0.12491318539705287]}, "mutation_prompt": null}
{"id": "b849b6ca-2cd3-4ae2-936e-d44eaa02ae32", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.95  # adaptive cooling rate\n        self.elite_percentage = 0.05  # dynamic elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Dynamic elite selection\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Adaptive cooling\n            if iter_num < self.iterations // 2:\n                self.temp *= self.cooling_rate\n            else:\n                self.temp *= (self.cooling_rate + 0.01)\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "APSOSA with dynamic elite selection and adaptive cooling to enhance convergence precision and robustness.", "configspace": "", "generation": 70, "fitness": 0.10993209360759774, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.110 with standard deviation 0.001. And the mean value of best solutions found was 0.125 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11145317373224817, 0.1083699588038135, 0.10997314828673155], "final_y": [0.11862483037151106, 0.1318579717480547, 0.12491318539705287]}, "mutation_prompt": null}
{"id": "c6b65e1e-fda4-4f93-9c17-cd36256f63d7", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.temp = 100\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Dynamic elite percentage based on progress\n            current_elite_percentage = self.elite_percentage * (1 - iter_num / self.iterations)\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(current_elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Refined APSOSA with dynamic elite selection, adjusting the elite percentage based on iteration progress to enhance exploration-exploitation balance.", "configspace": "", "generation": 71, "fitness": 0.11241528107981687, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.118 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11367155212719116, 0.11174264190486471, 0.11183164920739475], "final_y": [0.11567261341367252, 0.1168683870438495, 0.12215868440642619]}, "mutation_prompt": null}
{"id": "f4af48d4-927a-457c-a294-6e5a24dc6ba3", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - (iter_num / self.iterations)**2)  # nonlinear decay for inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Fine-tune the adaptive inertia formula using a nonlinear decay function for improved convergence rate.", "configspace": "", "generation": 72, "fitness": 0.11369703724563489, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.000. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.1139408469583022, 0.11321714764473712, 0.11393311713386534], "final_y": [0.11547151383071474, 0.1170778112175318, 0.11443919643436729]}, "mutation_prompt": null}
{"id": "77c06efd-d6d0-443d-a1f7-25f1db01aa43", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.9  # initial inertia weight; increased from 0.5 to 0.9 for better exploration\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.2  # increased elite percentage from 0.1 to 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhance APSOSA by refining inertia decay and increasing elite selection for better convergence.", "configspace": "", "generation": 73, "fitness": 0.1073905003531855, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.107 with standard deviation 0.001. And the mean value of best solutions found was 0.126 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.10858064696612302, 0.107672194878908, 0.10591865921452548], "final_y": [0.1188919537704135, 0.1285064444467907, 0.1308244964619234]}, "mutation_prompt": null}
{"id": "7208e0e3-e8ee-479e-aaf6-216eb0b7d8a6", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (0.9 + 0.1 * (1 - iter_num / self.iterations))  # improved adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int((self.elite_percentage + 0.05 * (iter_num / self.iterations)) * self.population_size))  # dynamic elite percentage\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Improved inertia weight adaptation and dynamic elite percentage for enhanced exploration-exploitation balance.", "configspace": "", "generation": 74, "fitness": 0.11346826789797959, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11391474910501165, 0.11249403916868828, 0.11399601542023885], "final_y": [0.11538229717998216, 0.11717864841609282, 0.11469255331718142]}, "mutation_prompt": null}
{"id": "b6f46ed6-10e8-42f0-9752-e7236e2798b3", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / (self.temp * (1 + iter_num/self.iterations)))\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Introduced a dynamic cooling rate in the simulated annealing acceptance to enhance exploration and exploitation balance.", "configspace": "", "generation": 75, "fitness": 0.11422441158007568, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.000. And the mean value of best solutions found was 0.114 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11388665747692484, 0.11418899207379218, 0.11459758518951002], "final_y": [0.11547117159345976, 0.11653569147733811, 0.11096526253767414]}, "mutation_prompt": null}
{"id": "bdcdb212-daf3-4b5b-bc08-1abc66f61a51", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.2  # updated elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Refined APSOSA with increased elite percentage for improved convergence.", "configspace": "", "generation": 76, "fitness": 0.11370238332801952, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.001. And the mean value of best solutions found was 0.114 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.1137980786157452, 0.11252160448472481, 0.11478746688358854], "final_y": [0.11378688199062903, 0.11638857678593195, 0.11325023450482341]}, "mutation_prompt": null}
{"id": "be710e4d-cfdf-4394-bc2c-f965d1788f74", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.15  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions) +\n                          0.1 * (np.random.rand(*velocities.shape) - 0.5))  # Added random perturbation\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "APSOSA with enhanced elite-based refinement by increasing the elite percentage and improving the velocity update strategy for better convergence.", "configspace": "", "generation": 77, "fitness": 0.11272449031450944, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.002. And the mean value of best solutions found was 0.118 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.1112894999499463, 0.11104481317564374, 0.1158391578179383], "final_y": [0.11832603397090713, 0.1227288390812451, 0.11325443871092056]}, "mutation_prompt": null}
{"id": "fbe1c7b5-e83e-4941-8216-6b4f8508f76b", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.1  # cognitive coefficient (fine-tuned)\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Improved APSOSA by fine-tuning the cognitive coefficient to enhance exploitation capabilities.", "configspace": "", "generation": 78, "fitness": 0.11238266276167197, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.117 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11257662159530413, 0.11312417095670191, 0.11144719573300987], "final_y": [0.11801804766118107, 0.1181213108161725, 0.11631488978240745]}, "mutation_prompt": null}
{"id": "f43c790d-b750-4d76-8a6f-75ce02e577de", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.15  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Improved APSOSA with enhanced exploitation through modified elite selection for faster convergence.", "configspace": "", "generation": 79, "fitness": 0.11280112103284756, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.118 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11337203293919185, 0.11318270724720225, 0.11184862291214859], "final_y": [0.11618317244560239, 0.11641275893063063, 0.12043713671734968]}, "mutation_prompt": null}
{"id": "2daf4f4b-d9ae-480e-b4c7-706d49c4cdca", "solution": "import numpy as np\n\nclass ImprovedAPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # initial cognitive coefficient\n        self.c2 = 2.05  # initial social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            adaptive_c1 = self.c1 * (1 - iter_num / self.iterations)  # dynamic cognitive coefficient\n            adaptive_c2 = self.c2 * (1 - iter_num / self.iterations)  # dynamic social coefficient\n            velocities = (adaptive_w * velocities +\n                          adaptive_c1 * r1 * (personal_best_positions - positions) +\n                          adaptive_c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n                            # Elite-based crossover\n                            mix = np.random.rand(self.dim)\n                            trial_position = mix * positions[i] + (1 - mix) * global_best_position\n                            trial_score = func(trial_position)\n                            evals += 1\n                            if trial_score < global_best_score:\n                                global_best_position = trial_position\n                                global_best_score = trial_score\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "ImprovedAPSOSA", "description": "Improved APSOSA using dynamic cognitive and social coefficients and elite-based crossover to enhance exploration and exploitation balance.", "configspace": "", "generation": 80, "fitness": 0.11042586322943708, "feedback": "The algorithm ImprovedAPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.110 with standard deviation 0.002. And the mean value of best solutions found was 0.125 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11097817607467342, 0.11236038865498166, 0.10793902495865615], "final_y": [0.12072523862306972, 0.12075382709192717, 0.13372569779771226]}, "mutation_prompt": null}
{"id": "f17f4a24-3f7b-4c0b-a3a1-db71cd806dfe", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.98  # modified cooling rate\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Improved APSOSA by modifying the cooling rate for enhanced exploration and exploitation.", "configspace": "", "generation": 81, "fitness": 0.11422441158007568, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.000. And the mean value of best solutions found was 0.114 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11388665747692484, 0.11418899207379218, 0.11459758518951002], "final_y": [0.11547117159345976, 0.11653569147733811, 0.11096526253767414]}, "mutation_prompt": null}
{"id": "ac8cc0d9-3091-4062-b666-40c0e9bbd0e5", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            velocities *= 0.9  # adaptive velocity scaling\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Integrated adaptive velocity scaling to enhance convergence speed while maintaining solution stability.", "configspace": "", "generation": 82, "fitness": 0.11344531899299874, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.002. And the mean value of best solutions found was 0.117 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11513755303121131, 0.11491841018591353, 0.11027999376187136], "final_y": [0.11228819177319094, 0.11379576645114209, 0.12373279604620968]}, "mutation_prompt": null}
{"id": "f73f8ceb-95d7-414b-a243-9ca8d0b55a42", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            # Change 1: Dynamic elite percentage\n            elite_count = max(1, int((0.1 + 0.1 * iter_num/self.iterations) * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Change 2: Adaptive cooling rate\n            self.temp *= (0.99 + 0.01 * iter_num/self.iterations)\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Introduced a dynamic elite percentage and an adaptive cooling schedule to enhance global exploration and convergence.", "configspace": "", "generation": 83, "fitness": 0.11422441158007568, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.000. And the mean value of best solutions found was 0.114 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11388665747692484, 0.11418899207379218, 0.11459758518951002], "final_y": [0.11547117159345976, 0.11653569147733811, 0.11096526253767414]}, "mutation_prompt": null}
{"id": "ae82a5c1-ba51-41f3-8afb-a62498fa2ccc", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.initial_population_size = 30\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.97  # refined cooling rate\n        self.elite_percentage = 0.15  # updated elite percentage\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            if iter_num % 10 == 0 and self.population_size > 10:  # dynamic resizing\n                self.population_size = max(10, self.population_size - 1)\n                elite_count = max(1, int(self.elite_percentage * self.population_size))\n                positions = positions[:self.population_size]\n                velocities = velocities[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Enhanced elite selection\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "A refined APSOSA with dynamic population resizing and enhanced elite selection to boost exploration and convergence.", "configspace": "", "generation": 84, "fitness": 0.11390952385733495, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.003. And the mean value of best solutions found was 0.117 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.10967474049011394, 0.11677322370422716, 0.11528060737766377], "final_y": [0.12624591866495127, 0.11197734920638447, 0.11271074902029099]}, "mutation_prompt": null}
{"id": "f4f82d92-5cc7-4818-a8ed-cab5baae80fa", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.base_elite_percentage = 0.1  # base elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            velocity_scale = 0.1 + 0.9 * (1 - iter_num / self.iterations)\n            velocities *= velocity_scale\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Dynamic elite percentage\n            elite_percentage = self.base_elite_percentage * (1 - iter_num / self.iterations)\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhanced APSOSA with adaptive velocity scaling and dynamic elite count for improved convergence and exploration balance.", "configspace": "", "generation": 85, "fitness": 0.11279753648925228, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.119 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11438465076037174, 0.11264474858473672, 0.11136321012264838], "final_y": [0.11324748975431675, 0.11852114501441546, 0.12458708797200169]}, "mutation_prompt": null}
{"id": "1433b7c0-12f2-4630-a2cb-dce6e59119b6", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.98  # slightly faster cooling\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            # Implementing logistic chaos for r2\n            r2 = np.sin(np.pi * r2)  \n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  \n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Hybrid local search for elite\n            for i in range(elite_count):\n                trial_position = positions[sorted_indices[i]] + 0.1 * np.random.normal(size=self.dim)\n                trial_position = np.clip(trial_position, lb, ub)\n                trial_score = func(trial_position)\n                evals += 1\n                if trial_score < scores[sorted_indices[i]]:\n                    positions[sorted_indices[i]] = trial_position\n                    scores[sorted_indices[i]] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial_position\n                        global_best_score = trial_score\n\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "APSOSA with chaos-enhanced velocities and hybrid local search for improved convergence.", "configspace": "", "generation": 86, "fitness": 0.11140306364632609, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.111 with standard deviation 0.003. And the mean value of best solutions found was 0.117 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11071722570077602, 0.11498986102747055, 0.1085021042107317], "final_y": [0.11932205432325282, 0.11654565930823768, 0.11660589716349934]}, "mutation_prompt": null}
{"id": "00874274-e28a-431f-8d7c-6b69a8dfa88b", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            # Dynamic population size adjustment\n            self.population_size = max(10, int(self.population_size * (1 - iter_num / self.iterations)))\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhanced APSOSA with dynamic population size adjustment for improved exploration and exploitation balance.", "configspace": "", "generation": 87, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (29,10) (30,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (29,10) (30,10) ')", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {}, "mutation_prompt": null}
{"id": "8064ee86-9646-46c0-bf06-de211711ffda", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5 \n        self.c1 = 2.05 \n        self.c2 = 2.05 \n        self.temp = 100  \n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1 \n\n    def chaos_map(self, x):\n        return 4 * x * (1 - x)\n\n    def dynamic_neighborhood_search(self, position, best_position, lb, ub):\n        factor = np.random.uniform(0.5, 1.5)\n        new_position = best_position + factor * (position - best_position)\n        return np.clip(new_position, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n        chaos_var = 0.5\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            chaos_var = self.chaos_map(chaos_var)\n            adaptive_w = self.w * (1 - iter_num / self.iterations) * chaos_var\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            for i in range(self.population_size):\n                positions[i] = self.dynamic_neighborhood_search(positions[i], global_best_position, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]: \n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "APSOSA+ introduces chaos-enhanced exploration and dynamic neighborhood search to improve convergence and solution diversity.", "configspace": "", "generation": 88, "fitness": 0.10893354946492191, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.109 with standard deviation 0.003. And the mean value of best solutions found was 0.129 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.10425451488961623, 0.11052323017572385, 0.11202290332942566], "final_y": [0.13947011402714016, 0.12539025282638472, 0.12260485702183888]}, "mutation_prompt": null}
{"id": "ce81e63d-17a3-46d0-bfdd-8d183558ee9b", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - (iter_num / self.iterations)**2)  # non-linear adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Introduced a non-linear decreasing inertia weight to improve exploration-exploitation balance.", "configspace": "", "generation": 89, "fitness": 0.11369703724563489, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.000. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.1139408469583022, 0.11321714764473712, 0.11393311713386534], "final_y": [0.11547151383071474, 0.1170778112175318, 0.11443919643436729]}, "mutation_prompt": null}
{"id": "63edd3f7-b6cd-4eca-a738-56a993679012", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.15  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            if np.isclose(global_best_score, 0, atol=1e-6):  # early convergence check\n                break\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Refined APSOSA with enhanced elite-based criterion by adjusting elite percentage and enabling early convergence check.", "configspace": "", "generation": 90, "fitness": 0.11280112103284756, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.118 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11337203293919185, 0.11318270724720225, 0.11184862291214859], "final_y": [0.11618317244560239, 0.11641275893063063, 0.12043713671734968]}, "mutation_prompt": null}
{"id": "9c2c64af-81fa-45f1-867f-4a672dd75a2e", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            self.c1 = 2.05 - 1.5 * (iter_num / self.iterations)  # dynamically adjust c1\n            self.c2 = 1.5 + 1.5 * (iter_num / self.iterations)  # dynamically adjust c2\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Improved APSOSA by dynamically adjusting cognitive and social coefficients to enhance exploration and exploitation balance.", "configspace": "", "generation": 91, "fitness": 0.1121865734442918, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.000. And the mean value of best solutions found was 0.121 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.1126904176205702, 0.11173324477841495, 0.11213605793389025], "final_y": [0.12011391426669082, 0.12062925848941086, 0.12307752509774672]}, "mutation_prompt": null}
{"id": "a0d5bd76-04cf-43e8-8888-92cc72076dd4", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            self.c1 = 2.05 - iter_num * (2.05 - 1.5) / self.iterations  # dynamic cognitive coefficient\n            self.c2 = 1.5 + iter_num * (2.05 - 1.5) / self.iterations  # dynamic social coefficient\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            self.elite_percentage = 0.1 + 0.05 * np.sin(iter_num / self.iterations * np.pi)  # dynamic elite percentage\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Adjust convergence by introducing a dynamic elite percentage and adapting the cognitive and social coefficients for balancing exploration and exploitation.", "configspace": "", "generation": 92, "fitness": 0.11188956095033176, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.123 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11262693246740596, 0.11114170885192776, 0.11190004153166155], "final_y": [0.11917586817385473, 0.1265605244689908, 0.12231304959820621]}, "mutation_prompt": null}
{"id": "3572884a-8900-4bc5-bce9-e87382e28b6a", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.995  # slightly increased cooling rate\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhanced APSOSA with improved cooling by slightly increasing the cooling rate to refine global exploration and convergence.", "configspace": "", "generation": 93, "fitness": 0.11422441158007568, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.000. And the mean value of best solutions found was 0.114 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11388665747692484, 0.11418899207379218, 0.11459758518951002], "final_y": [0.11547117159345976, 0.11653569147733811, 0.11096526253767414]}, "mutation_prompt": null}
{"id": "88ab9c90-78a2-4210-aff7-b8ec25f92d17", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.1  # fine-tuned cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhance APSOSA by fine-tuning the cognitive coefficient for improved balance between exploration and exploitation.", "configspace": "", "generation": 94, "fitness": 0.11238266276167197, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.117 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11257662159530413, 0.11312417095670191, 0.11144719573300987], "final_y": [0.11801804766118107, 0.1181213108161725, 0.11631488978240745]}, "mutation_prompt": null}
{"id": "f4c5ecc6-065e-4513-9722-23f2af732f4e", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.15  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Slightly adjusted the elite percentage to enhance the exploration-exploitation balance.", "configspace": "", "generation": 95, "fitness": 0.11280112103284756, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.118 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11337203293919185, 0.11318270724720225, 0.11184862291214859], "final_y": [0.11618317244560239, 0.11641275893063063, 0.12043713671734968]}, "mutation_prompt": null}
{"id": "e84ec692-7b77-4651-85d9-b72ab0a46fbe", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.10  # increased social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhanced APSOSA with a slight increase in social influence to boost exploration and global convergence.", "configspace": "", "generation": 96, "fitness": 0.11291669512477676, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.115 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11106949449027703, 0.11349960850281304, 0.11418098238124019], "final_y": [0.11256413108542906, 0.11843980151125855, 0.11439692115271827]}, "mutation_prompt": null}
{"id": "d6852f26-199a-4fb9-9a75-a86d054deec7", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.95  # adjusted cooling rate\n        self.elite_percentage = 0.1\n        self.velocity_clamp = 0.1  # velocity clamping factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)\n            velocities = np.clip(adaptive_w * velocities + \n                                 self.c1 * r1 * (personal_best_positions - positions) + \n                                 self.c2 * r2 * (global_best_position - positions),\n                                 -self.velocity_clamp, self.velocity_clamp)\n            positions = np.clip(positions + velocities, lb, ub)\n\n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / (self.temp + iter_num))  # dynamic cooling\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhanced APSOSA with adaptive velocity clamping, dynamic temperature cooling, and elite diversity to improve global search capability.", "configspace": "", "generation": 97, "fitness": 0.09244646849226767, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.092 with standard deviation 0.006. And the mean value of best solutions found was 0.182 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.08454451449354006, 0.09647167711226579, 0.09632321387099718], "final_y": [0.20969536459367544, 0.17003838335987964, 0.16586318776306785]}, "mutation_prompt": null}
{"id": "368e2170-64f3-45f5-afc3-5c59f7bb243e", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Adjust elite percentage dynamically\n            current_elite_percentage = self.elite_percentage * (1 - iter_num / self.iterations)\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(current_elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n\n            # Adaptive cooling rate for temperature\n            self.temp *= (self.cooling_rate + 0.01 * (iter_num / self.iterations))\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Introducing dynamic elite percentage adjustment and adaptive cooling for enhanced convergence and diversity.", "configspace": "", "generation": 98, "fitness": 0.11241528107981687, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.118 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.11367155212719116, 0.11174264190486471, 0.11183164920739475], "final_y": [0.11567261341367252, 0.1168683870438495, 0.12215868440642619]}, "mutation_prompt": null}
{"id": "2f6dc4e4-cef4-4cae-9952-4ee49d5da232", "solution": "import numpy as np\n\nclass APSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.iterations = budget // dim\n        self.population_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 2.05  # cognitive coefficient\n        self.c2 = 2.05  # social coefficient\n        self.temp = 100  # initial temperature for simulated annealing\n        self.cooling_rate = 0.99\n        self.elite_percentage = 0.1  # elite percentage for elite-based criterion\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evals = self.population_size\n\n        for iter_num in range(self.iterations):\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            adaptive_w = self.w * (1 - iter_num / self.iterations)  # adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions = np.clip(positions + velocities, lb, ub)\n            \n            scores = np.array([func(x) for x in positions])\n            evals += self.population_size\n\n            # Simulated Annealing acceptance criterion\n            sorted_indices = np.argsort(scores)\n            elite_count = max(1, int(self.elite_percentage * self.population_size))\n            for i in sorted_indices[:elite_count]:  # apply acceptance only to elite\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = scores[i]\n                    if scores[i] < global_best_score:\n                        delta = scores[i] - global_best_score\n                        probability = np.exp(-delta / self.temp)\n                        if np.random.rand() < probability:\n                            global_best_position = positions[i]\n                            global_best_score = scores[i]\n            # Apply stochastic tunneling to improve exploration\n            if np.random.rand() < 0.1:\n                perturbation = np.random.uniform(-0.1, 0.1, self.dim)\n                positions[global_best_index] = np.clip(global_best_position + perturbation, lb, ub)\n\n            # Cool down the temperature\n            self.temp *= self.cooling_rate\n\n            if evals >= self.budget:\n                break\n\n        return global_best_position, global_best_score", "name": "APSOSA", "description": "Enhanced APSOSA with adaptive inertia and stochastic tunneling to escape local optima and improve convergence.", "configspace": "", "generation": 99, "fitness": 0.11134944382907493, "feedback": "The algorithm APSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.111 with standard deviation 0.001. And the mean value of best solutions found was 0.120 (0. is the best).", "error": "", "parent_id": "64f44042-a3a2-4b3b-9fc0-d606a60c5b71", "metadata": {"aucs": [0.10954027095318453, 0.11311946517018423, 0.11138859536385604], "final_y": [0.12340707413022678, 0.11641115133966906, 0.11919542329269517]}, "mutation_prompt": null}

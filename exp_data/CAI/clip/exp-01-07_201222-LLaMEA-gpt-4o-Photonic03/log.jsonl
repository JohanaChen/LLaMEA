{"id": "8839feff-1e86-43cf-b8fd-c224f6265a7e", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Standard PSO population size\n        self.c1 = 2.05  # Cognitive coefficient\n        self.c2 = 2.05  # Social coefficient\n        self.w = 0.729  # Inertia weight\n        self.mutation_factor = 0.8  # Differential Evolution factor\n        self.crossover_rate = 0.9  # Differential Evolution crossover rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            # Update velocities and positions for PSO\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            # Evaluate new population\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n            \n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n            \n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            # Apply DE operations on a random subset of the population\n            num_de_individuals = int(self.population_size * 0.3)  # 30% of the population\n            de_indices = np.random.choice(self.population_size, num_de_individuals, replace=False)\n            for idx in de_indices:\n                idxs = [i for i in range(self.population_size) if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n        return global_best, global_best_score", "name": "HybridPSO_DE", "description": "A hybrid particle swarm optimization with differential evolution for exploring diverse solutions while refining the best candidates.", "configspace": "", "generation": 0, "fitness": 0.10840299103585782, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.108 with standard deviation 0.003. And the mean value of best solutions found was 0.130 (0. is the best).", "error": "", "parent_id": null, "metadata": {"aucs": [0.1043637224233791, 0.11188643660251618, 0.10895881408167818], "final_y": [0.14028516789646206, 0.12187716507567925, 0.12710934178754718]}, "mutation_prompt": null}
{"id": "13806066-6296-43bc-8e81-1cf67c881835", "solution": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.w = 0.729\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.convergence_threshold = 1e-6\n        self.adaptive_factor = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n        last_global_best_score = global_best_score\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            # Update velocities and positions for PSO\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            # Evaluate new population\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n            \n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n            \n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            # Adaptive adjustment based on convergence speed\n            if abs(last_global_best_score - global_best_score) < self.convergence_threshold:\n                self.w *= (1 + self.adaptive_factor)\n                self.mutation_factor = min(self.mutation_factor * (1 + self.adaptive_factor), 1.0)\n            else:\n                self.w = max(self.w * (1 - self.adaptive_factor), 0.4)\n                self.mutation_factor = max(self.mutation_factor * (1 - self.adaptive_factor), 0.5)\n            \n            last_global_best_score = global_best_score\n\n            # Apply DE operations on a random subset of the population\n            num_de_individuals = int(self.population_size * 0.3)\n            de_indices = np.random.choice(self.population_size, num_de_individuals, replace=False)\n            for idx in de_indices:\n                idxs = [i for i in range(self.population_size) if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n        return global_best, global_best_score", "name": "AdaptiveHybridPSO_DE", "description": "An adaptive hybrid particle swarm optimization with differential evolution, introducing dynamic parameter adjustment based on convergence speed to accelerate and refine search efficiency.", "configspace": "", "generation": 1, "fitness": 0.10799519329880551, "feedback": "The algorithm AdaptiveHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.108 with standard deviation 0.003. And the mean value of best solutions found was 0.128 (0. is the best).", "error": "", "parent_id": "8839feff-1e86-43cf-b8fd-c224f6265a7e", "metadata": {"aucs": [0.1071600990854662, 0.11251082491623177, 0.10431465589471856], "final_y": [0.11736945365950979, 0.12274243393055906, 0.1433899467575811]}, "mutation_prompt": null}
{"id": "f6f34339-3c4d-4aa2-a1b2-7a6a3cd3aff0", "solution": "import numpy as np\n\nclass CoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.8\n        self.subpop_size = int(self.population_size / 2)\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            # Update velocities and positions for PSO\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            # Evaluate new population\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n            \n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n            \n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            # Divide population into two subpopulations\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            # Apply DE on subpop1\n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            # Apply local search on subpop2\n            for idx in subpop2_indices:\n                candidate = pop[idx] + np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "CoevolutionaryOptimizer", "description": "A cooperative coevolutionary algorithm that combines dynamic resource allocation with individual-level learning to improve exploration and exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.10996961943364907, "feedback": "The algorithm CoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.110 with standard deviation 0.001. And the mean value of best solutions found was 0.122 (0. is the best).", "error": "", "parent_id": "8839feff-1e86-43cf-b8fd-c224f6265a7e", "metadata": {"aucs": [0.10935779014514901, 0.11151986984247775, 0.10903119831332042], "final_y": [0.12114737827613531, 0.12024635650537652, 0.1238763139029605]}, "mutation_prompt": null}
{"id": "b4ebcdf3-a72a-4672-9277-b1739a1866e4", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.8\n        self.subpop_size = int(self.population_size / 2)\n        self.adaptive_factor = 0.5\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            # Update velocities and positions for PSO\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            # Evaluate new population\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n            \n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n            \n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            # Divide population into two subpopulations\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            # Apply enhanced DE on subpop1\n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * evaluations / self.budget)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            # Apply adaptive local search on subpop2\n            for idx in subpop2_indices:\n                candidate = pop[idx] + np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "An enhanced coevolutionary algorithm utilizing hybridized dynamic subpopulation interactions and adaptive mutation strategies to boost convergence and diversity.", "configspace": "", "generation": 3, "fitness": 0.111235113942394, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.111 with standard deviation 0.001. And the mean value of best solutions found was 0.120 (0. is the best).", "error": "", "parent_id": "f6f34339-3c4d-4aa2-a1b2-7a6a3cd3aff0", "metadata": {"aucs": [0.11086051860047319, 0.11243605333962836, 0.11040876988708048], "final_y": [0.12157646720044879, 0.11476125206377275, 0.12396050217542276]}, "mutation_prompt": null}
{"id": "22f04077-f375-4aba-aceb-095088c6d2aa", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.7\n        self.mutation_factor = 0.95  # Increased mutation factor from 0.9 to 0.95 for enhanced exploration\n        self.crossover_rate = 0.8\n        self.subpop_size = int(self.population_size / 2)\n        self.adaptive_factor = 0.5\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            # Update velocities and positions for PSO\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            # Evaluate new population\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n            \n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n            \n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            # Divide population into two subpopulations\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            # Apply enhanced DE on subpop1\n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * evaluations / self.budget)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            # Apply adaptive local search on subpop2\n            for idx in subpop2_indices:\n                candidate = pop[idx] + np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "A refined coevolutionary optimizer using increased mutation factor for enhanced exploration and diversity.", "configspace": "", "generation": 4, "fitness": 0.1107396340470052, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.111 with standard deviation 0.001. And the mean value of best solutions found was 0.121 (0. is the best).", "error": "", "parent_id": "b4ebcdf3-a72a-4672-9277-b1739a1866e4", "metadata": {"aucs": [0.11004812614636184, 0.11217021754946999, 0.11000055844518375], "final_y": [0.12069819014841421, 0.1185669698899613, 0.12248311567642478]}, "mutation_prompt": null}
{"id": "a9ce9064-a048-4350-9722-e0d6d5b7807e", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.85  # Changed from 0.8 to 0.85\n        self.subpop_size = int(self.population_size / 2)\n        self.adaptive_factor = 0.5\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            # Update velocities and positions for PSO\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            # Evaluate new population\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n            \n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n            \n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            # Divide population into two subpopulations\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            # Apply enhanced DE on subpop1\n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * evaluations / self.budget)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            # Apply adaptive local search on subpop2\n            for idx in subpop2_indices:\n                candidate = pop[idx] + np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "A slightly increased crossover rate to enhance exploration and convergence speed.", "configspace": "", "generation": 5, "fitness": 0.11024153734691478, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.110 with standard deviation 0.001. And the mean value of best solutions found was 0.121 (0. is the best).", "error": "", "parent_id": "b4ebcdf3-a72a-4672-9277-b1739a1866e4", "metadata": {"aucs": [0.10905383943054581, 0.11230434603171469, 0.10936642657848383], "final_y": [0.12154110831073706, 0.1173323712383405, 0.1241741212761237]}, "mutation_prompt": null}
{"id": "66886cb6-1643-456d-b48b-a613269f4394", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.8\n        self.subpop_size = int(self.population_size / 2)\n        self.adaptive_factor = 0.5\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n            \n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n            \n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * (1 - evaluations / self.budget)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)  # Adjusted mutation\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                candidate = pop[idx] + np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim) * (ub - lb)  # Adjusted exploration\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "A refined coevolutionary algorithm with improved differential evolution strategies and adaptive local exploration for enhanced convergence.", "configspace": "", "generation": 6, "fitness": 0.10887188868828383, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.109 with standard deviation 0.002. And the mean value of best solutions found was 0.122 (0. is the best).", "error": "", "parent_id": "b4ebcdf3-a72a-4672-9277-b1739a1866e4", "metadata": {"aucs": [0.10649162802469725, 0.11023658790159152, 0.10988745013856271], "final_y": [0.12318799789175028, 0.11813335149343573, 0.12438012447292757]}, "mutation_prompt": null}
{"id": "57a555b6-98a1-4165-b982-55d97cf12e30", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.8\n        self.subpop_size = int(self.population_size / 2)\n        self.adaptive_factor = 0.5\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            w = 0.9 - 0.5 * (evaluations / self.budget) # Dynamic inertia weight\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            # Update velocities and positions for PSO\n            velocities = w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            # Evaluate new population\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n            \n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n            \n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            # Divide population into two subpopulations\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            # Apply enhanced DE with dual crossover on subpop1\n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * evaluations / self.budget)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[idx])\n                if np.random.rand() < 0.5: # Second crossover strategy\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, pop[idx], mutant)\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            # Apply adaptive local search on subpop2\n            for idx in subpop2_indices:\n                candidate = pop[idx] + np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "A refined coevolutionary optimizer with dynamic inertia weight and enhanced diversity through dual crossover strategies for improved exploration and exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.10767313498286302, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.108 with standard deviation 0.004. And the mean value of best solutions found was 0.124 (0. is the best).", "error": "", "parent_id": "b4ebcdf3-a72a-4672-9277-b1739a1866e4", "metadata": {"aucs": [0.1042714386677972, 0.10621665275317294, 0.11253131352761891], "final_y": [0.13094169356612084, 0.12776104312922487, 0.1141165149448451]}, "mutation_prompt": null}
{"id": "fc21e176-5234-4033-a5a0-fc4594c12a83", "solution": "import numpy as np\n\nclass QuantumHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.quantum_factor = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.local_search_probability = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            # Update velocities and positions for PSO with quantum influence\n            velocities = (self.w * velocities + \n                          self.c1 * r1 * (personal_best - pop) + \n                          self.c2 * r2 * np.sin(global_best - pop) * self.quantum_factor)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            # Evaluate new population\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n            \n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n            \n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            # Quantum-inspired evolutionary process\n            for idx in range(self.population_size):\n                if np.random.rand() < self.local_search_probability:\n                    a, b, c = pop[np.random.choice(np.arange(self.population_size), 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[idx])\n\n                    trial_score = func(trial)\n                    evaluations += 1\n                    if trial_score < scores[idx]:\n                        scores[idx] = trial_score\n                        pop[idx] = trial\n\n        return global_best, global_best_score", "name": "QuantumHybridOptimizer", "description": "Quantum-inspired hybrid optimizer leveraging particle swarm intelligence and evolutionary quantum gates to enhance global exploration and local exploitation.", "configspace": "", "generation": 8, "fitness": 0.10332675050901134, "feedback": "The algorithm QuantumHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.103 with standard deviation 0.003. And the mean value of best solutions found was 0.139 (0. is the best).", "error": "", "parent_id": "b4ebcdf3-a72a-4672-9277-b1739a1866e4", "metadata": {"aucs": [0.09957406047256256, 0.10381385514687325, 0.1065923359075982], "final_y": [0.15121226683433298, 0.13032480455008244, 0.1351466357521326]}, "mutation_prompt": null}
{"id": "34ac01a4-4da3-4945-99e8-959871f12800", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.8\n        self.subpop_size = int(self.population_size / 2)\n        self.adaptive_factor = 0.5\n        self.gradient_perturbation_factor = 0.05\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            # Update velocities and positions for PSO\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            # Evaluate new population\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n            \n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n            \n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            # Divide population into two subpopulations\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            # Apply enhanced DE on subpop1\n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * evaluations / self.budget)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            # Apply adaptive local search on subpop2\n            for idx in subpop2_indices:\n                candidate = pop[idx] + np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim) * (ub - lb)\n                gradient_perturbation = np.random.normal(0, self.gradient_perturbation_factor, self.dim)\n                candidate += gradient_perturbation * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "A refined coevolutionary optimizer integrating stochastic gradient perturbation and adaptive subpopulation dynamics to enhance exploration and exploitation balance.", "configspace": "", "generation": 9, "fitness": 0.10897497734083839, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.109 with standard deviation 0.002. And the mean value of best solutions found was 0.128 (0. is the best).", "error": "", "parent_id": "b4ebcdf3-a72a-4672-9277-b1739a1866e4", "metadata": {"aucs": [0.1067330133358928, 0.1094172709063076, 0.11077464778031476], "final_y": [0.13704519242672442, 0.12518614302014186, 0.12194655165202906]}, "mutation_prompt": null}
{"id": "44398bd4-5597-42bb-bab0-ca65126386c8", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0  # Changed from 1.5\n        self.c2 = 2.0  # Changed from 1.5\n        self.w = 0.6   # Changed from 0.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.9  # Changed from 0.8\n        self.subpop_size = int(self.population_size / 2)\n        self.adaptive_factor = 0.6  # Changed from 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            # Update velocities and positions for PSO\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            # Evaluate new population\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            # Divide population into two subpopulations\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n\n            # Apply enhanced DE on subpop1\n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * evaluations / self.budget)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            # Apply adaptive local search on subpop2\n            for idx in subpop2_indices:\n                candidate = pop[idx] + np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "A refined coevolutionary optimizer with enhanced swarm intelligence and adaptive differential evolution to improve exploration and exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.10992137488246818, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.110 with standard deviation 0.001. And the mean value of best solutions found was 0.121 (0. is the best).", "error": "", "parent_id": "b4ebcdf3-a72a-4672-9277-b1739a1866e4", "metadata": {"aucs": [0.1089487186492436, 0.11016762795548907, 0.1106477780426719], "final_y": [0.11997769100894462, 0.12420459803062633, 0.12014578321043701]}, "mutation_prompt": null}
{"id": "d6321320-ca11-4f05-ba20-ee78b38c5a4d", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.8\n        self.subpop_size = int(self.population_size / 2)\n        self.adaptive_factor = 0.5\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            # Update velocities and positions for PSO\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            # Evaluate new population\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n            \n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n            \n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            # Divide population into two subpopulations\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            # Apply enhanced DE on subpop1\n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * evaluations / self.budget)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            # Apply improved adaptive local search on subpop2\n            for idx in subpop2_indices:\n                candidate = pop[idx] + np.random.normal(0, 0.2 * (1 - evaluations / self.budget), self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Improved adaptive mutation and local search mechanisms to enhance exploration within limited evaluations.", "configspace": "", "generation": 11, "fitness": 0.10807942230726726, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.108 with standard deviation 0.001. And the mean value of best solutions found was 0.126 (0. is the best).", "error": "", "parent_id": "b4ebcdf3-a72a-4672-9277-b1739a1866e4", "metadata": {"aucs": [0.10788998700247765, 0.1090399404490825, 0.10730833947024165], "final_y": [0.12560483391626787, 0.1187661989297999, 0.13414562958506426]}, "mutation_prompt": null}
{"id": "ff44b27e-f9e5-468d-a932-80be7320d6d3", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9  # Changed from static w to adaptive w_max\n        self.w_min = 0.4  # New adaptive w_min\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.8\n        self.subpop_size = int(self.population_size / 2)\n        self.adaptive_factor = 0.5\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            \n            # Adaptive inertia weight\n            w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n            \n            # Update velocities and positions for PSO\n            velocities = w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            # Evaluate new population\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n            \n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n            \n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            # Divide population into two subpopulations\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            # Apply enhanced DE on subpop1\n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * evaluations / self.budget)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            # Apply adaptive local search on subpop2\n            for idx in subpop2_indices:\n                candidate = pop[idx] + np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Introduced adaptive inertia weight and enhanced mutation strategies to improve convergence speed and solution quality while maintaining balance between exploration and exploitation.", "configspace": "", "generation": 12, "fitness": 0.10788230706055058, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.108 with standard deviation 0.001. And the mean value of best solutions found was 0.122 (0. is the best).", "error": "", "parent_id": "b4ebcdf3-a72a-4672-9277-b1739a1866e4", "metadata": {"aucs": [0.10737574755076051, 0.10694559190355657, 0.10932558172733464], "final_y": [0.12159935043027936, 0.12069208619977789, 0.12246936538237196]}, "mutation_prompt": null}
{"id": "ea663c0b-c741-4e8b-8f56-88b504ee1d95", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.8\n        self.subpop_size = int(self.population_size / 2)\n        self.adaptive_factor = 0.5\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            # Update velocities and positions for PSO\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            # Evaluate new population\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n            \n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n            \n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            # Divide population into two subpopulations\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            # Apply enhanced DE on subpop1\n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * evaluations / self.budget)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            # Apply adaptive local search on subpop2\n            for idx in subpop2_indices:\n                candidate = pop[idx] + np.random.normal(0, 0.1 * (1 - evaluations / self.budget) * 0.9, self.dim) * (ub - lb)  # Altered line\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced dynamic parameter adjustment in subpopulation interactions for improved convergence.", "configspace": "", "generation": 13, "fitness": 0.10981909760517945, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.110 with standard deviation 0.000. And the mean value of best solutions found was 0.121 (0. is the best).", "error": "", "parent_id": "b4ebcdf3-a72a-4672-9277-b1739a1866e4", "metadata": {"aucs": [0.10970147155733279, 0.10966134185283394, 0.11009447940537165], "final_y": [0.12171694459116, 0.11855408348820906, 0.12211131099303107]}, "mutation_prompt": null}
{"id": "2b3a5a50-d2e1-4ae2-b17c-57a4a4a42193", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.8\n        self.subpop_size = int(self.population_size / 2)\n        self.adaptive_factor = 0.5\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            # Adaptive inertia weight\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n\n            # Update velocities and positions for PSO\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            # Evaluate new population\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n            \n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n            \n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            # Divide population into two subpopulations\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            # Apply enhanced DE on subpop1\n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * evaluations / self.budget)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < (self.crossover_rate * (1 - evaluations / self.budget)), mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            # Apply adaptive local search on subpop2\n            for idx in subpop2_indices:\n                candidate = pop[idx] + np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "A refined coevolutionary algorithm with adaptive inertia weight and dynamic crossover rates for improved exploration and exploitation.", "configspace": "", "generation": 14, "fitness": 0.10826677393481905, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.108 with standard deviation 0.000. And the mean value of best solutions found was 0.123 (0. is the best).", "error": "", "parent_id": "b4ebcdf3-a72a-4672-9277-b1739a1866e4", "metadata": {"aucs": [0.1083310561177303, 0.10849985796370809, 0.10796940772301877], "final_y": [0.1256489472637975, 0.11971135084933782, 0.12381470084292379]}, "mutation_prompt": null}
{"id": "5a9175c2-e5c9-4fe8-9dd2-276fb6a751b5", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9  # Change 1: Start with higher inertia weight\n        self.w_min = 0.4  # Change 2: Introduce minimum inertia weight\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.8\n        self.subpop_size = int(self.population_size / 2)\n        self.adaptive_factor = 0.5\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.w = self.w_min + (self.w - self.w_min) * ((self.budget - evaluations) / self.budget)  # Change 3: Dynamic inertia\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n            \n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n            \n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * evaluations / self.budget)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                step_size = 0.1 * (1 - evaluations / self.budget) * (ub - lb)  # Change 4: Adaptive step size\n                candidate = pop[idx] + np.random.normal(0, step_size, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "A refined coevolutionary optimizer employing a dynamic inertia weight in PSO and enhanced local search with adaptive step sizes to improve convergence speed and solution quality.", "configspace": "", "generation": 15, "fitness": 0.11045861775949924, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.110 with standard deviation 0.001. And the mean value of best solutions found was 0.121 (0. is the best).", "error": "", "parent_id": "b4ebcdf3-a72a-4672-9277-b1739a1866e4", "metadata": {"aucs": [0.11184772202134463, 0.11026841754891514, 0.10925971370823795], "final_y": [0.12032744276968843, 0.11947818449155045, 0.12206562534281129]}, "mutation_prompt": null}
{"id": "f36fe0b3-749c-4a65-8aa9-3fa56ed251f1", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.7\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.8  # Changed line: This line remains unchanged in terms of placement but note the interaction with the added dynamic element below.\n        self.subpop_size = int(self.population_size / 2)\n        self.adaptive_factor = 0.5\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            # Update velocities and positions for PSO\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            # Evaluate new population\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n            \n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n            \n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            # Divide population into two subpopulations\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            # Apply enhanced DE on subpop1\n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * evaluations / self.budget)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)  # Changed line\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            # Apply adaptive local search on subpop2\n            for idx in subpop2_indices:\n                candidate = pop[idx] + np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Refined mutation strategy by introducing a dynamically adaptive crossover rate to enhance exploration and exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.11079284337133204, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.111 with standard deviation 0.001. And the mean value of best solutions found was 0.119 (0. is the best).", "error": "", "parent_id": "b4ebcdf3-a72a-4672-9277-b1739a1866e4", "metadata": {"aucs": [0.11009002431070358, 0.1119051076461205, 0.11038339815717202], "final_y": [0.12158989807991671, 0.11342870993651522, 0.12279190723625366]}, "mutation_prompt": null}
{"id": "ef4179d6-f6c0-4739-96ae-70d632b8b853", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0  # Increased cognitive coefficient\n        self.c2 = 1.5\n        self.w = 0.5  # Reduced inertia weight for faster convergence\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.8\n        self.subpop_size = int(self.population_size / 2)\n        self.adaptive_factor = 0.5\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            # Update velocities and positions for PSO\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            # Evaluate new population\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n            \n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n            \n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            # Divide population into two subpopulations\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            # Apply enhanced DE on subpop1\n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * evaluations / self.budget)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            # Apply enhanced local search on subpop2\n            for idx in subpop2_indices:\n                learning_rate = 0.05 * (1 - evaluations / self.budget)  # Adaptive learning rate\n                candidate = pop[idx] + np.random.normal(0, learning_rate, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "A refined coevolutionary optimizer incorporating adaptive learning rates and enhanced local search to improve optimization efficiency and performance.", "configspace": "", "generation": 17, "fitness": 0.1120781774235294, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.002. And the mean value of best solutions found was 0.119 (0. is the best).", "error": "", "parent_id": "b4ebcdf3-a72a-4672-9277-b1739a1866e4", "metadata": {"aucs": [0.10990763220765964, 0.11416574468003926, 0.11216115538288929], "final_y": [0.12598834142192794, 0.1117429437935854, 0.11798301021727775]}, "mutation_prompt": null}
{"id": "66a2c123-b7c9-4456-9a0f-198ef78a2f6a", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 1.5  # Adjusted cognitive coefficient for balanced exploration\n        self.c2 = 2.0  # Increased social coefficient for stronger convergence\n        self.w = 0.6  # Adjusted inertia weight for stability\n        self.mutation_factor = 0.8  # Lower mutation for smoother changes\n        self.crossover_rate = 0.9  # Higher crossover rate for better diversity\n        self.subpop_size = int(self.population_size / 2)\n        self.adaptive_factor = 0.6\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            # Update velocities and positions for PSO\n            velocities = (self.w + 0.1 * np.random.rand()) * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            # Evaluate new population\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            # Divide population into two subpopulations\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n\n            # Apply enhanced DE on subpop1\n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * evaluations / self.budget)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            # Apply enhanced local search on subpop2\n            for idx in subpop2_indices:\n                learning_rate = 0.05 * (1 - evaluations / self.budget)\n                candidate = pop[idx] + np.random.normal(0, learning_rate, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "An enhanced coevolutionary optimizer with adaptive mutation rates and dynamic crossover strategies to improve solution exploration and convergence efficiency.", "configspace": "", "generation": 18, "fitness": 0.1083716178139998, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.108 with standard deviation 0.001. And the mean value of best solutions found was 0.126 (0. is the best).", "error": "", "parent_id": "ef4179d6-f6c0-4739-96ae-70d632b8b853", "metadata": {"aucs": [0.1087025206977319, 0.10980752125487148, 0.10660481148939605], "final_y": [0.12463666407277074, 0.11985574163295021, 0.13216780485150126]}, "mutation_prompt": null}
{"id": "03c1a75c-ceb8-40d5-86b4-daaa7cc31f57", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4  # Reduced inertia weight for faster convergence\n        self.mutation_factor = 0.95  # Slightly increased mutation factor\n        self.crossover_rate = 0.85  # Slightly increased crossover rate\n        self.subpop_size = int(self.population_size / 2)\n        self.adaptive_factor = 0.3  # Adjusted adaptive factor for mutation\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n            \n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n            \n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * evaluations / self.budget)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                learning_rate = 0.1 * (1 - evaluations / self.budget)  # Increased adaptive learning rate\n                candidate = pop[idx] + np.random.normal(0, learning_rate, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced adaptive learning and mutation in a coevolutionary optimizer for improved efficiency and convergence.", "configspace": "", "generation": 19, "fitness": 0.11335562484740118, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.114 (0. is the best).", "error": "", "parent_id": "ef4179d6-f6c0-4739-96ae-70d632b8b853", "metadata": {"aucs": [0.11124766645719364, 0.11447239994657543, 0.11434680813843445], "final_y": [0.1157565874954849, 0.11497635736004908, 0.11273260485436509]}, "mutation_prompt": null}
{"id": "c1b214f4-25a5-4118-bca8-02fa360b632d", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size = int(self.population_size / 2)\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        initial_population_size = self.population_size\n\n        while evaluations < self.budget:\n            current_budget_ratio = evaluations / self.budget\n            dynamic_population_size = max(10, int(initial_population_size * (1 - current_budget_ratio)))\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.w = 0.4 + 0.4 * (1 - current_budget_ratio)  # Linearly decrease inertia weight\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n\n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * evaluations / self.budget)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                learning_rate = 0.1 * (1 - evaluations / self.budget)\n                candidate = pop[idx] + np.random.normal(0, learning_rate, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Introducing adaptive population size and dynamic parameter tuning for improved exploration-exploitation balance.", "configspace": "", "generation": 20, "fitness": 0.10851440404857134, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.109 with standard deviation 0.000. And the mean value of best solutions found was 0.122 (0. is the best).", "error": "", "parent_id": "03c1a75c-ceb8-40d5-86b4-daaa7cc31f57", "metadata": {"aucs": [0.1079324067062194, 0.10904408793107734, 0.10856671750841729], "final_y": [0.12165053410595472, 0.1203897504713134, 0.12417490274172349]}, "mutation_prompt": null}
{"id": "17b45935-0e1f-4087-b5de-cdbe3de44654", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5  # Adjusted factor for dynamic subpopulation size\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)  # Dynamic subpopulation size\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * evaluations / self.budget)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                learning_rate = 0.1 * (1 - evaluations / self.budget)\n                candidate = pop[idx] + np.random.normal(0, learning_rate, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Introduced dynamic subpopulation division and adaptive crossover rate for balancing exploration and exploitation.", "configspace": "", "generation": 21, "fitness": 0.11353716695371674, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.001. And the mean value of best solutions found was 0.114 (0. is the best).", "error": "", "parent_id": "03c1a75c-ceb8-40d5-86b4-daaa7cc31f57", "metadata": {"aucs": [0.11298202007234337, 0.1154923207225208, 0.11213716006628605], "final_y": [0.1141631075041657, 0.11298604529727174, 0.11559085913927769]}, "mutation_prompt": null}
{"id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Improved EnhancedCoevolutionaryOptimizer by introducing Levy flight-based exploration and adjusting adaptive mutation strategies.", "configspace": "", "generation": 22, "fitness": 0.11487791364169216, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.113 (0. is the best).", "error": "", "parent_id": "17b45935-0e1f-4087-b5de-cdbe3de44654", "metadata": {"aucs": [0.11514730254837546, 0.11550847389866359, 0.11397796447803743], "final_y": [0.11203844779707639, 0.11048869623636148, 0.11555404922151713]}, "mutation_prompt": null}
{"id": "05506a0f-bf79-4c53-9161-1dff55c48346", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n        self.chaotic_map_factor = np.random.rand()  # Initialize chaotic map factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.chaotic_map_factor = 4 * self.chaotic_map_factor * (1 - self.chaotic_map_factor)  # Chaotic map update\n            self.w = 0.4 + 0.2 * self.chaotic_map_factor  # Update inertia weight using chaotic map\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced the optimizer by introducing a chaotic map-based parameter control to adjust exploration and exploitation dynamics effectively.", "configspace": "", "generation": 23, "fitness": 0.10698871425382846, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.107 with standard deviation 0.004. And the mean value of best solutions found was 0.130 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.10504768324350466, 0.10350639424498453, 0.11241206527299619], "final_y": [0.1326441324117429, 0.14156702311112024, 0.11696549711726689]}, "mutation_prompt": null}
{"id": "49c4a856-2a06-409b-9e66-aab816fdeb88", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w_max = 0.9  # Changed to adaptive inertia weight\n        self.w_min = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            # Adaptive inertia weight\n            w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n            velocities = w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            # Dynamic subpopulation factor\n            dynamic_subpop_size = int(self.population_size * (1 - evaluations / self.budget))\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:dynamic_subpop_size]\n            subpop2_indices = indices[dynamic_subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Improved exploration-exploitation balance using adaptive inertia weight and dynamic subpopulation factor for enhanced convergence.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {}, "mutation_prompt": null}
{"id": "fca08060-cf01-45b9-b1b9-4c6644c75abd", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - (evaluations / self.budget)**0.5)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Improved exploration by adjusting the crossover rate decay factor for a more balanced exploitation-exploration trade-off.", "configspace": "", "generation": 25, "fitness": 0.11367142251682945, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.000. And the mean value of best solutions found was 0.113 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.11349664532556558, 0.11410923565145215, 0.11340838657347063], "final_y": [0.11450987324598039, 0.11059682307849694, 0.11518021274712886]}, "mutation_prompt": null}
{"id": "854d796e-9d32-4279-aced-20423e116c42", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            # Use chaotic logistic map for inertia weight\n            self.w = 0.5 * (1 - (3.9 * (self.w * (1 - self.w))))\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                # Adaptive differential mutation using chaotic factor\n                chaotic_factor = 0.7 + 0.3 * np.random.random()\n                adaptive_mutation = chaotic_factor * self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced exploration with chaotic maps and adaptive differential mutation for improved convergence.", "configspace": "", "generation": 26, "fitness": 0.11019848436716946, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.110 with standard deviation 0.001. And the mean value of best solutions found was 0.121 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.1097007853034776, 0.10946019360137527, 0.11143447419665553], "final_y": [0.1237845464759374, 0.12365707739550891, 0.11682880093904913]}, "mutation_prompt": null}
{"id": "985038c6-5015-428f-a42c-3ab23a11c172", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.5  # Adjusted inertia weight for better balance\n        self.mutation_factor = 0.85  # Adjusted mutation factor for diversity\n        self.crossover_rate = 0.9  # Adjusted crossover rate for improved exploration\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.5)  # More adaptive exploration\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced exploration and exploitation using adaptive Levy flight and mutation rates in a coevolutionary framework.", "configspace": "", "generation": 27, "fitness": 0.1133927234301404, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.11425880253750342, 0.11324114607194635, 0.11267822168097141], "final_y": [0.11349228679352197, 0.11393639285836865, 0.12090991467079859]}, "mutation_prompt": null}
{"id": "1db1a161-883b-49ff-99f0-7c751fb5d6ec", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)) * 0.5)\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced local search by altering Cauchy distribution scaling factor for improved exploration-exploitation balance.", "configspace": "", "generation": 28, "fitness": 0.1136173117121843, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.002. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.11297814697008546, 0.11585855078157514, 0.11201523738489227], "final_y": [0.11520631798242364, 0.10980312580940199, 0.12219691772882424]}, "mutation_prompt": null}
{"id": "f393b5ee-43d5-4656-a2ed-7b176ac59ac3", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.9  # Adaptive initial inertia weight\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            \n            # Adaptive inertia weight\n            w_adaptive = self.w - evaluations / self.budget * (self.w - 0.4)\n            velocities = w_adaptive * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                # Improved adaptive mutation\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget))\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Improved exploration-exploitation balance by introducing adaptive inertia weight and enhanced mutation factor tuning.", "configspace": "", "generation": 29, "fitness": 0.10822456443995143, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.108 with standard deviation 0.001. And the mean value of best solutions found was 0.122 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.10773752087873234, 0.10790185681076814, 0.10903431563035382], "final_y": [0.12673028173771295, 0.11518016959367983, 0.12430558032035477]}, "mutation_prompt": null}
{"id": "23df1006-c58e-4c7a-b94a-df237a5d66ff", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.1  # slightly increased cognitive component\n        self.c2 = 1.7  # slightly increased social component\n        self.w = 0.9  # initial inertia\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            # Dynamic adjustment of inertia weight\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                # Reduced levy step size for finer exploration\n                levy_step = np.random.normal(0, 0.05, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced the balance between exploration and exploitation by introducing dynamic adjustment of inertia weight and refined mutation strategies for improved convergence.", "configspace": "", "generation": 30, "fitness": 0.10564239002719282, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.106 with standard deviation 0.002. And the mean value of best solutions found was 0.129 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.10860782564747762, 0.10275408206142134, 0.10556526237267949], "final_y": [0.12172230012920271, 0.13872581438958898, 0.12521352396341467]}, "mutation_prompt": null}
{"id": "28bd28ad-eaf8-4ad6-84ea-756e184da374", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            # Adjusted line for adaptive velocity update\n            velocities = (self.w * (1 - evaluations / self.budget)) * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Introduced adaptive velocity update by adding inertia reduction for improved convergence speed in dynamic landscapes.", "configspace": "", "generation": 31, "fitness": 0.11332679493388598, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.118 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.11407369063404815, 0.11359580870139885, 0.11231088546621093], "final_y": [0.114970644303942, 0.11753584772483017, 0.12133922332689728]}, "mutation_prompt": null}
{"id": "b50564ee-a4b2-4692-957d-d811c2dc3c29", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2 + np.random.rand())  # Change made here\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced exploration by adjusting the mutation factor dynamically based on iteration progress.", "configspace": "", "generation": 32, "fitness": 0.11187252106192698, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.118 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.11113822782983074, 0.11196367486363656, 0.11251566049231365], "final_y": [0.11832012839208528, 0.11481852599321041, 0.12086474168780614]}, "mutation_prompt": null}
{"id": "c07cb7f8-056c-4552-8154-d92709214ce7", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 1.8  # Reduced to balance exploration\n        self.c2 = 1.7  # Increased to enhance convergence\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                fitness_diversity = np.std(scores)  # New fitness diversity measure\n                adaptive_mutation *= (1 + fitness_diversity)  # Adjust mutation based on diversity\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "EnhancedCoevolutionaryOptimizer with hybrid mutation and dynamic adaptation based on fitness diversity to improve global exploration and local exploitation.", "configspace": "", "generation": 33, "fitness": 0.11276030381596114, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.002. And the mean value of best solutions found was 0.117 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.1106808751409587, 0.11434278287206556, 0.11325725343485915], "final_y": [0.11931848268582412, 0.11176384034591891, 0.11860045615284498]}, "mutation_prompt": null}
{"id": "fa6d2388-7759-4990-b6bf-c42184d4d1b8", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.standard_cauchy(self.dim) * (ub - lb) * (0.1 * np.random.normal(0, 1, self.dim))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced exploration by adjusting the Levy flight step distribution.", "configspace": "", "generation": 34, "fitness": 0.11332517725432596, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.117 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.11423353255936186, 0.1125706871965666, 0.11317131200704944], "final_y": [0.11622737142279849, 0.11818861292407523, 0.11789440057409495]}, "mutation_prompt": null}
{"id": "20e573d3-8a0e-49c5-8572-a2b228df08a0", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.9  # Updated line\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Chaotic map-based population initialization (Updated line)\n        pop = lb + (ub - lb) * np.abs(np.sin(np.linspace(0, np.pi, self.population_size * self.dim).reshape(self.population_size, self.dim)))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            # Adaptive inertia weight line (Updated line)\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced diversity and convergence rate with chaotic map-based initialization and adaptive inertia weighting.", "configspace": "", "generation": 35, "fitness": 0.10954101261325182, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.110 with standard deviation 0.001. And the mean value of best solutions found was 0.123 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.10983954300842924, 0.11114060252383484, 0.10764289230749136], "final_y": [0.12270533871446843, 0.12322437980549839, 0.12366098974640627]}, "mutation_prompt": null}
{"id": "41422af1-25c9-4f0a-ba00-5108edb486a1", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / (1.5 * self.budget))  # adjusted crossover rate\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced the algorithm by dynamically adjusting crossover rate during mutation for better exploration.", "configspace": "", "generation": 36, "fitness": 0.11318097278165844, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.118 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.11222619735370765, 0.11340358548194251, 0.11391313550932514], "final_y": [0.12048247504716603, 0.1170483619134648, 0.11516092724601945]}, "mutation_prompt": null}
{"id": "6301198e-48f1-4d92-9a84-9765d8d7af53", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step \n                candidate = candidate + 0.5 * (global_best - candidate)  # Enhanced exploration\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced exploration using a combination of Levy flights and adaptive sub-population mutation, with dynamic crossover for improved convergence.", "configspace": "", "generation": 37, "fitness": 0.11229074339210303, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.002. And the mean value of best solutions found was 0.118 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.11395851463292173, 0.11277158649575525, 0.1101421290476321], "final_y": [0.11623492520916201, 0.1181767942909081, 0.11989481719731465]}, "mutation_prompt": null}
{"id": "62c718e9-8ac5-4ecc-9844-6ca7b800ef29", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.2, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))  # Adjusted variance\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Improved exploration by adjusting the distribution of Levy flights for better diverse search capabilities.", "configspace": "", "generation": 38, "fitness": 0.11374888209773615, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.000. And the mean value of best solutions found was 0.115 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.11344493525736976, 0.11420531755030072, 0.11359639348553796], "final_y": [0.11625339241674604, 0.11265347965563888, 0.1151606213985571]}, "mutation_prompt": null}
{"id": "1740398e-7da6-42e7-b947-dace6618ae40", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.6  # Adjusted inertia weight\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Modified the inertia weight `w` during velocity update to enhance the balance between exploration and exploitation.", "configspace": "", "generation": 39, "fitness": 0.11107158911403188, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.111 with standard deviation 0.002. And the mean value of best solutions found was 0.120 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.1086441818727436, 0.11384683684305164, 0.11072374862630041], "final_y": [0.12426645639840617, 0.11488258097460069, 0.12204635697829491]}, "mutation_prompt": null}
{"id": "0cd9ec65-0f79-4b7e-bc02-b0742233aad3", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizerV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n            # Opposition-based learning for enhanced exploration\n            opp_population = lb + ub - pop\n            opp_population = np.clip(opp_population, lb, ub)\n            opp_scores = np.array([func(ind) for ind in opp_population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if opp_scores[i] < scores[i]:\n                    scores[i] = opp_scores[i]\n                    pop[i] = opp_population[i]\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizerV2", "description": "Introduce opposition-based learning and dynamic inertia weight adjustment to enhance exploration and exploitation balance.", "configspace": "", "generation": 40, "fitness": 0.10567912644015205, "feedback": "The algorithm EnhancedCoevolutionaryOptimizerV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.106 with standard deviation 0.001. And the mean value of best solutions found was 0.135 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.10419752269769389, 0.10543405916879178, 0.1074057974539705], "final_y": [0.13859515153711177, 0.13786166780120368, 0.1296094360197303]}, "mutation_prompt": null}
{"id": "8e0a4ec7-47e4-4bd4-b198-1825c317d589", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.6  # Changed from 0.5 to 0.6 to improve exploration\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n\n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.2, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))  # Changed from 0.1 to 0.2 for increased step size\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced dynamic strategies in the coevolutionary optimizer by optimizing subpopulation division and improving Lévy flight adaptation to boost exploration.", "configspace": "", "generation": 41, "fitness": 0.11182574511579575, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.121 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.1104896149152026, 0.11250759340424887, 0.1124800270279358], "final_y": [0.12444441451384491, 0.11723112384899848, 0.12083005221130216]}, "mutation_prompt": null}
{"id": "156e24fb-d3ed-4465-ac0f-bf49c4c19bd5", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - (evaluations / self.budget)**1.1)  # Slightly slower reduction\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Improved EnhancedCoevolutionaryOptimizer by fine-tuning the dynamic crossover rate to balance exploration and exploitation more effectively.", "configspace": "", "generation": 42, "fitness": 0.11422221002856114, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.001. And the mean value of best solutions found was 0.115 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.11305276829035238, 0.11561997585879435, 0.1139938859365367], "final_y": [0.11755001033310897, 0.11057283286707675, 0.11599388527653343]}, "mutation_prompt": null}
{"id": "1a71eb7d-d2ae-433e-9063-2b47b0d6ebf0", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / (self.budget + 1e-9))**1.2)  # Adjusted mutation factor\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced exploration by fine-tuning mutation factor's dynamic adjustment.", "configspace": "", "generation": 43, "fitness": 0.11487791364169216, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.113 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.11514730254837546, 0.11550847389866359, 0.11397796447803743], "final_y": [0.1120384477970765, 0.1104886962363617, 0.11555404922151713]}, "mutation_prompt": null}
{"id": "0ea3cfbf-3cf6-4577-b860-cb62fd1c9a13", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.2, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced solution by refining Levy flight parameters to increase exploration efficiency.", "configspace": "", "generation": 44, "fitness": 0.11374888209773615, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.000. And the mean value of best solutions found was 0.115 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.11344493525736976, 0.11420531755030072, 0.11359639348553796], "final_y": [0.11625339241674604, 0.11265347965563888, 0.1151606213985571]}, "mutation_prompt": null}
{"id": "169300b4-6dbc-475b-a3f4-47125c193c63", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.initial_w = 0.9\n        self.final_w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_w = self.initial_w - (self.initial_w - self.final_w) * (evaluations / self.budget)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = current_w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                cosine_scaled_mutation = adaptive_mutation * np.cos(0.5 * np.pi * evaluations / self.budget)\n                mutant = np.clip(a + cosine_scaled_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Improved exploration-exploitation balance by incorporating adaptive inertia weight for velocity updates and enhanced mutation mechanism with cosine scaling.", "configspace": "", "generation": 45, "fitness": 0.10844740620078741, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.108 with standard deviation 0.001. And the mean value of best solutions found was 0.122 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.10752549481882778, 0.10883860157739533, 0.10897812220613912], "final_y": [0.12692656542746383, 0.11477913170220144, 0.12321879147811132]}, "mutation_prompt": null}
{"id": "ce245961-4f2c-4a20-919b-02416af80a13", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.3  # Adjusted from 0.4 to 0.3\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Fine-tuned inertia weight (w) to enhance convergence speed and balance exploration-exploitation.", "configspace": "", "generation": 46, "fitness": 0.11245095974827764, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.002. And the mean value of best solutions found was 0.121 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.11029961207913308, 0.11365366259554321, 0.11339960457015663], "final_y": [0.12452930874962342, 0.11867826690062522, 0.1186041801733676]}, "mutation_prompt": null}
{"id": "1d25b48b-a12e-41cc-922b-850f7a30c9dd", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.1  # Increased from 2.0 to 2.1 to slightly boost personal best influence\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Refined EnhancedCoevolutionaryOptimizer by slightly increasing the influence of the personal best component in velocity updates to enhance convergence.", "configspace": "", "generation": 47, "fitness": 0.1136762813780156, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.002. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.11289218231161025, 0.1160703245174608, 0.11206633730497573], "final_y": [0.11623741329486925, 0.11061413116129293, 0.12152733029530882]}, "mutation_prompt": null}
{"id": "df3d89d3-ef50-4134-9a57-4ed766c2956a", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.5  # Adjusted the inertia weight\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced EnhancedCoevolutionaryOptimizer by fine-tuning the inertia weight parameter for better exploration-exploitation balance.", "configspace": "", "generation": 48, "fitness": 0.11280355647475582, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.000. And the mean value of best solutions found was 0.115 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.11299076920131135, 0.11235287076309108, 0.11306702945986502], "final_y": [0.11642332387358967, 0.11348754178610032, 0.11639263160889501]}, "mutation_prompt": null}
{"id": "ea212bce-00df-4feb-8d37-afa2a967d9fb", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.random.uniform(0.8, 1.2) * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced exploration by introducing stochastic variation in the mutation factor.", "configspace": "", "generation": 49, "fitness": 0.11207655033457146, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.002. And the mean value of best solutions found was 0.120 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.10966337925638137, 0.1129044957351425, 0.11366177601219052], "final_y": [0.12430961579641331, 0.11860660721131622, 0.11748836663161233]}, "mutation_prompt": null}
{"id": "b982ed86-e562-4ceb-a294-e96d40bf7719", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.9  # Changed initial inertia weight\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            \n            self.w = 0.9 - (0.5 * evaluations / self.budget)  # Dynamic inertia weight adjustment\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n\n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate / self.dim, mutant, pop[idx])  # Dimensional-based crossover\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced exploration through dynamic inertia weight adjustment and dimensional-based crossover in the co-evolutionary framework for better convergence.", "configspace": "", "generation": 50, "fitness": 0.10794968105451386, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.108 with standard deviation 0.002. And the mean value of best solutions found was 0.127 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.10970171454946287, 0.10503455532538253, 0.10911277328869617], "final_y": [0.1191600754450951, 0.13734592396731393, 0.12369012158321402]}, "mutation_prompt": null}
{"id": "4c812232-7f36-46ff-ad9f-d07d56f140ce", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            # Dynamic inertia weight\n            w_dynamic = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Introducing a dynamic inertia weight in the velocity update to enhance exploration and exploitation balance.", "configspace": "", "generation": 51, "fitness": 0.10744430009126878, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.107 with standard deviation 0.001. And the mean value of best solutions found was 0.127 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.10756683643102116, 0.10613255423116896, 0.10863350961161622], "final_y": [0.1255342769121519, 0.13184772649349386, 0.12419342234461839]}, "mutation_prompt": null}
{"id": "c2db18de-d108-4835-afec-e898eb042b0a", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                # Change: Adjusted Levy flight step size calculation for exploration\n                levy_step = np.random.normal(0, 0.2, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Improved exploration by adjusting the Levy flight step size for greater diversity.", "configspace": "", "generation": 52, "fitness": 0.11374888209773615, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.000. And the mean value of best solutions found was 0.115 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.11344493525736976, 0.11420531755030072, 0.11359639348553796], "final_y": [0.11625339241674604, 0.11265347965563888, 0.1151606213985571]}, "mutation_prompt": null}
{"id": "853d95b2-2c66-468c-b46d-2c28731e4c80", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.1)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Improved adaptive mutation strategy by altering the decay exponent for enhanced exploration-exploitation balance.", "configspace": "", "generation": 53, "fitness": 0.11488351251857161, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.113 (0. is the best).", "error": "", "parent_id": "d332706d-ac01-4cf2-81c9-6581b8ca468a", "metadata": {"aucs": [0.11511747597980226, 0.11557166472828173, 0.11396139684763085], "final_y": [0.11215312540636158, 0.11058046142968658, 0.11539303062077344]}, "mutation_prompt": null}
{"id": "ebc89d00-ca0d-4acd-8026-9050f2bf153a", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            \n            # Adaptive inertia weight\n            adaptive_w = self.w * (1 - evaluations / self.budget)\n\n            velocities = adaptive_w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.1)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Introduced an adaptive inertia weight for improved balance between exploration and exploitation in velocity updates.", "configspace": "", "generation": 54, "fitness": 0.1133022078315112, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.118 (0. is the best).", "error": "", "parent_id": "853d95b2-2c66-468c-b46d-2c28731e4c80", "metadata": {"aucs": [0.11405326605510635, 0.11359665255045004, 0.11225670488897721], "final_y": [0.11515378050511704, 0.11754323971162084, 0.12129935996604801]}, "mutation_prompt": null}
{"id": "9436f407-86c5-460c-845a-9bbcf6d2468c", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            # Modified line\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)  # Dynamic inertia weight\n            \n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.1)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Incorporate a dynamic inertia weight adjustment to balance exploration and exploitation better.", "configspace": "", "generation": 55, "fitness": 0.1081096225114027, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.108 with standard deviation 0.000. And the mean value of best solutions found was 0.123 (0. is the best).", "error": "", "parent_id": "853d95b2-2c66-468c-b46d-2c28731e4c80", "metadata": {"aucs": [0.10775599065676955, 0.10792991913428951, 0.10864295774314903], "final_y": [0.12674473872268666, 0.11835499196668597, 0.12482540314606716]}, "mutation_prompt": null}
{"id": "9c7bfa17-f02a-485c-974d-5c0a19162533", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.90  # Adjusted mutation factor for improved convergence\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.1)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced convergence by fine-tuning the exploration-exploitation balance with adjusted mutation factor.", "configspace": "", "generation": 56, "fitness": 0.11359700719434973, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.000. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "853d95b2-2c66-468c-b46d-2c28731e4c80", "metadata": {"aucs": [0.11365458556725405, 0.11320746149236327, 0.11392897452343187], "final_y": [0.11622724747668467, 0.11715313602393262, 0.11521334965821683]}, "mutation_prompt": null}
{"id": "11080eda-927e-401c-a080-791583877efb", "solution": "import numpy as np\n\nclass DynamicDifferentialOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n        self.diff_factor = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.1)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                diff_mutation = self.diff_factor * (pop[np.random.choice(subpop2_indices)] - pop[np.random.choice(subpop2_indices)])\n                candidate = pop[idx] + diff_mutation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "DynamicDifferentialOptimizer", "description": "Integrate a dynamic differential perturbation mechanism for enhanced local search in the coevolutionary framework.", "configspace": "", "generation": 57, "fitness": 0.1117349678665452, "feedback": "The algorithm DynamicDifferentialOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.119 (0. is the best).", "error": "", "parent_id": "853d95b2-2c66-468c-b46d-2c28731e4c80", "metadata": {"aucs": [0.11042798511020435, 0.1124360421342796, 0.11234087635515166], "final_y": [0.11712989388469197, 0.11866171323792007, 0.1203447699395721]}, "mutation_prompt": null}
{"id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)  # Changed decay exponent from 1.1 to 1.15\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Slightly adjusted the decay exponent for an adaptive mutation strategy to further refine exploration-exploitation balance.", "configspace": "", "generation": 58, "fitness": 0.11488852190813263, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.113 (0. is the best).", "error": "", "parent_id": "853d95b2-2c66-468c-b46d-2c28731e4c80", "metadata": {"aucs": [0.11512589666795325, 0.11557899686900475, 0.11396067218743988], "final_y": [0.1120324782532951, 0.11051256684266153, 0.11557757944751512]}, "mutation_prompt": null}
{"id": "5f37fd79-9ac1-40a5-9a6e-ebdcfbd24390", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            dimensional_decay = np.exp(-self.adaptive_factor * (evaluations / self.budget) * np.arange(self.dim))  # New adaptive dimensional decay\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            velocities *= dimensional_decay  # Apply decay to velocities\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Introduced adaptive dimensional learning rates for improved convergence by adjusting velocities with a decay factor based on dimensional interactions.", "configspace": "", "generation": 59, "fitness": 0.11151284919297637, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.124 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11041454607778212, 0.11157321606442927, 0.1125507854367177], "final_y": [0.12663119448511784, 0.12277739928500597, 0.12215245213561488]}, "mutation_prompt": null}
{"id": "3f3dcc0b-ae92-46a2-8730-2b3ab8eba796", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)  # Changed decay exponent from 1.15 to 1.2\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Adjusted the adaptive mutation factor's decay exponent to 1.2 to enhance exploration capabilities slightly.", "configspace": "", "generation": 60, "fitness": 0.11487791364169216, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.113 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11514730254837546, 0.11550847389866359, 0.11397796447803743], "final_y": [0.11203844779707639, 0.11048869623636148, 0.11555404922151713]}, "mutation_prompt": null}
{"id": "1325ad37-967a-4cb6-8a82-85fd1dac8289", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                # Adjust mutation with a dynamic range based on evaluations\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.15, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Introduces dynamic mutation factor adjustment and enhances population diversity to balance exploration and exploitation more effectively.", "configspace": "", "generation": 61, "fitness": 0.11205055552926353, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.119 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11309549842754418, 0.11095745832474846, 0.11209870983549797], "final_y": [0.11630462478727266, 0.11937749959403687, 0.12214387168790608]}, "mutation_prompt": null}
{"id": "78b3fcdd-c2ab-4739-9d3b-b0728da37081", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)  # Changed decay exponent from 1.1 to 1.15\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Introduced a slight increase in the adaptive mutation factor to enhance exploration capabilities.", "configspace": "", "generation": 62, "fitness": 0.11488852190813263, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.113 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11512589666795325, 0.11557899686900475, 0.11396067218743988], "final_y": [0.1120324782532951, 0.11051256684266153, 0.11557757944751512]}, "mutation_prompt": null}
{"id": "90ea97b8-5d68-4705-9307-19fcacaf057c", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim) * 0.8))  # Adjusted range\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Adjusted the range of the standard Cauchy distribution for Levy flights to enhance exploration capabilities.", "configspace": "", "generation": 63, "fitness": 0.11424180021919672, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.002. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11405047244855604, 0.11643224351790227, 0.11224268469113186], "final_y": [0.11622535007809909, 0.11048902727046084, 0.12209465103299999]}, "mutation_prompt": null}
{"id": "5dfe62a1-47a8-4622-adc5-d2cc5433f747", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.45  # Changed from 0.4 to 0.45\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Slightly adjusted the inertia weight for better velocity control in particle swarm optimization.", "configspace": "", "generation": 64, "fitness": 0.11326631293385063, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.118 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.1145507731676656, 0.11251043549478512, 0.11273773013910116], "final_y": [0.116229907622872, 0.11835780216563363, 0.12079665311770338]}, "mutation_prompt": null}
{"id": "af41dd77-48b3-44e9-b098-389ab4c78db5", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)  # Changed decay exponent from 1.1 to 1.15\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Improved exploration by adjusting the mutation factor based on the cosine function of the evaluation ratio.", "configspace": "", "generation": 65, "fitness": 0.11488852190813263, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.113 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11512589666795325, 0.11557899686900475, 0.11396067218743988], "final_y": [0.1120324782532951, 0.11051256684266153, 0.11557757944751512]}, "mutation_prompt": null}
{"id": "83d5f81d-7c07-449e-acfa-69da1b804e24", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n        self.elite_archive_size = 5  # New parameter\n        self.elite_archive = []  # New parameter\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n            # Elite archiving logic\n            elite_candidates = [pop[i] for i in np.argsort(scores)[:self.elite_archive_size]]\n            self.elite_archive.extend(elite_candidates)\n            self.elite_archive = sorted(self.elite_archive, key=lambda x: func(x))[:self.elite_archive_size]\n            for e in self.elite_archive:  # Feedback learning from elite archive\n                if func(e) < global_best_score:\n                    global_best = e\n                    global_best_score = func(e)\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Introduced elite archiving and feedback learning to utilize successful strategies in future generations.", "configspace": "", "generation": 66, "fitness": 0.11269075280940317, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.002. And the mean value of best solutions found was 0.117 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11177295843200186, 0.11567718748145306, 0.11062211251475462], "final_y": [0.1133163076402528, 0.11175482324747099, 0.12572746649043176]}, "mutation_prompt": null}
{"id": "5008056b-a644-4c4b-8e9c-9b75f92a76f7", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim))**0.8)  # Adjusted decay exponent for Levy flights\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Slightly adjusted the decay exponent for Levy flight step size to refine exploration-exploitation balance.", "configspace": "", "generation": 67, "fitness": 0.11264625646802758, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.120 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11396629726207597, 0.11155233170971468, 0.11242014043229209], "final_y": [0.11624986512128843, 0.12131215503214299, 0.12172671699445314]}, "mutation_prompt": null}
{"id": "71e1638a-e03d-4208-856b-0a1baacc5188", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)  # Changed decay exponent from 1.1 to 1.15\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (0.5 - evaluations / self.budget)  # Adjusted calculation\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Adjusted the dynamic crossover rate calculation to improve balance between exploration and exploitation.", "configspace": "", "generation": 68, "fitness": 0.11373722939642668, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.001. And the mean value of best solutions found was 0.114 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11260574594051287, 0.11520857102946414, 0.11339737121930304], "final_y": [0.11622500176333272, 0.11024054247389725, 0.11648085039254064]}, "mutation_prompt": null}
{"id": "84ac27fc-7d26-4fe5-a8c5-21cd75bb8e3d", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.1)  # Revert to original decay exponent\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n                elif np.random.rand() < 0.1:  # Introduce probabilistic replacement to enhance diversity\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n                elif np.random.rand() < 0.05:  # Another probabilistic replacement condition\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced diversity and exploitation balance using a novel dual-adaptive mutation and selection strategy.", "configspace": "", "generation": 69, "fitness": 0.11127392658252822, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.111 with standard deviation 0.001. And the mean value of best solutions found was 0.120 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11129023636668278, 0.10962968257537686, 0.112901860805525], "final_y": [0.12117140745374844, 0.12055412291838052, 0.11754389417335587]}, "mutation_prompt": null}
{"id": "7c6e4873-a243-4825-a133-8f6407ddff5e", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)  # Changed decay exponent from 1.15 to 1.2\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Improved the decay exponent for adaptive mutation strategy to enhance exploration capabilities.", "configspace": "", "generation": 70, "fitness": 0.11487791364169216, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.113 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11514730254837546, 0.11550847389866359, 0.11397796447803743], "final_y": [0.11203844779707639, 0.11048869623636148, 0.11555404922151713]}, "mutation_prompt": null}
{"id": "3787a41c-2719-4d6d-8328-5398eb83271e", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.92  # Changed from 0.95 to 0.92\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced exploration by fine-tuning the mutation factor for better adaptability.", "configspace": "", "generation": 71, "fitness": 0.11422009217787694, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.001. And the mean value of best solutions found was 0.115 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11343190918787038, 0.11535442529563822, 0.11387394205012225], "final_y": [0.11630451188605007, 0.11089092875432349, 0.11649564436050186]}, "mutation_prompt": null}
{"id": "c3985628-dbfe-4a87-8cba-6fd83d848c1d", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.92  # Changed from 0.95 to 0.92\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Fine-tuned the mutation factor for a more dynamic exploration strategy across the budget.", "configspace": "", "generation": 72, "fitness": 0.11422009217787694, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.001. And the mean value of best solutions found was 0.115 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11343190918787038, 0.11535442529563822, 0.11387394205012225], "final_y": [0.11630451188605007, 0.11089092875432349, 0.11649564436050186]}, "mutation_prompt": null}
{"id": "b2363b5e-3397-4325-8563-fcaa36d4f19e", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * ((self.budget - evaluations) / self.budget)**0.5  # Made crossover more adaptive\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                levy_factor = ((self.budget - evaluations) / self.budget)  # Adaptive levy step size\n                candidate = pop[idx] + levy_step * levy_factor\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Introduced an adaptive levy flight strategy and improved dynamic crossover rate to enhance exploration and convergence balance.", "configspace": "", "generation": 73, "fitness": 0.11253410046118602, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.000. And the mean value of best solutions found was 0.119 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11297787790247937, 0.11246040434853333, 0.11216401913254537], "final_y": [0.11627065895988575, 0.11755959331321242, 0.12201008697916316]}, "mutation_prompt": null}
{"id": "691c14d0-61a0-499d-bab5-c491f0f60397", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.14)  # Changed decay exponent from 1.15 to 1.14\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Fine-tuned the adaptive mutation's decay exponent for a more balanced convergence behavior.", "configspace": "", "generation": 74, "fitness": 0.11488762394053142, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.113 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11512276865038229, 0.11557941793083104, 0.11396068524038094], "final_y": [0.11208638956193573, 0.1105237258195424, 0.11557801334525952]}, "mutation_prompt": null}
{"id": "ef3e51b3-7a72-4d14-b6fb-a34b1ed6b6ed", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.1)  # Revert decay exponent to 1.1\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (0.5 + 0.5 * np.sin(evaluations * np.pi / self.budget))\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Improved exploration via dynamic mutation rate adjustment and adaptive crossover for enhanced convergence.", "configspace": "", "generation": 75, "fitness": 0.11330127211100749, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.002. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11174649769743583, 0.11554377081307154, 0.11261354782251509], "final_y": [0.11897296342543229, 0.11104601787628487, 0.11782422317211971]}, "mutation_prompt": null}
{"id": "2d7e02b3-6984-4a20-ae96-4128b080f4a2", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)  # Changed decay exponent from 1.15 to 1.2\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced adaptive mutation by adjusting the decay exponent for improved convergence speed and balance.", "configspace": "", "generation": 76, "fitness": 0.11487791364169216, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.113 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11514730254837546, 0.11550847389866359, 0.11397796447803743], "final_y": [0.11203844779707639, 0.11048869623636148, 0.11555404922151713]}, "mutation_prompt": null}
{"id": "0adc38d5-2296-4942-bea7-45485a330f79", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)  # Changed decay exponent from 1.1 to 1.15\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * np.exp(-evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Fine-tuned the dynamic crossover rate equation for improved solution exploration-exploitation balance.", "configspace": "", "generation": 77, "fitness": 0.11450532741629856, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.114 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11395115598287775, 0.11559602280327108, 0.11396880346274685], "final_y": [0.116247671814811, 0.11052104104420823, 0.11550217437685895]}, "mutation_prompt": null}
{"id": "d7d1fb59-6bf3-46dd-81e3-efe9c57c2837", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.16)  # Changed decay exponent from 1.15 to 1.16\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced adaptive mutation strategy by slightly increasing the decay exponent for better exploration and exploitation balance.", "configspace": "", "generation": 78, "fitness": 0.1148863613929942, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.113 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11514652569851791, 0.11557832056086803, 0.11393423791959667], "final_y": [0.11203365552219235, 0.1105138876501861, 0.11589517449254394]}, "mutation_prompt": null}
{"id": "72a12506-c437-4eb1-b8ca-9522173bbe3e", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 1.05  # Adjusted from 0.95 to 1.05\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Adjusted mutation factor to enhance exploration during early optimization stages.", "configspace": "", "generation": 79, "fitness": 0.1141620466744638, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.001. And the mean value of best solutions found was 0.115 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11308835877209822, 0.11520339536981572, 0.11419438588147746], "final_y": [0.11787099594750972, 0.11127522584951832, 0.11537460245995601]}, "mutation_prompt": null}
{"id": "14542129-6527-44d3-848b-30890e63b849", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.97  # Increased mutation factor\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Improved exploration by slightly increasing the mutation factor for more diverse candidate solutions.", "configspace": "", "generation": 80, "fitness": 0.11478043911396903, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.113 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11503878196652007, 0.11527513728823635, 0.11402739808715068], "final_y": [0.1120498411587868, 0.11125346724408491, 0.11548619766130097]}, "mutation_prompt": null}
{"id": "691992cf-013a-4140-8aca-5b9829ea8bf4", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.97  # Increased mutation factor from 0.95 to 0.97\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Improved exploration by slightly increasing the mutation factor, enhancing diversification in search space.", "configspace": "", "generation": 81, "fitness": 0.11478043911396903, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.113 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11503878196652007, 0.11527513728823635, 0.11402739808715068], "final_y": [0.1120498411587868, 0.11125346724408491, 0.11548619766130097]}, "mutation_prompt": null}
{"id": "f7447606-11cf-40fd-a21f-c77518a386b5", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)  # Changed decay exponent from 1.1 to 1.15\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * np.exp(-evaluations / (2 * self.budget))  # Slightly modified dynamic crossover rate calculation\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced exploration by slightly modifying the dynamic crossover rate calculation for better adaptability.", "configspace": "", "generation": 82, "fitness": 0.11353767942069644, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.001. And the mean value of best solutions found was 0.115 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11236632135532121, 0.11436073384071532, 0.1138859830660528], "final_y": [0.11946510501798002, 0.11074816286781242, 0.11521343523511873]}, "mutation_prompt": null}
{"id": "e57f8283-748a-4577-bbf0-d6799b691973", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 1.00  # Increased mutation factor from 0.95 to 1.00\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Introduced a minor increase in the mutation factor to enhance search space exploration.", "configspace": "", "generation": 83, "fitness": 0.11473041219710083, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.000. And the mean value of best solutions found was 0.113 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11507370198490174, 0.11490527397607886, 0.11421226063032186], "final_y": [0.11214652212313336, 0.11100204722793872, 0.11515017119639881]}, "mutation_prompt": null}
{"id": "f1ae5d05-f632-4cfe-b67c-992f4828d7a0", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.97  # Increased mutation factor slightly from 0.95 to 0.97\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced balance between exploration and exploitation by adjusting the mutation factor for better diversity.", "configspace": "", "generation": 84, "fitness": 0.11478043911396903, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.113 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11503878196652007, 0.11527513728823635, 0.11402739808715068], "final_y": [0.1120498411587868, 0.11125346724408491, 0.11548619766130097]}, "mutation_prompt": null}
{"id": "f144464c-0a70-4f00-92aa-1567f1420a4c", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)  # Changed decay exponent from 1.15 to 1.2\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Further adjusted the adaptive mutation strategy by modifying the decay exponent for better exploration-exploitation balance.", "configspace": "", "generation": 85, "fitness": 0.11487791364169216, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.113 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11514730254837546, 0.11550847389866359, 0.11397796447803743], "final_y": [0.11203844779707639, 0.11048869623636148, 0.11555404922151713]}, "mutation_prompt": null}
{"id": "1f1722fd-b866-43f8-b883-7824bc4ae4a4", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)**0.5  # Changed exponent from 1 to 0.5\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Slightly adjusted the dynamic crossover rate to improve solution diversity and exploration during optimization.", "configspace": "", "generation": 86, "fitness": 0.11334731876014281, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11223762432281315, 0.11396733698907946, 0.11383699496853583], "final_y": [0.12037309214398029, 0.11211235169416256, 0.1153252016160975]}, "mutation_prompt": null}
{"id": "0a9b9661-4851-4428-ad62-b9fbeb19a543", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.97  # Changed mutation factor from 0.95 to 0.97\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(personal_best_scores) < global_best_score:\n                global_best_score = np.min(personal_best_scores)\n                global_best = personal_best[np.argmin(personal_best_scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Adjusted mutation factor to improve adaptive exploration in early stages.", "configspace": "", "generation": 87, "fitness": 0.11478043911396903, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.113 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11503878196652007, 0.11527513728823635, 0.11402739808715068], "final_y": [0.1120498411587868, 0.11125346724408491, 0.11548619766130097]}, "mutation_prompt": null}
{"id": "1ed90eff-082a-48fa-8625-fb0a6a554448", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(scores) < global_best_score:  # Change: Update global best based on current scores\n                global_best_score = np.min(scores)\n                global_best = pop[np.argmin(scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Introduced a slight improvement in score updating to better track personal bests.", "configspace": "", "generation": 88, "fitness": 0.11489992847791035, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.113 (0. is the best).", "error": "", "parent_id": "f60bad35-cfff-4869-b2b9-6f739eb99c3f", "metadata": {"aucs": [0.11512589666795325, 0.1156132165783379, 0.11396067218743988], "final_y": [0.1120324782532951, 0.11063984449599218, 0.11557757944751512]}, "mutation_prompt": null}
{"id": "aaff93b1-f88f-422f-a64e-39f57069962b", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.98  # Change: Adjusted mutation factor\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(scores) < global_best_score:  # Change: Update global best based on current scores\n                global_best_score = np.min(scores)\n                global_best = pop[np.argmin(scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Slightly enhanced the algorithm by adjusting mutation factor scaling for better exploration.", "configspace": "", "generation": 89, "fitness": 0.11483386370713748, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.113 (0. is the best).", "error": "", "parent_id": "1ed90eff-082a-48fa-8625-fb0a6a554448", "metadata": {"aucs": [0.11503321797176247, 0.11537017153286055, 0.11409820161678941], "final_y": [0.11210075779183648, 0.11125548575576294, 0.11523102205905211]}, "mutation_prompt": null}
{"id": "765335aa-7c15-48d1-b0fc-376514dd6418", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(scores) < global_best_score - 1e-5:  # Change: Introduced a small threshold to update global best\n                global_best_score = np.min(scores)\n                global_best = pop[np.argmin(scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Improved global best updating logic by using a tolerance threshold to prevent premature convergence.", "configspace": "", "generation": 90, "fitness": 0.1148956838342412, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.113 (0. is the best).", "error": "", "parent_id": "1ed90eff-082a-48fa-8625-fb0a6a554448", "metadata": {"aucs": [0.11511336130994632, 0.11561301800533741, 0.11396067218743988], "final_y": [0.11209203913967591, 0.11064183693840646, 0.11557757944751512]}, "mutation_prompt": null}
{"id": "71c76876-58d7-420d-ba85-f5c27905ae8b", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_score = np.min(scores)\n                global_best = pop[np.argmin(scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)  # Adjusted exponent\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Slightly adjusted mutation factor decay to improve convergence speed.", "configspace": "", "generation": 91, "fitness": 0.11487120245037093, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.113 (0. is the best).", "error": "", "parent_id": "1ed90eff-082a-48fa-8625-fb0a6a554448", "metadata": {"aucs": [0.11514730254837546, 0.1154883403246999, 0.11397796447803743], "final_y": [0.11203844779707639, 0.11051003553606109, 0.11555404922151713]}, "mutation_prompt": null}
{"id": "914e0f92-3111-48f5-8ece-57d9dd5c8a5c", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            # Change: Introduce nonlinear decay to inertia weight\n            inertia_weight = self.w * (1 - (evaluations / self.budget)**2)\n            velocities = inertia_weight * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_score = np.min(scores)\n                global_best = pop[np.argmin(scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Introduced a small tweak to the velocity update to include a nonlinear decay in the inertia weight for better exploration-exploitation balance.", "configspace": "", "generation": 92, "fitness": 0.11457244905317854, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.114 (0. is the best).", "error": "", "parent_id": "1ed90eff-082a-48fa-8625-fb0a6a554448", "metadata": {"aucs": [0.11404043555955301, 0.11547886390969708, 0.11419804769028552], "final_y": [0.11622334173363735, 0.11079346891328745, 0.1152964917700432]}, "mutation_prompt": null}
{"id": "021068e7-2552-4b92-89a7-16820c293950", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(scores) < global_best_score or evaluations % 50 == 0:  # Change: Update global best more frequently\n                global_best_score = np.min(scores)\n                global_best = pop[np.argmin(scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced global best update mechanism to improve convergence accuracy.", "configspace": "", "generation": 93, "fitness": 0.1141303468699646, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.001. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "1ed90eff-082a-48fa-8625-fb0a6a554448", "metadata": {"aucs": [0.11454447961268, 0.1156132165783379, 0.11223334441887589], "final_y": [0.11444643376101349, 0.11063984449599218, 0.1214192174393427]}, "mutation_prompt": null}
{"id": "f2755416-4b06-492a-bbf9-d69e7717fa33", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            # Change: line for updating inertia weight\n            self.w = 0.9 - (evaluations / self.budget) * 0.5\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(scores) < global_best_score:  # Change: Update global best based on current scores\n                global_best_score = np.min(scores)\n                global_best = pop[np.argmin(scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Improved the inertia weight adaptation strategy to enhance exploration and exploitation balance.", "configspace": "", "generation": 94, "fitness": 0.1079356065927715, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.108 with standard deviation 0.001. And the mean value of best solutions found was 0.122 (0. is the best).", "error": "", "parent_id": "1ed90eff-082a-48fa-8625-fb0a6a554448", "metadata": {"aucs": [0.10765371121964606, 0.10747878841025793, 0.1086743201484105], "final_y": [0.12678169840943354, 0.11690846893773366, 0.12376023596242802]}, "mutation_prompt": null}
{"id": "de5b82a6-3366-4b96-a893-af47623a9db6", "solution": "import numpy as np\n\nclass QuantumInspiredChaosPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 1.5   # Cognitive component\n        self.c2 = 2.0   # Social component\n        self.w = 0.5    # Inertia weight\n        self.chaotic_factor = 0.7  # Initial chaotic factor\n        self.beta = 0.5  # Quantum factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        z = np.random.random(self.population_size)  # Chaotic variable\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            z = self.chaotic_factor * z * (1 - z)  # Logistic map for chaotic sequence\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities + z[:, np.newaxis] * (np.random.uniform(lb, ub, (self.population_size, self.dim)) - pop)\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_score = np.min(scores)\n                global_best = pop[np.argmin(scores)]\n\n            # Quantum-inspired update\n            for i in range(self.population_size):\n                quantum_jump = self.beta * (np.random.uniform(lb, ub, self.dim) - pop[i])\n                quantum_candidate = pop[i] + quantum_jump\n                quantum_candidate = np.clip(quantum_candidate, lb, ub)\n                quantum_score = func(quantum_candidate)\n                evaluations += 1\n                if quantum_score < scores[i]:\n                    scores[i] = quantum_score\n                    pop[i] = quantum_candidate\n\n        return global_best, global_best_score", "name": "QuantumInspiredChaosPSO", "description": "Quantum-Inspired Particle Swarm Optimization with Chaotic Mapping for enhanced exploration and exploitation balance.", "configspace": "", "generation": 95, "fitness": 0.112130441735434, "feedback": "The algorithm QuantumInspiredChaosPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "1ed90eff-082a-48fa-8625-fb0a6a554448", "metadata": {"aucs": [0.11276579186471725, 0.11112676489778095, 0.1124987684438038], "final_y": [0.11653741957368069, 0.11884033244190162, 0.11338354944405116]}, "mutation_prompt": null}
{"id": "1881619e-5fdb-4916-baae-b11d49f68945", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(scores) < global_best_score:  # Change: Update global best based on current scores\n                global_best_score = np.min(scores)\n                global_best = pop[np.argmin(scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.2)  # Slight change here\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced adaptation by tweaking the mutation factor decay rate for better convergence.", "configspace": "", "generation": 96, "fitness": 0.11487120245037093, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.113 (0. is the best).", "error": "", "parent_id": "1ed90eff-082a-48fa-8625-fb0a6a554448", "metadata": {"aucs": [0.11514730254837546, 0.1154883403246999, 0.11397796447803743], "final_y": [0.11203844779707639, 0.11051003553606109, 0.11555404922151713]}, "mutation_prompt": null}
{"id": "09a08d35-076d-4b16-81ef-9d4bfbad981e", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            \n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_score = np.min(scores)  # Change: Enhanced selection criteria\n                global_best = pop[np.argmin(scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n\n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.15)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n                    \n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step + 0.05 * (global_best - pop[idx])  # New: slight global pull\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced diversity through adaptive population strategies and improved global best updates.", "configspace": "", "generation": 97, "fitness": 0.11345316184897813, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.117 (0. is the best).", "error": "", "parent_id": "1ed90eff-082a-48fa-8625-fb0a6a554448", "metadata": {"aucs": [0.11374347498981308, 0.1125094838578411, 0.11410652669928023], "final_y": [0.11662243514222104, 0.1186635173551327, 0.11535647259421511]}, "mutation_prompt": null}
{"id": "5646ac53-7b3b-43f1-a33e-fe4c19c155a0", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_score = np.min(scores)\n                global_best = pop[np.argmin(scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n\n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.1)\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n            elitist_idx = np.argmin(scores)\n            if np.random.rand() < 0.1:\n                pop[elitist_idx] = global_best\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced adaptive mutation and elitism for improved convergence in coevolutionary optimization.", "configspace": "", "generation": 98, "fitness": 0.11267823614678123, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.000. And the mean value of best solutions found was 0.119 (0. is the best).", "error": "", "parent_id": "1ed90eff-082a-48fa-8625-fb0a6a554448", "metadata": {"aucs": [0.11272185968655446, 0.11317577627827113, 0.11213707247551807], "final_y": [0.1189346644355227, 0.11838274767407353, 0.12075259227340562]}, "mutation_prompt": null}
{"id": "f6dc6a7f-16cf-4070-b024-f0f4cf9ef771", "solution": "import numpy as np\n\nclass EnhancedCoevolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0\n        self.c2 = 1.5\n        self.w = 0.4\n        self.mutation_factor = 0.95\n        self.crossover_rate = 0.85\n        self.subpop_size_factor = 0.5\n        self.adaptive_factor = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = pop + velocities\n            pop = np.clip(pop, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best[i] = pop[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_score = np.min(scores)\n                global_best = pop[np.argmin(scores)]\n\n            self.subpop_size = int(self.population_size * self.subpop_size_factor)\n            indices = np.arange(self.population_size)\n            np.random.shuffle(indices)\n            subpop1_indices = indices[:self.subpop_size]\n            subpop2_indices = indices[self.subpop_size:]\n            \n            for idx in subpop1_indices:\n                idxs = [i for i in subpop1_indices if i != idx]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_mutation = self.mutation_factor * np.exp(-self.adaptive_factor * (evaluations / self.budget)**1.25)  # Change made here\n                mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n                dynamic_crossover_rate = self.crossover_rate * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_crossover_rate, mutant, pop[idx])\n\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < scores[idx]:\n                    scores[idx] = trial_score\n                    pop[idx] = trial\n\n            for idx in subpop2_indices:\n                levy_step = np.random.normal(0, 0.1, self.dim) * (ub - lb) * (np.abs(np.random.standard_cauchy(self.dim)))\n                candidate = pop[idx] + levy_step\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n                if candidate_score < scores[idx]:\n                    scores[idx] = candidate_score\n                    pop[idx] = candidate\n\n        return global_best, global_best_score", "name": "EnhancedCoevolutionaryOptimizer", "description": "Enhanced adaptive mutation factor to improve exploration as evaluations increase.", "configspace": "", "generation": 99, "fitness": 0.11483222772396488, "feedback": "The algorithm EnhancedCoevolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.113 (0. is the best).", "error": "", "parent_id": "1ed90eff-082a-48fa-8625-fb0a6a554448", "metadata": {"aucs": [0.1151188602176042, 0.11539837442030176, 0.11397944853398867], "final_y": [0.11214460897121936, 0.11079530512283553, 0.11550558068624173]}, "mutation_prompt": null}

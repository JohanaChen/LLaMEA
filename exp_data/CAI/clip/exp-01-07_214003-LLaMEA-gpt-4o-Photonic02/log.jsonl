{"id": "4212e12c-b11a-422f-be5c-ba3d1bc808a5", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.5   # Inertia weight\n        self.F = 0.5   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "A hybrid algorithm combining Particle Swarm Optimization (PSO) and Differential Evolution (DE) to balance exploration and exploitation for effective optimization of complex black box functions.", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 187, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 264, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 128, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 74, in __call__\n  File \"<string>\", line 52, in differential_evolution_step\nNameError: name 'func' is not defined\n.", "error": "NameError(\"name 'func' is not defined\")Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 187, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 264, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 128, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 74, in __call__\n  File \"<string>\", line 52, in differential_evolution_step\nNameError: name 'func' is not defined\n", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "2bc17557-5456-4f94-b11e-86261fb4dfcb", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.5   # Inertia weight\n        self.F = 0.5   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):  # Fixed: added 'func' parameter\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)  # Fixed: added 'func' argument\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "A hybrid algorithm blending PSO and DE for robust optimization, correcting a function definition oversight.", "configspace": "", "generation": 1, "fitness": 0.26916892040494184, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.269 with standard deviation 0.042. And the mean value of best solutions found was 0.020 (0. is the best).", "error": "", "parent_id": "4212e12c-b11a-422f-be5c-ba3d1bc808a5", "metadata": {"aucs": [0.22750368800830512, 0.3258296212022611, 0.25417345200425934], "final_y": [0.04625895169199143, 0.003021847508363628, 0.010310313747313612]}, "mutation_prompt": null}
{"id": "ae22915a-1579-4d4c-9799-aa00ff1d05a9", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Adaptive inertia weight, changed from 0.5 to 0.9\n        self.F = 0.5   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):  # Fixed: added 'func' parameter\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)  # Fixed: added 'func' argument\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "A hybrid algorithm blending PSO and DE for robust optimization with an adaptive inertia weight.", "configspace": "", "generation": 2, "fitness": 0.2593879547376435, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.259 with standard deviation 0.019. And the mean value of best solutions found was 0.043 (0. is the best).", "error": "", "parent_id": "2bc17557-5456-4f94-b11e-86261fb4dfcb", "metadata": {"aucs": [0.23354223557177178, 0.2666305615084893, 0.2779910671326694], "final_y": [0.07988476114108715, 0.03181804351516647, 0.015958260719013705]}, "mutation_prompt": null}
{"id": "8ff0bc20-9bcf-4468-a386-a742fc723b85", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.5   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):  # Fixed: added 'func' parameter\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.5 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)  # Fixed: added 'func' argument\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Optimized inertia weight to dynamically adjust from 0.9 to 0.4 for improved convergence.", "configspace": "", "generation": 3, "fitness": 0.2965060615648228, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.297 with standard deviation 0.004. And the mean value of best solutions found was 0.010 (0. is the best).", "error": "", "parent_id": "2bc17557-5456-4f94-b11e-86261fb4dfcb", "metadata": {"aucs": [0.3005543011358278, 0.29790571600800897, 0.2910581675506315], "final_y": [0.006112676550086048, 0.00925234508498593, 0.013369461527384646]}, "mutation_prompt": null}
{"id": "41888788-e2e8-47d1-b2bc-8d8097276c79", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.5   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n        self.local_search_frequency = 5\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds, iteration, max_iterations):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.w = self.w_max - ((self.w_max - self.w_min) * (iteration / max_iterations))  # Annealing-inspired inertia\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def local_search(self, func):\n        for i in range(self.population_size):\n            candidate = self.population[i] + np.random.normal(0, 0.1, self.dim)\n            candidate_fitness = func(candidate)\n            if candidate_fitness < self.personal_best_fitness[i]:\n                self.population[i] = candidate\n                self.personal_best_fitness[i] = candidate_fitness\n                self.personal_best[i] = candidate\n                if candidate_fitness < self.global_best_fitness:\n                    self.global_best_fitness = candidate_fitness\n                    self.global_best = candidate\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n        max_iterations = int(self.budget / self.population_size)\n        iteration = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.update_particles(func.bounds, iteration, max_iterations)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            if iteration % self.local_search_frequency == 0:\n                self.local_search(func)\n            iteration += 1\n\n        return self.global_best, self.global_best_fitness", "name": "EnhancedHybridPSODE", "description": "Enhanced HybridPSODE with adaptive local search and annealing-inspired inertia reduction for improved convergence.", "configspace": "", "generation": 4, "fitness": 0.29105457547106356, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.291 with standard deviation 0.003. And the mean value of best solutions found was 0.014 (0. is the best).", "error": "", "parent_id": "8ff0bc20-9bcf-4468-a386-a742fc723b85", "metadata": {"aucs": [0.29409764265562766, 0.28788782322994766, 0.2911782605276153], "final_y": [0.01648533386816329, 0.017542387714968164, 0.007100785197504296]}, "mutation_prompt": null}
{"id": "5efa24e8-fcb5-45d1-a352-379005226f5a", "solution": "import numpy as np\n\nclass AdaptiveModeSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.F_base = 0.5\n        self.CR = 0.9\n        self.velocity_clamp = (-1, 1)\n\n    def diversity_metric(self, population):\n        return np.mean(np.std(population, axis=0))\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds, w):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def adaptive_differential_evolution(self, bounds, diversity, func):\n        lb, ub = bounds.lb, bounds.ub\n        F = self.F_base + 0.5 * diversity  # Adaptive scale factor based on diversity\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            \n            diversity = self.diversity_metric(self.population)\n            w = self.w_min + (self.w_max - self.w_min) * (1 - diversity)\n            self.update_particles(func.bounds, w)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            \n            self.adaptive_differential_evolution(func.bounds, diversity, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "AdaptiveModeSearch", "description": "Adaptive Mode Search (AMS) Algorithm, combining Particle Swarm Optimization with Adaptive Differential Evolution to balance exploration and exploitation based on population diversity.", "configspace": "", "generation": 5, "fitness": 0.11876728758981754, "feedback": "The algorithm AdaptiveModeSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.119 with standard deviation 0.006. And the mean value of best solutions found was 2.573 (0. is the best).", "error": "", "parent_id": "8ff0bc20-9bcf-4468-a386-a742fc723b85", "metadata": {"aucs": [0.1256134014747694, 0.11200634327809078, 0.11868211801659245], "final_y": [2.194859540122896, 2.730752532244437, 2.7940774173943135]}, "mutation_prompt": null}
{"id": "5d4abd64-8633-4567-83fd-017dd3f0a50d", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor (modified from 0.5 to 0.6)\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):  # Fixed: added 'func' parameter\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.5 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)  # Fixed: added 'func' argument\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Tweaked the differential evolution scale factor for enhanced exploration.", "configspace": "", "generation": 6, "fitness": 0.3053217835431475, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.305 with standard deviation 0.015. And the mean value of best solutions found was 0.008 (0. is the best).", "error": "", "parent_id": "8ff0bc20-9bcf-4468-a386-a742fc723b85", "metadata": {"aucs": [0.28571829333498244, 0.30866350130583675, 0.3215835559886232], "final_y": [0.012491655402656633, 0.006423690492489169, 0.004578323972985219]}, "mutation_prompt": null}
{"id": "cf51a380-80aa-4b33-9a5b-560faec6941f", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.5 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Adjusted cognitive parameter for improved convergence speed.  ", "configspace": "", "generation": 7, "fitness": 0.30771883920440674, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.308 with standard deviation 0.028. And the mean value of best solutions found was 0.009 (0. is the best).", "error": "", "parent_id": "5d4abd64-8633-4567-83fd-017dd3f0a50d", "metadata": {"aucs": [0.3161681898878256, 0.2696145462436145, 0.3373737814817802], "final_y": [0.005081486800058037, 0.017630967457187716, 0.0050645510451438015]}, "mutation_prompt": null}
{"id": "d7ee52fe-55ad-4bc2-bda9-6ffec3140613", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            self.F = 0.5 + 0.5 * np.random.rand()  # Change made here\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.5 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduced adaptive differential evolution scale factor to balance exploration and exploitation more effectively.", "configspace": "", "generation": 8, "fitness": 0.3052009169490557, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.305 with standard deviation 0.016. And the mean value of best solutions found was 0.007 (0. is the best).", "error": "", "parent_id": "cf51a380-80aa-4b33-9a5b-560faec6941f", "metadata": {"aucs": [0.32075710315077577, 0.3115654885422362, 0.28328015915415516], "final_y": [0.008750267147816635, 0.005617678874045046, 0.008119997044883176]}, "mutation_prompt": null}
{"id": "2cc86fa3-c07c-4f1b-8660-da20b03b3f02", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        adaptive_F = self.F * (1 - (self.global_best_fitness / np.max(self.personal_best_fitness)))\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + adaptive_F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.5 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduced adaptive mutation scaling to enhance exploration and convergence.", "configspace": "", "generation": 9, "fitness": 0.26631744823186204, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.266 with standard deviation 0.008. And the mean value of best solutions found was 0.028 (0. is the best).", "error": "", "parent_id": "cf51a380-80aa-4b33-9a5b-560faec6941f", "metadata": {"aucs": [0.2564603137536111, 0.27556478526444594, 0.2669272456775291], "final_y": [0.021362422481112295, 0.019210372803841715, 0.043947097873182045]}, "mutation_prompt": null}
{"id": "398ffbfd-395e-4de8-83c4-188ba51978a0", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.5 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Adjusted cognitive parameter for improved convergence speed.  ", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "cf51a380-80aa-4b33-9a5b-560faec6941f", "metadata": {"aucs": [0.3161681898878256, 0.2696145462436145, 0.3373737814817802], "final_y": [0.005081486800058037, 0.017630967457187716, 0.0050645510451438015]}, "mutation_prompt": null}
{"id": "f059366a-51ae-4e87-9b68-7a7ac7c5f1d8", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.3 + 0.4 * np.random.rand()  # Social parameter (dynamically adjusted)\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.5 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Dynamic social parameter tuning to enhance exploration and exploitation balance.", "configspace": "", "generation": 11, "fitness": 0.2749659990491812, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.275 with standard deviation 0.016. And the mean value of best solutions found was 0.029 (0. is the best).", "error": "", "parent_id": "cf51a380-80aa-4b33-9a5b-560faec6941f", "metadata": {"aucs": [0.2532574786900613, 0.2806128200457326, 0.2910276984117496], "final_y": [0.04560329133492821, 0.027692086230108187, 0.01459193351727497]}, "mutation_prompt": null}
{"id": "7ed2b588-483c-47a3-94a2-a8dd0529e6d8", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.5 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduced adaptive dynamic adjustment of the cognitive parameter `c1` to balance exploration and exploitation.", "configspace": "", "generation": 12, "fitness": 0.30979066928148635, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.310 with standard deviation 0.021. And the mean value of best solutions found was 0.006 (0. is the best).", "error": "", "parent_id": "cf51a380-80aa-4b33-9a5b-560faec6941f", "metadata": {"aucs": [0.3109651810711501, 0.28335304894092384, 0.3350537778323851], "final_y": [0.007059181616444831, 0.007962331462129152, 0.004203775173696575]}, "mutation_prompt": null}
{"id": "123cb53c-2e8b-4186-8c47-0bb5c56f715b", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.4 * evaluations / self.budget)  # Update inertia weight dynamically (Modified)\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduced a subtle alteration to the inertia weight dynamic update formula for improved convergence.", "configspace": "", "generation": 13, "fitness": 0.3007506387547927, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.301 with standard deviation 0.025. And the mean value of best solutions found was 0.013 (0. is the best).", "error": "", "parent_id": "7ed2b588-483c-47a3-94a2-a8dd0529e6d8", "metadata": {"aucs": [0.3041129276451594, 0.26894143795905956, 0.3291975506601591], "final_y": [0.009766103263099412, 0.021281451585506882, 0.008299900603455266]}, "mutation_prompt": null}
{"id": "90b9084b-e774-44ba-8bc3-bf10eaa16da6", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.7 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Fine-tuned inertia weight decay to enhance convergence speed.", "configspace": "", "generation": 14, "fitness": 0.32671534682563075, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.327 with standard deviation 0.006. And the mean value of best solutions found was 0.003 (0. is the best).", "error": "", "parent_id": "7ed2b588-483c-47a3-94a2-a8dd0529e6d8", "metadata": {"aucs": [0.33430821501138575, 0.324905232954824, 0.3209325925106825], "final_y": [0.001350151986130252, 0.003869425852872956, 0.004673255897514894]}, "mutation_prompt": null}
{"id": "f297ae29-75dd-443b-8af4-b573218e52fd", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n        self.levy_probability = 0.3   # Probability of applying Lévy flight\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def levy_flight(self, size, dim):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size, dim) * sigma\n        v = np.random.randn(size, dim)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.7 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n            # Lévy flight for additional exploration\n            if np.random.rand() < self.levy_probability:\n                step = self.levy_flight(self.population_size, self.dim)\n                self.population = np.clip(self.population + step, func.bounds.lb, func.bounds.ub)\n\n        return self.global_best, self.global_best_fitness", "name": "EnhancedHybridPSODE", "description": "Introduce a Lévy flight-based exploration phase to enhance global search ability in the HybridPSODE algorithm.", "configspace": "", "generation": 15, "fitness": 0.2954112957464356, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.295 with standard deviation 0.041. And the mean value of best solutions found was 0.021 (0. is the best).", "error": "", "parent_id": "90b9084b-e774-44ba-8bc3-bf10eaa16da6", "metadata": {"aucs": [0.3519777685923735, 0.275754895896995, 0.25850122274993836], "final_y": [0.0021630080035331166, 0.016317868427417212, 0.04581412054990137]}, "mutation_prompt": null}
{"id": "b528e74c-a25c-4736-b8bd-22ca97441656", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -1 + 0.5 * (self.budget - evaluations) / self.budget, 1 - 0.5 * (self.budget - evaluations) / self.budget)  # Adaptive velocity clamp\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.7 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduced adaptive reduction in velocity clamp range to enhance exploration-exploitation balance.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'evaluations' is not defined\").", "error": "NameError(\"name 'evaluations' is not defined\")", "parent_id": "90b9084b-e774-44ba-8bc3-bf10eaa16da6", "metadata": {}, "mutation_prompt": null}
{"id": "379d5e43-7120-492c-bfc9-eef2f058f66f", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.8   # Differential evolution scale factor (modified from 0.6 to 0.8)\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.7 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Adjusted the differential evolution scale factor (F) for improved exploration and convergence balance.", "configspace": "", "generation": 17, "fitness": 0.23004921468549436, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.230 with standard deviation 0.072. And the mean value of best solutions found was 0.507 (0. is the best).", "error": "", "parent_id": "90b9084b-e774-44ba-8bc3-bf10eaa16da6", "metadata": {"aucs": [0.2786297295501058, 0.28285382867343767, 0.12866408583293965], "final_y": [0.015914364146711685, 0.0173167432238145, 1.4863809253015585]}, "mutation_prompt": null}
{"id": "e60cf0f7-6353-4050-b223-219a9a049f88", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            adaptive_F = self.F + (0.4 * (i / self.population_size))  # Adaptive mutation scaling\n            mutant_vector = np.clip(a + adaptive_F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.7 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduce adaptive mutation scaling in DE step for better exploration.", "configspace": "", "generation": 18, "fitness": 0.2555168528735172, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.256 with standard deviation 0.065. And the mean value of best solutions found was 0.350 (0. is the best).", "error": "", "parent_id": "90b9084b-e774-44ba-8bc3-bf10eaa16da6", "metadata": {"aucs": [0.303381226619714, 0.16420562974103614, 0.2989637022598015], "final_y": [0.00466348457715048, 1.036229939587895, 0.008420092732736298]}, "mutation_prompt": null}
{"id": "b576b300-a282-48e1-b3b9-ebdc88373d1a", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.6  # Cognitive parameter (modified from 1.7 to 1.6)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.7 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.6 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Fine-tuned cognitive parameter for improved balance between exploration and exploitation.", "configspace": "", "generation": 19, "fitness": 0.31865733026373483, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.319 with standard deviation 0.016. And the mean value of best solutions found was 0.005 (0. is the best).", "error": "", "parent_id": "90b9084b-e774-44ba-8bc3-bf10eaa16da6", "metadata": {"aucs": [0.31013026439946945, 0.30499187766889824, 0.34084984872283686], "final_y": [0.005094306916639629, 0.006445443569865754, 0.00222027587034558]}, "mutation_prompt": null}
{"id": "890f2fa2-6195-4dd4-bb56-491fca73ac05", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.8  # Cognitive parameter (modified from 1.7 to 1.8)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.7 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Enhanced cognitive parameter for improved local search in HybridPSODE.", "configspace": "", "generation": 20, "fitness": 0.32671534682563075, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.327 with standard deviation 0.006. And the mean value of best solutions found was 0.003 (0. is the best).", "error": "", "parent_id": "90b9084b-e774-44ba-8bc3-bf10eaa16da6", "metadata": {"aucs": [0.33430821501138575, 0.324905232954824, 0.3209325925106825], "final_y": [0.001350151986130252, 0.003869425852872956, 0.004673255897514894]}, "mutation_prompt": null}
{"id": "ae03d657-b148-45f1-b18c-f2cdd8311c42", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.6  # Social parameter (modified from 1.5 to 1.6)\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.7 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Fine-tune the social parameter to balance exploration and exploitation.", "configspace": "", "generation": 21, "fitness": 0.25364076283323994, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.254 with standard deviation 0.066. And the mean value of best solutions found was 0.365 (0. is the best).", "error": "", "parent_id": "90b9084b-e774-44ba-8bc3-bf10eaa16da6", "metadata": {"aucs": [0.3132509818112025, 0.2861996697937276, 0.16147163689478972], "final_y": [0.00438394704299965, 0.014174600298730352, 1.0756038063532967]}, "mutation_prompt": null}
{"id": "d1e876b4-a91b-4f37-8cbe-0c0cd189c8d1", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.8 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Enhanced inertia weight decay to improve convergence stability and performance.", "configspace": "", "generation": 22, "fitness": 0.3601846334234571, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.360 with standard deviation 0.003. And the mean value of best solutions found was 0.001 (0. is the best).", "error": "", "parent_id": "90b9084b-e774-44ba-8bc3-bf10eaa16da6", "metadata": {"aucs": [0.36474032019227476, 0.3583559933803758, 0.35745758669772054], "final_y": [0.0003803882786911175, 0.000815805350533686, 0.0007449942927362027]}, "mutation_prompt": null}
{"id": "ca0002ff-d9d2-4597-8dd3-3767111ea264", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.8 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.velocity_clamp = (-1 + 0.8 * evaluations / self.budget, 1 - 0.8 * evaluations / self.budget)  # Linearly reduce velocity clamp\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Incorporate linear velocity reduction to enhance exploration-exploitation balance.", "configspace": "", "generation": 23, "fitness": 0.33166600994701306, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.332 with standard deviation 0.005. And the mean value of best solutions found was 0.003 (0. is the best).", "error": "", "parent_id": "d1e876b4-a91b-4f37-8cbe-0c0cd189c8d1", "metadata": {"aucs": [0.3347983191117837, 0.32506975997244214, 0.3351299507568134], "final_y": [0.0018871526855285146, 0.0038360569996393847, 0.002199310402298122]}, "mutation_prompt": null}
{"id": "e97dbab2-850d-40f0-9d4b-b1c64c9e47c9", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1.5, 1.5)  # Slightly increased velocity clamp range\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.8 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Slightly increased velocity clamp range to explore larger portion of the search space, improving convergence behavior.", "configspace": "", "generation": 24, "fitness": 0.231407082382617, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.231 with standard deviation 0.097. And the mean value of best solutions found was 0.708 (0. is the best).", "error": "", "parent_id": "d1e876b4-a91b-4f37-8cbe-0c0cd189c8d1", "metadata": {"aucs": [0.16173730197708802, 0.16402910846568042, 0.3684548367050826], "final_y": [1.0756038055431238, 1.0475276722506122, 0.0014738618101190475]}, "mutation_prompt": null}
{"id": "5816578f-93e1-40e1-8b92-b4c057b8fcdb", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.7   # Differential evolution scale factor (adjusted from 0.6 to 0.7)\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.8 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Adjusting the Differential Evolution scale factor for improved exploration capabilities.", "configspace": "", "generation": 25, "fitness": 0.2156425620820774, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.216 with standard deviation 0.075. And the mean value of best solutions found was 0.708 (0. is the best).", "error": "", "parent_id": "d1e876b4-a91b-4f37-8cbe-0c0cd189c8d1", "metadata": {"aucs": [0.3212758136151249, 0.16405812793086116, 0.16159374470024612], "final_y": [0.003499688090200082, 1.045384262621789, 1.0756038056635062]}, "mutation_prompt": null}
{"id": "0997828d-b49c-400e-a839-0fd1798874d8", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.7   # Differential evolution scale factor (adjusted from 0.6 to 0.7)\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.8 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Refining the strategy by adjusting the Differential Evolution scale factor for better exploration.", "configspace": "", "generation": 26, "fitness": 0.2156425620820774, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.216 with standard deviation 0.075. And the mean value of best solutions found was 0.708 (0. is the best).", "error": "", "parent_id": "d1e876b4-a91b-4f37-8cbe-0c0cd189c8d1", "metadata": {"aucs": [0.3212758136151249, 0.16405812793086116, 0.16159374470024612], "final_y": [0.003499688090200082, 1.045384262621789, 1.0756038056635062]}, "mutation_prompt": null}
{"id": "b0fc1bbe-27aa-4f02-b08c-913ddfbc1112", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            self.F = 0.6 + 0.4 * (1 - self.global_best_fitness / max(self.personal_best_fitness))  # Adaptive F\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.8 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduce time-varying differential evolution parameters to enhance exploration and exploitation balance.", "configspace": "", "generation": 27, "fitness": 0.20425931540540063, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.204 with standard deviation 0.060. And the mean value of best solutions found was 0.719 (0. is the best).", "error": "", "parent_id": "d1e876b4-a91b-4f37-8cbe-0c0cd189c8d1", "metadata": {"aucs": [0.16174628243560096, 0.2896338378727501, 0.1613978259078508], "final_y": [1.0756038055513397, 0.006729340656550854, 1.0756038056512087]}, "mutation_prompt": null}
{"id": "1d5f7045-d9bb-46e4-8208-429b2c311079", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.65  # Differential evolution scale factor adjusted from 0.6 to 0.65\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.8 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Improved convergence by slightly adjusting the differential evolution scale factor.", "configspace": "", "generation": 28, "fitness": 0.32045506256648987, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.320 with standard deviation 0.011. And the mean value of best solutions found was 0.004 (0. is the best).", "error": "", "parent_id": "d1e876b4-a91b-4f37-8cbe-0c0cd189c8d1", "metadata": {"aucs": [0.33590400853528235, 0.3155606106483403, 0.309900568515847], "final_y": [0.002886960572279279, 0.0030043942367510177, 0.005394492316332581]}, "mutation_prompt": null}
{"id": "2583e4cf-123b-4844-b8c6-c3a9cd2abe7b", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocity_clamp = (-0.5 + (0.5 * self.global_best_fitness), 0.5 + (0.5 * self.global_best_fitness))  # Adaptive velocity clamp\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.8 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduce adaptive velocity clamping to further stabilize convergence without reducing exploration capabilities.", "configspace": "", "generation": 29, "fitness": 0.19051034051876573, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.191 with standard deviation 0.131. And the mean value of best solutions found was 3.330 (0. is the best).", "error": "", "parent_id": "d1e876b4-a91b-4f37-8cbe-0c0cd189c8d1", "metadata": {"aucs": [0.12109500430664, 0.3735627980681059, 0.07687321918155132], "final_y": [2.7039290929647644, 0.0008583761069203802, 7.285081269778163]}, "mutation_prompt": null}
{"id": "0f1e6579-c269-431b-94fc-22ff75e6538f", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.8   # Inertia weight initial value (changed from 0.9 to 0.8)\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.8 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Fine-tuned initial value for inertia weight to balance exploration and exploitation better in HybridPSODE.", "configspace": "", "generation": 30, "fitness": 0.3601846334234571, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.360 with standard deviation 0.003. And the mean value of best solutions found was 0.001 (0. is the best).", "error": "", "parent_id": "d1e876b4-a91b-4f37-8cbe-0c0cd189c8d1", "metadata": {"aucs": [0.36474032019227476, 0.3583559933803758, 0.35745758669772054], "final_y": [0.0003803882786911175, 0.000815805350533686, 0.0007449942927362027]}, "mutation_prompt": null}
{"id": "1768c6ab-a7a3-40fd-b281-7004067821b7", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.8  # Cognitive parameter (modified from 1.7 to 1.8)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.8 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Adjust cognitive parameter (`c1`) for enhanced convergence efficiency.", "configspace": "", "generation": 31, "fitness": 0.3601846334234571, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.360 with standard deviation 0.003. And the mean value of best solutions found was 0.001 (0. is the best).", "error": "", "parent_id": "d1e876b4-a91b-4f37-8cbe-0c0cd189c8d1", "metadata": {"aucs": [0.36474032019227476, 0.3583559933803758, 0.35745758669772054], "final_y": [0.0003803882786911175, 0.000815805350533686, 0.0007449942927362027]}, "mutation_prompt": null}
{"id": "a3babe5f-9d9c-45ad-b1ea-fd32a278125c", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.92 # Crossover probability increased from 0.9 to 0.92\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.8 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Slightly increase the crossover probability to enhance the exploration capability of the algorithm.", "configspace": "", "generation": 32, "fitness": 0.3475867831366386, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.348 with standard deviation 0.009. And the mean value of best solutions found was 0.001 (0. is the best).", "error": "", "parent_id": "d1e876b4-a91b-4f37-8cbe-0c0cd189c8d1", "metadata": {"aucs": [0.3385531334502818, 0.35955857242675493, 0.34464864353287905], "final_y": [0.002259314676112776, 0.0003572467517494895, 0.0013657186277633258]}, "mutation_prompt": null}
{"id": "75af5e85-f1fc-45ea-96e2-6d2ff8a97950", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.7   # Differential evolution scale factor (adjusted from 0.6 to 0.7)\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.8 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduced a performance improvement by adjusting the differential evolution scale factor.", "configspace": "", "generation": 33, "fitness": 0.2156425620820774, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.216 with standard deviation 0.075. And the mean value of best solutions found was 0.708 (0. is the best).", "error": "", "parent_id": "d1e876b4-a91b-4f37-8cbe-0c0cd189c8d1", "metadata": {"aucs": [0.3212758136151249, 0.16405812793086116, 0.16159374470024612], "final_y": [0.003499688090200082, 1.045384262621789, 1.0756038056635062]}, "mutation_prompt": null}
{"id": "427c4300-f103-449f-960e-af57db2afce1", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.8 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduced dynamic adjustment of the social parameter (c2) to enhance exploitation capabilities.", "configspace": "", "generation": 34, "fitness": 0.339705748401542, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.340 with standard deviation 0.010. And the mean value of best solutions found was 0.002 (0. is the best).", "error": "", "parent_id": "d1e876b4-a91b-4f37-8cbe-0c0cd189c8d1", "metadata": {"aucs": [0.3479072570145254, 0.32615660486938636, 0.3450533833207141], "final_y": [0.000607887498533602, 0.0024164038525641765, 0.0023605608583408782]}, "mutation_prompt": null}
{"id": "474cfb2a-99fa-43f0-8022-715d47e36cc8", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.8 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 * np.exp(-0.05 * evaluations / self.budget)  # Exponential decay of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduce exponential decay in cognitive parameter c1 to enhance convergence on challenging landscapes.", "configspace": "", "generation": 35, "fitness": 0.35051226980072875, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.351 with standard deviation 0.004. And the mean value of best solutions found was 0.001 (0. is the best).", "error": "", "parent_id": "d1e876b4-a91b-4f37-8cbe-0c0cd189c8d1", "metadata": {"aucs": [0.3480125803468803, 0.3479688507919896, 0.3555553782633164], "final_y": [0.0009009517365496138, 0.0012217350124029355, 0.001090820609434352]}, "mutation_prompt": null}
{"id": "ad001d4b-2b3e-43a7-8944-0f41ffc94f94", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            self.F = 0.6 + 0.4 * (1 - self.global_best_fitness / self.personal_best_fitness.mean())  # Adaptive F\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.8 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduce adaptive differential evolution scale factor adjustment to enhance global exploration capacity.", "configspace": "", "generation": 36, "fitness": 0.1623661642068062, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.162 with standard deviation 0.001. And the mean value of best solutions found was 1.068 (0. is the best).", "error": "", "parent_id": "d1e876b4-a91b-4f37-8cbe-0c0cd189c8d1", "metadata": {"aucs": [0.16173076436933942, 0.16395493363390468, 0.1614127946171745], "final_y": [1.0756038055118415, 1.05175786176821, 1.0756038056796184]}, "mutation_prompt": null}
{"id": "8eb475af-6c4c-4dd0-80d6-32462761f605", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        local_adjustment = np.random.rand(self.population_size, self.dim) * (self.population - self.personal_best)  # Local velocity adaptation\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity + local_adjustment\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.8 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduce local velocity adaptation in HybridPSODE to enhance convergence precision.", "configspace": "", "generation": 37, "fitness": 0.33020702908844096, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.330 with standard deviation 0.026. And the mean value of best solutions found was 0.003 (0. is the best).", "error": "", "parent_id": "d1e876b4-a91b-4f37-8cbe-0c0cd189c8d1", "metadata": {"aucs": [0.33441017631525305, 0.3592140013023445, 0.2969969096477254], "final_y": [0.0010273804661489506, 0.0010563610475916925, 0.007816487038472304]}, "mutation_prompt": null}
{"id": "f993db4b-1055-4190-b486-12504238bd19", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocity_clamp = (-0.5, 0.5)  # Adaptively updating velocity clamp\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.8 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Implemented adaptive velocity clamping for improved convergence control.", "configspace": "", "generation": 38, "fitness": 0.2557444382203141, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.256 with standard deviation 0.018. And the mean value of best solutions found was 0.025 (0. is the best).", "error": "", "parent_id": "d1e876b4-a91b-4f37-8cbe-0c0cd189c8d1", "metadata": {"aucs": [0.23221462109622282, 0.25780006498916075, 0.2772186285755588], "final_y": [0.03507921848267641, 0.012658663111564092, 0.02803234562290754]}, "mutation_prompt": null}
{"id": "bd027076-dea3-419c-b4e2-85d7dbc95648", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.8 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.F = 0.6 + (0.2 * evaluations / self.budget)  # Adaptive adjustment of F\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Enhanced convergence with adaptive differential evolution parameters.", "configspace": "", "generation": 39, "fitness": 0.33654989324379453, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.337 with standard deviation 0.025. And the mean value of best solutions found was 0.003 (0. is the best).", "error": "", "parent_id": "d1e876b4-a91b-4f37-8cbe-0c0cd189c8d1", "metadata": {"aucs": [0.3707079685204687, 0.32790656529178897, 0.31103514591912607], "final_y": [0.000619982286316883, 0.0027463748511975315, 0.005353247461021112]}, "mutation_prompt": null}
{"id": "b205e5ca-27bf-4dc9-9f2f-6edb88f71903", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -0.5, 0.5)  # Modified velocity clamp to [-0.5, 0.5]\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.8 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Dynamic velocity clamping to prevent premature convergence and enhance exploration.", "configspace": "", "generation": 40, "fitness": 0.3475551386312758, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.348 with standard deviation 0.006. And the mean value of best solutions found was 0.001 (0. is the best).", "error": "", "parent_id": "d1e876b4-a91b-4f37-8cbe-0c0cd189c8d1", "metadata": {"aucs": [0.35611737684920775, 0.34285325957702706, 0.3436947794675925], "final_y": [0.0003693734052165251, 0.0011162447720253024, 0.0007299228808527278]}, "mutation_prompt": null}
{"id": "75460193-d135-43eb-9299-e8350363ed65", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.85 # Crossover probability (changed from 0.9 to 0.85)\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.8 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Slightly decrease the crossover probability to encourage greater exploration diversity in the differential evolution step.", "configspace": "", "generation": 41, "fitness": 0.3059798774518386, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.306 with standard deviation 0.069. And the mean value of best solutions found was 0.022 (0. is the best).", "error": "", "parent_id": "d1e876b4-a91b-4f37-8cbe-0c0cd189c8d1", "metadata": {"aucs": [0.31792470604225986, 0.38425145107148695, 0.21576347524176887], "final_y": [0.003570714427060585, 0.0004254757259779393, 0.06316909368837123]}, "mutation_prompt": null}
{"id": "ebc6088f-546a-4e2b-8a2f-1dc06b77735a", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        # Apply opposition-based learning for initialization\n        opposition_population = lb + ub - self.population\n        combined_population = np.vstack((self.population, opposition_population))\n        self.population = combined_population[np.random.choice(combined_population.shape[0], self.population_size, replace=False)]\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.8 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduced opposition-based learning for population initialization to enhance diversity and improve exploration capabilities.", "configspace": "", "generation": 42, "fitness": 0.22295510897757442, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.223 with standard deviation 0.086. And the mean value of best solutions found was 0.703 (0. is the best).", "error": "", "parent_id": "d1e876b4-a91b-4f37-8cbe-0c0cd189c8d1", "metadata": {"aucs": [0.3449651392457225, 0.16387349326749334, 0.16002669441950745], "final_y": [0.001489513604348347, 1.0333507767444812, 1.0756038056188995]}, "mutation_prompt": null}
{"id": "738acf09-d8fa-459c-aa4a-e0c3ed624518", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            mutant_vector *= 1.02  # Line modified for enhanced exploration\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.8 * evaluations / self.budget)  # Update inertia weight dynamically\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduce a mutation scaling factor for enhanced exploration in the differential evolution step.", "configspace": "", "generation": 43, "fitness": 0.33171928959502694, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.332 with standard deviation 0.008. And the mean value of best solutions found was 0.003 (0. is the best).", "error": "", "parent_id": "d1e876b4-a91b-4f37-8cbe-0c0cd189c8d1", "metadata": {"aucs": [0.341175376677591, 0.3214320976295052, 0.3325503944779846], "final_y": [0.002327370536801936, 0.004643747519234194, 0.003063400251135467]}, "mutation_prompt": null}
{"id": "3d82da34-55ac-4e66-a332-6e532ea9f4a7", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Incorporate exponential decay in inertia weight for enhanced exploration-exploitation balance.", "configspace": "", "generation": 44, "fitness": 0.38839025352544826, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.388 with standard deviation 0.035. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "d1e876b4-a91b-4f37-8cbe-0c0cd189c8d1", "metadata": {"aucs": [0.43355393880942217, 0.38280892687507184, 0.3488078948918507], "final_y": [2.997056336164401e-05, 0.000312516591896068, 0.0005057288012689494]}, "mutation_prompt": null}
{"id": "9438e5a3-fb41-4a6f-b2de-a1d202f9598e", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduce adaptive adjustment of c2 to enhance balance in exploration and exploitation.", "configspace": "", "generation": 45, "fitness": 0.41074878838028034, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.411 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "3d82da34-55ac-4e66-a332-6e532ea9f4a7", "metadata": {"aucs": [0.44131152861433, 0.3976353234131781, 0.393299513113333], "final_y": [3.563481359947103e-05, 0.00014898267463201646, 8.995144937042075e-05]}, "mutation_prompt": null}
{"id": "cbd5f3ba-c451-421b-852c-ae7af8047768", "solution": "import numpy as np\n\nclass LevyFlightPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Initial inertia weight\n        self.velocity_clamp = (-1, 1)  # Velocity clamp\n        self.alpha = 0.05  # Step size for Levy flight\n\n    def levy_flight(self, step):\n        beta = 1.5\n        sigma_u = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                   (np.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size=step.shape)\n        v = np.random.normal(0, 1, size=step.shape)\n        step = u / np.abs(v) ** (1 / beta)\n        return self.alpha * step\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity + self.levy_flight(self.velocities)\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c2 = 1.5 + (0.1 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n\n        return self.global_best, self.global_best_fitness", "name": "LevyFlightPSO", "description": "Introduce a Lévy Flight-enhanced PSO with adaptive social learning to improve exploration and convergence.", "configspace": "", "generation": 46, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "9438e5a3-fb41-4a6f-b2de-a1d202f9598e", "metadata": {}, "mutation_prompt": null}
{"id": "8517a771-578e-41af-93c0-fd63e06581b0", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.65  # Differential evolution scale factor (slightly increased from 0.6 to 0.65)\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Slightly increase the scale factor F for differential evolution to enhance exploration capability. ", "configspace": "", "generation": 47, "fitness": 0.29460102113946857, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.295 with standard deviation 0.055. And the mean value of best solutions found was 0.023 (0. is the best).", "error": "", "parent_id": "9438e5a3-fb41-4a6f-b2de-a1d202f9598e", "metadata": {"aucs": [0.3310904804140572, 0.3352993540371846, 0.21741322896716397], "final_y": [0.0009447036695986167, 0.004705606745916587, 0.06354773009078228]}, "mutation_prompt": null}
{"id": "28b66111-e2f0-4462-a622-f901a02e9994", "solution": "import numpy as np\n\nclass HybridPSODERefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_initial = 1.7  # Initial cognitive parameter\n        self.c2_initial = 1.5  # Initial social parameter\n        self.w_initial = 0.9   # Initial inertia weight\n        self.w_final = 0.4     # Final inertia weight\n        self.F = 0.6           # Differential evolution scale factor\n        self.CR = 0.9          # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def calculate_diversity(self):\n        mean_pos = np.mean(self.population, axis=0)\n        diversity = np.mean(np.linalg.norm(self.population - mean_pos, axis=1))\n        return diversity\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n        diversity_threshold = 0.1 * np.linalg.norm(func.bounds.ub - func.bounds.lb)\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n\n            # Calculate current diversity\n            diversity = self.calculate_diversity()\n            \n            # Adaptive parameters based on diversity\n            self.w = self.w_final + (self.w_initial - self.w_final) * np.exp(-diversity / diversity_threshold)\n            self.c1 = self.c1_initial + (1.0 - diversity / diversity_threshold) * (2.5 - self.c1_initial)\n            self.c2 = self.c2_initial + (diversity / diversity_threshold) * (2.5 - self.c2_initial)\n\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODERefined", "description": "Introduce a non-linear inertia weight and adaptive c1, c2 adjustments based on dynamic population diversity for enhanced exploration-exploitation balance.", "configspace": "", "generation": 48, "fitness": 0.3203829840987398, "feedback": "The algorithm HybridPSODERefined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.320 with standard deviation 0.021. And the mean value of best solutions found was 0.009 (0. is the best).", "error": "", "parent_id": "9438e5a3-fb41-4a6f-b2de-a1d202f9598e", "metadata": {"aucs": [0.3467944413742694, 0.3178590660430557, 0.29649544487889423], "final_y": [0.0006522795962686501, 0.011580444395988045, 0.014434954627173978]}, "mutation_prompt": null}
{"id": "57c15892-8064-4241-838a-9d3d10d5cd37", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - (0.5 * evaluations / self.budget)  # Adaptive adjustment of w\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduce adaptive adjustment of inertia weight to enhance particle convergence and stability.", "configspace": "", "generation": 49, "fitness": 0.3135048905513159, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.314 with standard deviation 0.012. And the mean value of best solutions found was 0.005 (0. is the best).", "error": "", "parent_id": "9438e5a3-fb41-4a6f-b2de-a1d202f9598e", "metadata": {"aucs": [0.31801314235461453, 0.2966630321828738, 0.3258384971164594], "final_y": [0.0034694192825670406, 0.005688338209437257, 0.00458115664910978]}, "mutation_prompt": null}
{"id": "bd6c3cc4-d747-4ad2-b2ee-16b9e07bfab7", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.65  # Differential evolution scale factor (increased from 0.6 to 0.65)\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Slightly increase the differential evolution scale factor to enhance diversity and exploration.", "configspace": "", "generation": 50, "fitness": 0.39538860284074734, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.395 with standard deviation 0.030. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "9438e5a3-fb41-4a6f-b2de-a1d202f9598e", "metadata": {"aucs": [0.4312581498905558, 0.35706711077244524, 0.39784054785924106], "final_y": [8.46334516935742e-05, 0.0008262135788157578, 0.0001950991321446334]}, "mutation_prompt": null}
{"id": "70597874-666c-4c86-a7b7-5ffb57718e93", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size from 20 to 25\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Enhance convergence by increasing population size for better diversity.", "configspace": "", "generation": 51, "fitness": 0.3694233881311289, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.369 with standard deviation 0.007. And the mean value of best solutions found was 0.001 (0. is the best).", "error": "", "parent_id": "9438e5a3-fb41-4a6f-b2de-a1d202f9598e", "metadata": {"aucs": [0.36098756832212053, 0.3692205269475489, 0.3780620691237173], "final_y": [0.0006267758011099478, 0.0006742659439556388, 0.00034651443300162725]}, "mutation_prompt": null}
{"id": "2c0a1629-df22-45fd-9366-f30671520bb9", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-4 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Fine-tune adaptive parameter adjustment by modifying the decay rate of inertia weight for enhanced exploration-exploitation balance.", "configspace": "", "generation": 52, "fitness": 0.27672719957877306, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.277 with standard deviation 0.068. And the mean value of best solutions found was 0.143 (0. is the best).", "error": "", "parent_id": "9438e5a3-fb41-4a6f-b2de-a1d202f9598e", "metadata": {"aucs": [0.2636821992394739, 0.3657490234414148, 0.20075037605543045], "final_y": [0.019379205161111475, 0.00045873446896282764, 0.4098685298439821]}, "mutation_prompt": null}
{"id": "c11739a7-c08d-4d33-9e2d-7d24967c52a8", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.8  # Cognitive parameter (modified from 1.7 to 1.8)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Slightly enhance the convergence speed by adjusting the cognitive parameter `c1` default value from 1.7 to 1.8 to promote more exploration at the start.", "configspace": "", "generation": 53, "fitness": 0.41074878838028034, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.411 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "9438e5a3-fb41-4a6f-b2de-a1d202f9598e", "metadata": {"aucs": [0.44131152861433, 0.3976353234131781, 0.393299513113333], "final_y": [3.563481359947103e-05, 0.00014898267463201646, 8.995144937042075e-05]}, "mutation_prompt": null}
{"id": "a7eaaf14-c446-4612-a7cb-8161202b792a", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            # Adaptive velocity clamp adjustment for stability\n            self.velocity_clamp = (-1 + 0.1 * (evaluations / self.budget), 1 - 0.1 * (evaluations / self.budget))\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduce adaptive adjustment of velocity clamp to enhance stability in exploration and exploitation.", "configspace": "", "generation": 54, "fitness": 0.4024054346328452, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.402 with standard deviation 0.036. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "9438e5a3-fb41-4a6f-b2de-a1d202f9598e", "metadata": {"aucs": [0.4373647645331995, 0.41764848408378574, 0.3522030552815505], "final_y": [4.782866107615015e-05, 5.380475832025385e-05, 0.0006967990160832989]}, "mutation_prompt": null}
{"id": "9e8aba23-36bb-42db-bd18-7383b27dc7b5", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.06 * evaluations / self.budget)  # Increased adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Improve global convergence by slightly increasing adaptive adjustment of the social parameter c2.", "configspace": "", "generation": 55, "fitness": 0.40460962250773447, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.405 with standard deviation 0.039. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "9438e5a3-fb41-4a6f-b2de-a1d202f9598e", "metadata": {"aucs": [0.45411976825540723, 0.4010722722606238, 0.3586368270071725], "final_y": [1.8419781590505815e-05, 0.00019956169111532793, 0.0005022398514070125]}, "mutation_prompt": null}
{"id": "0bef0268-93a4-4571-8703-2ade9af81936", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Fine-tune initialization of velocities to enhance exploration at the start.", "configspace": "", "generation": 56, "fitness": 0.4241774402612279, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.424 with standard deviation 0.010. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "9438e5a3-fb41-4a6f-b2de-a1d202f9598e", "metadata": {"aucs": [0.4120485726250317, 0.4358199888524861, 0.42466375930616596], "final_y": [7.767764883237583e-05, 3.2341080483052197e-05, 7.506702328224853e-05]}, "mutation_prompt": null}
{"id": "fcc8d7c5-17e4-4d37-a8ff-d7f0818f88c0", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.6  # Cognitive parameter (modified from 1.7 to 1.6)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Enhance the exploration capability by reducing the cognitive coefficient to balance exploration and exploitation.", "configspace": "", "generation": 57, "fitness": 0.4241774402612279, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.424 with standard deviation 0.010. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0bef0268-93a4-4571-8703-2ade9af81936", "metadata": {"aucs": [0.4120485726250317, 0.4358199888524861, 0.42466375930616596], "final_y": [7.767764883237583e-05, 3.2341080483052197e-05, 7.506702328224853e-05]}, "mutation_prompt": null}
{"id": "ab5b4e62-edbd-4c30-8f04-1c3cdca639f9", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.F = 0.6 + 0.4 * (evaluations / self.budget)  # Adaptive scaling factor for DE\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduce adaptive scaling for differential evolution to balance exploration and exploitation more effectively.", "configspace": "", "generation": 58, "fitness": 0.4011366643937711, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.401 with standard deviation 0.009. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0bef0268-93a4-4571-8703-2ade9af81936", "metadata": {"aucs": [0.4110226940296642, 0.40231772427742696, 0.39006957487422234], "final_y": [4.70058863365178e-05, 5.285219268685385e-05, 0.0002086405439029244]}, "mutation_prompt": null}
{"id": "7c8a4ec2-f446-4974-bbb4-12be2eb77f0d", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.92  # Crossover probability (slightly increased from 0.9)\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Enhanced local search by adjusting differential evolution crossover probability.", "configspace": "", "generation": 59, "fitness": 0.41554641645357987, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.416 with standard deviation 0.016. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0bef0268-93a4-4571-8703-2ade9af81936", "metadata": {"aucs": [0.3932791214032836, 0.42543744703967246, 0.4279226809177835], "final_y": [0.00021190822877097096, 4.314866135373679e-05, 7.438931558315639e-05]}, "mutation_prompt": null}
{"id": "b9edd7eb-6c95-426c-b8a5-9226f39f4e38", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Fine-tune initialization of velocities to enhance exploration at the start.", "configspace": "", "generation": 57, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "0bef0268-93a4-4571-8703-2ade9af81936", "metadata": {"aucs": [0.4120485726250317, 0.4358199888524861, 0.42466375930616596], "final_y": [7.767764883237583e-05, 3.2341080483052197e-05, 7.506702328224853e-05]}, "mutation_prompt": null}
{"id": "248ff1fe-3ee7-455a-9717-c574fa1245a7", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-4 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Tweak inertia weight decay for improved convergence precision.", "configspace": "", "generation": 61, "fitness": 0.35775499564104685, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.358 with standard deviation 0.025. And the mean value of best solutions found was 0.001 (0. is the best).", "error": "", "parent_id": "0bef0268-93a4-4571-8703-2ade9af81936", "metadata": {"aucs": [0.33149453818067265, 0.39181842587607063, 0.34995202286639715], "final_y": [0.0008843092908766301, 0.0002039535376766087, 0.0011794954828634365]}, "mutation_prompt": null}
{"id": "269c4dc9-0bd6-4c71-be58-7f6dc3bf9755", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Fine-tune initialization of velocities to enhance exploration at the start.", "configspace": "", "generation": 57, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "0bef0268-93a4-4571-8703-2ade9af81936", "metadata": {"aucs": [0.4120485726250317, 0.4358199888524861, 0.42466375930616596], "final_y": [7.767764883237583e-05, 3.2341080483052197e-05, 7.506702328224853e-05]}, "mutation_prompt": null}
{"id": "b072447b-abad-414c-a22b-ef67fa0faef4", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < (self.CR + 0.1 * np.random.rand())  # Slight randomization\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduce a slight randomization to the crossover probability to enhance exploration.", "configspace": "", "generation": 63, "fitness": 0.37029205706169527, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.370 with standard deviation 0.028. And the mean value of best solutions found was 0.001 (0. is the best).", "error": "", "parent_id": "0bef0268-93a4-4571-8703-2ade9af81936", "metadata": {"aucs": [0.37403165427465157, 0.334283260716709, 0.4025612561937254], "final_y": [0.00015459508010377964, 0.0013666036276176227, 5.47620772140496e-05]}, "mutation_prompt": null}
{"id": "41efcf92-ca12-4fa0-8539-04299020d066", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        dynamic_velocity_clamp = (-1 + 0.5 * evaluations / self.budget, 1 - 0.5 * evaluations / self.budget)  # New line\n        self.velocities = np.clip(self.velocities, *dynamic_velocity_clamp)  # Changed line\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduce dynamic adjustment of velocity clamp for better exploration-exploitation balance.", "configspace": "", "generation": 64, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'evaluations' is not defined\").", "error": "NameError(\"name 'evaluations' is not defined\")", "parent_id": "0bef0268-93a4-4571-8703-2ade9af81936", "metadata": {}, "mutation_prompt": null}
{"id": "3d1c59c2-e4ff-4cb7-9771-31904459d999", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.7   # Differential evolution scale factor increased from 0.6 to 0.7\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Enhance exploration by increasing the differential evolution scale factor for greater solution diversity.", "configspace": "", "generation": 65, "fitness": 0.31145967055619894, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.311 with standard deviation 0.022. And the mean value of best solutions found was 0.004 (0. is the best).", "error": "", "parent_id": "0bef0268-93a4-4571-8703-2ade9af81936", "metadata": {"aucs": [0.34193452003492975, 0.3022044738378611, 0.290240017795806], "final_y": [0.0008679499887483658, 0.006923202098487202, 0.004322782011093109]}, "mutation_prompt": null}
{"id": "c62571ab-aae1-49da-a898-761eca0d598a", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + 0.95 * (cognitive_velocity + social_velocity)  # Slightly increase precision in velocity update\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduce a minor adjustment in velocity update to enhance convergence precision.", "configspace": "", "generation": 66, "fitness": 0.41203611810148305, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.412 with standard deviation 0.026. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0bef0268-93a4-4571-8703-2ade9af81936", "metadata": {"aucs": [0.37560526374121883, 0.4279956675743354, 0.4325074229888948], "final_y": [0.00023271502508482667, 6.826049974551171e-05, 4.9350160469861784e-05]}, "mutation_prompt": null}
{"id": "7dd73000-f0e1-4a94-a406-b6566924cc4d", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)  # Linear decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Incorporate a refined adaptive inertia weight strategy for better exploration-exploitation balance.", "configspace": "", "generation": 67, "fitness": 0.22286717545096169, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.223 with standard deviation 0.062. And the mean value of best solutions found was 0.415 (0. is the best).", "error": "", "parent_id": "0bef0268-93a4-4571-8703-2ade9af81936", "metadata": {"aucs": [0.30712192278420947, 0.20001848344441198, 0.1614611201242636], "final_y": [0.006195956315331135, 0.16294928054506602, 1.0756038258346585]}, "mutation_prompt": null}
{"id": "e30f3080-d483-4706-95ca-4e8b6dcd8e34", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-2.5 * evaluations / self.budget)  # Slightly refined decay rate for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Refine inertia weight decay rate to enhance convergence stability.  ", "configspace": "", "generation": 68, "fitness": 0.3909630851244487, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.391 with standard deviation 0.021. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0bef0268-93a4-4571-8703-2ade9af81936", "metadata": {"aucs": [0.38761840923843416, 0.36678957747381746, 0.41848126866109436], "final_y": [0.00020827502208821546, 0.0005166986277998047, 6.796971367889637e-05]}, "mutation_prompt": null}
{"id": "f620e0da-46ab-4599-9140-102dc1f5519c", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        self.F = 0.4 + 0.2 * np.sin(np.pi * np.mean(self.personal_best_fitness) / self.global_best_fitness)  # Dynamic F adjustment\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduce a dynamic adjustment for the scale factor F in the differential evolution step for improved exploration.", "configspace": "", "generation": 69, "fitness": 0.3382092830382888, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.338 with standard deviation 0.119. And the mean value of best solutions found was 0.255 (0. is the best).", "error": "", "parent_id": "0bef0268-93a4-4571-8703-2ade9af81936", "metadata": {"aucs": [0.171447715068339, 0.4417159384187608, 0.4014641956277665], "final_y": [0.7653612293440051, 4.046371185213434e-05, 0.00024184086178993103]}, "mutation_prompt": null}
{"id": "c65bdfdd-b72d-4a58-a435-02a877f001b9", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.92  # Crossover probability (slightly increased from 0.9)\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Slightly increase the crossover probability to enhance diversity in trials.", "configspace": "", "generation": 70, "fitness": 0.41554641645357987, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.416 with standard deviation 0.016. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0bef0268-93a4-4571-8703-2ade9af81936", "metadata": {"aucs": [0.3932791214032836, 0.42543744703967246, 0.4279226809177835], "final_y": [0.00021190822877097096, 4.314866135373679e-05, 7.438931558315639e-05]}, "mutation_prompt": null}
{"id": "106366a6-ad4a-4cc5-9c97-a98a9d300151", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.65  # Differential evolution scale factor (modified from 0.6 to 0.65)\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Slightly tweak the differential evolution scale factor to enhance exploration and exploitation balance.", "configspace": "", "generation": 71, "fitness": 0.3531157400952267, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.353 with standard deviation 0.117. And the mean value of best solutions found was 0.094 (0. is the best).", "error": "", "parent_id": "0bef0268-93a4-4571-8703-2ade9af81936", "metadata": {"aucs": [0.19685030574570417, 0.38487143877874797, 0.47762547576122816], "final_y": [0.28107563825825066, 0.0002557362971658606, 3.2487231997475026e-05]}, "mutation_prompt": null}
{"id": "32677529-f3d4-4580-8c8f-f683e9fcb2ed", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.F = 0.6 - (0.3 * evaluations / self.budget)  # Adaptive adjustment of F\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Enhance exploration by incorporating an adaptive differential evolution scale factor (F) based on evaluations.", "configspace": "", "generation": 72, "fitness": 0.42394479435066196, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.424 with standard deviation 0.024. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0bef0268-93a4-4571-8703-2ade9af81936", "metadata": {"aucs": [0.4566294276702344, 0.3986355563541042, 0.4165693990276472], "final_y": [1.8844836350463573e-05, 0.00012191625963856156, 0.00010656196779659731]}, "mutation_prompt": null}
{"id": "e9d15d01-9928-43b0-9156-0acd69fd246a", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-2.5 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Fine-tune inertia weight decay to improve exploration-exploitation balance.", "configspace": "", "generation": 73, "fitness": 0.3909630851244487, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.391 with standard deviation 0.021. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0bef0268-93a4-4571-8703-2ade9af81936", "metadata": {"aucs": [0.38761840923843416, 0.36678957747381746, 0.41848126866109436], "final_y": [0.00020827502208821546, 0.0005166986277998047, 6.796971367889637e-05]}, "mutation_prompt": null}
{"id": "94a4bebb-fcb8-488a-8609-32aa893740ae", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.65  # Differential evolution scale factor (modified from 0.6 to 0.65)\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Fine-tune the differential evolution scale factor to enhance local search component slightly.", "configspace": "", "generation": 74, "fitness": 0.3531157400952267, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.353 with standard deviation 0.117. And the mean value of best solutions found was 0.094 (0. is the best).", "error": "", "parent_id": "0bef0268-93a4-4571-8703-2ade9af81936", "metadata": {"aucs": [0.19685030574570417, 0.38487143877874797, 0.47762547576122816], "final_y": [0.28107563825825066, 0.0002557362971658606, 3.2487231997475026e-05]}, "mutation_prompt": null}
{"id": "b84bd150-22f6-43fa-b400-8c03ed757d61", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.8  # Crossover probability, modified from 0.9\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Modify the differential evolution crossover probability to enhance exploration.", "configspace": "", "generation": 75, "fitness": 0.3728873779174536, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.373 with standard deviation 0.017. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0bef0268-93a4-4571-8703-2ade9af81936", "metadata": {"aucs": [0.37141922945361694, 0.3533691790399687, 0.3938737252587753], "final_y": [0.0004874800220048456, 0.0006083988061354688, 0.00019826360461995456]}, "mutation_prompt": null}
{"id": "b4d8345b-4393-424c-a11d-0cc5b9079e2b", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            self.CR = 0.9 * (self.global_best_fitness / (self.global_best_fitness + self.personal_best_fitness[i]))  # Dynamic crossover probability\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduce a dynamic crossover probability to improve exploitation in the differential evolution step.", "configspace": "", "generation": 76, "fitness": 0.23195299470186082, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.232 with standard deviation 0.070. And the mean value of best solutions found was 0.441 (0. is the best).", "error": "", "parent_id": "0bef0268-93a4-4571-8703-2ade9af81936", "metadata": {"aucs": [0.161655756756388, 0.328192493317616, 0.20601073403157844], "final_y": [1.0756038055130097, 0.0036531665833234588, 0.24421185898974612]}, "mutation_prompt": null}
{"id": "cebe473a-4f79-479a-97f7-023c6e887ad5", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-2, 2)  # Increased velocity clamp range for enhanced exploration\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Increase the velocity clamp range to improve exploration capabilities.", "configspace": "", "generation": 77, "fitness": 0.4238420359619474, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.424 with standard deviation 0.031. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0bef0268-93a4-4571-8703-2ade9af81936", "metadata": {"aucs": [0.38401858788906995, 0.4589149975219803, 0.42859252247479196], "final_y": [0.00020603562143858207, 4.119043308004307e-05, 0.00010297595956271367]}, "mutation_prompt": null}
{"id": "9b0b6c97-d1b0-458b-bc8d-3594742195e7", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocity_clamp = (-1 + 0.5 * evaluations / self.budget, 1 - 0.5 * evaluations / self.budget)  # Dynamic velocity clamp\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduce a dynamic velocity clamp based on function evaluations for better convergence control.", "configspace": "", "generation": 78, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'evaluations' is not defined\").", "error": "NameError(\"name 'evaluations' is not defined\")", "parent_id": "0bef0268-93a4-4571-8703-2ade9af81936", "metadata": {}, "mutation_prompt": null}
{"id": "d8d8f32e-80ca-4ee3-ac20-a0a4a712ad1b", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.9  # Crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-4 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Adjusted the inertia weight decay rate to enhance convergence speed and balance exploration-exploitation.", "configspace": "", "generation": 79, "fitness": 0.3170560136740636, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.317 with standard deviation 0.010. And the mean value of best solutions found was 0.004 (0. is the best).", "error": "", "parent_id": "0bef0268-93a4-4571-8703-2ade9af81936", "metadata": {"aucs": [0.33042647560386806, 0.31278167782838584, 0.30795988758993686], "final_y": [0.0018945063476488216, 0.0034532286400699302, 0.005970243908509963]}, "mutation_prompt": null}
{"id": "3089c280-3f93-48dd-a1a8-3252e3f81ad8", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.85  # Crossover probability modified from 0.9\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Enhance exploitation by adjusting the crossover probability for better convergence.", "configspace": "", "generation": 80, "fitness": 0.4345736466112912, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.435 with standard deviation 0.024. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0bef0268-93a4-4571-8703-2ade9af81936", "metadata": {"aucs": [0.43748365704932346, 0.40427691515959463, 0.4619603676249555], "final_y": [3.651666320680562e-05, 4.750613303203173e-05, 1.356713677742055e-05]}, "mutation_prompt": null}
{"id": "e32e104d-22c9-4f6a-9804-a697367b493a", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.85  # Crossover probability modified from 0.9\n        self.velocity_clamp = (-1.2, 1.2)  # Velocity clamp modified from (-1, 1)\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Enhance global exploration by slightly increasing the velocity clamp range to avoid premature convergence.", "configspace": "", "generation": 81, "fitness": 0.38682090250629053, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.387 with standard deviation 0.017. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "3089c280-3f93-48dd-a1a8-3252e3f81ad8", "metadata": {"aucs": [0.37334554564816536, 0.37603951310430683, 0.4110776487663994], "final_y": [0.0003917489468598613, 0.00025964894522261233, 0.00010622613123039722]}, "mutation_prompt": null}
{"id": "a8de157e-acef-4957-888c-8e33bb7f0e9d", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.85  # Crossover probability modified from 0.9\n        self.velocity_clamp = (-0.5, 0.5)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Improve convergence by better velocity clamping.", "configspace": "", "generation": 82, "fitness": 0.24150124069634613, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.242 with standard deviation 0.112. And the mean value of best solutions found was 0.707 (0. is the best).", "error": "", "parent_id": "3089c280-3f93-48dd-a1a8-3252e3f81ad8", "metadata": {"aucs": [0.1603337356374066, 0.16417888167304517, 0.39999110477858657], "final_y": [1.0756038055119177, 1.046482876829197, 0.0001185455395504895]}, "mutation_prompt": null}
{"id": "41657210-df76-484d-a4ba-c76880fe9992", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.8  # Cognitive parameter (modified from 1.7 to 1.8)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.85  # Crossover probability modified from 0.9\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Fine-tune the cognitive and social parameters for enhanced adaptive exploration and exploitation.", "configspace": "", "generation": 83, "fitness": 0.4345736466112912, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.435 with standard deviation 0.024. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "3089c280-3f93-48dd-a1a8-3252e3f81ad8", "metadata": {"aucs": [0.43748365704932346, 0.40427691515959463, 0.4619603676249555], "final_y": [3.651666320680562e-05, 4.750613303203173e-05, 1.356713677742055e-05]}, "mutation_prompt": null}
{"id": "27c35591-2f4b-4c87-9ec2-a4f0214192cf", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.85  # Crossover probability modified from 0.9\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.F = 0.6 + 0.4 * (evaluations / self.budget)  # Dynamically adjust the mutation factor\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Enhance adaptive capabilities by adjusting the mutation factor dynamically during the optimization process.", "configspace": "", "generation": 84, "fitness": 0.4121687875868077, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.412 with standard deviation 0.014. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "3089c280-3f93-48dd-a1a8-3252e3f81ad8", "metadata": {"aucs": [0.40317853243558643, 0.431394844519275, 0.4019329858055617], "final_y": [9.973352574312337e-05, 4.7482359065173784e-05, 9.837742163382232e-05]}, "mutation_prompt": null}
{"id": "551bc91b-7d99-49f9-b979-b9b9be22eb08", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.95  # Inertia weight initial value (modified from 0.9 to 0.95)\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.85  # Crossover probability modified from 0.9\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Improved exploration by tweaking the initial inertia weight.", "configspace": "", "generation": 85, "fitness": 0.4345736466112912, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.435 with standard deviation 0.024. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "3089c280-3f93-48dd-a1a8-3252e3f81ad8", "metadata": {"aucs": [0.43748365704932346, 0.40427691515959463, 0.4619603676249555], "final_y": [3.651666320680562e-05, 4.750613303203173e-05, 1.356713677742055e-05]}, "mutation_prompt": null}
{"id": "5f6a8d4f-5631-4cf3-97a1-82d5b1f6a400", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.85  # Crossover probability modified from 0.9\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocity_clamp = np.maximum(np.abs(self.velocities), 0.1)  # Adaptive velocity clamp\n        self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduced adaptive velocity clamping to improve convergence stability in HybridPSODE.", "configspace": "", "generation": 86, "fitness": 0.41331836193636295, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.413 with standard deviation 0.027. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "3089c280-3f93-48dd-a1a8-3252e3f81ad8", "metadata": {"aucs": [0.4250623517453873, 0.4384215133130205, 0.37647122075068096], "final_y": [4.8378176624494825e-05, 4.00763785057194e-05, 0.00042302518569436613]}, "mutation_prompt": null}
{"id": "b753290f-f49c-4310-9899-6ae56d80126e", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.55  # Increased social parameter slightly\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.85  # Crossover probability modified from 0.9\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Slightly increase the social parameter (c2) to enhance social learning and improve convergence.", "configspace": "", "generation": 87, "fitness": 0.4345736466112912, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.435 with standard deviation 0.024. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "3089c280-3f93-48dd-a1a8-3252e3f81ad8", "metadata": {"aucs": [0.43748365704932346, 0.40427691515959463, 0.4619603676249555], "final_y": [3.651666320680562e-05, 4.750613303203173e-05, 1.356713677742055e-05]}, "mutation_prompt": null}
{"id": "b059d73f-86f6-41c2-afb8-91e2897af78b", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.85  # Crossover probability modified from 0.9\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.CR = 0.85 - (0.1 * evaluations / self.budget)  # Dynamic adjustment of CR\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduce dynamic crossover probability adjustment for improved exploration-exploitation balance.", "configspace": "", "generation": 88, "fitness": 0.41729521352863036, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.417 with standard deviation 0.039. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "3089c280-3f93-48dd-a1a8-3252e3f81ad8", "metadata": {"aucs": [0.44450074651381266, 0.3616199594495192, 0.4457649346225592], "final_y": [1.3153706372029775e-05, 0.0004741118356349582, 6.728949367964381e-05]}, "mutation_prompt": null}
{"id": "32c2677d-6a81-4bdb-8182-678fc86c3f4c", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.85  # Initial crossover probability\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        generation_progress = (self.budget - evaluations) / self.budget  # Calculate progress\n        dynamic_CR = 0.85 * generation_progress + 0.6 * (1 - generation_progress)  # Dynamic CR\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < dynamic_CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduce a dynamic crossover probability adjustment based on generation progress to balance exploration and exploitation.", "configspace": "", "generation": 89, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'evaluations' is not defined\").", "error": "NameError(\"name 'evaluations' is not defined\")", "parent_id": "3089c280-3f93-48dd-a1a8-3252e3f81ad8", "metadata": {}, "mutation_prompt": null}
{"id": "9c285e2e-d5d4-456a-bbfd-82b225def396", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.6  # Social parameter (changed from 1.5 to 1.6)\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.85  # Crossover probability modified from 0.9\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Improve social learning by increasing the social parameter `c2` to enhance convergence.", "configspace": "", "generation": 90, "fitness": 0.3255597409280391, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.326 with standard deviation 0.018. And the mean value of best solutions found was 0.005 (0. is the best).", "error": "", "parent_id": "3089c280-3f93-48dd-a1a8-3252e3f81ad8", "metadata": {"aucs": [0.30290513098704464, 0.3480134151618208, 0.32576067663525177], "final_y": [0.004555186902493075, 0.0009036105948759848, 0.009789859331871806]}, "mutation_prompt": null}
{"id": "806c14b2-2086-4f08-bb88-619b814dfc3f", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.85  # Crossover probability modified from 0.9\n        self.velocity_clamp = (-2, 2)  # Modified velocity clamp to enhance exploration\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Enhance exploration by modifying the velocity clamp range to improve search space coverage.", "configspace": "", "generation": 91, "fitness": 0.32293661848416305, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.323 with standard deviation 0.114. And the mean value of best solutions found was 0.359 (0. is the best).", "error": "", "parent_id": "3089c280-3f93-48dd-a1a8-3252e3f81ad8", "metadata": {"aucs": [0.16158553592424563, 0.4033430284653049, 0.4038812910629386], "final_y": [1.0756038055166728, 0.0002553034372100474, 0.00010128505916957053]}, "mutation_prompt": null}
{"id": "98a162c1-db59-400d-b772-225bafb6917d", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 21  # Changed from 20 to 21\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.85  # Crossover probability modified from 0.9\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Increase the initial population size to 21 for better exploration, with minimal code change.", "configspace": "", "generation": 92, "fitness": 0.41783029284345874, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.418 with standard deviation 0.044. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "3089c280-3f93-48dd-a1a8-3252e3f81ad8", "metadata": {"aucs": [0.3590325731738424, 0.46486741311795, 0.4295908922385838], "final_y": [0.00023927304032571022, 1.510948314727916e-05, 4.4701677825912746e-05]}, "mutation_prompt": null}
{"id": "706e8754-6af1-48b5-9db3-032c812c30ea", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.87  # Crossover probability slightly increased from 0.85\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Fine-tune differential evolution step by slightly increasing crossover probability for better exploration.", "configspace": "", "generation": 93, "fitness": 0.31093187783590565, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.311 with standard deviation 0.047. And the mean value of best solutions found was 0.013 (0. is the best).", "error": "", "parent_id": "3089c280-3f93-48dd-a1a8-3252e3f81ad8", "metadata": {"aucs": [0.3387149521324069, 0.34954534015678596, 0.24453534121852405], "final_y": [0.0026248550283865537, 0.0011188932576879317, 0.03400730427751004]}, "mutation_prompt": null}
{"id": "e70769c2-0740-4239-a93c-f250d2b995f9", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.85  # Crossover probability modified from 0.9\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.CR = 0.85 * (1 - evaluations / self.budget)  # Adaptive crossover probability\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduce adaptive crossover probability scaling based on generation progress for enhanced exploration-exploitation balance.", "configspace": "", "generation": 94, "fitness": 0.2785303114399161, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.279 with standard deviation 0.098. And the mean value of best solutions found was 0.364 (0. is the best).", "error": "", "parent_id": "3089c280-3f93-48dd-a1a8-3252e3f81ad8", "metadata": {"aucs": [0.4006117927425019, 0.27361134714123436, 0.161367794436012], "final_y": [0.0001367905733333183, 0.017477281318581075, 1.075603805520718]}, "mutation_prompt": null}
{"id": "ee947bf4-a62d-4420-89ca-1c305fcaf2e1", "solution": "import numpy as np\n\nclass HybridQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.inertia_weight = 0.8\n        self.mutation_rate = 0.1\n        self.velocity_clamp = (-1, 1)\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))\n        self.personal_bests = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_bests[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_bests - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def quantum_inspired_mutation(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate:\n                quantum_bit = np.random.uniform(lb, ub, self.dim)\n                self.population[i] = self.population[i] + np.sin(quantum_bit - self.population[i])\n                self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.quantum_inspired_mutation(func.bounds)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridQIPSO", "description": "Hybrid Quantum-Inspired PSO with Adaptive Genetic Operators: Combines quantum-inspired search space exploration with adaptive genetic mutation to enhance diversity and convergence.", "configspace": "", "generation": 95, "fitness": 0.22563466743505145, "feedback": "The algorithm HybridQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.226 with standard deviation 0.016. And the mean value of best solutions found was 0.181 (0. is the best).", "error": "", "parent_id": "3089c280-3f93-48dd-a1a8-3252e3f81ad8", "metadata": {"aucs": [0.22110885053265572, 0.24729702270419984, 0.2084981290682988], "final_y": [0.16300978320666093, 0.14234992606991764, 0.23826642398128492]}, "mutation_prompt": null}
{"id": "7abf7260-6b22-4c9c-ac06-05e1f9b12465", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.85  # Crossover probability modified from 0.9\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        # Adaptive velocity clamping\n        v_max = 0.1 + 0.8 * (1 - self.global_best_fitness / np.max(self.personal_best_fitness))\n        self.velocities = np.clip(self.velocities, -v_max, v_max)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Implement adaptive velocity clamping to refine particle exploration and exploitation balance.", "configspace": "", "generation": 96, "fitness": 0.31765808665428724, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.318 with standard deviation 0.027. And the mean value of best solutions found was 0.003 (0. is the best).", "error": "", "parent_id": "3089c280-3f93-48dd-a1a8-3252e3f81ad8", "metadata": {"aucs": [0.3008882283257528, 0.3553972932818741, 0.2966887383552349], "final_y": [0.0047585563897358015, 0.001011769750462797, 0.0024767581785816576]}, "mutation_prompt": null}
{"id": "995dd736-f39b-4469-8a02-7bfc25863470", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.85  # Crossover probability modified from 0.9\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Enhance exploitation by adjusting the crossover probability for better convergence.", "configspace": "", "generation": 81, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "3089c280-3f93-48dd-a1a8-3252e3f81ad8", "metadata": {"aucs": [0.43748365704932346, 0.40427691515959463, 0.4619603676249555], "final_y": [3.651666320680562e-05, 4.750613303203173e-05, 1.356713677742055e-05]}, "mutation_prompt": null}
{"id": "d1cc4a99-6e28-4e4b-9337-5997e62928a6", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.8   # Inertia weight initial value reduced from 0.9 to 0.8\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.85  # Crossover probability modified from 0.9\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Further enhance exploration by reducing the initial inertia weight for wider search space coverage.", "configspace": "", "generation": 98, "fitness": 0.33680085602814297, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.337 with standard deviation 0.020. And the mean value of best solutions found was 0.001 (0. is the best).", "error": "", "parent_id": "3089c280-3f93-48dd-a1a8-3252e3f81ad8", "metadata": {"aucs": [0.33757232577013874, 0.3122087227446153, 0.3606215195696748], "final_y": [0.00043738421410144504, 0.0023255929140815835, 0.0005294667290217542]}, "mutation_prompt": null}
{"id": "e81b6bed-07d0-44d5-b5e2-4733a8624d3d", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.7  # Cognitive parameter (modified from 1.5 to 1.7)\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight initial value\n        self.F = 0.6   # Differential evolution scale factor\n        self.CR = 0.85  # Crossover probability modified from 0.9\n        self.velocity_clamp = (-1, 1)  # Velocity clamp to avoid explosion\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Modified velocity range\n        self.personal_best = self.population.copy()\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fitness = func(self.population[i])\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fitness\n                self.personal_best[i] = self.population[i].copy()\n            if fitness < self.global_best_fitness:\n                self.global_best_fitness = fitness\n                self.global_best = self.population[i].copy()\n\n    def update_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        cognitive_velocity = self.c1 * r1 * (self.personal_best - self.population)\n        social_velocity = self.c2 * r2 * (self.global_best - self.population)\n        self.velocities = self.w * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, *self.velocity_clamp)\n        self.population = self.population + self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n    def differential_evolution_step(self, bounds, func):\n        lb, ub = bounds.lb, bounds.ub\n        self.CR = 0.6 + 0.4 * np.sin(np.pi * self.budget)  # Changed line: Dynamic crossover probability\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n            crossover = np.random.rand(self.dim) < self.CR\n            trial_vector = np.where(crossover, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness < self.personal_best_fitness[i]:\n                self.population[i] = trial_vector\n                self.personal_best_fitness[i] = trial_fitness\n                self.personal_best[i] = trial_vector\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best_fitness = trial_fitness\n                    self.global_best = trial_vector\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.w = 0.9 * np.exp(-3 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.c1 = 1.7 - (0.05 * evaluations / self.budget)  # Adaptive adjustment of c1\n            self.c2 = 1.5 + (0.05 * evaluations / self.budget)  # Adaptive adjustment of c2\n            self.update_particles(func.bounds)\n            evaluations += self.population_size\n            if evaluations >= self.budget:\n                break\n            self.differential_evolution_step(func.bounds, func)\n            evaluations += self.population_size\n\n        return self.global_best, self.global_best_fitness", "name": "HybridPSODE", "description": "Introduce a dynamic crossover probability in DE to enhance exploration and convergence.", "configspace": "", "generation": 99, "fitness": 0.3311767335691422, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.331 with standard deviation 0.119. And the mean value of best solutions found was 0.349 (0. is the best).", "error": "", "parent_id": "3089c280-3f93-48dd-a1a8-3252e3f81ad8", "metadata": {"aucs": [0.43630998200710547, 0.16414414311196768, 0.39307607558835334], "final_y": [2.156457890868727e-05, 1.047388353569326, 0.00024389459977959178]}, "mutation_prompt": null}

{"id": "e48c90d9-4620-4129-9327-323bf24729df", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Evaluate the particle's current position\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            if eval_count >= self.budget:\n                break\n\n            # Update velocities and positions\n            for i in range(self.population_size):\n                # PSO Update\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component)\n                self.particles[i] += self.velocities[i]\n\n                # DE Mutation Strategy\n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n\n                if eval_count >= self.budget:\n                    break\n\n        return self.global_best_position, self.global_best_score", "name": "HybridPSO_DE", "description": "A hybrid Particle Swarm Optimization (PSO) with Differential Evolution (DE) mutation strategies to enhance exploration and exploitation capabilities in a constrained search space.", "configspace": "", "generation": 0, "fitness": 0.005243155569079653, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.005 with standard deviation 0.001. And the mean value of best solutions found was 0.863 (0. is the best).", "error": "", "parent_id": null, "metadata": {"aucs": [0.004722450398319644, 0.00472241823999997, 0.006284598068919345], "final_y": [0.9183673469387753, 0.9183673469387754, 0.7531164896776603]}, "mutation_prompt": null}
{"id": "1f3c2953-f839-47c7-aa57-8eab78d0b59a", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component)\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.5 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.5 + 1.5 * (eval_count / self.budget)\n            self.social_weight = 1.5 + 1.5 * (1 - eval_count / self.budget)\n            self.mutation_factor = 0.4 + 0.1 * np.sin(np.pi * generation / 10)\n            generation += 1\n\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Enhanced Hybrid PSO-DE with Adaptive Parameters and Stochastic Ranking to balance exploration and exploitation and handle constraints more effectively.", "configspace": "", "generation": 1, "fitness": 0.036641728299132516, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.037 with standard deviation 0.000. And the mean value of best solutions found was 0.416 (0. is the best).", "error": "", "parent_id": "e48c90d9-4620-4129-9327-323bf24729df", "metadata": {"aucs": [0.036731669723788385, 0.036565401587989266, 0.036628113585619904], "final_y": [0.4822538128946764, 0.35968237148961746, 0.40732084109469613]}, "mutation_prompt": null}
{"id": "58ff9998-622d-4f0b-a20e-44e6fd316b65", "solution": "import numpy as np\n\nclass QuantumInspiredPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component)\n                \n                # Quantum-inspired position update\n                phi = np.random.uniform(0, 2 * np.pi, self.dim)\n                distance = np.abs(self.particles[i] - self.global_best_position)\n                self.particles[i] += np.sin(phi) * distance / np.log(1 + generation + 1)\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.5 + 0.3 * np.cos(np.pi * eval_count / self.budget)\n            self.cognitive_weight = 1.2 + 0.8 * (eval_count / self.budget)\n            self.social_weight = 1.2 + 0.8 * (1 - eval_count / self.budget)\n            self.mutation_factor = 0.4 + 0.1 * np.cos(np.pi * generation / 10)\n            generation += 1\n\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "QuantumInspiredPSO_DE", "description": "Quantum-inspired Particle Swarm Optimization with Differential Evolution, utilizing quantum behavior for enhanced exploration and dynamic parameter adaptation.", "configspace": "", "generation": 2, "fitness": 0.004750772954123554, "feedback": "The algorithm QuantumInspiredPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.005 with standard deviation 0.000. And the mean value of best solutions found was 0.915 (0. is the best).", "error": "", "parent_id": "1f3c2953-f839-47c7-aa57-8eab78d0b59a", "metadata": {"aucs": [0.004808256656546828, 0.004721801626702993, 0.0047222605791208405], "final_y": [0.9074157607889154, 0.9183673895143262, 0.9183674018186041]}, "mutation_prompt": null}
{"id": "265817cd-7362-42a6-a0d5-cc9907ff2131", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v)**(1 / beta)\n        return L * step\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component)\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial = np.clip(trial + self.levy_flight(0.05), lb, ub)  # Levy flight incorporated\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.5 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.5 + 1.5 * (eval_count / self.budget)\n            self.social_weight = 1.5 + 1.5 * (1 - eval_count / self.budget)\n            self.mutation_factor = 0.4 + 0.1 * np.sin(np.pi * generation / 10)\n            generation += 1\n\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Enhanced Hybrid PSO-DE with Levy Flight to improve exploration and escape local optima during optimization.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "1f3c2953-f839-47c7-aa57-8eab78d0b59a", "metadata": {}, "mutation_prompt": null}
{"id": "3ae30653-7ede-4729-bea0-4ad94d923991", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.q_population = np.random.rand(self.population_size, self.dim) * 2 * np.pi\n        self.binary_population = np.sign(np.sin(self.q_population))\n        self.best_solution = None\n        self.best_score = np.inf\n        self.mutation_rate = 0.1\n        self.adapt_rate = 0.05\n    \n    def _quantum_to_real(self, q):\n        return 0.5 * (1 + np.sign(np.sin(q)))\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            real_population = lb + (ub - lb) * self._quantum_to_real(self.q_population)\n            scores = np.apply_along_axis(func, 1, np.clip(real_population, lb, ub))\n            eval_count += self.population_size\n            \n            best_idx = np.argmin(scores)\n            if scores[best_idx] < self.best_score:\n                self.best_score = scores[best_idx]\n                self.best_solution = real_population[best_idx]\n            \n            for i in range(self.population_size):\n                diff = self.best_solution - real_population[i]\n                self.q_population[i] += self.adapt_rate * diff * np.random.rand(self.dim)\n                self.q_population[i] = np.mod(self.q_population[i], 2 * np.pi)\n                \n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.rand(self.dim) * 2 * np.pi\n                    self.q_population[i] = np.mod(self.q_population[i] + mutation, 2 * np.pi)\n        \n        return self.best_solution, self.best_score", "name": "QuantumInspiredEA", "description": "Quantum-inspired Adaptive Evolutionary Algorithm (QAEA) utilizing quantum bits and adaptive mutation strategies to enhance exploration and exploitation in diverse landscapes.", "configspace": "", "generation": 4, "fitness": 0.004722483486963025, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.005 with standard deviation 0.000. And the mean value of best solutions found was 0.918 (0. is the best).", "error": "", "parent_id": "1f3c2953-f839-47c7-aa57-8eab78d0b59a", "metadata": {"aucs": [0.004722483486963025, 0.004722483486963025, 0.004722483486963025], "final_y": [0.9183673469387754, 0.9183673469387754, 0.9183673469387754]}, "mutation_prompt": null}
{"id": "d232db5d-2f0b-47ff-801e-68b5ed105105", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component)\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.5 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.5 + 1.5 * (eval_count / self.budget)\n            self.social_weight = 1.5 + 1.5 * (1 - eval_count / self.budget)\n            self.mutation_factor = 0.4 + 0.1 * np.sin(np.pi * generation / 10)\n            generation += 1\n\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Improved Enhanced Hybrid PSO-DE with Dynamic Population Resizing for Adaptive Exploration and Exploitation.", "configspace": "", "generation": 5, "fitness": 0.03678950124498792, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.037 with standard deviation 0.002. And the mean value of best solutions found was 0.439 (0. is the best).", "error": "", "parent_id": "1f3c2953-f839-47c7-aa57-8eab78d0b59a", "metadata": {"aucs": [0.03588556103356255, 0.03927292893449541, 0.0352100137669058], "final_y": [0.47110633699404236, 0.3684049292556324, 0.4782598350539272]}, "mutation_prompt": null}
{"id": "942cf3b4-7f8c-420d-9fb7-4ad02bf8263c", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(5, int(20 - (15 * eval_count / self.budget)))  # Changed line\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component)\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate / 1.5, mutant, self.particles[i])  # Changed line\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.5 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.5 + 1.5 * (eval_count / self.budget)\n            self.social_weight = 1.5 + 1.5 * (1 - eval_count / self.budget)\n            self.mutation_factor = 0.4 + 0.1 * np.sin(np.pi * generation / 10)\n            self.crossover_rate = 0.8 + 0.1 * np.cos(np.pi * generation / 10)  # Changed line\n            generation += 1\n\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with time-varying population size and dynamic crossover rate for improved convergence.", "configspace": "", "generation": 6, "fitness": 0.03520662161322763, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.035 with standard deviation 0.002. And the mean value of best solutions found was 0.381 (0. is the best).", "error": "", "parent_id": "d232db5d-2f0b-47ff-801e-68b5ed105105", "metadata": {"aucs": [0.03865707139149854, 0.03349878592418043, 0.033464007524003914], "final_y": [0.3541471779249923, 0.34355278147838675, 0.44480748240805656]}, "mutation_prompt": null}
{"id": "95823d19-a61c-44bc-9e56-471d73164797", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget))) + 1  # Change 1: Enhanced resizing\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component)\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate * 1.1, mutant, self.particles[i])  # Change 2: Enhanced crossover\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.5 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.5 + 1.5 * (eval_count / self.budget)\n            self.social_weight = 1.5 + 1.5 * (1 - eval_count / self.budget)\n            self.mutation_factor = 0.4 + 0.1 * np.sin(np.pi * generation / 10)\n            generation += 1\n\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Improved Enhanced Hybrid PSO-DE with Adaptive Dynamic Population Resizing and Enhanced Crossover for Exploration and Exploitation.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "d232db5d-2f0b-47ff-801e-68b5ed105105", "metadata": {}, "mutation_prompt": null}
{"id": "d58c8788-7062-4bb0-bb23-17e11a2ead8d", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component)\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.5 + 0.4 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.5 + 1.5 * (eval_count / self.budget)\n            self.social_weight = 1.5 + 1.5 * (1 - eval_count / self.budget)\n            self.mutation_factor = 0.4 + 0.1 * np.sin(np.pi * generation / 10)\n            generation += 1\n\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Enhanced adaptive parameter adjustment by modifying inertia weight's calculation for improved exploration-exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.033400120144151536, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.033 with standard deviation 0.004. And the mean value of best solutions found was 0.510 (0. is the best).", "error": "", "parent_id": "d232db5d-2f0b-47ff-801e-68b5ed105105", "metadata": {"aucs": [0.02798851023341309, 0.037964503694960516, 0.03424734650408101], "final_y": [0.5711572691387448, 0.4698243354914038, 0.4900992392932043]}, "mutation_prompt": null}
{"id": "d8cf5501-3f2c-4751-bb0a-f9a0832eaa9d", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0  # Added for stagnation detection\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score  # Storing previous best score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component)\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.5 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.5 + 1.5 * (eval_count / self.budget)\n            self.social_weight = 1.5 + 1.5 * (1 - eval_count / self.budget)\n            self.mutation_factor = 0.4 + 0.1 * np.sin(np.pi * generation / 10)\n            \n            # Turbulent search for stagnation handling\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:  # If stagnant, apply turbulence\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)  # Injecting turbulence\n                self.stagnation_count = 0  # Reset stagnation counter\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with Turbulent Search for Improved Exploration in Stagnant Phases.", "configspace": "", "generation": 9, "fitness": 0.03823218001271378, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.038 with standard deviation 0.001. And the mean value of best solutions found was 0.408 (0. is the best).", "error": "", "parent_id": "d232db5d-2f0b-47ff-801e-68b5ed105105", "metadata": {"aucs": [0.03820993173829024, 0.039434338211851716, 0.037052270087999384], "final_y": [0.4341626367565953, 0.3436100374196537, 0.44619279035877457]}, "mutation_prompt": null}
{"id": "c6d43b24-288e-4558-a3e4-0c60d9a6ee61", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0  # Added for stagnation detection\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score  # Storing previous best score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component)\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.5 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.5 + 1.5 * (eval_count / self.budget)\n            self.social_weight = 1.5 + 1.5 * (1 - eval_count / self.budget)\n            self.mutation_factor = 0.4 + 0.1 * np.sin(np.pi * generation / 10)\n            \n            # Turbulent search for stagnation handling\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:  # If stagnant, apply turbulence\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)  # Injecting turbulence\n                self.stagnation_count = 0  # Reset stagnation counter\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with Turbulent Search for Improved Exploration in Stagnant Phases.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "d8cf5501-3f2c-4751-bb0a-f9a0832eaa9d", "metadata": {"aucs": [0.03820993173829024, 0.039434338211851716, 0.037052270087999384], "final_y": [0.4341626367565953, 0.3436100374196537, 0.44619279035877457]}, "mutation_prompt": null}
{"id": "da9d19ca-46c9-4ef2-8006-a3a021605e6e", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0  # Added for stagnation detection\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score  # Storing previous best score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component)\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.5 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.5 + 1.5 * (eval_count / self.budget)\n            self.social_weight = 1.5 + 1.5 * (1 - eval_count / self.budget)\n            self.mutation_factor = 0.4 + 0.1 * np.sin(np.pi * generation / 10)\n            \n            # Turbulent search for stagnation handling\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:  # If stagnant, apply turbulence\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)  # Injecting turbulence\n                self.stagnation_count = 0  # Reset stagnation counter\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with Turbulent Search for Improved Exploration in Stagnant Phases.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "d8cf5501-3f2c-4751-bb0a-f9a0832eaa9d", "metadata": {"aucs": [0.03820993173829024, 0.039434338211851716, 0.037052270087999384], "final_y": [0.4341626367565953, 0.3436100374196537, 0.44619279035877457]}, "mutation_prompt": null}
{"id": "3769b437-049f-4b99-b313-85aeaec91178", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0  # Added for stagnation detection\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score  # Storing previous best score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component)\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)  # Adaptive mutation\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.5 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.5 + 1.5 * (eval_count / self.budget)\n            self.social_weight = 1.5 + 1.5 * (1 - eval_count / self.budget)\n            self.mutation_factor = 0.4 + 0.1 * np.sin(np.pi * generation / 10)\n            \n            # Turbulent search for stagnation handling\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:  # If stagnant, apply turbulence\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)  # Injecting turbulence\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:  # Reinitialize if too close\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0  # Reset stagnation counter\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with Adaptive Differential Mutation and Reinitialization for Escaping Local Minima.", "configspace": "", "generation": 12, "fitness": 0.04286498834724425, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.043 with standard deviation 0.007. And the mean value of best solutions found was 0.379 (0. is the best).", "error": "", "parent_id": "d8cf5501-3f2c-4751-bb0a-f9a0832eaa9d", "metadata": {"aucs": [0.048504128753441345, 0.03347503865507273, 0.04661579763321866], "final_y": [0.3726792416225665, 0.433417408660033, 0.32972783781612813]}, "mutation_prompt": null}
{"id": "a8ea39fe-d195-4c97-9ecf-38effe9a3a49", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0  # Added for stagnation detection\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score  # Storing previous best score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component)\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)  # Adaptive mutation\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.5 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.5 + 1.5 * (eval_count / self.budget)\n            self.social_weight = 1.5 + 1.5 * (1 - eval_count / self.budget)\n            self.mutation_factor = 0.4 + 0.1 * np.sin(np.pi * generation / 10)\n            \n            # Turbulent search for stagnation handling\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:  # If stagnant, apply turbulence\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)  # Injecting turbulence\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-4:  # Reinitialize if too close\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0  # Reset stagnation counter\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with Improved Stagnation Handling by Adjusting Reinitialization Threshold.", "configspace": "", "generation": 13, "fitness": 0.04286498834724425, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.043 with standard deviation 0.007. And the mean value of best solutions found was 0.379 (0. is the best).", "error": "", "parent_id": "3769b437-049f-4b99-b313-85aeaec91178", "metadata": {"aucs": [0.048504128753441345, 0.03347503865507273, 0.04661579763321866], "final_y": [0.3726792416225665, 0.433417408660033, 0.32972783781612813]}, "mutation_prompt": null}
{"id": "2b8d4f6f-4ab1-4c91-b075-98a1677fd378", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0  # Added for stagnation detection\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score  # Storing previous best score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component)\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)  # Adaptive mutation\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.5 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.5 + 1.5 * (eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget)) # temporal decay\n            self.social_weight = 1.5 + 1.5 * (1 - eval_count / self.budget)\n            self.mutation_factor = 0.4 + 0.1 * np.sin(np.pi * generation / 10)\n            \n            # Turbulent search for stagnation handling\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:  # If stagnant, apply turbulence\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)  # Injecting turbulence\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:  # Reinitialize if too close\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0  # Reset stagnation counter\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduced temporal decay to the cognitive weight for enhanced exploration control in EnhancedHybridPSO_DE.", "configspace": "", "generation": 14, "fitness": 0.05091089834850526, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.051 with standard deviation 0.017. And the mean value of best solutions found was 0.350 (0. is the best).", "error": "", "parent_id": "3769b437-049f-4b99-b313-85aeaec91178", "metadata": {"aucs": [0.04851777252036915, 0.07267880102053592, 0.031536121504610715], "final_y": [0.3725839500912733, 0.21053002499378903, 0.46547838610157155]}, "mutation_prompt": null}
{"id": "af7a5bf2-0b40-4c9a-a99f-ac53e8e344c4", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0  # Added for stagnation detection\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score  # Storing previous best score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component)\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)  # Adaptive mutation\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.5 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.5 + 1.5 * (eval_count / self.budget)**2  # Non-linear scaling\n            self.social_weight = 1.5 + 1.5 * (1 - (eval_count / self.budget)**2)  # Non-linear scaling\n            self.mutation_factor = 0.4 + 0.1 * np.sin(np.pi * generation / 10)\n            \n            # Turbulent search for stagnation handling\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:  # If stagnant, apply turbulence\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)  # Injecting turbulence\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:  # Reinitialize if too close\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0  # Reset stagnation counter\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Enhanced the exploration by introducing non-linear scaling of cognitive and social weights over generations.", "configspace": "", "generation": 15, "fitness": 0.04857042939925701, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.049 with standard deviation 0.010. And the mean value of best solutions found was 0.348 (0. is the best).", "error": "", "parent_id": "2b8d4f6f-4ab1-4c91-b075-98a1677fd378", "metadata": {"aucs": [0.06159910316780137, 0.03920846891961427, 0.044903716110355374], "final_y": [0.28603852624072856, 0.4389197478134653, 0.31834198596079144]}, "mutation_prompt": null}
{"id": "5a7aae45-4339-4e16-bfef-683e0341ee8d", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0  # Added for stagnation detection\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score  # Storing previous best score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component)\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)  # Adaptive mutation\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.5 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.5 + 1.5 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget)) # temporal decay\n            self.social_weight = 1.5 + 1.5 * (eval_count / self.budget)\n            self.mutation_factor = 0.4 + 0.1 * np.sin(np.pi * generation / 10)\n            \n            # Turbulent search for stagnation handling\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:  # If stagnant, apply turbulence\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)  # Injecting turbulence\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:  # Reinitialize if too close\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0  # Reset stagnation counter\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Adaptive rebalance of cognitive and social weights for enhanced convergence in EnhancedHybridPSO_DE.", "configspace": "", "generation": 16, "fitness": 0.05962015899653128, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.060 with standard deviation 0.015. And the mean value of best solutions found was 0.282 (0. is the best).", "error": "", "parent_id": "2b8d4f6f-4ab1-4c91-b075-98a1677fd378", "metadata": {"aucs": [0.06138380077370764, 0.07752540362672111, 0.03995127258916509], "final_y": [0.28438733354834145, 0.18623652311273486, 0.3751101469714855]}, "mutation_prompt": null}
{"id": "c33ecc36-a47d-419b-9bc9-c8250ce91e95", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0  # Added for stagnation detection\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score  # Storing previous best score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component)\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)  # Adaptive mutation\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.5 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.5 + 1.5 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget)) # temporal decay\n            self.social_weight = 1.5 + 1.5 * (eval_count / self.budget)\n            self.mutation_factor = 0.4 + 0.1 * np.sin(np.pi * generation / 10) * (1 - eval_count / self.budget) # Adjusted line\n            \n            # Turbulent search for stagnation handling\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:  # If stagnant, apply turbulence\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)  # Injecting turbulence\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:  # Reinitialize if too close\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0  # Reset stagnation counter\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduced adaptive mutation factor scaling based on evaluation count to enhance exploration and exploitation balance.", "configspace": "", "generation": 17, "fitness": 0.042320354781077395, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.042 with standard deviation 0.014. And the mean value of best solutions found was 0.346 (0. is the best).", "error": "", "parent_id": "5a7aae45-4339-4e16-bfef-683e0341ee8d", "metadata": {"aucs": [0.06196070441957913, 0.0287151281053315, 0.03628523181832155], "final_y": [0.2366101566211437, 0.4410907398039545, 0.36173468519872043]}, "mutation_prompt": null}
{"id": "b53a2f28-3d4e-4599-9b51-dd705e2fa7bd", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.55  # Slight increase in mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0  # Added for stagnation detection\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score  # Storing previous best score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component)\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)  # Adaptive mutation\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.5 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.5 + 1.5 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget)) # temporal decay\n            self.social_weight = 1.5 + 1.5 * (eval_count / self.budget)\n            self.mutation_factor = 0.4 + 0.1 * np.sin(np.pi * generation / 10)\n            \n            # Turbulent search for stagnation handling\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:  # If stagnant, apply turbulence\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)  # Injecting turbulence\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:  # Reinitialize if too close\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0  # Reset stagnation counter\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduced a slight increase in mutation factor for enhanced diversity and exploration in EnhancedHybridPSO_DE.", "configspace": "", "generation": 18, "fitness": 0.05861650796966137, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.059 with standard deviation 0.015. And the mean value of best solutions found was 0.301 (0. is the best).", "error": "", "parent_id": "5a7aae45-4339-4e16-bfef-683e0341ee8d", "metadata": {"aucs": [0.06129943042854413, 0.07566539187070698, 0.03888470160973301], "final_y": [0.2854109749140069, 0.19817032910510068, 0.4183568230403135]}, "mutation_prompt": null}
{"id": "bef06b9d-660e-484c-81f5-33dc8d9dcb3c", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n\n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_component + social_component\n                self.particles[i] += self.velocities[i] * (1 + np.random.rand(self.dim) * 0.5) # Adaptive velocities\n\n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate * np.random.rand(), mutant, self.particles[i]) # Dynamic crossover\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n\n            self.inertia_weight = 0.4 + 0.5 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.5 + 1.5 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.5 + 1.5 * (eval_count / self.budget)\n            self.mutation_factor = 0.4 + 0.1 * np.sin(np.pi * generation / 10)\n\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n\n            if self.stagnation_count > 10:\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n\n            generation += 1\n\n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduce adaptive velocities and dynamic crossover rates to enhance exploration and convergence.", "configspace": "", "generation": 19, "fitness": 0.02609182645278792, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.026 with standard deviation 0.004. And the mean value of best solutions found was 0.563 (0. is the best).", "error": "", "parent_id": "5a7aae45-4339-4e16-bfef-683e0341ee8d", "metadata": {"aucs": [0.024078045743691434, 0.03199679693806179, 0.02220063667661054], "final_y": [0.6113258818860309, 0.42477374394670875, 0.6532553583474207]}, "mutation_prompt": null}
{"id": "5af475ae-a870-42fa-a426-a346f3122d8a", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0  # Added for stagnation detection\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score  # Storing previous best score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component)\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)  # Adaptive mutation\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.5 * (1 - (eval_count / self.budget)**1.1)\n            self.cognitive_weight = 1.5 + 1.5 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget)) # temporal decay\n            self.social_weight = 1.5 + 1.5 * (eval_count / self.budget)\n            self.mutation_factor = 0.4 + 0.1 * np.sin(np.pi * generation / 10)\n            \n            # Turbulent search for stagnation handling\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:  # If stagnant, apply turbulence\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)  # Injecting turbulence\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:  # Reinitialize if too close\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0  # Reset stagnation counter\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Enhanced exploration by introducing a slight nonlinear scaling to the inertia weight to balance exploration and exploitation.", "configspace": "", "generation": 20, "fitness": 0.05696238632504639, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.057 with standard deviation 0.007. And the mean value of best solutions found was 0.312 (0. is the best).", "error": "", "parent_id": "5a7aae45-4339-4e16-bfef-683e0341ee8d", "metadata": {"aucs": [0.050315680983401556, 0.06596862043422191, 0.054602857557515705], "final_y": [0.3512858672110315, 0.23927984712828365, 0.3469289667824229]}, "mutation_prompt": null}
{"id": "d295502e-3281-4fe8-a589-f306cbf9b965", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0  # Added for stagnation detection\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score  # Storing previous best score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()  # Random scaling\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)  # Adaptive mutation\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.5 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.5 + 1.5 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget)) # temporal decay\n            self.social_weight = 1.5 + 1.5 * (eval_count / self.budget)\n            self.mutation_factor = 0.4 + 0.1 * np.sin(np.pi * generation / 10)\n            \n            # Turbulent search for stagnation handling\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:  # If stagnant, apply turbulence\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)  # Injecting turbulence\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:  # Reinitialize if too close\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0  # Reset stagnation counter\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Improve mutation strategy by diversifying particle movement using random scaling of velocities.", "configspace": "", "generation": 21, "fitness": 0.0769636373326383, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.077 with standard deviation 0.011. And the mean value of best solutions found was 0.216 (0. is the best).", "error": "", "parent_id": "5a7aae45-4339-4e16-bfef-683e0341ee8d", "metadata": {"aucs": [0.09049213582366666, 0.06253635406701996, 0.07786242210722827], "final_y": [0.1648557973002821, 0.2827466934083528, 0.2004449216164167]}, "mutation_prompt": null}
{"id": "5d947b52-ca6a-4071-a85e-2dbfd68ffc49", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0  # Added for stagnation detection\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score  # Storing previous best score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()  # Random scaling\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)  # Adaptive mutation\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)  # Increased dynamic range\n            self.cognitive_weight = 1.5 + 1.5 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget)) # temporal decay\n            self.social_weight = 1.5 + 1.5 * (eval_count / self.budget)\n            self.mutation_factor = 0.4 + 0.1 * np.sin(np.pi * generation / 10)\n            \n            # Turbulent search for stagnation handling\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:  # If stagnant, apply turbulence\n                turbulence = np.random.uniform(-0.05, 0.05, size=(self.population_size, self.dim))  # Reduced turbulence range\n                self.particles += turbulence * (ub - lb)  # Injecting turbulence\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:  # Reinitialize if too close\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0  # Reset stagnation counter\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Enhanced dynamic parameter adaptation and turbulence management in hybrid PSO-DE.", "configspace": "", "generation": 22, "fitness": 0.08838193972313417, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.088 with standard deviation 0.002. And the mean value of best solutions found was 0.171 (0. is the best).", "error": "", "parent_id": "d295502e-3281-4fe8-a589-f306cbf9b965", "metadata": {"aucs": [0.09009071410918423, 0.08977002382201249, 0.08528508123820577], "final_y": [0.16485578226458275, 0.1648557740983796, 0.18187810173615093]}, "mutation_prompt": null}
{"id": "e099758a-c1d6-43c3-bc55-0b7b2efe38ab", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0  # Added for stagnation detection\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score  # Storing previous best score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()  # Random scaling\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)  # Adaptive mutation\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)  # Increased dynamic range\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget)) # temporal decay\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = 0.4 + 0.1 * np.sin(np.pi * generation / 10)\n            \n            # Turbulent search for stagnation handling\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:  # If stagnant, apply turbulence\n                turbulence = np.random.uniform(-0.06, 0.06, size=(self.population_size, self.dim))  # Revised turbulence range\n                self.particles += turbulence * (ub - lb)  # Injecting turbulence\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:  # Reinitialize if too close\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0  # Reset stagnation counter\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "By slightly adjusting the turbulence effect and enhancing the dynamic parameter adjustment, the refined algorithm aims to improve escape from local optima and convergence speed.", "configspace": "", "generation": 23, "fitness": 0.08856262174338214, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.089 with standard deviation 0.002. And the mean value of best solutions found was 0.171 (0. is the best).", "error": "", "parent_id": "5d947b52-ca6a-4071-a85e-2dbfd68ffc49", "metadata": {"aucs": [0.09056925147884265, 0.08571624967359515, 0.08940236407770863], "final_y": [0.1648557723754276, 0.1818780972487808, 0.16485577462242917]}, "mutation_prompt": null}
{"id": "2c7c8dcb-1158-4d60-8e8d-8ae6e22f12a7", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0  # Added for stagnation detection\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score  # Storing previous best score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()  # Random scaling\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)  # Adaptive mutation\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)  # Increased dynamic range\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget)) # temporal decay\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.1 * self.stagnation_count)  # Dynamic adjustment\n            \n            # Turbulent search for stagnation handling\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:  # If stagnant, apply turbulence\n                turbulence = np.random.uniform(-0.06, 0.06, size=(self.population_size, self.dim))  # Revised turbulence range\n                self.particles += turbulence * (ub - lb)  # Injecting turbulence\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:  # Reinitialize if too close\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0  # Reset stagnation counter\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "By introducing a dynamic mutation factor adjustment based on stagnation, the algorithm enhances exploration capability when convergence stalls.", "configspace": "", "generation": 24, "fitness": 0.08948092835697315, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.089 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "e099758a-c1d6-43c3-bc55-0b7b2efe38ab", "metadata": {"aucs": [0.09026410688765496, 0.09077675965641996, 0.08740191852684454], "final_y": [0.16485579919779725, 0.164855772477965, 0.1648557781607476]}, "mutation_prompt": null}
{"id": "bee34ac4-dab7-4d87-8c05-fca0b640aa28", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0  # Added for stagnation detection\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score  # Storing previous best score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                velocity_perturbation = 0.05 * np.random.randn(self.dim)  # Added velocity perturbation\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component + velocity_perturbation)  # Integrated perturbation\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)  # Adaptive mutation\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)  # Increased dynamic range\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget)) # temporal decay\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.1 * self.stagnation_count)  # Dynamic adjustment\n            \n            # Turbulent search for stagnation handling\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.06, 0.06, size=(self.population_size, self.dim))  # Revised turbulence range\n                self.particles += turbulence * (ub - lb)  # Injecting turbulence\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:  # Reinitialize if too close\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0  # Reset stagnation counter\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "By enhancing particle diversity through strategic velocity perturbation and refining stagnation handling, the algorithm improves its exploration efficiency.", "configspace": "", "generation": 25, "fitness": 0.03176962107079032, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.032 with standard deviation 0.003. And the mean value of best solutions found was 0.495 (0. is the best).", "error": "", "parent_id": "2c7c8dcb-1158-4d60-8e8d-8ae6e22f12a7", "metadata": {"aucs": [0.03581813984791238, 0.031122284133634603, 0.028368439230823994], "final_y": [0.4996961152131181, 0.4448416976190612, 0.541572462659676]}, "mutation_prompt": null}
{"id": "22acac6b-b47d-426a-9733-5c0885c61387", "solution": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            dynamic_pop_size = max(10, int(20 - (10 * eval_count / self.budget)))\n            if dynamic_pop_size != self.population_size:\n                self.population_size = dynamic_pop_size\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n\n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.1 * self.stagnation_count)\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:\n                turbulence = np.random.uniform(-0.06, 0.06, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveHybridPSO_DE", "description": "By incorporating multi-level adaptive population control and hybrid mutation schemes, the algorithm dynamically balances exploration and exploitation to enhance convergence and prevent premature stagnation.", "configspace": "", "generation": 26, "fitness": 0.08870464395343632, "feedback": "The algorithm AdaptiveHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.089 with standard deviation 0.002. And the mean value of best solutions found was 0.171 (0. is the best).", "error": "", "parent_id": "2c7c8dcb-1158-4d60-8e8d-8ae6e22f12a7", "metadata": {"aucs": [0.08982009425069104, 0.08994696013673298, 0.08634687747288494], "final_y": [0.16485578874549167, 0.1648557741841602, 0.18187811986616687]}, "mutation_prompt": null}
{"id": "6bcff4a7-e172-4802-855f-40cc280c2f82", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0  # Added for stagnation detection\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score  # Storing previous best score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * (0.9 + 0.1 * np.random.rand())  # Slightly increasing randomness\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)  # Adaptive mutation\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)  # Increased dynamic range\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget)) # temporal decay\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.1 * self.stagnation_count)  # Dynamic adjustment\n            \n            # Turbulent search for stagnation handling\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:  # If stagnant, apply turbulence\n                turbulence = np.random.uniform(-0.06, 0.06, size=(self.population_size, self.dim))  # Revised turbulence range\n                self.particles += turbulence * (ub - lb)  # Injecting turbulence\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:  # Reinitialize if too close\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0  # Reset stagnation counter\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Slightly increase the randomness in velocity update to enhance exploration and prevent premature convergence.", "configspace": "", "generation": 27, "fitness": 0.05346215242838855, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.053 with standard deviation 0.016. And the mean value of best solutions found was 0.338 (0. is the best).", "error": "", "parent_id": "2c7c8dcb-1158-4d60-8e8d-8ae6e22f12a7", "metadata": {"aucs": [0.03121078190686566, 0.070672035048297, 0.05850364033000299], "final_y": [0.4766057192423785, 0.21914112052246038, 0.3190675108594291]}, "mutation_prompt": null}
{"id": "702f381d-c917-47c8-9e6a-c5f5f3eb87c2", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0  # Added for stagnation detection\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score  # Storing previous best score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()  # Random scaling\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)  # Adaptive mutation\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)  # Increased dynamic range\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget)) # temporal decay\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.1 * self.stagnation_count)  # Dynamic adjustment\n            \n            # Turbulent search for stagnation handling\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n                self.crossover_rate = 0.9 + 0.1 * self.stagnation_count / 10  # Dynamic crossover rate adjustment\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:  # If stagnant, apply turbulence\n                turbulence = np.random.uniform(-0.06, 0.06, size=(self.population_size, self.dim))  # Revised turbulence range\n                self.particles += turbulence * (ub - lb)  # Injecting turbulence\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:  # Reinitialize if too close\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0  # Reset stagnation counter\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduced a dynamic crossover rate adjustment to enhance diversity when convergence stalls.", "configspace": "", "generation": 28, "fitness": 0.08511120758441852, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.085 with standard deviation 0.007. And the mean value of best solutions found was 0.179 (0. is the best).", "error": "", "parent_id": "2c7c8dcb-1158-4d60-8e8d-8ae6e22f12a7", "metadata": {"aucs": [0.0904201395898121, 0.08928293401281229, 0.07563054915063117], "final_y": [0.16485590799185756, 0.16485577469326318, 0.20725427037532518]}, "mutation_prompt": null}
{"id": "e5860123-d6ad-41cd-b7fc-da3935b89f09", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0  # Added for stagnation detection\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score  # Storing previous best score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()  # Random scaling\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)  # Adaptive mutation\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)  # Increased dynamic range\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget)) # temporal decay\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.1 * self.stagnation_count)  # Dynamic adjustment\n            \n            # Turbulent search for stagnation handling\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:  # If stagnant, apply turbulence\n                turbulence = np.random.uniform(-0.06, 0.06, size=(self.population_size, self.dim))  # Revised turbulence range\n                self.particles += turbulence * (ub - lb)  # Injecting turbulence\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:  # Reinitialize if too close\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0  # Reset stagnation counter\n            \n            # Reset velocities periodically\n            if generation % 15 == 0:\n                self.velocities = np.random.rand(self.population_size, self.dim) * 0.1  # Velocity reset\n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "By introducing periodic velocity reset and improved convergence rate calculation, the algorithm reduces local optima trapping and enhances convergence speed.", "configspace": "", "generation": 29, "fitness": 0.0878742672105181, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.088 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "2c7c8dcb-1158-4d60-8e8d-8ae6e22f12a7", "metadata": {"aucs": [0.08587336788023636, 0.09041384766455796, 0.08733558608675995], "final_y": [0.16485577327695555, 0.16485577199726953, 0.16485577473592716]}, "mutation_prompt": null}
{"id": "3c5498fc-5df2-402f-8c9b-cc591d6a2da5", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0  # Added for stagnation detection\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score  # Storing previous best score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()  # Random scaling\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:  # Enhanced crossover mechanism\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)  # Adaptive mutation\n                    trial = np.where(np.random.rand(self.dim) < 0.8 + 0.2 * np.cos(np.pi * generation / self.budget), mutant, self.particles[i])  # Nonlinear crossover\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget) ** 2  # Nonlinear decay\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget)) # temporal decay\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.1 * self.stagnation_count)  # Dynamic adjustment\n            \n            # Turbulent search for stagnation handling\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:  # If stagnant, apply turbulence\n                turbulence = np.random.uniform(-0.06, 0.06, size=(self.population_size, self.dim))  # Revised turbulence range\n                self.particles += turbulence * (ub - lb)  # Injecting turbulence\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:  # Reinitialize if too close\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0  # Reset stagnation counter\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "By incorporating nonlinear decaying inertia and enhanced crossover mechanisms, the algorithm refines its convergence and exploration balance.", "configspace": "", "generation": 30, "fitness": 0.08679228355158553, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.087 with standard deviation 0.003. And the mean value of best solutions found was 0.176 (0. is the best).", "error": "", "parent_id": "2c7c8dcb-1158-4d60-8e8d-8ae6e22f12a7", "metadata": {"aucs": [0.0905474108173634, 0.08409558228320746, 0.08573385755418572], "final_y": [0.16485580179552617, 0.18187811190648917, 0.18187817660021988]}, "mutation_prompt": null}
{"id": "3d3dbc67-fc45-4c8d-895a-f5526d81a92b", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0  # Added for stagnation detection\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score  # Storing previous best score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()  # Random scaling\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)  # Adaptive mutation\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)  # Increased dynamic range\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget)) # temporal decay\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.1 * self.stagnation_count)  # Dynamic adjustment\n            self.crossover_rate = 0.8 + 0.1 * np.cos(np.pi * generation / 15)  # Adaptive crossover rate\n            \n            # Turbulent search for stagnation handling\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:  # If stagnant, apply turbulence\n                turbulence = np.random.uniform(-0.06, 0.06, size=(self.population_size, self.dim))  # Revised turbulence range\n                self.particles += turbulence * (ub - lb)  # Injecting turbulence\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:  # Reinitialize if too close\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0  # Reset stagnation counter\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduced adaptive crossover rate based on generation count to enhance exploration and exploitation balance.", "configspace": "", "generation": 31, "fitness": 0.088432927605128, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.088 with standard deviation 0.002. And the mean value of best solutions found was 0.171 (0. is the best).", "error": "", "parent_id": "2c7c8dcb-1158-4d60-8e8d-8ae6e22f12a7", "metadata": {"aucs": [0.08498652727521205, 0.0906504172120356, 0.08966183832813635], "final_y": [0.181878101468, 0.1648557763970333, 0.16485579690269325]}, "mutation_prompt": null}
{"id": "5b9707f4-2565-44d8-8ee6-d4d6cf29a8bf", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0  # Added for stagnation detection\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score  # Storing previous best score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()  # Random scaling\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)  # Adaptive mutation\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))  # Introduced cosine variation\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget)) # temporal decay\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.1 * self.stagnation_count)  # Dynamic adjustment\n            \n            # Turbulent search for stagnation handling\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:  # If stagnant, apply turbulence\n                turbulence = np.random.uniform(-0.06, 0.06, size=(self.population_size, self.dim))  # Revised turbulence range\n                self.particles += turbulence * (ub - lb)  # Injecting turbulence\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:  # Reinitialize if too close\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0  # Reset stagnation counter\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduce a cosine-based inertia weight variation for smoother convergence dynamics.", "configspace": "", "generation": 32, "fitness": 0.0891087318732043, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.089 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "2c7c8dcb-1158-4d60-8e8d-8ae6e22f12a7", "metadata": {"aucs": [0.09067349237329958, 0.08916825600340839, 0.08748444724290494], "final_y": [0.1648558286900248, 0.16485579718913024, 0.16485578192543104]}, "mutation_prompt": null}
{"id": "5b49538f-7b27-4e75-a883-21e7f71083c6", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0  # Added for stagnation detection\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score  # Storing previous best score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()  # Random scaling\n                self.particles[i] += self.velocities[i]\n                \n                # Updated line for adaptive crossover rate\n                if np.random.rand() < self.crossover_rate * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget)):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)  # Adaptive mutation\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)  # Increased dynamic range\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget)) # temporal decay\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.1 * self.stagnation_count)  # Dynamic adjustment\n            \n            # Turbulent search for stagnation handling\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:  # If stagnant, apply turbulence\n                turbulence = np.random.uniform(-0.06, 0.06, size=(self.population_size, self.dim))  # Revised turbulence range\n                self.particles += turbulence * (ub - lb)  # Injecting turbulence\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:  # Reinitialize if too close\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0  # Reset stagnation counter\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "By introducing an adaptive crossover rate influenced by the generation count, the algorithm refines its balance between exploration and exploitation.", "configspace": "", "generation": 33, "fitness": 0.0894809283445817, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.089 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "2c7c8dcb-1158-4d60-8e8d-8ae6e22f12a7", "metadata": {"aucs": [0.09026410586432498, 0.09077675967547816, 0.08740191949394194], "final_y": [0.1648558088772749, 0.16485577228086268, 0.16485577819179942]}, "mutation_prompt": null}
{"id": "1fb48172-a120-4e4a-aee1-f96f7468c6ab", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0  # Added for stagnation detection\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score  # Storing previous best score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()  # Random scaling\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)  # Adaptive mutation\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adjusted dynamic range\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget)) # temporal decay\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.1 * self.stagnation_count)  # Dynamic adjustment\n            \n            # Turbulent search for stagnation handling\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:  # If stagnant, apply turbulence\n                turbulence = np.random.uniform(-0.06, 0.06, size=(self.population_size, self.dim))  # Revised turbulence range\n                self.particles += turbulence * (ub - lb)  # Injecting turbulence\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:  # Reinitialize if too close\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0  # Reset stagnation counter\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduced a secondary mutation strategy and revised inertia dynamics for enhanced exploration.", "configspace": "", "generation": 34, "fitness": 0.0882028652646158, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.088 with standard deviation 0.002. And the mean value of best solutions found was 0.173 (0. is the best).", "error": "", "parent_id": "2c7c8dcb-1158-4d60-8e8d-8ae6e22f12a7", "metadata": {"aucs": [0.08484960309591949, 0.09084508710955452, 0.08891390558837342], "final_y": [0.18813064484088904, 0.16485577768119897, 0.1648557795224055]}, "mutation_prompt": null}
{"id": "a3c5ac85-5d48-4084-b406-0ff2f2c0d16a", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE_Chaos:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n        self.chaos = np.random.rand(self.population_size, self.dim)  # Chaos initialization\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    chaos_mutation = self.chaos[i] * (a - b) + (c - a)  \n                    mutant = np.clip(a + self.mutation_factor * chaos_mutation, lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.1 * self.stagnation_count)\n            self.crossover_rate = 0.8 + 0.2 * np.cos(np.pi * generation / self.budget)  # Adaptive crossover rate\n\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:\n                turbulence = np.random.uniform(-0.06, 0.06, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE_Chaos", "description": "Integrate a chaos-based mutation strategy and adaptive crossover rate to enhance exploration and exploitation balance.", "configspace": "", "generation": 35, "fitness": 0.08860546201109203, "feedback": "The algorithm EnhancedHybridPSO_DE_Chaos got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.089 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "2c7c8dcb-1158-4d60-8e8d-8ae6e22f12a7", "metadata": {"aucs": [0.09032275043213589, 0.08984787255438276, 0.08564576304675742], "final_y": [0.16485577194933454, 0.164855771905853, 0.16485577301031018]}, "mutation_prompt": null}
{"id": "332e6ed7-7f40-4af1-9320-49667c3933e9", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.5 * (1 - eval_count / self.budget)  # Line 1 changed\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.1 * self.stagnation_count)  # Line 2 changed\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:\n                turbulence = np.random.uniform(-0.05, 0.06, size=(self.population_size, self.dim))  # Line 3 changed\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-5:  # Line 4 changed\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                    self.personal_best_scores = np.full(self.population_size, np.inf)  # Line 5 added\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "By incorporating adaptive learning rates and a re-evaluation mechanism, the algorithm improves convergence by fine-tuning exploration versus exploitation balance.", "configspace": "", "generation": 36, "fitness": 0.08926635939826495, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.089 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "2c7c8dcb-1158-4d60-8e8d-8ae6e22f12a7", "metadata": {"aucs": [0.09033265683240754, 0.08916078733056143, 0.0883056340318259], "final_y": [0.16485583631700162, 0.16485578531062595, 0.16485580937943878]}, "mutation_prompt": null}
{"id": "0028f280-d0f4-4fbd-b728-b64449f1e130", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0  # Added for stagnation detection\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:  # Dynamic population resizing\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score  # Storing previous best score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()  # Random scaling\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)  # Adaptive mutation\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            # Adaptive parameter adjustment\n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)  # Increased dynamic range\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget)) # temporal decay\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.1 * self.stagnation_count)  # Dynamic adjustment\n            \n            # Turbulent search for stagnation handling\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 10:  # If stagnant, apply turbulence\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))  # Revised turbulence range\n                self.particles += turbulence * (ub - lb)  # Injecting turbulence\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:  # Reinitialize if too close\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0  # Reset stagnation counter\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Refine the turbulence range for stagnant conditions to enhance exploration.", "configspace": "", "generation": 37, "fitness": 0.08952047685462901, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.090 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "2c7c8dcb-1158-4d60-8e8d-8ae6e22f12a7", "metadata": {"aucs": [0.09026410688765496, 0.09077675965641996, 0.08752056401981212], "final_y": [0.16485579919779725, 0.164855772477965, 0.16485577590817335]}, "mutation_prompt": null}
{"id": "cf3cb2a1-7dba-42a0-bcb7-a20df5263107", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduce diversity by amplifying the mutation factor and enhancing turbulence detection.", "configspace": "", "generation": 38, "fitness": 0.09067191753563919, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.091 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "0028f280-d0f4-4fbd-b728-b64449f1e130", "metadata": {"aucs": [0.09059548276840379, 0.09076005035780255, 0.09066021948071123], "final_y": [0.1648557999271637, 0.16485577475943702, 0.1648557939414692]}, "mutation_prompt": null}
{"id": "50760d1d-90e8-4988-b07d-2055c8dd82f0", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n\n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = 0.6 * np.exp(-5 * eval_count / self.budget)  # Changed dynamic adjustment for mutation factor\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduce a dynamic mutation factor based on the ratio of the current evaluation count to budget to refine exploration and exploitation balance.", "configspace": "", "generation": 39, "fitness": 0.08786465141549538, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.088 with standard deviation 0.004. And the mean value of best solutions found was 0.177 (0. is the best).", "error": "", "parent_id": "cf3cb2a1-7dba-42a0-bcb7-a20df5263107", "metadata": {"aucs": [0.08179780493992672, 0.09064948692593955, 0.09114666238061986], "final_y": [0.2004449130340109, 0.1648557719939907, 0.1648557719468512]}, "mutation_prompt": null}
{"id": "be00260c-f0cb-4a51-b147-a43b54db0229", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n        self.chaos_factor = np.random.rand()\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(8, int(20 - (12 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + \n                                     self.chaos_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)\n            \n            self.chaos_factor = 0.7 * self.chaos_factor * (1 - self.chaos_factor) + 0.1 * np.random.rand()\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE_Refined", "description": "Introduce adaptive chaos-driven mutation and dynamic population resizing to enhance exploration and exploitation balance.", "configspace": "", "generation": 40, "fitness": 0.0888932543503288, "feedback": "The algorithm EnhancedHybridPSO_DE_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.089 with standard deviation 0.003. And the mean value of best solutions found was 0.171 (0. is the best).", "error": "", "parent_id": "cf3cb2a1-7dba-42a0-bcb7-a20df5263107", "metadata": {"aucs": [0.09123194587515115, 0.09082191591208921, 0.08462590126374603], "final_y": [0.16485577206023905, 0.164855771934041, 0.18187809762669616]}, "mutation_prompt": null}
{"id": "d40627d1-bbb6-4ce1-9e62-985942ba4b67", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.1  # Changed social weight from 2.0 to 2.1\n        self.mutation_factor = 0.6\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Increase social weight for improved convergence.", "configspace": "", "generation": 41, "fitness": 0.08808479621936798, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.088 with standard deviation 0.003. And the mean value of best solutions found was 0.173 (0. is the best).", "error": "", "parent_id": "cf3cb2a1-7dba-42a0-bcb7-a20df5263107", "metadata": {"aucs": [0.0849136936218785, 0.08786940983850366, 0.09147128519772174], "final_y": [0.18813065289454522, 0.16485580887666307, 0.16485577716944033]}, "mutation_prompt": null}
{"id": "afedfba3-f202-4cef-9162-46d63895fe36", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduce adaptive crossover rate and dynamic population resizing for enhanced exploration.", "configspace": "", "generation": 42, "fitness": 0.08709029263232097, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.087 with standard deviation 0.002. And the mean value of best solutions found was 0.176 (0. is the best).", "error": "", "parent_id": "cf3cb2a1-7dba-42a0-bcb7-a20df5263107", "metadata": {"aucs": [0.08923132348370166, 0.0862028745427944, 0.08583667987046684], "final_y": [0.1648557830527312, 0.18187809739994176, 0.18187809683010003]}, "mutation_prompt": null}
{"id": "8a14aea3-9f39-4764-a24d-3920c243f2c8", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Increased initial population size\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.8  # Adjusted inertia weight\n        self.cognitive_weight = 1.8  # Adjusted cognitive weight\n        self.social_weight = 2.1  # Adjusted social weight\n        self.mutation_factor = 0.65  # Increased mutation factor\n        self.crossover_rate = 0.85  # Adjusted crossover rate\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(25 - (15 * eval_count / self.budget)))  # Adjusted resizing strategy\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.uniform(0.8, 1.2)  # Added variability\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.5 + 0.5 * (1 - eval_count / self.budget)  # Adjusted inertia dynamic\n            self.cognitive_weight = 1.5 + 1.5 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))  # Adjusted cognitive dynamic\n            self.social_weight = 1.5 + 1.5 * (eval_count / self.budget)  # Adjusted social dynamic\n            self.mutation_factor = (0.5 + 0.15 * np.sin(np.pi * generation / 9)) * (1 + 0.2 * self.stagnation_count)  # Fine-tuned mutation dynamic\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 7:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Enhanced Particle Swarm Optimization with Adaptive Mutation and Diversity-Driven Strategy.", "configspace": "", "generation": 43, "fitness": 0.03825760808934001, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.038 with standard deviation 0.006. And the mean value of best solutions found was 0.447 (0. is the best).", "error": "", "parent_id": "cf3cb2a1-7dba-42a0-bcb7-a20df5263107", "metadata": {"aucs": [0.0396240730482621, 0.044356039565929484, 0.030792711653828464], "final_y": [0.44313598119115205, 0.4190159209902026, 0.47908430337611163]}, "mutation_prompt": null}
{"id": "ff3f629a-29ff-4fa2-a428-297c648c9c4e", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n\n            self.crossover_rate = 0.8 + 0.1 * np.cos(np.pi * generation / 50)  # Newly added dynamic crossover rate adjustment\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduce dynamic adjustment in crossover rate based on generation to enhance exploration.", "configspace": "", "generation": 44, "fitness": 0.09048773432401536, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.090 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "cf3cb2a1-7dba-42a0-bcb7-a20df5263107", "metadata": {"aucs": [0.0905189926288813, 0.08939330436815762, 0.09155090597500715], "final_y": [0.16485579424052654, 0.1648557719648902, 0.1648557976554973]}, "mutation_prompt": null}
{"id": "c7e57170-7f42-4466-8548-6c56a4de8711", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.15, 0.15, size=(self.population_size, self.dim))  # Slightly increased turbulence scale\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Slightly tweak the turbulence scale to enhance recovery from stagnation.", "configspace": "", "generation": 45, "fitness": 0.09067191753563919, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.091 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "cf3cb2a1-7dba-42a0-bcb7-a20df5263107", "metadata": {"aucs": [0.09059548276840379, 0.09076005035780255, 0.09066021948071123], "final_y": [0.1648557999271637, 0.16485577475943702, 0.1648557939414692]}, "mutation_prompt": null}
{"id": "accbbfd1-b81e-457c-b9f8-5f0698636cd9", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(25 - (15 * eval_count / self.budget)))  # Modified population resizing\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.15 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  # Adjusted mutation factor\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Enhance exploration by dynamic population resizing and mutation factor adjustment.", "configspace": "", "generation": 46, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "cf3cb2a1-7dba-42a0-bcb7-a20df5263107", "metadata": {}, "mutation_prompt": null}
{"id": "bb4efad3-bb02-450b-bb68-879a67c0fd87", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduce oscillatory learning rates to improve exploration and exploitation balance.", "configspace": "", "generation": 47, "fitness": 0.09067191753563919, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.091 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "cf3cb2a1-7dba-42a0-bcb7-a20df5263107", "metadata": {"aucs": [0.09059548276840379, 0.09076005035780255, 0.09066021948071123], "final_y": [0.1648557999271637, 0.16485577475943702, 0.1648557939414692]}, "mutation_prompt": null}
{"id": "ff2711e7-e97c-42cc-8a19-40c231a57a27", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence_intensity = 0.1 - 0.05 * (eval_count / self.budget)  # Dynamic turbulence range adjustment\n                turbulence = np.random.uniform(-turbulence_intensity, turbulence_intensity, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduce a dynamic turbulence range based on progress to adapt exploration intensity.", "configspace": "", "generation": 48, "fitness": 0.09067191753563919, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.091 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "cf3cb2a1-7dba-42a0-bcb7-a20df5263107", "metadata": {"aucs": [0.09059548276840379, 0.09076005035780255, 0.09066021948071123], "final_y": [0.1648557999271637, 0.16485577475943702, 0.1648557939414692]}, "mutation_prompt": null}
{"id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Adjust crossover rate dynamically with generation to balance exploration and exploitation.", "configspace": "", "generation": 49, "fitness": 0.09110392022650926, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.091 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "cf3cb2a1-7dba-42a0-bcb7-a20df5263107", "metadata": {"aucs": [0.09133571007558494, 0.09002529961383565, 0.09195075099010719], "final_y": [0.16485577240162075, 0.16485579578695653, 0.16485579864000377]}, "mutation_prompt": null}
{"id": "d06268a2-183b-4327-8d95-d966d60c8793", "solution": "import numpy as np\n\nclass AdaptiveDifferentialMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = trial_score\n                    self.personal_best_positions[i] = trial\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best_position = trial\n            \n            # Adaptive mutation factor\n            self.mutation_factor = 0.5 + 0.3 * (1 - eval_count / self.budget) * np.random.rand()\n            \n            # Preserve spatial diversity\n            diversity = np.mean(np.std(self.particles, axis=0))\n            if diversity < self.diversity_threshold:\n                turbulence = np.random.uniform(-0.2, 0.2, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveDifferentialMutation", "description": "Introduce adaptive differential mutation and spatial diversity preservation to enhance convergence and prevent stagnation.", "configspace": "", "generation": 50, "fitness": 0.004721338161643551, "feedback": "The algorithm AdaptiveDifferentialMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.005 with standard deviation 0.000. And the mean value of best solutions found was 0.918 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.004721698342794678, 0.004720753084459961, 0.004721563057676015], "final_y": [0.9183754915724518, 0.9183829526450024, 0.9183745059972979]}, "mutation_prompt": null}
{"id": "52255910-116f-494c-9118-23f6d9915870", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * (eval_count + generation) / (2 * self.budget))))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduce adaptive population dynamics by varying population size based on both generations and evaluations.", "configspace": "", "generation": 51, "fitness": 0.09109957632957573, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.091 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.09126284356838565, 0.09011765486647305, 0.0919182305538685], "final_y": [0.164855789233868, 0.16485580185425253, 0.1648557752023594]}, "mutation_prompt": null}
{"id": "78cdb7d4-0e2e-4e62-91a8-f07a22b24d62", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.41 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduce a slight increment in mutation factor to enhance exploration capability during stagnation periods.", "configspace": "", "generation": 52, "fitness": 0.08860415274646656, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.089 with standard deviation 0.003. And the mean value of best solutions found was 0.171 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.09022491294228907, 0.08493198238356237, 0.09065556291354826], "final_y": [0.16485577426796583, 0.1818781085684813, 0.1648558626614971]}, "mutation_prompt": null}
{"id": "67f7f986-3c03-4354-a8a3-8f8d1e009088", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.1  # Slightly increased cognitive weight\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Slightly increase the cognitive weight to enhance local exploration.", "configspace": "", "generation": 53, "fitness": 0.09110392022650926, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.091 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.09133571007558494, 0.09002529961383565, 0.09195075099010719], "final_y": [0.16485577240162075, 0.16485579578695653, 0.16485579864000377]}, "mutation_prompt": null}
{"id": "c63322d0-6f78-4480-84f4-1d02656bf37c", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = 0.75 * (1 + 0.15 * self.stagnation_count)\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:\n                self.particles += np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim)) * (ub - lb)\n                self.particles = np.where(np.mean(self.personal_best_scores) - self.global_best_score < 1e-6,\n                                          np.random.rand(self.population_size, self.dim) * (ub - lb) + lb, self.particles)\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduced adaptive particle reset and a more aggressive mutation factor to enhance exploration in stagnation phases.", "configspace": "", "generation": 54, "fitness": 0.08754659478907663, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.088 with standard deviation 0.005. And the mean value of best solutions found was 0.177 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.09084334898972701, 0.08044360772721015, 0.09135282765029273], "final_y": [0.16485603482458322, 0.20044499130373883, 0.16485577865665568]}, "mutation_prompt": null}
{"id": "4c1ea59b-aa98-4a52-acc5-56c2b87336fc", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + (self.mutation_factor + 0.05 * np.sin(eval_count)) * (b - c), lb, ub)  # Adaptive oscillation\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduce adaptive mutation factor oscillation for enhanced convergence.", "configspace": "", "generation": 55, "fitness": 0.08910177731520892, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.089 with standard deviation 0.004. And the mean value of best solutions found was 0.171 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.09214748300344289, 0.09131230202784879, 0.0838455469143351], "final_y": [0.16485577190589484, 0.16485577197202927, 0.18187809678851907]}, "mutation_prompt": null}
{"id": "303c9be9-7757-4276-bad8-6e02c7832827", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(0.5 * np.pi * generation / self.budget))  # Changed line\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduce adaptive inertia weight decay to adjust exploration-exploitation balance dynamically based on stagnation.", "configspace": "", "generation": 56, "fitness": 0.07782534347845808, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.078 with standard deviation 0.019. And the mean value of best solutions found was 0.196 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.09101331183744366, 0.05151017800775792, 0.09095254059017266], "final_y": [0.16485577526136797, 0.25781033147678756, 0.16485577349589553]}, "mutation_prompt": null}
{"id": "64a95f63-ca1e-4c7c-827b-af3e775bcac7", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.45 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Slightly adjusted the mutation factor calculation to potentially enhance exploration during optimization.", "configspace": "", "generation": 57, "fitness": 0.09056479315783539, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.091 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.09091723936108387, 0.09044967317562569, 0.09032746693679661], "final_y": [0.16485577262775153, 0.16485581895023094, 0.16485577226748716]}, "mutation_prompt": null}
{"id": "f81d5f2d-5828-4486-bb5d-3abfa5ce727a", "solution": "import numpy as np\n\nclass AQPSO_LS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.best_positions = np.copy(self.particles)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.quantum_radius = 0.1\n        self.local_search_prob = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.inertia_weight * (cognitive_component + social_component)\n\n                if np.random.rand() < self.local_search_prob:\n                    local_search_step = np.random.normal(0, self.quantum_radius, self.dim)\n                    local_candidate = np.clip(self.particles[i] + local_search_step, lb, ub)\n                    local_score = func(local_candidate)\n                    eval_count += 1\n                    if local_score < self.best_scores[i]:\n                        self.best_scores[i] = local_score\n                        self.best_positions[i] = local_candidate\n                        if local_score < self.global_best_score:\n                            self.global_best_score = local_score\n                            self.global_best_position = local_candidate\n\n            self.inertia_weight = 0.5 + 0.4 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.2 + 0.8 * (1 - eval_count / self.budget)\n            self.social_weight = 1.2 + 0.8 * (eval_count / self.budget)\n            self.quantum_radius *= (0.95 if eval_count / self.budget > 0.5 else 1.05)\n            self.local_search_prob = 0.1 + 0.2 * (1 - eval_count / self.budget)\n\n        return self.global_best_position, self.global_best_score", "name": "AQPSO_LS", "description": "Adaptive Quantum Particle Swarm with Local Search (AQPSO-LS) combines quantum-inspired representation with adaptive parameters and local search for enhanced exploration and exploitation.", "configspace": "", "generation": 58, "fitness": 0.03331425367482388, "feedback": "The algorithm AQPSO_LS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.033 with standard deviation 0.006. And the mean value of best solutions found was 0.346 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.02872381059567719, 0.04105262694701417, 0.030166323481780277], "final_y": [0.39018590851630175, 0.25809788139271606, 0.3902239248939121]}, "mutation_prompt": null}
{"id": "7da8efac-bed7-46f6-b06d-4d52263814c9", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.3 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Adjust mutation factor range to enhance adaptation during stagnation periods.", "configspace": "", "generation": 59, "fitness": 0.09009338827538926, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.090 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.089654971030806, 0.08965415186574333, 0.09097104192961847], "final_y": [0.1648557749534001, 0.16485577441521637, 0.16485577198055779]}, "mutation_prompt": null}
{"id": "1fb19ee5-5759-4e62-8747-3572368dd4ba", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget) * (1.0 + 0.1 * np.cos(np.pi * generation / 10)):  # Dynamic adjustment with enhancement\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduced adaptive crossover rate enhancement for better dynamic balance between exploration and exploitation.", "configspace": "", "generation": 60, "fitness": 0.08237338162223933, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.082 with standard deviation 0.009. And the mean value of best solutions found was 0.169 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.06900622738018669, 0.08864891026738642, 0.08946500721914485], "final_y": [0.17720537552392657, 0.16485577354125758, 0.1648557811018927]}, "mutation_prompt": null}
{"id": "65a28657-087a-44d4-9c46-d8187243f9ce", "solution": "import numpy as np\n\nclass AdaptiveLearningPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.base_inertia_weight = 0.9\n        self.cognitive_base = 2.0\n        self.social_base = 2.0\n        self.learning_rates = np.full(self.population_size, 0.5)\n        self.stagnation_count = np.zeros(self.population_size)\n        self.adaptive_threshold = 0.01\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    self.stagnation_count[i] = 0  # Reset stagnation for improved particles\n                else:\n                    self.stagnation_count[i] += 1\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                adaptive_inertia = self.base_inertia_weight - (self.base_inertia_weight - 0.4) * (eval_count / self.budget)\n                cognitive_component = self.learning_rates[i] * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.learning_rates[i] * np.random.rand(self.dim) * (self.global_best_position - self.particles[i])\n                self.velocities[i] = adaptive_inertia * self.velocities[i] + cognitive_component + social_component\n                self.particles[i] += self.velocities[i]\n\n                if self.stagnation_count[i] > 5:  # If stagnated, adjust learning rate\n                    self.learning_rates[i] = min(1.0, self.learning_rates[i] + self.adaptive_threshold)\n                else:\n                    self.learning_rates[i] = max(0.1, self.learning_rates[i] - self.adaptive_threshold)\n            \n        return self.global_best_position, self.global_best_score", "name": "AdaptiveLearningPSO", "description": "Introduce adaptive learning rates and inertia weights based on particle's historical performance to enhance convergence.", "configspace": "", "generation": 61, "fitness": 0.004722420647187087, "feedback": "The algorithm AdaptiveLearningPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.005 with standard deviation 0.000. And the mean value of best solutions found was 0.918 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.004722428034874437, 0.004722411383412117, 0.004722422523274705], "final_y": [0.9183673469387754, 0.9183673469387754, 0.9183673469387754]}, "mutation_prompt": null}
{"id": "55a689c9-a81c-4353-b478-df8427ed7fc0", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * np.abs(np.sin(np.pi * generation / 10))  # Sinusoidal modulation\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.6 + 0.2 * self.stagnation_count)  # Enhanced mutation factor increase\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduce adaptive inertia with sinusoidal modulation and enhance exploration by increasing mutation factor upon stagnation.", "configspace": "", "generation": 62, "fitness": 0.08794525625369065, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.088 with standard deviation 0.003. And the mean value of best solutions found was 0.171 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.09143794195512422, 0.08536210958067891, 0.08703571722526882], "final_y": [0.16485577234859106, 0.1818781210181566, 0.16485578688504032]}, "mutation_prompt": null}
{"id": "58cdd085-8ad5-4afa-ba24-84bbcbb3ae53", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (8 * eval_count / self.budget)))  # Adjusted resizing\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)  # Simplified mutation\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.5 + 0.5 * (1 - eval_count / self.budget)  # Smoother weight update\n            self.cognitive_weight = 1.6 + 1.4 * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))  # Fixed dynamic adjustment\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 12)) * (1 + 0.12 * self.stagnation_count)  # Enhanced mutation dynamic\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduce adaptive population resizing and dynamic weight strategy to enhance convergence and exploration.", "configspace": "", "generation": 63, "fitness": 0.0900758226676186, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.090 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.09101417278542545, 0.09157121324416662, 0.08764208197326373], "final_y": [0.16485577190470213, 0.1648557719047007, 0.16485577190470835]}, "mutation_prompt": null}
{"id": "bbf25ba2-9430-4f60-a0d3-bab46ba2aa13", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n\n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = 0.5 + 0.3 * np.sin(np.pi * generation / 10)  # Changed mutation factor adaptation\n\n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduced adaptive mutation factor based on generation to enhance diversity and convergence.", "configspace": "", "generation": 64, "fitness": 0.08899360296016938, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.089 with standard deviation 0.003. And the mean value of best solutions found was 0.171 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.09132457715888154, 0.08453995875044662, 0.09111627297117997], "final_y": [0.16485579950443408, 0.18187809827666757, 0.16485577420033737]}, "mutation_prompt": null}
{"id": "53a95644-b771-4081-92bc-d52547ee6dee", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    # Change made here for Gaussian perturbation\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + np.random.normal(0, 0.1, self.dim), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Adjust crossover strategy to enhance diversity by using Gaussian perturbation during DE mutation.", "configspace": "", "generation": 65, "fitness": 0.08548733285621686, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.085 with standard deviation 0.003. And the mean value of best solutions found was 0.178 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.08856861179189346, 0.08594889311750886, 0.08194449365924827], "final_y": [0.1648557723102767, 0.1818781252424333, 0.18813064479353991]}, "mutation_prompt": null}
{"id": "0e69ac52-ca69-4689-9eb1-87f9b1d2e6f5", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.5 * (1 - eval_count / self.budget)  # Modified decay\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Enhanced convergence by modifying the inertia weight decay strategy.", "configspace": "", "generation": 66, "fitness": 0.08896851646007727, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.089 with standard deviation 0.003. And the mean value of best solutions found was 0.171 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.09112687972805, 0.08476104130211204, 0.09101762835006977], "final_y": [0.16485577411030283, 0.181878106757149, 0.16485579465254263]}, "mutation_prompt": null}
{"id": "859f6d4f-fd5e-4aba-b4b9-174dfdf68cb3", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduced adaptive population size variation based on performance metrics for improved exploration-exploitation balance.", "configspace": "", "generation": 67, "fitness": 0.09110392022650926, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.091 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.09133571007558494, 0.09002529961383565, 0.09195075099010719], "final_y": [0.16485577240162075, 0.16485579578695653, 0.16485579864000377]}, "mutation_prompt": null}
{"id": "025f613d-076d-43b3-8c09-5a70707e1fb9", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Fine-tuned inertia weight formula\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Fine-tuned the inertia weight formula for improved balancing of exploration and exploitation.", "configspace": "", "generation": 68, "fitness": 0.09064772882829408, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.091 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.09092296017557144, 0.08962268712438237, 0.09139753918492843], "final_y": [0.164855819455891, 0.16485577198517698, 0.16485577549339092]}, "mutation_prompt": null}
{"id": "8587b1d6-003e-4fe3-8dfb-8758a089e2c1", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  \n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.5 + 0.4 * (1 - eval_count / self.budget)  \n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  \n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 5:  \n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Refined inertia weight dynamics and adjusted stagnation handling for better balance between exploration and exploitation.", "configspace": "", "generation": 69, "fitness": 0.08877419079530117, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.089 with standard deviation 0.003. And the mean value of best solutions found was 0.176 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.09260745061467912, 0.08689894476146798, 0.08681617700975641], "final_y": [0.16485577712639288, 0.1818781252370899, 0.18187809702249857]}, "mutation_prompt": null}
{"id": "651f9aa5-7245-4cf1-9013-0b10a7dab4a5", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.20 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Enhanced dynamic adaptation of crossover rate and mutation factor for improved exploration-exploitation balance. ", "configspace": "", "generation": 70, "fitness": 0.08948297989845196, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.089 with standard deviation 0.003. And the mean value of best solutions found was 0.171 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.09114837880196247, 0.08550395017950518, 0.09179661071388823], "final_y": [0.1648557736692413, 0.18187809859077808, 0.1648557928466542]}, "mutation_prompt": null}
{"id": "19dbe79e-f49c-468a-ad7d-838f06e48840", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                velocity_scale = 1.0 - (0.5 * eval_count / self.budget)  # Adaptive velocity scaling\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand() * velocity_scale\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduce adaptive velocity scaling to enhance convergence speed while maintaining diversity.", "configspace": "", "generation": 71, "fitness": 0.08860596336231034, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.089 with standard deviation 0.002. And the mean value of best solutions found was 0.171 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.08623624766739957, 0.08976098558115742, 0.08982065683837404], "final_y": [0.18187814066037666, 0.16485593097430307, 0.16485609681924707]}, "mutation_prompt": null}
{"id": "14bfd345-eceb-4494-96d0-016110d2fd5f", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.5 * (1 - eval_count / self.budget)  # Modified adaptive inertia weight\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduce adaptive inertia weight decrease for improved convergence in EnhancedHybridPSO_DE.", "configspace": "", "generation": 72, "fitness": 0.08896851646007727, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.089 with standard deviation 0.003. And the mean value of best solutions found was 0.171 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.09112687972805, 0.08476104130211204, 0.09101762835006977], "final_y": [0.16485577411030283, 0.181878106757149, 0.16485579465254263]}, "mutation_prompt": null}
{"id": "ebc74fac-c9ce-4491-b71e-8edb62d4e763", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.velocities[i] = np.clip(self.velocities[i], -0.2, 0.2)  # Adaptive velocity clamping\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.05 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  # Minor tweak in mutation factor\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduce adaptive velocity clamping and minor tweak in mutation factor to enhance convergence stability.", "configspace": "", "generation": 73, "fitness": 0.06025217505734167, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.060 with standard deviation 0.004. And the mean value of best solutions found was 0.262 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.06436378683021327, 0.06120976543758572, 0.055182972904226024], "final_y": [0.2502498628857457, 0.25436379941603726, 0.28045879436258303]}, "mutation_prompt": null}
{"id": "5f8049d1-c10f-439b-ab85-d0661828adf3", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            diversity = np.mean(np.std(self.particles, axis=0))  # Calculate diversity\n            self.mutation_factor = 0.4 + 0.2 * diversity  # Adaptive mutation based on diversity\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduce adaptive mutation factor based on diversity measures to maintain population diversity.", "configspace": "", "generation": 74, "fitness": 0.08740261566840342, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.087 with standard deviation 0.003. And the mean value of best solutions found was 0.171 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.08941897008823341, 0.08902439229293813, 0.08376448462403874], "final_y": [0.1648557814160143, 0.1648557791437265, 0.18187810433160012]}, "mutation_prompt": null}
{"id": "36ed6563-09c8-444d-bffc-1a2a35af5d93", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 + np.cos(np.pi * generation / self.budget))  # Adjusted inertia weight\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduce adaptive inertia weight using cosine annealing to enhance convergence and exploration balance.", "configspace": "", "generation": 75, "fitness": 0.0749806227370982, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.075 with standard deviation 0.010. And the mean value of best solutions found was 0.194 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.08184864253773139, 0.06064617858933796, 0.08244704708422523], "final_y": [0.18478736353960024, 0.2064479403586087, 0.18982122436235327]}, "mutation_prompt": null}
{"id": "408aa454-350a-4b23-92e9-ce5b3ebab13c", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  \n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count) \n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8: \n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                self.particles = np.random.rand(self.population_size + 5, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduce adaptive population resizing and incorporate a restart mechanism to escape local optima.", "configspace": "", "generation": 76, "fitness": 0.08843045645974101, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.088 with standard deviation 0.003. And the mean value of best solutions found was 0.171 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.09083804662407347, 0.0904092063323444, 0.08404411642280518], "final_y": [0.16485583919898772, 0.16485584012540966, 0.18187810150685202]}, "mutation_prompt": null}
{"id": "460a004d-f25b-4f65-a5e7-e7f477b8c3fc", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.8 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))  # Adjusted cognitive weight\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Adjust the cognitive weight to increase diversity and prevent premature convergence.", "configspace": "", "generation": 77, "fitness": 0.08814001868333758, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.088 with standard deviation 0.004. And the mean value of best solutions found was 0.173 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.08270102345743013, 0.09037256112021774, 0.09134647147236485], "final_y": [0.18813065349427172, 0.16485579081586388, 0.16485578544353718]}, "mutation_prompt": null}
{"id": "868e509e-00dc-458c-b333-df5e9d4ed3ff", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 9.5)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Slightly tweak the mutation factor calculation to enhance convergence speed by introducing a subtle change in its sinusoidal component.", "configspace": "", "generation": 78, "fitness": 0.09070573590091675, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.091 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.08993687547708018, 0.09020665519649085, 0.09197367702917925], "final_y": [0.16485580440783576, 0.16485577202063284, 0.16485577716916533]}, "mutation_prompt": null}
{"id": "fbb04510-b7e6-4aa9-a4d2-c5e43cd95c86", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.2, 0.2, size=(self.population_size, self.dim))  # Changed turbulence magnitude\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Improve exploration by altering turbulence magnitude to expand search space adaptively.", "configspace": "", "generation": 79, "fitness": 0.09110392022650926, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.091 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.09133571007558494, 0.09002529961383565, 0.09195075099010719], "final_y": [0.16485577240162075, 0.16485579578695653, 0.16485579864000377]}, "mutation_prompt": null}
{"id": "72205239-0bc9-4a3f-84c2-5f792fb151e3", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget + 0.1 * self.stagnation_count):  # Enhanced dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adjusted weight\n            self.cognitive_weight = 1.5 + 1.5 * (1 - eval_count / self.budget) * (0.4 + 0.6 * np.cos(np.pi * generation / self.budget))  # Adjusted weights\n            self.social_weight += 0.1 * (eval_count / self.budget)  # Increase over time\n            self.mutation_factor = 0.5 + 0.2 * np.sin(np.pi * generation / 15) * (1 + 0.2 * self.stagnation_count)  # Further modified mutation dynamic\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Incorporate adaptive mutation and crossover strategies to improve exploration and convergence efficiency.", "configspace": "", "generation": 80, "fitness": 0.08947329624215916, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.089 with standard deviation 0.002. And the mean value of best solutions found was 0.167 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.08955113936924641, 0.09207814966392003, 0.08679059969331104], "final_y": [0.16485668661062758, 0.16485597206393754, 0.17187054827720594]}, "mutation_prompt": null}
{"id": "19794447-a037-40d0-8b38-48a8de9ab263", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))          \n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10 + np.pi/4)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Enhanced dynamic adjustment of cognitive and social weights along with a new criterion for mutation to effectively balance exploration and exploitation.", "configspace": "", "generation": 81, "fitness": 0.0869155251268637, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.087 with standard deviation 0.003. And the mean value of best solutions found was 0.176 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.08627277176975423, 0.09133480284672224, 0.08313900076411462], "final_y": [0.18187813796804853, 0.1648557812006325, 0.18187811198669002]}, "mutation_prompt": null}
{"id": "9f6d5eea-cf76-43bf-b22e-2ab2784d552a", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            diversity = np.mean(np.std(self.particles, axis=0))  # Added line for diversity calculation\n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget)) * (1 + 0.5 * diversity)  # Adjusted cognitive weight\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduce adaptive cognitive weight based on diversity to improve exploration.", "configspace": "", "generation": 82, "fitness": 0.05801115523738439, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.058 with standard deviation 0.014. And the mean value of best solutions found was 0.336 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.04782826574061494, 0.04806339361060474, 0.07814180636093349], "final_y": [0.3960207299608789, 0.39333114012348835, 0.21844120334755524]}, "mutation_prompt": null}
{"id": "ef5e3a7d-f655-4e81-9015-a42a0349ca60", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand() * 1.01  # Slightly increase exploration\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Incorporate adaptive learning strategy by slightly increasing the exploration phase.", "configspace": "", "generation": 83, "fitness": 0.08889716505401057, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.089 with standard deviation 0.003. And the mean value of best solutions found was 0.171 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.09060624787502092, 0.08534145807160143, 0.09074378921540938], "final_y": [0.16485577450040168, 0.1818781711987416, 0.16485581161394658]}, "mutation_prompt": null}
{"id": "d37da67c-e687-4611-bb1e-85d673982c06", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n\n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(8, int(18 - (8 * eval_count / self.budget)))  # Reduce population size more aggressively\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * (0.5 + 0.5 * np.random.rand())  # Adjust velocity modulation\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.5 * (1 - eval_count / self.budget)  # Adjust inertia weight\n            self.cognitive_weight = 1.7 + 1.3 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.3 + 1.5 * (eval_count / self.budget)\n            self.mutation_factor = (0.5 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduce adaptive swarm resizing and dynamic velocity modulation to enhance convergence and prevent premature stagnation. ", "configspace": "", "generation": 84, "fitness": 0.0879153755281062, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.088 with standard deviation 0.005. And the mean value of best solutions found was 0.171 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.09113285909005664, 0.09197779233711867, 0.08063547515714331], "final_y": [0.16485577190470024, 0.16485577190529965, 0.18188282316333382]}, "mutation_prompt": null}
{"id": "7ab9ac79-634f-4b0b-9c0e-1eec2c88c76f", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Slightly adjusted inertia range\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.15, 0.15, size=(self.population_size, self.dim))  # Adjusted turbulence range\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Slightly modified the strategy by adjusting the inertia weight and turbulence range for better exploration.", "configspace": "", "generation": 85, "fitness": 0.09064772882829408, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.091 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.09092296017557144, 0.08962268712438237, 0.09139753918492843], "final_y": [0.164855819455891, 0.16485577198517698, 0.16485577549339092]}, "mutation_prompt": null}
{"id": "c1653d24-6691-4e29-a2b2-845be1ff6d2b", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight *= 0.9  # Minor change: adapt cognitive weight\n            self.social_weight *= 1.1  # Minor change: adapt social weight\n            self.mutation_factor = (0.4 + 0.1 * np.sin(np.pi * generation / 10)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduce learning rates to adapt cognitive and social weights based on progress to enhance convergence.", "configspace": "", "generation": 86, "fitness": 0.05090148343742303, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.051 with standard deviation 0.008. And the mean value of best solutions found was 0.377 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.06184425592673137, 0.044231102324327365, 0.04662909206121035], "final_y": [0.3010112040926859, 0.42382630232919316, 0.4056874084890646]}, "mutation_prompt": null}
{"id": "b3c8e4ee-e31b-41c0-9f93-514a9cfd8c52", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.15 * np.sin(np.pi * generation / 5)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            self.crossover_rate = 0.8 + 0.1 * np.cos(np.pi * generation / 8)  # Enhanced crossover adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Enhanced dynamic adjustment of mutation factor and crossover rate to boost performance.", "configspace": "", "generation": 87, "fitness": 0.09125514048899082, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.091 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "8586c740-816a-42f0-9dae-2b3b6dc83b53", "metadata": {"aucs": [0.0909769032877259, 0.09151783268796077, 0.09127068549128581], "final_y": [0.1648557719480359, 0.16485581446547826, 0.1648557719518935]}, "mutation_prompt": null}
{"id": "2f3921b1-db94-4250-8e51-3acd18e819af", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i]) + np.random.normal(0, 0.01, self.dim)  # Added noise\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.15 * np.sin(np.pi * generation / 5)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            self.crossover_rate = 0.8 + 0.1 * np.cos(np.pi * generation / 8)  # Enhanced crossover adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Added noise to the cognitive component to allow exploration in personal best update.", "configspace": "", "generation": 88, "fitness": 0.09147968316837347, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.091 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "b3c8e4ee-e31b-41c0-9f93-514a9cfd8c52", "metadata": {"aucs": [0.0925497535005334, 0.09127964252106413, 0.0906096534835229], "final_y": [0.16485579973641673, 0.16485585487425847, 0.16485579444606469]}, "mutation_prompt": null}
{"id": "2f058df4-6a0a-4ae1-94ab-6ef757db24ac", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i]) + np.random.normal(0, 0.01, self.dim)  # Added noise\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.15 * np.sin(np.pi * generation / 5)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            self.crossover_rate = 0.8 + 0.1 * np.cos(np.pi * generation / 8)  # Enhanced crossover adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Added noise to the cognitive component to allow exploration in personal best update.", "configspace": "", "generation": 89, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "2f3921b1-db94-4250-8e51-3acd18e819af", "metadata": {"aucs": [0.0925497535005334, 0.09127964252106413, 0.0906096534835229], "final_y": [0.16485579973641673, 0.16485585487425847, 0.16485579444606469]}, "mutation_prompt": null}
{"id": "4ea79f5c-c544-44c0-a8b9-16991893c623", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (5 * eval_count / self.budget)))  # Adjusted scaling\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n            \n            elite_index = np.argmin(self.personal_best_scores)  # Identify elite\n            elite_particle = self.personal_best_positions[elite_index]  # Preserve elite\n\n            for i in range(self.population_size):\n                if i == elite_index:  # Skip elite in regular update\n                    continue\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                if i == elite_index:  # Skip elite in regular update\n                    continue\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i]) + np.random.normal(0, 0.01, self.dim)\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.15 * np.sin(np.pi * generation / 5)) * (1 + 0.15 * self.stagnation_count)\n            self.crossover_rate = 0.8 + 0.1 * np.cos(np.pi * generation / 8)\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Enhanced evolutionary strategy with adaptive diversity control and elite preservation for improved convergence.", "configspace": "", "generation": 90, "fitness": 0.09140102401279578, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.091 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "2f3921b1-db94-4250-8e51-3acd18e819af", "metadata": {"aucs": [0.09077495023577575, 0.09113565010535662, 0.09229247169725496], "final_y": [0.16485579127748307, 0.16485583587874464, 0.1648557757841672]}, "mutation_prompt": null}
{"id": "8ee99acd-2f88-4bb9-8e1f-380edcdb46aa", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i]) + np.random.normal(0, 0.01, self.dim)  # Added noise\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.8 * (eval_count / self.budget)  # Adjusted social weight dependency\n            self.mutation_factor = (0.4 + 0.15 * np.sin(np.pi * generation / 5)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            self.crossover_rate = 0.8 + 0.1 * np.cos(np.pi * generation / 8)  # Enhanced crossover adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Adjusted the social weight to depend more on the evaluation count for improved exploration.", "configspace": "", "generation": 91, "fitness": 0.08946602051702028, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.089 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "2f3921b1-db94-4250-8e51-3acd18e819af", "metadata": {"aucs": [0.09052811249671544, 0.09224390639301205, 0.08562604266133333], "final_y": [0.16485578614571728, 0.1648557825138126, 0.16529594617588506]}, "mutation_prompt": null}
{"id": "ce5e2066-eeaf-44aa-96d3-944a75ea8bd3", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.65  # Slightly increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i]) + np.random.normal(0, 0.01, self.dim)  # Added noise\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.5 * np.sin(np.pi * eval_count / self.budget)  # Adaptive weight oscillation\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.15 * np.sin(np.pi * generation / 5)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            self.crossover_rate = 0.8 + 0.1 * np.cos(np.pi * generation / 8)  # Enhanced crossover adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduced adaptive inertia weight oscillation and slightly increased the mutation factor for improved exploration.", "configspace": "", "generation": 92, "fitness": 0.08939509234294814, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.089 with standard deviation 0.003. And the mean value of best solutions found was 0.171 (0. is the best).", "error": "", "parent_id": "2f3921b1-db94-4250-8e51-3acd18e819af", "metadata": {"aucs": [0.0915740821559502, 0.08500869431588165, 0.09160250055701258], "final_y": [0.1648557790977231, 0.1818781049348822, 0.16485579004717588]}, "mutation_prompt": null}
{"id": "3b64588e-ae5a-4108-8502-2e2d1014a65e", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i]) + np.random.normal(0, 0.01, self.dim)\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.15 * np.sin(np.pi * generation / 5)) * (1 + 0.15 * self.stagnation_count)\n            self.crossover_rate = 0.8 + 0.1 * np.cos(np.pi * generation / 8)\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                random_stochastic = np.random.normal(0, 0.1, size=(self.population_size, self.dim))  # Added stochastic component\n                self.particles += (turbulence + random_stochastic) * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Implemented an additional stochastic component to enhance diversity upon stagnation.", "configspace": "", "generation": 93, "fitness": 0.09089919334874012, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.091 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "2f3921b1-db94-4250-8e51-3acd18e819af", "metadata": {"aucs": [0.09108135600971623, 0.0909984880615442, 0.09061773597495992], "final_y": [0.16485578791251432, 0.16485578533139122, 0.1648557850600858]}, "mutation_prompt": null}
{"id": "bd56e43e-60cc-40d9-81ae-dc37507f4e00", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i]) + np.random.normal(0, 0.012, self.dim)  # Added noise\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.15 * np.sin(np.pi * generation / 5)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            self.crossover_rate = 0.8 + 0.1 * np.cos(np.pi * generation / 8)  # Enhanced crossover adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Slightly increased noise in the cognitive component to enhance exploration capabilities.", "configspace": "", "generation": 94, "fitness": 0.0917030930271479, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.092 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "2f3921b1-db94-4250-8e51-3acd18e819af", "metadata": {"aucs": [0.09270636623028217, 0.09118679327935775, 0.09121611957180376], "final_y": [0.16485579850428378, 0.16485577639732774, 0.16485578319668892]}, "mutation_prompt": null}
{"id": "1ed05eb7-d47f-4227-ba5a-c0998a4cf559", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i]) + np.random.normal(0, 0.012, self.dim)\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget): \n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget) + 0.01 * np.random.uniform(-0.1, 0.1)  # Added perturbation\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.15 * np.sin(np.pi * generation / 5)) * (1 + 0.15 * self.stagnation_count)\n            self.crossover_rate = 0.8 + 0.1 * np.cos(np.pi * generation / 8)\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introducing a small random perturbation to the inertia weight to enhance exploration.", "configspace": "", "generation": 95, "fitness": 0.08910173773356733, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.089 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "bd56e43e-60cc-40d9-81ae-dc37507f4e00", "metadata": {"aucs": [0.09031873342388042, 0.09165963049517378, 0.0853268492816478], "final_y": [0.16485579921541726, 0.16485580332079697, 0.16486311178547908]}, "mutation_prompt": null}
{"id": "2137bd66-37b7-4d0f-a813-9b243b28ebbf", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i]) + np.random.normal(0, 0.012, self.dim)\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.15 * np.sin(np.pi * generation / 5)) * (1 + 0.15 * self.stagnation_count)\n            self.crossover_rate = 0.8 + 0.1 * np.cos(np.pi * generation / 8)\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb) * (1 + 0.5 * self.stagnation_count)  # Increased turbulence during stagnation\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Further enhances exploration by dynamically increasing noise during stagnation.", "configspace": "", "generation": 96, "fitness": 0.0917030930271479, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.092 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "bd56e43e-60cc-40d9-81ae-dc37507f4e00", "metadata": {"aucs": [0.09270636623028217, 0.09118679327935775, 0.09121611957180376], "final_y": [0.16485579850428378, 0.16485577639732774, 0.16485578319668892]}, "mutation_prompt": null}
{"id": "e351d706-814a-44ce-b8ef-b4a0f986e8f6", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i]) + np.random.normal(0, 0.012 * (1 - eval_count / self.budget), self.dim)  # Adjusted noise\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.15 * np.sin(np.pi * generation / 5)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            self.crossover_rate = 0.8 + 0.1 * np.cos(np.pi * generation / 8)  # Enhanced crossover adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Improved convergence by adjusting cognitive component noise dynamically based on generation count.", "configspace": "", "generation": 97, "fitness": 0.075253501638385, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.075 with standard deviation 0.012. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "bd56e43e-60cc-40d9-81ae-dc37507f4e00", "metadata": {"aucs": [0.09083874343558784, 0.07198108219435839, 0.06294067928520874], "final_y": [0.16485578038318383, 0.16485577513792316, 0.16485577216577196]}, "mutation_prompt": null}
{"id": "202b42da-7535-4b89-b31c-e7a88575932c", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i]) + np.random.normal(0, 0.02, self.dim)  # Adjusted noise\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * (0.9 + 0.1 * np.random.rand())  # Smoothed inertia\n                self.particles[i] += self.velocities[i]\n\n                if np.random.rand() < self.crossover_rate:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n\n            self.inertia_weight = 0.5 + 0.5 * (1 - eval_count / self.budget)  # Adaptive inertia adjustment\n            self.mutation_factor = (0.4 + 0.15 * np.sin(np.pi * generation / 5))  # Simplified dynamic adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Enhanced PSO with adaptive inertia and cognitive strategies to improve convergence speed and accuracy.", "configspace": "", "generation": 98, "fitness": 0.05070405289578861, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.051 with standard deviation 0.004. And the mean value of best solutions found was 0.226 (0. is the best).", "error": "", "parent_id": "bd56e43e-60cc-40d9-81ae-dc37507f4e00", "metadata": {"aucs": [0.04465232909099559, 0.05231442478090831, 0.05514540481546193], "final_y": [0.2634327381904492, 0.19565643273480537, 0.21785554108351346]}, "mutation_prompt": null}
{"id": "9016dfd5-c682-40ca-b2c0-927d18c74d40", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.particles = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 2.0\n        self.mutation_factor = 0.6  # Increased mutation factor\n        self.crossover_rate = 0.9\n        self.stagnation_count = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        eval_count = 0\n        generation = 0\n        \n        while eval_count < self.budget:\n            if generation % 5 == 0:\n                self.population_size = max(10, int(20 - (10 * eval_count / self.budget)))\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.personal_best_positions = self.personal_best_positions[:self.population_size]\n                self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n            prev_best_score = self.global_best_score\n\n            for i in range(self.population_size):\n                score = func(np.clip(self.particles[i], lb, ub))\n                eval_count += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                    \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            if eval_count >= self.budget:\n                break\n\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.cognitive_weight * r1 * (self.personal_best_positions[i] - self.particles[i]) + np.random.normal(0, 0.012, self.dim)  # Added noise\n                social_component = self.social_weight * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_component + social_component) * np.random.rand()\n                self.particles[i] += self.velocities[i]\n                \n                if np.random.rand() < self.crossover_rate * (1 - eval_count / self.budget):  # Dynamic adjustment\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.mutation_factor * (b - c) + self.mutation_factor * (np.random.rand(self.dim) - 0.5), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, self.particles[i])\n                    trial_score = func(trial)\n                    eval_count += 1\n                    if trial_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = trial_score\n                        self.personal_best_positions[i] = trial\n                        if trial_score < self.global_best_score:\n                            self.global_best_score = trial_score\n                            self.global_best_position = trial\n            \n            self.inertia_weight = 0.4 + 0.6 * (1 - eval_count / self.budget)\n            self.cognitive_weight = 1.6 + 1.4 * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * generation / self.budget))\n            self.social_weight = 1.4 + 1.6 * (eval_count / self.budget)\n            self.mutation_factor = (0.4 + 0.15 * np.sin(np.pi * generation / 5)) * (1 + 0.15 * self.stagnation_count)  # Modified mutation dynamic adjustment\n            self.crossover_rate = 0.8 + 0.1 * np.cos(np.pi * generation / 8)  # Enhanced crossover adjustment\n            \n            if self.global_best_score == prev_best_score:\n                self.stagnation_count += 1\n            else:\n                self.stagnation_count = 0\n            \n            if self.stagnation_count > 8:  # Adjusted stagnation threshold\n                turbulence = np.random.uniform(-0.1, 0.1, size=(self.population_size, self.dim))\n                self.particles += turbulence * (ub - lb)\n                self.velocities += turbulence * 0.1  # Added turbulence to velocities\n                if np.mean(self.personal_best_scores) - self.global_best_score < 1e-6:\n                    self.particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n                self.stagnation_count = 0\n            \n            generation += 1\n            \n            if eval_count >= self.budget:\n                break\n\n        return self.global_best_position, self.global_best_score", "name": "EnhancedHybridPSO_DE", "description": "Introduced slight turbulence into velocities after stagnation to enhance exploration.", "configspace": "", "generation": 99, "fitness": 0.09171711972880314, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.092 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "bd56e43e-60cc-40d9-81ae-dc37507f4e00", "metadata": {"aucs": [0.0927062871589367, 0.09122896838964822, 0.09121610363782451], "final_y": [0.1648558249621781, 0.16485577930562845, 0.16485579141865114]}, "mutation_prompt": null}

{"id": "e4155181-0a58-4fc7-a8a9-265921fcdcaa", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.7\n        self.f_scale = 0.8\n        self.temperature = 1.0\n        self.cooling_rate = 0.95\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.f_scale * (b - c), lb, ub)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "name": "HybridDE_SA", "description": "A hybrid Differential Evolution and Simulated Annealing algorithm that combines population-based global search with local temperature-based refinement for robust optimization.", "configspace": "", "generation": 0, "fitness": 0.2791565694119104, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.279 with standard deviation 0.017. And the mean value of best solutions found was 0.008 (0. is the best).", "error": "", "parent_id": null, "metadata": {"aucs": [0.269562809739489, 0.26534978998863035, 0.30255710850761197], "final_y": [0.0036982952137224246, 0.017553029819915897, 0.0015565090966129774]}, "mutation_prompt": null}
{"id": "baf993cc-57f7-4390-8538-a740012ff302", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9  # Changed from 0.7 to 0.9\n        self.f_scale = 0.8\n        self.temperature = 1.0\n        self.cooling_rate = 0.95\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.f_scale * (b - c), lb, ub)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "name": "HybridDE_SA", "description": "A refined Hybrid Differential Evolution and Simulated Annealing algorithm with enhanced exploration-exploitation balance for improved optimization.", "configspace": "", "generation": 1, "fitness": 0.28507932459878393, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.285 with standard deviation 0.023. And the mean value of best solutions found was 0.011 (0. is the best).", "error": "", "parent_id": "e4155181-0a58-4fc7-a8a9-265921fcdcaa", "metadata": {"aucs": [0.2703261628145631, 0.31803481549634927, 0.2668769954854394], "final_y": [0.015057402899141783, 0.009715123793109902, 0.008487490137859143]}, "mutation_prompt": null}
{"id": "1fb8314d-34a2-45d2-8d33-e8e21aec1a98", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9  # Changed from 0.7 to 0.9\n        self.f_scale = 0.8\n        self.temperature = 1.0\n        self.cooling_rate = 0.98  # Changed from 0.95 to 0.98\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.f_scale * (b - c), lb, ub)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "name": "HybridDE_SA", "description": "Improved Hybrid Differential Evolution and Simulated Annealing algorithm by increasing the cooling rate for faster convergence.", "configspace": "", "generation": 2, "fitness": 0.2669510124992553, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.267 with standard deviation 0.007. And the mean value of best solutions found was 0.028 (0. is the best).", "error": "", "parent_id": "baf993cc-57f7-4390-8538-a740012ff302", "metadata": {"aucs": [0.2675569720170239, 0.2575518597929084, 0.27574420568783364], "final_y": [0.026972953583062648, 0.02952995459521007, 0.0281069528817489]}, "mutation_prompt": null}
{"id": "ee00dea6-982d-4fa0-aeaa-aca0b8850d8b", "solution": "import numpy as np\n\nclass QuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.inertia_weight = 0.9\n        self.cognitive_param = 2.0\n        self.social_param = 2.0\n        self.quantum_param = 0.5\n        self.inertia_min = 0.4\n        self.inertia_max = 0.9\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best)\n        global_best_idx = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_idx]\n        global_best_fitness = personal_best_fitness[global_best_idx]\n        \n        eval_count = self.swarm_size\n\n        while eval_count < self.budget:\n            for i in range(self.swarm_size):\n                if eval_count >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (\n                    self.inertia_weight * velocities[i] +\n                    self.cognitive_param * r1 * (personal_best[i] - swarm[i]) +\n                    self.social_param * r2 * (global_best - swarm[i])\n                )\n                quantum_walk = self.quantum_param * np.random.uniform(lb, ub, self.dim)\n                swarm[i] = np.where(np.random.rand(self.dim) < 0.5, swarm[i] + velocities[i], quantum_walk)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                current_fitness = func(swarm[i])\n                eval_count += 1\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < global_best_fitness:\n                        global_best = swarm[i]\n                        global_best_fitness = current_fitness\n\n            # Dynamically adjust inertia weight\n            self.inertia_weight = self.inertia_max - ((self.inertia_max - self.inertia_min) * (eval_count / self.budget))\n\n        return global_best", "name": "QuantumPSO", "description": "A Quantum-inspired Particle Swarm Optimization with Dynamic Inertia Weight focusing on diverse exploration and adaptive convergence for enhanced optimization.", "configspace": "", "generation": 3, "fitness": 0.1131796559955659, "feedback": "The algorithm QuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.005. And the mean value of best solutions found was 2.803 (0. is the best).", "error": "", "parent_id": "baf993cc-57f7-4390-8538-a740012ff302", "metadata": {"aucs": [0.10889126713776609, 0.11103363242462816, 0.11961406842430344], "final_y": [3.4842637815047186, 3.1154831149167546, 1.809675005725203]}, "mutation_prompt": null}
{"id": "495f2ea1-5f57-44e1-9f5f-7bc6e2bd8c92", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9  # Changed from 0.7 to 0.9\n        self.f_scale = 0.8\n        self.temperature = 1.0\n        self.cooling_rate = 0.95\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.f_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)  # Adaptive crossover probability\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhanced HybridDE_SA with adaptive crossover probability for better exploration-exploitation trade-off.", "configspace": "", "generation": 4, "fitness": 0.286466277080299, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.286 with standard deviation 0.009. And the mean value of best solutions found was 0.012 (0. is the best).", "error": "", "parent_id": "baf993cc-57f7-4390-8538-a740012ff302", "metadata": {"aucs": [0.29977314275144307, 0.28035495899982044, 0.2792707294896335], "final_y": [0.017546543723302395, 0.016307186005945575, 0.0026196218430684236]}, "mutation_prompt": null}
{"id": "464cea91-0a90-4f60-8715-36e07659fdb7", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Changed from 10 * dim to 12 * dim\n        self.cross_prob = 0.9\n        self.f_scale = 0.8\n        self.temperature = 1.0\n        self.cooling_rate = 0.95\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.f_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)  # Adaptive crossover probability\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhanced HybridDE_SA with increased population size for improved solution diversity.", "configspace": "", "generation": 5, "fitness": 0.24324584262952578, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.243 with standard deviation 0.016. And the mean value of best solutions found was 0.034 (0. is the best).", "error": "", "parent_id": "495f2ea1-5f57-44e1-9f5f-7bc6e2bd8c92", "metadata": {"aucs": [0.25938599411754715, 0.24803601627544425, 0.22231551749558598], "final_y": [0.012734722994746319, 0.007388107108469674, 0.08070248545275538]}, "mutation_prompt": null}
{"id": "280c3de9-98a6-4a53-b496-81e5e7944cfc", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9  # Changed from 0.7 to 0.9\n        self.f_scale = 0.8\n        self.temperature = 1.0\n        self.cooling_rate = 0.97  # Changed from 0.95 to 0.97\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.f_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)  # Adaptive crossover probability\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "name": "HybridDE_SA", "description": "Refined HybridDE_SA with a slightly increased cooling rate for more gradual temperature reduction.", "configspace": "", "generation": 6, "fitness": 0.28597879495587547, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.286 with standard deviation 0.015. And the mean value of best solutions found was 0.024 (0. is the best).", "error": "", "parent_id": "495f2ea1-5f57-44e1-9f5f-7bc6e2bd8c92", "metadata": {"aucs": [0.2914683023545811, 0.26605114708731303, 0.3004169354257322], "final_y": [0.015046095778139293, 0.04967267564213715, 0.007441270200312825]}, "mutation_prompt": null}
{"id": "97748184-673e-43bc-ba40-ca448bcf2d81", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9  # Changed from 0.7 to 0.9\n        self.f_scale = 0.8\n        self.temperature = 1.0\n        self.cooling_rate = 0.98  # Changed from 0.95 to 0.98\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.f_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)  # Adaptive crossover probability\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "name": "HybridDE_SA", "description": "Fine-tuned the cooling rate to allow for more gradual temperature reduction and improved convergence.", "configspace": "", "generation": 7, "fitness": 0.27622709350477453, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.276 with standard deviation 0.010. And the mean value of best solutions found was 0.024 (0. is the best).", "error": "", "parent_id": "495f2ea1-5f57-44e1-9f5f-7bc6e2bd8c92", "metadata": {"aucs": [0.2703860829601976, 0.26816080918601237, 0.29013438836811367], "final_y": [0.02694386668903743, 0.027871342819002543, 0.017464437596045476]}, "mutation_prompt": null}
{"id": "112b8bd7-bc3e-4745-9d62-4abf0077a5fe", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9  # Changed from 0.7 to 0.9\n        self.f_scale = 0.8\n        self.temperature = 1.0\n        self.cooling_rate = 0.95\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + 0.85 * self.f_scale * (b - c), lb, ub)  # Mutation clipping refined\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)  # Adaptive crossover probability\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "name": "HybridDE_SA", "description": "Refined HybridDE_SA by optimizing mutation clipping for improved convergence efficiency.", "configspace": "", "generation": 8, "fitness": 0.29240210996487803, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.292 with standard deviation 0.012. And the mean value of best solutions found was 0.011 (0. is the best).", "error": "", "parent_id": "495f2ea1-5f57-44e1-9f5f-7bc6e2bd8c92", "metadata": {"aucs": [0.28597744263983926, 0.30979497077119067, 0.28143391648360416], "final_y": [0.01831835470879125, 0.0038668914539979463, 0.010110682032680179]}, "mutation_prompt": null}
{"id": "5a5d2ac2-8b3f-4761-8be3-94717ecea960", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9  # Changed from 0.7 to 0.9\n        self.f_scale = 0.9  # Adjusted the value from 0.8 to 0.9\n        self.temperature = 1.0\n        self.cooling_rate = 0.95\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + 0.85 * self.f_scale * (b - c), lb, ub)  # Mutation clipping refined\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)  # Adaptive crossover probability\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "name": "HybridDE_SA", "description": "Adjusted the f_scale to 0.9 to enhance the exploratory capability of the algorithm.", "configspace": "", "generation": 9, "fitness": 0.27696095049419117, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.277 with standard deviation 0.005. And the mean value of best solutions found was 0.015 (0. is the best).", "error": "", "parent_id": "112b8bd7-bc3e-4745-9d62-4abf0077a5fe", "metadata": {"aucs": [0.2723319768149318, 0.2838085692542698, 0.27474230541337186], "final_y": [0.010191160942321888, 0.016254518774235657, 0.0189301003254183]}, "mutation_prompt": null}
{"id": "517e0804-30a3-4d12-a131-1fced1b08631", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9  # Changed from 0.7 to 0.9\n        self.f_scale = 0.8\n        self.temperature = 1.0\n        self.cooling_rate = 0.90  # Adjusted cooling rate from 0.95 to 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + 0.85 * self.f_scale * (b - c), lb, ub)  # Mutation clipping refined\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)  # Adaptive crossover probability\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhanced HybridDE_SA by adjusting the cooling rate for better exploration-exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.29797472826141724, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.298 with standard deviation 0.010. And the mean value of best solutions found was 0.003 (0. is the best).", "error": "", "parent_id": "112b8bd7-bc3e-4745-9d62-4abf0077a5fe", "metadata": {"aucs": [0.3083394309466616, 0.2842075326953801, 0.30137722114221], "final_y": [0.003609010760754808, 0.004499253634349458, 0.0008099004770642541]}, "mutation_prompt": null}
{"id": "452dc67f-e09c-487a-a6ea-20af577bcb5f", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9  # Changed from 0.7 to 0.9\n        self.f_scale = 0.85  # Changed from 0.8 to 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90  # Adjusted cooling rate from 0.95 to 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + 0.85 * self.f_scale * (b - c), lb, ub)  # Mutation clipping refined\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)  # Adaptive crossover probability\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhanced HybridDE_SA by slightly increasing the mutation factor for better diversity.", "configspace": "", "generation": 11, "fitness": 0.3247685780894312, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.325 with standard deviation 0.007. And the mean value of best solutions found was 0.002 (0. is the best).", "error": "", "parent_id": "517e0804-30a3-4d12-a131-1fced1b08631", "metadata": {"aucs": [0.32898872729044093, 0.3299389152051999, 0.31537809177265275], "final_y": [0.0016108653737721178, 0.0024834993900155374, 0.001121953826526108]}, "mutation_prompt": null}
{"id": "aa1309bf-d396-444a-8656-7222f3253439", "solution": "import numpy as np\n\nclass HybridDE_SA_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9\n        self.initial_f_scale = 0.8\n        self.temperature = 1.0\n        self.cooling_rate = 0.95\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Adaptive mutation factor based on convergence progress\n                f_scale = self.initial_f_scale + 0.2 * (1 - eval_count / self.budget)\n                mutant = np.clip(a + f_scale * (b - c), lb, ub)\n                \n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Dynamic temperature annealing in Simulated Annealing\n                trial_fitness = func(trial)\n                eval_count += 1\n                acceptance_probability = np.exp((fitness[i] - trial_fitness) / self.temperature)\n                if trial_fitness < fitness[i] or np.random.rand() < acceptance_probability:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature more gradually\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "name": "HybridDE_SA_Adaptive", "description": "Introduce adaptive mutation factor and dynamic temperature annealing in Enhanced HybridDE_SA for improved exploration-exploitation balance.", "configspace": "", "generation": 12, "fitness": 0.22128439758688592, "feedback": "The algorithm HybridDE_SA_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.221 with standard deviation 0.050. And the mean value of best solutions found was 0.439 (0. is the best).", "error": "", "parent_id": "452dc67f-e09c-487a-a6ea-20af577bcb5f", "metadata": {"aucs": [0.20400493640638118, 0.28897047721237734, 0.17087777914189928], "final_y": [0.43404844945862986, 0.018918041808335503, 0.8642234067623775]}, "mutation_prompt": null}
{"id": "03bf18b6-5dfd-420f-985b-f135360d98b3", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9  # Changed from 0.7 to 0.9\n        self.f_scale = 0.90  # Changed from 0.85 to 0.90\n        self.temperature = 1.0\n        self.cooling_rate = 0.90  # Adjusted cooling rate from 0.95 to 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + 0.85 * self.f_scale * (b - c), lb, ub)  # Mutation clipping refined\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)  # Adaptive crossover probability\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "name": "HybridDE_SA", "description": "Slightly enhance the mutation factor to improve exploration capability in early stages.", "configspace": "", "generation": 13, "fitness": 0.3131939955079431, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.313 with standard deviation 0.019. And the mean value of best solutions found was 0.002 (0. is the best).", "error": "", "parent_id": "452dc67f-e09c-487a-a6ea-20af577bcb5f", "metadata": {"aucs": [0.3391855242261813, 0.296252728238909, 0.30414373405873896], "final_y": [0.000881471636125524, 0.0036287059346841667, 0.0018716514562918023]}, "mutation_prompt": null}
{"id": "43b3f602-1935-415d-a044-a0a4dee26e9b", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9  # Changed from 0.7 to 0.9\n        self.f_scale = 0.85  # Changed from 0.8 to 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90  # Adjusted cooling rate from 0.95 to 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + 0.85 * self.f_scale * (b - c), lb, ub)  # Mutation clipping refined\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)  # Adaptive crossover probability\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature\n            self.temperature *= self.cooling_rate * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Adjust the cooling rate dynamically based on evaluation progress for an enhanced balance between exploration and exploitation.", "configspace": "", "generation": 14, "fitness": 0.3568323581074999, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.357 with standard deviation 0.006. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "452dc67f-e09c-487a-a6ea-20af577bcb5f", "metadata": {"aucs": [0.3578161790857298, 0.34891531975047474, 0.3637655754862952], "final_y": [0.00024164423774803505, 7.113734910765233e-05, 0.00013905019232828632]}, "mutation_prompt": null}
{"id": "f86bde30-b683-4cc2-9dc0-a1652adb6e4a", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9  # Changed from 0.7 to 0.9\n        self.f_scale = 0.85  # Changed from 0.8 to 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90  # Adjusted cooling rate from 0.95 to 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)  # Adaptive mutation scale\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)  # Mutation clipping refined\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)  # Adaptive crossover probability\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature\n            self.temperature *= self.cooling_rate * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Introduce adaptive mutation scaling to further enhance the balance between exploration and exploitation.", "configspace": "", "generation": 15, "fitness": 0.3935423550901569, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.394 with standard deviation 0.035. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "43b3f602-1935-415d-a044-a0a4dee26e9b", "metadata": {"aucs": [0.3937417049946742, 0.43604132213420477, 0.3508440381415916], "final_y": [1.4912820707884782e-05, 1.8102687253566534e-06, 0.00019693565260801258]}, "mutation_prompt": null}
{"id": "04e7acd7-f5f2-4a7f-a42b-c23f85d51688", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.88  # Adjusted cooling rate from 0.90 to 0.88\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - (eval_count / self.budget) ** 2)  # Further adaptive scaling\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.85 + 0.15 * (1 - eval_count / self.budget)  # Fine-tuned adaptive crossover\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature\n            self.temperature *= self.cooling_rate * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Implement hybrid adaptive differential evolution with simulated annealing for improved convergence.", "configspace": "", "generation": 16, "fitness": 0.3842545791629044, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.384 with standard deviation 0.008. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "f86bde30-b683-4cc2-9dc0-a1652adb6e4a", "metadata": {"aucs": [0.37950555876225245, 0.3959473966520799, 0.37731078207438085], "final_y": [2.0579217638038414e-05, 9.897412012486175e-05, 3.777311598608066e-05]}, "mutation_prompt": null}
{"id": "90a188ba-01ef-4fc3-98e5-885f57361f43", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Changed from 10 * dim to 12 * dim\n        self.cross_prob = 0.9  # Changed from 0.7 to 0.9\n        self.f_scale = 0.85  # Changed from 0.8 to 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90  # Adjusted cooling rate from 0.95 to 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)  # Adaptive mutation scale\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)  # Mutation clipping refined\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)  # Adaptive crossover probability\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature\n            self.temperature *= self.cooling_rate * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Introduce dynamic adjustment to the initial population size for enhanced exploratory capability.", "configspace": "", "generation": 17, "fitness": 0.36645524007756425, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.366 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "f86bde30-b683-4cc2-9dc0-a1652adb6e4a", "metadata": {"aucs": [0.3829609280356646, 0.37455704964688463, 0.3418477425501435], "final_y": [0.0001563343548096567, 0.0001563379517339325, 0.00047588257885752486]}, "mutation_prompt": null}
{"id": "f8e704d9-d5e3-46c7-99d3-1da272fee0be", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n        self.dynamic_population = True  # New attribute to enable dynamic resizing\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * ((1 - eval_count / self.budget) ** 2)  # Enhanced adaptivity\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * ((1 - eval_count / self.budget) ** 2)  # Enhanced adaptivity on crossover\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature\n            self.temperature *= self.cooling_rate * (1 - eval_count / self.budget)\n            \n            # Dynamic population resizing\n            if self.dynamic_population and eval_count > self.budget // 2:\n                self.population_size = max(5 * self.dim, self.population_size // 2)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance adaptive mutation scaling and dynamic population resizing to improve solution quality and diversity.", "configspace": "", "generation": 18, "fitness": 0.37386618778929276, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.374 with standard deviation 0.039. And the mean value of best solutions found was 0.002 (0. is the best).", "error": "", "parent_id": "f86bde30-b683-4cc2-9dc0-a1652adb6e4a", "metadata": {"aucs": [0.320736068231008, 0.41408811142118873, 0.3867743837156814], "final_y": [0.004791229543518538, 0.0001603128306364524, 0.00048165527603063774]}, "mutation_prompt": null}
{"id": "e4174624-622d-45b8-9811-47c561f8b4cd", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.93  # Adjusted cooling rate from 0.90 to 0.93\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature\n            self.temperature *= self.cooling_rate * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance convergence by refining the cooling strategy to maintain a more gradual temperature decrease.", "configspace": "", "generation": 19, "fitness": 0.38410534838042976, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.384 with standard deviation 0.025. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "f86bde30-b683-4cc2-9dc0-a1652adb6e4a", "metadata": {"aucs": [0.3491314805680643, 0.4040088961978344, 0.39917566837539054], "final_y": [0.0006225435712779099, 1.2469915305841132e-05, 2.5437346238647207e-05]}, "mutation_prompt": null}
{"id": "6ba61c7c-450a-4977-ba78-3061de3a095d", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            adaptive_population_size = int(self.population_size * (1 - eval_count / self.budget)) + 1  # Adaptive population size\n            for i in range(adaptive_population_size):  # Adjust loop range\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            self.temperature *= self.cooling_rate * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Introduce adaptive population size adjustment to balance exploration and exploitation throughout the optimization process.", "configspace": "", "generation": 20, "fitness": 0.26257961680360714, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.263 with standard deviation 0.025. And the mean value of best solutions found was 0.013 (0. is the best).", "error": "", "parent_id": "f86bde30-b683-4cc2-9dc0-a1652adb6e4a", "metadata": {"aucs": [0.27660892021365746, 0.2275373940590183, 0.2835925361381456], "final_y": [0.003805775381308608, 0.02601756461928882, 0.009223035381236186]}, "mutation_prompt": null}
{"id": "10d55c65-7038-4108-be3a-9791ba4b26dd", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9  # Changed from 0.7 to 0.9\n        self.f_scale = 0.85  # Changed from 0.8 to 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90  # Adjusted cooling rate from 0.95 to 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)  # Adaptive mutation scale\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)  # Mutation clipping refined\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)  # Adaptive crossover probability\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature\n            self.temperature *= self.cooling_rate * (1 - (eval_count / self.budget)**0.5)  # Dynamic cooling strategy\n\n        return best_solution", "name": "HybridDE_SA", "description": "Introduce a dynamic cooling strategy to improve simulated annealing performance.", "configspace": "", "generation": 21, "fitness": 0.3561005992721495, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.356 with standard deviation 0.021. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "f86bde30-b683-4cc2-9dc0-a1652adb6e4a", "metadata": {"aucs": [0.3368954626987416, 0.3453973638408562, 0.3860089712768505], "final_y": [4.762516443409521e-05, 0.0001317656319262077, 2.4557787872702533e-05]}, "mutation_prompt": null}
{"id": "d62a8223-87b2-4f66-8b44-d675e870b1f1", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9  # Changed from 0.7 to 0.9\n        self.f_scale = 0.85  # Changed from 0.8 to 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90  # Adjusted cooling rate from 0.95 to 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness  # Track previous best fitness for improvement rate\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)  # Adaptive mutation scale\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)  # Mutation clipping refined\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)  # Adaptive crossover probability\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance exploration by adjusting temperature decay based on the current best solution's improvement rate.", "configspace": "", "generation": 22, "fitness": 0.4269745559848237, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.427 with standard deviation 0.025. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "f86bde30-b683-4cc2-9dc0-a1652adb6e4a", "metadata": {"aucs": [0.4159842686981482, 0.46189007027680185, 0.40304932897952106], "final_y": [9.801985081478128e-06, 1.4621578597010332e-07, 1.74636712385967e-05]}, "mutation_prompt": null}
{"id": "afd5c7ca-1ab9-493f-9759-4099ade91e6d", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9  # Changed from 0.7 to 0.9\n        self.f_scale = 0.85  # Changed from 0.8 to 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90  # Adjusted cooling rate from 0.95 to 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness  # Track previous best fitness for improvement rate\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)  # Adaptive mutation scale\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)  # Mutation clipping refined\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)  # Adaptive crossover probability\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)  # Adjustment\n            if improvement_rate < 0.001:  # New adaptive condition\n                self.temperature *= 0.95  # Additional cooling when improvement rate is low\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance local search efficiency by introducing adaptive temperature adjustment based on convergence rate.", "configspace": "", "generation": 23, "fitness": 0.366270206912815, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.366 with standard deviation 0.020. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "d62a8223-87b2-4f66-8b44-d675e870b1f1", "metadata": {"aucs": [0.3901915404771439, 0.3416295332840802, 0.36698954697722097], "final_y": [9.50228218105515e-05, 9.120504346849015e-05, 0.0002500604848425531]}, "mutation_prompt": null}
{"id": "3908bc07-91de-49c3-8986-9452db17959f", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9  # Changed from 0.7 to 0.9\n        self.f_scale = 0.85  # Changed from 0.8 to 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.88  # Adjusted cooling rate from 0.90 to 0.88\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n        stable_count = 0  # Track stability count\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness  # Track previous best fitness for improvement rate\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.85 + 0.15 * (1 - eval_count / self.budget)  # Adaptive crossover probability\n                \n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        stable_count = 0  # Reset stable count on improvement\n                    else:\n                        stable_count += 1  # Increment stable count if no improvement\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n            \n            # Adjust f_scale based on stable count to encourage exploration\n            if stable_count > 5:\n                self.f_scale = min(self.f_scale * 1.1, 0.9)\n        \n        return best_solution", "name": "HybridDE_SA", "description": "Incorporate adaptive mutation probability and cooling rate based on fitness stability to balance exploration and exploitation.", "configspace": "", "generation": 24, "fitness": 0.37160538367683954, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.372 with standard deviation 0.038. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "d62a8223-87b2-4f66-8b44-d675e870b1f1", "metadata": {"aucs": [0.35289147265550946, 0.4239524702095936, 0.3379722081654156], "final_y": [6.34476542225547e-05, 2.244226222009445e-06, 0.0004846421179990461]}, "mutation_prompt": null}
{"id": "1f308b09-2325-4e31-9dcd-0d14acc47e51", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9  # Changed from 0.7 to 0.9\n        self.f_scale = 0.85  # Changed from 0.8 to 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90  # Adjusted cooling rate from 0.95 to 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness  # Track previous best fitness for improvement rate\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                diversity = np.mean(np.std(population, axis=0))  # Calculate diversity within population\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget) * diversity  # Adaptive mutation scale\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)  # Mutation clipping refined\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)  # Adaptive crossover probability\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Refine exploration by incorporating adaptive mutation scales based on diversity within the population.", "configspace": "", "generation": 25, "fitness": 0.1768976328153724, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.177 with standard deviation 0.039. And the mean value of best solutions found was 0.872 (0. is the best).", "error": "", "parent_id": "d62a8223-87b2-4f66-8b44-d675e870b1f1", "metadata": {"aucs": [0.21485493750890616, 0.19212602537056567, 0.12371193556664539], "final_y": [0.04571181969580206, 0.02498124004197889, 2.544938120346907]}, "mutation_prompt": null}
{"id": "e08c4746-5ea3-4f32-8730-56f6158f2b41", "solution": "import numpy as np\n\nclass EnhancedHybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        ranked_indices = np.argsort(fitness)\n        best_idx = ranked_indices[0]\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            rank_weights = np.linspace(1, 0, self.population_size)\n            for i in ranked_indices:\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in ranked_indices if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget) * rank_weights[i]\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                adaptive_cross_prob = self.cross_prob * (1 - eval_count / self.budget) * rank_weights[i]\n                crossover_mask = np.random.rand(self.dim) < adaptive_cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n            ranked_indices = np.argsort(fitness)\n\n        return best_solution", "name": "EnhancedHybridDE_SA", "description": "Integrate a rank-based adaptive cooling schedule and adaptive crossover scale to dynamically balance exploration and exploitation during optimization.", "configspace": "", "generation": 26, "fitness": 0.25462613394557115, "feedback": "The algorithm EnhancedHybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.255 with standard deviation 0.027. And the mean value of best solutions found was 0.049 (0. is the best).", "error": "", "parent_id": "d62a8223-87b2-4f66-8b44-d675e870b1f1", "metadata": {"aucs": [0.24807813251147748, 0.2898959797852476, 0.2259042895399883], "final_y": [0.03873306477280729, 0.01085402553989367, 0.09814032452922401]}, "mutation_prompt": null}
{"id": "228db556-eb55-414d-ba62-6e52b6b49514", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 5 * dim + (budget // 100)  # Adaptive population size\n        self.cross_prob = 0.9\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                dynamic_scale = self.f_scale * (0.5 + 0.5 * (best_fitness / np.min(fitness)))  # Dynamic mutation\n                mutant = np.clip(a + dynamic_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Introduce adaptive population size and dynamic mutation strategy to balance exploration and exploitation for improved convergence.", "configspace": "", "generation": 27, "fitness": 0.25334559784851696, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.253 with standard deviation 0.084. And the mean value of best solutions found was 0.311 (0. is the best).", "error": "", "parent_id": "d62a8223-87b2-4f66-8b44-d675e870b1f1", "metadata": {"aucs": [0.19308277490541303, 0.19462737909149375, 0.3723266395486441], "final_y": [0.4670964181974756, 0.467096418197473, 8.107932304375493e-05]}, "mutation_prompt": null}
{"id": "77395add-32b8-4dbb-9e24-7a037bcb1547", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9  # Changed from 0.7 to 0.9\n        self.f_scale = 0.85  # Changed from 0.8 to 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90  # Adjusted cooling rate from 0.95 to 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness  # Track previous best fitness for improvement rate\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - 0.9 * eval_count / self.budget)  # Slightly increased adaptive mutation scale\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)  # Mutation clipping refined\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)  # Adaptive crossover probability\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Slight increase in adaptive mutation scale for enhanced exploration.", "configspace": "", "generation": 28, "fitness": 0.3854475895628961, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.385 with standard deviation 0.030. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "d62a8223-87b2-4f66-8b44-d675e870b1f1", "metadata": {"aucs": [0.4273302906108395, 0.3582096091218132, 0.37080286895603554], "final_y": [1.455708197049668e-05, 9.862059533643237e-05, 5.566544158510778e-05]}, "mutation_prompt": null}
{"id": "2a947085-5267-4af1-9f8c-9332e754734a", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9  # Changed from 0.7 to 0.9\n        self.f_scale = 0.85  # Changed from 0.8 to 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90  # Adjusted cooling rate from 0.95 to 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness  # Track previous best fitness for improvement rate\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - (eval_count / self.budget) ** 1.2)  # Non-linear scaling added\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)  # Mutation clipping refined\n                self.cross_prob = 0.75 + 0.25 * np.sin(np.pi * eval_count / self.budget)  # Sinusoidal crossover probability\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Refine mutation strategy by introducing non-linear scaling and adjust adaptive crossover probability to enhance exploration and exploitation balance.", "configspace": "", "generation": 29, "fitness": 0.3843994764816329, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.384 with standard deviation 0.016. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "d62a8223-87b2-4f66-8b44-d675e870b1f1", "metadata": {"aucs": [0.3649857146811074, 0.4035120534012422, 0.3847006613625491], "final_y": [0.00013254997451955946, 5.116090049570059e-06, 1.1096306976229948e-05]}, "mutation_prompt": null}
{"id": "f86cffc0-1594-418f-b74f-66641e0568f9", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_pop_size = self.population_size\n        self.cross_prob = 0.9\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            self.population_size = max(5, int(self.initial_pop_size * (1 - eval_count / self.budget)))\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget) * (0.9 + 0.1 * np.random.rand())\n\n        return best_solution", "name": "HybridDE_SA", "description": "Incorporate dynamic population resizing and adaptive cooling to enhance exploration and exploitation balance.", "configspace": "", "generation": 30, "fitness": 0.37201227484488575, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.372 with standard deviation 0.014. And the mean value of best solutions found was 0.001 (0. is the best).", "error": "", "parent_id": "d62a8223-87b2-4f66-8b44-d675e870b1f1", "metadata": {"aucs": [0.366327085014174, 0.35855531117246997, 0.3911544283480133], "final_y": [0.0006691530942438522, 0.0017597650339249973, 0.0009012980851750642]}, "mutation_prompt": null}
{"id": "83bbc8df-cb7c-4a4c-ad9e-139e9911473f", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9  # Changed from 0.7 to 0.9\n        self.f_scale = 0.85  # Changed from 0.8 to 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90  # Adjusted cooling rate from 0.95 to 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness  # Track previous best fitness for improvement rate\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)  # Adaptive mutation scale\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)  # Mutation clipping refined\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)  # Adaptive crossover probability\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.08 * improvement_rate) * (1 - eval_count / self.budget)  # Changed from 0.05 to 0.08\n\n        return best_solution", "name": "HybridDE_SA", "description": "Introduce adaptive scaling for the temperature based on the improvement rate to dynamically control the exploration-exploitation balance.", "configspace": "", "generation": 31, "fitness": 0.3782713253647773, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.378 with standard deviation 0.023. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "d62a8223-87b2-4f66-8b44-d675e870b1f1", "metadata": {"aucs": [0.38810497432217084, 0.3459841043378783, 0.40072489743428286], "final_y": [1.3845184801194804e-05, 0.0005442244416663565, 4.348776184235859e-06]}, "mutation_prompt": null}
{"id": "1325a4a2-a400-4483-88b9-a51fa4f36a3e", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.9\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n        self.learning_rate = 0.01  # New parameter for learning rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness  # Track previous best fitness for improvement rate\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Cooling the temperature\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n            # Adjust learning rate based on improvement\n            self.learning_rate *= 1.0 + improvement_rate\n\n        return best_solution", "name": "HybridDE_SA", "description": "Integrate adaptive learning rate adjustment to balance exploration and exploitation.", "configspace": "", "generation": 32, "fitness": 0.404936115442013, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.405 with standard deviation 0.040. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "d62a8223-87b2-4f66-8b44-d675e870b1f1", "metadata": {"aucs": [0.403289099219894, 0.4549555838892343, 0.3565636632169109], "final_y": [3.29892819846019e-05, 2.77145302157981e-06, 1.5666584478835958e-05]}, "mutation_prompt": null}
{"id": "9ea2739f-0ed8-436a-9d65-c16468bbe8c5", "solution": "import numpy as np\n\nclass EnhancedHybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_cross_prob = 0.8\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n        dynamic_cooling_rate = self.cooling_rate\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n\n                # Self-adaptive crossover probability\n                cross_prob = self.initial_cross_prob + 0.2 * abs(np.random.normal(0, 1)) * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Simulated Annealing acceptance criterion\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Dynamic cooling based on improvement\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            dynamic_cooling_rate = self.cooling_rate + 0.05 * improvement_rate\n            self.temperature *= dynamic_cooling_rate * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "EnhancedHybridDE_SA", "description": "Integrate adaptive mutation scaling with self-adaptive crossover probability to dynamically balance exploration and exploitation.", "configspace": "", "generation": 33, "fitness": 0.3755842036744526, "feedback": "The algorithm EnhancedHybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.376 with standard deviation 0.037. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "d62a8223-87b2-4f66-8b44-d675e870b1f1", "metadata": {"aucs": [0.4264292267767449, 0.33727816194948, 0.363045222297133], "final_y": [1.0998167036483851e-05, 0.0002204288559101363, 0.00079998547447365]}, "mutation_prompt": null}
{"id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Improve exploitation by slightly increasing the crossover probability, enhancing the exploration-exploitation balance.", "configspace": "", "generation": 34, "fitness": 0.47326624265543754, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.473 with standard deviation 0.004. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "d62a8223-87b2-4f66-8b44-d675e870b1f1", "metadata": {"aucs": [0.4780669959868844, 0.47276340058932487, 0.4689683313901033], "final_y": [3.735959320562518e-06, 1.8587225945493154e-06, 1.1595343440227362e-06]}, "mutation_prompt": null}
{"id": "9c3b0be1-e718-4edb-8bd4-2dd7a64d485e", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.9  # Changed from 0.85 to 0.9\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Further enhance exploration by increasing the initial mutation factor, allowing more significant diversity in early iterations.", "configspace": "", "generation": 35, "fitness": 0.3725443332043932, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.373 with standard deviation 0.044. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.4136904520564758, 0.3117653292797511, 0.3921772182769526], "final_y": [1.7851729276466027e-06, 0.00040589451724901555, 8.421549655177242e-05]}, "mutation_prompt": null}
{"id": "0a58ae25-d898-494f-a725-746fb87bede7", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - (0.5 * eval_count) / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n            \n            # Dynamic population resizing\n            if eval_count / self.budget > 0.5:\n                population_size = int(self.initial_population_size * (1 - 0.5 * eval_count / self.budget))\n                population = population[:population_size]\n                fitness = fitness[:population_size]\n\n        return best_solution", "name": "HybridDE_SA", "description": "Introduce adaptive mutation scaling and dynamic population resizing to enhance exploration and exploitation balance in HybridDE_SA.", "configspace": "", "generation": 36, "fitness": 0.3967800057718815, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.397 with standard deviation 0.014. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.4028190786815151, 0.37680410516852914, 0.4107168334656003], "final_y": [9.275848170176751e-07, 2.5658330694564316e-07, 4.8766144735035254e-08]}, "mutation_prompt": null}
{"id": "c4d43198-395a-4461-a809-ff7253b53f15", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.92  # Changed from 0.90 to 0.92\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Refine the simulated annealing component by slightly increasing the cooling rate, enhancing convergence speed.", "configspace": "", "generation": 37, "fitness": 0.3889160966055832, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.389 with standard deviation 0.021. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.36165408524783416, 0.41410833337528064, 0.3909858711936348], "final_y": [2.7154227143743045e-05, 9.278407353317265e-06, 7.913224071873618e-06]}, "mutation_prompt": null}
{"id": "7b9732bb-a757-4b52-a818-65f8db01e3a5", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                rotation_matrix = np.random.normal(size=(self.dim, self.dim))  # Added line\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c).dot(rotation_matrix), lb, ub)  # Modified line\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance exploration by introducing a rotation matrix to the mutation step, increasing diversity in the search space.", "configspace": "", "generation": 38, "fitness": 0.2099799215277004, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.210 with standard deviation 0.041. And the mean value of best solutions found was 0.398 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.26818696722803304, 0.18562355403067488, 0.17612924332439328], "final_y": [0.044318577766896974, 0.49343416632144277, 0.6549567637577707]}, "mutation_prompt": null}
{"id": "0ccd7d26-4052-4b14-a4c6-114db29814ad", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.1 * improvement_rate) * (1 - eval_count / self.budget)  # Adjusted cooling rate dynamically\n\n        return best_solution", "name": "HybridDE_SA", "description": "Slightly adjust the cooling rate dynamically based on the improvement rate for enhanced convergence.", "configspace": "", "generation": 39, "fitness": 0.400136988703224, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.400 with standard deviation 0.032. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.39915891063502074, 0.3616322993278279, 0.43961975614682347], "final_y": [1.7819112727085414e-05, 4.145122684319419e-05, 1.0443769678233618e-05]}, "mutation_prompt": null}
{"id": "be95b455-edc6-45be-a51e-1c653065c357", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * np.exp(-eval_count / self.budget)  # Changed calculation\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance exploration by optimizing adaptive scale factor calculation for better performance across varied function landscapes.", "configspace": "", "generation": 40, "fitness": 0.43806253367151077, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.438 with standard deviation 0.016. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.41568102859004497, 0.44416426478569615, 0.45434230763879124], "final_y": [4.177259017872185e-06, 7.199805584135649e-07, 7.793862711155559e-07]}, "mutation_prompt": null}
{"id": "393a7d97-7324-4073-aa09-be8965713d4f", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.92  # Changed from 0.90 to 0.92\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Fine-tune the cooling rate to dynamically adapt based on improvement, enhancing convergence speed.", "configspace": "", "generation": 41, "fitness": 0.3934111277255857, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.393 with standard deviation 0.017. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.37286408839096097, 0.41386508418382195, 0.39350421060197416], "final_y": [5.244816630700026e-05, 9.370625495209969e-06, 6.499695624332397e-05]}, "mutation_prompt": null}
{"id": "4b4f19aa-5378-49e2-831b-399d49f48bc0", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - (eval_count / self.budget) ** 2) # Altered line\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.85 + 0.15 * (1 - eval_count / self.budget) # Altered line\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance exploration by slightly adapting the scale factor and crossover probability dynamically.", "configspace": "", "generation": 42, "fitness": 0.37443026225858017, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.374 with standard deviation 0.021. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.404070380021758, 0.36005125490584644, 0.3591691518481359], "final_y": [4.302730549154417e-06, 0.00010962390708879258, 2.92281429019361e-06]}, "mutation_prompt": null}
{"id": "0db83c85-df5a-4051-b374-e0a2a604f73d", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget) * (0.6 + 0.4 * eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Improve balance by dynamically adjusting both crossover probability and scale factor in response to budget usage.", "configspace": "", "generation": 43, "fitness": 0.4333450283493021, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.433 with standard deviation 0.025. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.4054271210989362, 0.46692650107751377, 0.4276814628714565], "final_y": [1.834915416504082e-05, 7.802918413875049e-06, 1.5822341155364571e-06]}, "mutation_prompt": null}
{"id": "e8b9306c-b68a-4deb-88fc-8251f11d73e2", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * np.exp(-0.5 * eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Fine-tune the adaptive scale factor for enhanced convergence in later iterations.", "configspace": "", "generation": 44, "fitness": 0.33926694345222347, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.339 with standard deviation 0.032. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.38393381599957876, 0.3106103454400375, 0.3232566689170542], "final_y": [3.69865388156018e-05, 6.38946770193804e-05, 0.0005122463142754915]}, "mutation_prompt": null}
{"id": "583b953a-91f9-4eb1-92f8-ba21b540362e", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Changed from 10 * dim to 12 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Increase the population size to improve diversity and solution quality.", "configspace": "", "generation": 45, "fitness": 0.33969102363873666, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.340 with standard deviation 0.015. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.36035098563045864, 0.3237289564836221, 0.33499312880212917], "final_y": [1.6683059611898482e-05, 0.0001752808156517758, 0.00029701378848343094]}, "mutation_prompt": null}
{"id": "33278e08-7430-43f6-81db-446a124ac155", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c + np.random.uniform(lb, ub, self.dim)), lb, ub)  # Modified line\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance exploration by adjusting the mutation strategy to introduce more diversity.", "configspace": "", "generation": 46, "fitness": 0.12117219286415452, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.121 with standard deviation 0.003. And the mean value of best solutions found was 1.277 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.11740451472392543, 0.12458762904909282, 0.1215244348194453], "final_y": [1.0555635181488883, 1.4157867122132841, 1.3602009652731402]}, "mutation_prompt": null}
{"id": "8c1b1f38-19bc-4738-b765-1aef8cc6b7f7", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * np.random.uniform(0.5, 1.5) * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n            \n            # Dynamic population resizing\n            if eval_count < self.budget * 0.5:  # Only adjust size in early stages\n                self.population_size = max(4 * self.dim, int(10 * self.dim * (1 - eval_count / self.budget)))\n                population = np.resize(population, (self.population_size, self.dim))\n                fitness = np.resize(fitness, self.population_size)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Introduce adaptive mutation scaling and dynamic population resizing to enhance exploration and convergence speed.", "configspace": "", "generation": 47, "fitness": 0.44435014977873477, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.444 with standard deviation 0.021. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.4723080408298239, 0.43842252886854594, 0.42231987963783435], "final_y": [5.686458350567456e-06, 2.3007005334175652e-05, 0.00020712131750957467]}, "mutation_prompt": null}
{"id": "485b12dc-6219-415a-9a58-ddffbe9ac1cf", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.93  # Changed from 0.90 to 0.93\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * np.random.uniform(0.5, 1.5) * (1 - eval_count / self.budget)  # Added randomness to scale\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.07 * improvement_rate) * (1 - eval_count / self.budget)  # Modified cooling\n\n        return best_solution", "name": "HybridDE_SA", "description": "Introduce a dynamic mutation scale and adaptive cooling schedule to improve exploration-exploitation balance.", "configspace": "", "generation": 48, "fitness": 0.35819149729144045, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.358 with standard deviation 0.049. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.4197148947399869, 0.35577964732966083, 0.2990799498046737], "final_y": [8.424957344967865e-06, 3.718582471744082e-05, 0.0008989894151512201]}, "mutation_prompt": null}
{"id": "fc75a428-4744-4a8c-902d-358cddee3471", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.80  # Changed from 0.85 to 0.80\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance exploration by slightly decreasing the adaptive scale factor to balance global and local search.", "configspace": "", "generation": 49, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'mutant' is not defined\").", "error": "NameError(\"name 'mutant' is not defined\")", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {}, "mutation_prompt": null}
{"id": "b1f5100e-3aa9-4318-a7ac-6cc78e671630", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 + np.sin(np.pi * eval_count / self.budget))  # Adjusted line\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance exploration by dynamically adjusting the mutation factor, improving the diversity of candidate solutions.", "configspace": "", "generation": 50, "fitness": 0.20497750704451786, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.205 with standard deviation 0.004. And the mean value of best solutions found was 0.047 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.19916448104559348, 0.20920978510677224, 0.20655825498118785], "final_y": [0.020464646656976365, 0.05547710077243098, 0.06509034139402091]}, "mutation_prompt": null}
{"id": "4fa3efc7-78cd-41d5-83f0-9c0a59aeea30", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.f_scale = 0.85 + 0.15 * (1 - eval_count / self.budget)  # Dynamic scaling\n                mutant = np.clip(a + self.f_scale * (b - c), lb, ub)\n                self.cross_prob = 0.85 + 0.15 * (1 - eval_count / self.budget)  # Dynamic crossover\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance adaptability by dynamically adjusting the scaling factor and crossover probability, improving solution quality.", "configspace": "", "generation": 51, "fitness": 0.28924990792157074, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.289 with standard deviation 0.021. And the mean value of best solutions found was 0.005 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.303117687366365, 0.30469900024506036, 0.2599330361532868], "final_y": [0.0005268207104665695, 0.001293303048535014, 0.014361008593777503]}, "mutation_prompt": null}
{"id": "182b906d-955d-40cb-a6e2-31e765e2628b", "solution": "import numpy as np\n\nclass PSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 * dim\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n        self.temperature = 1.0\n        self.cooling_rate = 0.98\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_fitness = np.apply_along_axis(func, 1, personal_best_positions)\n        global_best_idx = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_fitness = personal_best_fitness[global_best_idx]\n\n        eval_count = self.swarm_size\n\n        while eval_count < self.budget:\n            for i in range(self.swarm_size):\n                if eval_count >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_const * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_const * r2 * (global_best_position - positions[i]))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                fitness = func(positions[i])\n                eval_count += 1\n\n                if fitness < personal_best_fitness[i] or np.random.rand() < np.exp((personal_best_fitness[i] - fitness) / self.temperature):\n                    personal_best_positions[i] = positions[i]\n                    personal_best_fitness[i] = fitness\n\n                    if fitness < global_best_fitness:\n                        global_best_position = positions[i]\n                        global_best_fitness = fitness\n\n            self.temperature *= self.cooling_rate\n\n        return global_best_position", "name": "PSO_SA", "description": "A hybrid algorithm combining Particle Swarm Optimization with Simulated Annealing for adaptive exploration and exploitation balance.", "configspace": "", "generation": 52, "fitness": 0.2158746578905297, "feedback": "The algorithm PSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.216 with standard deviation 0.036. And the mean value of best solutions found was 0.328 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.2452701976521271, 0.23664472352376587, 0.16570905249569612], "final_y": [0.05166243637743719, 0.014606629890007878, 0.9166961593892505]}, "mutation_prompt": null}
{"id": "f5623ccf-2c94-4d5a-9609-5a0eb8466f19", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.95  # Changed from 0.90 to 0.95\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                d = population[np.random.choice(indices, 1, replace=False)][0]  # Added additional solution for more diversity\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c + d - a), lb, ub)  # Modified mutation strategy\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance mutation diversity and adjust cooling rate for adaptive exploration-exploitation.", "configspace": "", "generation": 53, "fitness": 0.4284687838954467, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.428 with standard deviation 0.045. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.49252021370039045, 0.39233575139866117, 0.40055038658728837], "final_y": [1.8234606991262972e-07, 0.00015851797526538917, 6.365315792386652e-05]}, "mutation_prompt": null}
{"id": "41dca10c-0d9c-41c4-ac88-8b36dcabe6e7", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget) * np.random.uniform(0.5, 1.0)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Fine-tune exploration by dynamically adjusting the mutation factor, enhancing adaptability over evaluations.", "configspace": "", "generation": 54, "fitness": 0.4372368858855296, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.437 with standard deviation 0.015. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.4548932786528901, 0.41899670455729265, 0.43782067444640616], "final_y": [2.543225941338226e-06, 1.4000823453970955e-05, 1.1871031073489932e-05]}, "mutation_prompt": null}
{"id": "0f062f41-b936-4ca2-af9a-ea9855444a88", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget) * np.random.rand()  # Adaptive mutation scale\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n            if improvement_rate < 0.01 and eval_count < self.budget / 2:  # Dynamic population resizing\n                self.population_size = max(4 * self.dim, self.population_size // 2)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return best_solution", "name": "HybridDE_SA", "description": "Introduce adaptive mutation scale and dynamic population resizing to enhance convergence speed and solution quality.", "configspace": "", "generation": 55, "fitness": 0.1870774409249573, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.187 with standard deviation 0.025. And the mean value of best solutions found was 0.687 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.17233617796609113, 0.2218939432656678, 0.16700220154311296], "final_y": [0.8786453950409027, 0.2582828540264819, 0.9232306028614236]}, "mutation_prompt": null}
{"id": "4e9f6494-ab31-4622-8cdf-394255800e2d", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.92  # Changed from 0.90 to 0.92\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Increase the cooling rate slightly to enhance convergence speed while maintaining exploration capabilities.", "configspace": "", "generation": 56, "fitness": 0.4397588669812831, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.440 with standard deviation 0.030. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.4790769524178853, 0.40684363661498046, 0.4333560119109834], "final_y": [3.977281785945774e-06, 5.122392915255732e-05, 1.648767908684497e-05]}, "mutation_prompt": null}
{"id": "bf30ab56-d54b-4701-9d38-6e84e82af844", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.1 * improvement_rate) * (1 - eval_count / self.budget)  # Changed from 0.05 to 0.1\n\n        return best_solution", "name": "HybridDE_SA", "description": "Introduce adaptive temperature modulation based on improvement rate for better convergence.", "configspace": "", "generation": 57, "fitness": 0.3956902427757772, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.396 with standard deviation 0.008. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.40709264031894177, 0.3909828978776577, 0.388995190130732], "final_y": [5.061001761125938e-05, 3.043343207511888e-06, 3.351754745016073e-06]}, "mutation_prompt": null}
{"id": "fde4c5f8-1599-4973-933f-9539030bb428", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            adaptive_pop_size = max(4, int(self.population_size * (1 - eval_count / self.budget)))\n            for i in range(adaptive_pop_size):  # Line change (1)\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n            self.f_scale = 0.85 + 0.15 * improvement_rate  # Line change (2)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Introduce adaptive population size reduction and dynamic mutation adaptation to enhance diversity and convergence efficiency.", "configspace": "", "generation": 58, "fitness": 0.2817428014256141, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.282 with standard deviation 0.012. And the mean value of best solutions found was 0.005 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.2960513361562751, 0.26681766579099453, 0.2823594023295727], "final_y": [0.005652416989261433, 0.005442916809054879, 0.0050014837806306375]}, "mutation_prompt": null}
{"id": "973353e3-5376-415e-96b8-36c14bee18ce", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        eval_count = self.population_size\n        stagnation_counter = 0\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            diversity = np.std(population, axis=0).mean()\n            adaptive_cooling = self.cooling_rate + 0.1 * diversity\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 + stagnation_counter / 10)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n\n            self.temperature *= adaptive_cooling * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance exploration by introducing a dynamic mutation scale and adaptive cooling based on diversity and stagnation detection.", "configspace": "", "generation": 59, "fitness": 0.18856958544265898, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.189 with standard deviation 0.066. And the mean value of best solutions found was 1.339 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.11497931225331215, 0.17557855327781824, 0.2751508907968465], "final_y": [3.153390180028366, 0.7729503257894813, 0.0901161867746035]}, "mutation_prompt": null}
{"id": "71afb92e-cfc2-43d1-9c65-014b1f71ac5f", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.91  # Adjusted from 0.90 to 0.91\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Fine-tune cooling rate to dynamically adapt based on the average improvement rate.", "configspace": "", "generation": 60, "fitness": 0.3607853433707124, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.361 with standard deviation 0.007. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.3672822601832588, 0.3505139654417877, 0.3645598044870907], "final_y": [3.7613805762867663e-05, 0.0005683883693479637, 0.000100920323684743]}, "mutation_prompt": null}
{"id": "f71626aa-36dd-4846-80c7-58f8ac7c2cb3", "solution": "import numpy as np\n\nclass EnhancedHybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Calculate population diversity\n                diversity = np.std(population, axis=0).mean()\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget) * diversity\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                \n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "EnhancedHybridDE_SA", "description": "Introduce adaptive mutation by adjusting F-scale based on population diversity to enhance exploration and convergence.", "configspace": "", "generation": 61, "fitness": 0.15583586387509554, "feedback": "The algorithm EnhancedHybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.156 with standard deviation 0.020. And the mean value of best solutions found was 1.118 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.17303221844706007, 0.16724994244568636, 0.12722543073254022], "final_y": [0.8574897386564544, 0.05560868737710074, 2.4417715744589303]}, "mutation_prompt": null}
{"id": "dd9fa792-feb2-4d1d-8dce-d5441ec96420", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - (eval_count / self.budget)**2)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Improved exploration by adjusting the adaptive scaling factor for better balance between exploration and exploitation.", "configspace": "", "generation": 62, "fitness": 0.33879807867233813, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.339 with standard deviation 0.024. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.31697420167144064, 0.32709242309173037, 0.3723276112538435], "final_y": [0.00017551948499314854, 0.0002344095363117726, 3.0203770376620683e-05]}, "mutation_prompt": null}
{"id": "93fd1d56-98d5-4d28-9bbd-378a86f3482a", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            diversity = np.mean(np.std(population, axis=0))  # Calculate population diversity\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget) * (1 + 0.1 * diversity)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget) * (1 + 0.1 * diversity)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance adaptive exploration by adjusting mutation factor and crossover probability dynamically based on current diversity.", "configspace": "", "generation": 63, "fitness": 0.3180720839671851, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.318 with standard deviation 0.017. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.3262860049809996, 0.2946250341084611, 0.3333052128120947], "final_y": [0.0005085333203330884, 9.228586941832431e-05, 0.0006477783934382529]}, "mutation_prompt": null}
{"id": "bc2da54b-14b4-4322-b0fc-efdf870683e7", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.population_size = self.initial_population_size\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget) * np.random.rand()\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n            self.population_size = max(self.initial_population_size // 2, int(self.initial_population_size * (1 - eval_count / self.budget)))\n\n        return best_solution", "name": "HybridDE_SA", "description": "Introduce adaptive mutation scaling and dynamic population size adjustments to enhance local search and global exploration.", "configspace": "", "generation": 64, "fitness": 0.31030721459455696, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.310 with standard deviation 0.039. And the mean value of best solutions found was 0.040 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.34357275544738375, 0.2548401885913135, 0.33250869974497355], "final_y": [0.004526392457186417, 0.11103916224911786, 0.004678403037818254]}, "mutation_prompt": null}
{"id": "411e8487-dd33-4320-a0e9-6246a364decc", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            diversity = np.std(population, axis=0).mean()  # New line\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget) * (1 + diversity)  # Changed line\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n            self.cooling_rate = 0.9 - 0.1 * diversity  # New line\n\n        return best_solution", "name": "HybridDE_SA", "description": "Improve exploration by introducing a dynamic adjustment of the f_scale parameter and adaptive cooling rate based on the population's diversity.", "configspace": "", "generation": 65, "fitness": 0.12386859949296199, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.124 with standard deviation 0.039. And the mean value of best solutions found was 3.420 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.17603641053156105, 0.11395530620278282, 0.0816140817445421], "final_y": [0.7801386836317055, 3.1947756549083657, 6.285615287501153]}, "mutation_prompt": null}
{"id": "3fb11a05-a3a5-4e5a-8d7d-02a616d61a1f", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n            self.f_scale = 0.9 - 0.5 * (eval_count / self.budget)  # Adjust mutation factor dynamically\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance the exploration phase by dynamically adjusting the mutation factor.", "configspace": "", "generation": 66, "fitness": 0.441928940246602, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.442 with standard deviation 0.032. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.46630254246028224, 0.39669761198489506, 0.4627866662946287], "final_y": [1.281280872227233e-06, 0.0001767439495045834, 7.949888451497186e-07]}, "mutation_prompt": null}
{"id": "605508cf-8bdb-47c4-b918-5b81a985c1b7", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.88  # Changed from 0.85 to 0.88\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Adjust the factor scaling (f_scale) from 0.85 to 0.88 for enhanced diversity and convergence.", "configspace": "", "generation": 67, "fitness": 0.39747506465497645, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.397 with standard deviation 0.034. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.444992900007268, 0.3734810420094833, 0.373951251948178], "final_y": [1.3454914847478692e-06, 4.451938152102597e-05, 1.2523631589953712e-05]}, "mutation_prompt": null}
{"id": "77efe13b-b108-4134-8ce0-2706e1d01f56", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * np.random.uniform(0.5, 1.5) * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget) * np.random.uniform(0.9, 1.1)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Introduce a dynamic scaling factor and a stochastic temperature adjustment to enhance convergence speed.", "configspace": "", "generation": 68, "fitness": 0.40817406583332766, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.408 with standard deviation 0.020. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.4117639269024963, 0.4300761299611602, 0.38268214063632633], "final_y": [1.9035239768558953e-06, 6.899804480357586e-06, 0.00019169087471396364]}, "mutation_prompt": null}
{"id": "0304c64f-53ed-4241-95dd-44d1f53e9230", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n        initial_population_size = self.population_size  # New\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            adaptive_population_size = max(4, int(initial_population_size * (1 - eval_count / self.budget)))  # Changed\n            for i in range(adaptive_population_size):  # Changed\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Introduce adaptive population size reduction for improved convergence in Hybrid Differential Evolution with Simulated Annealing.", "configspace": "", "generation": 69, "fitness": 0.28686848662382103, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.287 with standard deviation 0.031. And the mean value of best solutions found was 0.010 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.2517372732309552, 0.28193528872649576, 0.32693289791401214], "final_y": [0.026820530576314706, 0.0019711358747474313, 0.001304742345067134]}, "mutation_prompt": null}
{"id": "82313896-b400-49c3-a51c-f03c0c7be7a5", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.92  # Changed from 0.90 to 0.92\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.7 + 0.3 * (1 - eval_count / self.budget)  # Changed from 0.8 to 0.7\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Adjust crossover probability to be adaptive and increase cooling rate to enhance exploration and convergence.", "configspace": "", "generation": 70, "fitness": 0.3825006055249353, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.383 with standard deviation 0.007. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.3914291113773384, 0.38231495148288497, 0.37375775371458253], "final_y": [2.796150749874697e-05, 4.85806564346779e-05, 0.00011333587928320464]}, "mutation_prompt": null}
{"id": "bf527f77-054d-4c6b-9f69-676e92335456", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n        inertia_factor = 0.1\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget) * np.random.rand()\n                mutant = np.clip(a + adaptive_scale * (b - c) + inertia_factor * (best_solution - population[i]), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Improve exploitation by dynamically adjusting mutation factor and incorporating inertia factor for faster convergence.", "configspace": "", "generation": 71, "fitness": 0.40293343251554076, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.403 with standard deviation 0.074. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.4477443798890587, 0.4620065351875572, 0.29904938247000645], "final_y": [1.5198430159593918e-06, 2.035539397992299e-06, 0.00077233722084724]}, "mutation_prompt": null}
{"id": "15231b93-4868-44b9-a997-b1d4459bae87", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= self.cooling_rate * (1 - eval_count / self.budget) * (1 + improvement_rate)\n            if eval_count % (self.budget // 5) == 0:\n                population_size = max(5, int(population_size * 0.9))\n\n        return best_solution", "name": "HybridDE_SA", "description": "Introduce dynamic population sizing and adaptive temperature to enhance convergence speed and solution quality.", "configspace": "", "generation": 72, "fitness": 0.4168498286504278, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.417 with standard deviation 0.014. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.4343926262255394, 0.3993602797495842, 0.4167965799761597], "final_y": [9.765055696225775e-07, 7.652900814730212e-06, 7.743123775107883e-06]}, "mutation_prompt": null}
{"id": "dc341ecf-b353-44cb-bde1-f357dfd2f994", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            diversity = np.std(population, axis=0).mean()  # Population diversity\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget) * (1 + diversity)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget) * (1 + diversity)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance exploration by adaptively tuning the mutation factor and crossover probability based on the diversity of the population.", "configspace": "", "generation": 73, "fitness": 0.15067602502669933, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.151 with standard deviation 0.055. And the mean value of best solutions found was 2.149 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.11278430473672618, 0.2286807331331484, 0.11056303721022342], "final_y": [3.3066696111057374, 0.2442040579909423, 2.895643277203709]}, "mutation_prompt": null}
{"id": "913551d6-ab44-43c5-a77a-30cadd2c8520", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n            self.cooling_rate *= 1 - 0.5 * (eval_count / self.budget)  # Adjust cooling rate based on budget usage\n\n        return best_solution", "name": "HybridDE_SA", "description": "Improve the adaptability by dynamically adjusting the cooling rate based on the budget usage.", "configspace": "", "generation": 74, "fitness": 0.4556264602231915, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.456 with standard deviation 0.025. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.48981567213134447, 0.4293639461360488, 0.44769976240218123], "final_y": [1.9012578651917255e-07, 7.188207501038808e-06, 2.557226747132065e-07]}, "mutation_prompt": null}
{"id": "720a0a37-9b45-4bb1-8315-7f95f47e0d40", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.85  # Changed from 0.92 to 0.85\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.95  # Changed from 0.90 to 0.95\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                improvement_factor = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n                self.cross_prob = 0.8 + 0.25 * improvement_factor  # Adjusted from 0.8 + 0.2\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                selection_pressure = np.exp((fitness[i] - trial_fitness) / (self.temperature * (1 + improvement_factor)))\n                if trial_fitness < fitness[i] or np.random.rand() < selection_pressure:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance exploitation by dynamically adjusting crossover probability and selection pressure based on fitness improvement.", "configspace": "", "generation": 75, "fitness": 0.3400081852686907, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.340 with standard deviation 0.035. And the mean value of best solutions found was 0.002 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.2948998719553845, 0.343860697605906, 0.38126398624478175], "final_y": [0.005133388200730744, 0.00010401698383364903, 3.22885767659167e-05]}, "mutation_prompt": null}
{"id": "d91d816c-5e04-4835-aa96-fd5ca6e225b8", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget) * np.random.rand()  # Changed line\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget) + 0.1 * np.random.rand()  # Changed line\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Improve exploration by introducing an adaptive mutation and crossover strategy based on dynamic factors.", "configspace": "", "generation": 76, "fitness": 0.43316502234437104, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.433 with standard deviation 0.009. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.4410382954626453, 0.4372366174422233, 0.42122015412824454], "final_y": [3.633757071195435e-05, 9.376944650317569e-05, 0.00019445999402564943]}, "mutation_prompt": null}
{"id": "583c1631-70aa-4269-ba7e-755231c4ba10", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.89  # Changed from 0.90 to 0.89\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance exploration by slightly decreasing the cooling rate to allow more diverse search paths.", "configspace": "", "generation": 77, "fitness": 0.39352875455155245, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.394 with standard deviation 0.027. And the mean value of best solutions found was 0.001 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.3582124316865054, 0.42330913141630166, 0.3990647005518503], "final_y": [0.0035444581510432715, 4.111929738485703e-05, 6.530799536467041e-06]}, "mutation_prompt": null}
{"id": "a6ae3d56-0120-48d0-b9cd-f942f069fc0e", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget) * (1 + 0.1 * np.exp(-best_fitness))\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Adjust the scaling factor for mutation adaptively using the best solution found, enhancing convergence.", "configspace": "", "generation": 78, "fitness": 0.38957801405972764, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.390 with standard deviation 0.030. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.43179187459401114, 0.3710840320286346, 0.3658581355565371], "final_y": [1.5059553657130438e-06, 3.851914205729049e-05, 6.725967001944936e-05]}, "mutation_prompt": null}
{"id": "d1224dfe-3abe-4753-9f12-d3e778b657b9", "solution": "import numpy as np\n\nclass HybridDE_SA_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_population_size = 5 * dim  # Changed from 10 to 5\n        self.max_population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.max_population_size  # Changed to a variable\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            population_size = int(self.min_population_size + (self.max_population_size - self.min_population_size) * (1 - eval_count / self.budget))  # Adaptive size\n            for i in range(population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA_Adaptive", "description": "Refine exploration by introducing an adaptive population size based on budget progression.", "configspace": "", "generation": 79, "fitness": 0.39431165284551994, "feedback": "The algorithm HybridDE_SA_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.394 with standard deviation 0.044. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.36279873093723936, 0.3630696746448768, 0.45706655295444376], "final_y": [8.834613136579298e-05, 0.0003714744860344627, 3.7834180582931045e-06]}, "mutation_prompt": null}
{"id": "235003c9-17d6-477e-9e3e-e791183d5b80", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Introduce adaptive cooling to enhance the convergence rate.", "configspace": "", "generation": 80, "fitness": 0.37325730117234474, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.373 with standard deviation 0.021. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.36262575646260087, 0.3548155461711021, 0.40233060088333106], "final_y": [6.579120740124098e-05, 0.00034255589456622077, 7.673010465985484e-06]}, "mutation_prompt": null}
{"id": "cded53ba-22b9-454b-a2ff-451bbb104440", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.8  # Changed from 0.85 to 0.8\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Slightly increase the exploration by reducing the scaling factor in differential mutation.", "configspace": "", "generation": 81, "fitness": 0.40431074967196395, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.404 with standard deviation 0.011. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.40817419198090676, 0.388991626394266, 0.41576643064071894], "final_y": [7.405757214374082e-05, 3.0732378628105604e-05, 4.5256945466503486e-06]}, "mutation_prompt": null}
{"id": "1530bbf0-7ead-48fc-9496-37592939350b", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget) * np.random.rand()\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n            if improvement_rate > 0.01:  # Reduce population size if significant improvement\n                self.population_size = max(4 * self.dim, self.population_size - 1)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance exploration by incorporating dynamic mutation scaling and adaptive population size reduction.", "configspace": "", "generation": 82, "fitness": 0.2992882401042383, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.299 with standard deviation 0.050. And the mean value of best solutions found was 0.044 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.3670886482160468, 0.28188630602131637, 0.24888976607535174], "final_y": [0.0030332012654078347, 0.027828956831284436, 0.10021247215603385]}, "mutation_prompt": null}
{"id": "150eb5e8-9c4f-4916-ba32-eaa55d2caae5", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.92  # Changed from 0.90 to 0.92\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Fine-tuned the cooling rate of the temperature to improve convergence speed and solution quality.", "configspace": "", "generation": 83, "fitness": 0.4164161174314727, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.416 with standard deviation 0.014. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.4095490703083071, 0.4036057559035289, 0.43609352608258223], "final_y": [1.575691662663294e-05, 1.75849720020126e-05, 1.8249906159600667e-07]}, "mutation_prompt": null}
{"id": "e35f6c79-fa8d-409d-b51f-8a24ffaf09f3", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Chaotic sequence for mutation factor\n                self.f_scale = 0.5 * (1 + np.sin(np.pi * eval_count / self.budget))\n                mutant = np.clip(a + self.f_scale * (b - c), lb, ub)\n                \n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance exploration by dynamically adjusting the mutation factor and introducing chaotic sequence for better diversity.", "configspace": "", "generation": 84, "fitness": 0.33135326814290933, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.331 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.30595534480534814, 0.32751143636382996, 0.3605930232595499], "final_y": [0.00039797645691768834, 9.438064039523271e-05, 6.798520762632253e-05]}, "mutation_prompt": null}
{"id": "27415fc4-1918-4a3d-84e8-386d48d25e74", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.88  # Changed from 0.85 to 0.88\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Fine-tune the scaling factor to enhance the balance between exploration and exploitation.", "configspace": "", "generation": 85, "fitness": 0.3847090650911353, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.385 with standard deviation 0.031. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.39547675580408004, 0.4155208023190722, 0.34312963715025346], "final_y": [7.498843797655014e-05, 1.6143262648510827e-06, 8.126951656014975e-05]}, "mutation_prompt": null}
{"id": "3c389da9-5b70-4da6-858e-93181389f143", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            self.population_size = int(10 * self.dim * (1 + 0.1 * (eval_count / self.budget)))\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget) * np.random.uniform(0.8, 1.2)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance exploration by introducing adaptive mutation and dynamically adjusted population size based on convergence speed.", "configspace": "", "generation": 86, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {}, "mutation_prompt": null}
{"id": "9dfc3782-05f9-4391-be19-d11d42948996", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.91  # Changed from 0.92 to 0.91\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance exploration by slightly reducing the crossover probability, which balances exploration and exploitation more effectively.", "configspace": "", "generation": 87, "fitness": 0.37947847227201986, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.379 with standard deviation 0.035. And the mean value of best solutions found was 0.001 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.41475604569713387, 0.33209616398047914, 0.3915832071384465], "final_y": [2.9439056977007797e-06, 0.0016445471999852828, 0.00011223126413002035]}, "mutation_prompt": null}
{"id": "f78519c5-9ca5-4863-9f38-73682f28dfc6", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.88  # Changed from 0.90 to 0.88\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance convergence by slightly decreasing the cooling rate to maintain temperature longer.  ", "configspace": "", "generation": 88, "fitness": 0.3959558362443583, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.396 with standard deviation 0.026. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.36664050734338516, 0.3908487644020092, 0.43037823698768063], "final_y": [0.0002900780225903188, 0.00013170134982378278, 1.0978072091574875e-06]}, "mutation_prompt": null}
{"id": "7bb78476-9b77-4477-b621-6b869c5bfd30", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.88  # Changed from 0.90 to 0.88\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance exploration by slightly decreasing the cooling rate, improving solution diversity.", "configspace": "", "generation": 89, "fitness": 0.3912278275550338, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.391 with standard deviation 0.048. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.45846081016809503, 0.36426722396778244, 0.350955448529224], "final_y": [2.2818420360450807e-06, 3.2998516117941006e-05, 6.459179668110247e-05]}, "mutation_prompt": null}
{"id": "e57e6806-ce17-4a18-9ce8-b10253e8aed0", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate * (np.std(fitness) / np.mean(fitness))) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Improve convergence by dynamically adjusting the cooling rate based on the fitness variance.", "configspace": "", "generation": 90, "fitness": 0.41868170282274986, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.419 with standard deviation 0.033. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.4535883582310446, 0.42776064789497714, 0.37469610234222783], "final_y": [5.482056084627451e-07, 6.167154140081713e-06, 3.111529392147643e-05]}, "mutation_prompt": null}
{"id": "5e997e95-0d78-45aa-9934-83b26930f2c6", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            self.population_size = max(int(10 * self.dim * (1 - eval_count / self.budget)), 4)  # Dynamic population\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * np.random.rand()  # Adaptive mutation\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Introduce adaptive mutation strategy and dynamic population size reduction to enhance convergence.", "configspace": "", "generation": 91, "fitness": 0.22393145368984704, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.224 with standard deviation 0.102. And the mean value of best solutions found was 0.869 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.36603410182420404, 0.1739418639078142, 0.13181839533752293], "final_y": [0.0016192073156185152, 0.6407581500919878, 1.9657805561014323]}, "mutation_prompt": null}
{"id": "02c6ef72-d94e-4e7b-ac50-30541b8ba67b", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.92  # Changed from 0.90 to 0.92\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Slightly adjust the cooling rate to improve convergence speed and exploration-exploitation balance.", "configspace": "", "generation": 92, "fitness": 0.3832540225936298, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.383 with standard deviation 0.023. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.35265289869366323, 0.38827725070033703, 0.40883191838688915], "final_y": [0.00018686677745328873, 1.4057862317453787e-05, 3.4633847742090153e-06]}, "mutation_prompt": null}
{"id": "4393562a-d55c-47b8-9e50-4b65d472dbdb", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.95  # Changed from 0.90 to 0.95\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Adjust the cooling rate to adapt more dynamically based on the budget utilization.", "configspace": "", "generation": 93, "fitness": 0.3862503997550116, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.386 with standard deviation 0.009. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.37458790615962223, 0.39648564217729654, 0.3876776509281159], "final_y": [0.0001789404595125225, 2.0130772364981798e-05, 0.00010848337637787655]}, "mutation_prompt": null}
{"id": "69aae54e-d835-49b9-ac0d-396a70e1cea8", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                if eval_count < self.budget / 2:  # Dynamic mutation strategy\n                    mutant += 0.1 * (best_solution - mutant)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n            \n            if eval_count % (self.population_size // 2) == 0:  # Dynamic population adjustment\n                self.population_size = max(self.dim, int(self.population_size * 0.95))\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance adaptive mutation and dynamic population adjustment to improve convergence speed and solution quality.", "configspace": "", "generation": 94, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {}, "mutation_prompt": null}
{"id": "bcc36fae-c5ff-474b-997e-ff5d76e37ed1", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.85 + 0.15 * ((self.budget - eval_count) / self.budget) # Adjusted calculation\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Improve both exploration and exploitation by dynamically adjusting crossover probability and mutation strategy.", "configspace": "", "generation": 95, "fitness": 0.4445427359171408, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.445 with standard deviation 0.030. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.41053825081763573, 0.4394084219251303, 0.4836815350086562], "final_y": [9.695802381292889e-05, 9.434317277309627e-07, 2.0210473854682877e-07]}, "mutation_prompt": null}
{"id": "9e94a4c4-0bea-463e-acfe-780077df9b7e", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - (eval_count / self.budget) ** 0.5)  # Adjusted mutation factor\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance exploitation by increasing the mutation factor adaptively to improve convergence rate.", "configspace": "", "generation": 96, "fitness": 0.42570740771637894, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.426 with standard deviation 0.051. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.4536283243567618, 0.46977747667274006, 0.35371642211963505], "final_y": [9.426899281236858e-06, 3.6878494657432814e-05, 0.0012508629580008429]}, "mutation_prompt": null}
{"id": "4f73655d-d57d-4e14-bafb-d907ac8e4df7", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92\n        self.f_scale = 0.90  # Changed from 0.85 to 0.90\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance exploitation by increasing the adaptive scaling factor for robust convergence.", "configspace": "", "generation": 97, "fitness": 0.3909349386857301, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.391 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.4147920138487112, 0.3869445339478431, 0.3710682682606359], "final_y": [2.21316097446481e-05, 2.3294418718308226e-05, 7.62082837353853e-05]}, "mutation_prompt": null}
{"id": "fa91c6cb-2558-45a5-9bf5-f7c9a1909b70", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.8  # Changed from 0.92 to 0.8\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.05 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Enhance exploration by slightly decreasing the crossover probability during initial stages, then adaptively increasing it.", "configspace": "", "generation": 98, "fitness": 0.3865986618591097, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.387 with standard deviation 0.007. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.39591320835340993, 0.3812871930356361, 0.3825955841882831], "final_y": [6.893464333887627e-05, 0.0001565560741724029, 7.005442992085712e-05]}, "mutation_prompt": null}
{"id": "6fc069e6-a8df-4c75-a9d8-32551fb0c8e4", "solution": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.cross_prob = 0.92  # Changed from 0.9 to 0.92\n        self.f_scale = 0.85\n        self.temperature = 1.0\n        self.cooling_rate = 0.90\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            previous_best_fitness = best_fitness\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_scale = self.f_scale * (1 - eval_count / self.budget)\n                mutant = np.clip(a + adaptive_scale * (b - c), lb, ub)\n                self.cross_prob = 0.8 + 0.2 * (1 - eval_count / self.budget)\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            improvement_rate = (previous_best_fitness - best_fitness) / abs(previous_best_fitness) if previous_best_fitness != 0 else 1\n            self.temperature *= (self.cooling_rate + 0.1 * improvement_rate) * (1 - eval_count / self.budget)\n\n        return best_solution", "name": "HybridDE_SA", "description": "Improve dynamic temperature adjustment by making it more sensitive to small improvements in fitness.", "configspace": "", "generation": 99, "fitness": 0.4222955641680541, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.422 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "238b1029-8721-47bc-b89b-ba88c538ddf1", "metadata": {"aucs": [0.43359709651868494, 0.3970914659128083, 0.43619813007266894], "final_y": [4.211168673320719e-06, 5.883449876590507e-05, 2.4610468457939235e-05]}, "mutation_prompt": null}

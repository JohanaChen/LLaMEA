{"id": "bffb408c-1c7b-4b18-9e15-0d256311ee7f", "solution": "import numpy as np\n\nclass APSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            \n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(3, self.population_size // 10)\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01", "name": "APSO_DN", "description": "Adaptive Particle Swarm Optimization with Dynamic Neighborhoods (APSO-DN) leverages adaptive particle interactions and dynamic neighborhood restructuring to efficiently explore and exploit the search space within budget constraints.", "configspace": "", "generation": 0, "fitness": 0.23287124741533627, "feedback": "The algorithm APSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.233 with standard deviation 0.018. And the mean value of best solutions found was 0.038 (0. is the best).", "error": "", "parent_id": null, "metadata": {"aucs": [0.25302134938370135, 0.21002927949932482, 0.23556311336298263], "final_y": [0.01117057514103362, 0.08538909417634105, 0.016736322574816123]}, "mutation_prompt": null}
{"id": "0cd71612-83fe-4225-bc32-0884278e7a09", "solution": "import numpy as np\n\nclass QEA_DAM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.theta_angles = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        self.init_population()\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                solution = self.decode_solution(self.theta_angles[i], lb, ub)\n                score = func(solution)\n                self.evaluations += 1\n                \n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = solution\n            \n            self.update_population()\n            \n        return self.best_solution, self.best_score\n\n    def init_population(self):\n        self.theta_angles = np.random.uniform(0, 2 * np.pi, (self.population_size, self.dim))\n\n    def decode_solution(self, theta, lb, ub):\n        binary_solution = np.sign(np.sin(theta))\n        return lb + 0.5 * (binary_solution + 1) * (ub - lb)\n\n    def update_population(self):\n        for i in range(self.population_size):\n            delta_theta = np.random.uniform(-0.1, 0.1, self.dim)\n            self.theta_angles[i] += delta_theta\n            self.theta_angles[i] = np.mod(self.theta_angles[i], 2 * np.pi)\n\n            if np.random.rand() < 0.1:  # Dynamic angle modulation\n                j = np.random.randint(0, self.population_size)\n                self.theta_angles[i] = 0.5 * (self.theta_angles[i] + self.theta_angles[j])", "name": "QEA_DAM", "description": "Quantum-inspired Evolutionary Algorithm with Dynamic Angle Modulation (QEA-DAM) combines quantum-inspired operators and adaptive angle modulation to efficiently navigate the search space for multimodal optimization problems.", "configspace": "", "generation": 1, "fitness": 0.07881067689845518, "feedback": "The algorithm QEA_DAM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.079 with standard deviation 0.000. And the mean value of best solutions found was 7.110 (0. is the best).", "error": "", "parent_id": "bffb408c-1c7b-4b18-9e15-0d256311ee7f", "metadata": {"aucs": [0.07904939087150453, 0.07846856451956141, 0.07891407530429961], "final_y": [7.110086311175707, 7.110086311175707, 7.110086311175707]}, "mutation_prompt": null}
{"id": "57bf0086-789a-4dec-bfc9-ea1ecd8547b7", "solution": "import numpy as np\n\nclass APSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            \n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(3, self.population_size // 5)  # Changed from // 10 to // 5 for better local search\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01", "name": "APSO_DN", "description": "Improved the dynamic neighborhood size for better local exploration.", "configspace": "", "generation": 2, "fitness": 0.22904919411495386, "feedback": "The algorithm APSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.229 with standard deviation 0.013. And the mean value of best solutions found was 0.025 (0. is the best).", "error": "", "parent_id": "bffb408c-1c7b-4b18-9e15-0d256311ee7f", "metadata": {"aucs": [0.21129906128332876, 0.23697783064162492, 0.23887069041990794], "final_y": [0.009808394844376392, 0.04286987168720926, 0.021115895713889457]}, "mutation_prompt": null}
{"id": "e7688b9c-176a-40f4-b023-255150a8a55e", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(3, self.population_size // 10)\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 1.01", "name": "QAPSO_DN", "description": "Quantum-inspired Adaptive Particle Swarm Optimization with Dynamic Neighborhoods (QAPSO-DN) integrates quantum particle behavior to enhance exploration capabilities and improve convergence speed within budget constraints.", "configspace": "", "generation": 3, "fitness": 0.2731895431870142, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.273 with standard deviation 0.019. And the mean value of best solutions found was 0.009 (0. is the best).", "error": "", "parent_id": "bffb408c-1c7b-4b18-9e15-0d256311ee7f", "metadata": {"aucs": [0.28820352853986453, 0.2842980651592776, 0.24706703586190049], "final_y": [0.01230160505453079, 0.00440763017856761, 0.011355013922247553]}, "mutation_prompt": null}
{"id": "409e5dcf-855a-436c-a33c-50ba4bfd3bd0", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(4, self.population_size // 10)  # Increased neighborhood size from 3 to 4\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 1.01", "name": "QAPSO_DN", "description": "Enhanced QAPSO-DN by increasing local neighborhood size for improved local exploration.", "configspace": "", "generation": 4, "fitness": 0.27123750036754185, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.271 with standard deviation 0.040. And the mean value of best solutions found was 0.013 (0. is the best).", "error": "", "parent_id": "e7688b9c-176a-40f4-b023-255150a8a55e", "metadata": {"aucs": [0.2519528243891157, 0.23423686085944806, 0.32752281585406184], "final_y": [0.0046968338861169846, 0.03354256144355465, 0.0010826253664538532]}, "mutation_prompt": null}
{"id": "3b00986d-f625-418a-bf69-f0ecc0ed4083", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = max(0.4, self.inertia) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(3, self.population_size // 10)\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 1.01", "name": "QAPSO_DN", "description": "The refined QAPSO-DN algorithm reduces the inertia weight dynamically, enhancing convergence precision by adjusting velocity updates.", "configspace": "", "generation": 5, "fitness": 0.27123750036754185, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.271 with standard deviation 0.040. And the mean value of best solutions found was 0.013 (0. is the best).", "error": "", "parent_id": "e7688b9c-176a-40f4-b023-255150a8a55e", "metadata": {"aucs": [0.2519528243891157, 0.23423686085944806, 0.32752281585406184], "final_y": [0.0046968338861169846, 0.03354256144355465, 0.0010826253664538532]}, "mutation_prompt": null}
{"id": "f7cd682a-1594-406e-ae3a-1644a54e0142", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(40 + (budget / 1000))  # Dynamic population size adjustment\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(3, self.population_size // 10)\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 1.01", "name": "QAPSO_DN", "description": "Introducing a dynamic adjustment of the population size to enhance adaptability and convergence efficiency.", "configspace": "", "generation": 6, "fitness": 0.25523761455341115, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.255 with standard deviation 0.007. And the mean value of best solutions found was 0.025 (0. is the best).", "error": "", "parent_id": "e7688b9c-176a-40f4-b023-255150a8a55e", "metadata": {"aucs": [0.2502574599723282, 0.250318357871525, 0.2651370258163802], "final_y": [0.0304386666899846, 0.00805047102467545, 0.03664344006008328]}, "mutation_prompt": null}
{"id": "87cde4ee-b3b0-4ffc-9d95-a74f2a7fd844", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(3, self.population_size // 10)\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 1.02  # Slight increase in quantum component", "name": "QAPSO_DN", "description": "Introduce a slight increase in the quantum component multiplier over time to enhance exploration and prevent premature convergence.", "configspace": "", "generation": 7, "fitness": 0.215413974683745, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.215 with standard deviation 0.014. And the mean value of best solutions found was 0.060 (0. is the best).", "error": "", "parent_id": "e7688b9c-176a-40f4-b023-255150a8a55e", "metadata": {"aucs": [0.2352445011802926, 0.2062429342129889, 0.20475448865795354], "final_y": [0.07692009459786367, 0.03255620061906866, 0.07068370309353585]}, "mutation_prompt": null}
{"id": "2a02ee23-2d11-4871-86e2-aea88f6b66fd", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i]) * (1.0 + 0.1 * np.sin(2 * np.pi * self.evaluations / float(self.budget)))\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(3, self.population_size // 10)\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 1.01", "name": "QAPSO_DN", "description": "Enhanced quantum component scaling to dynamically boost exploration capabilities during vital optimization phases.", "configspace": "", "generation": 8, "fitness": 0.26881583193327363, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.269 with standard deviation 0.013. And the mean value of best solutions found was 0.011 (0. is the best).", "error": "", "parent_id": "e7688b9c-176a-40f4-b023-255150a8a55e", "metadata": {"aucs": [0.2684222487267536, 0.2531482837103912, 0.2848769633626761], "final_y": [0.008201407388878264, 0.004651051461207695, 0.019798398737973323]}, "mutation_prompt": null}
{"id": "00e63171-035e-4467-91a4-c594fbdfe92c", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(3, self.population_size // 10)\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 1.015  # Slight increase to enhance adaptation in quantum component", "name": "QAPSO_DN", "description": "Enhanced QAPSO-DN with adaptive quantum component adjustment to improve exploration-exploitation balance.", "configspace": "", "generation": 9, "fitness": 0.27189386274158206, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.272 with standard deviation 0.041. And the mean value of best solutions found was 0.015 (0. is the best).", "error": "", "parent_id": "e7688b9c-176a-40f4-b023-255150a8a55e", "metadata": {"aucs": [0.251805830911943, 0.23495868769991457, 0.3289170696128887], "final_y": [0.008639922492185488, 0.035958688845774356, 0.0011922268093657589]}, "mutation_prompt": null}
{"id": "e8b0e0ff-0069-4962-adb7-f1641de6b684", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim) * 1.1  # Enhancement: Increase random factor in quantum component\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(3, self.population_size // 10)\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 1.01", "name": "QAPSO_DN", "description": "Enhanced exploration by adjusting random factor in quantum component for improved search diversity.", "configspace": "", "generation": 10, "fitness": 0.25588969795817557, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.256 with standard deviation 0.011. And the mean value of best solutions found was 0.013 (0. is the best).", "error": "", "parent_id": "e7688b9c-176a-40f4-b023-255150a8a55e", "metadata": {"aucs": [0.26708785021700443, 0.2405579051546003, 0.26002333850292203], "final_y": [0.013943130207364663, 0.010925639182947847, 0.013535587012167588]}, "mutation_prompt": null}
{"id": "2e0f350f-3dd0-41cb-8eed-2f7e6920cf8a", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(3, self.population_size // 10)\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= (1.01 + 0.01 * np.sin(self.evaluations / float(self.budget) * np.pi))\n            self.quantum_component *= (1.01 + 0.01 * np.cos(self.evaluations / float(self.budget) * np.pi))", "name": "QAPSO_DN", "description": "Introducing adaptive quantum and social component scaling based on the evaluation progress to improve exploration and convergence.", "configspace": "", "generation": 11, "fitness": 0.2678447295529343, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.268 with standard deviation 0.033. And the mean value of best solutions found was 0.025 (0. is the best).", "error": "", "parent_id": "e7688b9c-176a-40f4-b023-255150a8a55e", "metadata": {"aucs": [0.24516338126683956, 0.24365640804141198, 0.31471439935055134], "final_y": [0.04078701881472371, 0.022519826268846202, 0.012238639216199672]}, "mutation_prompt": null}
{"id": "7bebe097-a0f0-424a-be5d-00b27ebeafef", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(3, self.population_size // 10)\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= (1 + 0.1 * np.exp(-0.001 * self.evaluations))", "name": "QAPSO_DN", "description": "Introduce a dynamic quantum component by adapting it based on the best-known solution improvement rate to enhance exploration and convergence.", "configspace": "", "generation": 12, "fitness": 0.2659722462930516, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.266 with standard deviation 0.036. And the mean value of best solutions found was 0.020 (0. is the best).", "error": "", "parent_id": "e7688b9c-176a-40f4-b023-255150a8a55e", "metadata": {"aucs": [0.25086616043964194, 0.23126980113457662, 0.31578077730493626], "final_y": [0.01212826028248581, 0.03469288098677447, 0.01296176130720068]}, "mutation_prompt": null}
{"id": "0989a865-4161-4947-8fe3-994f05dfaacb", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 1.01", "name": "QAPSO_DN", "description": "Improved dynamic neighborhood selection by increasing neighborhood size to enhance local exploration in QAPSO-DN.", "configspace": "", "generation": 13, "fitness": 0.29956187776664017, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.300 with standard deviation 0.029. And the mean value of best solutions found was 0.008 (0. is the best).", "error": "", "parent_id": "e7688b9c-176a-40f4-b023-255150a8a55e", "metadata": {"aucs": [0.3122332799621489, 0.25892953748370984, 0.32752281585406184], "final_y": [0.005991950096960391, 0.017734512984611348, 0.0010826253664538532]}, "mutation_prompt": null}
{"id": "e1f1ca7a-7263-4eee-8595-39efd5cd4d9a", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 1.01", "name": "QAPSO_DN", "description": "Improved dynamic neighborhood selection by increasing neighborhood size to enhance local exploration in QAPSO-DN.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "0989a865-4161-4947-8fe3-994f05dfaacb", "metadata": {"aucs": [0.3122332799621489, 0.25892953748370984, 0.32752281585406184], "final_y": [0.005991950096960391, 0.017734512984611348, 0.0010826253664538532]}, "mutation_prompt": null}
{"id": "7ddad8c2-1eed-412f-90bf-87ebfef8beba", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= (1.01 * (1 - self.evaluations / self.budget))  # Modified line", "name": "QAPSO_DN", "description": "Enhanced global exploration by adapting quantum component decay with budget progress.", "configspace": "", "generation": 15, "fitness": 0.27201331566607106, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.272 with standard deviation 0.017. And the mean value of best solutions found was 0.007 (0. is the best).", "error": "", "parent_id": "0989a865-4161-4947-8fe3-994f05dfaacb", "metadata": {"aucs": [0.25899392342206395, 0.26151321440168196, 0.29553280917446734], "final_y": [0.004556660769625477, 0.012197698738201151, 0.003916520885624392]}, "mutation_prompt": null}
{"id": "be6cdb94-4672-4a50-a5f0-a5f7fee22a65", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.99  # Introduced decay factor for quantum component", "name": "QAPSO_DN", "description": "Introduced a decay factor to reduce the quantum component over time for improved convergence.", "configspace": "", "generation": 16, "fitness": 0.30408161648157833, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.304 with standard deviation 0.033. And the mean value of best solutions found was 0.010 (0. is the best).", "error": "", "parent_id": "0989a865-4161-4947-8fe3-994f05dfaacb", "metadata": {"aucs": [0.3122332799621489, 0.2603867818857606, 0.33962478759682546], "final_y": [0.005991950096960391, 0.02202908562531143, 0.0016681930097102618]}, "mutation_prompt": null}
{"id": "8679eba9-167f-44db-9dd0-a86d6cb17f44", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.995  # Change: Adjust cognitive component for dynamic exploration-exploitation balance\n            self.social_component *= 1.01\n            self.quantum_component *= 0.99  # Introduced decay factor for quantum component", "name": "QAPSO_DN", "description": "Enhance convergence by dynamically adjusting the cognitive component based on exploration-exploitation balance.", "configspace": "", "generation": 17, "fitness": 0.2993165413375339, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.299 with standard deviation 0.028. And the mean value of best solutions found was 0.009 (0. is the best).", "error": "", "parent_id": "be6cdb94-4672-4a50-a5f0-a5f7fee22a65", "metadata": {"aucs": [0.3122332799621489, 0.2605785809001292, 0.3251377631503236], "final_y": [0.005991950096960391, 0.014790443003301436, 0.005080824179355836]}, "mutation_prompt": null}
{"id": "b687c38f-8006-4546-a370-73f93f966750", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 6)  # Increased neighborhood size slightly\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.99  # Introduced decay factor for quantum component", "name": "QAPSO_DN", "description": "Enhanced exploration by increasing the neighborhood size slightly, fostering diverse solutions.", "configspace": "", "generation": 18, "fitness": 0.2842911783942412, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.284 with standard deviation 0.025. And the mean value of best solutions found was 0.010 (0. is the best).", "error": "", "parent_id": "be6cdb94-4672-4a50-a5f0-a5f7fee22a65", "metadata": {"aucs": [0.2762589441306761, 0.25830065134533053, 0.31831393970671684], "final_y": [0.0018825553436805074, 0.018304923863399197, 0.008607004569406758]}, "mutation_prompt": null}
{"id": "b2b21655-2d72-4af3-ae0c-d01f04ee4616", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(3, int(self.population_size // (8 - 6 * (self.evaluations / self.budget))))  # Adaptive neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.99  # Introduced decay factor for quantum component", "name": "QAPSO_DN", "description": "Enhanced dynamic neighborhood adjustment by altering the neighborhood size to adaptively reduce during the optimization process for improved local exploration.", "configspace": "", "generation": 19, "fitness": 0.2861476955518217, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.286 with standard deviation 0.039. And the mean value of best solutions found was 0.010 (0. is the best).", "error": "", "parent_id": "be6cdb94-4672-4a50-a5f0-a5f7fee22a65", "metadata": {"aucs": [0.27268129008830977, 0.24613700897032986, 0.33962478759682546], "final_y": [0.007351162672956257, 0.02128234604689099, 0.0016681930097102618]}, "mutation_prompt": null}
{"id": "5a352912-ce00-4a90-83d3-00febe654269", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.99 * (0.5 + 0.5 * np.cos(np.pi * self.evaluations / self.budget))  # Sinusoidal decay for quantum component", "name": "QAPSO_DN", "description": "Introduced a sinusoidal decay for the quantum component to dynamically adjust exploration over time.", "configspace": "", "generation": 20, "fitness": 0.2956390229734478, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.296 with standard deviation 0.022. And the mean value of best solutions found was 0.008 (0. is the best).", "error": "", "parent_id": "be6cdb94-4672-4a50-a5f0-a5f7fee22a65", "metadata": {"aucs": [0.31484057989169567, 0.2641477380416343, 0.30792875098701344], "final_y": [0.00362968234976805, 0.004047078547947596, 0.017768001033225157]}, "mutation_prompt": null}
{"id": "a03ba6c9-6f83-498c-a072-bfe066c6413c", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        random_neighbor = np.random.choice(self.population_size)  # Adding random neighbor\n        return np.append(neighbors[:neighborhood_size], random_neighbor)\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.99", "name": "QAPSO_DN", "description": "Enhanced the neighborhood selection by adding a random neighbor to introduce occasional exploration.", "configspace": "", "generation": 21, "fitness": 0.2549923494303076, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.255 with standard deviation 0.010. And the mean value of best solutions found was 0.017 (0. is the best).", "error": "", "parent_id": "be6cdb94-4672-4a50-a5f0-a5f7fee22a65", "metadata": {"aucs": [0.2519798375297625, 0.2449451762042376, 0.2680520345569226], "final_y": [0.004660060571014484, 0.02814538147510512, 0.017163201909885087]}, "mutation_prompt": null}
{"id": "9dd1f761-9875-4dc7-b256-7e009c36e5cc", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.99  # Introduced decay factor for quantum component", "name": "QAPSO_DN", "description": "Introduced a decay factor to reduce the quantum component over time for improved convergence.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "be6cdb94-4672-4a50-a5f0-a5f7fee22a65", "metadata": {"aucs": [0.3122332799621489, 0.2603867818857606, 0.33962478759682546], "final_y": [0.005991950096960391, 0.02202908562531143, 0.0016681930097102618]}, "mutation_prompt": null}
{"id": "40b3ab29-b87c-474e-ae75-b96cbee2d347", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.98  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Adjust the decay factor for the quantum component to improve convergence and exploration.", "configspace": "", "generation": 23, "fitness": 0.25119910580373883, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.251 with standard deviation 0.013. And the mean value of best solutions found was 0.021 (0. is the best).", "error": "", "parent_id": "be6cdb94-4672-4a50-a5f0-a5f7fee22a65", "metadata": {"aucs": [0.23634085831919138, 0.2484889743906572, 0.2687674847013679], "final_y": [0.019658670952027824, 0.025184476369967693, 0.01782151944119443]}, "mutation_prompt": null}
{"id": "5e32496f-62cc-448d-ad85-4ca947a1357d", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component = 0.5 + 0.2 * np.sin(self.evaluations / float(self.budget) * np.pi)  # Sinusoidal adaptation for quantum component", "name": "QAPSO_DN", "description": "Introduced a sinusoidal adaptation for quantum component to enhance exploration during stagnation.", "configspace": "", "generation": 24, "fitness": 0.2980004344914215, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.298 with standard deviation 0.028. And the mean value of best solutions found was 0.007 (0. is the best).", "error": "", "parent_id": "be6cdb94-4672-4a50-a5f0-a5f7fee22a65", "metadata": {"aucs": [0.3122332799621489, 0.25876808686215, 0.3229999366499656], "final_y": [0.005991950096960391, 0.01066943023541015, 0.0045804738577525555]}, "mutation_prompt": null}
{"id": "9f2f80f5-04e8-46d8-8298-3566d04d9a9b", "solution": "import numpy as np\n\nclass QAPSO_DN_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(30, budget // 200)  # Adaptive population size\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.985  # Slightly faster decay\n            self.social_component *= 1.015     # Slightly faster increase\n            self.quantum_component *= 0.98     # Adjusted decay factor for quantum component", "name": "QAPSO_DN_Improved", "description": "Introduced adaptive population size and fine-tuned parameter decay to enhance convergence.", "configspace": "", "generation": 25, "fitness": 0.2748347345105649, "feedback": "The algorithm QAPSO_DN_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.275 with standard deviation 0.019. And the mean value of best solutions found was 0.002 (0. is the best).", "error": "", "parent_id": "be6cdb94-4672-4a50-a5f0-a5f7fee22a65", "metadata": {"aucs": [0.27870779830868075, 0.25036115940108217, 0.2954352458219318], "final_y": [0.0016914205341439325, 0.0023210658593214193, 0.002082901753921137]}, "mutation_prompt": null}
{"id": "8afbe1ac-8d8c-4ef1-bdfa-6e1dfe1d08a4", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + 1.2 * social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.99  # Introduced decay factor for quantum component", "name": "QAPSO_DN", "description": "Optimized velocity update by increasing the local neighborhood influence for better convergence.", "configspace": "", "generation": 26, "fitness": 0.26998705330279993, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.270 with standard deviation 0.007. And the mean value of best solutions found was 0.017 (0. is the best).", "error": "", "parent_id": "be6cdb94-4672-4a50-a5f0-a5f7fee22a65", "metadata": {"aucs": [0.26144398791008117, 0.26896777536976313, 0.2795493966285555], "final_y": [0.019391084119625746, 0.020876011714427444, 0.009519035869910061]}, "mutation_prompt": null}
{"id": "54e76658-b730-462f-9dac-a4ece526c275", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.98  # Enhanced decay factor for quantum component", "name": "QAPSO_DN", "description": "Enhanced the decay factor for the quantum component to improve the exploration-exploitation balance.", "configspace": "", "generation": 27, "fitness": 0.3009267334219745, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.301 with standard deviation 0.030. And the mean value of best solutions found was 0.011 (0. is the best).", "error": "", "parent_id": "be6cdb94-4672-4a50-a5f0-a5f7fee22a65", "metadata": {"aucs": [0.3124451447582277, 0.2592623712683929, 0.3310726842393029], "final_y": [0.004384757930836141, 0.025105149384566892, 0.0032461357143001154]}, "mutation_prompt": null}
{"id": "008c0679-2e7c-41cb-bdf6-6ab8a3661c91", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, int(self.population_size * 0.1))  # Changed neighborhood size dynamically\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.99  # Introduced decay factor for quantum component", "name": "QAPSO_DN", "description": "Introduced a dynamic adjustment to neighborhood size for better exploration-exploitation balance.", "configspace": "", "generation": 28, "fitness": 0.30408161648157833, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.304 with standard deviation 0.033. And the mean value of best solutions found was 0.010 (0. is the best).", "error": "", "parent_id": "be6cdb94-4672-4a50-a5f0-a5f7fee22a65", "metadata": {"aucs": [0.3122332799621489, 0.2603867818857606, 0.33962478759682546], "final_y": [0.005991950096960391, 0.02202908562531143, 0.0016681930097102618]}, "mutation_prompt": null}
{"id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Adjusted quantum component decay factor for enhanced convergence stability.", "configspace": "", "generation": 29, "fitness": 0.3068169839500961, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.307 with standard deviation 0.034. And the mean value of best solutions found was 0.002 (0. is the best).", "error": "", "parent_id": "be6cdb94-4672-4a50-a5f0-a5f7fee22a65", "metadata": {"aucs": [0.32835815853289885, 0.25883593344364764, 0.33325685987374176], "final_y": [0.0007812924155456595, 0.0029224013754659797, 0.00280597879648201]}, "mutation_prompt": null}
{"id": "d7f0f504-0277-4dc5-a5b3-49e2ea164dac", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Adjusted quantum component decay factor for enhanced convergence stability.", "configspace": "", "generation": 30, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.32835815853289885, 0.25883593344364764, 0.33325685987374176], "final_y": [0.0007812924155456595, 0.0029224013754659797, 0.00280597879648201]}, "mutation_prompt": null}
{"id": "4cef2fc2-33c7-4c9c-b880-75660f92b921", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 4)  # Changed neighborhood size from population_size // 8 to // 4\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Enhanced dynamic neighborhood selection to improve local exploration.", "configspace": "", "generation": 31, "fitness": 0.2678563632952769, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.268 with standard deviation 0.019. And the mean value of best solutions found was 0.009 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.24347104803385533, 0.2696198210104983, 0.2904782208414771], "final_y": [0.009000086039728981, 0.014343288285289742, 0.004340377629956861]}, "mutation_prompt": null}
{"id": "97a1c6ac-c24b-440a-983c-6281f9e5428b", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(3, self.population_size // 6)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Enhanced convergence by adapting neighborhood influence size.", "configspace": "", "generation": 32, "fitness": 0.28393872352883637, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.284 with standard deviation 0.027. And the mean value of best solutions found was 0.007 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.28156300182575356, 0.25272867688546663, 0.31752449187528897], "final_y": [0.0030814900402135613, 0.009482091800520448, 0.009183029721953515]}, "mutation_prompt": null}
{"id": "843d2e0f-3aeb-48db-98d8-074d156983c0", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995 + 0.001 * np.sin(self.evaluations / float(self.budget) * np.pi)  # Fine-tuned decay factor for quantum component", "name": "QAPSO_DN", "description": "Enhanced quantum component decay factor dynamically increases exploration as evaluations progress.", "configspace": "", "generation": 33, "fitness": 0.3007954077985932, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.301 with standard deviation 0.033. And the mean value of best solutions found was 0.007 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.3156484538072164, 0.25468451273764436, 0.3320532568509189], "final_y": [0.003892075953946457, 0.014206310748250649, 0.003096106104866922]}, "mutation_prompt": null}
{"id": "4072b73b-5cce-4432-a5ca-ee7facc524d6", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 1.005 if self.global_best_score < 0.001 else 0.995  # Adjusted quantum factor based on score", "name": "QAPSO_DN", "description": "Introduced dynamic quantum component adjustment based on solution quality.", "configspace": "", "generation": 34, "fitness": 0.3068169839500961, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.307 with standard deviation 0.034. And the mean value of best solutions found was 0.002 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.32835815853289885, 0.25883593344364764, 0.33325685987374176], "final_y": [0.0007812924155456595, 0.0029224013754659797, 0.00280597879648201]}, "mutation_prompt": null}
{"id": "048652cf-65bd-4c55-9f82-f02c25432cea", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Adjusted quantum component decay factor for enhanced convergence stability.", "configspace": "", "generation": 30, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.32835815853289885, 0.25883593344364764, 0.33325685987374176], "final_y": [0.0007812924155456595, 0.0029224013754659797, 0.00280597879648201]}, "mutation_prompt": null}
{"id": "d21833d3-0490-4817-9b03-5fb3af364cf6", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.55  # Slightly increased quantum component\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Enhanced global exploration by increasing the quantum component slightly to improve diversity.", "configspace": "", "generation": 36, "fitness": 0.2739453425562411, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.274 with standard deviation 0.022. And the mean value of best solutions found was 0.006 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.24723368644849542, 0.2737806864650426, 0.3008216547551853], "final_y": [0.005373405215754739, 0.003169375851977414, 0.00994264199777379]}, "mutation_prompt": null}
{"id": "52deb1cd-9378-42bd-80fe-adf16ef240ec", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 4)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Enhanced dynamic neighborhood selection for improved local exploration.", "configspace": "", "generation": 37, "fitness": 0.2554136823501359, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.255 with standard deviation 0.022. And the mean value of best solutions found was 0.012 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.2766480402149092, 0.2258937872580502, 0.26369921957744835], "final_y": [0.01152829864022871, 0.014837925913895284, 0.010494084079438516]}, "mutation_prompt": null}
{"id": "1f44f515-667c-4769-b00b-1de57aa8e8e4", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01 * np.sin(self.evaluations / float(self.budget) * np.pi)  # Adaptive social influence\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Introduced adaptive social influence weighting to dynamically adjust exploration-exploitation balance.", "configspace": "", "generation": 38, "fitness": 0.3011971507622461, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.301 with standard deviation 0.019. And the mean value of best solutions found was 0.006 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.3122332799621489, 0.2743058992925489, 0.31705227303204053], "final_y": [0.005991950096960391, 0.0054895028542254485, 0.006913011512766581]}, "mutation_prompt": null}
{"id": "e95f67ec-a6d4-4361-9c02-f83b86edf5eb", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 6)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Enhance neighborhood size determination for increased local exploration.", "configspace": "", "generation": 39, "fitness": 0.28393872352883637, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.284 with standard deviation 0.027. And the mean value of best solutions found was 0.007 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.28156300182575356, 0.25272867688546663, 0.31752449187528897], "final_y": [0.0030814900402135613, 0.009482091800520448, 0.009183029721953515]}, "mutation_prompt": null}
{"id": "20074dc4-e06a-4ca4-a9b0-275a8ec39fd6", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.15 * np.sin(self.evaluations / float(self.budget) * np.pi)  # Slightly increased factor for inertia\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Enhanced adaptation of inertia component for improved convergence towards global best.", "configspace": "", "generation": 40, "fitness": 0.2979728720395302, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.298 with standard deviation 0.027. And the mean value of best solutions found was 0.009 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.3122332799621489, 0.26047105517214175, 0.32121428098429994], "final_y": [0.005991950096960391, 0.016336961735324642, 0.00366843348201265]}, "mutation_prompt": null}
{"id": "db8b74b3-fb02-463d-9529-22a20ee2c605", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.998  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Fine-tuned quantum component decrease rate to enhance stability and convergence precision.", "configspace": "", "generation": 41, "fitness": 0.30060891132534406, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.301 with standard deviation 0.031. And the mean value of best solutions found was 0.004 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.3144318615166778, 0.25768974533078204, 0.32970512712857236], "final_y": [0.0016106567575924471, 0.0055345547511428065, 0.003751940198675464]}, "mutation_prompt": null}
{"id": "0467ce30-1ef4-4c51-adb9-5f3bc6c524e6", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.45  # Fine-tuned for improved balance\n        self.social_component = 1.55  # Fine-tuned for improved balance\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995", "name": "QAPSO_DN", "description": "Fine-tune the balance of the cognitive and social components to improve convergence.", "configspace": "", "generation": 42, "fitness": 0.27711432761047256, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.277 with standard deviation 0.024. And the mean value of best solutions found was 0.019 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.26531226592302004, 0.25549678232718664, 0.3105339345812109], "final_y": [0.03992019168796164, 0.009744748392130955, 0.00771833599033733]}, "mutation_prompt": null}
{"id": "b9214e1c-2018-4aec-af12-9fe432359002", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, int(self.population_size // 8 * (0.5 + 0.5 * np.cos(self.evaluations / float(self.budget) * np.pi))))  # Adaptive neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Introduce adaptive neighborhood size for dynamic exploration balance.", "configspace": "", "generation": 43, "fitness": 0.3068169839500961, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.307 with standard deviation 0.034. And the mean value of best solutions found was 0.002 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.32835815853289885, 0.25883593344364764, 0.33325685987374176], "final_y": [0.0007812924155456595, 0.0029224013754659797, 0.00280597879648201]}, "mutation_prompt": null}
{"id": "c8f2c8a0-04f1-4032-82f3-25ceb41e7b41", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position + 0.001 * np.random.randn(self.dim) - self.positions[i])  # Perturbation added to global best\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995", "name": "QAPSO_DN", "description": "Introduce a slight perturbation to the global best position to enhance exploration.", "configspace": "", "generation": 44, "fitness": 0.2519088210575288, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.252 with standard deviation 0.014. And the mean value of best solutions found was 0.005 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.2582786337853381, 0.23205266821968085, 0.26539516116756745], "final_y": [0.0011281910116993756, 0.00787767593229763, 0.005147548876569173]}, "mutation_prompt": null}
{"id": "054f5c51-7fd9-49ea-beda-1626db51aa69", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.3 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)  # Reduced the lower bound of inertia weight\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Enhanced convergence by reducing inertia weight's lower bound for better exploration-exploitation balance.", "configspace": "", "generation": 45, "fitness": 0.2644088389225646, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.264 with standard deviation 0.023. And the mean value of best solutions found was 0.007 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.2621397323141428, 0.2931374529164119, 0.23794933153713915], "final_y": [0.006407668643676478, 0.004884501239596778, 0.010497050461009407]}, "mutation_prompt": null}
{"id": "dc3f3e70-aba2-4e9e-b9c7-3a0c84156b91", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 1.005  # Adjusted growth factor for quantum component", "name": "QAPSO_DN", "description": "Introduced adaptive quantum component growth for enhanced exploration.", "configspace": "", "generation": 46, "fitness": 0.30141756531904534, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.301 with standard deviation 0.025. And the mean value of best solutions found was 0.006 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.3122332799621489, 0.2673575372001302, 0.324661878794857], "final_y": [0.005991950096960391, 0.007419498169616936, 0.004933291894762919]}, "mutation_prompt": null}
{"id": "27f6b808-997b-4781-8333-e3aa390a7ff0", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.997  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Fine-tuned quantum decay factor to enhance exploration-exploitation balance.", "configspace": "", "generation": 47, "fitness": 0.3007916369161359, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.301 with standard deviation 0.031. And the mean value of best solutions found was 0.007 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.31403546897793977, 0.2575173488213748, 0.33082209294909315], "final_y": [0.002041140322351147, 0.015813860626182976, 0.003423934885884235]}, "mutation_prompt": null}
{"id": "4dd6958e-178d-499f-8112-f3309710cc55", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 41  # Changed population size from 40 to 41\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Enhanced convergence by increasing population size slightly for better exploration.", "configspace": "", "generation": 48, "fitness": 0.25496482760973854, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.255 with standard deviation 0.023. And the mean value of best solutions found was 0.013 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.22913684683640934, 0.28411407450751125, 0.251643561485295], "final_y": [0.011931693577588883, 0.006620522952055708, 0.02107514749559941]}, "mutation_prompt": null}
{"id": "cf632b51-fed3-4a15-8e4d-52e3053bb054", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.994  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Fine-tuned decay factor for enhanced control of component interactions.", "configspace": "", "generation": 49, "fitness": 0.23598131829505506, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.236 with standard deviation 0.006. And the mean value of best solutions found was 0.047 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.23668914613128011, 0.22890276738435844, 0.2423520413695266], "final_y": [0.054665880273898765, 0.042582475975148, 0.04394650895887401]}, "mutation_prompt": null}
{"id": "8a3fd7ec-d4fd-4cf6-a39f-c613147fd348", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995 + 0.0001 * np.sin(self.evaluations / float(self.budget) * np.pi)  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Enhanced quantum component adaptation for improved convergence.", "configspace": "", "generation": 50, "fitness": 0.3060690214957182, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.306 with standard deviation 0.034. And the mean value of best solutions found was 0.002 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.32622904186648616, 0.2588441309641868, 0.33313389165648155], "final_y": [0.0010224355186710056, 0.0027610337412902505, 0.0028343152784755707]}, "mutation_prompt": null}
{"id": "2e5f5da9-6bd0-4a8f-91ac-af48a6012f73", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.02  # Enhanced social component adjustment\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Enhanced social component adjustment for improved convergence precision.", "configspace": "", "generation": 51, "fitness": 0.2973494760263509, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.297 with standard deviation 0.023. And the mean value of best solutions found was 0.010 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.3122332799621489, 0.2652265311450195, 0.31458861697188434], "final_y": [0.005991950096960391, 0.01412070074659716, 0.010842716259045489]}, "mutation_prompt": null}
{"id": "8a5af32b-703d-481e-826c-b892aeaaadb1", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        self.inertia = 0.5 + 0.2 * np.sin(self.evaluations / float(self.budget) * np.pi)  # Enhanced inertia adaptation\n        if self.evaluations > self.budget // 2:\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Enhanced inertia adaptation for improved convergence dynamics in QAPSO_DN.", "configspace": "", "generation": 52, "fitness": 0.2753443645799605, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.275 with standard deviation 0.016. And the mean value of best solutions found was 0.014 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.2668895321027537, 0.2974761580540004, 0.26166740358312734], "final_y": [0.016105203161471453, 0.013969804771336069, 0.010861561759408007]}, "mutation_prompt": null}
{"id": "319aa9dc-cfcd-4cda-bdd4-2d3a04140b40", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component = 1.5 + 0.2 * (self.global_best_score - np.mean(self.personal_best_scores)) / np.std(self.personal_best_scores + 1e-8)\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995", "name": "QAPSO_DN", "description": "Enhanced adaptability by dynamically adjusting the cognitive component based on stagnation.", "configspace": "", "generation": 53, "fitness": 0.29260915229892775, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.293 with standard deviation 0.027. And the mean value of best solutions found was 0.010 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.31766324675393487, 0.2553002344371491, 0.30486397570569934], "final_y": [0.0034281658958455322, 0.01560056755176052, 0.009637222899731079]}, "mutation_prompt": null}
{"id": "891587f9-2d89-4d60-ac41-fb8ddf65af5c", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n\n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        dynamic_learning_rate = 1 + 0.5 * np.sin(self.evaluations / float(self.budget) * np.pi)  # New dynamic learning rate\n        self.cognitive_component *= dynamic_learning_rate  # Adjusted cognitive component\n        self.social_component *= dynamic_learning_rate  # Adjusted social component\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.quantum_component *= 0.995", "name": "QAPSO_DN", "description": "Enhanced local exploitation by incorporating a dynamic learning rate for cognitive and social components.", "configspace": "", "generation": 54, "fitness": 0.22946581724157436, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.229 with standard deviation 0.044. And the mean value of best solutions found was 0.287 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.2066266417127527, 0.19038449671891622, 0.2913863132930542], "final_y": [0.310805432527514, 0.5034921736374184, 0.04539481958398229]}, "mutation_prompt": null}
{"id": "dbd1e2a6-a0f5-4f67-978e-be8ca3f5476a", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Adjusted quantum component decay factor for enhanced convergence stability.", "configspace": "", "generation": 30, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.32835815853289885, 0.25883593344364764, 0.33325685987374176], "final_y": [0.0007812924155456595, 0.0029224013754659797, 0.00280597879648201]}, "mutation_prompt": null}
{"id": "64236c58-dffb-4b61-b657-1842822ecf52", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.7  # Increased from 1.5 to improve local exploration\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995", "name": "QAPSO_DN", "description": "Increased cognitive weighting to enhance local exploration near personal bests.", "configspace": "", "generation": 56, "fitness": 0.2562401002361238, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.256 with standard deviation 0.037. And the mean value of best solutions found was 0.017 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.2078901579951984, 0.2629051668963285, 0.2979249758168445], "final_y": [0.03533556307719741, 0.011786583543780772, 0.002922453221611086]}, "mutation_prompt": null}
{"id": "ee6bb996-278e-4ff0-86bc-a487c5b73272", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.985  # Slightly increased decay for cognitive component\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Slightly increase the decay rate of the cognitive component for fine-tuning control.", "configspace": "", "generation": 57, "fitness": 0.30358986998354826, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.304 with standard deviation 0.028. And the mean value of best solutions found was 0.004 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.31256876692663804, 0.26529964042859233, 0.33290120259541445], "final_y": [0.00471686185244087, 0.004127714972553614, 0.0028338246020608963]}, "mutation_prompt": null}
{"id": "e95fb6b7-3a64-4316-8680-201eb4b4ab7d", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, int((self.evaluations / self.budget) * (self.population_size // 8)))  # Adapted neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Introduced adaptive dynamic neighborhood size in QAPSO_DN for improved convergence.", "configspace": "", "generation": 58, "fitness": 0.3068169839500961, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.307 with standard deviation 0.034. And the mean value of best solutions found was 0.002 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.32835815853289885, 0.25883593344364764, 0.33325685987374176], "final_y": [0.0007812924155456595, 0.0029224013754659797, 0.00280597879648201]}, "mutation_prompt": null}
{"id": "30c55c67-84ca-4b8b-a5f9-30a1561bf4f8", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(np.random.rand() * self.evaluations / float(self.budget) * np.pi)  # Stochastic component added\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Enhanced exploration with stochastic inertia adjustment for improved convergence.", "configspace": "", "generation": 59, "fitness": 0.2959627592947996, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.296 with standard deviation 0.018. And the mean value of best solutions found was 0.007 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.3122332799621489, 0.27084110227393854, 0.3048138956483114], "final_y": [0.005991950096960391, 0.0018272015382799797, 0.012086446773739533]}, "mutation_prompt": null}
{"id": "e56bf301-78a6-4ed8-8180-8c71ca47f1fa", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Adjusted quantum component decay factor for enhanced convergence stability.", "configspace": "", "generation": 30, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.32835815853289885, 0.25883593344364764, 0.33325685987374176], "final_y": [0.0007812924155456595, 0.0029224013754659797, 0.00280597879648201]}, "mutation_prompt": null}
{"id": "2ec22b19-9113-44d2-b7d2-2fa8e3de099f", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia *= 0.99  # Enhanced inertia decay strategy\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Enhanced inertia decay strategy to stabilize convergence towards the global optimum.", "configspace": "", "generation": 61, "fitness": 0.24751276620285043, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.015. And the mean value of best solutions found was 0.031 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.2539356700287164, 0.262393893318016, 0.22620873526181884], "final_y": [0.026868547279986624, 0.025583348777019798, 0.04002218381160935]}, "mutation_prompt": null}
{"id": "a684bd86-356e-4df8-bae8-7e72f94d5043", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size][::2]  # Adjusted to pick every second neighbor for diversity\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Enhanced local neighborhood by introducing diversity in the neighbor selection.", "configspace": "", "generation": 62, "fitness": 0.2834110936183769, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.283 with standard deviation 0.043. And the mean value of best solutions found was 0.012 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.2885048817370559, 0.22847153924433306, 0.33325685987374176], "final_y": [0.012064447804393455, 0.022100545493754724, 0.00280597879648201]}, "mutation_prompt": null}
{"id": "16951ce5-be5b-4455-97ad-9edb765d8c60", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.02  # Increase the influence of the social component\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Introduced a dynamic adjustment to the social component to improve convergence by increasing its influence as the budget progresses.", "configspace": "", "generation": 63, "fitness": 0.2973494760263509, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.297 with standard deviation 0.023. And the mean value of best solutions found was 0.010 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.3122332799621489, 0.2652265311450195, 0.31458861697188434], "final_y": [0.005991950096960391, 0.01412070074659716, 0.010842716259045489]}, "mutation_prompt": null}
{"id": "4cf2928c-614c-4e07-8dc1-d4c03380031b", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Adjusted quantum component decay factor for enhanced convergence stability.", "configspace": "", "generation": 30, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.32835815853289885, 0.25883593344364764, 0.33325685987374176], "final_y": [0.0007812924155456595, 0.0029224013754659797, 0.00280597879648201]}, "mutation_prompt": null}
{"id": "57a16897-a19d-4848-b213-8bc46a94786f", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n            r4 = np.random.random(self.dim)  # New random vector for local intensification\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n            local_intensification = 0.1 * r4 * (self.positions[local_best_position] - self.positions[i])  # Small local search step\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity + local_intensification\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.4 + 0.3 * np.cos(self.evaluations / float(self.budget) * np.pi)  # Changed inertia adaptation\n            self.cognitive_component *= 0.98  # Slight decrease\n            self.social_component *= 1.02  # Slight increase\n            self.quantum_component *= 0.995", "name": "QAPSO_DN", "description": "Improved convergence through adaptive inertia and enhanced local search intensification.", "configspace": "", "generation": 65, "fitness": 0.29389263723912157, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.294 with standard deviation 0.009. And the mean value of best solutions found was 0.001 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.28560404812593665, 0.2897406460661196, 0.3063332175253084], "final_y": [0.0016064705477712789, 0.0014185408225644135, 0.0008699301657675686]}, "mutation_prompt": null}
{"id": "884b0246-39d5-4c11-935d-887249f30863", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Adjusted quantum component decay factor for enhanced convergence stability.", "configspace": "", "generation": 30, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.32835815853289885, 0.25883593344364764, 0.33325685987374176], "final_y": [0.0007812924155456595, 0.0029224013754659797, 0.00280597879648201]}, "mutation_prompt": null}
{"id": "97e96cc1-e95d-489a-9cf5-7a0eb3a02038", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.015  # Slightly increased decay rate for exploration\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Slightly increase the social component decay rate to enhance exploration in later stages. ", "configspace": "", "generation": 67, "fitness": 0.2980137338831962, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.298 with standard deviation 0.021. And the mean value of best solutions found was 0.005 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.29411683670750777, 0.2749370538457995, 0.3249873110962813], "final_y": [0.0020187597335114475, 0.008332606168790366, 0.0040030857884719925]}, "mutation_prompt": null}
{"id": "5221842c-9b51-4d04-b39c-5d581f486de9", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 6)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Tweaked dynamic neighborhood size for enhanced local exploration.", "configspace": "", "generation": 68, "fitness": 0.28393872352883637, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.284 with standard deviation 0.027. And the mean value of best solutions found was 0.007 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.28156300182575356, 0.25272867688546663, 0.31752449187528897], "final_y": [0.0030814900402135613, 0.009482091800520448, 0.009183029721953515]}, "mutation_prompt": null}
{"id": "d9a14e0c-203a-40b8-952a-6119faaa0c14", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component\n        # Dynamically adjust population size based on progress\n        self.population_size = max(20, 40 - int(20 * self.evaluations / self.budget))", "name": "QAPSO_DN", "description": "Optimize performance by dynamically adjusting the population size based on evaluation progress.", "configspace": "", "generation": 69, "fitness": 0.2965705709718159, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.297 with standard deviation 0.012. And the mean value of best solutions found was 0.003 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.28053490284069926, 0.30720522783270376, 0.30197158224204457], "final_y": [0.0031272383565935672, 0.001983987544718389, 0.003912074096821855]}, "mutation_prompt": null}
{"id": "7937163a-5d6d-4ef3-85bf-996e9fff7750", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component\n        self.population_size = max(20, int(40 * (1 - self.evaluations / self.budget)))  # Adaptive population size", "name": "QAPSO_DN", "description": "Introduced adaptive population size for improved convergence dynamics.", "configspace": "", "generation": 70, "fitness": 0.28659450364263567, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.287 with standard deviation 0.032. And the mean value of best solutions found was 0.003 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.28178567775733754, 0.3285476447895147, 0.24945018838105482], "final_y": [0.0018139821196238037, 0.002215186034485839, 0.0041601508281784]}, "mutation_prompt": null}
{"id": "95aaf390-992a-4dbe-8313-4c6da7faef1a", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.9  # Increased initial inertia\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(3, self.population_size // 10)  # Reduced neighborhood size for more exploration\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.4 + 0.3 * np.sin(self.evaluations / float(self.budget) * np.pi)  # Dynamic inertia adaptation\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995", "name": "QAPSO_DN", "description": "Enhanced QAPSO with dynamic inertia and adaptive neighborhood for improved convergence quality.", "configspace": "", "generation": 71, "fitness": 0.2398318659106169, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.240 with standard deviation 0.014. And the mean value of best solutions found was 0.058 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.25319006825119783, 0.2201812229454383, 0.24612430653521455], "final_y": [0.06394954636711025, 0.05021265373619364, 0.06016205777481431]}, "mutation_prompt": null}
{"id": "1f6021f7-8c6f-457c-b3c7-e9dca59c6f05", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.02  # Fine-tuned adaptation for social component\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Fine-tuned the social component's adaptation to enhance convergence by balancing exploration and exploitation.", "configspace": "", "generation": 72, "fitness": 0.2973494760263509, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.297 with standard deviation 0.023. And the mean value of best solutions found was 0.010 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.3122332799621489, 0.2652265311450195, 0.31458861697188434], "final_y": [0.005991950096960391, 0.01412070074659716, 0.010842716259045489]}, "mutation_prompt": null}
{"id": "41280c75-c1eb-4c49-97b2-995933c405d8", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component = 1.5 + 0.5 * (self.evaluations / self.budget)  # Adjusted social component increment\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Enhance convergence by adjusting the social component to increase linearly over iterations.", "configspace": "", "generation": 73, "fitness": 0.2933259050148757, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.293 with standard deviation 0.026. And the mean value of best solutions found was 0.013 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.31329331337330746, 0.2564459974056691, 0.3102384042656505], "final_y": [0.005256601257866042, 0.01718103198282314, 0.015968572397987296]}, "mutation_prompt": null}
{"id": "f34ac7f8-23fa-46f3-a87f-94692d3ccb54", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi) * np.std(self.personal_best_scores) / np.mean(self.personal_best_scores)  # Adjusted inertia weight\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Introduced a dynamic inertia weight adjustment based on solution diversity to enhance convergence.", "configspace": "", "generation": 74, "fitness": 0.2981210687184747, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.298 with standard deviation 0.035. And the mean value of best solutions found was 0.006 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.3138992893184662, 0.25017692107161993, 0.33028699576533804], "final_y": [0.004299137888688106, 0.008962969127364493, 0.0036263241043331413]}, "mutation_prompt": null}
{"id": "0d515fe9-291f-4cd3-ba2f-2672b6bbd273", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.993  # Fine-tuned decay factor for quantum component", "name": "QAPSO_DN", "description": "Fine-tuned quantum component decay factor for improved exploratory behavior.", "configspace": "", "generation": 75, "fitness": 0.30296387757675197, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.303 with standard deviation 0.032. And the mean value of best solutions found was 0.004 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.3140171804161802, 0.2589619769681162, 0.33591247534595947], "final_y": [0.0037726726668567256, 0.007026370333408983, 0.0022592755459009367]}, "mutation_prompt": null}
{"id": "1925815a-4748-4d37-9d0c-7e47da4f1bd7", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * 2 * np.pi)  # Adjusted modulation\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Introduced sinusoidal modulation to inertia, dynamically enhancing exploration-exploitation balance.", "configspace": "", "generation": 76, "fitness": 0.3003459558283447, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.300 with standard deviation 0.026. And the mean value of best solutions found was 0.003 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.320931664821282, 0.2643132531146768, 0.31579294954907544], "final_y": [0.0017326622314443932, 0.001568377484709906, 0.00525712691945489]}, "mutation_prompt": null}
{"id": "0f045ee5-9b0d-4797-9b68-697e65e6d0a9", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.6  # Changed from 1.5 to 1.6\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Improved convergence by slightly enhancing the social component in QAPSO_DN.", "configspace": "", "generation": 77, "fitness": 0.2661431525650306, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.266 with standard deviation 0.036. And the mean value of best solutions found was 0.026 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.25384556065899355, 0.22981396026359946, 0.31476993677249887], "final_y": [0.03269708560477242, 0.0392044566515778, 0.005791354147381704]}, "mutation_prompt": null}
{"id": "63f1369a-aaf7-424d-a3cf-86898ffbb315", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, (self.population_size // 8) + (self.evaluations // (self.budget//10)))\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Enhanced convergence by dynamically adjusting the neighborhood size based on iterations.", "configspace": "", "generation": 78, "fitness": 0.28759818219051464, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.288 with standard deviation 0.035. And the mean value of best solutions found was 0.010 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.2797726329539484, 0.24976505374385383, 0.33325685987374176], "final_y": [0.004358445930200564, 0.022214711620621382, 0.00280597879648201]}, "mutation_prompt": null}
{"id": "f2b09f6a-f7a5-4747-8a17-75325102cb8d", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.2 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Introduce adaptive inertia oscillation for improved exploration-exploitation balance.", "configspace": "", "generation": 79, "fitness": 0.2899054977356437, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.290 with standard deviation 0.025. And the mean value of best solutions found was 0.017 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.3122332799621489, 0.254516529487821, 0.30296668375696134], "final_y": [0.005991950096960391, 0.01740195583036775, 0.026507902868341413]}, "mutation_prompt": null}
{"id": "f4657244-5805-4639-a875-4db600179451", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Adjusted quantum component decay factor for enhanced convergence stability.", "configspace": "", "generation": 30, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.32835815853289885, 0.25883593344364764, 0.33325685987374176], "final_y": [0.0007812924155456595, 0.0029224013754659797, 0.00280597879648201]}, "mutation_prompt": null}
{"id": "7f41c76b-3abc-4003-aa77-0440fbea4258", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Gradually intensify social influence by slightly increasing the social component throughout the optimization process.", "configspace": "", "generation": 81, "fitness": 0.27603937227543807, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.276 with standard deviation 0.016. And the mean value of best solutions found was 0.005 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.26080252067259335, 0.26924339090264393, 0.2980722052510769], "final_y": [0.006158542674531797, 0.004369325927385591, 0.005799337631008724]}, "mutation_prompt": null}
{"id": "8beaad32-4535-4d5e-899e-01be7e9dfb50", "solution": "import numpy as np\n\nclass QAPSO_DN_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.dynamic_population_adjustment()  # Added dynamic population adjustment\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, int(self.population_size / 7))  # Slightly increased neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.98  # Slightly increased decay for cognitive component\n            self.social_component *= 1.02  # Increased growth for social component\n            self.quantum_component *= 0.995\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations < self.budget // 4:\n            self.population_size = min(60, self.population_size + 2)  # Gradually increase population size\n        elif self.evaluations > 3 * self.budget // 4:\n            self.population_size = max(20, self.population_size - 2)  # Gradually decrease population size", "name": "QAPSO_DN_Enhanced", "description": "Enhanced local exploration and dynamic population adjustment for robust convergence.", "configspace": "", "generation": 82, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 40 is out of bounds for axis 0 with size 40').", "error": "IndexError('index 40 is out of bounds for axis 0 with size 40')", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {}, "mutation_prompt": null}
{"id": "46ee790d-d0fe-4343-8988-719acc9f5b1c", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 1.005  # Adjusted growth factor for quantum component", "name": "QAPSO_DN", "description": "Enhanced quantum particle adjustment for improved exploration.", "configspace": "", "generation": 83, "fitness": 0.3026511799197178, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.303 with standard deviation 0.027. And the mean value of best solutions found was 0.003 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.28088928840360594, 0.34068950954743216, 0.2863747418081153], "final_y": [0.0040059933885332934, 0.0018302114988668207, 0.0045418433243990634]}, "mutation_prompt": null}
{"id": "b991ba1c-6418-456d-8e95-c34c5a6abff9", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component\n\n        # Adjusted global best update frequency by skipping some iterations\n        if self.evaluations % 5 == 0:  \n            for i in range(self.population_size):\n                if self.personal_best_scores[i] < self.global_best_score:\n                    self.global_best_score = self.personal_best_scores[i]\n                    self.global_best_position = self.personal_best_positions[i].copy()", "name": "QAPSO_DN", "description": "Enhanced global best position update frequency to improve convergence reliability.", "configspace": "", "generation": 84, "fitness": 0.3068169839500961, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.307 with standard deviation 0.034. And the mean value of best solutions found was 0.002 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.32835815853289885, 0.25883593344364764, 0.33325685987374176], "final_y": [0.0007812924155456595, 0.0029224013754659797, 0.00280597879648201]}, "mutation_prompt": null}
{"id": "f5460cab-4456-4a11-867e-4c99af9f0d7d", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.99  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Reduced the quantum component decay factor for potentially enhanced convergence performance.", "configspace": "", "generation": 85, "fitness": 0.30408161648157833, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.304 with standard deviation 0.033. And the mean value of best solutions found was 0.010 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.3122332799621489, 0.2603867818857606, 0.33962478759682546], "final_y": [0.005991950096960391, 0.02202908562531143, 0.0016681930097102618]}, "mutation_prompt": null}
{"id": "022188f0-7e80-4606-a824-9f0dacccec3c", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.993  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Slightly increased decay rate for the quantum component to boost exploratory capabilities.", "configspace": "", "generation": 86, "fitness": 0.30296387757675197, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.303 with standard deviation 0.032. And the mean value of best solutions found was 0.004 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.3140171804161802, 0.2589619769681162, 0.33591247534595947], "final_y": [0.0037726726668567256, 0.007026370333408983, 0.0022592755459009367]}, "mutation_prompt": null}
{"id": "9b0d8384-efc6-4ad0-b044-75d7ca597b0e", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Adjusted quantum component decay factor for enhanced convergence stability.", "configspace": "", "generation": 30, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.32835815853289885, 0.25883593344364764, 0.33325685987374176], "final_y": [0.0007812924155456595, 0.0029224013754659797, 0.00280597879648201]}, "mutation_prompt": null}
{"id": "efb67a2f-199e-4133-bc25-d5853ef96a5c", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.993  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Enhanced parameter adaptation through a dynamic quantum component adjustment for improved exploration-exploitation balance.", "configspace": "", "generation": 88, "fitness": 0.273960041045179, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.274 with standard deviation 0.014. And the mean value of best solutions found was 0.008 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.2599931452332295, 0.2691835360402022, 0.2927034418621054], "final_y": [0.011358522248710446, 0.004332052687337472, 0.009809113658910022]}, "mutation_prompt": null}
{"id": "b43e0431-7b5a-4314-8f89-3aaf2053870b", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        dynamic_factor = 0.003  # Change made here\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 1 - dynamic_factor  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Optimized quantum component adaptation using a dynamic scaling factor for faster convergence.", "configspace": "", "generation": 89, "fitness": 0.3007916369161359, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.301 with standard deviation 0.031. And the mean value of best solutions found was 0.007 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.31403546897793977, 0.2575173488213748, 0.33082209294909315], "final_y": [0.002041140322351147, 0.015813860626182976, 0.003423934885884235]}, "mutation_prompt": null}
{"id": "36001e5a-9cb3-43ba-aa9b-0a5d084f2e55", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.995  # Adjusted decay factor for cognitive component\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Enhanced stability and convergence by refining the cognitive component decay rate.", "configspace": "", "generation": 90, "fitness": 0.29905487389536706, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.299 with standard deviation 0.030. And the mean value of best solutions found was 0.007 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.3122332799621489, 0.25743355916697475, 0.3274977825569776], "final_y": [0.005991950096960391, 0.01520172589107879, 0.0012989424397212364]}, "mutation_prompt": null}
{"id": "464c5174-7afb-46e1-8c9e-03bf5ee91bca", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.7  # Changed from 0.5 to 0.7 to increase influence\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Enhance global exploration by increasing quantum component influence.", "configspace": "", "generation": 91, "fitness": 0.28653463580093935, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.287 with standard deviation 0.030. And the mean value of best solutions found was 0.012 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.2689531963946884, 0.32863206117004895, 0.26201864983808076], "final_y": [0.023522539924352923, 0.005470786373611986, 0.007579329952341776]}, "mutation_prompt": null}
{"id": "d49cd67d-2101-4923-9c29-be316ff293fb", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        self.inertia = 0.5 + 0.2 * np.sin(self.evaluations / float(self.budget) * np.pi)  # Adjusted inertia factor\n        if self.evaluations > self.budget // 2:\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Introduced adaptive adjustment to the inertia factor for enhanced convergence stability.", "configspace": "", "generation": 92, "fitness": 0.2753443645799605, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.275 with standard deviation 0.016. And the mean value of best solutions found was 0.014 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.2668895321027537, 0.2974761580540004, 0.26166740358312734], "final_y": [0.016105203161471453, 0.013969804771336069, 0.010861561759408007]}, "mutation_prompt": null}
{"id": "f7f5b293-f5b1-4d2f-bd4b-5c67673f80ab", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(6, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Improved dynamic neighborhood strategy by increasing neighborhood size for better local exploration.", "configspace": "", "generation": 93, "fitness": 0.28393872352883637, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.284 with standard deviation 0.027. And the mean value of best solutions found was 0.007 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.28156300182575356, 0.25272867688546663, 0.31752449187528897], "final_y": [0.0030814900402135613, 0.009482091800520448, 0.009183029721953515]}, "mutation_prompt": null}
{"id": "15cf92c7-9312-40e8-a721-37fa0dda2263", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Adjusted quantum component decay factor for enhanced convergence stability.", "configspace": "", "generation": 30, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.32835815853289885, 0.25883593344364764, 0.33325685987374176], "final_y": [0.0007812924155456595, 0.0029224013754659797, 0.00280597879648201]}, "mutation_prompt": null}
{"id": "d3bedf93-2d53-4eed-b864-377768fe58bc", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(6, self.population_size // 8)  # Slightly increased neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Introduced a slight increase to the neighborhood size for enhanced local exploration.", "configspace": "", "generation": 95, "fitness": 0.27016871641634294, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.270 with standard deviation 0.039. And the mean value of best solutions found was 0.013 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.2176249262525196, 0.28312525892852414, 0.309755964067985], "final_y": [0.021097509894695058, 0.0074920955559163605, 0.011520762280384785]}, "mutation_prompt": null}
{"id": "7f5776b9-9d20-4e5a-8e52-bfe00f58c5b0", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(6, self.population_size // 8)  # Changed neighborhood size to 6\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Enhanced local neighborhood influence by updating the neighborhood size for improved exploration-exploitation balance.", "configspace": "", "generation": 96, "fitness": 0.28393872352883637, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.284 with standard deviation 0.027. And the mean value of best solutions found was 0.007 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.28156300182575356, 0.25272867688546663, 0.31752449187528897], "final_y": [0.0030814900402135613, 0.009482091800520448, 0.009183029721953515]}, "mutation_prompt": null}
{"id": "ac7cce32-7b1c-4e46-89e4-3dc39a4b6d59", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = (self.cognitive_component * (0.5 + 0.5 * np.sin(self.evaluations / float(self.budget) * np.pi))) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Introduced a dynamic scaling of the cognitive component to improve balance between exploration and exploitation.", "configspace": "", "generation": 97, "fitness": 0.2761819944898745, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.276 with standard deviation 0.015. And the mean value of best solutions found was 0.011 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.26502770828857425, 0.26622017673674825, 0.297298098444301], "final_y": [0.004683113263901072, 0.013079348028955655, 0.016571672188836574]}, "mutation_prompt": null}
{"id": "70323d4e-1175-4f48-acfc-30a06259221e", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(6, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component *= 0.99\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Incrementally enhance algorithm by slightly adjusting neighborhood size for better local convergence.", "configspace": "", "generation": 98, "fitness": 0.28393872352883637, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.284 with standard deviation 0.027. And the mean value of best solutions found was 0.007 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.28156300182575356, 0.25272867688546663, 0.31752449187528897], "final_y": [0.0030814900402135613, 0.009482091800520448, 0.009183029721953515]}, "mutation_prompt": null}
{"id": "85ba43b0-5bf4-4550-b769-1f9fe17b2ce0", "solution": "import numpy as np\n\nclass QAPSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.inertia = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.quantum_component = 0.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        self.init_population(func.bounds.lb, func.bounds.ub)\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_velocities_and_positions(func.bounds.lb, func.bounds.ub)\n            self.adapt_parameters()\n        return self.global_best_position, self.global_best_score\n\n    def init_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.population_size):\n            local_neighbors = self.get_dynamic_neighborhood(i)\n            local_best_position = min(local_neighbors, key=lambda x: self.personal_best_scores[x])\n            \n            r1 = np.random.random(self.dim)\n            r2 = np.random.random(self.dim)\n            r3 = np.random.random(self.dim)\n\n            cognitive_velocity = self.cognitive_component * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.social_component * r2 * (self.personal_best_positions[local_best_position] - self.positions[i])\n            quantum_velocity = self.quantum_component * r3 * (self.global_best_position - self.positions[i])\n\n            self.velocities[i] = self.inertia * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def get_dynamic_neighborhood(self, index):\n        neighborhood_size = max(5, self.population_size // 8)  # Changed neighborhood size\n        distances = np.linalg.norm(self.positions - self.positions[index], axis=1)\n        neighbors = np.argsort(distances)\n        return neighbors[:neighborhood_size]\n\n    def adapt_parameters(self):\n        if self.evaluations > self.budget // 2:\n            self.inertia = 0.5 + 0.1 * np.sin(self.evaluations / float(self.budget) * np.pi)\n            self.cognitive_component = 1.5 + 0.5 * np.cos(self.evaluations / float(self.budget) * np.pi)  # Changed line\n            self.social_component *= 1.01\n            self.quantum_component *= 0.995  # Adjusted decay factor for quantum component", "name": "QAPSO_DN", "description": "Dynamic adjustment of cognitive component to enhance exploration-exploitation balance.", "configspace": "", "generation": 99, "fitness": 0.2937848340278315, "feedback": "The algorithm QAPSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.294 with standard deviation 0.025. And the mean value of best solutions found was 0.009 (0. is the best).", "error": "", "parent_id": "c6ab56e8-d3b5-4e6b-81f0-ef4b82fbacdc", "metadata": {"aucs": [0.3122332799621489, 0.2588778698590013, 0.31024335226234434], "final_y": [0.005991950096960391, 0.016952720657754824, 0.004413576296438641]}, "mutation_prompt": null}

{"id": "6d29ec26-8794-4565-87ad-e16477a1af47", "solution": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.temperature = 1000\n        self.cooling_rate = 0.95\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity)\n                \n                # Update particle position\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Simulated Annealing local search\n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                # Update temperature\n                self.temperature *= self.cooling_rate\n                \n        return self.global_best_position", "name": "HybridPSO_SA", "description": "A hybrid Particle Swarm Optimization (PSO) with Simulated Annealing (SA) approach, combining the exploration capabilities of PSO with the exploitation abilities of SA to efficiently navigate the search space.", "configspace": "", "generation": 0, "fitness": 0.08737264075860651, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.087 with standard deviation 0.003. And the mean value of best solutions found was 0.176 (0. is the best).", "error": "", "parent_id": null, "metadata": {"aucs": [0.0878782825250135, 0.0901818018339452, 0.08405783791686083], "final_y": [0.18541089621358497, 0.1683859532859009, 0.1748978695649961]}, "mutation_prompt": null}
{"id": "d03600e6-bd9f-4635-ac7e-b6af168c5cf3", "solution": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.7  # Adjusted from 1.5 to 1.7\n        self.social_coef = 1.5\n        self.temperature = 1000\n        self.cooling_rate = 0.95\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity)\n                \n                # Update particle position\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Simulated Annealing local search\n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                # Update temperature\n                self.temperature *= self.cooling_rate\n                \n        return self.global_best_position", "name": "HybridPSO_SA", "description": "Fine-tuning the cognitive coefficient to enhance local search efficiency.", "configspace": "", "generation": 1, "fitness": 0.08116965283612898, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.081 with standard deviation 0.008. And the mean value of best solutions found was 0.204 (0. is the best).", "error": "", "parent_id": "6d29ec26-8794-4565-87ad-e16477a1af47", "metadata": {"aucs": [0.08727217567711709, 0.06921543210805137, 0.08702135072321848], "final_y": [0.18454753157025938, 0.258690447546986, 0.16876133345624866]}, "mutation_prompt": null}
{"id": "46323a98-71fc-4db6-bbfc-e537eb85a174", "solution": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_agents = min(30, budget//10)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.agents = np.random.rand(self.num_agents, self.dim)\n        self.best_agent = None\n        self.best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.agents = lb + (ub - lb) * np.random.rand(self.num_agents, self.dim)\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_agents):\n                indices = list(range(self.num_agents))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(self.agents[a] + self.mutation_factor * (self.agents[b] - self.agents[c]), lb, ub)\n                trial_vector = np.copy(self.agents[i])\n                \n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_prob:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < func(self.agents[i]):\n                    self.agents[i] = trial_vector\n                \n                if trial_score < self.best_score:\n                    self.best_score = trial_score\n                    self.best_agent = trial_vector\n            \n            # Adaptive mutation and crossover\n            if evaluations < self.budget/2:\n                self.mutation_factor = np.random.uniform(0.5, 1.0)\n                self.crossover_prob = np.random.uniform(0.6, 0.9)\n            else:\n                self.mutation_factor = np.random.uniform(0.4, 0.9)\n                self.crossover_prob = np.random.uniform(0.5, 0.8)\n        \n        return self.best_agent", "name": "AdaptiveDE", "description": "Differential Evolution with Adaptive Mutation and Crossover Rates, dynamically adjusting parameters to enhance exploration and exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.07327138219222125, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.073 with standard deviation 0.003. And the mean value of best solutions found was 0.197 (0. is the best).", "error": "", "parent_id": "6d29ec26-8794-4565-87ad-e16477a1af47", "metadata": {"aucs": [0.07530873456229747, 0.06893209314026938, 0.0755733188740969], "final_y": [0.1904559270347016, 0.2297399758284313, 0.17058182471283645]}, "mutation_prompt": null}
{"id": "a2c9ff24-fa07-46a7-aea5-8ad11774a6ae", "solution": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.temperature = 1000\n        self.cooling_rate = 0.95\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            # Adaptive inertia weight\n            self.inertia_weight = 0.4 + (0.9 - 0.4) * (1 - evaluations / self.budget)\n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity)\n                \n                # Update particle position\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Simulated Annealing local search\n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                # Update temperature\n                self.temperature *= self.cooling_rate\n                \n        return self.global_best_position", "name": "HybridPSO_SA", "description": "Introduced adaptive inertia weight in HybridPSO_SA to enhance exploration-exploitation balance through dynamic adjustment based on iterations.", "configspace": "", "generation": 3, "fitness": 0.07977879291461847, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.080 with standard deviation 0.009. And the mean value of best solutions found was 0.180 (0. is the best).", "error": "", "parent_id": "6d29ec26-8794-4565-87ad-e16477a1af47", "metadata": {"aucs": [0.07100730942963296, 0.09181237016403121, 0.07651669915019121], "final_y": [0.18240783197901234, 0.16568577697935682, 0.19064933268705087]}, "mutation_prompt": null}
{"id": "50eb7ba3-9a65-44a1-9891-eaf1ecf27b9c", "solution": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.temperature = 1000\n        self.cooling_rate = 0.98  # Changed from 0.95 to 0.98\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity)\n                \n                # Update particle position\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Simulated Annealing local search\n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                # Update temperature\n                self.temperature *= self.cooling_rate\n                \n        return self.global_best_position", "name": "HybridPSO_SA", "description": "A refined hybrid PSO-SA algorithm with an enhanced cooling rate for better convergence.", "configspace": "", "generation": 4, "fitness": 0.08690147520194254, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.087 with standard deviation 0.005. And the mean value of best solutions found was 0.180 (0. is the best).", "error": "", "parent_id": "6d29ec26-8794-4565-87ad-e16477a1af47", "metadata": {"aucs": [0.0870990572208904, 0.0933131090667132, 0.08029225931822404], "final_y": [0.188869735011015, 0.16576106071187313, 0.18485051025297983]}, "mutation_prompt": null}
{"id": "09deb2ae-0053-445f-b44a-975ca40f76b5", "solution": "import numpy as np\n\nclass ACO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_ants = min(30, budget // 10)\n        self.pheromone = np.ones((dim, 2))\n        self.alpha = 1.0\n        self.beta = 2.0\n        self.evaporation_rate = 0.5\n        self.f = 0.5  # DE mutation factor\n        self.cr = 0.7  # DE crossover probability\n        self.best_solution = None\n        self.best_score = float('inf')\n\n    def _select_route(self, lower_bound, upper_bound):\n        route = np.zeros(self.dim)\n        for i in range(self.dim):\n            norm_pheromone = self.pheromone[i] / np.sum(self.pheromone[i])\n            if np.random.rand() < norm_pheromone[0]:\n                route[i] = lower_bound[i] + np.random.rand() * (upper_bound[i] - lower_bound[i])\n            else:\n                route[i] = upper_bound[i] - np.random.rand() * (upper_bound[i] - lower_bound[i])\n        return route\n\n    def _apply_de(self, population, lb, ub):\n        new_population = np.copy(population)\n        for i in range(self.num_ants):\n            idxs = [idx for idx in range(self.num_ants) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.cr\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            new_population[i] = np.where(cross_points, mutant, population[i])\n        return new_population\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.array([self._select_route(lb, ub) for _ in range(self.num_ants)])\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.num_ants\n\n            best_ant_idx = np.argmin(scores)\n            if scores[best_ant_idx] < self.best_score:\n                self.best_score = scores[best_ant_idx]\n                self.best_solution = population[best_ant_idx]\n\n            # Update pheromone trails\n            for i in range(self.dim):\n                if np.random.rand() < self.evaporation_rate:\n                    self.pheromone[i] *= (1 - self.evaporation_rate)\n                    self.pheromone[i][0] += self.alpha / (1.0 + scores[best_ant_idx])\n                    self.pheromone[i][1] += self.beta / (1.0 + self.best_score)\n\n            # Apply Differential Evolution to refine solutions\n            population = self._apply_de(population, lb, ub)\n\n        return self.best_solution", "name": "ACO_DE", "description": "Bio-inspired Ant Colony Optimization (ACO) with Differential Evolution (DE) for adaptive exploration and exploitation in black-box optimization.", "configspace": "", "generation": 5, "fitness": 0.06484880851606385, "feedback": "The algorithm ACO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.065 with standard deviation 0.007. And the mean value of best solutions found was 0.266 (0. is the best).", "error": "", "parent_id": "6d29ec26-8794-4565-87ad-e16477a1af47", "metadata": {"aucs": [0.0606523552228837, 0.07487339210163668, 0.059020678223671186], "final_y": [0.2885435346177666, 0.20510357474981722, 0.3044330371697618]}, "mutation_prompt": null}
{"id": "8b216b7c-2000-43c7-b0d0-c2e48af31839", "solution": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9  # Initially increased for better exploration\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.temperature = 1000\n        self.cooling_rate = 0.95\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity)\n                \n                # Update particle position\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Simulated Annealing local search\n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                # Update temperature\n                self.temperature *= self.cooling_rate\n                \n        return self.global_best_position", "name": "HybridPSO_SA", "description": "Enhanced inertia weight dynamic adaptation in HybridPSO_SA to improve exploration-exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.06830683170286696, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.068 with standard deviation 0.005. And the mean value of best solutions found was 0.284 (0. is the best).", "error": "", "parent_id": "6d29ec26-8794-4565-87ad-e16477a1af47", "metadata": {"aucs": [0.06250726133098417, 0.07395334406958265, 0.06845988970803407], "final_y": [0.3158458172087827, 0.25519819266147215, 0.2821556563339378]}, "mutation_prompt": null}
{"id": "31777045-432b-4800-8dd0-80bd063f2897", "solution": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.temperature = 1000\n        self.cooling_rate = 0.95\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = ((0.5 + np.random.rand() / 2) * self.velocities[i] +\n                                      cognitive_velocity + social_velocity) # Changed line: adaptive inertia weight\n                \n                # Update particle position\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Simulated Annealing local search\n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                # Update temperature\n                self.temperature *= self.cooling_rate\n                \n        return self.global_best_position", "name": "HybridPSO_SA", "description": "Enhance exploration by introducing adaptive inertia weight adjustment in Particle Swarm Optimization (PSO).", "configspace": "", "generation": 7, "fitness": 0.08590203346876098, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.086 with standard deviation 0.002. And the mean value of best solutions found was 0.177 (0. is the best).", "error": "", "parent_id": "6d29ec26-8794-4565-87ad-e16477a1af47", "metadata": {"aucs": [0.0837073010667615, 0.08478963946292317, 0.08920915987659828], "final_y": [0.18838140969025674, 0.17441955882218463, 0.16841773504896573]}, "mutation_prompt": null}
{"id": "cf2e3517-59c0-4955-b55f-7419532be3f6", "solution": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9  # Increased initial inertia weight for exploration\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.temperature = 1000\n        self.cooling_rate = 0.95\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity)\n                \n                # Update particle position\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Simulated Annealing local search\n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                # Update temperature\n                self.temperature *= self.cooling_rate\n                \n            # Adaptive inertia weight update\n            self.inertia_weight *= 0.99  # Gradually decrease inertia weight to focus on exploitation\n                \n        return self.global_best_position", "name": "HybridPSO_SA", "description": "Enhanced Hybrid PSO-SA with adaptive inertia weight for improved convergence.", "configspace": "", "generation": 8, "fitness": 0.08807320114420847, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.088 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "6d29ec26-8794-4565-87ad-e16477a1af47", "metadata": {"aucs": [0.08659869826876898, 0.0914108161633912, 0.08621008900046523], "final_y": [0.1649724756104517, 0.16494648287017533, 0.16626639011638134]}, "mutation_prompt": null}
{"id": "08f6d59d-4260-4fd3-b940-6a7e7c4cc7c9", "solution": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9  # Increased initial inertia weight for exploration\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.temperature = 1000\n        self.cooling_rate = 0.95\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity)\n                \n                # Update particle position\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Simulated Annealing local search\n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                # Update temperature\n                self.temperature *= self.cooling_rate\n                \n            # Adaptive inertia weight update\n            self.inertia_weight *= 0.985  # Gradually decrease inertia weight to focus on exploitation\n                \n        return self.global_best_position", "name": "HybridPSO_SA", "description": "Improved convergence by adjusting the inertia weight to decrease more rapidly, enhancing exploitation in later stages.", "configspace": "", "generation": 9, "fitness": 0.08597676372670189, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.086 with standard deviation 0.004. And the mean value of best solutions found was 0.169 (0. is the best).", "error": "", "parent_id": "cf2e3517-59c0-4955-b55f-7419532be3f6", "metadata": {"aucs": [0.08496130971475269, 0.0912049048223198, 0.0817640766430332], "final_y": [0.16616024997234158, 0.16500967366870134, 0.17692535285221844]}, "mutation_prompt": null}
{"id": "fb269e06-14d8-426c-b4c2-65fe6ba233d9", "solution": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9  # Initial inertia weight\n        self.cognitive_coef = 2.0  # Increased cognitive coefficient\n        self.social_coef = 1.5\n        self.temperature = 1000\n        self.cooling_rate = 0.9  # Faster cooling rate\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            elite_index = np.argmin(self.personal_best_scores)  # Identify elite\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            for i in range(self.num_particles):\n                if i == elite_index: continue  # Elite does not change\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity)\n                \n                # Update particle position\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Simulated Annealing local search\n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)  # Reduced noise\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                # Update temperature\n                self.temperature *= self.cooling_rate\n                \n            # Adaptive inertia weight update\n            self.inertia_weight *= 0.99\n                \n        return self.global_best_position", "name": "HybridPSO_SA", "description": "Enhanced Hybrid PSO-SA with adaptive parameters and elite strategy for better convergence.", "configspace": "", "generation": 10, "fitness": 0.07282792900805442, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.073 with standard deviation 0.004. And the mean value of best solutions found was 0.188 (0. is the best).", "error": "", "parent_id": "cf2e3517-59c0-4955-b55f-7419532be3f6", "metadata": {"aucs": [0.06839484268640539, 0.077343251453029, 0.07274569288472887], "final_y": [0.20314683725834404, 0.1835716352558483, 0.17849418161585473]}, "mutation_prompt": null}
{"id": "1f273137-107e-4b6b-8977-b7de27dc913c", "solution": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9  # Increased initial inertia weight for exploration\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.temperature = 1000\n        self.cooling_rate = 0.98  # Improved cooling rate for better convergence\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity)\n                \n                # Update particle position\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Simulated Annealing local search\n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                # Update temperature\n                self.temperature *= self.cooling_rate\n                \n            # Adaptive inertia weight update\n            self.inertia_weight *= 0.99  # Gradually decrease inertia weight to focus on exploitation\n                \n        return self.global_best_position", "name": "HybridPSO_SA", "description": "Enhanced Hybrid PSO-SA with adaptive inertia weight and improved cooling strategy for better convergence.", "configspace": "", "generation": 11, "fitness": 0.08764830105346177, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.088 with standard deviation 0.003. And the mean value of best solutions found was 0.166 (0. is the best).", "error": "", "parent_id": "cf2e3517-59c0-4955-b55f-7419532be3f6", "metadata": {"aucs": [0.08621933196708509, 0.09132716620248882, 0.08539840499081142], "final_y": [0.16604565763270063, 0.16632255518094163, 0.16549984570528942]}, "mutation_prompt": null}
{"id": "41a5f5a3-71eb-4b38-b084-ae68b4bef560", "solution": "import numpy as np\n\nclass AdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget // 10)\n        self.inertia_weight = 0.7  # Dynamic inertia weight for balanced exploration and exploitation\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            phi = self.cognitive_coef + self.social_coef\n            chi = 2 / abs(2 - phi - np.sqrt(phi**2 - 4*phi))\n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = chi * (self.velocities[i] +\n                                            cognitive_velocity + social_velocity)\n                \n                # Update particle position with quantum behavior\n                new_position = self.particles[i] + self.velocities[i]\n                if np.random.rand() < 0.1:  # Quantum tunneling probability\n                    new_position = lb + (ub - lb) * np.random.rand(self.dim)\n                \n                # Dynamic boundary handling\n                self.particles[i] = np.where(new_position < lb, lb + 0.1 * (ub - lb), new_position)\n                self.particles[i] = np.where(new_position > ub, ub - 0.1 * (ub - lb), new_position)\n                \n                # Adaptive inertia weight update\n                self.inertia_weight = 0.9 - evaluations / self.budget * 0.5\n        \n        return self.global_best_position", "name": "AdaptiveQuantumPSO", "description": "Adaptive Quantum-based Particle Swarm Optimization (AQPSO) with dynamic boundary handling for robust global search.", "configspace": "", "generation": 12, "fitness": 0.061299660517896405, "feedback": "The algorithm AdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.061 with standard deviation 0.002. And the mean value of best solutions found was 0.309 (0. is the best).", "error": "", "parent_id": "cf2e3517-59c0-4955-b55f-7419532be3f6", "metadata": {"aucs": [0.06446523318819075, 0.059182860783948854, 0.06025088758154962], "final_y": [0.2824208090323097, 0.3223779115630361, 0.3233284618542538]}, "mutation_prompt": null}
{"id": "1339e528-958c-4683-b103-d2ec88e8c258", "solution": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9  # Increased initial inertia weight for exploration\n        self.cognitive_coef = 1.8  # Increased cognitive coefficient to enhance personal exploration\n        self.social_coef = 1.5\n        self.temperature = 1000\n        self.cooling_rate = 0.95\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity)\n                \n                # Update particle position\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Simulated Annealing local search\n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                # Update temperature\n                self.temperature *= self.cooling_rate\n                \n            # Adaptive inertia weight update\n            self.inertia_weight *= 0.99  # Gradually decrease inertia weight to focus on exploitation\n                \n        return self.global_best_position", "name": "HybridPSO_SA", "description": "Enhanced Hybrid PSO-SA with increased cognitive coefficient for improved individual exploration.", "configspace": "", "generation": 13, "fitness": 0.07859217540913015, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.079 with standard deviation 0.010. And the mean value of best solutions found was 0.202 (0. is the best).", "error": "", "parent_id": "cf2e3517-59c0-4955-b55f-7419532be3f6", "metadata": {"aucs": [0.08122221650003447, 0.08903317272863753, 0.06552113699871842], "final_y": [0.18343516288174888, 0.1653433650806274, 0.25858002025462723]}, "mutation_prompt": null}
{"id": "0bb3b074-1fb9-427b-bb4d-d5a78f35363b", "solution": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9  # Increased initial inertia weight for exploration\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.temperature = 1000\n        self.cooling_rate = 0.95\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity)\n                \n                # Dynamic velocity clamping\n                vel_max = 0.1 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                # Update particle position\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Simulated Annealing local search\n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                # Update temperature\n                self.temperature *= self.cooling_rate\n                \n            # Adaptive inertia weight update\n            self.inertia_weight *= 0.99  # Gradually decrease inertia weight to focus on exploitation\n                \n        return self.global_best_position", "name": "HybridPSO_SA", "description": "Enhanced Hybrid PSO-SA with dynamic velocity clamping for improved exploration-exploitation balance.", "configspace": "", "generation": 14, "fitness": 0.09575137783905467, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "cf2e3517-59c0-4955-b55f-7419532be3f6", "metadata": {"aucs": [0.09568498874601428, 0.09640943116488176, 0.09515971360626796], "final_y": [0.16506571290434335, 0.16497560562378433, 0.1651247238090784]}, "mutation_prompt": null}
{"id": "0953c040-8ab6-4258-99bd-1ec958aea904", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // 10)\n        self.quantum_bits = np.random.rand(self.population_size, dim)\n        self.population = np.zeros((self.population_size, dim))\n        self.best_solution = np.zeros(dim)\n        self.best_score = float('inf')\n        self.alpha = 0.75  # Quantum interference control\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        def measure(qubit):\n            return np.where(np.random.rand(self.dim) < qubit, 1, 0)\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                self.population[i] = measure(self.quantum_bits[i])\n                self.population[i] = lb + self.population[i] * (ub - lb)\n                score = func(self.population[i])\n                evaluations += 1\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = np.copy(self.population[i])\n            \n            # Quantum rotation gate update\n            for i in range(self.population_size):\n                probability_update = self.alpha * (self.best_solution - self.population[i]) / (ub - lb)\n                self.quantum_bits[i] = np.clip(self.quantum_bits[i] + probability_update, 0, 1)\n                \n        return self.best_solution", "name": "QuantumInspiredEA", "description": "Quantum-Inspired Evolutionary Algorithm (QIEA) using quantum bits and population dynamics for exploration and exploitation.", "configspace": "", "generation": 15, "fitness": 0.004722483486963025, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.005 with standard deviation 0.000. And the mean value of best solutions found was 0.918 (0. is the best).", "error": "", "parent_id": "0bb3b074-1fb9-427b-bb4d-d5a78f35363b", "metadata": {"aucs": [0.004722483486963025, 0.004722483486963025, 0.004722483486963025], "final_y": [0.9183673469387754, 0.9183673469387754, 0.9183673469387754]}, "mutation_prompt": null}
{"id": "ea7acfc1-4f1c-4f04-9e37-a9c3dea1bd6d", "solution": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9  # Increased initial inertia weight for exploration\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.temperature = 1000\n        self.cooling_rate = 0.95\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity)\n                \n                # Dynamic velocity clamping\n                vel_max = 0.2 * (ub - lb)  # Changed from 0.1 to 0.2\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                # Update particle position\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Simulated Annealing local search\n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                # Update temperature\n                self.temperature *= self.cooling_rate\n                \n            # Adaptive inertia weight update\n            self.inertia_weight *= 0.99  # Gradually decrease inertia weight to focus on exploitation\n                \n        return self.global_best_position", "name": "HybridPSO_SA", "description": "Improved exploration by adjusting the maximum velocity scaling factor.", "configspace": "", "generation": 16, "fitness": 0.09202696131128547, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.092 with standard deviation 0.002. And the mean value of best solutions found was 0.171 (0. is the best).", "error": "", "parent_id": "0bb3b074-1fb9-427b-bb4d-d5a78f35363b", "metadata": {"aucs": [0.08941014397707281, 0.09498643466509438, 0.09168430529168925], "final_y": [0.18210026724727524, 0.16494421757877065, 0.16515356599785058]}, "mutation_prompt": null}
{"id": "64b91ae8-9258-46f4-ac42-6e053297c792", "solution": "import numpy as np\n\nclass AdaptiveHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget // 10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.initial_temperature = 1000\n        self.min_temperature = 1\n        self.cooling_rate = 0.9\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        temperature = self.initial_temperature\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity)\n                \n                vel_max = 0.1 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Variable Neighborhood Search\n                neighborhood_radius = 0.05 * (ub - lb)\n                for _ in range(5):\n                    candidate_position = new_position + np.random.uniform(-neighborhood_radius, neighborhood_radius, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n\n                temperature = max(self.min_temperature, temperature * self.cooling_rate)\n                \n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Ensuring inertia weight does not fall below a minimum threshold\n                \n        return self.global_best_position", "name": "AdaptiveHybridPSO_SA", "description": "Adaptive Hybrid PSO-SA with variable neighborhood search and adaptive cooling to enhance convergence and solution quality.", "configspace": "", "generation": 17, "fitness": 0.09381401966641478, "feedback": "The algorithm AdaptiveHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.094 with standard deviation 0.001. And the mean value of best solutions found was 0.168 (0. is the best).", "error": "", "parent_id": "0bb3b074-1fb9-427b-bb4d-d5a78f35363b", "metadata": {"aucs": [0.0945054554363709, 0.09307079555290643, 0.09386580800996702], "final_y": [0.16905206676110085, 0.16822062518906888, 0.1673238729639287]}, "mutation_prompt": null}
{"id": "3bfef704-6d43-49c8-bf4e-7004616c7faa", "solution": "import numpy as np\n\nclass QuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget // 10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity)\n\n                # Quantum-inspired update: introduce a random mutation effect\n                mutation_probability = 0.1\n                if np.random.rand() < mutation_probability:\n                    quantum_shift = np.random.uniform(size=self.dim) * (ub - lb) * 0.05\n                    self.particles[i] = np.clip(self.particles[i] + quantum_shift, lb, ub)\n\n                # Update particle position\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                self.particles[i] = new_position\n\n            # Update inertia weight dynamically\n            self.inertia_weight *= 0.99  # Gradually decrease inertia weight\n\n        return self.global_best_position", "name": "QuantumPSO", "description": "Quantum-inspired Particle Swarm Optimization with dynamic mutation for enhanced global search capabilities.", "configspace": "", "generation": 18, "fitness": 0.09224556107230186, "feedback": "The algorithm QuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.092 with standard deviation 0.002. And the mean value of best solutions found was 0.171 (0. is the best).", "error": "", "parent_id": "0bb3b074-1fb9-427b-bb4d-d5a78f35363b", "metadata": {"aucs": [0.08982665612137475, 0.09344438116992237, 0.09346564592560846], "final_y": [0.18187815100164773, 0.16485579609241674, 0.16485583302352902]}, "mutation_prompt": null}
{"id": "6ccccd85-afba-4527-96a6-6f3dd44b259b", "solution": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.initial_temperature = 1000  # Use initial_temperature to reset temperature each iteration\n        self.cooling_rate = 0.9  # Adjust cooling rate for faster convergence\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature  # Reset temperature each cycle\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity)\n                \n                # Dynamic velocity clamping\n                vel_max = 0.1 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                # Update particle position\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Simulated Annealing local search\n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.5, self.dim)  # Adjusted standard deviation for finer search\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                # Update temperature\n                self.temperature *= self.cooling_rate\n                \n            # Adaptive inertia weight update\n            self.inertia_weight *= 0.99\n                \n        return self.global_best_position", "name": "HybridPSO_SA", "description": "Optimized HybridPSO_SA with adaptive temperature adjustment and enhanced local search for superior convergence.", "configspace": "", "generation": 19, "fitness": 0.09628180573094498, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "0bb3b074-1fb9-427b-bb4d-d5a78f35363b", "metadata": {"aucs": [0.09635208827249675, 0.0964194096033294, 0.09607391931700882], "final_y": [0.16487834671618196, 0.1648690472996277, 0.164878223166385]}, "mutation_prompt": null}
{"id": "bd02ea01-6cb1-4064-aff0-44288cc99056", "solution": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.initial_temperature = 1000  # Use initial_temperature to reset temperature each iteration\n        self.cooling_rate = 0.9  # Adjust cooling rate for faster convergence\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature  # Reset temperature each cycle\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = (self.social_coef + 0.1) * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity)\n                \n                # Dynamic velocity clamping\n                vel_max = 0.1 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                # Update particle position\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Simulated Annealing local search\n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.5, self.dim)  # Adjusted standard deviation for finer search\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                # Update temperature\n                self.temperature *= self.cooling_rate\n                \n            # Adaptive inertia weight update\n            self.inertia_weight *= 0.99\n                \n        return self.global_best_position", "name": "HybridPSO_SA", "description": "Introduced adaptive social coefficient adjustment to balance exploration and exploitation.", "configspace": "", "generation": 20, "fitness": 0.09603528778299734, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "6ccccd85-afba-4527-96a6-6f3dd44b259b", "metadata": {"aucs": [0.096129736724055, 0.09648908409091561, 0.0954870425340214], "final_y": [0.16487930893999592, 0.1648754035407658, 0.16488309689414116]}, "mutation_prompt": null}
{"id": "c3db0cf0-332c-453a-8183-381857414311", "solution": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.initial_temperature = 1000  # Use initial_temperature to reset temperature each iteration\n        self.cooling_rate = 0.9  # Adjust cooling rate for faster convergence\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature  # Reset temperature each cycle\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity)\n                \n                # Dynamic velocity clamping\n                vel_max = 0.1 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                # Update particle position\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Simulated Annealing local search\n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.5, self.dim)  # Adjusted standard deviation for finer search\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                # Update temperature\n                self.temperature *= self.cooling_rate\n                \n            # Adaptive inertia weight update\n            self.inertia_weight *= 0.99\n                \n        return self.global_best_position", "name": "HybridPSO_SA", "description": "Introduced a dynamic cognitive coefficient for better exploration-exploitation balance in PSO.", "configspace": "", "generation": 21, "fitness": 0.09634746111864945, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "6ccccd85-afba-4527-96a6-6f3dd44b259b", "metadata": {"aucs": [0.09636340244868535, 0.09652514943636703, 0.09615383147089596], "final_y": [0.16488314321087083, 0.16488124900304713, 0.16487496382822442]}, "mutation_prompt": null}
{"id": "52f4504f-69b0-4c05-baad-b773c26176fe", "solution": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.initial_temperature = 1000  # Use initial_temperature to reset temperature each iteration\n        self.cooling_rate = 0.9  # Adjust cooling rate for faster convergence\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature  # Reset temperature each cycle\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity)\n                \n                # Dynamic velocity clamping\n                vel_max = 0.1 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                # Update particle position\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Simulated Annealing local search\n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.5, self.dim)  # Adjusted standard deviation for finer search\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                # Update temperature\n                self.temperature *= self.cooling_rate\n                \n            # Adaptive inertia weight update\n            self.inertia_weight *= 0.995\n                \n        return self.global_best_position", "name": "HybridPSO_SA", "description": "Improved inertia weight adaptation speed by adjusting the decay rate for better convergence.", "configspace": "", "generation": 22, "fitness": 0.09601422835148536, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "c3db0cf0-332c-453a-8183-381857414311", "metadata": {"aucs": [0.09612475724922043, 0.09655421370648687, 0.09536371409874878], "final_y": [0.1648773425499508, 0.16488362908622123, 0.16490495443148634]}, "mutation_prompt": null}
{"id": "1067541a-97fd-4cc0-9b72-34d65a221099", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.2  # New elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85  # Adjusted cooling rate for balance\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.1 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate\n                \n            self.inertia_weight *= 0.98  # Slight reduction for finer control\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Enhanced the balance between exploration and exploitation by introducing adaptive coefficients and hybrid velocity strategy with elite learning.", "configspace": "", "generation": 23, "fitness": 0.09637676862776241, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "c3db0cf0-332c-453a-8183-381857414311", "metadata": {"aucs": [0.09636771683560219, 0.09627820167049284, 0.09648438737719223], "final_y": [0.16485623267328786, 0.16485627880066522, 0.1648564626299286]}, "mutation_prompt": null}
{"id": "16ac6ace-e19b-4b5d-99a6-d7e755c93df7", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.2  # New elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85  # Adjusted cooling rate for balance\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.1 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.98  # Slight reduction for finer control\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Enhanced the adaptive cooling strategy by introducing dynamic cooling rate based on budget utilization.", "configspace": "", "generation": 24, "fitness": 0.09639851352365562, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "1067541a-97fd-4cc0-9b72-34d65a221099", "metadata": {"aucs": [0.096420787282532, 0.09629194711664646, 0.0964828061717884], "final_y": [0.16485645753941014, 0.16485640984081296, 0.1648560745260338]}, "mutation_prompt": null}
{"id": "ace8cd78-2f94-4107-a3e2-7fa977e3fbaf", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.2  # New elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85  # Adjusted cooling rate for balance\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)  # Adjusted for tighter control\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.98  # Slight reduction for finer control\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Enhanced velocity clipping for improved divergence control.", "configspace": "", "generation": 25, "fitness": 0.0964812967428776, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "16ac6ace-e19b-4b5d-99a6-d7e755c93df7", "metadata": {"aucs": [0.09667561234164646, 0.09639020536036991, 0.09637807252661645], "final_y": [0.1648562839676534, 0.16485617563307176, 0.16485634983706654]}, "mutation_prompt": null}
{"id": "86223a32-b640-4629-8b99-7f4f27689018", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.2  # New elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85  # Adjusted cooling rate for balance\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)  # Adjusted for tighter control\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.05, self.dim)  # Reduced deviation\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.98  # Slight reduction for finer control\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Enhanced Hybrid PSO with improved mutation strategy for better exploration.", "configspace": "", "generation": 26, "fitness": 0.09647849761715395, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "ace8cd78-2f94-4107-a3e2-7fa977e3fbaf", "metadata": {"aucs": [0.09664370064615035, 0.09638546596877096, 0.09640632623654055], "final_y": [0.16485589062147954, 0.16485595338898718, 0.16485587302972626]}, "mutation_prompt": null}
{"id": "923f1395-2273-49f0-8635-a9815a2c6018", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5  # Initial cognitive coefficient\n        self.social_coef = 1.5\n        self.elite_coef = 0.2  # New elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85  # Adjusted cooling rate for balance\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            self.cognitive_coef = 0.5 + 1.0 * (1 - evaluations / self.budget)  # Adaptive cognitive coefficient\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)  # Adjusted for tighter control\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.98  # Slight reduction for finer control\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Introduced adaptive cognitive coefficient for balancing exploration and exploitation dynamically.", "configspace": "", "generation": 27, "fitness": 0.09643748508123866, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "ace8cd78-2f94-4107-a3e2-7fa977e3fbaf", "metadata": {"aucs": [0.09663347485780527, 0.09641118063262055, 0.09626779975329014], "final_y": [0.1648561505602324, 0.164856605950915, 0.16485642720248594]}, "mutation_prompt": null}
{"id": "224a3d75-f949-4ff7-a05d-7079b8c4ac0f", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.2  \n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85  \n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)  \n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight = 0.5 + 0.4 * (0.1 + 0.9 * (self.budget - evaluations) / self.budget)**2 \n            self.elite_coef = 0.2 + 0.1 * (evaluations / self.budget)\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Introduced non-linear dynamic inertia weight and adaptive elite coefficient adjustment for enhanced convergence.", "configspace": "", "generation": 28, "fitness": 0.09631266431333403, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "ace8cd78-2f94-4107-a3e2-7fa977e3fbaf", "metadata": {"aucs": [0.09653246699019913, 0.09621211712791022, 0.09619340882189276], "final_y": [0.16485752204031523, 0.16485806131567005, 0.16485695262613553]}, "mutation_prompt": null}
{"id": "2f5cca93-11e0-45f2-beda-866ce22e35f0", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.98\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Slightly increased the elite coefficient to enhance convergence speed by leveraging elite solutions more effectively.", "configspace": "", "generation": 29, "fitness": 0.09650083926561637, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.097 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "ace8cd78-2f94-4107-a3e2-7fa977e3fbaf", "metadata": {"aucs": [0.09666613523991252, 0.09638035136003875, 0.09645603119689783], "final_y": [0.1648562017563393, 0.16485632804295502, 0.164856173900234]}, "mutation_prompt": null}
{"id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Slightly modified the inertia weight decay rate to improve exploration and exploitation balance by decreasing it more gradually.", "configspace": "", "generation": 30, "fitness": 0.09653703544367565, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.097 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "2f5cca93-11e0-45f2-beda-866ce22e35f0", "metadata": {"aucs": [0.096708205218064, 0.09643266544394413, 0.0964702356690188], "final_y": [0.1648565398176508, 0.1648561366883594, 0.1648563283660618]}, "mutation_prompt": null}
{"id": "1b10683e-93de-4311-945d-78e86137cb06", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.3  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Adjusted the elite coefficient to further enhance exploration by slightly increasing its influence.", "configspace": "", "generation": 31, "fitness": 0.09649656866367402, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09663648127253088, 0.09641673959725594, 0.09643648512123526], "final_y": [0.16485626291038014, 0.16485623515743175, 0.16485648909189043]}, "mutation_prompt": null}
{"id": "02721e66-8ce9-4976-9130-311779c7ea9e", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                # Adaptive velocity clamping based on dynamic range\n                dynamic_range = (ub - lb) * (0.1 + 0.9 * (self.budget - evaluations)/self.budget)\n                self.velocities[i] = np.clip(self.velocities[i], -dynamic_range, dynamic_range)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            # Dynamic inertia weight adjustment based on progress\n            self.inertia_weight = 0.4 + 0.5 * (self.budget - evaluations) / self.budget\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Utilize a dynamic inertia weight adjustment and adaptive velocity clamping to enhance convergence efficiency and solution quality.", "configspace": "", "generation": 32, "fitness": 0.08900254979006832, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.089 with standard deviation 0.003. And the mean value of best solutions found was 0.171 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.08851804851957401, 0.09321236948246858, 0.08527723136816234], "final_y": [0.18191617476006017, 0.16487262508242417, 0.16521130078985313]}, "mutation_prompt": null}
{"id": "efd20a27-370a-4e63-87d1-ef906817a1f5", "solution": "import numpy as np\n\nclass AdaptiveMutationPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.mutation_rate = 0.1\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, self.mutation_rate, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n            \n            # Adjust mutation rate based on convergence\n            self.mutation_rate = 0.1 * (1 - evaluations / self.budget)\n                \n        return self.global_best_position", "name": "AdaptiveMutationPSO_SA", "description": "Introducing an adaptive mutation strategy to dynamically adjust search behavior based on convergence progress, enhancing exploration-exploitation trade-off.", "configspace": "", "generation": 33, "fitness": 0.09612061078533385, "feedback": "The algorithm AdaptiveMutationPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09651937216990814, 0.09620116985355076, 0.09564129033254265], "final_y": [0.1653500600681358, 0.16498099827160984, 0.1656892484817294]}, "mutation_prompt": null}
{"id": "84a9eb45-7914-4c6d-8fad-a2446487cd36", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                adaptive_cognitive_coef = self.cognitive_coef * (0.9 + 0.2 * evaluations/self.budget)  # Modify cognitive coefficient dynamically\n                cognitive_velocity = adaptive_cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    mutation_strength = 0.05 + 0.05 * (1 - evaluations/self.budget)  # Add adaptive mutation strength\n                    candidate_position = new_position + np.random.normal(0, mutation_strength, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Improved hybrid algorithm by enhancing exploration with a dynamic cognitive coefficient and adaptive mutation strategy to boost global search capabilities.", "configspace": "", "generation": 34, "fitness": 0.0964960612111075, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09667261014504891, 0.09653991828703079, 0.09627565520124282], "final_y": [0.16485617192035107, 0.16485601892969604, 0.16485615159471434]}, "mutation_prompt": null}
{"id": "844d34e8-b8b6-4848-bed0-c521820e9fc7", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = ((self.cognitive_coef + 0.5 * evaluations/self.budget) * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Adjusted the cognitive coefficient to dynamically increase exploration at higher evaluations, improving search diversity.", "configspace": "", "generation": 35, "fitness": 0.09651718901658464, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.097 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09669754086895588, 0.09638761814039443, 0.09646640804040363], "final_y": [0.1648564435423201, 0.1648561134951123, 0.1648562061144061]}, "mutation_prompt": null}
{"id": "65021c61-5e8d-4f9f-bbd8-aad35606c577", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3, r4 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand()\n                self.elite_coef = 0.1 + 0.4 * (1 - evaluations / self.budget)  # Adaptive elite coefficient\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb) * (0.5 + 0.5 * r4)  # Stochastic adaptive scaling\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Introduced adaptive elite coefficient and stochastic adaptive velocity scaling to enhance exploration and exploitation dynamics.", "configspace": "", "generation": 36, "fitness": 0.09595107106955485, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09639290803296241, 0.09556082241421737, 0.09589948276148474], "final_y": [0.1648562764328051, 0.16485627122481106, 0.1648564382443709]}, "mutation_prompt": null}
{"id": "0da7099c-e6f6-4d3e-8063-95784e401cf9", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.88  # Adjusted cooling rate\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Slight adjustment to the cooling rate to enhance simulated annealing effectiveness.", "configspace": "", "generation": 37, "fitness": 0.09641644975362958, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09670578239887995, 0.09628647571452986, 0.09625709114747893], "final_y": [0.1648565393564425, 0.16485642447434534, 0.16485632488606516]}, "mutation_prompt": null}
{"id": "1cff9c25-43e5-4cf6-8196-0ba6776085e5", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = ((1.5 - evaluations/self.budget * 0.5) * r1 * (self.personal_best_positions[i] - self.particles[i]))  # Dynamic cognitive_coef\n                social_velocity = ((1.5 + evaluations/self.budget * 0.5) * r2 * (self.global_best_position - self.particles[i]))  # Dynamic social_coef\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Introduced dynamic cognitive and social coefficients for adaptive exploration and exploitation balance.", "configspace": "", "generation": 38, "fitness": 0.09649091067906956, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09668619504579745, 0.09644997563127966, 0.09633656136013158], "final_y": [0.1648569112651902, 0.1648567946347259, 0.16485684386902266]}, "mutation_prompt": null}
{"id": "fc344ff5-d2e8-42f7-9f8c-13d38a76c6fc", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.9  # Adjusted cooling rate\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.98  # Further adjusted inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Enhanced inertia weight decay and adaptive cooling for improved exploration and convergence.", "configspace": "", "generation": 39, "fitness": 0.0963344968329578, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09666612537794439, 0.09620644314492488, 0.09613092197600415], "final_y": [0.16485628311811518, 0.16485614943652982, 0.16485625004295035]}, "mutation_prompt": null}
{"id": "e5d4a808-3795-48da-8c32-9b45d8d3fabc", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                self.cognitive_coef = 1.5 * (1.0 - evaluations / self.budget)  # Adaptive cognitive coefficient\n                self.social_coef = 1.5 * (evaluations / self.budget)           # Adaptive social coefficient\n                cognitive_velocity = (self.cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Introduced adaptive cognitive and social coefficients based on evaluation progress to enhance convergence and diversity balance.", "configspace": "", "generation": 40, "fitness": 0.09586128929506606, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09655753907643361, 0.09577927920858254, 0.09524704960018204], "final_y": [0.1648560948627319, 0.1648563533873294, 0.1648568675123515]}, "mutation_prompt": null}
{"id": "f406e8b9-cf11-4acb-b83d-5dbade78b2c9", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.6  # Changed social coefficient from 1.5 to 1.6\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Enhanced global exploration by slightly increasing the social coefficient to improve convergence speed.", "configspace": "", "generation": 41, "fitness": 0.09648074580073795, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09670024237002384, 0.09646700127134333, 0.0962749937608467], "final_y": [0.16485670472170832, 0.16485650116262784, 0.16485630604892543]}, "mutation_prompt": null}
{"id": "9eb11fa4-ef38-4802-8373-10cd684b50d2", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        self.learning_factor = 0.1  # New adaptive learning factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                adapt_lr = self.learning_factor * (evaluations/self.budget)  # Adapt learning rate\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                if i == np.argmin(self.personal_best_scores) and np.random.rand() < 0.05:  # Mutation for elite\n                    self.particles[i] += np.random.normal(0, 0.05, self.dim)  # New mutation strategy\n                \n            self.inertia_weight *= 0.985\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Introduced a dynamic adaptive learning rate and an elite particle mutation strategy to enhance exploration and exploitation balance in EnhancedHybridPSO_SA.", "configspace": "", "generation": 42, "fitness": 0.0963409743813692, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09663028557603026, 0.09606986420766095, 0.09632277336041639], "final_y": [0.16485612916699788, 0.164856480242481, 0.16485702474700548]}, "mutation_prompt": null}
{"id": "482f21bb-4a47-4c4f-bf47-4c221bf9f014", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                adaptive_cognitive_coef = self.cognitive_coef * (1 - evaluations/self.budget)\n                adaptive_social_coef = self.social_coef * (evaluations/self.budget)\n                cognitive_velocity = adaptive_cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = adaptive_social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Enhanced hybrid algorithm incorporating dynamically adjusted coefficients to improve search adaptability and solution quality.", "configspace": "", "generation": 43, "fitness": 0.09586128929506606, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09655753907643361, 0.09577927920858254, 0.09524704960018204], "final_y": [0.1648560948627319, 0.1648563533873294, 0.1648568675123515]}, "mutation_prompt": null}
{"id": "0cc3652d-8fa4-47f4-8538-96e98bd454e5", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.983  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Improved inertia weight decay to further enhance the exploration-exploitation balance by adjusting the decay rate.", "configspace": "", "generation": 44, "fitness": 0.09651432193845544, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.097 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.0967271605245067, 0.09641673819645691, 0.09639906709440271], "final_y": [0.16485617064422398, 0.16485655009834788, 0.16485648921784124]}, "mutation_prompt": null}
{"id": "1677428c-8ddf-4ada-afcf-fd43d36e4969", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.5 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Improved exploration by adjusting the random factor used in cognitive velocity.", "configspace": "", "generation": 45, "fitness": 0.09637682494327353, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09667957720842024, 0.0962335205672109, 0.09621737705418942], "final_y": [0.16485636185057573, 0.16485610677329932, 0.16485634446823372]}, "mutation_prompt": null}
{"id": "5d0fd618-c11b-4cec-aa67-92fa8834e814", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                adaptive_cognitive_coef = self.cognitive_coef * (1 - evaluations / self.budget)\n                adaptive_social_coef = self.social_coef * (evaluations / self.budget)\n                cognitive_velocity = adaptive_cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = adaptive_social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Introduced adaptive cognitive and social coefficients to dynamically balance exploration and exploitation based on optimization progress.", "configspace": "", "generation": 46, "fitness": 0.09586128929506606, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09655753907643361, 0.09577927920858254, 0.09524704960018204], "final_y": [0.1648560948627319, 0.1648563533873294, 0.1648568675123515]}, "mutation_prompt": null}
{"id": "4d68b033-a23a-4b6b-bee5-460376c04387", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                self.cognitive_coef = 1.5 + 0.5 * (self.global_best_score / (1 + self.personal_best_scores[i]))\n                self.social_coef = 1.5 + 0.5 * (1 - (self.global_best_score / (1 + self.personal_best_scores[i])))\n                cognitive_velocity = self.cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "EnhancedHybridPSO_SA with adaptive cognitive and social coefficients for improved convergence.", "configspace": "", "generation": 47, "fitness": 0.09650221088767215, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.097 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09668413632382833, 0.09652056799423658, 0.09630192834495155], "final_y": [0.1648584249914673, 0.16485742433628015, 0.16485760453784315]}, "mutation_prompt": null}
{"id": "3d7770a0-3b54-463c-adda-23f41e6556be", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.90  # Changed cooling rate\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Enhanced dynamic cooling schedule by decreasing the cooling rate more gradually for improved exploitation in simulated annealing.", "configspace": "", "generation": 48, "fitness": 0.09642555552282624, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09670582065701616, 0.09628666770863059, 0.09628417820283197], "final_y": [0.1648565563718407, 0.16485626891954186, 0.16485608857827205]}, "mutation_prompt": null}
{"id": "8e260d9d-07e5-4a87-9ecc-d3f558bb9704", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.55  # Slightly increased social coefficient\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Enhanced global optimization by slightly increasing the social coefficient to improve convergence speed.", "configspace": "", "generation": 49, "fitness": 0.09637563918036855, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09666459543043726, 0.09640140642122752, 0.09606091568944086], "final_y": [0.16485617876392344, 0.16485647548873206, 0.16485626770986894]}, "mutation_prompt": null}
{"id": "99b22a91-5659-4c1e-b923-9d36c4ccdf17", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.3  # Adjusted elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.87  # Adjusted cooling rate\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.98  # Adjusted inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Enhanced dynamic parameter adaptation and elite exploitation to improve convergence and solution quality.", "configspace": "", "generation": 50, "fitness": 0.09648854146155357, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09678055471667957, 0.09641751285659228, 0.09626755681138888], "final_y": [0.16485593731397996, 0.16485616781022938, 0.16485651576552318]}, "mutation_prompt": null}
{"id": "93919016-dc3d-4305-b81d-5e96e847d1db", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985\n            self.cooling_rate *= 0.995  # Slightly adaptively reducing cooling rate\n            \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Introduced adaptive cooling rate in the Simulated Annealing part to improve convergence speed.", "configspace": "", "generation": 51, "fitness": 0.09646099285505412, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09671415425120544, 0.09640430303586922, 0.09626452127808771], "final_y": [0.16485616044607831, 0.1648563857236537, 0.1648567367740429]}, "mutation_prompt": null}
{"id": "cb63db0f-0fc1-4965-824e-404897c68253", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.6  # Slightly increased cognitive coefficient\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Slightly increased cognitive coefficient to improve convergence speed and personal exploration.", "configspace": "", "generation": 52, "fitness": 0.09647830763043408, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09658933000215597, 0.0964621923820187, 0.09638340050712757], "final_y": [0.16485652477691748, 0.16485620033038384, 0.16485628683483045]}, "mutation_prompt": null}
{"id": "2fd36daf-a4db-487e-b995-584317bec888", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.6  # Slightly increased cognitive coefficient\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  \n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Slightly increased the cognitive coefficient to enhance the exploration capability of particles.", "configspace": "", "generation": 53, "fitness": 0.09647830763043408, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09658933000215597, 0.0964621923820187, 0.09638340050712757], "final_y": [0.16485652477691748, 0.16485620033038384, 0.16485628683483045]}, "mutation_prompt": null}
{"id": "24a2d565-8941-4e99-adb4-b8fff0d96983", "solution": "import numpy as np\n\nclass EnhancedAdaptivePSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.3  # Increased elite coefficient\n        self.diversity_coef = 0.1  # New adaptive diversity coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            diversity = np.std(self.particles, axis=0)  # Calculate diversity\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                diversity_velocity = self.diversity_coef * diversity  # Apply diversity mechanism\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity + diversity_velocity)\n\n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.05, self.dim)  # Reduced perturbation\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.98  # Further modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedAdaptivePSO_SA", "description": "Improved exploration-exploitation balance by incorporating adaptive learning rates and a diversity mechanism in the particle swarm.", "configspace": "", "generation": 54, "fitness": 0.0956647835315085, "feedback": "The algorithm EnhancedAdaptivePSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09645087143478781, 0.09511292800451954, 0.09543055115521815], "final_y": [0.16486309080821893, 0.16485588462854517, 0.16514804905345837]}, "mutation_prompt": null}
{"id": "eea5d108-3b75-4d0c-875c-ea5361f74122", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                scaling_factor = 0.8 + 0.4 * (1 - evaluations/self.budget)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * scaling_factor * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Enhanced convergence by adjusting social coefficients using a dynamic scaling factor based on evaluations.", "configspace": "", "generation": 55, "fitness": 0.09649285765847171, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.096660739403299, 0.0964409922485584, 0.09637684132355773], "final_y": [0.16485621095611325, 0.16485648328466662, 0.1648563903893251]}, "mutation_prompt": null}
{"id": "d7d4ce4e-12ba-485c-a9cd-e00862c06613", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.987  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Fine-tuned inertia weight decay rate from 0.985 to 0.987 for improved convergence.", "configspace": "", "generation": 56, "fitness": 0.09650028638809727, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.097 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09670532897173767, 0.09632565500284707, 0.09646987518970707], "final_y": [0.1648564257150017, 0.16485632689561303, 0.16485630166451481]}, "mutation_prompt": null}
{"id": "c35bb5b8-e951-4866-8bb1-8df7532a8137", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.7  # Adjusted cognitive coefficient for better exploration\n        self.social_coef = 1.5\n        self.elite_coef = 0.3  # Further increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.2 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.98  # Further tuned inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA_Improved", "description": "Improved inertia adaptation and elite handling to enhance exploration-exploitation balance.", "configspace": "", "generation": 57, "fitness": 0.09647339901422025, "feedback": "The algorithm EnhancedHybridPSO_SA_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09671416842234759, 0.09627459124901072, 0.09643143737130244], "final_y": [0.1648563335472386, 0.16485632804807326, 0.16485612169922736]}, "mutation_prompt": null}
{"id": "480476bf-394a-4d4e-8104-d6fdf064fd73", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.9  # Modified cooling rate\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            elite_threshold = np.percentile(self.personal_best_scores, 20)  # Adaptive elite threshold\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_candidates = self.personal_best_positions[self.personal_best_scores <= elite_threshold]\n            elite_position = elite_candidates[np.random.randint(len(elite_candidates))]  # Random elite selection\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Introducing Adaptive Elite Selection and Modified Cooling to Enhance Solution Diversity and Convergence.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('high <= 0').", "error": "ValueError('high <= 0')", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {}, "mutation_prompt": null}
{"id": "3f3d40ac-6ba2-49ae-9b8a-1580827ea1a4", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.55  # Slightly increased cognitive coefficient\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Improved exploration by slightly adjusting the cognitive coefficient for enhanced convergence.", "configspace": "", "generation": 59, "fitness": 0.0964196569472469, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.0965891574601565, 0.09645294217337519, 0.09621687120820899], "final_y": [0.16485673311090743, 0.16485661436823829, 0.16485640777392285]}, "mutation_prompt": null}
{"id": "5dfa6bb3-520e-435d-b279-93440c75fa2d", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.9  # Adjusted cooling rate\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Adjusted the cooling rate to enhance the convergence speed of the simulated annealing component.", "configspace": "", "generation": 60, "fitness": 0.09642555552282624, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09670582065701616, 0.09628666770863059, 0.09628417820283197], "final_y": [0.1648565563718407, 0.16485626891954186, 0.16485608857827205]}, "mutation_prompt": null}
{"id": "a3a44e0d-f173-4691-9d0b-1c7806fec220", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                self.social_coef = 1.5 * (0.5 + evaluations / (2 * self.budget))  # Dynamic social coefficient\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Introduced a dynamic social coefficient to improve convergence towards the global best position as evaluations progress.", "configspace": "", "generation": 61, "fitness": 0.09644098210666778, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.0967379307324221, 0.0961175734259796, 0.09646744216160164], "final_y": [0.16485611594544125, 0.16485621899686576, 0.16485624025100631]}, "mutation_prompt": null}
{"id": "8529d65e-2bc9-4d2f-98a3-7d9a371bdf88", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.055 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Slightly refined the velocity clipping factor to allow more diverse explorations by increasing it slightly.", "configspace": "", "generation": 62, "fitness": 0.0964154769907936, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09666201960202803, 0.09618977912961146, 0.0963946322407413], "final_y": [0.16485646342705607, 0.16485655252748488, 0.16485624263128607]}, "mutation_prompt": null}
{"id": "b3d9e3af-2b88-4f97-a506-7884c11177ea", "solution": "import numpy as np\n\nclass QuantumInspiredPSO_ACR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget // 10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.quantum_coef = 0.1  # Coefficient for quantum-inspired behavior\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.9\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n\n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                quantum_velocity = self.quantum_coef * r3 * (np.mean(self.particles, axis=0) - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + quantum_velocity)\n\n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n\n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n\n                self.temperature *= self.cooling_rate * np.exp(-evaluations / self.budget)\n\n            self.inertia_weight *= 0.99\n\n        return self.global_best_position", "name": "QuantumInspiredPSO_ACR", "description": "Quantum-Inspired Particle Swarm Optimization (QIPSO) with Adaptive Cooling Rate to exploit quantum superposition for enhanced exploration and a dynamic cooling mechanism for simulated annealing.", "configspace": "", "generation": 63, "fitness": 0.09634934119627385, "feedback": "The algorithm QuantumInspiredPSO_ACR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09646334673448342, 0.09635663680189377, 0.09622804005244434], "final_y": [0.16486301073823617, 0.16486116963658426, 0.16486114675986507]}, "mutation_prompt": null}
{"id": "25c22841-537b-4469-b118-7ca75139bf8c", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                self.cognitive_coef = 1.5 - 0.5 * evaluations / self.budget  # Dynamic cognitive coefficient\n                self.social_coef = 1.5 + 0.5 * evaluations / self.budget  # Dynamic social coefficient\n                cognitive_velocity = (self.cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                velocity_adaptation = np.tanh(np.linalg.norm(self.velocities[i]) / (0.1 + np.linalg.norm(self.particles[i])))\n                self.velocities[i] = (velocity_adaptation * self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Introduced velocity adaptation and dynamic cognitive and social coefficients to improve convergence and exploration balance.", "configspace": "", "generation": 64, "fitness": 0.09605211228179804, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09600333349475731, 0.09583421233377598, 0.0963187910168608], "final_y": [0.16485716428689845, 0.1648587549821785, 0.16485676923539994]}, "mutation_prompt": null}
{"id": "9f735267-ad2f-49db-8dd5-62f846d284ed", "solution": "import numpy as np\n\nclass SigmoidVelocityPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.elite_coef = 0.3\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.9\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_coef * r1 * (self.personal_best_positions[i] - self.particles[i])\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                \n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                # Use sigmoid function for dynamic velocity adjustment\n                sigmoid_factor = 1 / (1 + np.exp(-10 * (evaluations/self.budget - 0.5)))\n                self.velocities[i] *= sigmoid_factor\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.98  # Slightly increased decay rate\n                \n        return self.global_best_position", "name": "SigmoidVelocityPSO_SA", "description": "Introduced dynamic velocity adjustment using a sigmoid function for better convergence near the optima.", "configspace": "", "generation": 65, "fitness": 0.08668401719334755, "feedback": "The algorithm SigmoidVelocityPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.087 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.08861462444848311, 0.08478253176584805, 0.08665489536571147], "final_y": [0.16489666931792168, 0.16497632749227953, 0.16491510227720263]}, "mutation_prompt": null}
{"id": "28ee355c-d362-4a0e-9cde-8fbc2cbb2f54", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                # Adaptive temperature scaling\n                temperature_scaling = (self.global_best_score + 1e-10) / (self.personal_best_scores[i] + 1e-10)\n                self.temperature *= temperature_scaling\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985\n            # Dynamic social-cognitive balance adjustment\n            self.social_coef = 1.5 + 0.5 * (self.global_best_score / (np.mean(self.personal_best_scores) + 1e-10))\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Incorporate adaptive temperature scaling and dynamic social-cognitive balance to enhance convergence.", "configspace": "", "generation": 66, "fitness": 0.09600530987376543, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09640460773268167, 0.09526848687934175, 0.09634283500927288], "final_y": [0.16485616403226477, 0.16485650513479522, 0.1648560376924766]}, "mutation_prompt": null}
{"id": "b7772be9-f40d-4489-bf6e-8204604df077", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.3  # Modified elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Improved elite coefficient to enhance convergence speed and solution quality in the hybrid PSO-SA framework.", "configspace": "", "generation": 67, "fitness": 0.09649656866367402, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09663648127253088, 0.09641673959725594, 0.09643648512123526], "final_y": [0.16485626291038014, 0.16485623515743175, 0.16485648909189043]}, "mutation_prompt": null}
{"id": "f74fecdb-d774-4339-a2c5-e9936d65d1bf", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.6  # Slightly increased social coefficient\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Enhanced exploration by slightly increasing the social coefficient for better global communication.", "configspace": "", "generation": 68, "fitness": 0.09648074580073795, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09670024237002384, 0.09646700127134333, 0.0962749937608467], "final_y": [0.16485670472170832, 0.16485650116262784, 0.16485630604892543]}, "mutation_prompt": null}
{"id": "2cfa8837-401e-45af-bd92-f74505cb0d6b", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.6  # Slightly adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Improved balance between exploration and exploitation by slightly adjusting the cognitive coefficient.", "configspace": "", "generation": 69, "fitness": 0.09647830763043408, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09658933000215597, 0.0964621923820187, 0.09638340050712757], "final_y": [0.16485652477691748, 0.16485620033038384, 0.16485628683483045]}, "mutation_prompt": null}
{"id": "22ff6378-6018-4727-9e1a-4da23533c6ac", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.7  # Slight increase in social coefficient\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Adjusted social coefficient for improved convergence speed and balance between exploration and exploitation.", "configspace": "", "generation": 70, "fitness": 0.09648200566871219, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09673181513275175, 0.09650813079429377, 0.09620607107909107], "final_y": [0.16485611685328017, 0.16485622865164318, 0.16485654923118676]}, "mutation_prompt": null}
{"id": "78eb8f46-5db5-443c-ae1a-bbff7daeaa05", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.6  # Slightly increased cognitive coefficient\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Slightly increased the cognitive coefficient to enhance individual exploration, maintaining balance between exploration and exploitation.", "configspace": "", "generation": 71, "fitness": 0.09647830763043408, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09658933000215597, 0.0964621923820187, 0.09638340050712757], "final_y": [0.16485652477691748, 0.16485620033038384, 0.16485628683483045]}, "mutation_prompt": null}
{"id": "300a24a0-5db0-4a4b-8895-8c22490549c4", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.9  # Adjusted cooling rate for better annealing\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature * (evaluations / self.budget)  # Adaptive temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate\n                \n            self.inertia_weight *= 0.99  # Slightly adjusted inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Improved PSO-Simulated Annealing hybrid with adaptive inertia weight and temperature control to enhance convergence.", "configspace": "", "generation": 72, "fitness": -Infinity, "feedback": "An exception occurred: ZeroDivisionError('float division by zero').", "error": "ZeroDivisionError('float division by zero')", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {}, "mutation_prompt": null}
{"id": "23de6922-705d-46c5-b30f-a2aeb036f3b6", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.3  # Changed elite coefficient\n        self.initial_temperature = 900  # Adjusted initial temperature\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Enhanced convergence by adjusting the elite coefficient and initial temperature for better exploration.", "configspace": "", "generation": 73, "fitness": 0.09649682230521588, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.096634750992869, 0.09641834225028978, 0.09643737367248884], "final_y": [0.16485630619467484, 0.164856249123855, 0.16485632468345057]}, "mutation_prompt": null}
{"id": "4bdc50a8-46d4-47aa-b3f4-1fe195efd9f8", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.3  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                random_noise = np.random.normal(0, 0.01, self.dim)  # Added random noise\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity + random_noise)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Adjusted the elite coefficient and added random noise in the velocity update to enhance exploration in the search space.", "configspace": "", "generation": 74, "fitness": 0.09651711103829867, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.097 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09676551945576006, 0.0963479284926172, 0.09643788516651874], "final_y": [0.16485619694619158, 0.16485637025142763, 0.16485678838937567]}, "mutation_prompt": null}
{"id": "ae300953-82ba-4f48-b524-a95a5c6d241a", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.88  # Slightly adjusted cooling rate\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Slightly adjust the cooling rate to improve convergence speed and solution quality.", "configspace": "", "generation": 75, "fitness": 0.09641644975362958, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09670578239887995, 0.09628647571452986, 0.09625709114747893], "final_y": [0.1648565393564425, 0.16485642447434534, 0.16485632488606516]}, "mutation_prompt": null}
{"id": "2786e40e-d368-4257-953f-a6a74badbb20", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.6  # Slightly increased social coefficient\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Enhanced convergence by slightly increasing the social coefficient for better global search.", "configspace": "", "generation": 76, "fitness": 0.09648074580073795, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09670024237002384, 0.09646700127134333, 0.0962749937608467], "final_y": [0.16485670472170832, 0.16485650116262784, 0.16485630604892543]}, "mutation_prompt": null}
{"id": "efbda933-39c9-4b47-8262-e26dcb2f8ea7", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1200  # Slightly increased initial temperature\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Slightly increase the initial temperature to enhance the exploration phase of the algorithm.", "configspace": "", "generation": 77, "fitness": 0.09651739160558537, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.097 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.0967079961212326, 0.0963735199462803, 0.09647065874924321], "final_y": [0.1648561992918629, 0.16485651366901033, 0.1648562520149245]}, "mutation_prompt": null}
{"id": "f1d15b00-f798-474c-a314-252148593693", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.03 * (ub - lb)  # Reduced velocity clipping\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= 0.985  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Enhanced velocity clipping by decreasing the maximum velocity limit to improve precision and stability.", "configspace": "", "generation": 78, "fitness": 0.09550928535596226, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.09612492040058773, 0.09531008786544115, 0.0950928478018579], "final_y": [0.16485649116328138, 0.16485616850105345, 0.1648562164253352]}, "mutation_prompt": null}
{"id": "52293a5a-c873-40e2-b5bc-c086b3302575", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= (0.985 - 0.001 * evaluations/self.budget)  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Optimized inertia weight decay by introducing a dynamic decay factor to improve convergence speed.", "configspace": "", "generation": 79, "fitness": 0.096537612876051, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.097 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "87cd3268-9b9e-48b9-831f-da0b0e3e0846", "metadata": {"aucs": [0.0967078291357868, 0.09642794759326967, 0.09647706189909655], "final_y": [0.16485627668022707, 0.16485606933779373, 0.16485630101772486]}, "mutation_prompt": null}
{"id": "29849666-70ae-4e4d-9db9-a6f4cdf70d9e", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * (0.5 + 0.5 * evaluations/self.budget) * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= (0.985 - 0.001 * evaluations/self.budget)  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Introduced a dynamic global learning factor to enhance convergence efficiency.", "configspace": "", "generation": 80, "fitness": 0.09643736363393025, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "52293a5a-c873-40e2-b5bc-c086b3302575", "metadata": {"aucs": [0.09673643926470654, 0.09610948667683206, 0.09646616496025218], "final_y": [0.16485614184822495, 0.16485617072343228, 0.1648561928962171]}, "mutation_prompt": null}
{"id": "4c3707c0-f988-4d0a-ac4f-b041181c12d4", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / (self.temperature * (1.5 - evaluations/self.budget)))\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= (0.985 - 0.001 * evaluations/self.budget)  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Enhanced the Simulated Annealing acceptance criteria by increasing the exploration potential through a varied cooling schedule.", "configspace": "", "generation": 81, "fitness": 0.09644561433944965, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "52293a5a-c873-40e2-b5bc-c086b3302575", "metadata": {"aucs": [0.09670808986581636, 0.0963651958427697, 0.09626355730976288], "final_y": [0.16485647059176478, 0.16485616561481764, 0.16485627285718807]}, "mutation_prompt": null}
{"id": "f1c9d051-e5a0-46b3-b091-ba7b81e6feec", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.3  # Adjusted elite coefficient for better exploration\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= (0.985 - 0.001 * evaluations/self.budget)\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Enhanced elite coefficient optimization for improved exploration.", "configspace": "", "generation": 82, "fitness": 0.0964959652827189, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "52293a5a-c873-40e2-b5bc-c086b3302575", "metadata": {"aucs": [0.09663540869683018, 0.09641794260755976, 0.09643454454376676], "final_y": [0.16485644054950643, 0.1648561243215778, 0.16485636873307807]}, "mutation_prompt": null}
{"id": "0cfbfb31-5b60-477e-b3a2-37b8a72b55f5", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                \n                cognitive_adapt = 1 + (0.5 * evaluations/self.budget)  # Changed line\n                social_adapt = 1 + (0.5 * (1 - evaluations/self.budget))  # Changed line\n                \n                cognitive_velocity = (self.cognitive_coef * cognitive_adapt * r1 * (self.personal_best_positions[i] - self.particles[i]))  # Changed line\n                social_velocity = self.social_coef * social_adapt * r2 * (self.global_best_position - self.particles[i])  # Changed line\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= (0.985 - 0.001 * evaluations/self.budget)\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Introduced adaptive learning rates for cognitive and social coefficients to enhance convergence adaptability.", "configspace": "", "generation": 83, "fitness": 0.09637803326915244, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "52293a5a-c873-40e2-b5bc-c086b3302575", "metadata": {"aucs": [0.09651865481036237, 0.09631656002261824, 0.0962988849744767], "final_y": [0.1648577745832891, 0.16485793918909686, 0.16485950931322646]}, "mutation_prompt": null}
{"id": "3405b15a-99cc-4746-b175-13e7a914c886", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                self.cognitive_coef = 1.5 - 0.5 * (evaluations / self.budget)  # Adaptive cognitive coefficient\n                self.social_coef = 1.5 + 0.5 * (evaluations / self.budget)  # Adaptive social coefficient\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= (0.985 - 0.001 * evaluations/self.budget)  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Introduced adaptive cognitive and social coefficients based on evaluations to enhance convergence precision and stability.", "configspace": "", "generation": 84, "fitness": 0.09653716820177405, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.097 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "52293a5a-c873-40e2-b5bc-c086b3302575", "metadata": {"aucs": [0.09666713046196707, 0.09646756697026326, 0.09647680717309182], "final_y": [0.16485636919691538, 0.16485629896465492, 0.1648562698905176]}, "mutation_prompt": null}
{"id": "9b045911-04f3-435d-aca4-eb121c71ae12", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= (0.99 - 0.001 * evaluations/self.budget)  # Modified inertia weight decay\n            \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Refined inertia weight decay to enhance convergence by dynamically adjusting it based on evaluations.", "configspace": "", "generation": 85, "fitness": 0.09640457244188431, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "52293a5a-c873-40e2-b5bc-c086b3302575", "metadata": {"aucs": [0.09667593542357533, 0.09618227746953056, 0.09635550443254703], "final_y": [0.16485633445500536, 0.1648567330390568, 0.16485620641703458]}, "mutation_prompt": null}
{"id": "3fc2287f-2518-43ee-bfe2-2f302c15c6a6", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25  # Slightly increased elite coefficient\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                self.cognitive_coef = 1.5 + 0.5 * (self.global_best_score / np.min(self.personal_best_scores + 1e-8))\n                self.social_coef = 1.5 - 0.5 * (self.global_best_score / np.min(self.personal_best_scores + 1e-8))\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= (0.985 - 0.001 * evaluations/self.budget)  # Modified inertia weight decay rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "The algorithm improves exploration by adapting cognitive and social coefficients dynamically based on performance.", "configspace": "", "generation": 86, "fitness": 0.09640018368654801, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "52293a5a-c873-40e2-b5bc-c086b3302575", "metadata": {"aucs": [0.09661988636742969, 0.09618522968534637, 0.09639543500686798], "final_y": [0.16485614605833931, 0.16485631392290412, 0.1648562370327712]}, "mutation_prompt": null}
{"id": "78076e67-c1bf-4767-a5ce-62c235e261cd", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA_MultiSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.85\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        self.sub_swarms = 3\n        self.sub_swarm_best_positions = np.zeros((self.sub_swarms, dim))\n        self.sub_swarm_best_scores = np.full(self.sub_swarms, float('inf'))\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n                \n                sub_swarm_index = i % self.sub_swarms\n                if score < self.sub_swarm_best_scores[sub_swarm_index]:\n                    self.sub_swarm_best_scores[sub_swarm_index] = score\n                    self.sub_swarm_best_positions[sub_swarm_index] = self.particles[i]\n\n            for i in range(self.num_particles):\n                r1, r2, r3, r4 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                sub_swarm_index = i % self.sub_swarms\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                elite_velocity = self.elite_coef * r3 * (self.sub_swarm_best_positions[sub_swarm_index] - self.particles[i])\n                learning_velocity = r4 * (self.global_best_position - self.sub_swarm_best_positions[sub_swarm_index])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity + learning_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= (0.985 - 0.001 * evaluations/self.budget)\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA_MultiSwarm", "description": "Introducing a multi-swarm approach with adaptive learning rates to enhance diversity and convergence in optimization.", "configspace": "", "generation": 87, "fitness": 0.09555444686389276, "feedback": "The algorithm EnhancedHybridPSO_SA_MultiSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "52293a5a-c873-40e2-b5bc-c086b3302575", "metadata": {"aucs": [0.09649473419502042, 0.09455110360995256, 0.09561750278670533], "final_y": [0.16486013203091576, 0.16486707459163152, 0.1649004954336465]}, "mutation_prompt": null}
{"id": "80eb193a-e779-4dda-8ba4-f9f0f5cff19a", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.9  # Modified cooling rate\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                adaptive_elite_coef = self.elite_coef * (0.5 + evaluations/(2*self.budget))  # Adaptive elite coefficient\n                elite_velocity = adaptive_elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= (0.985 - 0.001 * evaluations/self.budget)\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Introduced adaptive elite coefficient and modified cooling schedule to enhance exploration and convergence balance.", "configspace": "", "generation": 88, "fitness": 0.09659125138136952, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.097 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "52293a5a-c873-40e2-b5bc-c086b3302575", "metadata": {"aucs": [0.09667386575449621, 0.09649529150442215, 0.09660459688519019], "final_y": [0.16485697986025316, 0.16485614105300905, 0.16485636012557237]}, "mutation_prompt": null}
{"id": "b171751c-c35b-42d2-a3c5-5617e22f997d", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA_Levy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.95  # Modified cooling rate\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                adaptive_elite_coef = self.elite_coef * (0.5 + evaluations/(2*self.budget))  # Adaptive elite coefficient\n                elite_velocity = adaptive_elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    step_size = np.random.standard_cauchy(self.dim)  # Levy flight step size\n                    candidate_position = new_position + step_size * np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= (0.985 - 0.001 * evaluations/self.budget)\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA_Levy", "description": "Enhanced exploration by incorporating Levy flights and fine-tuning the cooling schedule for improved convergence.", "configspace": "", "generation": 89, "fitness": 0.09618092189389353, "feedback": "The algorithm EnhancedHybridPSO_SA_Levy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "80eb193a-e779-4dda-8ba4-f9f0f5cff19a", "metadata": {"aucs": [0.09676518337258733, 0.09605933338328809, 0.09571824892580516], "final_y": [0.16485842065351497, 0.16486172370112406, 0.1648609389083172]}, "mutation_prompt": null}
{"id": "74090b13-e4ed-4d59-a917-507bbd87c7ce", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.9  # Modified cooling rate\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n\n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                adaptive_elite_coef = self.elite_coef * (0.5 + evaluations/(2*self.budget))  # Adaptive elite coefficient\n                elite_velocity = adaptive_elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n\n                # Adjusted velocity clamping for better stability\n                vel_max = 0.1 * (ub - lb)  \n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            # Enhanced inertia weight decay for improved adaptability\n            self.inertia_weight *= (0.99 - 0.001 * evaluations/self.budget)\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Enhanced stability and adaptability by fine-tuning velocity clamping and inertia weight adjustment.", "configspace": "", "generation": 90, "fitness": 0.09621996464456577, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "80eb193a-e779-4dda-8ba4-f9f0f5cff19a", "metadata": {"aucs": [0.09602275454302456, 0.09632306956624126, 0.09631406982443147], "final_y": [0.16485709693493578, 0.16485662148956015, 0.16485622127681288]}, "mutation_prompt": null}
{"id": "3f687b3d-5bc0-45b1-96b5-7f8c129a06aa", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.9  # Modified cooling rate\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                adaptive_elite_coef = self.elite_coef * (0.75 + evaluations/(2*self.budget))  # Improved adaptive elite coefficient\n                elite_velocity = adaptive_elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= (0.985 - 0.001 * evaluations/self.budget)\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "EnhancedHybridPSO_SA with improved adaptive elite coefficient initialization to enhance the balance between exploration and exploitation.", "configspace": "", "generation": 91, "fitness": 0.09637925662676272, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "80eb193a-e779-4dda-8ba4-f9f0f5cff19a", "metadata": {"aucs": [0.09661330350609676, 0.09613294699801156, 0.09639151937617985], "final_y": [0.1648562409322608, 0.16485640882196362, 0.16485620708864868]}, "mutation_prompt": null}
{"id": "e3440c25-c204-4f28-b9ec-83a7ce923b86", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.6  # Slight modification\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.9  # Modified cooling rate\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                adaptive_elite_coef = self.elite_coef * (0.5 + evaluations/(2*self.budget))  # Adaptive elite coefficient\n                elite_velocity = adaptive_elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= (0.985 - 0.001 * evaluations/self.budget)\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Minor tuning of the social coefficient to improve global exploration capabilities.", "configspace": "", "generation": 92, "fitness": 0.0965375203158572, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.097 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "80eb193a-e779-4dda-8ba4-f9f0f5cff19a", "metadata": {"aucs": [0.09663653537928696, 0.09650654625271071, 0.09646947931557392], "final_y": [0.16485656183721253, 0.16485630818344854, 0.1648560426758917]}, "mutation_prompt": null}
{"id": "d1075fff-b89a-4899-8ccc-b77450c2521d", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.9  # Modified cooling rate\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                self.social_coef = 1.5 - 0.5 * (evaluations / self.budget)  # Dynamic social coefficient\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                adaptive_elite_coef = self.elite_coef * (0.5 + evaluations/(2*self.budget))  # Adaptive elite coefficient\n                elite_velocity = adaptive_elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= (0.985 - 0.001 * evaluations/self.budget)\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Introduced a dynamic social coefficient to enhance adaptability based on the number of evaluations.", "configspace": "", "generation": 93, "fitness": 0.09656732850579071, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.097 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "80eb193a-e779-4dda-8ba4-f9f0f5cff19a", "metadata": {"aucs": [0.09659897356930613, 0.0965039522873351, 0.0965990596607309], "final_y": [0.16485604422999955, 0.16485622680027534, 0.1648563238784817]}, "mutation_prompt": null}
{"id": "2444928f-f75b-4e4b-b44c-94eb1a9439ac", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.95  # Adjusted cooling rate\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature * ((self.budget - evaluations) / self.budget)  # Dynamic temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * (1 + 0.1 * np.sin(evaluations/100)) * r2 * (self.global_best_position - self.particles[i])  # Added variation\n                adaptive_elite_coef = self.elite_coef * (0.5 + evaluations/(2*self.budget))\n                elite_velocity = adaptive_elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    perturbation = np.random.normal(0, 0.1 * (1 - evaluations/self.budget), self.dim)  # Reduced amplitude\n                    candidate_position = new_position + perturbation\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate\n                \n            self.inertia_weight *= (0.985 - 0.001 * evaluations/self.budget)\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "EnhancedHybridPSO_SA with dynamic temperature modulation and swarm diversity to improve convergence efficiency.", "configspace": "", "generation": 94, "fitness": 0.09649396046212133, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "80eb193a-e779-4dda-8ba4-f9f0f5cff19a", "metadata": {"aucs": [0.09665519089496943, 0.09626383259032478, 0.09656285790106978], "final_y": [0.16485578487761032, 0.16485577454016653, 0.1648557735680537]}, "mutation_prompt": null}
{"id": "e34c5ba1-4458-415f-a8c4-b5fdf2cf0f06", "solution": "import numpy as np\n\nclass AdvancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget // 10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.9\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n\n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n\n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations / self.budget) * r1 *\n                                      (self.personal_best_positions[i] - self.particles[i]))\n                social_influence = np.var(self.personal_best_scores) / (np.var(self.personal_best_scores) + 1e-10)\n                social_velocity = self.social_coef * r2 * social_influence * (self.global_best_position - self.particles[i])\n                adaptive_elite_coef = self.elite_coef * (0.5 + evaluations / (2 * self.budget))\n                elite_velocity = adaptive_elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] + cognitive_velocity +\n                                      social_velocity + elite_velocity)\n\n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n\n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n\n                self.temperature *= self.cooling_rate * ((self.budget - evaluations) / self.budget)\n\n            self.inertia_weight *= 0.99 - 0.02 * ((evaluations / self.budget) ** 2)\n\n        return self.global_best_position", "name": "AdvancedHybridPSO_SA", "description": "Introduced nonlinear inertia weight decay and diversified social influence to enhance global search efficiency.", "configspace": "", "generation": 95, "fitness": 0.09651114199509266, "feedback": "The algorithm AdvancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.097 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "80eb193a-e779-4dda-8ba4-f9f0f5cff19a", "metadata": {"aucs": [0.09665615404206107, 0.09635936918766075, 0.09651790275555616], "final_y": [0.16485618562612592, 0.1648560237005865, 0.16485643821963902]}, "mutation_prompt": null}
{"id": "bcb86d13-a7fc-4b75-a394-64b0c258c226", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.9  # Modified cooling rate\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (0.8 + 0.3 * np.sin(np.pi * evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.particles[i]))  # Adaptive cognitive coefficient\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                adaptive_elite_coef = self.elite_coef * (0.5 + evaluations/(2*self.budget))  # Adaptive elite coefficient\n                elite_velocity = adaptive_elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= (0.985 - 0.001 * evaluations/self.budget)\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Improved exploration by adjusting the cognitive coefficient dynamically.", "configspace": "", "generation": 96, "fitness": 0.09642855619708879, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "80eb193a-e779-4dda-8ba4-f9f0f5cff19a", "metadata": {"aucs": [0.09658454895615831, 0.09636916732449496, 0.09633195231061309], "final_y": [0.16485642518989485, 0.16485633641628628, 0.16485708058300852]}, "mutation_prompt": null}
{"id": "3d38d1b5-8373-4768-9a84-97a267bb0a23", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.9  # Modified cooling rate\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                adaptive_elite_coef = self.elite_coef * (0.5 + evaluations/(2*self.budget))  # Adaptive elite coefficient\n                elite_velocity = adaptive_elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= (0.99 - 0.001 * evaluations/self.budget)  # Changed adaptation rate\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Optimized inertia weight adaptation to enhance convergence speed.", "configspace": "", "generation": 97, "fitness": 0.09652219153586379, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.097 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "80eb193a-e779-4dda-8ba4-f9f0f5cff19a", "metadata": {"aucs": [0.09666828669387906, 0.0963532422841219, 0.09654504562959043], "final_y": [0.1648563993345289, 0.16485673963298741, 0.16485638150620674]}, "mutation_prompt": null}
{"id": "1a5bbfd6-f67d-485c-baf5-e9e5cc7dfc53", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.9  # Modified cooling rate\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    # Change made here\n                    self.global_best_position = (self.particles[i] + elite_position) / 2 \n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                adaptive_elite_coef = self.elite_coef * (0.5 + evaluations/(2*self.budget))  # Adaptive elite coefficient\n                elite_velocity = adaptive_elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight *= (0.985 - 0.001 * evaluations/self.budget)\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Improved global best position update strategy by introducing a weighted average that includes elite particles.", "configspace": "", "generation": 98, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'elite_position' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'elite_position' referenced before assignment\")", "parent_id": "80eb193a-e779-4dda-8ba4-f9f0f5cff19a", "metadata": {}, "mutation_prompt": null}
{"id": "70607617-80b5-4d87-b058-24424fd8f2c3", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(30, budget//10)\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.elite_coef = 0.25\n        self.initial_temperature = 1000\n        self.cooling_rate = 0.9  # Modified cooling rate\n        self.velocities = np.random.rand(self.num_particles, dim)\n        self.particles = np.random.rand(self.num_particles, dim)\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(dim)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.global_best_score = float('inf')\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_score = float('inf')\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            self.temperature = self.initial_temperature\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i]\n\n            elite_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n            \n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = (self.cognitive_coef * (1.1 - evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.particles[i]))\n                social_velocity = self.social_coef * r2 * (self.global_best_position - self.particles[i])\n                adaptive_elite_coef = self.elite_coef * (0.5 + evaluations/(2*self.budget))  # Adaptive elite coefficient\n                elite_velocity = adaptive_elite_coef * r3 * (elite_position - self.particles[i])\n                self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                      cognitive_velocity + social_velocity + elite_velocity)\n                \n                vel_max = 0.05 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n\n                new_position = self.particles[i] + self.velocities[i]\n                new_position = np.clip(new_position, lb, ub)\n                \n                if evaluations < self.budget:\n                    candidate_position = new_position + np.random.normal(0, 0.1, self.dim)\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    delta_score = candidate_score - score\n                    acceptance_probability = np.exp(-delta_score / self.temperature)\n                    if candidate_score < score or np.random.rand() < acceptance_probability:\n                        self.particles[i] = candidate_position\n                        score = candidate_score\n                \n                self.temperature *= self.cooling_rate * ((self.budget - evaluations)/self.budget)\n                \n            self.inertia_weight = 0.4 + 0.5 * (self.budget - evaluations) / self.budget\n                \n        return self.global_best_position", "name": "EnhancedHybridPSO_SA", "description": "Introduced dynamic inertia weight scaling to better balance exploration and exploitation.", "configspace": "", "generation": 99, "fitness": 0.0963947296167064, "feedback": "The algorithm EnhancedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best).", "error": "", "parent_id": "80eb193a-e779-4dda-8ba4-f9f0f5cff19a", "metadata": {"aucs": [0.0964988524693956, 0.09616308666696038, 0.09652224971376322], "final_y": [0.16485744169996064, 0.1648568034525827, 0.1648575511020418]}, "mutation_prompt": null}

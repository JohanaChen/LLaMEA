{"id": "cb08ea91-5969-4365-8bca-48d8e8744ffc", "solution": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.differential_weight = 0.8\n        self.crossover_prob = 0.9\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n\n    def __call__(self, func):\n        np.random.seed(0)\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_position = np.copy(position)\n        personal_best_value = np.full(self.population_size, np.inf)\n\n        global_best_position = None\n        global_best_value = np.inf\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                current_value = func(position[i])\n                evaluations += 1\n\n                if current_value < personal_best_value[i]:\n                    personal_best_value[i] = current_value\n                    personal_best_position[i] = position[i]\n\n                if current_value < global_best_value:\n                    global_best_value = current_value\n                    global_best_position = position[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocity and position for PSO\n            inertia_component = self.inertia_weight * velocity\n            cognitive_component = self.cognitive_coef * np.random.rand(self.dim) * (personal_best_position - position)\n            social_component = self.social_coef * np.random.rand(self.dim) * (global_best_position - position)\n            velocity = inertia_component + cognitive_component + social_component\n            position = np.clip(position + velocity, self.lower_bound, self.upper_bound)\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant_vector = np.clip(personal_best_position[a] + self.differential_weight * (personal_best_position[b] - personal_best_position[c]), self.lower_bound, self.upper_bound)\n                trial_vector = np.array([mutant_vector[j] if np.random.rand() < self.crossover_prob else position[i][j] for j in range(self.dim)])\n                \n                trial_value = func(trial_vector)\n                evaluations += 1\n\n                if trial_value < personal_best_value[i]:\n                    personal_best_value[i] = trial_value\n                    personal_best_position[i] = trial_vector\n\n                if trial_value < global_best_value:\n                    global_best_value = trial_value\n                    global_best_position = trial_vector\n\n        return global_best_position, global_best_value", "name": "PSO_DE_Optimizer", "description": "This algorithm combines particle swarm optimization (PSO) with differential evolution (DE) to leverage both exploration and exploitation for enhanced performance in black box optimization.", "configspace": "", "generation": 0, "fitness": 0.39465847486922073, "feedback": "", "error": "", "parent_id": null, "metadata": {"aucs": [0.8491853421673861, 0.8491853421673861, 0.8491853421673861, 0.18994646827276196, 0.18994646827276196, 0.18994646827276196, 0.8582863502593907, 0.8582863502593907, 0.8582863502593907, 0.7161294219760594, 0.7161294219760594, 0.7161294219760594, 0.7289718082745743, 0.7289718082745743, 0.7289718082745743, 0.7234191160588807, 0.7234191160588807, 0.7234191160588807, 0.13052065293358317, 0.13052065293358317, 0.13052065293358317, 0.6576368901328465, 0.6576368901328465, 0.6576368901328465, 0.1533495559276078, 0.1533495559276078, 0.1533495559276078, 0.1116579051689418, 0.1116579051689418, 0.1116579051689418, 0.15300417797775967, 0.15300417797775967, 0.15300417797775967, 0.1287251502370671, 0.1287251502370671, 0.1287251502370671, 0.9928958028799606, 0.9928958028799606, 0.9928958028799606, 0.9922970750363702, 0.9922970750363702, 0.9922970750363702, 0.9921249415202164, 0.9921249415202164, 0.9921249415202164, 0.05956391585795995, 0.05956391585795995, 0.05956391585795995, 0.7071472686209841, 0.7071472686209841, 0.7071472686209841, 0.1267905517321225, 0.1267905517321225, 0.1267905517321225, 0.37618653730065144, 0.37618653730065144, 0.37618653730065144, 0.8903242187197665, 0.8903242187197665, 0.8903242187197665, 0.8225568782998747, 0.8225568782998747, 0.8225568782998747, 0.46622838115471754, 0.46622838115471754, 0.46622838115471754, 0.5218342063386125, 0.5218342063386125, 0.5218342063386125, 0.5649906596671697, 0.5649906596671697, 0.5649906596671697, 0.5653434986181003, 0.5653434986181003, 0.5653434986181003, 0.4989240348134112, 0.4989240348134112, 0.4989240348134112, 0.1310391157507511, 0.1310391157507511, 0.1310391157507511, 0.16938031175263546, 0.16938031175263546, 0.16938031175263546, 0.24707246520313586, 0.24707246520313586, 0.24707246520313586, 0.2391544792755218, 0.2391544792755218, 0.2391544792755218, 0.27700916968638556, 0.27700916968638556, 0.27700916968638556, 0.34218201692083383, 0.34218201692083383, 0.34218201692083383, 0.5652538235802772, 0.5652538235802772, 0.5652538235802772, 0.1109952158253873, 0.1109952158253873, 0.1109952158253873, 0.1568477431763029, 0.1568477431763029, 0.1568477431763029, 0.17694629437890275, 0.17694629437890275, 0.17694629437890275, 0.29624149091768026, 0.29624149091768026, 0.29624149091768026, 0.36417508865701975, 0.36417508865701975, 0.36417508865701975, 0.05758185510334768, 0.05758185510334768, 0.05758185510334768, 0.7642948233050905, 0.7642948233050905, 0.7642948233050905, 0.6949919619562747, 0.6949919619562747, 0.6949919619562747, 0.7588915879762745, 0.7588915879762745, 0.7588915879762745, 0.06990617480478689, 0.06990617480478689, 0.06990617480478689, 0.14327845641487513, 0.14327845641487513, 0.14327845641487513, 0.063801267570334, 0.063801267570334, 0.063801267570334, 0.26147236540195196, 0.26147236540195196, 0.26147236540195196, 0.2869082056056572, 0.2869082056056572, 0.2869082056056572, 0.31460566125887424, 0.31460566125887424, 0.31460566125887424, 0.24195500363056088, 0.24195500363056088, 0.24195500363056088, 0.2727019188046915, 0.2727019188046915, 0.2727019188046915, 0.601941334195959, 0.601941334195959, 0.601941334195959, 0.3697566510384036, 0.3697566510384036, 0.3697566510384036, 0.35344330381697564, 0.35344330381697564, 0.35344330381697564, 0.45719426041073585, 0.45719426041073585, 0.45719426041073585, 0.21917971860708363, 0.21917971860708363, 0.21917971860708363, 0.200339242263184, 0.200339242263184, 0.200339242263184, 0.46178057959939367, 0.46178057959939367, 0.46178057959939367, 0.22198807230465034, 0.22198807230465034, 0.22198807230465034, 0.2462096460187161, 0.2462096460187161, 0.2462096460187161, 0.22353363176575225, 0.22353363176575225, 0.22353363176575225, 0.9349063797653724, 0.9349063797653724, 0.9349063797653724, 0.20034715035147765, 0.20034715035147765, 0.20034715035147765, 0.1670284023276758, 0.1670284023276758, 0.1670284023276758, 0.8236634785634748, 0.8236634785634748, 0.8236634785634748, 0.85132713002195, 0.85132713002195, 0.85132713002195, 0.2039722772091891, 0.2039722772091891, 0.2039722772091891, 0.19643285802232724, 0.19643285802232724, 0.19643285802232724, 0.2007770868999763, 0.2007770868999763, 0.2007770868999763, 0.18422338891404122, 0.18422338891404122, 0.18422338891404122, 0.0925622773788205, 0.0925622773788205, 0.0925622773788205, 0.1268796336801763, 0.1268796336801763, 0.1268796336801763, 0.09319638052422685, 0.09319638052422685, 0.09319638052422685]}, "mutation_prompt": null}
{"id": "738ec2ee-a1b6-4691-8880-5d42fd328dec", "solution": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.differential_weight = 0.8\n        self.crossover_prob = 0.9\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n\n    def __call__(self, func):\n        np.random.seed(0)\n        position = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_position = np.copy(position)\n        personal_best_value = np.full(self.population_size, np.inf)\n\n        global_best_position = None\n        global_best_value = np.inf\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                current_value = func(position[i])\n                evaluations += 1\n\n                if current_value < personal_best_value[i]:\n                    personal_best_value[i] = current_value\n                    personal_best_position[i] = position[i]\n\n                if current_value < global_best_value:\n                    global_best_value = current_value\n                    global_best_position = position[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocity and position for PSO\n            inertia_component = self.inertia_weight * velocity\n            cognitive_component = self.cognitive_coef * np.random.rand(self.dim) * (personal_best_position - position)\n            social_component = self.social_coef * np.random.rand(self.dim) * (global_best_position - position)\n            velocity = inertia_component + cognitive_component + social_component\n            position = np.clip(position + velocity, self.lower_bound, self.upper_bound)\n\n            # Dynamic inertia weight adjustment\n            self.inertia_weight = 0.4 + 0.3 * (1 - evaluations / self.budget)\n\n            # Differential Evolution step with dynamic differential weight\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant_vector = np.clip(personal_best_position[a] + self.differential_weight * (personal_best_position[b] - personal_best_position[c]), self.lower_bound, self.upper_bound)\n                trial_vector = np.array([mutant_vector[j] if np.random.rand() < self.crossover_prob else position[i][j] for j in range(self.dim)])\n                \n                trial_value = func(trial_vector)\n                evaluations += 1\n\n                if trial_value < personal_best_value[i]:\n                    personal_best_value[i] = trial_value\n                    personal_best_position[i] = trial_vector\n\n                if trial_value < global_best_value:\n                    global_best_value = trial_value\n                    global_best_position = trial_vector\n\n                # Dynamic differential weight adjustment\n                self.differential_weight = 0.6 + 0.2 * (1 - evaluations / self.budget)\n\n        return global_best_position, global_best_value", "name": "PSO_DE_Optimizer", "description": "Enhanced PSO-DE optimizer by dynamically adjusting inertia and differential weights to balance exploration and exploitation.", "configspace": "", "generation": 1, "fitness": 0.3977394061213141, "feedback": "", "error": "", "parent_id": "cb08ea91-5969-4365-8bca-48d8e8744ffc", "metadata": {"aucs": [0.8725356313414756, 0.8725356313414756, 0.8725356313414756, 0.18990796375679997, 0.18990796375679997, 0.18990796375679997, 0.8810719139679012, 0.8810719139679012, 0.8810719139679012, 0.7676093147058409, 0.7676093147058409, 0.7676093147058409, 0.7884220530869441, 0.7884220530869441, 0.7884220530869441, 0.0185638313870764, 0.0185638313870764, 0.0185638313870764, 0.15570276265883443, 0.15570276265883443, 0.15570276265883443, 0.15342689175215873, 0.15342689175215873, 0.15342689175215873, 0.1795484682459383, 0.1795484682459383, 0.1795484682459383, 0.11422341455964558, 0.11422341455964558, 0.11422341455964558, 0.15864843776212567, 0.15864843776212567, 0.15864843776212567, 0.12950144891195015, 0.12950144891195015, 0.12950144891195015, 0.9928956522255042, 0.9928956522255042, 0.9928956522255042, 0.9922968890865789, 0.9922968890865789, 0.9922968890865789, 0.9921252693543794, 0.9921252693543794, 0.9921252693543794, 0.059594284027001176, 0.059594284027001176, 0.059594284027001176, 0.7227368594698818, 0.7227368594698818, 0.7227368594698818, 0.7899848024721305, 0.7899848024721305, 0.7899848024721305, 0.2254079798469687, 0.2254079798469687, 0.2254079798469687, 0.8448600188387044, 0.8448600188387044, 0.8448600188387044, 0.8559275915123251, 0.8559275915123251, 0.8559275915123251, 0.5341080238732446, 0.5341080238732446, 0.5341080238732446, 0.5923503464852182, 0.5923503464852182, 0.5923503464852182, 0.5114976717152556, 0.5114976717152556, 0.5114976717152556, 0.37416315025679936, 0.37416315025679936, 0.37416315025679936, 0.6387947837849031, 0.6387947837849031, 0.6387947837849031, 0.6127502443624115, 0.6127502443624115, 0.6127502443624115, 0.1968865995041097, 0.1968865995041097, 0.1968865995041097, 0.07793241826174602, 0.07793241826174602, 0.07793241826174602, 0.24468179045836236, 0.24468179045836236, 0.24468179045836236, 0.5688889922778506, 0.5688889922778506, 0.5688889922778506, 0.23742439261473836, 0.23742439261473836, 0.23742439261473836, 0.23352002280345463, 0.23352002280345463, 0.23352002280345463, 0.03608719244381864, 0.03608719244381864, 0.03608719244381864, 0.18537960703488032, 0.18537960703488032, 0.18537960703488032, 0.19872325393430623, 0.19872325393430623, 0.19872325393430623, 0.2845167049772205, 0.2845167049772205, 0.2845167049772205, 0.43812441649666545, 0.43812441649666545, 0.43812441649666545, 0.04958832151018888, 0.04958832151018888, 0.04958832151018888, 0.8034651697816342, 0.8034651697816342, 0.8034651697816342, 0.7946150050399288, 0.7946150050399288, 0.7946150050399288, 0.7187976427772094, 0.7187976427772094, 0.7187976427772094, 0.14311047233920493, 0.14311047233920493, 0.14311047233920493, 0.1419327190790678, 0.1419327190790678, 0.1419327190790678, 0.06161434833693602, 0.06161434833693602, 0.06161434833693602, 0.19050714197767515, 0.19050714197767515, 0.19050714197767515, 0.36472645741573184, 0.36472645741573184, 0.36472645741573184, 0.2687930863074892, 0.2687930863074892, 0.2687930863074892, 0.24688978515880433, 0.24688978515880433, 0.24688978515880433, 0.5273296308889137, 0.5273296308889137, 0.5273296308889137, 0.537493885679103, 0.537493885679103, 0.537493885679103, 0.36720556077730404, 0.36720556077730404, 0.36720556077730404, 0.5192353706067138, 0.5192353706067138, 0.5192353706067138, 0.5488333761964357, 0.5488333761964357, 0.5488333761964357, 0.23680376655977098, 0.23680376655977098, 0.23680376655977098, 0.20313767186000908, 0.20313767186000908, 0.20313767186000908, 0.23744163907824412, 0.23744163907824412, 0.23744163907824412, 0.2217562083315514, 0.2217562083315514, 0.2217562083315514, 0.21908343919319107, 0.21908343919319107, 0.21908343919319107, 0.22271834926002, 0.22271834926002, 0.22271834926002, 0.9314840750920796, 0.9314840750920796, 0.9314840750920796, 0.20059051728338573, 0.20059051728338573, 0.20059051728338573, 0.16716730643590727, 0.16716730643590727, 0.16716730643590727, 0.8688542428783735, 0.8688542428783735, 0.8688542428783735, 0.8731247573725882, 0.8731247573725882, 0.8731247573725882, 0.2041657034262796, 0.2041657034262796, 0.2041657034262796, 0.1899516029967775, 0.1899516029967775, 0.1899516029967775, 0.20046385734272576, 0.20046385734272576, 0.20046385734272576, 0.19411680872251724, 0.19411680872251724, 0.19411680872251724, 0.09898497978336018, 0.09898497978336018, 0.09898497978336018, 0.13672388798550605, 0.13672388798550605, 0.13672388798550605, 0.09570936300484068, 0.09570936300484068, 0.09570936300484068]}, "mutation_prompt": null}

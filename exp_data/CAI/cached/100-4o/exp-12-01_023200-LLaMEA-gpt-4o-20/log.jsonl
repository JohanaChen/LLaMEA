{"id": "cd0bddb6-9bec-48cb-b3cf-de7a7ac86b81", "solution": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.w = 0.7\n        self.F = 0.8\n        self.CR = 0.9\n        self.bounds = (-5.0, 5.0)\n        \n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        \n        # Initialize particles\n        positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        # Evaluate initial particle positions\n        for i in range(self.swarm_size):\n            score = func(positions[i])\n            personal_best_scores[i] = score\n\n        # Identify the global best\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                # Update velocities and positions using PSO rules\n                r1, r2 = np.random.rand(2)\n                velocities[i] = self.w * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - positions[i]) + \\\n                                self.c2 * r2 * (global_best_position - positions[i])\n                positions[i] = positions[i] + velocities[i]\n                \n                # Apply boundary conditions\n                positions[i] = np.clip(positions[i], self.bounds[0], self.bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                if evaluations >= self.budget:\n                    break\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < np.min(personal_best_scores):\n                    global_best_position = positions[i]\n\n            # Hybrid with Differential Evolution mutation strategy\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.swarm_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant_vector = personal_best_positions[a] + self.F * (personal_best_positions[b] - personal_best_positions[c])\n                trial_vector = np.copy(positions[i])\n\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_vector = np.clip(trial_vector, self.bounds[0], self.bounds[1])\n\n                # Evaluate the trial vector\n                score = func(trial_vector)\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = trial_vector\n                \n                # Update global best\n                if score < np.min(personal_best_scores):\n                    global_best_position = trial_vector\n\n        return global_best_position", "name": "PSO_DE_Optimizer", "description": "A hybrid Particle Swarm Optimization and Differential Evolution algorithm that leverages swarm intelligence and mutation strategies for exploring and exploiting the search space.", "configspace": "", "generation": 0, "fitness": 0.2701612728896666, "feedback": "", "error": "", "parent_id": null, "metadata": {"aucs": [0.6059894666001648, 0.6059894666001648, 0.6059894666001648, 0.5728121402331312, 0.5728121402331312, 0.5728121402331312, 0.5944371302685055, 0.5944371302685055, 0.5944371302685055, 0.27022923606958626, 0.27022923606958626, 0.27022923606958626, 0.2633372160143742, 0.2633372160143742, 0.2633372160143742, 0.3095549276449189, 0.3095549276449189, 0.3095549276449189, 0.12902287586727523, 0.12902287586727523, 0.12902287586727523, 0.09934677630147415, 0.09934677630147415, 0.09934677630147415, 0.11114633274742192, 0.11114633274742192, 0.11114633274742192, 0.0880806334667128, 0.0880806334667128, 0.0880806334667128, 0.10249876306956918, 0.10249876306956918, 0.10249876306956918, 0.09252844342164224, 0.09252844342164224, 0.09252844342164224, 0.9818823662533555, 0.9818823662533555, 0.9818823662533555, 0.9798492608663729, 0.9798492608663729, 0.9798492608663729, 0.9791666968135954, 0.9791666968135954, 0.9791666968135954, 0.277277821505149, 0.277277821505149, 0.277277821505149, 0.2471723091382254, 0.2471723091382254, 0.2471723091382254, 0.30136531010514034, 0.30136531010514034, 0.30136531010514034, 0.5550980277568085, 0.5550980277568085, 0.5550980277568085, 0.5878919554186856, 0.5878919554186856, 0.5878919554186856, 0.5675996431148853, 0.5675996431148853, 0.5675996431148853, 0.19851741933207, 0.19851741933207, 0.19851741933207, 0.11800016832312499, 0.11800016832312499, 0.11800016832312499, 0.21792372570703722, 0.21792372570703722, 0.21792372570703722, 0.22752131768357342, 0.22752131768357342, 0.22752131768357342, 0.19981405694119625, 0.19981405694119625, 0.19981405694119625, 0.16568228505381744, 0.16568228505381744, 0.16568228505381744, 0.11149560888944976, 0.11149560888944976, 0.11149560888944976, 0.17374844510723064, 0.17374844510723064, 0.17374844510723064, 0.20380332302200366, 0.20380332302200366, 0.20380332302200366, 0.29047810270308205, 0.29047810270308205, 0.29047810270308205, 0.25015539910190276, 0.25015539910190276, 0.25015539910190276, 0.2842261400261006, 0.2842261400261006, 0.2842261400261006, 0.0663898909462225, 0.0663898909462225, 0.0663898909462225, 0.04558630353440474, 0.04558630353440474, 0.04558630353440474, 0.04265130277812279, 0.04265130277812279, 0.04265130277812279, 0.19912351167367692, 0.19912351167367692, 0.19912351167367692, 0.18463416232934515, 0.18463416232934515, 0.18463416232934515, 0.1709857185051753, 0.1709857185051753, 0.1709857185051753, 0.5043006773737216, 0.5043006773737216, 0.5043006773737216, 0.46829312027503545, 0.46829312027503545, 0.46829312027503545, 0.4942297140118822, 0.4942297140118822, 0.4942297140118822, 0.095350233791764, 0.095350233791764, 0.095350233791764, 0.12905970107601572, 0.12905970107601572, 0.12905970107601572, 0.0969314330368215, 0.0969314330368215, 0.0969314330368215, 0.1505412178065566, 0.1505412178065566, 0.1505412178065566, 0.17654723324771948, 0.17654723324771948, 0.17654723324771948, 0.24179758011659125, 0.24179758011659125, 0.24179758011659125, 0.29143588346119065, 0.29143588346119065, 0.29143588346119065, 0.28964533398651227, 0.28964533398651227, 0.28964533398651227, 0.28575782890525825, 0.28575782890525825, 0.28575782890525825, 0.23650716087844592, 0.23650716087844592, 0.23650716087844592, 0.2314558216625191, 0.2314558216625191, 0.2314558216625191, 0.24742132211231993, 0.24742132211231993, 0.24742132211231993, 0.1767664720128127, 0.1767664720128127, 0.1767664720128127, 0.18788989247670496, 0.18788989247670496, 0.18788989247670496, 0.2568879367077328, 0.2568879367077328, 0.2568879367077328, 0.20076177499875525, 0.20076177499875525, 0.20076177499875525, 0.2202125550389985, 0.2202125550389985, 0.2202125550389985, 0.1742119642318496, 0.1742119642318496, 0.1742119642318496, 0.7414359447488493, 0.7414359447488493, 0.7414359447488493, 0.16473611584421866, 0.16473611584421866, 0.16473611584421866, 0.19068491229671147, 0.19068491229671147, 0.19068491229671147, 0.16891611077732283, 0.16891611077732283, 0.16891611077732283, 0.20421041545253005, 0.20421041545253005, 0.20421041545253005, 0.1541097219205021, 0.1541097219205021, 0.1541097219205021, 0.19917597204286808, 0.19917597204286808, 0.19917597204286808, 0.18653337465306685, 0.18653337465306685, 0.18653337465306685, 0.17523744193680157, 0.17523744193680157, 0.17523744193680157, 0.09000600813826876, 0.09000600813826876, 0.09000600813826876, 0.0736794274471948, 0.0736794274471948, 0.0736794274471948, 0.07985713125392302, 0.07985713125392302, 0.07985713125392302]}, "mutation_prompt": null}
{"id": "9d1597be-cdec-446b-9f86-b177a2f127c6", "solution": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.w_max = 0.9  # Adapted max inertia weight\n        self.w_min = 0.4  # Adapted min inertia weight\n        self.F = 0.8\n        self.CR = 0.9\n        self.bounds = (-5.0, 5.0)\n        \n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        \n        # Initialize particles\n        positions = np.random.uniform(self.bounds[0], self.bounds[1], (self.swarm_size, self.dim))\n        velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        # Evaluate initial particle positions\n        for i in range(self.swarm_size):\n            score = func(positions[i])\n            personal_best_scores[i] = score\n\n        # Identify the global best\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n\n        evaluations = self.swarm_size\n        best_score = np.min(personal_best_scores)\n\n        while evaluations < self.budget:\n            # Update inertia weight dynamically\n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n            \n            for i in range(self.swarm_size):\n                # Update velocities and positions using PSO rules\n                r1, r2 = np.random.rand(2)\n                velocities[i] = w * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - positions[i]) + \\\n                                self.c2 * r2 * (global_best_position - positions[i])\n                positions[i] = positions[i] + velocities[i]\n                \n                # Apply boundary conditions\n                positions[i] = np.clip(positions[i], self.bounds[0], self.bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                if evaluations >= self.budget:\n                    break\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if score < best_score:\n                    global_best_position = positions[i]\n                    best_score = score\n\n            # Hybrid with Differential Evolution mutation strategy\n            for i in range(self.swarm_size):\n                if evaluations >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.swarm_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant_vector = personal_best_positions[a] + self.F * (personal_best_positions[b] - personal_best_positions[c])\n                trial_vector = np.copy(positions[i])\n\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_vector = np.clip(trial_vector, self.bounds[0], self.bounds[1])\n\n                # Evaluate the trial vector\n                score = func(trial_vector)\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = trial_vector\n                \n                # Update global best\n                if score < best_score:\n                    global_best_position = trial_vector\n                    best_score = score\n\n        return global_best_position", "name": "PSO_DE_Optimizer", "description": "An enhanced PSO-DE hybrid algorithm integrating adaptive inertia weights and elitism to improve convergence and exploration.", "configspace": "", "generation": 1, "fitness": 0.28961908057393954, "feedback": "", "error": "", "parent_id": "cd0bddb6-9bec-48cb-b3cf-de7a7ac86b81", "metadata": {"aucs": [0.5548352313433003, 0.5548352313433003, 0.5548352313433003, 0.6017484688267769, 0.6017484688267769, 0.6017484688267769, 0.5979966831150164, 0.5979966831150164, 0.5979966831150164, 0.2629437367370019, 0.2629437367370019, 0.2629437367370019, 0.31591455543635927, 0.31591455543635927, 0.31591455543635927, 0.32628875505472466, 0.32628875505472466, 0.32628875505472466, 0.10814573159815477, 0.10814573159815477, 0.10814573159815477, 0.09880102448863604, 0.09880102448863604, 0.09880102448863604, 0.1138904053583194, 0.1138904053583194, 0.1138904053583194, 0.08591937300979902, 0.08591937300979902, 0.08591937300979902, 0.09097401872825872, 0.09097401872825872, 0.09097401872825872, 0.11481605460267841, 0.11481605460267841, 0.11481605460267841, 0.9863221905169283, 0.9863221905169283, 0.9863221905169283, 0.991284579778477, 0.991284579778477, 0.991284579778477, 0.9803577886421571, 0.9803577886421571, 0.9803577886421571, 0.30921826343697545, 0.30921826343697545, 0.30921826343697545, 0.3014627862858157, 0.3014627862858157, 0.3014627862858157, 0.31305613309838065, 0.31305613309838065, 0.31305613309838065, 0.5289138005961809, 0.5289138005961809, 0.5289138005961809, 0.6567986761264658, 0.6567986761264658, 0.6567986761264658, 0.6040761772254711, 0.6040761772254711, 0.6040761772254711, 0.2530926500718449, 0.2530926500718449, 0.2530926500718449, 0.21090170428726707, 0.21090170428726707, 0.21090170428726707, 0.28364530842953684, 0.28364530842953684, 0.28364530842953684, 0.22694088873952045, 0.22694088873952045, 0.22694088873952045, 0.19238039741052781, 0.19238039741052781, 0.19238039741052781, 0.22047988607024094, 0.22047988607024094, 0.22047988607024094, 0.1424776957206827, 0.1424776957206827, 0.1424776957206827, 0.2047550828476794, 0.2047550828476794, 0.2047550828476794, 0.13079746481078602, 0.13079746481078602, 0.13079746481078602, 0.344471245223681, 0.344471245223681, 0.344471245223681, 0.2963770702594395, 0.2963770702594395, 0.2963770702594395, 0.3477314907430107, 0.3477314907430107, 0.3477314907430107, 0.06825005124232941, 0.06825005124232941, 0.06825005124232941, 0.06839733961257133, 0.06839733961257133, 0.06839733961257133, 0.09075540933332993, 0.09075540933332993, 0.09075540933332993, 0.16920567673967712, 0.16920567673967712, 0.16920567673967712, 0.18593839005195756, 0.18593839005195756, 0.18593839005195756, 0.16924398868390977, 0.16924398868390977, 0.16924398868390977, 0.49609586443758913, 0.49609586443758913, 0.49609586443758913, 0.5020723802638329, 0.5020723802638329, 0.5020723802638329, 0.4742056716054672, 0.4742056716054672, 0.4742056716054672, 0.1092206100217098, 0.1092206100217098, 0.1092206100217098, 0.10831453432904725, 0.10831453432904725, 0.10831453432904725, 0.10356416566625559, 0.10356416566625559, 0.10356416566625559, 0.32356182129016275, 0.32356182129016275, 0.32356182129016275, 0.2506621432381896, 0.2506621432381896, 0.2506621432381896, 0.1655393136510669, 0.1655393136510669, 0.1655393136510669, 0.3145028391258152, 0.3145028391258152, 0.3145028391258152, 0.2785481190960416, 0.2785481190960416, 0.2785481190960416, 0.2999620240973012, 0.2999620240973012, 0.2999620240973012, 0.265009381758311, 0.265009381758311, 0.265009381758311, 0.22734428653431937, 0.22734428653431937, 0.22734428653431937, 0.2510456689880268, 0.2510456689880268, 0.2510456689880268, 0.21355617504222724, 0.21355617504222724, 0.21355617504222724, 0.1846994411781876, 0.1846994411781876, 0.1846994411781876, 0.2040397470167422, 0.2040397470167422, 0.2040397470167422, 0.1863667869010045, 0.1863667869010045, 0.1863667869010045, 0.21766158484168996, 0.21766158484168996, 0.21766158484168996, 0.1928748576505217, 0.1928748576505217, 0.1928748576505217, 0.7524093216571095, 0.7524093216571095, 0.7524093216571095, 0.15740867587010632, 0.15740867587010632, 0.15740867587010632, 0.7059664576279372, 0.7059664576279372, 0.7059664576279372, 0.16887194045418308, 0.16887194045418308, 0.16887194045418308, 0.20448535860491024, 0.20448535860491024, 0.20448535860491024, 0.15483146847031803, 0.15483146847031803, 0.15483146847031803, 0.17649178592377446, 0.17649178592377446, 0.17649178592377446, 0.1986294743349154, 0.1986294743349154, 0.1986294743349154, 0.18843464291899836, 0.18843464291899836, 0.18843464291899836, 0.08623739404893183, 0.08623739404893183, 0.08623739404893183, 0.06283717639054898, 0.06283717639054898, 0.06283717639054898, 0.07751651400453319, 0.07751651400453319, 0.07751651400453319]}, "mutation_prompt": null}

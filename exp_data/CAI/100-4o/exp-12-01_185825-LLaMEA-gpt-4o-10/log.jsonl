{"id": "a927cd73-ac9d-452b-bd30-e3dc0e5678eb", "solution": "import numpy as np\n\nclass DynamicMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.bounds = (-5.0, 5.0)\n        self.num_swarms = 3\n        self.swarm_size = 30\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.velocity_clamp = (0.1 * (self.bounds[1] - self.bounds[0]), 0.1 * (self.bounds[1] - self.bounds[0]))\n        self.current_eval = 0\n    \n    def __call__(self, func):\n        def initialize_particle():\n            position = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n            velocity = np.random.uniform(-1, 1, self.dim)\n            return {'position': position, 'velocity': velocity, 'best_position': position.copy(), 'best_value': float('inf')}\n        \n        swarms = [[initialize_particle() for _ in range(self.swarm_size)] for _ in range(self.num_swarms)]\n        global_best_position = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n        global_best_value = float('inf')\n        \n        while self.current_eval < self.budget:\n            for swarm in swarms:\n                for particle in swarm:\n                    fitness_value = func(particle['position'])\n                    self.current_eval += 1\n                    \n                    if fitness_value < particle['best_value']:\n                        particle['best_value'] = fitness_value\n                        particle['best_position'] = particle['position'].copy()\n\n                    if fitness_value < global_best_value:\n                        global_best_value = fitness_value\n                        global_best_position = particle['position'].copy()\n\n                    if self.current_eval >= self.budget:\n                        break\n\n                if self.current_eval >= self.budget:\n                    break\n            \n            for swarm in swarms:\n                for particle in swarm:\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    cognitive_component = self.cognitive_coeff * r1 * (particle['best_position'] - particle['position'])\n                    social_component = self.social_coeff * r2 * (global_best_position - particle['position'])\n                    particle['velocity'] = (self.inertia_weight * particle['velocity'] +\n                                            cognitive_component +\n                                            social_component)\n\n                    particle['velocity'] = np.clip(particle['velocity'], self.velocity_clamp[0], self.velocity_clamp[1])\n                    particle['position'] += particle['velocity']\n                    particle['position'] = np.clip(particle['position'], self.bounds[0], self.bounds[1])\n\n            # Swarm adaptation logic\n            if self.current_eval % (self.budget // (2 * self.num_swarms)) == 0:\n                # Reinitializing half of the worst performing swarms\n                swarms.sort(key=lambda s: min(p['best_value'] for p in s))\n                for i in range(self.num_swarms // 2):\n                    swarms[-(i+1)] = [initialize_particle() for _ in range(self.swarm_size)]\n\n        return global_best_position, global_best_value", "name": "DynamicMultiSwarmPSO", "description": "A Dynamic Multi-Swarm Particle Swarm Optimization that adapts swarm sizes and leaders based on search performance.", "configspace": "", "generation": 0, "fitness": 0.0636862209010357, "feedback": "", "error": "", "parent_id": null, "metadata": {"aucs": [0.11571714502762132, 0.16905704847855685, 0.1486294163363835, 0.1312774728689201, 0.1075279305261212, 0.0832317108598587, 0.10012384373617855, 0.07432325825933439, 0.10951828747795334, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.022490388700587616, 0.02286728713976771, 0.025358869176704157, 0.028184375931572525, 0.024470430483813255, 0.031216772874287924, 0.028858434377642905, 0.007804745638138044, 0.02074572339249936, 0.02947247965087796, 0.012193045042004469, 0.02318632585416125, 0.02473160696108312, 0.009969662567792748, 0.02923739125643965, 0.027195435324281036, 0.011689108452807573, 0.007110468148290083, 0.04533348441024754, 0.0599959164337841, 0.060886022565308284, 0.05587984589798323, 0.08055708180722854, 0.04867207990124367, 0.05503105642156747, 0.0595887170747752, 0.05354328000649289, 0.03641577885965375, 9.999999999998899e-05, 0.03486362655628583, 0.03851592883343713, 0.00031549654350837564, 0.013185635587125266, 0.029961891646898442, 0.011296694046879385, 0.08977299820249895, 0.11505111704818316, 0.07625225586644702, 0.08875319462947773, 0.09453812554798247, 0.09245568622565459, 0.08158262404934502, 0.10204980389727025, 0.10555460015381757, 0.10043227571353641, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.018155433509030816, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04505923789091071, 0.016224345886461378, 0.01464745442456128, 0.031245932494963213, 9.999999999998899e-05, 0.0023822455168341916, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.22483589757394773, 0.15760210545903552, 0.16306325787960874, 0.1539496993761057, 0.13795151466900246, 0.14060200571278147, 0.17506427020320536, 0.14964768752463664, 0.1328741694193335, 0.03291159605687044, 0.03560443216398512, 0.014961433434548366, 0.022325623836053077, 0.019643416840285144, 0.018199906853401226, 0.01148894026135372, 0.0037503704438198726, 0.026768336265789783, 0.13754121313590617, 0.10811685662650417, 0.11853261449367891, 0.13777041357091024, 0.15428179099793615, 0.09242749973862407, 0.11718238965532624, 0.10588124746485938, 0.10082737667565367, 0.1395513846313985, 0.13219124051074338, 0.13981086809769327, 0.13685288316573574, 0.13635579730153569, 0.16864418981408413, 0.15050139402478124, 0.1413867300110172, 0.14179691359643587, 0.07587163506346295, 0.08444427683483469, 0.07752769727606812, 0.08302747156912771, 0.08468634135031206, 0.10308515060356094, 0.09896725757510216, 0.10032629730481879, 0.0964787057444042, 0.14309130249835966, 0.1184124628434382, 0.13595597576676322, 0.14047661296591474, 0.1268699215616731, 0.14638234998855482, 0.12839203530899923, 0.12112692558244398, 0.12942244117889845, 0.03290846568448902, 0.13667245925264848, 9.999999999998899e-05, 0.0795316143403445, 9.999999999998899e-05, 9.999999999998899e-05, 0.14633354450796765, 0.0035904796986140353, 0.07000856115109055, 0.1618680368854779, 0.10139076875992103, 0.10346076932625659, 0.10570807273308058, 0.10641537208196294, 0.08114307609264382, 0.10708117203048861, 0.11643570265389913, 0.11010632397615938, 0.09568666316291452, 0.10272653344053628, 0.11046386554847265, 0.06870888876633563, 0.08966130463360955, 0.2253460387047087, 0.20972292899037648, 0.11139089322666751, 0.09192428589986279, 0.17968708458040472, 0.22272082949569671, 0.1606977215641031, 0.16788271933910603, 0.22261604008291525, 0.18120097799741874, 0.1704067800747433, 0.15929280449791006, 0.16588761428174092, 0.03391366431502463, 0.028634700127870727, 0.04249149699383781, 0.052920841554979225, 0.05885446619899981, 0.05172226855432038, 0.040720400609710494, 0.0381106167372709, 0.04424600537273349]}, "mutation_prompt": null}
{"id": "7fce7b15-d174-4ca1-acd4-137479f38432", "solution": "import numpy as np\n\nclass DynamicMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.bounds = (-5.0, 5.0)\n        self.num_swarms = 3\n        self.swarm_size = 30\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.velocity_clamp = (0.1 * (self.bounds[1] - self.bounds[0]), 0.1 * (self.bounds[1] - self.bounds[0]))\n        self.current_eval = 0\n    \n    def __call__(self, func):\n        def initialize_particle():\n            position = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n            velocity = np.random.uniform(-1, 1, self.dim)\n            return {'position': position, 'velocity': velocity, 'best_position': position.copy(), 'best_value': float('inf')}\n        \n        swarms = [[initialize_particle() for _ in range(self.swarm_size)] for _ in range(self.num_swarms)]\n        global_best_position = np.random.uniform(self.bounds[0], self.bounds[1], self.dim)\n        global_best_value = float('inf')\n        \n        while self.current_eval < self.budget:\n            for swarm in swarms:\n                for particle in swarm:\n                    fitness_value = func(particle['position'])\n                    self.current_eval += 1\n                    \n                    if fitness_value < particle['best_value']:\n                        particle['best_value'] = fitness_value\n                        particle['best_position'] = particle['position'].copy()\n\n                    if fitness_value < global_best_value:\n                        global_best_value = fitness_value\n                        global_best_position = particle['position'].copy()\n\n                    if self.current_eval >= self.budget:\n                        break\n\n                if self.current_eval >= self.budget:\n                    break\n            \n            for swarm in swarms:\n                for particle in swarm:\n                    r1, r2 = np.random.rand(), np.random.rand()\n                    cognitive_component = self.cognitive_coeff * r1 * (particle['best_position'] - particle['position'])\n                    social_component = self.social_coeff * r2 * (global_best_position - particle['position'])\n                    particle['velocity'] = (self.inertia_weight * particle['velocity'] +\n                                            cognitive_component +\n                                            social_component)\n\n                    particle['velocity'] = np.clip(particle['velocity'], self.velocity_clamp[0], self.velocity_clamp[1])\n                    particle['position'] += particle['velocity']\n                    particle['position'] = np.clip(particle['position'], self.bounds[0], self.bounds[1])\n\n            # Swarm adaptation logic\n            if self.current_eval % (self.budget // (2 * self.num_swarms)) == 0:\n                # Reinitializing half of the worst performing swarms\n                swarms.sort(key=lambda s: min(p['best_value'] for p in s))\n                for i in range(self.num_swarms // 2):\n                    swarms[-(i+1)] = [initialize_particle() for _ in range(self.swarm_size)]\n\n        return global_best_position, global_best_value", "name": "DynamicMultiSwarmPSO", "description": "A Dynamic Multi-Swarm Particle Swarm Optimization that adapts swarm sizes and leaders based on search performance.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a927cd73-ac9d-452b-bd30-e3dc0e5678eb", "metadata": {"aucs": [0.11571714502762132, 0.16905704847855685, 0.1486294163363835, 0.1312774728689201, 0.1075279305261212, 0.0832317108598587, 0.10012384373617855, 0.07432325825933439, 0.10951828747795334, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.022490388700587616, 0.02286728713976771, 0.025358869176704157, 0.028184375931572525, 0.024470430483813255, 0.031216772874287924, 0.028858434377642905, 0.007804745638138044, 0.02074572339249936, 0.02947247965087796, 0.012193045042004469, 0.02318632585416125, 0.02473160696108312, 0.009969662567792748, 0.02923739125643965, 0.027195435324281036, 0.011689108452807573, 0.007110468148290083, 0.04533348441024754, 0.0599959164337841, 0.060886022565308284, 0.05587984589798323, 0.08055708180722854, 0.04867207990124367, 0.05503105642156747, 0.0595887170747752, 0.05354328000649289, 0.03641577885965375, 9.999999999998899e-05, 0.03486362655628583, 0.03851592883343713, 0.00031549654350837564, 0.013185635587125266, 0.029961891646898442, 0.011296694046879385, 0.08977299820249895, 0.11505111704818316, 0.07625225586644702, 0.08875319462947773, 0.09453812554798247, 0.09245568622565459, 0.08158262404934502, 0.10204980389727025, 0.10555460015381757, 0.10043227571353641, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.018155433509030816, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04505923789091071, 0.016224345886461378, 0.01464745442456128, 0.031245932494963213, 9.999999999998899e-05, 0.0023822455168341916, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.22483589757394773, 0.15760210545903552, 0.16306325787960874, 0.1539496993761057, 0.13795151466900246, 0.14060200571278147, 0.17506427020320536, 0.14964768752463664, 0.1328741694193335, 0.03291159605687044, 0.03560443216398512, 0.014961433434548366, 0.022325623836053077, 0.019643416840285144, 0.018199906853401226, 0.01148894026135372, 0.0037503704438198726, 0.026768336265789783, 0.13754121313590617, 0.10811685662650417, 0.11853261449367891, 0.13777041357091024, 0.15428179099793615, 0.09242749973862407, 0.11718238965532624, 0.10588124746485938, 0.10082737667565367, 0.1395513846313985, 0.13219124051074338, 0.13981086809769327, 0.13685288316573574, 0.13635579730153569, 0.16864418981408413, 0.15050139402478124, 0.1413867300110172, 0.14179691359643587, 0.07587163506346295, 0.08444427683483469, 0.07752769727606812, 0.08302747156912771, 0.08468634135031206, 0.10308515060356094, 0.09896725757510216, 0.10032629730481879, 0.0964787057444042, 0.14309130249835966, 0.1184124628434382, 0.13595597576676322, 0.14047661296591474, 0.1268699215616731, 0.14638234998855482, 0.12839203530899923, 0.12112692558244398, 0.12942244117889845, 0.03290846568448902, 0.13667245925264848, 9.999999999998899e-05, 0.0795316143403445, 9.999999999998899e-05, 9.999999999998899e-05, 0.14633354450796765, 0.0035904796986140353, 0.07000856115109055, 0.1618680368854779, 0.10139076875992103, 0.10346076932625659, 0.10570807273308058, 0.10641537208196294, 0.08114307609264382, 0.10708117203048861, 0.11643570265389913, 0.11010632397615938, 0.09568666316291452, 0.10272653344053628, 0.11046386554847265, 0.06870888876633563, 0.08966130463360955, 0.2253460387047087, 0.20972292899037648, 0.11139089322666751, 0.09192428589986279, 0.17968708458040472, 0.22272082949569671, 0.1606977215641031, 0.16788271933910603, 0.22261604008291525, 0.18120097799741874, 0.1704067800747433, 0.15929280449791006, 0.16588761428174092, 0.03391366431502463, 0.028634700127870727, 0.04249149699383781, 0.052920841554979225, 0.05885446619899981, 0.05172226855432038, 0.040720400609710494, 0.0381106167372709, 0.04424600537273349]}, "mutation_prompt": null}

{"id": "4720e5d8-9592-42ad-95cb-b0379a08dfb4", "solution": "import numpy as np\n\nclass PSO_ADM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Population size\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1\n        self.f = 0.5  # Differential mutation factor\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.velocity_limit, self.velocity_limit, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        # Evaluate initial population\n        scores = np.apply_along_axis(func, 1, positions)\n        evaluations = self.pop_size\n\n        # Initialize global best\n        global_best_index = np.argmin(scores)\n        global_best_position = positions[global_best_index]\n        global_best_score = scores[global_best_index]\n\n        # Main optimization loop\n        while evaluations < self.budget:\n            for i in range(self.pop_size):\n                # Update velocities\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                social_velocity = self.c2 * r2 * (global_best_position - positions[i])\n                velocities[i] = self.w * velocities[i] + cognitive_velocity + social_velocity\n                velocities[i] = np.clip(velocities[i], -self.velocity_limit, self.velocity_limit)\n\n                # Update positions\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], self.lower_bound, self.upper_bound)\n                \n                # Apply adaptive differential mutation\n                if np.random.rand() < 0.1:  # 10% chance to apply mutation\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    mutant = positions[indices[0]] + self.f * (positions[indices[1]] - positions[indices[2]])\n                    mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                    if func(mutant) < scores[i]:\n                        positions[i] = mutant\n\n                # Evaluate new positions\n                new_score = func(positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_score < personal_best_scores[i]:\n                    personal_best_scores[i] = new_score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if new_score < global_best_score:\n                    global_best_score = new_score\n                    global_best_position = positions[i]\n\n                # Check if budget is exceeded\n                if evaluations >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "PSO_ADM", "description": "A hybrid Particle Swarm Optimization with Adaptive Differential Mutation to enhance exploration and exploitation balance.", "configspace": "", "generation": 0, "fitness": 0.32502098562757725, "feedback": "", "error": "", "parent_id": null, "metadata": {"aucs": [0.88352495750521, 0.8605635007602068, 0.89808250856134, 0.8069739309105322, 0.8630992223853624, 0.8445862046683448, 0.8792336165455418, 0.837892616854005, 0.8614806932779269, 0.7363408663752976, 0.7074431384094814, 0.6918336794879114, 0.7753588446084039, 0.6046288969828311, 0.6434197226000248, 0.7375548689745988, 0.6601475954641436, 0.6518845708763077, 0.14327959078066976, 0.14220849635703758, 0.1109361304269958, 0.10624288480023547, 0.12650294987880584, 0.15505167109312046, 0.15625542439960516, 0.13394749611732548, 0.15981950160685532, 0.11716938286711776, 0.11341642838341448, 0.11723694699827336, 0.14358790704897073, 0.15242391263971644, 0.13564025227099197, 0.14903701186604235, 0.08539312976115765, 0.12634521199752213, 0.9600958612413536, 0.9665599965554155, 0.964379525720996, 0.9582305890296227, 0.9580944928525928, 0.9630787335844266, 0.9638174894021506, 0.9482411914086841, 0.9646717624274346, 0.627182321744651, 0.5634463529516607, 0.5227679120911011, 0.5478717627792417, 0.6108784300332252, 0.6363305134342674, 0.6411948170447276, 0.5673575218172289, 0.5952855989021487, 0.39217351420613156, 0.3811291560317315, 0.14121887003526934, 0.2832603370306237, 0.28123387991225746, 0.21489908869417407, 0.9108466773313327, 0.17337590353237609, 0.8262414669091988, 0.25045692713660883, 0.1317201130500114, 0.1942746154989533, 0.1983654668863022, 0.19782686563051155, 0.2331861663985052, 0.2997830840833925, 0.22577412195377378, 0.20419057989239453, 0.13696729097834903, 0.19863203539167784, 0.22291003996712722, 0.19245676306768, 0.19619703186756832, 0.2123689183199332, 0.2512093807099639, 0.23966606096212317, 0.2588244175842912, 0.04835365340758868, 0.013834709102746645, 0.010883079338781632, 0.05420078615934942, 0.07383408372933864, 9.999999999998899e-05, 0.06240036719931652, 9.999999999998899e-05, 9.999999999998899e-05, 0.1718673202797878, 0.07023587073235327, 0.12093398576419911, 0.06789516894753955, 0.04216597615081297, 0.024746807174612195, 0.08025627715012373, 0.06534269053744124, 0.1171301232328249, 0.04657960030016983, 0.07223761448803234, 0.2562839752313546, 0.13282047768800875, 0.15146575893671377, 0.15427956355489592, 0.2223000655948968, 0.13652703201292438, 0.07399644401602323, 0.2276471246276317, 0.10273408422302743, 0.22105260964436058, 0.3212882884923698, 0.18424775416768358, 0.04602428242650691, 0.08364142540516672, 0.1387403161872428, 0.08395882123295562, 0.50808044969747, 0.543130216017657, 0.5812224023708298, 0.5565713026326012, 0.5382244824480635, 0.5661713947284326, 0.5644110296498499, 0.5722523147242242, 0.555157468815477, 0.06912165341912169, 0.1311017308769964, 0.10564392426325064, 0.12653116544406107, 0.08306020581489226, 0.1352074969044803, 0.14364692691121417, 0.10995917453898785, 0.12504298790776158, 0.48322915212383255, 0.4283720820475052, 0.21347667286503125, 0.516823608967227, 0.33712155192043636, 0.23132726292709926, 0.17576431602411358, 0.2522731946538417, 0.25275304576491087, 0.2388868139815531, 0.4458970084095557, 0.44136409389855935, 0.32318109737361544, 0.3613328210007044, 0.5008020909615674, 0.25595864199001783, 0.5217112669871053, 0.2566751360845031, 0.29207955577728495, 0.3848497538651261, 0.18094799855344157, 0.2431461444823375, 0.19032640857409555, 0.23689684443019288, 0.23878161770081685, 0.24904210335526444, 0.22976061710624585, 0.22235513671008478, 0.18079718716558035, 0.2450146824587277, 0.21456394522118905, 0.2621425670063926, 0.2303942000450323, 0.2249345897497611, 0.22315919530912764, 0.21889106729775598, 0.22670045319607268, 0.24261528579842384, 0.1899635277777424, 0.21092943785522666, 0.19477521999434955, 0.24440548738463397, 0.21064119437488293, 0.20554294375681192, 0.2083473184615906, 0.1888068451994035, 0.1787541897857733, 0.15377298655713145, 0.8856777762025994, 0.2016446461026219, 0.9601425218892361, 0.1229964632743713, 0.17010279956821084, 0.9293320261096903, 0.611396671835722, 0.15670622728122563, 0.8418071668447904, 0.2124676407677748, 0.16988228135142258, 0.2120419645775724, 0.681622369558381, 0.16768240315625427, 0.8242835580081835, 0.20427066113171377, 0.18906976353779992, 0.19733543705016365, 0.21460491108475122, 0.18818919151374658, 0.2096183210637026, 0.2118463715663058, 0.2107053764275464, 0.2205145967034312, 0.09193798666179664, 0.08188748526387613, 0.077723722482817, 0.10168099539048348, 0.0898120050130079, 0.10834542482920717, 0.09283939237698724, 0.10145117027624784, 0.0826653287966852]}, "mutation_prompt": null}
{"id": "24cc4c4d-9c93-4875-b96b-f990b7d110ec", "solution": "import numpy as np\n\nclass PSO_ADM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30  # Population size\n        self.w = 0.9  # Initial inertia weight\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.c3 = 0.5  # Personal-best velocity component\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.velocity_limit = (self.upper_bound - self.lower_bound) * 0.1\n        self.f = 0.5  # Differential mutation factor\n\n    def __call__(self, func):\n        # Initialize positions and velocities\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-self.velocity_limit, self.velocity_limit, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.pop_size, np.inf)\n\n        # Evaluate initial population\n        scores = np.apply_along_axis(func, 1, positions)\n        evaluations = self.pop_size\n\n        # Initialize global best\n        global_best_index = np.argmin(scores)\n        global_best_position = positions[global_best_index]\n        global_best_score = scores[global_best_index]\n\n        # Main optimization loop\n        while evaluations < self.budget:\n            # Dynamic inertia weight\n            self.w = 0.9 - (0.5 * (evaluations / self.budget))\n            for i in range(self.pop_size):\n                # Update velocities\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                social_velocity = self.c2 * r2 * (global_best_position - positions[i])\n                personal_velocity = self.c3 * r3 * (personal_best_positions[i] - global_best_position)\n                velocities[i] = self.w * velocities[i] + cognitive_velocity + social_velocity + personal_velocity\n                velocities[i] = np.clip(velocities[i], -self.velocity_limit, self.velocity_limit)\n\n                # Update positions\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], self.lower_bound, self.upper_bound)\n                \n                # Apply adaptive differential mutation\n                if np.random.rand() < 0.1:  # 10% chance to apply mutation\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    mutant = positions[indices[0]] + self.f * (positions[indices[1]] - positions[indices[2]])\n                    mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                    if func(mutant) < scores[i]:\n                        positions[i] = mutant\n\n                # Evaluate new positions\n                new_score = func(positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_score < personal_best_scores[i]:\n                    personal_best_scores[i] = new_score\n                    personal_best_positions[i] = positions[i]\n\n                # Update global best\n                if new_score < global_best_score:\n                    global_best_score = new_score\n                    global_best_position = positions[i]\n\n                # Check if budget is exceeded\n                if evaluations >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "PSO_ADM", "description": "Enhance the original algorithm by introducing dynamic inertia weight and a new personal-best velocity component for improved convergence.", "configspace": "", "generation": 1, "fitness": 0.234727034937661, "feedback": "", "error": "", "parent_id": "4720e5d8-9592-42ad-95cb-b0379a08dfb4", "metadata": {"aucs": [0.5257516497197888, 0.5312829195374147, 0.4541462243737382, 0.49345931841444357, 0.5378090976326209, 0.48801406034564354, 0.5254444679106288, 0.4566602212084735, 0.5057821234235216, 0.14326027265830654, 0.16130924733908758, 0.12657543841723795, 0.14710426201763183, 0.1599892662794422, 0.11560414941171404, 0.08587602775115233, 0.11386731950556406, 0.10900067758865895, 0.12487060990153787, 0.11097503530181407, 0.12767876745608409, 0.11649828145572394, 0.11876021366137524, 0.1105334315387374, 0.11716438062488, 0.1280690687488124, 0.12071428453324429, 0.1017723921687197, 0.11237890905778203, 0.10328872835777947, 0.11207964487640476, 0.10133207244565623, 0.08389752770174963, 0.11084265106784008, 0.1036237017457241, 0.10421614102773569, 0.9622684225691173, 0.9669715115515372, 0.9640263320608907, 0.9672988967757324, 0.9638696821333681, 0.9564771912904284, 0.9698645265148041, 0.94941906882927, 0.9564445337992141, 0.2953316830197761, 0.3050639394296235, 0.3264383562604104, 0.3387596401851394, 0.29468041245766985, 0.32361979485411485, 0.2721977526343361, 0.30801442808480706, 0.26394641838491983, 0.4538747420303356, 0.5243950756454188, 0.30509997900663444, 0.27991481322116574, 0.5004507911229865, 0.5985182450120561, 0.44209324237339576, 0.20317700751162293, 0.3010953661464324, 0.15844218859914383, 0.16567219400935718, 0.17423979246528887, 0.16745297363479927, 0.15039707860274798, 0.13987987066357455, 0.15553129498872786, 0.13066716923217447, 0.14688106612711904, 0.17254259078855194, 0.19092751518656736, 0.1549352044320791, 0.15484949480476662, 0.16295006060207928, 0.12354973764397947, 0.1655222934744952, 0.1459013106842112, 0.16092811358160686, 0.022730601826128627, 0.0006649472865642991, 9.999999999998899e-05, 0.013680654827310734, 0.008758805108035395, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10717378611029194, 0.07919807786370825, 0.14264305405093125, 0.08461864320707246, 0.028919521740196963, 0.05976820998823473, 0.0954351157386194, 0.09408984727290148, 0.06197647180720156, 0.013940423420472636, 0.023505971506515788, 0.004225623537072343, 0.001971097025291746, 0.004687332907340358, 0.026823699899860887, 9.999999999998899e-05, 0.0002872072331249198, 0.0163929753425186, 0.09756252436471546, 0.09415532751718747, 0.07689309652316001, 0.09106911464187539, 0.1101607548326643, 0.09108396793961893, 0.061182280045589454, 0.06379697578109467, 0.06536507720646056, 0.410692387562938, 0.4125361683418872, 0.4139860917764747, 0.4369278786622526, 0.41937313503667917, 0.40598385994829456, 0.4133896304924609, 0.3907531649147564, 0.3918919434991417, 0.09362972983919848, 0.10118558943504052, 0.1113700302293611, 0.11386496157061154, 0.1031230770301772, 0.10709814898833725, 0.10479146407584905, 0.10670185771254836, 0.1173711399311973, 0.21786849268602415, 0.20082683518679934, 0.23055574062286543, 0.2289040604122563, 0.2900724699790359, 0.23184468738264774, 0.21739210475259285, 0.2344594929244369, 0.21604157767876864, 0.30237624223465365, 0.2748466593660027, 0.2723975847719189, 0.3132176800462204, 0.29383967990313276, 0.27939175406487415, 0.2923919884737708, 0.29886774476978417, 0.2672249688261338, 0.21828314433924678, 0.21520617995745328, 0.20419165376809534, 0.20013350322765522, 0.21813496779651065, 0.2241497753102749, 0.21920115762523673, 0.23325649632280843, 0.2045595188981446, 0.21338201572760462, 0.2136677873205065, 0.2316308606897426, 0.20635333539575373, 0.21856713840994857, 0.2343695912739706, 0.22750299875937607, 0.2548926673785177, 0.21701240817537237, 0.20770982680069328, 0.18381168569462203, 0.1950309876510231, 0.1915175398056188, 0.19260289088184968, 0.23211981989401897, 0.18510477888602694, 0.19129760300033527, 0.1952769265093064, 0.18462654719195837, 0.6121886420690172, 0.18131822275631215, 0.6708702270931837, 0.1969724557504855, 0.16781020675617742, 0.12078074648239001, 0.1694348464049774, 0.5696880666191119, 0.5720995884193432, 0.15537216857464986, 0.11041995151794204, 0.5046570830539073, 0.16799707281602005, 0.5120271229987085, 0.57581596594829, 0.10442926871125224, 0.43405670962146636, 0.18038668911418698, 0.16995912521017964, 0.1808391063061543, 0.19433607419492904, 0.1907819364715717, 0.1885557536751239, 0.2050730291242897, 0.1819559129726397, 0.19384081578811996, 0.07918885124546027, 0.08339810081275356, 0.09471922700738522, 0.08544129772841391, 0.09950293665313625, 0.0998795173169803, 0.0911914210515502, 0.09349287580660315, 0.0841991264563623]}, "mutation_prompt": null}

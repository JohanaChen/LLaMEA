{"id": "1e4bed2f-b46c-4ccd-ad63-1749c4496f29", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.de_cross_prob = 0.9\n        self.de_diff_weight = 0.8\n        self.pso_inertia_weight = 0.5\n        self.pso_cognitive_weight = 1.5\n        self.pso_social_weight = 1.5\n\n    def __call__(self, func):\n        np.random.seed(0)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        personal_best_positions = np.copy(pop)\n        personal_best_fitness = np.copy(fitness)\n        global_best_position = pop[np.argmin(fitness)]\n        global_best_fitness = np.min(fitness)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.de_diff_weight * (b - c), self.lower_bound, self.upper_bound)\n                cross_points = np.random.rand(self.dim) < self.de_cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n            \n            # Particle Swarm Optimization Update\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.pso_inertia_weight * velocities[i] +\n                                 self.pso_cognitive_weight * r1 * (personal_best_positions[i] - pop[i]) +\n                                 self.pso_social_weight * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], self.lower_bound, self.upper_bound)\n                current_fitness = func(pop[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best_position = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best_position, global_best_fitness", "name": "HybridDEPSO", "description": "A hybrid differential evolution and particle swarm optimization algorithm that balances exploration and exploitation for efficient black box optimization.", "configspace": "", "generation": 0, "fitness": 0.3150324542864677, "feedback": "", "error": "", "parent_id": null, "metadata": {"aucs": [0.8718103575413383, 0.8718103575413383, 0.8718103575413383, 0.9039190124838017, 0.9039190124838017, 0.9039190124838017, 0.9065515999022784, 0.9065515999022784, 0.9065515999022784, 0.6346451144886944, 0.6346451144886944, 0.6346451144886944, 0.794868637405087, 0.794868637405087, 0.794868637405087, 0.6952993311574232, 0.6952993311574232, 0.6952993311574232, 0.11281032512107136, 0.11281032512107136, 0.11281032512107136, 0.10959743060321747, 0.10959743060321747, 0.10959743060321747, 0.12595523822756682, 0.12595523822756682, 0.12595523822756682, 0.09783016528529243, 0.09783016528529243, 0.09783016528529243, 0.0954094336511192, 0.0954094336511192, 0.0954094336511192, 0.12786581369257832, 0.12786581369257832, 0.12786581369257832, 0.9915645590547798, 0.9915645590547798, 0.9915645590547798, 0.9843549654693914, 0.9843549654693914, 0.9843549654693914, 0.9922733246959285, 0.9922733246959285, 0.9922733246959285, 0.6945019816686402, 0.6945019816686402, 0.6945019816686402, 0.7386843556466307, 0.7386843556466307, 0.7386843556466307, 0.7388629868748058, 0.7388629868748058, 0.7388629868748058, 0.22864749758617242, 0.22864749758617242, 0.22864749758617242, 0.7065555411889795, 0.7065555411889795, 0.7065555411889795, 0.13221865902351693, 0.13221865902351693, 0.13221865902351693, 0.12903958490906875, 0.12903958490906875, 0.12903958490906875, 0.2663795135409136, 0.2663795135409136, 0.2663795135409136, 0.2781167024842611, 0.2781167024842611, 0.2781167024842611, 0.25740013492621006, 0.25740013492621006, 0.25740013492621006, 0.3166799015233419, 0.3166799015233419, 0.3166799015233419, 0.2692944218766974, 0.2692944218766974, 0.2692944218766974, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05739268338889547, 0.05739268338889547, 0.05739268338889547, 0.047207832623541224, 0.047207832623541224, 0.047207832623541224, 0.048468806433809575, 0.048468806433809575, 0.048468806433809575, 0.06462447767200286, 0.06462447767200286, 0.06462447767200286, 0.11553638486092899, 0.11553638486092899, 0.11553638486092899, 0.049263838907423474, 0.049263838907423474, 0.049263838907423474, 0.07683458345620242, 0.07683458345620242, 0.07683458345620242, 0.1541660713715517, 0.1541660713715517, 0.1541660713715517, 0.0438689369187365, 0.0438689369187365, 0.0438689369187365, 0.05412975074462212, 0.05412975074462212, 0.05412975074462212, 0.04983425661007601, 0.04983425661007601, 0.04983425661007601, 0.5229085900640762, 0.5229085900640762, 0.5229085900640762, 0.5784510080747952, 0.5784510080747952, 0.5784510080747952, 0.574311007551187, 0.574311007551187, 0.574311007551187, 0.10019634746056616, 0.10019634746056616, 0.10019634746056616, 0.1322020164588179, 0.1322020164588179, 0.1322020164588179, 0.08988331136869088, 0.08988331136869088, 0.08988331136869088, 0.22840906036181563, 0.22840906036181563, 0.22840906036181563, 0.19824544778329778, 0.19824544778329778, 0.19824544778329778, 0.19764556346047146, 0.19764556346047146, 0.19764556346047146, 0.2621658835474493, 0.2621658835474493, 0.2621658835474493, 0.5865038663036892, 0.5865038663036892, 0.5865038663036892, 0.40336911772197537, 0.40336911772197537, 0.40336911772197537, 0.3357000830708282, 0.3357000830708282, 0.3357000830708282, 0.21640863879655492, 0.21640863879655492, 0.21640863879655492, 0.25308790794997027, 0.25308790794997027, 0.25308790794997027, 0.24894876273697142, 0.24894876273697142, 0.24894876273697142, 0.2049451464561194, 0.2049451464561194, 0.2049451464561194, 0.19924618588498155, 0.19924618588498155, 0.19924618588498155, 0.21676973118691256, 0.21676973118691256, 0.21676973118691256, 0.21646559653180952, 0.21646559653180952, 0.21646559653180952, 0.17867814923505954, 0.17867814923505954, 0.17867814923505954, 0.18754733882894536, 0.18754733882894536, 0.18754733882894536, 0.17237034102076654, 0.17237034102076654, 0.17237034102076654, 0.09988775012143525, 0.09988775012143525, 0.09988775012143525, 0.08317012627543918, 0.08317012627543918, 0.08317012627543918, 0.7271144220465556, 0.7271144220465556, 0.7271144220465556, 0.6073496320908938, 0.6073496320908938, 0.6073496320908938, 0.19775314915832365, 0.19775314915832365, 0.19775314915832365, 0.18823354458145136, 0.18823354458145136, 0.18823354458145136, 0.19962892177240243, 0.19962892177240243, 0.19962892177240243, 0.1155817941193854, 0.1155817941193854, 0.1155817941193854, 0.10359453448134703, 0.10359453448134703, 0.10359453448134703, 0.09299951910609672, 0.09299951910609672, 0.09299951910609672]}, "mutation_prompt": null}
{"id": "6c0fca54-3209-47d3-8c22-f385a96b41b1", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.de_cross_prob = 0.9\n        self.de_diff_weight = 0.8\n        self.pso_inertia_weight = 0.5\n        self.pso_cognitive_weight = 1.5\n        self.pso_social_weight = 1.5\n\n    def __call__(self, func):\n        np.random.seed(0)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        personal_best_positions = np.copy(pop)\n        personal_best_fitness = np.copy(fitness)\n        global_best_position = pop[np.argmin(fitness)]\n        global_best_fitness = np.min(fitness)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                current_de_diff_weight = self.de_diff_weight * (1 - evaluations / self.budget) + 0.4 * (evaluations / self.budget)  # Dynamic DE differential weight\n                mutant = np.clip(a + current_de_diff_weight * (b - c), self.lower_bound, self.upper_bound)\n                cross_points = np.random.rand(self.dim) < self.de_cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n            \n            # Particle Swarm Optimization Update\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.pso_inertia_weight * velocities[i] +\n                                 self.pso_cognitive_weight * r1 * (personal_best_positions[i] - pop[i]) +\n                                 self.pso_social_weight * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], self.lower_bound, self.upper_bound)\n                current_fitness = func(pop[i])\n                evaluations += 1\n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best_position = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best_position, global_best_fitness", "name": "HybridDEPSO", "description": "Improved HybridDEPSO by adding a dynamic adjustment of DE differential weight based on evaluation progress for enhanced convergence performance.", "configspace": "", "generation": 1, "fitness": 0.29193230143928384, "feedback": "", "error": "", "parent_id": "1e4bed2f-b46c-4ccd-ad63-1749c4496f29", "metadata": {"aucs": [0.8797571915070896, 0.8797571915070896, 0.8797571915070896, 0.894656225469676, 0.894656225469676, 0.894656225469676, 0.9074164880843663, 0.9074164880843663, 0.9074164880843663, 0.761775916019002, 0.761775916019002, 0.761775916019002, 0.06646586615800787, 0.06646586615800787, 0.06646586615800787, 0.6632838979686977, 0.6632838979686977, 0.6632838979686977, 0.11285563185032566, 0.11285563185032566, 0.11285563185032566, 0.12290634820995616, 0.12290634820995616, 0.12290634820995616, 0.13825077311781497, 0.13825077311781497, 0.13825077311781497, 0.12153499329559403, 0.12153499329559403, 0.12153499329559403, 0.12824694307151363, 0.12824694307151363, 0.12824694307151363, 0.12347112275915861, 0.12347112275915861, 0.12347112275915861, 0.9915644876967004, 0.9915644876967004, 0.9915644876967004, 0.984249281567054, 0.984249281567054, 0.984249281567054, 0.9922729253840169, 0.9922729253840169, 0.9922729253840169, 0.7174583372396389, 0.7174583372396389, 0.7174583372396389, 0.15206702398748362, 0.15206702398748362, 0.15206702398748362, 0.0884764232408497, 0.0884764232408497, 0.0884764232408497, 0.21451636358932624, 0.21451636358932624, 0.21451636358932624, 0.2784810069041207, 0.2784810069041207, 0.2784810069041207, 0.15417416543140772, 0.15417416543140772, 0.15417416543140772, 0.1495444793592331, 0.1495444793592331, 0.1495444793592331, 0.2870637943305916, 0.2870637943305916, 0.2870637943305916, 0.2820776400355941, 0.2820776400355941, 0.2820776400355941, 0.2622652630592628, 0.2622652630592628, 0.2622652630592628, 0.314720666633558, 0.314720666633558, 0.314720666633558, 0.2864963708003082, 0.2864963708003082, 0.2864963708003082, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03557604206902765, 0.03557604206902765, 0.03557604206902765, 0.02426809717360412, 0.02426809717360412, 0.02426809717360412, 0.05771056242112593, 0.05771056242112593, 0.05771056242112593, 0.06800600749667951, 0.06800600749667951, 0.06800600749667951, 0.12381248267521949, 0.12381248267521949, 0.12381248267521949, 0.049111370324564474, 0.049111370324564474, 0.049111370324564474, 0.07704950208098926, 0.07704950208098926, 0.07704950208098926, 0.14849843420368325, 0.14849843420368325, 0.14849843420368325, 0.043756118077131534, 0.043756118077131534, 0.043756118077131534, 0.0780786184031651, 0.0780786184031651, 0.0780786184031651, 0.0495189896853, 0.0495189896853, 0.0495189896853, 0.5671481933852445, 0.5671481933852445, 0.5671481933852445, 0.5953394945121895, 0.5953394945121895, 0.5953394945121895, 0.6009305905395588, 0.6009305905395588, 0.6009305905395588, 0.1164583781468933, 0.1164583781468933, 0.1164583781468933, 0.14472611284018855, 0.14472611284018855, 0.14472611284018855, 0.18549559489084133, 0.18549559489084133, 0.18549559489084133, 0.3708445997825588, 0.3708445997825588, 0.3708445997825588, 0.3306681658005186, 0.3306681658005186, 0.3306681658005186, 0.20062430879860993, 0.20062430879860993, 0.20062430879860993, 0.2307092233698228, 0.2307092233698228, 0.2307092233698228, 0.2335824640508144, 0.2335824640508144, 0.2335824640508144, 0.5699388640907144, 0.5699388640907144, 0.5699388640907144, 0.2519463572250914, 0.2519463572250914, 0.2519463572250914, 0.34457378625591695, 0.34457378625591695, 0.34457378625591695, 0.3743948558946264, 0.3743948558946264, 0.3743948558946264, 0.20964265952364958, 0.20964265952364958, 0.20964265952364958, 0.2183333198573173, 0.2183333198573173, 0.2183333198573173, 0.2291304930925453, 0.2291304930925453, 0.2291304930925453, 0.1981646538055104, 0.1981646538055104, 0.1981646538055104, 0.20927417606798537, 0.20927417606798537, 0.20927417606798537, 0.20468104018309574, 0.20468104018309574, 0.20468104018309574, 0.18748078432695636, 0.18748078432695636, 0.18748078432695636, 0.17238040506027996, 0.17238040506027996, 0.17238040506027996, 0.0998852545471347, 0.0998852545471347, 0.0998852545471347, 0.08322737001214775, 0.08322737001214775, 0.08322737001214775, 0.7452072713200832, 0.7452072713200832, 0.7452072713200832, 0.6407405671644157, 0.6407405671644157, 0.6407405671644157, 0.18723786829820088, 0.18723786829820088, 0.18723786829820088, 0.18739012234951902, 0.18739012234951902, 0.18739012234951902, 0.1974194301428558, 0.1974194301428558, 0.1974194301428558, 0.088719479101244, 0.088719479101244, 0.088719479101244, 0.11579862691939347, 0.11579862691939347, 0.11579862691939347, 0.095495340891673, 0.095495340891673, 0.095495340891673]}, "mutation_prompt": null}

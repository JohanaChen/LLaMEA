{"id": "cfcba351-daac-443b-b8d0-947a4f724366", "solution": "import numpy as np\n\nclass AGE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n        # PSO parameters\n        self.population_size = 20\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.w = 0.7   # Inertia weight\n        self.gradient_learning_rate = 0.1\n        \n        self.X = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.V = np.zeros((self.population_size, self.dim))\n        self.p_best = self.X.copy()\n        self.p_best_values = np.full(self.population_size, np.inf)\n        self.g_best = None\n        self.g_best_value = np.inf\n        self.evaluations = 0\n        \n    def gradient_estimation(self, func, x):\n        epsilon = 1e-8\n        grad = np.zeros_like(x)\n        fx = func(x)\n        for i in range(len(x)):\n            x_temp = x.copy()\n            x_temp[i] += epsilon\n            grad[i] = (func(x_temp) - fx) / epsilon\n        return grad\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                fitness = func(self.X[i])\n                self.evaluations += 1\n                \n                if fitness < self.p_best_values[i]:\n                    self.p_best_values[i] = fitness\n                    self.p_best[i] = self.X[i]\n                \n                if fitness < self.g_best_value:\n                    self.g_best_value = fitness\n                    self.g_best = self.X[i]\n                \n            for i in range(self.population_size):\n                gradient = self.gradient_estimation(func, self.X[i])\n                self.V[i] = (self.w * self.V[i] +\n                             self.c1 * np.random.rand(self.dim) * (self.p_best[i] - self.X[i]) +\n                             self.c2 * np.random.rand(self.dim) * (self.g_best - self.X[i]) -\n                             self.gradient_learning_rate * gradient)\n                \n                self.X[i] = np.clip(self.X[i] + self.V[i], self.lower_bound, self.upper_bound)\n                \n        return self.g_best", "name": "AGE_PSO", "description": "Adaptive Gradient-Enhanced Particle Swarm Optimization (AGE-PSO) combines particle swarm optimization with adaptive gradient learning to efficiently explore and exploit the search space.", "configspace": "", "generation": 0, "fitness": 0.11160627884199012, "feedback": "", "error": "", "parent_id": null, "metadata": {"aucs": [0.6122782530672467, 0.4410466362554213, 0.40069257237424394, 0.26944265426592884, 0.5754947851202783, 0.3449051424962487, 0.4951021107312984, 0.30599175791514066, 0.3392503528449564, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004669746983119727, 0.01467079792556647, 0.02088663093084453, 0.010643412229028426, 0.0012186517326517876, 0.006669963150305325, 0.0182482641955537, 0.0032674191434746147, 0.01700139379581489, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972265650589, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.9503055319823273, 0.9598656912218211, 0.9728825621951173, 0.8869102684927238, 0.9606140126846685, 0.9509911673366932, 0.9602980528424361, 0.973321031292502, 0.9378935969205897, 0.022589896476240767, 9.999999999998899e-05, 0.0012753320505515253, 0.06669278783967925, 0.006591997023174145, 0.0608622333820531, 9.999999999998899e-05, 0.011293333769513136, 9.999999999998899e-05, 0.1933179583507566, 0.08556175424468515, 0.12355625972405737, 0.1476752463414145, 0.15051107366816396, 0.14730758899054652, 0.06649203212472254, 0.10030085759498308, 0.11516282503225395, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.34732290623463347, 0.2697036670391624, 0.3548351893154128, 0.2706656859014447, 0.31646370719308003, 0.3413094774118324, 0.31041748031148375, 0.23329268686596438, 0.3255359953731902, 0.013371672878761509, 0.022580599403550727, 0.019930714604077138, 0.006101770452676458, 9.999999999998899e-05, 0.017599932942281127, 0.013133466050977094, 9.999999999998899e-05, 0.026765670055938995, 0.0930837930232814, 0.0930879676939661, 0.09201968928967286, 0.09855319362205395, 0.10852978136211644, 0.07642094364422702, 0.08808207298526627, 0.0646005879006385, 0.07726402383730269, 0.1388395337534405, 0.13810308326650034, 0.13469798534301403, 0.1477386928146892, 0.12626253086235972, 0.1254264965990456, 0.11958967783141583, 0.17377774444449912, 0.12479806882761446, 0.043075408692187955, 0.03699025979674475, 0.03781410890675929, 0.04465067593208005, 0.06406947960079012, 0.04631025153993229, 0.056911071880148656, 0.09386031397023942, 0.03607953250695828, 0.09163478423391791, 0.06586926240156177, 0.13345160781877274, 0.10289079079968377, 0.0785526836310666, 0.08853974585413693, 0.1224597883275157, 0.06494044806858634, 0.12619664141663633, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14630035689522847, 0.17378490177423878, 0.13991437885561375, 0.16417193818288434, 0.1985364522124936, 0.14391258934722462, 0.12267731403153737, 0.16232041669390473, 0.14331028326495632, 0.1674042521156951, 0.1806466292529071, 0.13882676411058859, 0.09802053922101828, 0.1359557794985189, 0.13240352379570375, 0.18549798671937312, 0.13780390642035123, 0.1684114195038413, 0.1348017586297845, 0.12837221403531962, 0.15150214341534207, 0.14231108613207522, 0.12216965042850647, 0.12745912886626742, 0.1367845093655211, 0.13576200872288047, 0.1543966352488314, 9.999999999998899e-05, 0.01347814766383748, 0.03139349864392893, 0.02701529996319041, 0.018487336241716168, 0.008260914302704814, 0.011149456961032644, 9.999999999998899e-05, 0.017456305444254028]}, "mutation_prompt": null}
{"id": "99b86803-3ee4-416e-b1cb-fa224e5cf832", "solution": "import numpy as np\n\nclass AGE_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n        # PSO parameters\n        self.population_size = 20\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.w = 0.7   # Inertia weight\n        self.gradient_learning_rate = 0.1\n        \n        self.X = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        self.V = np.zeros((self.population_size, self.dim))\n        self.p_best = self.X.copy()\n        self.p_best_values = np.full(self.population_size, np.inf)\n        self.g_best = None\n        self.g_best_value = np.inf\n        self.evaluations = 0\n        \n    def gradient_estimation(self, func, x):\n        epsilon = 1e-8\n        grad = np.zeros_like(x)\n        fx = func(x)\n        for i in range(len(x)):\n            x_temp = x.copy()\n            x_temp[i] += epsilon\n            grad[i] = (func(x_temp) - fx) / epsilon\n        return grad\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                fitness = func(self.X[i])\n                self.evaluations += 1\n                \n                if fitness < self.p_best_values[i]:\n                    self.p_best_values[i] = fitness\n                    self.p_best[i] = self.X[i]\n                \n                if fitness < self.g_best_value:\n                    self.g_best_value = fitness\n                    self.g_best = self.X[i]\n                \n            for i in range(self.population_size):\n                gradient = self.gradient_estimation(func, self.X[i])\n                self.V[i] = (self.w * self.V[i] +\n                             self.c1 * np.random.rand(self.dim) * (self.p_best[i] - self.X[i]) +\n                             self.c2 * np.random.rand(self.dim) * (self.g_best - self.X[i]) -\n                             self.gradient_learning_rate * gradient)\n                \n                self.X[i] = np.clip(self.X[i] + self.V[i], self.lower_bound, self.upper_bound)\n                \n        return self.g_best", "name": "AGE_PSO", "description": "Adaptive Gradient-Enhanced Particle Swarm Optimization (AGE-PSO) combines particle swarm optimization with adaptive gradient learning to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "cfcba351-daac-443b-b8d0-947a4f724366", "metadata": {"aucs": [0.6122782530672467, 0.4410466362554213, 0.40069257237424394, 0.26944265426592884, 0.5754947851202783, 0.3449051424962487, 0.4951021107312984, 0.30599175791514066, 0.3392503528449564, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004669746983119727, 0.01467079792556647, 0.02088663093084453, 0.010643412229028426, 0.0012186517326517876, 0.006669963150305325, 0.0182482641955537, 0.0032674191434746147, 0.01700139379581489, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972265650589, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.9503055319823273, 0.9598656912218211, 0.9728825621951173, 0.8869102684927238, 0.9606140126846685, 0.9509911673366932, 0.9602980528424361, 0.973321031292502, 0.9378935969205897, 0.022589896476240767, 9.999999999998899e-05, 0.0012753320505515253, 0.06669278783967925, 0.006591997023174145, 0.0608622333820531, 9.999999999998899e-05, 0.011293333769513136, 9.999999999998899e-05, 0.1933179583507566, 0.08556175424468515, 0.12355625972405737, 0.1476752463414145, 0.15051107366816396, 0.14730758899054652, 0.06649203212472254, 0.10030085759498308, 0.11516282503225395, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.34732290623463347, 0.2697036670391624, 0.3548351893154128, 0.2706656859014447, 0.31646370719308003, 0.3413094774118324, 0.31041748031148375, 0.23329268686596438, 0.3255359953731902, 0.013371672878761509, 0.022580599403550727, 0.019930714604077138, 0.006101770452676458, 9.999999999998899e-05, 0.017599932942281127, 0.013133466050977094, 9.999999999998899e-05, 0.026765670055938995, 0.0930837930232814, 0.0930879676939661, 0.09201968928967286, 0.09855319362205395, 0.10852978136211644, 0.07642094364422702, 0.08808207298526627, 0.0646005879006385, 0.07726402383730269, 0.1388395337534405, 0.13810308326650034, 0.13469798534301403, 0.1477386928146892, 0.12626253086235972, 0.1254264965990456, 0.11958967783141583, 0.17377774444449912, 0.12479806882761446, 0.043075408692187955, 0.03699025979674475, 0.03781410890675929, 0.04465067593208005, 0.06406947960079012, 0.04631025153993229, 0.056911071880148656, 0.09386031397023942, 0.03607953250695828, 0.09163478423391791, 0.06586926240156177, 0.13345160781877274, 0.10289079079968377, 0.0785526836310666, 0.08853974585413693, 0.1224597883275157, 0.06494044806858634, 0.12619664141663633, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14630035689522847, 0.17378490177423878, 0.13991437885561375, 0.16417193818288434, 0.1985364522124936, 0.14391258934722462, 0.12267731403153737, 0.16232041669390473, 0.14331028326495632, 0.1674042521156951, 0.1806466292529071, 0.13882676411058859, 0.09802053922101828, 0.1359557794985189, 0.13240352379570375, 0.18549798671937312, 0.13780390642035123, 0.1684114195038413, 0.1348017586297845, 0.12837221403531962, 0.15150214341534207, 0.14231108613207522, 0.12216965042850647, 0.12745912886626742, 0.1367845093655211, 0.13576200872288047, 0.1543966352488314, 9.999999999998899e-05, 0.01347814766383748, 0.03139349864392893, 0.02701529996319041, 0.018487336241716168, 0.008260914302704814, 0.011149456961032644, 9.999999999998899e-05, 0.017456305444254028]}, "mutation_prompt": null}

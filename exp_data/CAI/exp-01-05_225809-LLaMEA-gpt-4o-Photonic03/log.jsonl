{"id": "f2e576dd-18cd-4563-a34d-9f8cd6e5b9d7", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75  # Exploration-Exploitation balance parameter\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.position[i])\n                evaluations += 1\n\n                # Update best position of swarm\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                # Update global best position\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            # Update positions with quantum-inspired approach\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                self.position[i] = (self.alpha * r1 * p_best +\n                                    (1 - self.alpha) * r2 * global_best) + np.random.normal(0, 0.1, self.dim)\n\n            # Ensure position stays within bounds\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Adaptive Quantum Swarm Optimization (AQSO) combining quantum-inspired position updates with real-time learning of swarm behavior for efficient exploration and exploitation.", "configspace": "", "generation": 0, "fitness": 0.12632245327761274, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": null, "metadata": {"aucs": [0.12725056429666837, 0.1274424380380501, 0.12427435749811977]}, "mutation_prompt": null}
{"id": "f807cc09-3858-421c-b41c-7529bad391e3", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75  # Exploration-Exploitation balance parameter\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.position[i])\n                evaluations += 1\n\n                # Update best position of swarm\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                # Update global best position\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            # Update positions with quantum-inspired approach\n            r1, r2 = np.random.rand(2)\n            self.alpha = 0.5 + 0.5 * np.random.rand()  # Dynamically adjust alpha\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                self.position[i] = (self.alpha * r1 * p_best +\n                                    (1 - self.alpha) * r2 * global_best) + np.random.normal(0, 0.1, self.dim)\n\n            # Ensure position stays within bounds\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhanced Adaptive Quantum Swarm Optimizer introduces dynamic adaptation of alpha based on convergence, improving exploration-exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.1259830423526244, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "f2e576dd-18cd-4563-a34d-9f8cd6e5b9d7", "metadata": {"aucs": [0.12663698205170704, 0.1274424380380501, 0.12386970696811606]}, "mutation_prompt": null}
{"id": "1c686a86-2394-4605-94e8-fc3cc7abb420", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75  # Exploration-Exploitation balance parameter\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.position[i])\n                evaluations += 1\n\n                # Update best position of swarm\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                # Update global best position\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            # Update positions with quantum-inspired approach\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                self.alpha = 0.9 - 0.5 * (evaluations / self.budget)  # Adjust alpha dynamically\n                self.position[i] = (self.alpha * r1 * p_best +\n                                    (1 - self.alpha) * r2 * global_best) + np.random.normal(0, 0.1, self.dim)\n\n            # Ensure position stays within bounds\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhanced Adaptive Quantum Swarm Optimization with dynamic exploration-exploitation balance adjustment for improved convergence.", "configspace": "", "generation": 2, "fitness": 0.12452212685533366, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.00.", "error": "", "parent_id": "f2e576dd-18cd-4563-a34d-9f8cd6e5b9d7", "metadata": {"aucs": [0.1222166551189201, 0.1274424380380501, 0.12390728740903079]}, "mutation_prompt": null}
{"id": "4a44c2c0-51a6-4226-abd6-69fc74df8fd2", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75  # Exploration-Exploitation balance parameter\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.position[i])\n                evaluations += 1\n\n                # Update best position of swarm\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                # Update global best position\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            # Update positions with quantum-inspired approach\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                self.position[i] = (self.alpha * r1 * p_best +\n                                    (1 - self.alpha) * r2 * global_best) + np.random.normal(0, 0.1, self.dim)\n            \n            # Dynamic adjustment of alpha\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            # Ensure position stays within bounds\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhanced AQSO with dynamic alpha adjustment for improved exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.126424871885127, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "f2e576dd-18cd-4563-a34d-9f8cd6e5b9d7", "metadata": {"aucs": [0.1260335470142261, 0.1274424380380501, 0.1257986306031048]}, "mutation_prompt": null}
{"id": "1e66b5f7-47fe-4529-8757-7a5dc0a9bb90", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75  # Exploration-Exploitation balance parameter\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.position[i])\n                evaluations += 1\n\n                # Update best position of swarm\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                # Update global best position\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            # Update positions with quantum-inspired approach\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                self.position[i] = (self.alpha * r1 * p_best +\n                                    (1 - self.alpha) * r2 * global_best) + np.random.normal(0, 0.1, self.dim)\n            \n            # Dynamic adjustment of alpha and population size\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n            self.population_size = max(5, int(self.population_size * (1 - evaluations / self.budget)))\n\n            # Ensure position stays within bounds\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhanced AQSO with adaptive population size for efficient resource utilization.", "configspace": "", "generation": 4, "fitness": 0.12350178849930316, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.00.", "error": "", "parent_id": "4a44c2c0-51a6-4226-abd6-69fc74df8fd2", "metadata": {"aucs": [0.12215242182429598, 0.1274424380380501, 0.12091050563556338]}, "mutation_prompt": null}
{"id": "d896d003-3c3c-4640-bd8c-780e21adb18d", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / abs(v) ** (1 / beta)\n        return L * step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                step_size = self.levy_flight(0.1)\n                mutation = np.random.normal(0, 0.05, self.dim)\n                self.position[i] = (self.alpha * r1 * p_best +\n                                    (1 - self.alpha) * r2 * global_best) + step_size + mutation\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Optimized AQSO with hybrid Lévy-flight mechanism and adaptive mutation for enhanced global search capabilities.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "4a44c2c0-51a6-4226-abd6-69fc74df8fd2", "metadata": {}, "mutation_prompt": null}
{"id": "04f7d38a-d948-4baa-b8a4-fbf9bedb40e2", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75  # Exploration-Exploitation balance parameter\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.position[i])\n                evaluations += 1\n\n                # Update best position of swarm\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                # Update global best position\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            # Update positions with quantum-inspired approach\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                self.position[i] = (self.alpha * r1 * p_best +\n                                    (1 - self.alpha) * r2 * global_best) + np.random.normal(0, 0.15, self.dim)\n\n            # Dynamic adjustment of alpha\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            # Ensure position stays within bounds\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduced a stochastic component to enhance the swarm's diversity and prevent premature convergence.", "configspace": "", "generation": 6, "fitness": 0.12642375404219863, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "4a44c2c0-51a6-4226-abd6-69fc74df8fd2", "metadata": {"aucs": [0.12606395135582604, 0.1274424380380501, 0.12576487273271975]}, "mutation_prompt": null}
{"id": "a5292c4b-91d8-426e-9282-d50553a0a848", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.population_size = self.initial_population_size\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75  # Exploration-Exploitation balance parameter\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.position[i])\n                evaluations += 1\n\n                # Update best position of swarm\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                # Update global best position\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            # Update positions with quantum-inspired approach\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                self.position[i] = (self.alpha * r1 * p_best +\n                                    (1 - self.alpha) * r2 * global_best) + np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n            \n            # Dynamic adjustment of alpha\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            # Adjust population size dynamically\n            self.population_size = max(5, int(self.initial_population_size * (1 - evaluations / self.budget)))\n\n            # Ensure position stays within bounds\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduced adaptive Gaussian mutation and dynamic population size adjustment for enhanced convergence precision.", "configspace": "", "generation": 7, "fitness": 0.12408494860974306, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.00.", "error": "", "parent_id": "4a44c2c0-51a6-4226-abd6-69fc74df8fd2", "metadata": {"aucs": [0.12167354678409059, 0.1274424380380501, 0.12313886100708848]}, "mutation_prompt": null}
{"id": "5ca9bfd3-bf0d-4237-9309-2ffef15021ec", "solution": "import numpy as np\n\nclass QuantumSwarmOptimizerEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75  # Initial exploration-exploitation balance parameter\n        self.beta = 0.5  # New parameter for adaptive convergence strategy\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                self.position[i] = (self.alpha * r1 * p_best +\n                                    self.beta * r2 * global_best) + np.random.normal(0, 0.1, self.dim)\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n            self.beta = 0.3 + 0.7 * (evaluations / self.budget)  # Adaptive beta for exploitation\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "QuantumSwarmOptimizerEnhanced", "description": "QuantumSwarmOptimizerEnhanced: Refined AQSO with adaptive beta for enhanced convergence and exploitation dynamics.", "configspace": "", "generation": 8, "fitness": 0.12471724272045226, "feedback": "The algorithm QuantumSwarmOptimizerEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.00.", "error": "", "parent_id": "4a44c2c0-51a6-4226-abd6-69fc74df8fd2", "metadata": {"aucs": [0.11984983359994261, 0.12784928757952874, 0.12645260698188543]}, "mutation_prompt": null}
{"id": "c7aecfde-a662-4cdb-a5ff-801cb2f29513", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75  # Exploration-Exploitation balance parameter\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.position[i])\n                evaluations += 1\n\n                # Update best position of swarm\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                # Update global best position\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            # Update positions with quantum-inspired approach\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                self.position[i] = (self.alpha * r1 * p_best +\n                                    (1 - self.alpha) * r2 * global_best) + np.random.normal(0, 0.1, self.dim)\n                \n                # Apply Gaussian mutation around the global best\n                if r1 < 0.1:\n                    self.position[i] += np.random.normal(0, 0.05, self.dim)\n            \n            # Dynamic adjustment of alpha\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            # Ensure position stays within bounds\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduced Gaussian mutation near global best for better local exploitation.", "configspace": "", "generation": 9, "fitness": 0.12633543469389116, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "4a44c2c0-51a6-4226-abd6-69fc74df8fd2", "metadata": {"aucs": [0.12576523544051854, 0.1274424380380501, 0.1257986306031048]}, "mutation_prompt": null}
{"id": "9ff18138-4d82-48b9-835f-0bd0e6117ce5", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75  # Exploration-Exploitation balance parameter\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.position[i])\n                evaluations += 1\n\n                # Update best position of swarm\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                # Update global best position\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            # Update positions with quantum-inspired approach\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                self.position[i] = (self.alpha * r1 * p_best +\n                                    (1 - self.alpha) * r2 * global_best) + np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n            \n            # Dynamic adjustment of alpha\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            # Ensure position stays within bounds\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhanced AQSO with stochastic perturbation and adaptive position scaling for improved exploration.", "configspace": "", "generation": 10, "fitness": 0.12642563560989872, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "4a44c2c0-51a6-4226-abd6-69fc74df8fd2", "metadata": {"aucs": [0.12602604794590755, 0.1274424380380501, 0.1258084208457385]}, "mutation_prompt": null}
{"id": "2307a3ef-8c1d-48ed-9098-449442e81fc6", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75  # Exploration-Exploitation balance parameter\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.position[i])\n                evaluations += 1\n\n                # Update best position of swarm\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                # Update global best position\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            # Update positions with quantum-inspired approach\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                self.position[i] = (self.alpha * r1 * p_best +\n                                    (1 - self.alpha) * r2 * global_best) + np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim)\n            \n            # Dynamic adjustment of alpha\n            self.alpha = 0.7 + 0.3 * (1 - evaluations / self.budget)\n\n            # Ensure position stays within bounds\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhanced quantum-inspired swarm optimization with adaptive Gaussian mutation for improved exploration and exploitation balance.", "configspace": "", "generation": 11, "fitness": 0.12632520265480085, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "9ff18138-4d82-48b9-835f-0bd0e6117ce5", "metadata": {"aucs": [0.12618645609687196, 0.1274424380380501, 0.12534671382948048]}, "mutation_prompt": null}
{"id": "c3568839-31eb-493e-939a-6502b1ca0965", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75  # Exploration-Exploitation balance parameter\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                # Evaluate current position\n                score = func(self.position[i])\n                evaluations += 1\n\n                # Update best position of swarm\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                # Update global best position\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            # Update positions with quantum-inspired approach\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                stochastic_factor = np.random.uniform(0.9, 1.1)  # Stochastic exploration factor\n                self.position[i] = (self.alpha * r1 * p_best +\n                                    (1 - self.alpha) * r2 * global_best) * stochastic_factor + np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n            \n            # Dynamic adjustment of alpha\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            # Ensure position stays within bounds\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduced adaptive population scaling and stochastic exploration factors for dynamic balance between exploration and exploitation.", "configspace": "", "generation": 12, "fitness": 0.1251416198630023, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "9ff18138-4d82-48b9-835f-0bd0e6117ce5", "metadata": {"aucs": [0.12633361439403012, 0.1274424380380501, 0.12164880715692661]}, "mutation_prompt": null}
{"id": "18970233-5a68-47eb-95ec-a9e23fd09de8", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                elite_influence = np.random.normal(0, 0.05, self.dim) * (self.best_positions[elite_idx] - self.position[i])\n                self.position[i] = ((self.alpha * r1 * p_best + \n                                     (1 - self.alpha) * r2 * global_best) +\n                                    elite_influence)\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Refined AQSO with enhanced convergence through adaptive learning rates and elite-guided perturbations.", "configspace": "", "generation": 13, "fitness": 0.12706208237663208, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "9ff18138-4d82-48b9-835f-0bd0e6117ce5", "metadata": {"aucs": [0.12686614660221773, 0.1274424380380501, 0.1268776624896284]}, "mutation_prompt": null}
{"id": "1e6de876-ce10-497b-baef-820231af452c", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                elite_influence = np.random.normal(0, 0.05, self.dim) * (self.best_positions[elite_idx] - self.position[i])\n                self.position[i] = ((self.alpha * r1 * p_best + \n                                     (1 - self.alpha) * r2 * global_best) +\n                                    elite_influence)\n                \n                # Strategic mutation to maintain diversity\n                mutation_chance = np.random.rand(self.dim) < 0.1 / self.dim\n                self.position[i] += mutation_chance * np.random.normal(0, 0.01, self.dim)\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhanced AQSO with strategic mutation for diversity preservation and better convergence.", "configspace": "", "generation": 14, "fitness": 0.1251510563742608, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "18970233-5a68-47eb-95ec-a9e23fd09de8", "metadata": {"aucs": [0.12321757663983968, 0.1274424380380501, 0.12479315444489258]}, "mutation_prompt": null}
{"id": "9ba1edb8-00dd-4269-823d-89cba3f3f9d5", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                levy = np.random.normal(0, 1, self.dim) * (self.best_positions[elite_idx] - self.position[i])\n                self.position[i] = ((self.alpha * r1 * p_best + \n                                     (1 - self.alpha) * r2 * global_best) +\n                                    levy)\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhanced AQSO by modifying elite perturbation to leverage Levy flight for improved exploration.", "configspace": "", "generation": 15, "fitness": 0.1283552323979995, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "18970233-5a68-47eb-95ec-a9e23fd09de8", "metadata": {"aucs": [0.1299154174388658, 0.13031140449575374, 0.12483887525937898]}, "mutation_prompt": null}
{"id": "85e122fb-42b9-4845-b6ff-e0bf11fb87de", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.initial_population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.initial_population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            # Adjust population size based on remaining budget\n            current_population_size = max(1, self.initial_population_size * (self.budget - evaluations) // self.budget)\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            for i in range(current_population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                levy = np.random.normal(0, 1, self.dim) * (self.best_positions[elite_idx] - self.position[i])\n                self.position[i] = ((self.alpha * r1 * p_best + \n                                     (1 - self.alpha) * r2 * global_best) +\n                                    levy)\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Improved convergence by dynamically adjusting population size based on the evaluation budget.", "configspace": "", "generation": 16, "fitness": 0.12690265069076379, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "9ba1edb8-00dd-4269-823d-89cba3f3f9d5", "metadata": {"aucs": [0.12848325549738981, 0.12959260706785114, 0.1226320895070504]}, "mutation_prompt": null}
{"id": "55b148f3-0bc4-4c84-9f08-293b7f3e948c", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                cauchy = np.random.standard_cauchy(self.dim) * \\\n                         (self.best_positions[elite_idx] - self.position[i])\n                self.position[i] = ((self.alpha * r1 * p_best + \n                                     (1 - self.alpha) * r2 * global_best) + \n                                    cauchy)\n\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size - 1)\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Improve AQSO using a Cauchy mutation in elite solutions and dynamic population size adjustment.", "configspace": "", "generation": 17, "fitness": 0.12702410365585318, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "9ba1edb8-00dd-4269-823d-89cba3f3f9d5", "metadata": {"aucs": [0.12691102278359812, 0.1286128094573784, 0.12554847872658303]}, "mutation_prompt": null}
{"id": "0a46291e-a565-4311-bd58-4044036f586f", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            beta = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Dynamic beta parameter\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                levy = np.random.normal(0, 1, self.dim) * (self.best_positions[elite_idx] - self.position[i])\n                self.position[i] = ((beta * r1 * p_best + \n                                     (1 - self.alpha) * r2 * global_best) +\n                                    levy)\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhanced AQSO by incorporating a dynamic beta parameter for improved exploitation.", "configspace": "", "generation": 18, "fitness": 0.12750304612395794, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "9ba1edb8-00dd-4269-823d-89cba3f3f9d5", "metadata": {"aucs": [0.12900084743922913, 0.12934022301758485, 0.12416806791505985]}, "mutation_prompt": null}
{"id": "96f091b5-d6cf-48cc-8be5-e7a70c22eadc", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.population_size = self.initial_population_size\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                levy = np.random.normal(0, 1, self.dim) * (self.best_positions[elite_idx] - self.position[i])\n                self.position[i] = ((self.alpha * r1 * p_best + \n                                     (1 - self.alpha) * r2 * global_best) +\n                                    levy)\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n            self.population_size = self.initial_population_size - int(evaluations / self.budget * self.initial_population_size) + 1  # Dynamic population size\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Incorporate a dynamic population size based on convergence to enhance exploration and exploitation balance.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 14 is out of bounds for axis 0 with size 14').", "error": "IndexError('index 14 is out of bounds for axis 0 with size 14')", "parent_id": "9ba1edb8-00dd-4269-823d-89cba3f3f9d5", "metadata": {}, "mutation_prompt": null}
{"id": "061d771c-fce9-43fa-bd33-e601d6aaefd1", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 1 - evaluations / self.budget  # New line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * (self.best_positions[elite_idx] - self.position[i])\n                self.position[i] = ((self.alpha * r1 * p_best + \n                                     (1 - self.alpha) * r2 * global_best) +\n                                    levy)\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Refinement involves adjusting the influence of the elite solution by scaling the Levy flight perturbation using a decreasing factor to balance exploration and exploitation.", "configspace": "", "generation": 20, "fitness": 0.12843481899042264, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "9ba1edb8-00dd-4269-823d-89cba3f3f9d5", "metadata": {"aucs": [0.1298905051537067, 0.12979680278385086, 0.12561714903371035]}, "mutation_prompt": null}
{"id": "e9297835-e8a6-447d-9c8b-88760877ad43", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 1 - evaluations / self.budget  # New line\n                sinusoidal_mod = np.sin(np.pi * evaluations / self.budget)  # New line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * sinusoidal_mod * (self.best_positions[elite_idx] - self.position[i])\n                self.position[i] = ((self.alpha * r1 * p_best + \n                                     (1 - self.alpha) * r2 * global_best) +\n                                    levy)\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhance exploration by introducing a sinusoidal modulation factor to the Levy flight perturbation.", "configspace": "", "generation": 21, "fitness": 0.12787185099511975, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "061d771c-fce9-43fa-bd33-e601d6aaefd1", "metadata": {"aucs": [0.1256377138525232, 0.1274424380380501, 0.1305354010947859]}, "mutation_prompt": null}
{"id": "1d407e38-39e5-4e29-9466-a0426deb8661", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            inertia_weight = 0.9 - 0.4 * (evaluations / self.budget)\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 1 - evaluations / self.budget\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * (self.best_positions[elite_idx] - self.position[i])\n                self.position[i] = inertia_weight * self.position[i] + (self.alpha * r1 * p_best + \n                                                                        (1 - self.alpha) * r2 * global_best) + levy\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduce adaptive inertia weight to balance exploration and exploitation by modifying velocity update.", "configspace": "", "generation": 22, "fitness": 0.12250885493253198, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.01.", "error": "", "parent_id": "061d771c-fce9-43fa-bd33-e601d6aaefd1", "metadata": {"aucs": [0.12248003101099714, 0.12963620497638773, 0.11541032881021107]}, "mutation_prompt": null}
{"id": "984b9325-4246-4de1-a511-f156d2ff9c90", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 1 - evaluations / self.budget\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * (self.best_positions[elite_idx] - self.position[i])\n                self.position[i] = (inertia_weight * self.position[i] +  # Modified line\n                                    self.alpha * r1 * p_best + \n                                    (1 - self.alpha) * r2 * global_best + levy)\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Incorporate a dynamic inertia weight to balance exploration and exploitation more effectively.", "configspace": "", "generation": 23, "fitness": 0.12374211500720718, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.00.", "error": "", "parent_id": "061d771c-fce9-43fa-bd33-e601d6aaefd1", "metadata": {"aucs": [0.12255540644393026, 0.12979331070369327, 0.11887762787399803]}, "mutation_prompt": null}
{"id": "e4333509-2743-4999-976c-078ed628171a", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 1 - evaluations / self.budget\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * (self.best_positions[elite_idx] - self.position[i])\n                self.position[i] = ((self.alpha * r1 * p_best + \n                                     (1 - self.alpha) * r2 * global_best) +\n                                    levy)\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduces dynamic population size adjustment during iterations to enhance exploration and convergence.", "configspace": "", "generation": 24, "fitness": 0.12871782370931942, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "061d771c-fce9-43fa-bd33-e601d6aaefd1", "metadata": {"aucs": [0.12782036182546108, 0.12979680278385086, 0.12853630651864634]}, "mutation_prompt": null}
{"id": "f63bd993-7cb6-419d-b72b-1f2fcbe71b1c", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.zeros_like(self.position)  # New line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 1 - evaluations / self.budget\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * (self.best_positions[elite_idx] - self.position[i])\n                self.velocity[i] = 0.5 * self.velocity[i] + (self.alpha * r1 * p_best + \n                                      (1 - self.alpha) * r2 * global_best + levy)  # Modified line\n                self.position[i] += self.velocity[i]  # Modified line\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Implement a momentum factor to enhance convergence speed by leveraging historical velocity.", "configspace": "", "generation": 25, "fitness": 0.1211206733066346, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.00.", "error": "", "parent_id": "e4333509-2743-4999-976c-078ed628171a", "metadata": {"aucs": [0.11984863112955568, 0.1274424380380501, 0.11607095075229801]}, "mutation_prompt": null}
{"id": "00be3a59-9dce-44f3-ae6d-e14af7274c7e", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 1 - evaluations / self.budget\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * (self.best_positions[elite_idx] - self.position[i])\n                learning_rate = 0.8 + 0.2 * (self.best_scores[elite_idx] / (self.best_scores[elite_idx] + self.best_scores[i]))  # Changed line\n                self.position[i] = ((self.alpha * r1 * p_best + \n                                     (1 - self.alpha) * r2 * global_best) +\n                                    levy * learning_rate)\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduces dynamic individual learning rate adjustment based on the elite solution to enhance convergence.", "configspace": "", "generation": 26, "fitness": 0.12862950709501922, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "e4333509-2743-4999-976c-078ed628171a", "metadata": {"aucs": [0.12631015615042107, 0.12940866713690302, 0.1301696979977336]}, "mutation_prompt": null}
{"id": "d4dacef9-a3e0-41e9-aaf3-0f6b58a8fb69", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 1 - evaluations / self.budget\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * (self.best_positions[elite_idx] - self.position[i])\n                self.position[i] = ((self.alpha * r1 * p_best + \n                                     (1 - self.alpha) * r2 * global_best) +\n                                    levy)\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhance convergence by introducing an adaptive learning factor that decreases over iterations.", "configspace": "", "generation": 27, "fitness": 0.12871782370931942, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "e4333509-2743-4999-976c-078ed628171a", "metadata": {"aucs": [0.12782036182546108, 0.12979680278385086, 0.12853630651864634]}, "mutation_prompt": null}
{"id": "468978ba-1b5d-42cf-96a1-f1679ffcca2f", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 1 - evaluations / self.budget\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * (self.best_positions[elite_idx] - self.position[i])\n                self.position[i] = ((self.alpha * r1 * p_best + \n                                     (1 - self.alpha) * r2 * global_best) +\n                                    levy)\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduces a decay factor to levy flights for adaptive exploration during optimization.", "configspace": "", "generation": 28, "fitness": 0.12871782370931942, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "e4333509-2743-4999-976c-078ed628171a", "metadata": {"aucs": [0.12782036182546108, 0.12979680278385086, 0.12853630651864634]}, "mutation_prompt": null}
{"id": "3866274d-445b-4a0f-baa1-b337935fdfcf", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 1 - evaluations / self.budget\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                self.position[i] = ((self.alpha * r1 * p_best + \n                                     (1 - self.alpha) * r2 * global_best) +\n                                    levy)\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduces an adaptive Levy flight factor to maintain exploration balance as evaluations progress.", "configspace": "", "generation": 29, "fitness": 0.12956597582338428, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "e4333509-2743-4999-976c-078ed628171a", "metadata": {"aucs": [0.12800714936266977, 0.13129225321745364, 0.12939852489002945]}, "mutation_prompt": null}
{"id": "93d0e4e6-0eba-4ef0-9ccd-77a31f811fe9", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            # Change: Introduces dynamic population adaptation based on diversity\n            diversity = np.mean([np.linalg.norm(self.position[i] - self.global_best_position) for i in range(self.population_size)])  # New line\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim) * (1 + diversity))  # Modified line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 1 - evaluations / self.budget\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])\n                self.position[i] = ((self.alpha * r1 * p_best + \n                                     (1 - self.alpha) * r2 * global_best) +\n                                    levy)\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduces a dynamic population adaptation method based on population diversity to improve global exploration.", "configspace": "", "generation": 30, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 14 is out of bounds for axis 0 with size 14').", "error": "IndexError('index 14 is out of bounds for axis 0 with size 14')", "parent_id": "3866274d-445b-4a0f-baa1-b337935fdfcf", "metadata": {}, "mutation_prompt": null}
{"id": "f3bf93fe-b159-4f19-9d2a-889cd859894e", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 1 - evaluations / self.budget\n                score_diff = (self.best_scores[elite_idx] - self.best_scores[i]) / (self.best_scores[i] + 1e-9)  # New line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * score_diff * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                self.position[i] = ((self.alpha * r1 * p_best + \n                                     (1 - self.alpha) * r2 * global_best) +\n                                    levy)\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Optimizes exploration by adjusting the Levy flight factor based on the normalized score difference between the best and current solutions.", "configspace": "", "generation": 31, "fitness": 0.12632471757898775, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "3866274d-445b-4a0f-baa1-b337935fdfcf", "metadata": {"aucs": [0.12500771800098254, 0.1274424380380501, 0.12652399669793057]}, "mutation_prompt": null}
{"id": "cfa849b6-15c2-4cf9-af11-43956ee37a5e", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 1 - evaluations / self.budget\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])\n                self.position[i] = ((self.alpha * r1 * p_best + \n                                     (1 - self.alpha) * r2 * global_best) +\n                                    levy)\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n        \n        # Change: Introduce a dynamic scaling factor to enhance convergence\n        self.alpha = 0.5 + 0.5 * np.exp(-0.05 * evaluations / self.budget)  # Changed line\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduces a dynamic scaling factor to enhance the convergence speed in the latter stages of optimization.", "configspace": "", "generation": 32, "fitness": 0.12956597582338428, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "3866274d-445b-4a0f-baa1-b337935fdfcf", "metadata": {"aucs": [0.12800714936266977, 0.13129225321745364, 0.12939852489002945]}, "mutation_prompt": null}
{"id": "9bebe9c1-d899-43e5-b1f6-6a65ca5bf4c6", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 1 - evaluations / self.budget\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                self.position[i] = ((self.alpha * r1 * p_best + \n                                     (1 - self.alpha) * r2 * global_best) +\n                                    levy)\n\n            self.alpha = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Modified line\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduces a dynamic adaptive alpha scaling to balance exploration and exploitation effectively.", "configspace": "", "generation": 33, "fitness": 0.12548272729069432, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "3866274d-445b-4a0f-baa1-b337935fdfcf", "metadata": {"aucs": [0.12302611636127092, 0.12773189895985348, 0.12569016655095855]}, "mutation_prompt": null}
{"id": "c7d9c196-520f-48c2-83c5-04065a2b015d", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 1 - evaluations / self.budget\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                self.position[i] = ((self.alpha * r1 * p_best + \n                                     (1 - self.alpha) * r2 * global_best) +\n                                    levy)\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Improves elite solution influence by enhancing the Levy flight mechanism for better global exploration.", "configspace": "", "generation": 34, "fitness": 0.12871782370931942, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "3866274d-445b-4a0f-baa1-b337935fdfcf", "metadata": {"aucs": [0.12782036182546108, 0.12979680278385086, 0.12853630651864634]}, "mutation_prompt": null}
{"id": "f51c25fd-bb59-4b37-aec3-6b440aaf2d0e", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 1 - evaluations / self.budget\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                self.position[i] = ((self.alpha * r1 * p_best + \n                                     (1 - self.alpha) * r2 * global_best) +\n                                    levy)\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n            # New mutation line to improve exploration\n            self.position[elite_idx] += np.random.normal(0, 0.1, self.dim)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Improves exploration by introducing a mutation operator using Gaussian perturbation on the best elite position.", "configspace": "", "generation": 35, "fitness": 0.12609575635898007, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "3866274d-445b-4a0f-baa1-b337935fdfcf", "metadata": {"aucs": [0.12342479479601154, 0.13139510045594605, 0.12346737382498263]}, "mutation_prompt": null}
{"id": "022ab527-ecab-41ad-ad95-7130f997874e", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 1 - evaluations / self.budget\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                self.position[i] = inertia_weight * self.position[i] + ((self.alpha * r1 * p_best +\n                                     (1 - self.alpha) * r2 * global_best) +\n                                    levy)\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduces dynamic inertia weight to further balance exploration and exploitation throughout the optimization process.", "configspace": "", "generation": 36, "fitness": 0.12359410524419075, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.00.", "error": "", "parent_id": "3866274d-445b-4a0f-baa1-b337935fdfcf", "metadata": {"aucs": [0.11984863112955568, 0.12931036110279615, 0.12162332350022043]}, "mutation_prompt": null}
{"id": "6271a34a-d756-4ca4-8fdd-5ddc833cc63e", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 1 - evaluations / self.budget\n                levy = np.random.normal(0, 1, self.dim) * (0.5 + np.random.rand() * 0.5 * decay_factor) * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                self.position[i] = ((self.alpha * r1 * p_best + \n                                     (1 - self.alpha) * r2 * global_best) +\n                                    levy)\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Adjusts the Levy flight factor to incorporate stochastic variability for better exploration.", "configspace": "", "generation": 37, "fitness": 0.1284140664810208, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "3866274d-445b-4a0f-baa1-b337935fdfcf", "metadata": {"aucs": [0.12966906315853355, 0.13051962983799337, 0.12505350644653546]}, "mutation_prompt": null}
{"id": "a085131e-e5fc-4f71-bb30-85a09c95a3d1", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))\n            communication_factor = 0.5 * (1 + np.cos(np.pi * evaluations / self.budget))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 1 - evaluations / self.budget\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])\n                self.position[i] = ((self.alpha * r1 * p_best + \n                                     (1 - self.alpha) * r2 * global_best) +\n                                    communication_factor * levy)  # Modified line\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Integrates a dynamic communication factor to enhance information exchange among particles during the optimization process.", "configspace": "", "generation": 38, "fitness": 0.12943109551857468, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "3866274d-445b-4a0f-baa1-b337935fdfcf", "metadata": {"aucs": [0.12737025885101316, 0.13137278470543434, 0.12955024299927653]}, "mutation_prompt": null}
{"id": "bfaf6ba8-f5b7-4a10-a4e5-86460ac0f3a9", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = (1 - evaluations / self.budget) / np.sqrt(self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])\n                self.position[i] = ((self.alpha * r1 * p_best + \n                                     (1 - self.alpha) * r2 * global_best) +\n                                    levy)\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Adjusted the decay factor in the Levy flight term to account for dimensionality impact on exploration.", "configspace": "", "generation": 39, "fitness": 0.12680460974392774, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "3866274d-445b-4a0f-baa1-b337935fdfcf", "metadata": {"aucs": [0.12315990042822378, 0.1274424380380501, 0.12981149076550935]}, "mutation_prompt": null}
{"id": "db633a0b-c179-4772-9f81-524f91111411", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = np.exp(-evaluations / self.budget)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])\n                self.position[i] = ((self.alpha * r1 * p_best + \n                                     (1 - self.alpha) * r2 * global_best) +\n                                    levy)\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduces a dynamic adjustment to the decay factor, enhancing exploration and exploitation balance.", "configspace": "", "generation": 40, "fitness": 0.12956591182686825, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "3866274d-445b-4a0f-baa1-b337935fdfcf", "metadata": {"aucs": [0.1281143702130445, 0.1312296484487604, 0.1293537168187998]}, "mutation_prompt": null}
{"id": "60932d31-9868-4e86-a923-8ca8e3bcb10b", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            inertia_weight = 0.9 - (0.5 * evaluations / self.budget)  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 1 - evaluations / self.budget\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                self.position[i] = ((self.alpha * r1 * p_best + \n                                     (1 - self.alpha) * r2 * global_best) +\n                                    levy)\n\n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Integrates adaptive inertia weight to enhance convergence dynamics.", "configspace": "", "generation": 41, "fitness": 0.12951123187194633, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "3866274d-445b-4a0f-baa1-b337935fdfcf", "metadata": {"aucs": [0.12800714936266977, 0.13112802136313972, 0.12939852489002945]}, "mutation_prompt": null}
{"id": "4866b5e4-ea45-4ae9-ba27-dd2586820979", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.1  # New line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 1 - evaluations / self.budget\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhances convergence by integrating a momentum component to improve exploitation without increasing the number of parameters.", "configspace": "", "generation": 42, "fitness": 0.1310454266050901, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "3866274d-445b-4a0f-baa1-b337935fdfcf", "metadata": {"aucs": [0.13358760845263973, 0.1315961416357031, 0.1279525297269275]}, "mutation_prompt": null}
{"id": "785c6d92-b60c-42a6-967f-452356ceab3c", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.1\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 1 - evaluations / self.budget\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])\n                inertia = 0.9 - 0.4 * (evaluations / self.budget)  # Modified line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduce adaptive inertia weight to balance exploration and exploitation dynamically within the swarm.", "configspace": "", "generation": 43, "fitness": 0.13036584632743345, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "4866b5e4-ea45-4ae9-ba27-dd2586820979", "metadata": {"aucs": [0.13344480953286264, 0.1319123047832621, 0.12574042466617563]}, "mutation_prompt": null}
{"id": "df1a2c16-c688-446b-8475-ae0c629a98c3", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.1  # New line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introducing a dynamic adjustment to the decay factor for more adaptive exploration-exploitation balance.", "configspace": "", "generation": 44, "fitness": 0.13164350913804057, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "4866b5e4-ea45-4ae9-ba27-dd2586820979", "metadata": {"aucs": [0.13047275993420437, 0.13210725827179826, 0.13235050920811908]}, "mutation_prompt": null}
{"id": "75ee8623-ef7f-4e48-a5fb-2a2881abe92b", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.1  # New line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                turbulence = np.random.normal(0, 0.1, self.dim)  # New line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhanced velocity update with adaptive turbulence factor for improved exploration.", "configspace": "", "generation": 45, "fitness": 0.13165167367856875, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "df1a2c16-c688-446b-8475-ae0c629a98c3", "metadata": {"aucs": [0.133334208598205, 0.1326496177634504, 0.12897119467405083]}, "mutation_prompt": null}
{"id": "851c2f7a-48fd-417f-9d35-8084d25b7fc7", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.1  # New line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                turbulence = np.random.normal(0, 0.1, self.dim)  # New line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.7 + 0.3 * np.cos(np.pi * evaluations / self.budget)  # Modified line for dynamic adjustment\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Improved exploration-exploitation balance by adjusting inertia dynamically.", "configspace": "", "generation": 46, "fitness": 0.1315863413565492, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "75ee8623-ef7f-4e48-a5fb-2a2881abe92b", "metadata": {"aucs": [0.13307938200246083, 0.1330538432971764, 0.12862579877001035]}, "mutation_prompt": null}
{"id": "1dc85e55-9a95-4e99-9db0-a50d8a7547da", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.1  # New line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                turbulence = np.random.normal(0, 0.05, self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Improved the algorithm by adjusting the turbulence factor's distribution for a better balance between exploration and exploitation.", "configspace": "", "generation": 47, "fitness": 0.1317324563689888, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "75ee8623-ef7f-4e48-a5fb-2a2881abe92b", "metadata": {"aucs": [0.1333841556796923, 0.13264271466232003, 0.12917049876495412]}, "mutation_prompt": null}
{"id": "598d6296-1e26-4314-aa18-ad23cfcead51", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.1  # New line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                turbulence = np.random.normal(0, 0.06, self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhanced exploration by slightly increasing the turbulence magnitude for better coverage of the search space.", "configspace": "", "generation": 48, "fitness": 0.1317079945873101, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "1dc85e55-9a95-4e99-9db0-a50d8a7547da", "metadata": {"aucs": [0.13337702267400264, 0.13256953873507593, 0.1291774223528518]}, "mutation_prompt": null}
{"id": "03bebba2-33ee-46a2-81c0-e0c4ddad641f", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.1  # New line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhanced exploration by dynamically adjusting the turbulence factor's variance based on the population's diversity.", "configspace": "", "generation": 49, "fitness": 0.13222981958734967, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "1dc85e55-9a95-4e99-9db0-a50d8a7547da", "metadata": {"aucs": [0.1326882016661457, 0.13385790260123243, 0.13014335449467085]}, "mutation_prompt": null}
{"id": "59577c8f-c874-433a-81dd-4549f97998cb", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.1\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)\n                diversity = np.std(self.position, axis=0).mean()\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity), self.dim)\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)\n                time_varying_influence = 0.1 + 0.4 * (1 - evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * time_varying_influence * (global_best - self.position[i])) + levy + turbulence\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Improved global exploration by introducing a time-varying global influence factor.", "configspace": "", "generation": 50, "fitness": 0.13129780568968263, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "03bebba2-33ee-46a2-81c0-e0c4ddad641f", "metadata": {"aucs": [0.13300458903916723, 0.13423251166592076, 0.1266563163639599]}, "mutation_prompt": null}
{"id": "8dbd08f5-d753-437e-bd2c-79affaa84be1", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.1  # New line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * np.exp(-5 * evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Refined exploration by introducing a non-linear decay factor to enhance convergence towards the end of the budget.", "configspace": "", "generation": 51, "fitness": 0.13188203893294007, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "03bebba2-33ee-46a2-81c0-e0c4ddad641f", "metadata": {"aucs": [0.13306230661229446, 0.1331566169828975, 0.12942719320362828]}, "mutation_prompt": null}
{"id": "a749c01c-d194-4e80-932c-0647b4af4bac", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.1\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)\n                diversity = np.std(self.position, axis=0).mean()\n                turbulence = np.random.normal(0, 0.1 * (1 + diversity), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Improved exploration by adjusting the turbulence factor's variance based on population diversity with a dynamic scale.", "configspace": "", "generation": 52, "fitness": 0.1318059827788273, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "03bebba2-33ee-46a2-81c0-e0c4ddad641f", "metadata": {"aucs": [0.13113546379169005, 0.13402469921002824, 0.13025778533476362]}, "mutation_prompt": null}
{"id": "fb062280-4071-4fe0-ba69-d3614a432dc7", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.1  # New line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.4 * (evaluations / self.budget)  # Modified line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhanced inertia mechanism by making it time-variant to improve convergence speed.", "configspace": "", "generation": 53, "fitness": 0.13194467292548062, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "03bebba2-33ee-46a2-81c0-e0c4ddad641f", "metadata": {"aucs": [0.13200558518705408, 0.13351657307866338, 0.1303118605107244]}, "mutation_prompt": null}
{"id": "092df19e-3014-4836-94c7-aaf47a2e60b7", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.1\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)\n                diversity = np.std(self.position, axis=0).mean()\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity / (1 + evaluations / self.budget)), self.dim)  # Adjusted line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Improved convergence by adjusting the turbulence factor based on evaluations and diversity.", "configspace": "", "generation": 54, "fitness": 0.13170925346064186, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "03bebba2-33ee-46a2-81c0-e0c4ddad641f", "metadata": {"aucs": [0.13127276525456222, 0.13390561567544745, 0.12994937945191587]}, "mutation_prompt": null}
{"id": "dcee0973-3107-41f1-ad57-66e982da9302", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.1\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)\n                diversity = np.std(self.position, axis=0).mean()\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity), self.dim)\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * diversity * (self.best_positions[elite_idx] - self.position[i])  # Changed line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Improved global exploration by introducing a dynamic levy flight scaling based on current diversity.", "configspace": "", "generation": 55, "fitness": 0.11965712619051683, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.01.", "error": "", "parent_id": "03bebba2-33ee-46a2-81c0-e0c4ddad641f", "metadata": {"aucs": [0.11984863112955568, 0.1274424380380501, 0.11168030940394469]}, "mutation_prompt": null}
{"id": "8fcd36fe-f8bb-47f8-9e88-e26bb1d737d3", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.1  # New line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduce adaptive amortized turbulence to improve convergence by scaling it based on both population diversity and iteration progress.", "configspace": "", "generation": 56, "fitness": 0.1329225626764651, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "03bebba2-33ee-46a2-81c0-e0c4ddad641f", "metadata": {"aucs": [0.13317561175320336, 0.1337470241838219, 0.13184505209237007]}, "mutation_prompt": null}
{"id": "762fb5dd-fa31-4cbd-9d31-d1f5029e4161", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.1\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)\n                diversity = np.std(self.position, axis=0).mean()\n                convergence_speed = (evaluations / self.budget) ** 0.5  # New dynamic scaling for turbulence\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - convergence_speed), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Fine-tune the turbulence factor by incorporating a dynamic scaling based on convergence speed.", "configspace": "", "generation": 57, "fitness": 0.1316216942861683, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "8fcd36fe-f8bb-47f8-9e88-e26bb1d737d3", "metadata": {"aucs": [0.13235396815037104, 0.13202310151126273, 0.1304880131968711]}, "mutation_prompt": null}
{"id": "83824567-024a-48a1-be9b-b0686abde6ca", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.1\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)\n                diversity = np.std(self.position, axis=0).mean()\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])\n                inertia = 0.9 - diversity * 0.5  # Changed line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Adjust the inertia component dynamically based on the diversity in the population.", "configspace": "", "generation": 58, "fitness": 0.12172462823269492, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.01.", "error": "", "parent_id": "8fcd36fe-f8bb-47f8-9e88-e26bb1d737d3", "metadata": {"aucs": [0.12505905405860573, 0.12598634942163245, 0.11412848121784658]}, "mutation_prompt": null}
{"id": "ec71bc13-9da7-4ce2-b007-9145b9d2e5ec", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.1  # New line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.4 * (evaluations / self.budget)  # Changed line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduce adaptive inertia weight to enhance exploration and exploitation balance dynamically.", "configspace": "", "generation": 59, "fitness": 0.1317493668958335, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "8fcd36fe-f8bb-47f8-9e88-e26bb1d737d3", "metadata": {"aucs": [0.13315329159544298, 0.13203079733722478, 0.13006401175483273]}, "mutation_prompt": null}
{"id": "5f0424e1-2bb4-48fc-b232-ec48d99538da", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.1\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)\n                diversity = np.std(self.position, axis=0).mean()\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - evaluations / self.budget) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Adjust the turbulence influence by dynamically modifying its Gaussian scale based on convergence rate for enhanced exploration.", "configspace": "", "generation": 60, "fitness": 0.13129204617179555, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "8fcd36fe-f8bb-47f8-9e88-e26bb1d737d3", "metadata": {"aucs": [0.13238515432393783, 0.13232773376206008, 0.1291632504293887]}, "mutation_prompt": null}
{"id": "fdce9259-5133-47bb-9637-9a45fa686a39", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.1  # New line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            # Modified line\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim) * (1 + (1 - self.global_best_score/self.budget)))  \n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhance convergence through dynamic adjustment of population size based on both time and fitness improvements.", "configspace": "", "generation": 61, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 14 is out of bounds for axis 0 with size 14').", "error": "IndexError('index 14 is out of bounds for axis 0 with size 14')", "parent_id": "8fcd36fe-f8bb-47f8-9e88-e26bb1d737d3", "metadata": {}, "mutation_prompt": null}
{"id": "21b0e6e5-ab01-4a76-a3f4-4736ddcda253", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.1\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)\n                diversity = np.std(self.position, axis=0).mean()\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)\n                velocity_scaling = 1 + diversity * (1 - evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] * velocity_scaling + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduce a dynamic velocity scaling factor based on population diversity for improved exploration and exploitation balance.", "configspace": "", "generation": 62, "fitness": 0.12155974932348608, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.01.", "error": "", "parent_id": "8fcd36fe-f8bb-47f8-9e88-e26bb1d737d3", "metadata": {"aucs": [0.12633914060425944, 0.12598634942163245, 0.11235375794456637]}, "mutation_prompt": null}
{"id": "fb1cf9c2-8d5f-40a7-a71a-2744840477e6", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.1  # New line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - evaluations / self.budget)**1.5, self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhance the swarm exploration by introducing a time-varying turbulence factor that dynamically adjusts based on the current iteration, improving convergence speed.", "configspace": "", "generation": 63, "fitness": 0.13196571974282723, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "8fcd36fe-f8bb-47f8-9e88-e26bb1d737d3", "metadata": {"aucs": [0.13314882290547492, 0.13377689046547858, 0.12897144585752818]}, "mutation_prompt": null}
{"id": "3ae7bc8a-4b1b-4b93-b2e7-44d1a1059648", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.1\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)\n                diversity = np.std(self.position, axis=0).mean()\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha + 0.05) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Slightly increase the contribution of the global best position to encourage exploration and potentially find better solutions.", "configspace": "", "generation": 64, "fitness": 0.1321974577531612, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "8fcd36fe-f8bb-47f8-9e88-e26bb1d737d3", "metadata": {"aucs": [0.13313230158710532, 0.13327455272900823, 0.13018551894337005]}, "mutation_prompt": null}
{"id": "0cac95a5-0717-44d3-8716-760a264fce79", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.12  # Changed line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Slightly increased velocity scaling factor to enhance exploration in early iterations.", "configspace": "", "generation": 65, "fitness": 0.13292625916042378, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "8fcd36fe-f8bb-47f8-9e88-e26bb1d737d3", "metadata": {"aucs": [0.13317763203556254, 0.1337482380406364, 0.13185290740507238]}, "mutation_prompt": null}
{"id": "19398ccb-196c-4e9a-ac40-9cb47a1ce4a8", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.12  # Changed line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha + 0.05) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Adjusted the velocity update rule to give slightly more weight to global best influence, enhancing convergence.", "configspace": "", "generation": 66, "fitness": 0.13222342032422366, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "0cac95a5-0717-44d3-8716-760a264fce79", "metadata": {"aucs": [0.13313849792505383, 0.13327406882580395, 0.13025769422181321]}, "mutation_prompt": null}
{"id": "d5f410a8-2ac1-4ba2-bd8c-e9bdc2a69e47", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.15  # Changed line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Adjusted the velocity scaling factor to 0.15 to boost exploration capabilities during early iterations.", "configspace": "", "generation": 67, "fitness": 0.13292877502310282, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "0cac95a5-0717-44d3-8716-760a264fce79", "metadata": {"aucs": [0.1331806666380635, 0.1337423244042094, 0.13186333402703554]}, "mutation_prompt": null}
{"id": "ccc0f57d-7188-458f-9f59-62e124924ec5", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.15\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)\n                diversity = np.std(self.position, axis=0).mean()\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i]) * (1 + diversity / self.dim)) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhanced the convergence rate by dynamically adjusting the influence of personal and global best positions based on diversity.", "configspace": "", "generation": 68, "fitness": 0.12862771365562178, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.01.", "error": "", "parent_id": "d5f410a8-2ac1-4ba2-bd8c-e9bdc2a69e47", "metadata": {"aucs": [0.13484302247493385, 0.12896497911291405, 0.12207513937901748]}, "mutation_prompt": null}
{"id": "c7625b64-ebbd-42a5-96bc-f4d0591d6f63", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.15\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)\n                diversity = np.std(self.position, axis=0).mean()\n                turbulence = np.random.normal(0, 0.06 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Increased from 0.05 to 0.06\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Slightly increased turbulence scaling factor to enhance exploration in later stages.", "configspace": "", "generation": 69, "fitness": 0.1315263253583416, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "d5f410a8-2ac1-4ba2-bd8c-e9bdc2a69e47", "metadata": {"aucs": [0.13146208584518904, 0.1336451556305307, 0.12947173459930506]}, "mutation_prompt": null}
{"id": "9c480fd4-b608-49ef-887f-39934bc9fcf9", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.15  # Changed line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.7 + 0.2 * (1 - evaluations / self.budget)  # Changed line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduced a dynamic inertia weight to enhance convergence speed.", "configspace": "", "generation": 70, "fitness": 0.1316356076011561, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "d5f410a8-2ac1-4ba2-bd8c-e9bdc2a69e47", "metadata": {"aucs": [0.13302047174455955, 0.13149171432449525, 0.13039463673441354]}, "mutation_prompt": null}
{"id": "e55a19c0-2612-4b6e-b50f-4e3e363185db", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.15  # Changed line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - evaluations / self.budget**2), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduced a dynamic adjustment to the turbulence factor to enhance exploration adaptively based on iteration progress.", "configspace": "", "generation": 71, "fitness": 0.13224031069131192, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "d5f410a8-2ac1-4ba2-bd8c-e9bdc2a69e47", "metadata": {"aucs": [0.1326931603628606, 0.13385711154113988, 0.13017066016993528]}, "mutation_prompt": null}
{"id": "66af9e7a-8deb-4989-934f-2ee97b9cc3c3", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.15  # Changed line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                adaptive_mutation = np.random.normal(0, diversity * (1 - evaluations / self.budget), self.dim)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence + adaptive_mutation  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduced adaptive mutation to enhance local search capabilities based on current diversity within the swarm.", "configspace": "", "generation": 72, "fitness": 0.1244710976359209, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.00.", "error": "", "parent_id": "d5f410a8-2ac1-4ba2-bd8c-e9bdc2a69e47", "metadata": {"aucs": [0.12238915859565491, 0.12924415218229268, 0.12177998212981511]}, "mutation_prompt": null}
{"id": "85dd724c-bd27-47cf-99b2-c5cde14c5a0f", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.15  # Changed line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1.1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhanced the global best position influence in velocity update to improve convergence speed.", "configspace": "", "generation": 73, "fitness": 0.13203641420028597, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "d5f410a8-2ac1-4ba2-bd8c-e9bdc2a69e47", "metadata": {"aucs": [0.13169334261556065, 0.13375793128883795, 0.1306579686964593]}, "mutation_prompt": null}
{"id": "eda7cf1c-36eb-40d4-a09a-10a9a9a8ea1b", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.15  # Changed line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.1 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Adjusted the turbulence scaling factor to increase robustness against local optima and enhance convergence.", "configspace": "", "generation": 74, "fitness": 0.13207737517877183, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "d5f410a8-2ac1-4ba2-bd8c-e9bdc2a69e47", "metadata": {"aucs": [0.131925864127583, 0.13363508856628736, 0.13067117284244512]}, "mutation_prompt": null}
{"id": "2ea16afd-2781-4a18-b91e-ebbd8a9e56f9", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.15  # Changed line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            diversity = np.std(self.position, axis=0).mean()  # New line\n            self.population_size = 10 + int(diversity * 2 * np.sqrt(self.dim))  # Changed line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduced a dynamic adjustment to the population size based on the diversity of solutions to improve exploration and exploitation balance.", "configspace": "", "generation": 75, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 14 is out of bounds for axis 0 with size 14').", "error": "IndexError('index 14 is out of bounds for axis 0 with size 14')", "parent_id": "d5f410a8-2ac1-4ba2-bd8c-e9bdc2a69e47", "metadata": {}, "mutation_prompt": null}
{"id": "bf1eea10-5e7c-42a3-a7fe-abe9e8a4b568", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.15\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)\n                diversity = np.std(self.position, axis=0).mean()\n                turbulence = np.random.normal(0, 0.1 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])\n                inertia = 0.7 + 0.2 * np.sin(np.pi * evaluations / self.budget)  # Modified line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduced a dynamic inertia weight for better exploitation-exploration balance and enhanced turbulence scaling based on diversity.", "configspace": "", "generation": 76, "fitness": 0.12997045611092953, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "d5f410a8-2ac1-4ba2-bd8c-e9bdc2a69e47", "metadata": {"aucs": [0.12971144691516978, 0.1319742345080097, 0.12822568690960912]}, "mutation_prompt": null}
{"id": "c6097327-bc6c-4ed0-93e0-06a523e51ae3", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.15  # Changed line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.1 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhanced the turbulence influence by modifying its standard deviation scaling factor to improve exploration during later iterations.", "configspace": "", "generation": 77, "fitness": 0.13207737517877183, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "d5f410a8-2ac1-4ba2-bd8c-e9bdc2a69e47", "metadata": {"aucs": [0.131925864127583, 0.13363508856628736, 0.13067117284244512]}, "mutation_prompt": null}
{"id": "05d3605f-00eb-4ef0-99cc-27bf079998bb", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.2  # Changed line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhanced velocity scaling factor to 0.2 for improved exploration in early iterations.", "configspace": "", "generation": 78, "fitness": 0.13268261402870718, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "d5f410a8-2ac1-4ba2-bd8c-e9bdc2a69e47", "metadata": {"aucs": [0.13245511442615154, 0.13366357993537858, 0.1319291477245914]}, "mutation_prompt": null}
{"id": "ab898fe1-523e-4d49-b7e1-bd55074b2a8f", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 15 + 2 * int(np.sqrt(dim))  # Modified line\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.15\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)\n                diversity = np.std(self.position, axis=0).mean()\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Optimized exploration by increasing the initial population size for better coverage of the search space.", "configspace": "", "generation": 79, "fitness": 0.13224597874544863, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "d5f410a8-2ac1-4ba2-bd8c-e9bdc2a69e47", "metadata": {"aucs": [0.1306542104664843, 0.13255028532533797, 0.13353344044452364]}, "mutation_prompt": null}
{"id": "16ee5233-2b14-4c2c-b8a2-d6bec95b6eec", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.15  # Changed line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.03 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhanced convergence by adjusting turbulence parameters and increasing the impact of the elite position in velocity calculation.", "configspace": "", "generation": 80, "fitness": 0.12980986669401295, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "d5f410a8-2ac1-4ba2-bd8c-e9bdc2a69e47", "metadata": {"aucs": [0.12923220702151128, 0.13178285904540477, 0.12841453401512282]}, "mutation_prompt": null}
{"id": "65f27d28-12c2-4535-bd18-14fdcaa0ac38", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.15  # Changed line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.1 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Increase search diversity by adjusting turbulence scaling to promote better global exploration.", "configspace": "", "generation": 81, "fitness": 0.13207737517877183, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "d5f410a8-2ac1-4ba2-bd8c-e9bdc2a69e47", "metadata": {"aucs": [0.131925864127583, 0.13363508856628736, 0.13067117284244512]}, "mutation_prompt": null}
{"id": "f0e8d57e-6115-4281-ad90-200cc66e85ad", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.15  # Changed line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.4 * (evaluations / self.budget)  # Modified line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduced adaptive inertia weight to enhance convergence rate by dynamically balancing exploration and exploitation.", "configspace": "", "generation": 82, "fitness": 0.13167675588025327, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "d5f410a8-2ac1-4ba2-bd8c-e9bdc2a69e47", "metadata": {"aucs": [0.13315363989188522, 0.13203010111019053, 0.129846526638684]}, "mutation_prompt": null}
{"id": "80d3d68b-3a40-4958-a260-ac23f42727cf", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.15\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)\n                diversity = np.std(self.position, axis=0).mean()\n                turbulence = np.random.normal(0, 0.1 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhanced the turbulence factor to boost exploration by increasing its standard deviation for better diversity.", "configspace": "", "generation": 83, "fitness": 0.13207737517877183, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "d5f410a8-2ac1-4ba2-bd8c-e9bdc2a69e47", "metadata": {"aucs": [0.131925864127583, 0.13363508856628736, 0.13067117284244512]}, "mutation_prompt": null}
{"id": "5aef4676-acc3-4a16-9a34-f95a875dd79a", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.15  # Changed line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] * (1 - 0.01 * evaluations / self.budget) + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduced a small dynamic adjustment to the velocity to enhance local exploitation as evaluations progress.", "configspace": "", "generation": 84, "fitness": 0.13267276667835637, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "d5f410a8-2ac1-4ba2-bd8c-e9bdc2a69e47", "metadata": {"aucs": [0.13243891893361215, 0.13368928057742946, 0.1318901005240275]}, "mutation_prompt": null}
{"id": "12dec41e-83dd-4907-9178-30a1e6ac81b2", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.15\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)\n                diversity = np.std(self.position, axis=0).mean()\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence + np.random.normal(0, 0.01, self.dim)  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhanced exploration by dynamically adjusting velocity scaling with additional random perturbation.", "configspace": "", "generation": 85, "fitness": 0.1302971594196833, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "d5f410a8-2ac1-4ba2-bd8c-e9bdc2a69e47", "metadata": {"aucs": [0.12964049190208637, 0.13159743458886886, 0.12965355176809468]}, "mutation_prompt": null}
{"id": "fa70dd9c-8da3-4a9a-b46c-a727a599046f", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.15  # Changed line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.1 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified turbulence factor\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhanced the velocity calculation by increasing the turbulence factor to improve exploration.", "configspace": "", "generation": 86, "fitness": 0.13207737517877183, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "d5f410a8-2ac1-4ba2-bd8c-e9bdc2a69e47", "metadata": {"aucs": [0.131925864127583, 0.13363508856628736, 0.13067117284244512]}, "mutation_prompt": null}
{"id": "4d445103-3325-4b50-96da-bbfb0745aead", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.15  # Changed line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.1 + 0.9 * (1 - evaluations / self.budget)  # Changed line\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhanced search by dynamically adjusting the learning factor to improve exploitative capabilities.", "configspace": "", "generation": 87, "fitness": 0.1324512772527726, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "d5f410a8-2ac1-4ba2-bd8c-e9bdc2a69e47", "metadata": {"aucs": [0.13283877719442105, 0.13386289314919908, 0.1306521614146976]}, "mutation_prompt": null}
{"id": "7e31e842-28e8-481b-8d99-ba94f439b741", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * 0.15  # Changed line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1.5, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Improved exploration by increasing the Levy flight effect to encourage wider search space traversal.", "configspace": "", "generation": 88, "fitness": 0.13108969483954305, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "d5f410a8-2ac1-4ba2-bd8c-e9bdc2a69e47", "metadata": {"aucs": [0.12996370183269257, 0.13124904689055394, 0.13205633579538267]}, "mutation_prompt": null}
{"id": "74958a12-410d-4497-a68b-0e0e0a645382", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * (0.15 + 0.05 * np.random.rand())  # Modified line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Enhanced velocity scaling factor with a time-varying element to improve adaptability over iterations.", "configspace": "", "generation": 89, "fitness": 0.13295447007327643, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "d5f410a8-2ac1-4ba2-bd8c-e9bdc2a69e47", "metadata": {"aucs": [0.1338607727083272, 0.13263134775255458, 0.13237128975894752]}, "mutation_prompt": null}
{"id": "2fe26799-ec8d-40bb-95b4-22662119ec4a", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * (0.15 + 0.05 * np.random.rand())  # Modified line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Changed line for dynamic adjustment\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduced a dynamic adjustment to alpha parameter to enhance exploration in early stages.", "configspace": "", "generation": 90, "fitness": 0.13047404210858474, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "74958a12-410d-4497-a68b-0e0e0a645382", "metadata": {"aucs": [0.12535789923933316, 0.13262892154689532, 0.13343530553952576]}, "mutation_prompt": null}
{"id": "0521604e-e68a-4128-aaf4-75dd4f287e98", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * (0.15 + 0.05 * np.random.rand())  # Modified line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                turbulence = np.random.normal(0, 0.1 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introducing a dynamic turbulence factor to enhance exploration capability throughout the optimization process.", "configspace": "", "generation": 91, "fitness": 0.13241295585759258, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "74958a12-410d-4497-a68b-0e0e0a645382", "metadata": {"aucs": [0.13161093521303557, 0.13347253299263573, 0.1321553993671064]}, "mutation_prompt": null}
{"id": "0d0e0637-7631-46df-ab57-52fb62155a5f", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * (0.15 + 0.05 * np.random.rand())  # Modified line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                weight = 0.1 + 0.9 * (1 - evaluations / self.budget)  # Modified line\n                turbulence = np.random.normal(0, weight * 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduce adaptive weight scaling in the turbulence factor to enhance exploration capabilities dynamically.", "configspace": "", "generation": 92, "fitness": 0.13297680386677388, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "74958a12-410d-4497-a68b-0e0e0a645382", "metadata": {"aucs": [0.13386452071258081, 0.1326219263432319, 0.1324439645445089]}, "mutation_prompt": null}
{"id": "26fdfd3c-94dc-41c4-80ca-6a3b853454ed", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * (0.15 + 0.05 * np.random.rand())  # Modified line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                weight = 0.1 + 0.9 * (1 - evaluations / self.budget)  # Modified line\n                turbulence = np.random.normal(0, weight * 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.5 + 0.4 * (1 - evaluations / self.budget)  # Changed line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduce adaptive inertia weight scaling to enhance convergence speed at later stages.", "configspace": "", "generation": 93, "fitness": 0.13279308603523576, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "0d0e0637-7631-46df-ab57-52fb62155a5f", "metadata": {"aucs": [0.13396663308200019, 0.1317080433169283, 0.1327045817067788]}, "mutation_prompt": null}
{"id": "a1f52729-666f-4c62-9459-5f7b866ae833", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * (0.15 + 0.05 * np.random.rand())  # Modified line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * np.exp(-evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                weight = 0.1 + 0.9 * (1 - evaluations / self.budget)  # Modified line\n                turbulence = np.random.normal(0, weight * 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Incorporate an exponential decay factor for adaptive weight scaling to enhance convergence speed.", "configspace": "", "generation": 94, "fitness": 0.13258560340958894, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "0d0e0637-7631-46df-ab57-52fb62155a5f", "metadata": {"aucs": [0.1337844506001683, 0.13165781278839406, 0.1323145468402045]}, "mutation_prompt": null}
{"id": "808f2d49-4360-4615-86df-227f21aa8155", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * (0.15 + 0.05 * np.random.rand())  # Modified line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.linalg.norm(global_best - self.position[i])  # Changed line\n                weight = 0.1 + 0.9 * (1 - evaluations / self.budget)  # Modified line\n                turbulence = np.random.normal(0, weight * 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Improve swarm diversity by dynamically adjusting the turbulence factor based on the global best position distance.", "configspace": "", "generation": 95, "fitness": 0.13228687184634455, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "0d0e0637-7631-46df-ab57-52fb62155a5f", "metadata": {"aucs": [0.13133236507715573, 0.13304652418190666, 0.13248172627997123]}, "mutation_prompt": null}
{"id": "c28c0e55-54e3-4e48-b762-70de15b283a4", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * (0.15 + 0.05 * np.random.rand())\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)\n                diversity = np.std(self.position, axis=0).mean()\n                weight = 0.1 + 0.9 * (1 - evaluations / self.budget)\n                turbulence = np.random.normal(0, weight * 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)\n                mutation = np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)  # Added line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence + mutation  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduce adaptive mutation in the velocity update to enhance local searching abilities.", "configspace": "", "generation": 96, "fitness": 0.1316661183945832, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "0d0e0637-7631-46df-ab57-52fb62155a5f", "metadata": {"aucs": [0.1327438443974338, 0.1322032709054054, 0.13005123988091039]}, "mutation_prompt": null}
{"id": "d568bc74-ace2-4079-b1e7-fc3976f25c6c", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * (0.15 + 0.05 * np.random.rand())\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()\n                weight = 0.1 + 0.9 * ((1 - evaluations / self.budget) ** 2)  # Changed line\n                turbulence = np.random.normal(0, weight * 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Introduce a non-linear decay factor for turbulence to enhance convergence acceleration in later stages.", "configspace": "", "generation": 97, "fitness": 0.13257860494890672, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "0d0e0637-7631-46df-ab57-52fb62155a5f", "metadata": {"aucs": [0.1341758594385163, 0.1314841300108356, 0.13207582539736828]}, "mutation_prompt": null}
{"id": "053f65a3-6cdd-4a40-ba58-9f15eda4527f", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * (0.15 + 0.05 * np.random.rand())  # Modified line\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)  # Track elite solution\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))  # New line\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)  # Modified line\n                diversity = np.std(self.position, axis=0).mean()  # New line\n                weight = 0.1 + 0.9 * (1 - evaluations / self.budget)  # Modified line\n                turbulence = np.random.normal(0, weight * 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)  # Modified line\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])  # Modified line\n                inertia = 0.9 - 0.5 * (evaluations / self.budget) + 0.05 * (np.std(self.position))  # Modified line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Update the inertia weight function to include position variance for enhanced convergence.", "configspace": "", "generation": 98, "fitness": 0.12241781973221715, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.00.", "error": "", "parent_id": "0d0e0637-7631-46df-ab57-52fb62155a5f", "metadata": {"aucs": [0.11926065715055756, 0.12598634942163223, 0.12200645262446164]}, "mutation_prompt": null}
{"id": "5658d73f-b405-426c-9aec-1650b6e37cd1", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.position = np.random.rand(self.population_size, dim)\n        self.velocity = np.random.rand(self.population_size, dim) * (0.15 + 0.05 * np.random.rand())\n        self.best_positions = np.copy(self.position)\n        self.best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.75\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + (ub - lb) * self.position\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            elite_idx = np.argmin(self.best_scores)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score = func(self.position[i])\n                evaluations += 1\n\n                if score < self.best_scores[i]:\n                    self.best_scores[i] = score\n                    self.best_positions[i] = self.position[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.position[i]\n\n            r1, r2 = np.random.rand(2)\n            self.population_size = 10 + int((1 - evaluations / self.budget) * 2 * np.sqrt(self.dim))\n            for i in range(self.population_size):\n                p_best = self.best_positions[i]\n                global_best = self.global_best_position\n                decay_factor = 0.5 * (1 - evaluations / self.budget)\n                diversity = np.std(self.position, axis=0).mean()\n                weight = 0.1 + 0.9 * (1 - evaluations / self.budget)\n                turbulence = np.random.normal(0, weight * 0.05 * (1 + diversity) * (1 - evaluations / self.budget), self.dim)\n                levy = np.random.normal(0, 1, self.dim) * decay_factor * 0.5 * (self.best_positions[elite_idx] - self.position[i])\n                inertia = 0.9 - 0.5 * (evaluations / self.budget)\n                adaptive_scale = 0.05 + 0.45 * (1 - evaluations / self.budget)  # New line\n                self.velocity[i] = inertia * self.velocity[i] + (self.alpha * r1 * (p_best - self.position[i]) + (1 - self.alpha) * r2 * (global_best - self.position[i])) + levy * adaptive_scale + turbulence  # Modified line\n                self.position[i] += self.velocity[i]\n            \n            self.alpha = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n            self.position = np.clip(self.position, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AdaptiveQuantumSwarmOptimizer", "description": "Adjust elite solution influence by incorporating adaptive differential scaling for better exploitation.", "configspace": "", "generation": 99, "fitness": 0.1331517670328479, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "0d0e0637-7631-46df-ab57-52fb62155a5f", "metadata": {"aucs": [0.1337140503610429, 0.13309732350157844, 0.13264392723592233]}, "mutation_prompt": null}

{"id": "a1a3da39-49e2-41a4-893c-9c3a138a214c", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Adaptive Hybrid Genetic Algorithm combining Differential Evolution and Particle Swarm Optimization for dynamic exploration and exploitation.", "configspace": "", "generation": 0, "fitness": 0.3101317135320787, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.27.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8146234638307646, 0.8146234638307646, 0.8146234638307646, 0.8109148170888494, 0.8109148170888494, 0.8109148170888494, 0.7799439168447343, 0.7799439168447343, 0.7799439168447343, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.6066864066507274, 0.6066864066507274, 0.6066864066507274, 0.6320147171109352, 0.6320147171109352, 0.6320147171109352, 0.16371827998483168, 0.16371827998483168, 0.16371827998483168, 0.15591871114213296, 0.15591871114213296, 0.15591871114213296, 0.1286679014131863, 0.1286679014131863, 0.1286679014131863, 0.11962123409810288, 0.11962123409810288, 0.11962123409810288, 0.09033667771072762, 0.09033667771072762, 0.09033667771072762, 0.1083343945926647, 0.1083343945926647, 0.1083343945926647, 0.9863077542148404, 0.9863077542148404, 0.9863077542148404, 0.9854293723349518, 0.9854293723349518, 0.9854293723349518, 0.9810535235818876, 0.9810535235818876, 0.9810535235818876, 0.6322651504105392, 0.6322651504105392, 0.6322651504105392, 0.5734279366331225, 0.5734279366331225, 0.5734279366331225, 0.5614451479128058, 0.5614451479128058, 0.5614451479128058, 0.7205698139309911, 0.7205698139309911, 0.7205698139309911, 0.19116513450195738, 0.19116513450195738, 0.19116513450195738, 0.7392326809706304, 0.7392326809706304, 0.7392326809706304, 0.23795048630399795, 0.23795048630399795, 0.23795048630399795, 0.12734343515719082, 0.12734343515719082, 0.12734343515719082, 0.2328110748688358, 0.2328110748688358, 0.2328110748688358, 0.3473537293549659, 0.3473537293549659, 0.3473537293549659, 0.2384721502302487, 0.2384721502302487, 0.2384721502302487, 0.23648455367820853, 0.23648455367820853, 0.23648455367820853, 0.039212341293526354, 0.039212341293526354, 0.039212341293526354, 0.013474837993585842, 0.013474837993585842, 0.013474837993585842, 0.008547804602012543, 0.008547804602012543, 0.008547804602012543, 0.13084228347586813, 0.13084228347586813, 0.13084228347586813, 0.07622424331558864, 0.07622424331558864, 0.07622424331558864, 0.06959713122861444, 0.06959713122861444, 0.06959713122861444, 0.0797339560530802, 0.0797339560530802, 0.0797339560530802, 0.14139787424003536, 0.14139787424003536, 0.14139787424003536, 0.08873453278083177, 0.08873453278083177, 0.08873453278083177, 0.04509568533092423, 0.04509568533092423, 0.04509568533092423, 0.08334850636107127, 0.08334850636107127, 0.08334850636107127, 0.07763337198983167, 0.07763337198983167, 0.07763337198983167, 0.5872570528544033, 0.5872570528544033, 0.5872570528544033, 0.5271422100861474, 0.5271422100861474, 0.5271422100861474, 0.5890085336492433, 0.5890085336492433, 0.5890085336492433, 0.5415921394063445, 0.5415921394063445, 0.5415921394063445, 0.13173773362204833, 0.13173773362204833, 0.13173773362204833, 0.0817429552732537, 0.0817429552732537, 0.0817429552732537, 0.3982455897382179, 0.3982455897382179, 0.3982455897382179, 0.18707675582490102, 0.18707675582490102, 0.18707675582490102, 0.2133403694799424, 0.2133403694799424, 0.2133403694799424, 0.2845671046130992, 0.2845671046130992, 0.2845671046130992, 0.1948950736852092, 0.1948950736852092, 0.1948950736852092, 0.26053379037545366, 0.26053379037545366, 0.26053379037545366, 0.17281507669077878, 0.17281507669077878, 0.17281507669077878, 0.19003216992037064, 0.19003216992037064, 0.19003216992037064, 0.25857085544028535, 0.25857085544028535, 0.25857085544028535, 0.23464455817478724, 0.23464455817478724, 0.23464455817478724, 0.2259956452027434, 0.2259956452027434, 0.2259956452027434, 0.2145669164850489, 0.2145669164850489, 0.2145669164850489, 0.18917699993398196, 0.18917699993398196, 0.18917699993398196, 0.2119708859530216, 0.2119708859530216, 0.2119708859530216, 0.21340091886950696, 0.21340091886950696, 0.21340091886950696, 0.8827489131172525, 0.8827489131172525, 0.8827489131172525, 0.8337035585135748, 0.8337035585135748, 0.8337035585135748, 0.1709948759035922, 0.1709948759035922, 0.1709948759035922, 0.16854767470001752, 0.16854767470001752, 0.16854767470001752, 0.21269185023656045, 0.21269185023656045, 0.21269185023656045, 0.16517146176337572, 0.16517146176337572, 0.16517146176337572, 0.19211108340755456, 0.19211108340755456, 0.19211108340755456, 0.19776688025715927, 0.19776688025715927, 0.19776688025715927, 0.18937510065702245, 0.18937510065702245, 0.18937510065702245, 0.096364790052343, 0.096364790052343, 0.096364790052343, 0.10194227453578975, 0.10194227453578975, 0.10194227453578975, 0.15371654266883028, 0.15371654266883028, 0.15371654266883028]}, "mutation_prompt": null}
{"id": "7370c7ff-bef2-4d59-bd2d-2f3003381a58", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.6  # Differential Evolution parameter (changed from 0.5)\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Improved parameter settings for the Adaptive Hybrid GA to enhance convergence speed and solution quality.", "configspace": "", "generation": 1, "fitness": 0.299477559532773, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.26.", "error": "", "parent_id": "a1a3da39-49e2-41a4-893c-9c3a138a214c", "metadata": {"aucs": [0.8288706661474327, 0.8288706661474327, 0.8288706661474327, 0.7956231587112106, 0.7956231587112106, 0.7956231587112106, 0.8332885627537072, 0.8332885627537072, 0.8332885627537072, 0.6397088471052232, 0.6397088471052232, 0.6397088471052232, 0.567490645284266, 0.567490645284266, 0.567490645284266, 0.6087600260044173, 0.6087600260044173, 0.6087600260044173, 0.14077288275328792, 0.14077288275328792, 0.14077288275328792, 0.16218981689018763, 0.16218981689018763, 0.16218981689018763, 0.1388545552426682, 0.1388545552426682, 0.1388545552426682, 0.0980497736876863, 0.0980497736876863, 0.0980497736876863, 0.14216612284745933, 0.14216612284745933, 0.14216612284745933, 0.1255431967136934, 0.1255431967136934, 0.1255431967136934, 0.9857336960226455, 0.9857336960226455, 0.9857336960226455, 0.9854395235775701, 0.9854395235775701, 0.9854395235775701, 0.9813424162994477, 0.9813424162994477, 0.9813424162994477, 0.5914635569516513, 0.5914635569516513, 0.5914635569516513, 0.6251730508183043, 0.6251730508183043, 0.6251730508183043, 0.5741828974398391, 0.5741828974398391, 0.5741828974398391, 0.3701777991046299, 0.3701777991046299, 0.3701777991046299, 0.16089775845435883, 0.16089775845435883, 0.16089775845435883, 0.34679144829674924, 0.34679144829674924, 0.34679144829674924, 0.184627916912931, 0.184627916912931, 0.184627916912931, 0.2336374388805259, 0.2336374388805259, 0.2336374388805259, 0.12758770778824768, 0.12758770778824768, 0.12758770778824768, 0.18773031061223644, 0.18773031061223644, 0.18773031061223644, 0.227599390537641, 0.227599390537641, 0.227599390537641, 0.25195741054056897, 0.25195741054056897, 0.25195741054056897, 0.01881880780660561, 0.01881880780660561, 0.01881880780660561, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.022321494309338386, 0.022321494309338386, 0.022321494309338386, 0.04564245422296831, 0.04564245422296831, 0.04564245422296831, 0.07743355837465937, 0.07743355837465937, 0.07743355837465937, 0.06470757012087092, 0.06470757012087092, 0.06470757012087092, 0.08559418606144242, 0.08559418606144242, 0.08559418606144242, 0.086597121886274, 0.086597121886274, 0.086597121886274, 0.10479129312165514, 0.10479129312165514, 0.10479129312165514, 0.1349233600704962, 0.1349233600704962, 0.1349233600704962, 0.07840826643696963, 0.07840826643696963, 0.07840826643696963, 0.5500810178560263, 0.5500810178560263, 0.5500810178560263, 0.5939282492532847, 0.5939282492532847, 0.5939282492532847, 0.5521335704736603, 0.5521335704736603, 0.5521335704736603, 0.14974236528668772, 0.14974236528668772, 0.14974236528668772, 0.11538155747214529, 0.11538155747214529, 0.11538155747214529, 0.16236838265064546, 0.16236838265064546, 0.16236838265064546, 0.19343779460642163, 0.19343779460642163, 0.19343779460642163, 0.4552349018758628, 0.4552349018758628, 0.4552349018758628, 0.43143271037018716, 0.43143271037018716, 0.43143271037018716, 0.25426445127577324, 0.25426445127577324, 0.25426445127577324, 0.4339489392554863, 0.4339489392554863, 0.4339489392554863, 0.5097315685931854, 0.5097315685931854, 0.5097315685931854, 0.26052017629126534, 0.26052017629126534, 0.26052017629126534, 0.25099939782378156, 0.25099939782378156, 0.25099939782378156, 0.14060756620302706, 0.14060756620302706, 0.14060756620302706, 0.21693323278480314, 0.21693323278480314, 0.21693323278480314, 0.25936482540161576, 0.25936482540161576, 0.25936482540161576, 0.20194442412355262, 0.20194442412355262, 0.20194442412355262, 0.20458132351845848, 0.20458132351845848, 0.20458132351845848, 0.2179671466093116, 0.2179671466093116, 0.2179671466093116, 0.19880639421269775, 0.19880639421269775, 0.19880639421269775, 0.8564572274552759, 0.8564572274552759, 0.8564572274552759, 0.15734178582027558, 0.15734178582027558, 0.15734178582027558, 0.17455373749807712, 0.17455373749807712, 0.17455373749807712, 0.15450183031322917, 0.15450183031322917, 0.15450183031322917, 0.21177037234689455, 0.21177037234689455, 0.21177037234689455, 0.16297316455045363, 0.16297316455045363, 0.16297316455045363, 0.18807551242134324, 0.18807551242134324, 0.18807551242134324, 0.18527196034452076, 0.18527196034452076, 0.18527196034452076, 0.18173315113593191, 0.18173315113593191, 0.18173315113593191, 0.08489975833341545, 0.08489975833341545, 0.08489975833341545, 0.08886531205606774, 0.08886531205606774, 0.08886531205606774, 0.12743178935642518, 0.12743178935642518, 0.12743178935642518]}, "mutation_prompt": null}
{"id": "a0d08e3a-ac07-4e0c-91b9-2fdd2e168e05", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                self.F = 0.5 + 0.3 * np.random.rand()  # Dynamically adjust F\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced mutation strategy by dynamically adjusting the Differential Evolution parameter F.", "configspace": "", "generation": 2, "fitness": 0.27548961368686165, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.25.", "error": "", "parent_id": "a1a3da39-49e2-41a4-893c-9c3a138a214c", "metadata": {"aucs": [0.8193592055042593, 0.8193592055042593, 0.8193592055042593, 0.82012443701623, 0.82012443701623, 0.82012443701623, 0.7975417002566477, 0.7975417002566477, 0.7975417002566477, 0.5991209300991258, 0.5991209300991258, 0.5991209300991258, 0.5397708952872735, 0.5397708952872735, 0.5397708952872735, 0.5719949177286041, 0.5719949177286041, 0.5719949177286041, 0.15063136362356622, 0.15063136362356622, 0.15063136362356622, 0.16560857141762497, 0.16560857141762497, 0.16560857141762497, 0.1409996826745028, 0.1409996826745028, 0.1409996826745028, 0.10780901998694248, 0.10780901998694248, 0.10780901998694248, 0.12758232334572184, 0.12758232334572184, 0.12758232334572184, 0.10215261453864555, 0.10215261453864555, 0.10215261453864555, 0.9860376246299154, 0.9860376246299154, 0.9860376246299154, 0.9844156158968164, 0.9844156158968164, 0.9844156158968164, 0.9853676968321999, 0.9853676968321999, 0.9853676968321999, 0.5970361623754905, 0.5970361623754905, 0.5970361623754905, 0.15163458807993735, 0.15163458807993735, 0.15163458807993735, 0.08931273119621819, 0.08931273119621819, 0.08931273119621819, 0.35960535717188735, 0.35960535717188735, 0.35960535717188735, 0.27257753721195566, 0.27257753721195566, 0.27257753721195566, 0.2219108171015357, 0.2219108171015357, 0.2219108171015357, 0.2247942615846663, 0.2247942615846663, 0.2247942615846663, 0.1317107486486775, 0.1317107486486775, 0.1317107486486775, 0.1227362916531074, 0.1227362916531074, 0.1227362916531074, 0.10505835118799844, 0.10505835118799844, 0.10505835118799844, 0.25565402581057883, 0.25565402581057883, 0.25565402581057883, 0.25593302068891366, 0.25593302068891366, 0.25593302068891366, 0.02846102593161104, 0.02846102593161104, 0.02846102593161104, 0.12384037588717256, 0.12384037588717256, 0.12384037588717256, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07992003383146351, 0.07992003383146351, 0.07992003383146351, 0.02013812324173936, 0.02013812324173936, 0.02013812324173936, 0.09069224929127517, 0.09069224929127517, 0.09069224929127517, 0.05227749369471457, 0.05227749369471457, 0.05227749369471457, 0.11010734501253372, 0.11010734501253372, 0.11010734501253372, 0.06370269003965345, 0.06370269003965345, 0.06370269003965345, 0.06243915156774715, 0.06243915156774715, 0.06243915156774715, 0.12753553693540653, 0.12753553693540653, 0.12753553693540653, 0.05597338574192978, 0.05597338574192978, 0.05597338574192978, 0.5743780760858639, 0.5743780760858639, 0.5743780760858639, 0.5595824421957516, 0.5595824421957516, 0.5595824421957516, 0.5432023988145706, 0.5432023988145706, 0.5432023988145706, 0.10094971244574003, 0.10094971244574003, 0.10094971244574003, 0.1234980236700427, 0.1234980236700427, 0.1234980236700427, 0.11127908262365094, 0.11127908262365094, 0.11127908262365094, 0.20855310607940658, 0.20855310607940658, 0.20855310607940658, 0.25894119847006414, 0.25894119847006414, 0.25894119847006414, 0.19654521262782443, 0.19654521262782443, 0.19654521262782443, 0.2817011862407719, 0.2817011862407719, 0.2817011862407719, 0.4112318914685752, 0.4112318914685752, 0.4112318914685752, 0.2799906810960596, 0.2799906810960596, 0.2799906810960596, 0.298886884490682, 0.298886884490682, 0.298886884490682, 0.20729116675560055, 0.20729116675560055, 0.20729116675560055, 0.18450523950495812, 0.18450523950495812, 0.18450523950495812, 0.21879622909021879, 0.21879622909021879, 0.21879622909021879, 0.19655560114913628, 0.19655560114913628, 0.19655560114913628, 0.2086987083666375, 0.2086987083666375, 0.2086987083666375, 0.24072451488417812, 0.24072451488417812, 0.24072451488417812, 0.22230554229202903, 0.22230554229202903, 0.22230554229202903, 0.206366456618008, 0.206366456618008, 0.206366456618008, 0.8947140158799767, 0.8947140158799767, 0.8947140158799767, 0.1974462968978279, 0.1974462968978279, 0.1974462968978279, 0.17137011758307397, 0.17137011758307397, 0.17137011758307397, 0.21066213397478528, 0.21066213397478528, 0.21066213397478528, 0.21188957799113273, 0.21188957799113273, 0.21188957799113273, 0.1548279493881164, 0.1548279493881164, 0.1548279493881164, 0.1852462664893031, 0.1852462664893031, 0.1852462664893031, 0.19673171124278055, 0.19673171124278055, 0.19673171124278055, 0.19584393076488438, 0.19584393076488438, 0.19584393076488438, 0.08822276139550234, 0.08822276139550234, 0.08822276139550234, 0.09611180139583098, 0.09611180139583098, 0.09611180139583098, 0.09653436475676591, 0.09653436475676591, 0.09653436475676591]}, "mutation_prompt": null}
{"id": "d6c222b9-0a35-4d47-9a06-4bbd21e56794", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.5 - evaluations/self.budget * 1.5\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced Adaptive Hybrid GA with time-varying PSO coefficients for improved convergence.", "configspace": "", "generation": 3, "fitness": 0.3315290206079212, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.27.", "error": "", "parent_id": "a1a3da39-49e2-41a4-893c-9c3a138a214c", "metadata": {"aucs": [0.8216992617670291, 0.8216992617670291, 0.8216992617670291, 0.834555770812918, 0.834555770812918, 0.834555770812918, 0.8601843397563315, 0.8601843397563315, 0.8601843397563315, 0.5980513848633461, 0.5980513848633461, 0.5980513848633461, 0.6327843132735819, 0.6327843132735819, 0.6327843132735819, 0.6361202515020358, 0.6361202515020358, 0.6361202515020358, 0.13421153457302248, 0.13421153457302248, 0.13421153457302248, 0.14218408253177295, 0.14218408253177295, 0.14218408253177295, 0.13808461639288494, 0.13808461639288494, 0.13808461639288494, 0.12391576140189986, 0.12391576140189986, 0.12391576140189986, 0.11434339894540901, 0.11434339894540901, 0.11434339894540901, 0.11030764537358062, 0.11030764537358062, 0.11030764537358062, 0.9733779791276902, 0.9733779791276902, 0.9733779791276902, 0.9710929435198247, 0.9710929435198247, 0.9710929435198247, 0.9673918437285987, 0.9673918437285987, 0.9673918437285987, 0.6594384842139365, 0.6594384842139365, 0.6594384842139365, 0.5885876584934088, 0.5885876584934088, 0.5885876584934088, 0.5957543435799345, 0.5957543435799345, 0.5957543435799345, 0.7069376150242797, 0.7069376150242797, 0.7069376150242797, 0.20868813439719114, 0.20868813439719114, 0.20868813439719114, 0.22743203928658384, 0.22743203928658384, 0.22743203928658384, 0.22641593834231155, 0.22641593834231155, 0.22641593834231155, 0.25904375730635765, 0.25904375730635765, 0.25904375730635765, 0.13234779040715416, 0.13234779040715416, 0.13234779040715416, 0.22966881433446207, 0.22966881433446207, 0.22966881433446207, 0.13024112938629373, 0.13024112938629373, 0.13024112938629373, 0.24164128071119007, 0.24164128071119007, 0.24164128071119007, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005758506896028304, 0.005758506896028304, 0.005758506896028304, 0.06796026402235822, 0.06796026402235822, 0.06796026402235822, 0.16889524541444356, 0.16889524541444356, 0.16889524541444356, 0.054008474790019134, 0.054008474790019134, 0.054008474790019134, 0.12352084311833789, 0.12352084311833789, 0.12352084311833789, 0.10860882836766161, 0.10860882836766161, 0.10860882836766161, 0.31545027781117985, 0.31545027781117985, 0.31545027781117985, 0.19111555886209508, 0.19111555886209508, 0.19111555886209508, 0.17954142119051264, 0.17954142119051264, 0.17954142119051264, 0.11191071611963632, 0.11191071611963632, 0.11191071611963632, 0.04904028352268164, 0.04904028352268164, 0.04904028352268164, 0.5177374065839205, 0.5177374065839205, 0.5177374065839205, 0.5953458306536531, 0.5953458306536531, 0.5953458306536531, 0.5544281014721079, 0.5544281014721079, 0.5544281014721079, 0.12425832493217981, 0.12425832493217981, 0.12425832493217981, 0.137206511262702, 0.137206511262702, 0.137206511262702, 0.14098851976330284, 0.14098851976330284, 0.14098851976330284, 0.16134853154856066, 0.16134853154856066, 0.16134853154856066, 0.2994056794795542, 0.2994056794795542, 0.2994056794795542, 0.17889317203700905, 0.17889317203700905, 0.17889317203700905, 0.4654936839139957, 0.4654936839139957, 0.4654936839139957, 0.2688947925001848, 0.2688947925001848, 0.2688947925001848, 0.4444986852307854, 0.4444986852307854, 0.4444986852307854, 0.3172044211601194, 0.3172044211601194, 0.3172044211601194, 0.2676666258484469, 0.2676666258484469, 0.2676666258484469, 0.19996885012061816, 0.19996885012061816, 0.19996885012061816, 0.2043688373208018, 0.2043688373208018, 0.2043688373208018, 0.1944176429182769, 0.1944176429182769, 0.1944176429182769, 0.2192393739515125, 0.2192393739515125, 0.2192393739515125, 0.23878103752373103, 0.23878103752373103, 0.23878103752373103, 0.2203335703599767, 0.2203335703599767, 0.2203335703599767, 0.23972884254261861, 0.23972884254261861, 0.23972884254261861, 0.8547404889332653, 0.8547404889332653, 0.8547404889332653, 0.16739007107986092, 0.16739007107986092, 0.16739007107986092, 0.7644801573757153, 0.7644801573757153, 0.7644801573757153, 0.20637745463252133, 0.20637745463252133, 0.20637745463252133, 0.6667150837110141, 0.6667150837110141, 0.6667150837110141, 0.7116336998129731, 0.7116336998129731, 0.7116336998129731, 0.18023461025612486, 0.18023461025612486, 0.18023461025612486, 0.20252992239711576, 0.20252992239711576, 0.20252992239711576, 0.19779116279521314, 0.19779116279521314, 0.19779116279521314, 0.0811555068128379, 0.0811555068128379, 0.0811555068128379, 0.092863427164389, 0.092863427164389, 0.092863427164389, 0.11355692450725641, 0.11355692450725641, 0.11355692450725641]}, "mutation_prompt": null}
{"id": "6369971a-01a6-4516-a8f5-e1b22bed10da", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.5 - evaluations/self.budget * 1.5\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                self.w = 0.9 - evaluations/self.budget * 0.4  # Dynamic inertia weight\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Introduce a dynamic inertia weight adjustment in the PSO step for balance between exploration and exploitation.", "configspace": "", "generation": 4, "fitness": 0.19812200461634547, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.20.", "error": "", "parent_id": "d6c222b9-0a35-4d47-9a06-4bbd21e56794", "metadata": {"aucs": [0.43486590630087596, 0.43486590630087596, 0.43486590630087596, 0.4196865643840717, 0.4196865643840717, 0.4196865643840717, 0.4159055468049865, 0.4159055468049865, 0.4159055468049865, 0.0569867999396898, 0.0569867999396898, 0.0569867999396898, 0.1065571641026154, 0.1065571641026154, 0.1065571641026154, 0.12516798471832358, 0.12516798471832358, 0.12516798471832358, 0.09668045109155787, 0.09668045109155787, 0.09668045109155787, 0.11757986925283037, 0.11757986925283037, 0.11757986925283037, 0.08906217508630798, 0.08906217508630798, 0.08906217508630798, 0.08747741755209426, 0.08747741755209426, 0.08747741755209426, 0.08990349966237177, 0.08990349966237177, 0.08990349966237177, 0.0754456804710335, 0.0754456804710335, 0.0754456804710335, 0.977641019122219, 0.977641019122219, 0.977641019122219, 0.974965998389739, 0.974965998389739, 0.974965998389739, 0.9736493313222908, 0.9736493313222908, 0.9736493313222908, 0.21319245301775336, 0.21319245301775336, 0.21319245301775336, 0.273515066815623, 0.273515066815623, 0.273515066815623, 0.2393179510655543, 0.2393179510655543, 0.2393179510655543, 0.19676773859300334, 0.19676773859300334, 0.19676773859300334, 0.1553998389783976, 0.1553998389783976, 0.1553998389783976, 0.16219221950221852, 0.16219221950221852, 0.16219221950221852, 0.13368502971293816, 0.13368502971293816, 0.13368502971293816, 0.11861225779181117, 0.11861225779181117, 0.11861225779181117, 0.08726412618998436, 0.08726412618998436, 0.08726412618998436, 0.08283629500611056, 0.08283629500611056, 0.08283629500611056, 0.09536451014419167, 0.09536451014419167, 0.09536451014419167, 0.11625095867726265, 0.11625095867726265, 0.11625095867726265, 0.021930844051926024, 0.021930844051926024, 0.021930844051926024, 0.00549643890106033, 0.00549643890106033, 0.00549643890106033, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08312291160095975, 0.08312291160095975, 0.08312291160095975, 0.057952454685564536, 0.057952454685564536, 0.057952454685564536, 0.02844257565646402, 0.02844257565646402, 0.02844257565646402, 0.019854125746097462, 0.019854125746097462, 0.019854125746097462, 0.02249902745935728, 0.02249902745935728, 0.02249902745935728, 0.02504003459454396, 0.02504003459454396, 0.02504003459454396, 0.10855560901914119, 0.10855560901914119, 0.10855560901914119, 0.1000703553313892, 0.1000703553313892, 0.1000703553313892, 0.0844972944558453, 0.0844972944558453, 0.0844972944558453, 0.356765217046221, 0.356765217046221, 0.356765217046221, 0.36595730295647977, 0.36595730295647977, 0.36595730295647977, 0.36447914020793537, 0.36447914020793537, 0.36447914020793537, 0.09814373222117445, 0.09814373222117445, 0.09814373222117445, 0.14021554489812227, 0.14021554489812227, 0.14021554489812227, 0.10552047148628385, 0.10552047148628385, 0.10552047148628385, 0.1617080831117197, 0.1617080831117197, 0.1617080831117197, 0.14201063348138088, 0.14201063348138088, 0.14201063348138088, 0.1573985866185732, 0.1573985866185732, 0.1573985866185732, 0.2766540526148974, 0.2766540526148974, 0.2766540526148974, 0.28276234174698367, 0.28276234174698367, 0.28276234174698367, 0.28981906967076343, 0.28981906967076343, 0.28981906967076343, 0.17883789074902923, 0.17883789074902923, 0.17883789074902923, 0.20548459302046418, 0.20548459302046418, 0.20548459302046418, 0.21726478697743634, 0.21726478697743634, 0.21726478697743634, 0.22283759824588323, 0.22283759824588323, 0.22283759824588323, 0.1769523221098872, 0.1769523221098872, 0.1769523221098872, 0.17230295437001042, 0.17230295437001042, 0.17230295437001042, 0.2150143947718749, 0.2150143947718749, 0.2150143947718749, 0.20857877995844543, 0.20857877995844543, 0.20857877995844543, 0.19380017949032213, 0.19380017949032213, 0.19380017949032213, 0.6449101622407879, 0.6449101622407879, 0.6449101622407879, 0.18381261663293724, 0.18381261663293724, 0.18381261663293724, 0.15443481132919046, 0.15443481132919046, 0.15443481132919046, 0.1657480465064094, 0.1657480465064094, 0.1657480465064094, 0.1874311288383429, 0.1874311288383429, 0.1874311288383429, 0.14372942529101096, 0.14372942529101096, 0.14372942529101096, 0.17995189889946073, 0.17995189889946073, 0.17995189889946073, 0.19448297590228414, 0.19448297590228414, 0.19448297590228414, 0.1917963772871617, 0.1917963772871617, 0.1917963772871617, 0.06910185827438964, 0.06910185827438964, 0.06910185827438964, 0.07631925051424004, 0.07631925051424004, 0.07631925051424004, 0.06702257970856684, 0.06702257970856684, 0.06702257970856684]}, "mutation_prompt": null}
{"id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Improved exploitation by slightly increasing the influence of personal best in PSO.  ", "configspace": "", "generation": 5, "fitness": 0.3400727075450199, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.26.", "error": "", "parent_id": "d6c222b9-0a35-4d47-9a06-4bbd21e56794", "metadata": {"aucs": [0.8540447072940346, 0.8540447072940346, 0.8540447072940346, 0.8465583710666816, 0.8465583710666816, 0.8465583710666816, 0.8646527589516538, 0.8646527589516538, 0.8646527589516538, 0.629570429025394, 0.629570429025394, 0.629570429025394, 0.6572990182074965, 0.6572990182074965, 0.6572990182074965, 0.6633616751865419, 0.6633616751865419, 0.6633616751865419, 0.43432583378995837, 0.43432583378995837, 0.43432583378995837, 0.15675846499621715, 0.15675846499621715, 0.15675846499621715, 0.3956766611066812, 0.3956766611066812, 0.3956766611066812, 0.10728137809150284, 0.10728137809150284, 0.10728137809150284, 0.12308083043797213, 0.12308083043797213, 0.12308083043797213, 0.13290080778273317, 0.13290080778273317, 0.13290080778273317, 0.9734552242079392, 0.9734552242079392, 0.9734552242079392, 0.9738488572202405, 0.9738488572202405, 0.9738488572202405, 0.9697987212556279, 0.9697987212556279, 0.9697987212556279, 0.5652408953095993, 0.5652408953095993, 0.5652408953095993, 0.529209487011978, 0.529209487011978, 0.529209487011978, 0.5482166386608378, 0.5482166386608378, 0.5482166386608378, 0.7784102034800175, 0.7784102034800175, 0.7784102034800175, 0.26786438258645584, 0.26786438258645584, 0.26786438258645584, 0.6669983256831089, 0.6669983256831089, 0.6669983256831089, 0.18887595098872512, 0.18887595098872512, 0.18887595098872512, 0.2005049712382525, 0.2005049712382525, 0.2005049712382525, 0.25884093698768307, 0.25884093698768307, 0.25884093698768307, 0.21528194500730147, 0.21528194500730147, 0.21528194500730147, 0.13137256478713166, 0.13137256478713166, 0.13137256478713166, 0.2348923214303863, 0.2348923214303863, 0.2348923214303863, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1769343559140465, 0.1769343559140465, 0.1769343559140465, 0.060002636497266004, 0.060002636497266004, 0.060002636497266004, 0.058252176130646705, 0.058252176130646705, 0.058252176130646705, 0.13712491276005545, 0.13712491276005545, 0.13712491276005545, 0.35144242778120194, 0.35144242778120194, 0.35144242778120194, 0.26112604317550625, 0.26112604317550625, 0.26112604317550625, 0.2350763119506718, 0.2350763119506718, 0.2350763119506718, 0.09812702949551422, 0.09812702949551422, 0.09812702949551422, 0.05457108392156973, 0.05457108392156973, 0.05457108392156973, 0.5374772653648969, 0.5374772653648969, 0.5374772653648969, 0.5752305217450722, 0.5752305217450722, 0.5752305217450722, 0.5571960056035636, 0.5571960056035636, 0.5571960056035636, 0.13960991963129454, 0.13960991963129454, 0.13960991963129454, 0.11167906551650941, 0.11167906551650941, 0.11167906551650941, 0.11219055440277803, 0.11219055440277803, 0.11219055440277803, 0.1617977375392491, 0.1617977375392491, 0.1617977375392491, 0.16134673628192941, 0.16134673628192941, 0.16134673628192941, 0.21596301221449965, 0.21596301221449965, 0.21596301221449965, 0.3856359101929955, 0.3856359101929955, 0.3856359101929955, 0.4381899537856434, 0.4381899537856434, 0.4381899537856434, 0.4365768714152741, 0.4365768714152741, 0.4365768714152741, 0.4008940740175161, 0.4008940740175161, 0.4008940740175161, 0.20132587345969843, 0.20132587345969843, 0.20132587345969843, 0.2901498033166575, 0.2901498033166575, 0.2901498033166575, 0.24487850389293775, 0.24487850389293775, 0.24487850389293775, 0.1966586578178371, 0.1966586578178371, 0.1966586578178371, 0.2184538647252544, 0.2184538647252544, 0.2184538647252544, 0.18998346381953013, 0.18998346381953013, 0.18998346381953013, 0.40632590525145584, 0.40632590525145584, 0.40632590525145584, 0.5226324045522219, 0.5226324045522219, 0.5226324045522219, 0.8145538747892331, 0.8145538747892331, 0.8145538747892331, 0.16316978485202527, 0.16316978485202527, 0.16316978485202527, 0.7307646036617415, 0.7307646036617415, 0.7307646036617415, 0.168036312347141, 0.168036312347141, 0.168036312347141, 0.207912735678645, 0.207912735678645, 0.207912735678645, 0.20678892929056436, 0.20678892929056436, 0.20678892929056436, 0.22002939184160653, 0.22002939184160653, 0.22002939184160653, 0.20188615696029644, 0.20188615696029644, 0.20188615696029644, 0.20853474941722538, 0.20853474941722538, 0.20853474941722538, 0.08069826156317317, 0.08069826156317317, 0.08069826156317317, 0.08335513025594832, 0.08335513025594832, 0.08335513025594832, 0.09402956861838407, 0.09402956861838407, 0.09402956861838407]}, "mutation_prompt": null}
{"id": "6f503069-16e0-4831-a873-396bc51f6150", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.6  # Differential Evolution parameter (changed from 0.5 to 0.6)\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Optimized the mutation strategy by tweaking the mutation factor to enhance exploration capabilities in the Differential Evolution step.", "configspace": "", "generation": 6, "fitness": 0.3282104894661493, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.27.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.8519741438328772, 0.8519741438328772, 0.8519741438328772, 0.8522232729402333, 0.8522232729402333, 0.8522232729402333, 0.8716537146579036, 0.8716537146579036, 0.8716537146579036, 0.5938755616911529, 0.5938755616911529, 0.5938755616911529, 0.6347477094250065, 0.6347477094250065, 0.6347477094250065, 0.645366152370004, 0.645366152370004, 0.645366152370004, 0.14805126111338973, 0.14805126111338973, 0.14805126111338973, 0.15561870599481753, 0.15561870599481753, 0.15561870599481753, 0.13749608685890158, 0.13749608685890158, 0.13749608685890158, 0.11101595148291943, 0.11101595148291943, 0.11101595148291943, 0.12560222304408541, 0.12560222304408541, 0.12560222304408541, 0.11768101500154848, 0.11768101500154848, 0.11768101500154848, 0.9737729386068896, 0.9737729386068896, 0.9737729386068896, 0.9717227899301932, 0.9717227899301932, 0.9717227899301932, 0.9699333372574342, 0.9699333372574342, 0.9699333372574342, 0.6012529666705773, 0.6012529666705773, 0.6012529666705773, 0.5598586336410543, 0.5598586336410543, 0.5598586336410543, 0.5737566673849597, 0.5737566673849597, 0.5737566673849597, 0.6652179915178237, 0.6652179915178237, 0.6652179915178237, 0.5625705490401767, 0.5625705490401767, 0.5625705490401767, 0.5206460660957841, 0.5206460660957841, 0.5206460660957841, 0.21096662586000747, 0.21096662586000747, 0.21096662586000747, 0.23234065337763754, 0.23234065337763754, 0.23234065337763754, 0.13055149276655553, 0.13055149276655553, 0.13055149276655553, 0.19126400964882262, 0.19126400964882262, 0.19126400964882262, 0.23178004281940578, 0.23178004281940578, 0.23178004281940578, 0.21634564122982314, 0.21634564122982314, 0.21634564122982314, 0.011018369516471838, 0.011018369516471838, 0.011018369516471838, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07628567475946402, 0.07628567475946402, 0.07628567475946402, 0.04577023734441277, 0.04577023734441277, 0.04577023734441277, 0.0463952273900341, 0.0463952273900341, 0.0463952273900341, 0.04684347765028796, 0.04684347765028796, 0.04684347765028796, 0.11524310858608311, 0.11524310858608311, 0.11524310858608311, 0.17443770576349094, 0.17443770576349094, 0.17443770576349094, 0.12848492670217415, 0.12848492670217415, 0.12848492670217415, 0.08627428670970572, 0.08627428670970572, 0.08627428670970572, 0.060632934957143725, 0.060632934957143725, 0.060632934957143725, 0.5160686659032837, 0.5160686659032837, 0.5160686659032837, 0.5258287042647534, 0.5258287042647534, 0.5258287042647534, 0.5633471549684006, 0.5633471549684006, 0.5633471549684006, 0.12184911571248935, 0.12184911571248935, 0.12184911571248935, 0.14717044565793058, 0.14717044565793058, 0.14717044565793058, 0.12536996722979765, 0.12536996722979765, 0.12536996722979765, 0.1718073317929033, 0.1718073317929033, 0.1718073317929033, 0.21566019484398258, 0.21566019484398258, 0.21566019484398258, 0.21234288628452025, 0.21234288628452025, 0.21234288628452025, 0.47998250600961745, 0.47998250600961745, 0.47998250600961745, 0.48990524234828947, 0.48990524234828947, 0.48990524234828947, 0.42902101305167084, 0.42902101305167084, 0.42902101305167084, 0.22753949459305767, 0.22753949459305767, 0.22753949459305767, 0.2224878010904915, 0.2224878010904915, 0.2224878010904915, 0.2051621466004533, 0.2051621466004533, 0.2051621466004533, 0.22176979125645158, 0.22176979125645158, 0.22176979125645158, 0.22277818914159164, 0.22277818914159164, 0.22277818914159164, 0.21244402777535054, 0.21244402777535054, 0.21244402777535054, 0.18887979639897912, 0.18887979639897912, 0.18887979639897912, 0.21524848010984088, 0.21524848010984088, 0.21524848010984088, 0.21184513350231637, 0.21184513350231637, 0.21184513350231637, 0.8630674223679039, 0.8630674223679039, 0.8630674223679039, 0.16350862170902414, 0.16350862170902414, 0.16350862170902414, 0.19475736807897792, 0.19475736807897792, 0.19475736807897792, 0.6361580249552758, 0.6361580249552758, 0.6361580249552758, 0.6375543428505228, 0.6375543428505228, 0.6375543428505228, 0.6769254155405378, 0.6769254155405378, 0.6769254155405378, 0.1868332209529151, 0.1868332209529151, 0.1868332209529151, 0.1851520338909204, 0.1851520338909204, 0.1851520338909204, 0.22205451632085693, 0.22205451632085693, 0.22205451632085693, 0.08860476967864361, 0.08860476967864361, 0.08860476967864361, 0.09027986585121761, 0.09027986585121761, 0.09027986585121761, 0.11087939719052498, 0.11087939719052498, 0.11087939719052498]}, "mutation_prompt": null}
{"id": "875bfdc7-f07f-4bec-9614-b3fc6c5c74b3", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                self.w = 0.9 - 0.4 * (evaluations / self.budget)  # Dynamic inertia weight adjustment\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Improved exploration by dynamically adjusting the inertia weight in PSO.", "configspace": "", "generation": 7, "fitness": 0.1905985125195022, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.437605286148927, 0.437605286148927, 0.437605286148927, 0.4548483346002523, 0.4548483346002523, 0.4548483346002523, 0.4807776073732434, 0.4807776073732434, 0.4807776073732434, 0.10137514983641505, 0.10137514983641505, 0.10137514983641505, 0.049834645307488046, 0.049834645307488046, 0.049834645307488046, 0.02628286255110235, 0.02628286255110235, 0.02628286255110235, 0.0844780636365755, 0.0844780636365755, 0.0844780636365755, 0.08766721836909674, 0.08766721836909674, 0.08766721836909674, 0.08502418371943421, 0.08502418371943421, 0.08502418371943421, 0.07705562381719444, 0.07705562381719444, 0.07705562381719444, 0.07472857816598899, 0.07472857816598899, 0.07472857816598899, 0.08061123337641407, 0.08061123337641407, 0.08061123337641407, 0.975652090494761, 0.975652090494761, 0.975652090494761, 0.9790366890189451, 0.9790366890189451, 0.9790366890189451, 0.9736664876013109, 0.9736664876013109, 0.9736664876013109, 0.281429548677698, 0.281429548677698, 0.281429548677698, 0.19621990574529247, 0.19621990574529247, 0.19621990574529247, 0.2096629104369263, 0.2096629104369263, 0.2096629104369263, 0.18701423690835983, 0.18701423690835983, 0.18701423690835983, 0.18332241035662344, 0.18332241035662344, 0.18332241035662344, 0.1991846570435214, 0.1991846570435214, 0.1991846570435214, 0.12333134526260581, 0.12333134526260581, 0.12333134526260581, 0.13085889400922657, 0.13085889400922657, 0.13085889400922657, 0.12340971554608982, 0.12340971554608982, 0.12340971554608982, 0.019550142587097974, 0.019550142587097974, 0.019550142587097974, 0.10950163133381119, 0.10950163133381119, 0.10950163133381119, 0.1177956983214784, 0.1177956983214784, 0.1177956983214784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00950637459719128, 0.00950637459719128, 0.00950637459719128, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10106885035602009, 0.10106885035602009, 0.10106885035602009, 0.04465698958158304, 0.04465698958158304, 0.04465698958158304, 0.07258536355953182, 0.07258536355953182, 0.07258536355953182, 0.013005801850459853, 0.013005801850459853, 0.013005801850459853, 0.006472194279493304, 0.006472194279493304, 0.006472194279493304, 0.02355355952731175, 0.02355355952731175, 0.02355355952731175, 0.03591986374834777, 0.03591986374834777, 0.03591986374834777, 0.04411588696491331, 0.04411588696491331, 0.04411588696491331, 0.08604786458357705, 0.08604786458357705, 0.08604786458357705, 0.3721972396434816, 0.3721972396434816, 0.3721972396434816, 0.32785117041377165, 0.32785117041377165, 0.32785117041377165, 0.3191748871910909, 0.3191748871910909, 0.3191748871910909, 0.08459005096922123, 0.08459005096922123, 0.08459005096922123, 0.10192835821712865, 0.10192835821712865, 0.10192835821712865, 0.09248598957574816, 0.09248598957574816, 0.09248598957574816, 0.16439007814830298, 0.16439007814830298, 0.16439007814830298, 0.16513681059269092, 0.16513681059269092, 0.16513681059269092, 0.1481488140498476, 0.1481488140498476, 0.1481488140498476, 0.261510016304523, 0.261510016304523, 0.261510016304523, 0.23815083626712874, 0.23815083626712874, 0.23815083626712874, 0.2543841551111472, 0.2543841551111472, 0.2543841551111472, 0.22006955393172245, 0.22006955393172245, 0.22006955393172245, 0.16858121251514335, 0.16858121251514335, 0.16858121251514335, 0.18557368929442108, 0.18557368929442108, 0.18557368929442108, 0.1824320921383441, 0.1824320921383441, 0.1824320921383441, 0.19769733786703114, 0.19769733786703114, 0.19769733786703114, 0.19230837653923083, 0.19230837653923083, 0.19230837653923083, 0.17570374458313687, 0.17570374458313687, 0.17570374458313687, 0.20251793593804024, 0.20251793593804024, 0.20251793593804024, 0.16434101028399106, 0.16434101028399106, 0.16434101028399106, 0.5047688863531201, 0.5047688863531201, 0.5047688863531201, 0.19016039680171526, 0.19016039680171526, 0.19016039680171526, 0.17640693852197142, 0.17640693852197142, 0.17640693852197142, 0.19621505054565602, 0.19621505054565602, 0.19621505054565602, 0.19381752126562424, 0.19381752126562424, 0.19381752126562424, 0.20035116540292175, 0.20035116540292175, 0.20035116540292175, 0.18453816311407745, 0.18453816311407745, 0.18453816311407745, 0.1709701339416373, 0.1709701339416373, 0.1709701339416373, 0.19104830268622186, 0.19104830268622186, 0.19104830268622186, 0.07310600968431136, 0.07310600968431136, 0.07310600968431136, 0.06854543834691518, 0.06854543834691518, 0.06854543834691518, 0.06693363587053258, 0.06693363587053258, 0.06693363587053258]}, "mutation_prompt": null}
{"id": "d899ba9e-a21e-42a7-aa4d-6dd28f4c0884", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.6  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced mutation strategy in DE step by increasing differential weight F for better exploration.", "configspace": "", "generation": 8, "fitness": 0.3282104894661493, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.27.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.8519741438328772, 0.8519741438328772, 0.8519741438328772, 0.8522232729402333, 0.8522232729402333, 0.8522232729402333, 0.8716537146579036, 0.8716537146579036, 0.8716537146579036, 0.5938755616911529, 0.5938755616911529, 0.5938755616911529, 0.6347477094250065, 0.6347477094250065, 0.6347477094250065, 0.645366152370004, 0.645366152370004, 0.645366152370004, 0.14805126111338973, 0.14805126111338973, 0.14805126111338973, 0.15561870599481753, 0.15561870599481753, 0.15561870599481753, 0.13749608685890158, 0.13749608685890158, 0.13749608685890158, 0.11101595148291943, 0.11101595148291943, 0.11101595148291943, 0.12560222304408541, 0.12560222304408541, 0.12560222304408541, 0.11768101500154848, 0.11768101500154848, 0.11768101500154848, 0.9737729386068896, 0.9737729386068896, 0.9737729386068896, 0.9717227899301932, 0.9717227899301932, 0.9717227899301932, 0.9699333372574342, 0.9699333372574342, 0.9699333372574342, 0.6012529666705773, 0.6012529666705773, 0.6012529666705773, 0.5598586336410543, 0.5598586336410543, 0.5598586336410543, 0.5737566673849597, 0.5737566673849597, 0.5737566673849597, 0.6652179915178237, 0.6652179915178237, 0.6652179915178237, 0.5625705490401767, 0.5625705490401767, 0.5625705490401767, 0.5206460660957841, 0.5206460660957841, 0.5206460660957841, 0.21096662586000747, 0.21096662586000747, 0.21096662586000747, 0.23234065337763754, 0.23234065337763754, 0.23234065337763754, 0.13055149276655553, 0.13055149276655553, 0.13055149276655553, 0.19126400964882262, 0.19126400964882262, 0.19126400964882262, 0.23178004281940578, 0.23178004281940578, 0.23178004281940578, 0.21634564122982314, 0.21634564122982314, 0.21634564122982314, 0.011018369516471838, 0.011018369516471838, 0.011018369516471838, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07628567475946402, 0.07628567475946402, 0.07628567475946402, 0.04577023734441277, 0.04577023734441277, 0.04577023734441277, 0.0463952273900341, 0.0463952273900341, 0.0463952273900341, 0.04684347765028796, 0.04684347765028796, 0.04684347765028796, 0.11524310858608311, 0.11524310858608311, 0.11524310858608311, 0.17443770576349094, 0.17443770576349094, 0.17443770576349094, 0.12848492670217415, 0.12848492670217415, 0.12848492670217415, 0.08627428670970572, 0.08627428670970572, 0.08627428670970572, 0.060632934957143725, 0.060632934957143725, 0.060632934957143725, 0.5160686659032837, 0.5160686659032837, 0.5160686659032837, 0.5258287042647534, 0.5258287042647534, 0.5258287042647534, 0.5633471549684006, 0.5633471549684006, 0.5633471549684006, 0.12184911571248935, 0.12184911571248935, 0.12184911571248935, 0.14717044565793058, 0.14717044565793058, 0.14717044565793058, 0.12536996722979765, 0.12536996722979765, 0.12536996722979765, 0.1718073317929033, 0.1718073317929033, 0.1718073317929033, 0.21566019484398258, 0.21566019484398258, 0.21566019484398258, 0.21234288628452025, 0.21234288628452025, 0.21234288628452025, 0.47998250600961745, 0.47998250600961745, 0.47998250600961745, 0.48990524234828947, 0.48990524234828947, 0.48990524234828947, 0.42902101305167084, 0.42902101305167084, 0.42902101305167084, 0.22753949459305767, 0.22753949459305767, 0.22753949459305767, 0.2224878010904915, 0.2224878010904915, 0.2224878010904915, 0.2051621466004533, 0.2051621466004533, 0.2051621466004533, 0.22176979125645158, 0.22176979125645158, 0.22176979125645158, 0.22277818914159164, 0.22277818914159164, 0.22277818914159164, 0.21244402777535054, 0.21244402777535054, 0.21244402777535054, 0.18887979639897912, 0.18887979639897912, 0.18887979639897912, 0.21524848010984088, 0.21524848010984088, 0.21524848010984088, 0.21184513350231637, 0.21184513350231637, 0.21184513350231637, 0.8630674223679039, 0.8630674223679039, 0.8630674223679039, 0.16350862170902414, 0.16350862170902414, 0.16350862170902414, 0.19475736807897792, 0.19475736807897792, 0.19475736807897792, 0.6361580249552758, 0.6361580249552758, 0.6361580249552758, 0.6375543428505228, 0.6375543428505228, 0.6375543428505228, 0.6769254155405378, 0.6769254155405378, 0.6769254155405378, 0.1868332209529151, 0.1868332209529151, 0.1868332209529151, 0.1851520338909204, 0.1851520338909204, 0.1851520338909204, 0.22205451632085693, 0.22205451632085693, 0.22205451632085693, 0.08860476967864361, 0.08860476967864361, 0.08860476967864361, 0.09027986585121761, 0.09027986585121761, 0.09027986585121761, 0.11087939719052498, 0.11087939719052498, 0.11087939719052498]}, "mutation_prompt": null}
{"id": "8c9b2f12-8ea6-46bc-a1f3-5178b8c5f588", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 3.0 - evaluations/self.budget * 1.5  # Further increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced exploitation by increasing cognitive coefficient further based on evaluation ratio.", "configspace": "", "generation": 9, "fitness": 0.28993247450904513, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.24.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.8131453162760713, 0.8131453162760713, 0.8131453162760713, 0.8053837142047615, 0.8053837142047615, 0.8053837142047615, 0.8551534128095577, 0.8551534128095577, 0.8551534128095577, 0.5415255725332933, 0.5415255725332933, 0.5415255725332933, 0.6008373789892774, 0.6008373789892774, 0.6008373789892774, 0.5437058797455752, 0.5437058797455752, 0.5437058797455752, 0.13457788603728116, 0.13457788603728116, 0.13457788603728116, 0.14877992013635122, 0.14877992013635122, 0.14877992013635122, 0.1323332405840718, 0.1323332405840718, 0.1323332405840718, 0.1506106572715158, 0.1506106572715158, 0.1506106572715158, 0.12466424870336945, 0.12466424870336945, 0.12466424870336945, 0.13088854065553657, 0.13088854065553657, 0.13088854065553657, 0.9734451408988667, 0.9734451408988667, 0.9734451408988667, 0.9716974780496069, 0.9716974780496069, 0.9716974780496069, 0.9715768505683203, 0.9715768505683203, 0.9715768505683203, 0.5014027180918458, 0.5014027180918458, 0.5014027180918458, 0.4407908074291973, 0.4407908074291973, 0.4407908074291973, 0.4655341226749887, 0.4655341226749887, 0.4655341226749887, 0.21039226398363087, 0.21039226398363087, 0.21039226398363087, 0.21090640661215598, 0.21090640661215598, 0.21090640661215598, 0.22626279512413083, 0.22626279512413083, 0.22626279512413083, 0.19481974154760906, 0.19481974154760906, 0.19481974154760906, 0.18218203455132775, 0.18218203455132775, 0.18218203455132775, 0.20315637074721926, 0.20315637074721926, 0.20315637074721926, 0.20643788108970584, 0.20643788108970584, 0.20643788108970584, 0.12982997876266267, 0.12982997876266267, 0.12982997876266267, 0.219644492175466, 0.219644492175466, 0.219644492175466, 0.012510680057762125, 0.012510680057762125, 0.012510680057762125, 0.029130910185198755, 0.029130910185198755, 0.029130910185198755, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12802457243438037, 0.12802457243438037, 0.12802457243438037, 0.08661675445665551, 0.08661675445665551, 0.08661675445665551, 0.07733440150927096, 0.07733440150927096, 0.07733440150927096, 0.22455312543089545, 0.22455312543089545, 0.22455312543089545, 0.07301609634371076, 0.07301609634371076, 0.07301609634371076, 0.259449108439314, 0.259449108439314, 0.259449108439314, 0.08721393141762857, 0.08721393141762857, 0.08721393141762857, 0.06293973886047222, 0.06293973886047222, 0.06293973886047222, 0.054990495256878824, 0.054990495256878824, 0.054990495256878824, 0.4873225341955294, 0.4873225341955294, 0.4873225341955294, 0.5412828149929511, 0.5412828149929511, 0.5412828149929511, 0.5900646557769056, 0.5900646557769056, 0.5900646557769056, 0.11565700711863669, 0.11565700711863669, 0.11565700711863669, 0.12823452535085855, 0.12823452535085855, 0.12823452535085855, 0.1355634784477665, 0.1355634784477665, 0.1355634784477665, 0.16288713720098946, 0.16288713720098946, 0.16288713720098946, 0.19103869847651367, 0.19103869847651367, 0.19103869847651367, 0.17982063897347578, 0.17982063897347578, 0.17982063897347578, 0.3676638331058316, 0.3676638331058316, 0.3676638331058316, 0.2287350964879703, 0.2287350964879703, 0.2287350964879703, 0.42048675171694816, 0.42048675171694816, 0.42048675171694816, 0.22772594922545863, 0.22772594922545863, 0.22772594922545863, 0.19619941945804198, 0.19619941945804198, 0.19619941945804198, 0.2345076362465729, 0.2345076362465729, 0.2345076362465729, 0.20869947420803214, 0.20869947420803214, 0.20869947420803214, 0.19905095184457255, 0.19905095184457255, 0.19905095184457255, 0.19372172899005669, 0.19372172899005669, 0.19372172899005669, 0.1955017967905428, 0.1955017967905428, 0.1955017967905428, 0.2169928894809795, 0.2169928894809795, 0.2169928894809795, 0.40808562851298014, 0.40808562851298014, 0.40808562851298014, 0.7958533301628847, 0.7958533301628847, 0.7958533301628847, 0.1631490159072304, 0.1631490159072304, 0.1631490159072304, 0.15466743191074261, 0.15466743191074261, 0.15466743191074261, 0.5375922581748063, 0.5375922581748063, 0.5375922581748063, 0.3811711199849622, 0.3811711199849622, 0.3811711199849622, 0.16557047498585775, 0.16557047498585775, 0.16557047498585775, 0.1874632779287333, 0.1874632779287333, 0.1874632779287333, 0.20346646591248685, 0.20346646591248685, 0.20346646591248685, 0.19143956647165428, 0.19143956647165428, 0.19143956647165428, 0.0928648095695862, 0.0928648095695862, 0.0928648095695862, 0.07990690960819224, 0.07990690960819224, 0.07990690960819224, 0.10718619278693331, 0.10718619278693331, 0.10718619278693331]}, "mutation_prompt": null}
{"id": "f5740c97-2cfd-4e52-9d7b-2acf0bf2c477", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                self.F = 0.1 + 0.9 * (1 - evaluations / self.budget)  # Adjust F over time\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhance global exploration by dynamically adjusting the differential evolution parameter F over time.", "configspace": "", "generation": 10, "fitness": 0.312865611094477, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.27.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.8524076144907007, 0.8524076144907007, 0.8524076144907007, 0.8489482263228144, 0.8489482263228144, 0.8489482263228144, 0.8491332782307222, 0.8491332782307222, 0.8491332782307222, 0.6708122444672329, 0.6708122444672329, 0.6708122444672329, 0.6543510233264312, 0.6543510233264312, 0.6543510233264312, 0.6602507027357549, 0.6602507027357549, 0.6602507027357549, 0.14759505895158798, 0.14759505895158798, 0.14759505895158798, 0.15806482122113175, 0.15806482122113175, 0.15806482122113175, 0.16042834677419415, 0.16042834677419415, 0.16042834677419415, 0.1380658340926828, 0.1380658340926828, 0.1380658340926828, 0.10273629309868959, 0.10273629309868959, 0.10273629309868959, 0.13434426953022538, 0.13434426953022538, 0.13434426953022538, 0.9794427570710449, 0.9794427570710449, 0.9794427570710449, 0.9735912897453545, 0.9735912897453545, 0.9735912897453545, 0.9730211756019589, 0.9730211756019589, 0.9730211756019589, 0.6217601255202814, 0.6217601255202814, 0.6217601255202814, 0.5484928685601982, 0.5484928685601982, 0.5484928685601982, 0.5944752279349507, 0.5944752279349507, 0.5944752279349507, 0.6349933775756352, 0.6349933775756352, 0.6349933775756352, 0.25842586717081395, 0.25842586717081395, 0.25842586717081395, 0.5632234966282874, 0.5632234966282874, 0.5632234966282874, 0.2079018154007245, 0.2079018154007245, 0.2079018154007245, 0.22329887804421655, 0.22329887804421655, 0.22329887804421655, 0.12958925228758578, 0.12958925228758578, 0.12958925228758578, 0.11070381019845477, 0.11070381019845477, 0.11070381019845477, 0.22645109580562128, 0.22645109580562128, 0.22645109580562128, 0.2276732088921758, 0.2276732088921758, 0.2276732088921758, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004308565261914699, 0.004308565261914699, 0.004308565261914699, 0.006989468328098547, 0.006989468328098547, 0.006989468328098547, 0.11186777457012809, 0.11186777457012809, 0.11186777457012809, 0.039671782448477244, 0.039671782448477244, 0.039671782448477244, 0.05901832432852283, 0.05901832432852283, 0.05901832432852283, 0.05649602468971482, 0.05649602468971482, 0.05649602468971482, 0.1134624035747338, 0.1134624035747338, 0.1134624035747338, 0.1832055028730667, 0.1832055028730667, 0.1832055028730667, 0.07712647611470524, 0.07712647611470524, 0.07712647611470524, 0.08960594337546335, 0.08960594337546335, 0.08960594337546335, 0.06360088565512156, 0.06360088565512156, 0.06360088565512156, 0.5388473126601454, 0.5388473126601454, 0.5388473126601454, 0.5362064299017155, 0.5362064299017155, 0.5362064299017155, 0.5740961011604957, 0.5740961011604957, 0.5740961011604957, 0.13707752777760074, 0.13707752777760074, 0.13707752777760074, 0.13748486546656857, 0.13748486546656857, 0.13748486546656857, 0.10846810056758804, 0.10846810056758804, 0.10846810056758804, 0.15140982482628917, 0.15140982482628917, 0.15140982482628917, 0.24343184432408393, 0.24343184432408393, 0.24343184432408393, 0.14892713259939105, 0.14892713259939105, 0.14892713259939105, 0.4114366575251953, 0.4114366575251953, 0.4114366575251953, 0.3320934545534163, 0.3320934545534163, 0.3320934545534163, 0.4870396751435988, 0.4870396751435988, 0.4870396751435988, 0.22412693453335464, 0.22412693453335464, 0.22412693453335464, 0.2206138867801516, 0.2206138867801516, 0.2206138867801516, 0.2163107230112945, 0.2163107230112945, 0.2163107230112945, 0.21594457284542623, 0.21594457284542623, 0.21594457284542623, 0.2352967910899757, 0.2352967910899757, 0.2352967910899757, 0.20366524237289418, 0.20366524237289418, 0.20366524237289418, 0.18871308929665576, 0.18871308929665576, 0.18871308929665576, 0.20339283252290652, 0.20339283252290652, 0.20339283252290652, 0.23439922740349517, 0.23439922740349517, 0.23439922740349517, 0.8134697239686464, 0.8134697239686464, 0.8134697239686464, 0.1649073540646827, 0.1649073540646827, 0.1649073540646827, 0.7710667731375169, 0.7710667731375169, 0.7710667731375169, 0.32754425595492476, 0.32754425595492476, 0.32754425595492476, 0.2103039175954281, 0.2103039175954281, 0.2103039175954281, 0.2026421967453349, 0.2026421967453349, 0.2026421967453349, 0.21059107417401124, 0.21059107417401124, 0.21059107417401124, 0.18418765683229976, 0.18418765683229976, 0.18418765683229976, 0.1856166611558725, 0.1856166611558725, 0.1856166611558725, 0.08035742376716881, 0.08035742376716881, 0.08035742376716881, 0.08573068723117683, 0.08573068723117683, 0.08573068723117683, 0.08528893691361994, 0.08528893691361994, 0.08528893691361994]}, "mutation_prompt": null}
{"id": "d25c097b-76d0-45a5-9d89-94aef871f299", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Initial inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.w = 0.9 - (0.5 * evaluations / self.budget)  # Adaptive inertia weight\n                self.c1 = 2.7 - evaluations/self.budget * 1.5\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Introduce adaptive inertia weight in PSO to enhance exploration and exploitation balance.", "configspace": "", "generation": 11, "fitness": 0.20577492177781914, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.44758853118755115, 0.44758853118755115, 0.44758853118755115, 0.5466156977500924, 0.5466156977500924, 0.5466156977500924, 0.4807008716687816, 0.4807008716687816, 0.4807008716687816, 0.12366888526057884, 0.12366888526057884, 0.12366888526057884, 0.17767300616067727, 0.17767300616067727, 0.17767300616067727, 0.2065798473130781, 0.2065798473130781, 0.2065798473130781, 0.0988579180126189, 0.0988579180126189, 0.0988579180126189, 0.1081361840076337, 0.1081361840076337, 0.1081361840076337, 0.09963585736028491, 0.09963585736028491, 0.09963585736028491, 0.08109380353766449, 0.08109380353766449, 0.08109380353766449, 0.08519866607291138, 0.08519866607291138, 0.08519866607291138, 0.09163140126409886, 0.09163140126409886, 0.09163140126409886, 0.975651045096156, 0.975651045096156, 0.975651045096156, 0.9790362992505957, 0.9790362992505957, 0.9790362992505957, 0.9736668129840342, 0.9736668129840342, 0.9736668129840342, 0.2913679120706736, 0.2913679120706736, 0.2913679120706736, 0.2549019415282592, 0.2549019415282592, 0.2549019415282592, 0.2595875451798102, 0.2595875451798102, 0.2595875451798102, 0.24975608698443053, 0.24975608698443053, 0.24975608698443053, 0.16938114229449852, 0.16938114229449852, 0.16938114229449852, 0.16184508959737798, 0.16184508959737798, 0.16184508959737798, 0.09441635482944422, 0.09441635482944422, 0.09441635482944422, 0.19078210425831343, 0.19078210425831343, 0.19078210425831343, 0.19028496913239568, 0.19028496913239568, 0.19028496913239568, 0.042746067586211356, 0.042746067586211356, 0.042746067586211356, 0.11527350072230225, 0.11527350072230225, 0.11527350072230225, 0.12431717607551385, 0.12431717607551385, 0.12431717607551385, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0787400252107916, 0.0787400252107916, 0.0787400252107916, 0.06907151679223622, 0.06907151679223622, 0.06907151679223622, 0.06435206586822972, 0.06435206586822972, 0.06435206586822972, 0.017864077197967676, 0.017864077197967676, 0.017864077197967676, 0.06176875968303708, 0.06176875968303708, 0.06176875968303708, 0.03499618171061425, 0.03499618171061425, 0.03499618171061425, 0.0370664250550683, 0.0370664250550683, 0.0370664250550683, 0.0891172103226352, 0.0891172103226352, 0.0891172103226352, 0.03892962365755337, 0.03892962365755337, 0.03892962365755337, 0.3835547593022345, 0.3835547593022345, 0.3835547593022345, 0.39393277978697494, 0.39393277978697494, 0.39393277978697494, 0.3793510952057222, 0.3793510952057222, 0.3793510952057222, 0.08424628248284693, 0.08424628248284693, 0.08424628248284693, 0.09840668691393673, 0.09840668691393673, 0.09840668691393673, 0.10339739159368966, 0.10339739159368966, 0.10339739159368966, 0.17211817624461512, 0.17211817624461512, 0.17211817624461512, 0.1863635839168436, 0.1863635839168436, 0.1863635839168436, 0.15120320850345137, 0.15120320850345137, 0.15120320850345137, 0.28121285095416215, 0.28121285095416215, 0.28121285095416215, 0.26219718151078497, 0.26219718151078497, 0.26219718151078497, 0.2653662357826615, 0.2653662357826615, 0.2653662357826615, 0.18477563388248686, 0.18477563388248686, 0.18477563388248686, 0.20250773159947, 0.20250773159947, 0.20250773159947, 0.1756798866194491, 0.1756798866194491, 0.1756798866194491, 0.17662582065245247, 0.17662582065245247, 0.17662582065245247, 0.1802211752050622, 0.1802211752050622, 0.1802211752050622, 0.1862266468019117, 0.1862266468019117, 0.1862266468019117, 0.18178382476566035, 0.18178382476566035, 0.18178382476566035, 0.1887550617696726, 0.1887550617696726, 0.1887550617696726, 0.20987439864355828, 0.20987439864355828, 0.20987439864355828, 0.5613909862669498, 0.5613909862669498, 0.5613909862669498, 0.1511788111992819, 0.1511788111992819, 0.1511788111992819, 0.1791580623678275, 0.1791580623678275, 0.1791580623678275, 0.19193715196545014, 0.19193715196545014, 0.19193715196545014, 0.19660007486030728, 0.19660007486030728, 0.19660007486030728, 0.1857322973189689, 0.1857322973189689, 0.1857322973189689, 0.195319602465868, 0.195319602465868, 0.195319602465868, 0.19033097172020963, 0.19033097172020963, 0.19033097172020963, 0.1756322862540154, 0.1756322862540154, 0.1756322862540154, 0.0709170233676294, 0.0709170233676294, 0.0709170233676294, 0.07582857042875879, 0.07582857042875879, 0.07582857042875879, 0.08136751496594352, 0.08136751496594352, 0.08136751496594352]}, "mutation_prompt": null}
{"id": "34afd0cd-aae8-412f-88e4-826217888943", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.6  # Inertia weight for PSO (increased from 0.5)\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced exploration by slightly increasing the inertia weight in PSO.", "configspace": "", "generation": 12, "fitness": 0.2797633581038645, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.23.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.7749319254847502, 0.7749319254847502, 0.7749319254847502, 0.7587484578443413, 0.7587484578443413, 0.7587484578443413, 0.7978635231988749, 0.7978635231988749, 0.7978635231988749, 0.4439637678128827, 0.4439637678128827, 0.4439637678128827, 0.4445003520696983, 0.4445003520696983, 0.4445003520696983, 0.2942508039327506, 0.2942508039327506, 0.2942508039327506, 0.13014604240515093, 0.13014604240515093, 0.13014604240515093, 0.1497182183100938, 0.1497182183100938, 0.1497182183100938, 0.13663223051302198, 0.13663223051302198, 0.13663223051302198, 0.13186116070199716, 0.13186116070199716, 0.13186116070199716, 0.09731148283043822, 0.09731148283043822, 0.09731148283043822, 0.11394990384542703, 0.11394990384542703, 0.11394990384542703, 0.9734237863293943, 0.9734237863293943, 0.9734237863293943, 0.9739704831338388, 0.9739704831338388, 0.9739704831338388, 0.9702329832334816, 0.9702329832334816, 0.9702329832334816, 0.44156411476993496, 0.44156411476993496, 0.44156411476993496, 0.4107148703423873, 0.4107148703423873, 0.4107148703423873, 0.4671670964483595, 0.4671670964483595, 0.4671670964483595, 0.5370005212694076, 0.5370005212694076, 0.5370005212694076, 0.21193338043049492, 0.21193338043049492, 0.21193338043049492, 0.2294670974525964, 0.2294670974525964, 0.2294670974525964, 0.1788270761033829, 0.1788270761033829, 0.1788270761033829, 0.186727006497306, 0.186727006497306, 0.186727006497306, 0.17891800136124925, 0.17891800136124925, 0.17891800136124925, 0.189526929226139, 0.189526929226139, 0.189526929226139, 0.19433655004047012, 0.19433655004047012, 0.19433655004047012, 0.21524852184964094, 0.21524852184964094, 0.21524852184964094, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006557029308984941, 0.006557029308984941, 0.006557029308984941, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08742355152447412, 0.08742355152447412, 0.08742355152447412, 0.05324146281287723, 0.05324146281287723, 0.05324146281287723, 0.0545836430851625, 0.0545836430851625, 0.0545836430851625, 0.1395688402667321, 0.1395688402667321, 0.1395688402667321, 0.06693852141994228, 0.06693852141994228, 0.06693852141994228, 0.22134018702291092, 0.22134018702291092, 0.22134018702291092, 0.16964127007509866, 0.16964127007509866, 0.16964127007509866, 0.10854765984722703, 0.10854765984722703, 0.10854765984722703, 0.056063385569116164, 0.056063385569116164, 0.056063385569116164, 0.5065431708667353, 0.5065431708667353, 0.5065431708667353, 0.4937063131907611, 0.4937063131907611, 0.4937063131907611, 0.5123426762216357, 0.5123426762216357, 0.5123426762216357, 0.1606868198784447, 0.1606868198784447, 0.1606868198784447, 0.13735228368598096, 0.13735228368598096, 0.13735228368598096, 0.1117564102585793, 0.1117564102585793, 0.1117564102585793, 0.23130743993398406, 0.23130743993398406, 0.23130743993398406, 0.18278489640456408, 0.18278489640456408, 0.18278489640456408, 0.3655003287552415, 0.3655003287552415, 0.3655003287552415, 0.3347281897822797, 0.3347281897822797, 0.3347281897822797, 0.3609055168021359, 0.3609055168021359, 0.3609055168021359, 0.4097281005190886, 0.4097281005190886, 0.4097281005190886, 0.29198801442616706, 0.29198801442616706, 0.29198801442616706, 0.22406921661621526, 0.22406921661621526, 0.22406921661621526, 0.20054824237285573, 0.20054824237285573, 0.20054824237285573, 0.18604405838175953, 0.18604405838175953, 0.18604405838175953, 0.21032800172109323, 0.21032800172109323, 0.21032800172109323, 0.19941601620425142, 0.19941601620425142, 0.19941601620425142, 0.18669218143741628, 0.18669218143741628, 0.18669218143741628, 0.23359481647632352, 0.23359481647632352, 0.23359481647632352, 0.3858506879691199, 0.3858506879691199, 0.3858506879691199, 0.8596568202874606, 0.8596568202874606, 0.8596568202874606, 0.16336119700933072, 0.16336119700933072, 0.16336119700933072, 0.16080004086557476, 0.16080004086557476, 0.16080004086557476, 0.16674224910528046, 0.16674224910528046, 0.16674224910528046, 0.20539043656553735, 0.20539043656553735, 0.20539043656553735, 0.19388040372637227, 0.19388040372637227, 0.19388040372637227, 0.18939349308545184, 0.18939349308545184, 0.18939349308545184, 0.20059231881802364, 0.20059231881802364, 0.20059231881802364, 0.19243905393939909, 0.19243905393939909, 0.19243905393939909, 0.0781173685526273, 0.0781173685526273, 0.0781173685526273, 0.07776410995802474, 0.07776410995802474, 0.07776410995802474, 0.13190907129049245, 0.13190907129049245, 0.13190907129049245]}, "mutation_prompt": null}
{"id": "7fda4a3e-24aa-4389-ad1c-cf480a4212e2", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.6  # Adjusted inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Slightly adjusted the inertia weight w in the PSO step to enhance exploration and exploitation balance.", "configspace": "", "generation": 13, "fitness": 0.2797633581038645, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.23.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.7749319254847502, 0.7749319254847502, 0.7749319254847502, 0.7587484578443413, 0.7587484578443413, 0.7587484578443413, 0.7978635231988749, 0.7978635231988749, 0.7978635231988749, 0.4439637678128827, 0.4439637678128827, 0.4439637678128827, 0.4445003520696983, 0.4445003520696983, 0.4445003520696983, 0.2942508039327506, 0.2942508039327506, 0.2942508039327506, 0.13014604240515093, 0.13014604240515093, 0.13014604240515093, 0.1497182183100938, 0.1497182183100938, 0.1497182183100938, 0.13663223051302198, 0.13663223051302198, 0.13663223051302198, 0.13186116070199716, 0.13186116070199716, 0.13186116070199716, 0.09731148283043822, 0.09731148283043822, 0.09731148283043822, 0.11394990384542703, 0.11394990384542703, 0.11394990384542703, 0.9734237863293943, 0.9734237863293943, 0.9734237863293943, 0.9739704831338388, 0.9739704831338388, 0.9739704831338388, 0.9702329832334816, 0.9702329832334816, 0.9702329832334816, 0.44156411476993496, 0.44156411476993496, 0.44156411476993496, 0.4107148703423873, 0.4107148703423873, 0.4107148703423873, 0.4671670964483595, 0.4671670964483595, 0.4671670964483595, 0.5370005212694076, 0.5370005212694076, 0.5370005212694076, 0.21193338043049492, 0.21193338043049492, 0.21193338043049492, 0.2294670974525964, 0.2294670974525964, 0.2294670974525964, 0.1788270761033829, 0.1788270761033829, 0.1788270761033829, 0.186727006497306, 0.186727006497306, 0.186727006497306, 0.17891800136124925, 0.17891800136124925, 0.17891800136124925, 0.189526929226139, 0.189526929226139, 0.189526929226139, 0.19433655004047012, 0.19433655004047012, 0.19433655004047012, 0.21524852184964094, 0.21524852184964094, 0.21524852184964094, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006557029308984941, 0.006557029308984941, 0.006557029308984941, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08742355152447412, 0.08742355152447412, 0.08742355152447412, 0.05324146281287723, 0.05324146281287723, 0.05324146281287723, 0.0545836430851625, 0.0545836430851625, 0.0545836430851625, 0.1395688402667321, 0.1395688402667321, 0.1395688402667321, 0.06693852141994228, 0.06693852141994228, 0.06693852141994228, 0.22134018702291092, 0.22134018702291092, 0.22134018702291092, 0.16964127007509866, 0.16964127007509866, 0.16964127007509866, 0.10854765984722703, 0.10854765984722703, 0.10854765984722703, 0.056063385569116164, 0.056063385569116164, 0.056063385569116164, 0.5065431708667353, 0.5065431708667353, 0.5065431708667353, 0.4937063131907611, 0.4937063131907611, 0.4937063131907611, 0.5123426762216357, 0.5123426762216357, 0.5123426762216357, 0.1606868198784447, 0.1606868198784447, 0.1606868198784447, 0.13735228368598096, 0.13735228368598096, 0.13735228368598096, 0.1117564102585793, 0.1117564102585793, 0.1117564102585793, 0.23130743993398406, 0.23130743993398406, 0.23130743993398406, 0.18278489640456408, 0.18278489640456408, 0.18278489640456408, 0.3655003287552415, 0.3655003287552415, 0.3655003287552415, 0.3347281897822797, 0.3347281897822797, 0.3347281897822797, 0.3609055168021359, 0.3609055168021359, 0.3609055168021359, 0.4097281005190886, 0.4097281005190886, 0.4097281005190886, 0.29198801442616706, 0.29198801442616706, 0.29198801442616706, 0.22406921661621526, 0.22406921661621526, 0.22406921661621526, 0.20054824237285573, 0.20054824237285573, 0.20054824237285573, 0.18604405838175953, 0.18604405838175953, 0.18604405838175953, 0.21032800172109323, 0.21032800172109323, 0.21032800172109323, 0.19941601620425142, 0.19941601620425142, 0.19941601620425142, 0.18669218143741628, 0.18669218143741628, 0.18669218143741628, 0.23359481647632352, 0.23359481647632352, 0.23359481647632352, 0.3858506879691199, 0.3858506879691199, 0.3858506879691199, 0.8596568202874606, 0.8596568202874606, 0.8596568202874606, 0.16336119700933072, 0.16336119700933072, 0.16336119700933072, 0.16080004086557476, 0.16080004086557476, 0.16080004086557476, 0.16674224910528046, 0.16674224910528046, 0.16674224910528046, 0.20539043656553735, 0.20539043656553735, 0.20539043656553735, 0.19388040372637227, 0.19388040372637227, 0.19388040372637227, 0.18939349308545184, 0.18939349308545184, 0.18939349308545184, 0.20059231881802364, 0.20059231881802364, 0.20059231881802364, 0.19243905393939909, 0.19243905393939909, 0.19243905393939909, 0.0781173685526273, 0.0781173685526273, 0.0781173685526273, 0.07776410995802474, 0.07776410995802474, 0.07776410995802474, 0.13190907129049245, 0.13190907129049245, 0.13190907129049245]}, "mutation_prompt": null}
{"id": "11559382-167e-478f-a812-f28100e2b69e", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.6  # Increased inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Improved exploration by slightly increasing the influence of the inertia weight in PSO.", "configspace": "", "generation": 14, "fitness": 0.2797633581038645, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.23.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.7749319254847502, 0.7749319254847502, 0.7749319254847502, 0.7587484578443413, 0.7587484578443413, 0.7587484578443413, 0.7978635231988749, 0.7978635231988749, 0.7978635231988749, 0.4439637678128827, 0.4439637678128827, 0.4439637678128827, 0.4445003520696983, 0.4445003520696983, 0.4445003520696983, 0.2942508039327506, 0.2942508039327506, 0.2942508039327506, 0.13014604240515093, 0.13014604240515093, 0.13014604240515093, 0.1497182183100938, 0.1497182183100938, 0.1497182183100938, 0.13663223051302198, 0.13663223051302198, 0.13663223051302198, 0.13186116070199716, 0.13186116070199716, 0.13186116070199716, 0.09731148283043822, 0.09731148283043822, 0.09731148283043822, 0.11394990384542703, 0.11394990384542703, 0.11394990384542703, 0.9734237863293943, 0.9734237863293943, 0.9734237863293943, 0.9739704831338388, 0.9739704831338388, 0.9739704831338388, 0.9702329832334816, 0.9702329832334816, 0.9702329832334816, 0.44156411476993496, 0.44156411476993496, 0.44156411476993496, 0.4107148703423873, 0.4107148703423873, 0.4107148703423873, 0.4671670964483595, 0.4671670964483595, 0.4671670964483595, 0.5370005212694076, 0.5370005212694076, 0.5370005212694076, 0.21193338043049492, 0.21193338043049492, 0.21193338043049492, 0.2294670974525964, 0.2294670974525964, 0.2294670974525964, 0.1788270761033829, 0.1788270761033829, 0.1788270761033829, 0.186727006497306, 0.186727006497306, 0.186727006497306, 0.17891800136124925, 0.17891800136124925, 0.17891800136124925, 0.189526929226139, 0.189526929226139, 0.189526929226139, 0.19433655004047012, 0.19433655004047012, 0.19433655004047012, 0.21524852184964094, 0.21524852184964094, 0.21524852184964094, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006557029308984941, 0.006557029308984941, 0.006557029308984941, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08742355152447412, 0.08742355152447412, 0.08742355152447412, 0.05324146281287723, 0.05324146281287723, 0.05324146281287723, 0.0545836430851625, 0.0545836430851625, 0.0545836430851625, 0.1395688402667321, 0.1395688402667321, 0.1395688402667321, 0.06693852141994228, 0.06693852141994228, 0.06693852141994228, 0.22134018702291092, 0.22134018702291092, 0.22134018702291092, 0.16964127007509866, 0.16964127007509866, 0.16964127007509866, 0.10854765984722703, 0.10854765984722703, 0.10854765984722703, 0.056063385569116164, 0.056063385569116164, 0.056063385569116164, 0.5065431708667353, 0.5065431708667353, 0.5065431708667353, 0.4937063131907611, 0.4937063131907611, 0.4937063131907611, 0.5123426762216357, 0.5123426762216357, 0.5123426762216357, 0.1606868198784447, 0.1606868198784447, 0.1606868198784447, 0.13735228368598096, 0.13735228368598096, 0.13735228368598096, 0.1117564102585793, 0.1117564102585793, 0.1117564102585793, 0.23130743993398406, 0.23130743993398406, 0.23130743993398406, 0.18278489640456408, 0.18278489640456408, 0.18278489640456408, 0.3655003287552415, 0.3655003287552415, 0.3655003287552415, 0.3347281897822797, 0.3347281897822797, 0.3347281897822797, 0.3609055168021359, 0.3609055168021359, 0.3609055168021359, 0.4097281005190886, 0.4097281005190886, 0.4097281005190886, 0.29198801442616706, 0.29198801442616706, 0.29198801442616706, 0.22406921661621526, 0.22406921661621526, 0.22406921661621526, 0.20054824237285573, 0.20054824237285573, 0.20054824237285573, 0.18604405838175953, 0.18604405838175953, 0.18604405838175953, 0.21032800172109323, 0.21032800172109323, 0.21032800172109323, 0.19941601620425142, 0.19941601620425142, 0.19941601620425142, 0.18669218143741628, 0.18669218143741628, 0.18669218143741628, 0.23359481647632352, 0.23359481647632352, 0.23359481647632352, 0.3858506879691199, 0.3858506879691199, 0.3858506879691199, 0.8596568202874606, 0.8596568202874606, 0.8596568202874606, 0.16336119700933072, 0.16336119700933072, 0.16336119700933072, 0.16080004086557476, 0.16080004086557476, 0.16080004086557476, 0.16674224910528046, 0.16674224910528046, 0.16674224910528046, 0.20539043656553735, 0.20539043656553735, 0.20539043656553735, 0.19388040372637227, 0.19388040372637227, 0.19388040372637227, 0.18939349308545184, 0.18939349308545184, 0.18939349308545184, 0.20059231881802364, 0.20059231881802364, 0.20059231881802364, 0.19243905393939909, 0.19243905393939909, 0.19243905393939909, 0.0781173685526273, 0.0781173685526273, 0.0781173685526273, 0.07776410995802474, 0.07776410995802474, 0.07776410995802474, 0.13190907129049245, 0.13190907129049245, 0.13190907129049245]}, "mutation_prompt": null}
{"id": "0dd45bbb-ecda-4a69-8d34-666e31a05c44", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                self.w = 0.5 + 0.2 * np.sin(2 * np.pi * evaluations / self.budget)  # Adjusted inertia weight\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Fine-tuned Particle Swarm Optimization (PSO) inertia weight for better exploration-exploitation balance.", "configspace": "", "generation": 15, "fitness": 0.28456168867892495, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.24.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.7497012650031744, 0.7497012650031744, 0.7497012650031744, 0.7283932398417229, 0.7283932398417229, 0.7283932398417229, 0.7523492754248952, 0.7523492754248952, 0.7523492754248952, 0.43029118224242513, 0.43029118224242513, 0.43029118224242513, 0.5042868184051542, 0.5042868184051542, 0.5042868184051542, 0.46471729357059244, 0.46471729357059244, 0.46471729357059244, 0.15096443233650825, 0.15096443233650825, 0.15096443233650825, 0.12309440878074074, 0.12309440878074074, 0.12309440878074074, 0.1160556224217607, 0.1160556224217607, 0.1160556224217607, 0.15245017070114975, 0.15245017070114975, 0.15245017070114975, 0.11891378193326907, 0.11891378193326907, 0.11891378193326907, 0.11072599708609487, 0.11072599708609487, 0.11072599708609487, 0.9734726971169028, 0.9734726971169028, 0.9734726971169028, 0.9738718464389337, 0.9738718464389337, 0.9738718464389337, 0.9698759153944417, 0.9698759153944417, 0.9698759153944417, 0.5463230798856727, 0.5463230798856727, 0.5463230798856727, 0.5366735578706152, 0.5366735578706152, 0.5366735578706152, 0.49044836733662045, 0.49044836733662045, 0.49044836733662045, 0.6023328017351757, 0.6023328017351757, 0.6023328017351757, 0.20074429869963129, 0.20074429869963129, 0.20074429869963129, 0.7430616302720884, 0.7430616302720884, 0.7430616302720884, 0.17924270880158277, 0.17924270880158277, 0.17924270880158277, 0.1838427781240285, 0.1838427781240285, 0.1838427781240285, 0.18815523478687335, 0.18815523478687335, 0.18815523478687335, 0.20626694575296267, 0.20626694575296267, 0.20626694575296267, 0.1290444994122909, 0.1290444994122909, 0.1290444994122909, 0.12769349765958182, 0.12769349765958182, 0.12769349765958182, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0021045899963095804, 0.0021045899963095804, 0.0021045899963095804, 0.14872671552623873, 0.14872671552623873, 0.14872671552623873, 0.0683538484946401, 0.0683538484946401, 0.0683538484946401, 0.0740135057310437, 0.0740135057310437, 0.0740135057310437, 0.13095631199443103, 0.13095631199443103, 0.13095631199443103, 0.12007007225470356, 0.12007007225470356, 0.12007007225470356, 0.16558215646241115, 0.16558215646241115, 0.16558215646241115, 0.16260746937504478, 0.16260746937504478, 0.16260746937504478, 0.1391702488031733, 0.1391702488031733, 0.1391702488031733, 0.04755882794536104, 0.04755882794536104, 0.04755882794536104, 0.49306095469622135, 0.49306095469622135, 0.49306095469622135, 0.490248814376425, 0.490248814376425, 0.490248814376425, 0.49900183952655996, 0.49900183952655996, 0.49900183952655996, 0.11416644834566236, 0.11416644834566236, 0.11416644834566236, 0.11836753933724142, 0.11836753933724142, 0.11836753933724142, 0.10908891182091107, 0.10908891182091107, 0.10908891182091107, 0.20292606263011947, 0.20292606263011947, 0.20292606263011947, 0.173360469981526, 0.173360469981526, 0.173360469981526, 0.176646405989224, 0.176646405989224, 0.176646405989224, 0.36898256728914736, 0.36898256728914736, 0.36898256728914736, 0.34685096814035943, 0.34685096814035943, 0.34685096814035943, 0.35941940881255396, 0.35941940881255396, 0.35941940881255396, 0.2693464581401669, 0.2693464581401669, 0.2693464581401669, 0.17522193015956256, 0.17522193015956256, 0.17522193015956256, 0.21089544962937223, 0.21089544962937223, 0.21089544962937223, 0.2285683877116469, 0.2285683877116469, 0.2285683877116469, 0.22201201472519183, 0.22201201472519183, 0.22201201472519183, 0.23105916959423345, 0.23105916959423345, 0.23105916959423345, 0.20050086535092848, 0.20050086535092848, 0.20050086535092848, 0.22108310587429159, 0.22108310587429159, 0.22108310587429159, 0.20877641671996405, 0.20877641671996405, 0.20877641671996405, 0.7637875275390694, 0.7637875275390694, 0.7637875275390694, 0.1636582910230825, 0.1636582910230825, 0.1636582910230825, 0.19006279507601098, 0.19006279507601098, 0.19006279507601098, 0.1680037615559451, 0.1680037615559451, 0.1680037615559451, 0.20770930367636475, 0.20770930367636475, 0.20770930367636475, 0.20666673719663986, 0.20666673719663986, 0.20666673719663986, 0.1797972519000095, 0.1797972519000095, 0.1797972519000095, 0.18357608060967356, 0.18357608060967356, 0.18357608060967356, 0.20504077357103256, 0.20504077357103256, 0.20504077357103256, 0.08864400597525579, 0.08864400597525579, 0.08864400597525579, 0.08607704812903871, 0.08607704812903871, 0.08607704812903871, 0.11349672616091944, 0.11349672616091944, 0.11349672616091944]}, "mutation_prompt": null}
{"id": "16e2b64a-8231-4e52-a06a-add29fee9235", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.6  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced global exploration by increasing the differential weight F slightly in Differential Evolution.", "configspace": "", "generation": 16, "fitness": 0.3282104894661493, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.27.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.8519741438328772, 0.8519741438328772, 0.8519741438328772, 0.8522232729402333, 0.8522232729402333, 0.8522232729402333, 0.8716537146579036, 0.8716537146579036, 0.8716537146579036, 0.5938755616911529, 0.5938755616911529, 0.5938755616911529, 0.6347477094250065, 0.6347477094250065, 0.6347477094250065, 0.645366152370004, 0.645366152370004, 0.645366152370004, 0.14805126111338973, 0.14805126111338973, 0.14805126111338973, 0.15561870599481753, 0.15561870599481753, 0.15561870599481753, 0.13749608685890158, 0.13749608685890158, 0.13749608685890158, 0.11101595148291943, 0.11101595148291943, 0.11101595148291943, 0.12560222304408541, 0.12560222304408541, 0.12560222304408541, 0.11768101500154848, 0.11768101500154848, 0.11768101500154848, 0.9737729386068896, 0.9737729386068896, 0.9737729386068896, 0.9717227899301932, 0.9717227899301932, 0.9717227899301932, 0.9699333372574342, 0.9699333372574342, 0.9699333372574342, 0.6012529666705773, 0.6012529666705773, 0.6012529666705773, 0.5598586336410543, 0.5598586336410543, 0.5598586336410543, 0.5737566673849597, 0.5737566673849597, 0.5737566673849597, 0.6652179915178237, 0.6652179915178237, 0.6652179915178237, 0.5625705490401767, 0.5625705490401767, 0.5625705490401767, 0.5206460660957841, 0.5206460660957841, 0.5206460660957841, 0.21096662586000747, 0.21096662586000747, 0.21096662586000747, 0.23234065337763754, 0.23234065337763754, 0.23234065337763754, 0.13055149276655553, 0.13055149276655553, 0.13055149276655553, 0.19126400964882262, 0.19126400964882262, 0.19126400964882262, 0.23178004281940578, 0.23178004281940578, 0.23178004281940578, 0.21634564122982314, 0.21634564122982314, 0.21634564122982314, 0.011018369516471838, 0.011018369516471838, 0.011018369516471838, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07628567475946402, 0.07628567475946402, 0.07628567475946402, 0.04577023734441277, 0.04577023734441277, 0.04577023734441277, 0.0463952273900341, 0.0463952273900341, 0.0463952273900341, 0.04684347765028796, 0.04684347765028796, 0.04684347765028796, 0.11524310858608311, 0.11524310858608311, 0.11524310858608311, 0.17443770576349094, 0.17443770576349094, 0.17443770576349094, 0.12848492670217415, 0.12848492670217415, 0.12848492670217415, 0.08627428670970572, 0.08627428670970572, 0.08627428670970572, 0.060632934957143725, 0.060632934957143725, 0.060632934957143725, 0.5160686659032837, 0.5160686659032837, 0.5160686659032837, 0.5258287042647534, 0.5258287042647534, 0.5258287042647534, 0.5633471549684006, 0.5633471549684006, 0.5633471549684006, 0.12184911571248935, 0.12184911571248935, 0.12184911571248935, 0.14717044565793058, 0.14717044565793058, 0.14717044565793058, 0.12536996722979765, 0.12536996722979765, 0.12536996722979765, 0.1718073317929033, 0.1718073317929033, 0.1718073317929033, 0.21566019484398258, 0.21566019484398258, 0.21566019484398258, 0.21234288628452025, 0.21234288628452025, 0.21234288628452025, 0.47998250600961745, 0.47998250600961745, 0.47998250600961745, 0.48990524234828947, 0.48990524234828947, 0.48990524234828947, 0.42902101305167084, 0.42902101305167084, 0.42902101305167084, 0.22753949459305767, 0.22753949459305767, 0.22753949459305767, 0.2224878010904915, 0.2224878010904915, 0.2224878010904915, 0.2051621466004533, 0.2051621466004533, 0.2051621466004533, 0.22176979125645158, 0.22176979125645158, 0.22176979125645158, 0.22277818914159164, 0.22277818914159164, 0.22277818914159164, 0.21244402777535054, 0.21244402777535054, 0.21244402777535054, 0.18887979639897912, 0.18887979639897912, 0.18887979639897912, 0.21524848010984088, 0.21524848010984088, 0.21524848010984088, 0.21184513350231637, 0.21184513350231637, 0.21184513350231637, 0.8630674223679039, 0.8630674223679039, 0.8630674223679039, 0.16350862170902414, 0.16350862170902414, 0.16350862170902414, 0.19475736807897792, 0.19475736807897792, 0.19475736807897792, 0.6361580249552758, 0.6361580249552758, 0.6361580249552758, 0.6375543428505228, 0.6375543428505228, 0.6375543428505228, 0.6769254155405378, 0.6769254155405378, 0.6769254155405378, 0.1868332209529151, 0.1868332209529151, 0.1868332209529151, 0.1851520338909204, 0.1851520338909204, 0.1851520338909204, 0.22205451632085693, 0.22205451632085693, 0.22205451632085693, 0.08860476967864361, 0.08860476967864361, 0.08860476967864361, 0.09027986585121761, 0.09027986585121761, 0.09027986585121761, 0.11087939719052498, 0.11087939719052498, 0.11087939719052498]}, "mutation_prompt": null}
{"id": "53b7bd0e-601a-4565-a3dd-a1b532b5f7a3", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                self.F = 0.5 + 0.5 * np.sin((evaluations/self.budget) * np.pi)  # Adjust F with a sine function\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced exploration by dynamically adjusting the Differential Evolution parameter F.", "configspace": "", "generation": 17, "fitness": 0.31410631917950316, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.27.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.8459357787280527, 0.8459357787280527, 0.8459357787280527, 0.8314427833370026, 0.8314427833370026, 0.8314427833370026, 0.8568831137293778, 0.8568831137293778, 0.8568831137293778, 0.6164197636955308, 0.6164197636955308, 0.6164197636955308, 0.6706242146313687, 0.6706242146313687, 0.6706242146313687, 0.6231837146823567, 0.6231837146823567, 0.6231837146823567, 0.14016418380949758, 0.14016418380949758, 0.14016418380949758, 0.12580541031998527, 0.12580541031998527, 0.12580541031998527, 0.15525751389639697, 0.15525751389639697, 0.15525751389639697, 0.12563917403356117, 0.12563917403356117, 0.12563917403356117, 0.11370592044366368, 0.11370592044366368, 0.11370592044366368, 0.10825989359619848, 0.10825989359619848, 0.10825989359619848, 0.9734212600238856, 0.9734212600238856, 0.9734212600238856, 0.9738471676696788, 0.9738471676696788, 0.9738471676696788, 0.9697903212425925, 0.9697903212425925, 0.9697903212425925, 0.5639931384124546, 0.5639931384124546, 0.5639931384124546, 0.5635839191182433, 0.5635839191182433, 0.5635839191182433, 0.5705909716375487, 0.5705909716375487, 0.5705909716375487, 0.7631583590806635, 0.7631583590806635, 0.7631583590806635, 0.18983417773058742, 0.18983417773058742, 0.18983417773058742, 0.6815045553315666, 0.6815045553315666, 0.6815045553315666, 0.17944520577185596, 0.17944520577185596, 0.17944520577185596, 0.18856463089808273, 0.18856463089808273, 0.18856463089808273, 0.2034718971406695, 0.2034718971406695, 0.2034718971406695, 0.22001065634018868, 0.22001065634018868, 0.22001065634018868, 0.17012443771845842, 0.17012443771845842, 0.17012443771845842, 0.22234720420605547, 0.22234720420605547, 0.22234720420605547, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.010938921809651059, 0.010938921809651059, 0.010938921809651059, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12010344955931962, 0.12010344955931962, 0.12010344955931962, 0.061998551145590275, 0.061998551145590275, 0.061998551145590275, 0.0804645567786858, 0.0804645567786858, 0.0804645567786858, 0.20749305533756346, 0.20749305533756346, 0.20749305533756346, 0.13427296804841804, 0.13427296804841804, 0.13427296804841804, 0.12797947236437035, 0.12797947236437035, 0.12797947236437035, 0.17283584006255637, 0.17283584006255637, 0.17283584006255637, 0.13355017309502748, 0.13355017309502748, 0.13355017309502748, 0.07110751377449265, 0.07110751377449265, 0.07110751377449265, 0.5308169911312102, 0.5308169911312102, 0.5308169911312102, 0.5657476083083961, 0.5657476083083961, 0.5657476083083961, 0.5878917976056803, 0.5878917976056803, 0.5878917976056803, 0.147708080561207, 0.147708080561207, 0.147708080561207, 0.16094884053998726, 0.16094884053998726, 0.16094884053998726, 0.13867123637527934, 0.13867123637527934, 0.13867123637527934, 0.15277334763341166, 0.15277334763341166, 0.15277334763341166, 0.16407139180380637, 0.16407139180380637, 0.16407139180380637, 0.1593132021330177, 0.1593132021330177, 0.1593132021330177, 0.2533712663597876, 0.2533712663597876, 0.2533712663597876, 0.29357199766679765, 0.29357199766679765, 0.29357199766679765, 0.4783931568515284, 0.4783931568515284, 0.4783931568515284, 0.2754952057017658, 0.2754952057017658, 0.2754952057017658, 0.21292600327515487, 0.21292600327515487, 0.21292600327515487, 0.2547644767838144, 0.2547644767838144, 0.2547644767838144, 0.20480430918203274, 0.20480430918203274, 0.20480430918203274, 0.20336899816537768, 0.20336899816537768, 0.20336899816537768, 0.2081288279119382, 0.2081288279119382, 0.2081288279119382, 0.23899986624711955, 0.23899986624711955, 0.23899986624711955, 0.188832723015794, 0.188832723015794, 0.188832723015794, 0.21280358304729452, 0.21280358304729452, 0.21280358304729452, 0.8523063825299845, 0.8523063825299845, 0.8523063825299845, 0.16285517550643258, 0.16285517550643258, 0.16285517550643258, 0.739216362052447, 0.739216362052447, 0.739216362052447, 0.16804724639545343, 0.16804724639545343, 0.16804724639545343, 0.20861498254107147, 0.20861498254107147, 0.20861498254107147, 0.20355642147373476, 0.20355642147373476, 0.20355642147373476, 0.20101000524230228, 0.20101000524230228, 0.20101000524230228, 0.21301703906981306, 0.21301703906981306, 0.21301703906981306, 0.1860988045544808, 0.1860988045544808, 0.1860988045544808, 0.0980841168119474, 0.0980841168119474, 0.0980841168119474, 0.09714462828725468, 0.09714462828725468, 0.09714462828725468, 0.08434703695770729, 0.08434703695770729, 0.08434703695770729]}, "mutation_prompt": null}
{"id": "fc86ba74-db0d-475d-9fd0-c2cfeedfabaf", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                self.w = 0.9 - 0.5 * (evaluations / self.budget)  # Adaptive inertia weight\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Introduced adaptive inertia weight in PSO to enhance exploration and exploitation balance.", "configspace": "", "generation": 18, "fitness": 0.20577492177781914, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.44758853118755115, 0.44758853118755115, 0.44758853118755115, 0.5466156977500924, 0.5466156977500924, 0.5466156977500924, 0.4807008716687816, 0.4807008716687816, 0.4807008716687816, 0.12366888526057884, 0.12366888526057884, 0.12366888526057884, 0.17767300616067727, 0.17767300616067727, 0.17767300616067727, 0.2065798473130781, 0.2065798473130781, 0.2065798473130781, 0.0988579180126189, 0.0988579180126189, 0.0988579180126189, 0.1081361840076337, 0.1081361840076337, 0.1081361840076337, 0.09963585736028491, 0.09963585736028491, 0.09963585736028491, 0.08109380353766449, 0.08109380353766449, 0.08109380353766449, 0.08519866607291138, 0.08519866607291138, 0.08519866607291138, 0.09163140126409886, 0.09163140126409886, 0.09163140126409886, 0.975651045096156, 0.975651045096156, 0.975651045096156, 0.9790362992505957, 0.9790362992505957, 0.9790362992505957, 0.9736668129840342, 0.9736668129840342, 0.9736668129840342, 0.2913679120706736, 0.2913679120706736, 0.2913679120706736, 0.2549019415282592, 0.2549019415282592, 0.2549019415282592, 0.2595875451798102, 0.2595875451798102, 0.2595875451798102, 0.24975608698443053, 0.24975608698443053, 0.24975608698443053, 0.16938114229449852, 0.16938114229449852, 0.16938114229449852, 0.16184508959737798, 0.16184508959737798, 0.16184508959737798, 0.09441635482944422, 0.09441635482944422, 0.09441635482944422, 0.19078210425831343, 0.19078210425831343, 0.19078210425831343, 0.19028496913239568, 0.19028496913239568, 0.19028496913239568, 0.042746067586211356, 0.042746067586211356, 0.042746067586211356, 0.11527350072230225, 0.11527350072230225, 0.11527350072230225, 0.12431717607551385, 0.12431717607551385, 0.12431717607551385, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0787400252107916, 0.0787400252107916, 0.0787400252107916, 0.06907151679223622, 0.06907151679223622, 0.06907151679223622, 0.06435206586822972, 0.06435206586822972, 0.06435206586822972, 0.017864077197967676, 0.017864077197967676, 0.017864077197967676, 0.06176875968303708, 0.06176875968303708, 0.06176875968303708, 0.03499618171061425, 0.03499618171061425, 0.03499618171061425, 0.0370664250550683, 0.0370664250550683, 0.0370664250550683, 0.0891172103226352, 0.0891172103226352, 0.0891172103226352, 0.03892962365755337, 0.03892962365755337, 0.03892962365755337, 0.3835547593022345, 0.3835547593022345, 0.3835547593022345, 0.39393277978697494, 0.39393277978697494, 0.39393277978697494, 0.3793510952057222, 0.3793510952057222, 0.3793510952057222, 0.08424628248284693, 0.08424628248284693, 0.08424628248284693, 0.09840668691393673, 0.09840668691393673, 0.09840668691393673, 0.10339739159368966, 0.10339739159368966, 0.10339739159368966, 0.17211817624461512, 0.17211817624461512, 0.17211817624461512, 0.1863635839168436, 0.1863635839168436, 0.1863635839168436, 0.15120320850345137, 0.15120320850345137, 0.15120320850345137, 0.28121285095416215, 0.28121285095416215, 0.28121285095416215, 0.26219718151078497, 0.26219718151078497, 0.26219718151078497, 0.2653662357826615, 0.2653662357826615, 0.2653662357826615, 0.18477563388248686, 0.18477563388248686, 0.18477563388248686, 0.20250773159947, 0.20250773159947, 0.20250773159947, 0.1756798866194491, 0.1756798866194491, 0.1756798866194491, 0.17662582065245247, 0.17662582065245247, 0.17662582065245247, 0.1802211752050622, 0.1802211752050622, 0.1802211752050622, 0.1862266468019117, 0.1862266468019117, 0.1862266468019117, 0.18178382476566035, 0.18178382476566035, 0.18178382476566035, 0.1887550617696726, 0.1887550617696726, 0.1887550617696726, 0.20987439864355828, 0.20987439864355828, 0.20987439864355828, 0.5613909862669498, 0.5613909862669498, 0.5613909862669498, 0.1511788111992819, 0.1511788111992819, 0.1511788111992819, 0.1791580623678275, 0.1791580623678275, 0.1791580623678275, 0.19193715196545014, 0.19193715196545014, 0.19193715196545014, 0.19660007486030728, 0.19660007486030728, 0.19660007486030728, 0.1857322973189689, 0.1857322973189689, 0.1857322973189689, 0.195319602465868, 0.195319602465868, 0.195319602465868, 0.19033097172020963, 0.19033097172020963, 0.19033097172020963, 0.1756322862540154, 0.1756322862540154, 0.1756322862540154, 0.0709170233676294, 0.0709170233676294, 0.0709170233676294, 0.07582857042875879, 0.07582857042875879, 0.07582857042875879, 0.08136751496594352, 0.08136751496594352, 0.08136751496594352]}, "mutation_prompt": null}
{"id": "ee0b133e-ffc5-4dec-91cc-46ca3ad37813", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.w = 0.9 - (0.5 * evaluations / self.budget)  # Dynamic inertia weight\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  \n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Improved AdaptiveHybridGA by introducing dynamic adjustment of inertia weight in PSO step.", "configspace": "", "generation": 19, "fitness": 0.20577492177781914, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.44758853118755115, 0.44758853118755115, 0.44758853118755115, 0.5466156977500924, 0.5466156977500924, 0.5466156977500924, 0.4807008716687816, 0.4807008716687816, 0.4807008716687816, 0.12366888526057884, 0.12366888526057884, 0.12366888526057884, 0.17767300616067727, 0.17767300616067727, 0.17767300616067727, 0.2065798473130781, 0.2065798473130781, 0.2065798473130781, 0.0988579180126189, 0.0988579180126189, 0.0988579180126189, 0.1081361840076337, 0.1081361840076337, 0.1081361840076337, 0.09963585736028491, 0.09963585736028491, 0.09963585736028491, 0.08109380353766449, 0.08109380353766449, 0.08109380353766449, 0.08519866607291138, 0.08519866607291138, 0.08519866607291138, 0.09163140126409886, 0.09163140126409886, 0.09163140126409886, 0.975651045096156, 0.975651045096156, 0.975651045096156, 0.9790362992505957, 0.9790362992505957, 0.9790362992505957, 0.9736668129840342, 0.9736668129840342, 0.9736668129840342, 0.2913679120706736, 0.2913679120706736, 0.2913679120706736, 0.2549019415282592, 0.2549019415282592, 0.2549019415282592, 0.2595875451798102, 0.2595875451798102, 0.2595875451798102, 0.24975608698443053, 0.24975608698443053, 0.24975608698443053, 0.16938114229449852, 0.16938114229449852, 0.16938114229449852, 0.16184508959737798, 0.16184508959737798, 0.16184508959737798, 0.09441635482944422, 0.09441635482944422, 0.09441635482944422, 0.19078210425831343, 0.19078210425831343, 0.19078210425831343, 0.19028496913239568, 0.19028496913239568, 0.19028496913239568, 0.042746067586211356, 0.042746067586211356, 0.042746067586211356, 0.11527350072230225, 0.11527350072230225, 0.11527350072230225, 0.12431717607551385, 0.12431717607551385, 0.12431717607551385, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0787400252107916, 0.0787400252107916, 0.0787400252107916, 0.06907151679223622, 0.06907151679223622, 0.06907151679223622, 0.06435206586822972, 0.06435206586822972, 0.06435206586822972, 0.017864077197967676, 0.017864077197967676, 0.017864077197967676, 0.06176875968303708, 0.06176875968303708, 0.06176875968303708, 0.03499618171061425, 0.03499618171061425, 0.03499618171061425, 0.0370664250550683, 0.0370664250550683, 0.0370664250550683, 0.0891172103226352, 0.0891172103226352, 0.0891172103226352, 0.03892962365755337, 0.03892962365755337, 0.03892962365755337, 0.3835547593022345, 0.3835547593022345, 0.3835547593022345, 0.39393277978697494, 0.39393277978697494, 0.39393277978697494, 0.3793510952057222, 0.3793510952057222, 0.3793510952057222, 0.08424628248284693, 0.08424628248284693, 0.08424628248284693, 0.09840668691393673, 0.09840668691393673, 0.09840668691393673, 0.10339739159368966, 0.10339739159368966, 0.10339739159368966, 0.17211817624461512, 0.17211817624461512, 0.17211817624461512, 0.1863635839168436, 0.1863635839168436, 0.1863635839168436, 0.15120320850345137, 0.15120320850345137, 0.15120320850345137, 0.28121285095416215, 0.28121285095416215, 0.28121285095416215, 0.26219718151078497, 0.26219718151078497, 0.26219718151078497, 0.2653662357826615, 0.2653662357826615, 0.2653662357826615, 0.18477563388248686, 0.18477563388248686, 0.18477563388248686, 0.20250773159947, 0.20250773159947, 0.20250773159947, 0.1756798866194491, 0.1756798866194491, 0.1756798866194491, 0.17662582065245247, 0.17662582065245247, 0.17662582065245247, 0.1802211752050622, 0.1802211752050622, 0.1802211752050622, 0.1862266468019117, 0.1862266468019117, 0.1862266468019117, 0.18178382476566035, 0.18178382476566035, 0.18178382476566035, 0.1887550617696726, 0.1887550617696726, 0.1887550617696726, 0.20987439864355828, 0.20987439864355828, 0.20987439864355828, 0.5613909862669498, 0.5613909862669498, 0.5613909862669498, 0.1511788111992819, 0.1511788111992819, 0.1511788111992819, 0.1791580623678275, 0.1791580623678275, 0.1791580623678275, 0.19193715196545014, 0.19193715196545014, 0.19193715196545014, 0.19660007486030728, 0.19660007486030728, 0.19660007486030728, 0.1857322973189689, 0.1857322973189689, 0.1857322973189689, 0.195319602465868, 0.195319602465868, 0.195319602465868, 0.19033097172020963, 0.19033097172020963, 0.19033097172020963, 0.1756322862540154, 0.1756322862540154, 0.1756322862540154, 0.0709170233676294, 0.0709170233676294, 0.0709170233676294, 0.07582857042875879, 0.07582857042875879, 0.07582857042875879, 0.08136751496594352, 0.08136751496594352, 0.08136751496594352]}, "mutation_prompt": null}
{"id": "e920780c-b7a9-4e49-9c0a-ee97b35f05a1", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                self.w = 0.9 - 0.4 * (evaluations/self.budget)  # Change: Dynamic inertia weight\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced convergence by dynamically adjusting the inertia weight (w) in PSO based on evaluations.", "configspace": "", "generation": 20, "fitness": 0.1905985125195022, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.437605286148927, 0.437605286148927, 0.437605286148927, 0.4548483346002523, 0.4548483346002523, 0.4548483346002523, 0.4807776073732434, 0.4807776073732434, 0.4807776073732434, 0.10137514983641505, 0.10137514983641505, 0.10137514983641505, 0.049834645307488046, 0.049834645307488046, 0.049834645307488046, 0.02628286255110235, 0.02628286255110235, 0.02628286255110235, 0.0844780636365755, 0.0844780636365755, 0.0844780636365755, 0.08766721836909674, 0.08766721836909674, 0.08766721836909674, 0.08502418371943421, 0.08502418371943421, 0.08502418371943421, 0.07705562381719444, 0.07705562381719444, 0.07705562381719444, 0.07472857816598899, 0.07472857816598899, 0.07472857816598899, 0.08061123337641407, 0.08061123337641407, 0.08061123337641407, 0.975652090494761, 0.975652090494761, 0.975652090494761, 0.9790366890189451, 0.9790366890189451, 0.9790366890189451, 0.9736664876013109, 0.9736664876013109, 0.9736664876013109, 0.281429548677698, 0.281429548677698, 0.281429548677698, 0.19621990574529247, 0.19621990574529247, 0.19621990574529247, 0.2096629104369263, 0.2096629104369263, 0.2096629104369263, 0.18701423690835983, 0.18701423690835983, 0.18701423690835983, 0.18332241035662344, 0.18332241035662344, 0.18332241035662344, 0.1991846570435214, 0.1991846570435214, 0.1991846570435214, 0.12333134526260581, 0.12333134526260581, 0.12333134526260581, 0.13085889400922657, 0.13085889400922657, 0.13085889400922657, 0.12340971554608982, 0.12340971554608982, 0.12340971554608982, 0.019550142587097974, 0.019550142587097974, 0.019550142587097974, 0.10950163133381119, 0.10950163133381119, 0.10950163133381119, 0.1177956983214784, 0.1177956983214784, 0.1177956983214784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00950637459719128, 0.00950637459719128, 0.00950637459719128, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10106885035602009, 0.10106885035602009, 0.10106885035602009, 0.04465698958158304, 0.04465698958158304, 0.04465698958158304, 0.07258536355953182, 0.07258536355953182, 0.07258536355953182, 0.013005801850459853, 0.013005801850459853, 0.013005801850459853, 0.006472194279493304, 0.006472194279493304, 0.006472194279493304, 0.02355355952731175, 0.02355355952731175, 0.02355355952731175, 0.03591986374834777, 0.03591986374834777, 0.03591986374834777, 0.04411588696491331, 0.04411588696491331, 0.04411588696491331, 0.08604786458357705, 0.08604786458357705, 0.08604786458357705, 0.3721972396434816, 0.3721972396434816, 0.3721972396434816, 0.32785117041377165, 0.32785117041377165, 0.32785117041377165, 0.3191748871910909, 0.3191748871910909, 0.3191748871910909, 0.08459005096922123, 0.08459005096922123, 0.08459005096922123, 0.10192835821712865, 0.10192835821712865, 0.10192835821712865, 0.09248598957574816, 0.09248598957574816, 0.09248598957574816, 0.16439007814830298, 0.16439007814830298, 0.16439007814830298, 0.16513681059269092, 0.16513681059269092, 0.16513681059269092, 0.1481488140498476, 0.1481488140498476, 0.1481488140498476, 0.261510016304523, 0.261510016304523, 0.261510016304523, 0.23815083626712874, 0.23815083626712874, 0.23815083626712874, 0.2543841551111472, 0.2543841551111472, 0.2543841551111472, 0.22006955393172245, 0.22006955393172245, 0.22006955393172245, 0.16858121251514335, 0.16858121251514335, 0.16858121251514335, 0.18557368929442108, 0.18557368929442108, 0.18557368929442108, 0.1824320921383441, 0.1824320921383441, 0.1824320921383441, 0.19769733786703114, 0.19769733786703114, 0.19769733786703114, 0.19230837653923083, 0.19230837653923083, 0.19230837653923083, 0.17570374458313687, 0.17570374458313687, 0.17570374458313687, 0.20251793593804024, 0.20251793593804024, 0.20251793593804024, 0.16434101028399106, 0.16434101028399106, 0.16434101028399106, 0.5047688863531201, 0.5047688863531201, 0.5047688863531201, 0.19016039680171526, 0.19016039680171526, 0.19016039680171526, 0.17640693852197142, 0.17640693852197142, 0.17640693852197142, 0.19621505054565602, 0.19621505054565602, 0.19621505054565602, 0.19381752126562424, 0.19381752126562424, 0.19381752126562424, 0.20035116540292175, 0.20035116540292175, 0.20035116540292175, 0.18453816311407745, 0.18453816311407745, 0.18453816311407745, 0.1709701339416373, 0.1709701339416373, 0.1709701339416373, 0.19104830268622186, 0.19104830268622186, 0.19104830268622186, 0.07310600968431136, 0.07310600968431136, 0.07310600968431136, 0.06854543834691518, 0.06854543834691518, 0.06854543834691518, 0.06693363587053258, 0.06693363587053258, 0.06693363587053258]}, "mutation_prompt": null}
{"id": "860853bd-c945-4994-aa4b-4dd5aab79e2e", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                self.w = 0.9 - evaluations/self.budget * 0.4  # Adjusting inertia weight over time\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced exploration by adjusting the inertia weight in PSO.", "configspace": "", "generation": 21, "fitness": 0.1905985125195022, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.437605286148927, 0.437605286148927, 0.437605286148927, 0.4548483346002523, 0.4548483346002523, 0.4548483346002523, 0.4807776073732434, 0.4807776073732434, 0.4807776073732434, 0.10137514983641505, 0.10137514983641505, 0.10137514983641505, 0.049834645307488046, 0.049834645307488046, 0.049834645307488046, 0.02628286255110235, 0.02628286255110235, 0.02628286255110235, 0.0844780636365755, 0.0844780636365755, 0.0844780636365755, 0.08766721836909674, 0.08766721836909674, 0.08766721836909674, 0.08502418371943421, 0.08502418371943421, 0.08502418371943421, 0.07705562381719444, 0.07705562381719444, 0.07705562381719444, 0.07472857816598899, 0.07472857816598899, 0.07472857816598899, 0.08061123337641407, 0.08061123337641407, 0.08061123337641407, 0.975652090494761, 0.975652090494761, 0.975652090494761, 0.9790366890189451, 0.9790366890189451, 0.9790366890189451, 0.9736664876013109, 0.9736664876013109, 0.9736664876013109, 0.281429548677698, 0.281429548677698, 0.281429548677698, 0.19621990574529247, 0.19621990574529247, 0.19621990574529247, 0.2096629104369263, 0.2096629104369263, 0.2096629104369263, 0.18701423690835983, 0.18701423690835983, 0.18701423690835983, 0.18332241035662344, 0.18332241035662344, 0.18332241035662344, 0.1991846570435214, 0.1991846570435214, 0.1991846570435214, 0.12333134526260581, 0.12333134526260581, 0.12333134526260581, 0.13085889400922657, 0.13085889400922657, 0.13085889400922657, 0.12340971554608982, 0.12340971554608982, 0.12340971554608982, 0.019550142587097974, 0.019550142587097974, 0.019550142587097974, 0.10950163133381119, 0.10950163133381119, 0.10950163133381119, 0.1177956983214784, 0.1177956983214784, 0.1177956983214784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00950637459719128, 0.00950637459719128, 0.00950637459719128, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10106885035602009, 0.10106885035602009, 0.10106885035602009, 0.04465698958158304, 0.04465698958158304, 0.04465698958158304, 0.07258536355953182, 0.07258536355953182, 0.07258536355953182, 0.013005801850459853, 0.013005801850459853, 0.013005801850459853, 0.006472194279493304, 0.006472194279493304, 0.006472194279493304, 0.02355355952731175, 0.02355355952731175, 0.02355355952731175, 0.03591986374834777, 0.03591986374834777, 0.03591986374834777, 0.04411588696491331, 0.04411588696491331, 0.04411588696491331, 0.08604786458357705, 0.08604786458357705, 0.08604786458357705, 0.3721972396434816, 0.3721972396434816, 0.3721972396434816, 0.32785117041377165, 0.32785117041377165, 0.32785117041377165, 0.3191748871910909, 0.3191748871910909, 0.3191748871910909, 0.08459005096922123, 0.08459005096922123, 0.08459005096922123, 0.10192835821712865, 0.10192835821712865, 0.10192835821712865, 0.09248598957574816, 0.09248598957574816, 0.09248598957574816, 0.16439007814830298, 0.16439007814830298, 0.16439007814830298, 0.16513681059269092, 0.16513681059269092, 0.16513681059269092, 0.1481488140498476, 0.1481488140498476, 0.1481488140498476, 0.261510016304523, 0.261510016304523, 0.261510016304523, 0.23815083626712874, 0.23815083626712874, 0.23815083626712874, 0.2543841551111472, 0.2543841551111472, 0.2543841551111472, 0.22006955393172245, 0.22006955393172245, 0.22006955393172245, 0.16858121251514335, 0.16858121251514335, 0.16858121251514335, 0.18557368929442108, 0.18557368929442108, 0.18557368929442108, 0.1824320921383441, 0.1824320921383441, 0.1824320921383441, 0.19769733786703114, 0.19769733786703114, 0.19769733786703114, 0.19230837653923083, 0.19230837653923083, 0.19230837653923083, 0.17570374458313687, 0.17570374458313687, 0.17570374458313687, 0.20251793593804024, 0.20251793593804024, 0.20251793593804024, 0.16434101028399106, 0.16434101028399106, 0.16434101028399106, 0.5047688863531201, 0.5047688863531201, 0.5047688863531201, 0.19016039680171526, 0.19016039680171526, 0.19016039680171526, 0.17640693852197142, 0.17640693852197142, 0.17640693852197142, 0.19621505054565602, 0.19621505054565602, 0.19621505054565602, 0.19381752126562424, 0.19381752126562424, 0.19381752126562424, 0.20035116540292175, 0.20035116540292175, 0.20035116540292175, 0.18453816311407745, 0.18453816311407745, 0.18453816311407745, 0.1709701339416373, 0.1709701339416373, 0.1709701339416373, 0.19104830268622186, 0.19104830268622186, 0.19104830268622186, 0.07310600968431136, 0.07310600968431136, 0.07310600968431136, 0.06854543834691518, 0.06854543834691518, 0.06854543834691518, 0.06693363587053258, 0.06693363587053258, 0.06693363587053258]}, "mutation_prompt": null}
{"id": "72065625-baf8-4aa6-963b-1b7d595fa7f2", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential Evolution parameter (changed from 0.5 to 0.8)\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced global exploration by adjusting the differential evolution parameter F.", "configspace": "", "generation": 22, "fitness": 0.30806922192736336, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.26.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.8271934177252913, 0.8271934177252913, 0.8271934177252913, 0.8586394672654286, 0.8586394672654286, 0.8586394672654286, 0.8509598210155822, 0.8509598210155822, 0.8509598210155822, 0.6597228914739197, 0.6597228914739197, 0.6597228914739197, 0.6377444393744354, 0.6377444393744354, 0.6377444393744354, 0.6788106305877273, 0.6788106305877273, 0.6788106305877273, 0.13288279407414705, 0.13288279407414705, 0.13288279407414705, 0.14116779211267783, 0.14116779211267783, 0.14116779211267783, 0.14944651790790064, 0.14944651790790064, 0.14944651790790064, 0.09931251824060106, 0.09931251824060106, 0.09931251824060106, 0.11703426266106376, 0.11703426266106376, 0.11703426266106376, 0.13002423800100127, 0.13002423800100127, 0.13002423800100127, 0.9745436877713427, 0.9745436877713427, 0.9745436877713427, 0.9730352066889033, 0.9730352066889033, 0.9730352066889033, 0.9698388305797714, 0.9698388305797714, 0.9698388305797714, 0.6587362188705821, 0.6587362188705821, 0.6587362188705821, 0.4872914062045224, 0.4872914062045224, 0.4872914062045224, 0.616836754585651, 0.616836754585651, 0.616836754585651, 0.3500198635149382, 0.3500198635149382, 0.3500198635149382, 0.21061168681812037, 0.21061168681812037, 0.21061168681812037, 0.22329595209497322, 0.22329595209497322, 0.22329595209497322, 0.2118281433131104, 0.2118281433131104, 0.2118281433131104, 0.20354579772174697, 0.20354579772174697, 0.20354579772174697, 0.21290716238498386, 0.21290716238498386, 0.21290716238498386, 0.21080251975226705, 0.21080251975226705, 0.21080251975226705, 0.13362245265890382, 0.13362245265890382, 0.13362245265890382, 0.2689071967366563, 0.2689071967366563, 0.2689071967366563, 0.005395313851878969, 0.005395313851878969, 0.005395313851878969, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11403958962503324, 0.11403958962503324, 0.11403958962503324, 0.13956550641678622, 0.13956550641678622, 0.13956550641678622, 0.057963605899211346, 0.057963605899211346, 0.057963605899211346, 0.08423784662684863, 0.08423784662684863, 0.08423784662684863, 0.14348000980477116, 0.14348000980477116, 0.14348000980477116, 0.1354471989805094, 0.1354471989805094, 0.1354471989805094, 0.09534494002435445, 0.09534494002435445, 0.09534494002435445, 0.06754631467220151, 0.06754631467220151, 0.06754631467220151, 0.0812665027421905, 0.0812665027421905, 0.0812665027421905, 0.5281281700431186, 0.5281281700431186, 0.5281281700431186, 0.5369078345866216, 0.5369078345866216, 0.5369078345866216, 0.5593784284530074, 0.5593784284530074, 0.5593784284530074, 0.1317942506105394, 0.1317942506105394, 0.1317942506105394, 0.1676611018891757, 0.1676611018891757, 0.1676611018891757, 0.1100763756938552, 0.1100763756938552, 0.1100763756938552, 0.16986702265516618, 0.16986702265516618, 0.16986702265516618, 0.2536817386224177, 0.2536817386224177, 0.2536817386224177, 0.15471815277676537, 0.15471815277676537, 0.15471815277676537, 0.4008748730936852, 0.4008748730936852, 0.4008748730936852, 0.4445045639210582, 0.4445045639210582, 0.4445045639210582, 0.4532020258062721, 0.4532020258062721, 0.4532020258062721, 0.25220649882274215, 0.25220649882274215, 0.25220649882274215, 0.23013901794534797, 0.23013901794534797, 0.23013901794534797, 0.20403700703036998, 0.20403700703036998, 0.20403700703036998, 0.24011694429771946, 0.24011694429771946, 0.24011694429771946, 0.18571956556752478, 0.18571956556752478, 0.18571956556752478, 0.2012607747185826, 0.2012607747185826, 0.2012607747185826, 0.23716777242646792, 0.23716777242646792, 0.23716777242646792, 0.2196378095060708, 0.2196378095060708, 0.2196378095060708, 0.22402952582575275, 0.22402952582575275, 0.22402952582575275, 0.8687207304276037, 0.8687207304276037, 0.8687207304276037, 0.1612602500818071, 0.1612602500818071, 0.1612602500818071, 0.8133825310881138, 0.8133825310881138, 0.8133825310881138, 0.1669442844127541, 0.1669442844127541, 0.1669442844127541, 0.3171489559729187, 0.3171489559729187, 0.3171489559729187, 0.1632461728727883, 0.1632461728727883, 0.1632461728727883, 0.20711942234335856, 0.20711942234335856, 0.20711942234335856, 0.18900764869337516, 0.18900764869337516, 0.18900764869337516, 0.20699022044723603, 0.20699022044723603, 0.20699022044723603, 0.08387778209756902, 0.08387778209756902, 0.08387778209756902, 0.08535497867586606, 0.08535497867586606, 0.08535497867586606, 0.09957304858447402, 0.09957304858447402, 0.09957304858447402]}, "mutation_prompt": null}
{"id": "c4375064-af58-45ee-9ff4-539dfdcc8d7b", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.6  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced global exploration by slightly increasing inertia weight in PSO.", "configspace": "", "generation": 23, "fitness": 0.2797633581038645, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.23.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.7749319254847502, 0.7749319254847502, 0.7749319254847502, 0.7587484578443413, 0.7587484578443413, 0.7587484578443413, 0.7978635231988749, 0.7978635231988749, 0.7978635231988749, 0.4439637678128827, 0.4439637678128827, 0.4439637678128827, 0.4445003520696983, 0.4445003520696983, 0.4445003520696983, 0.2942508039327506, 0.2942508039327506, 0.2942508039327506, 0.13014604240515093, 0.13014604240515093, 0.13014604240515093, 0.1497182183100938, 0.1497182183100938, 0.1497182183100938, 0.13663223051302198, 0.13663223051302198, 0.13663223051302198, 0.13186116070199716, 0.13186116070199716, 0.13186116070199716, 0.09731148283043822, 0.09731148283043822, 0.09731148283043822, 0.11394990384542703, 0.11394990384542703, 0.11394990384542703, 0.9734237863293943, 0.9734237863293943, 0.9734237863293943, 0.9739704831338388, 0.9739704831338388, 0.9739704831338388, 0.9702329832334816, 0.9702329832334816, 0.9702329832334816, 0.44156411476993496, 0.44156411476993496, 0.44156411476993496, 0.4107148703423873, 0.4107148703423873, 0.4107148703423873, 0.4671670964483595, 0.4671670964483595, 0.4671670964483595, 0.5370005212694076, 0.5370005212694076, 0.5370005212694076, 0.21193338043049492, 0.21193338043049492, 0.21193338043049492, 0.2294670974525964, 0.2294670974525964, 0.2294670974525964, 0.1788270761033829, 0.1788270761033829, 0.1788270761033829, 0.186727006497306, 0.186727006497306, 0.186727006497306, 0.17891800136124925, 0.17891800136124925, 0.17891800136124925, 0.189526929226139, 0.189526929226139, 0.189526929226139, 0.19433655004047012, 0.19433655004047012, 0.19433655004047012, 0.21524852184964094, 0.21524852184964094, 0.21524852184964094, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006557029308984941, 0.006557029308984941, 0.006557029308984941, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08742355152447412, 0.08742355152447412, 0.08742355152447412, 0.05324146281287723, 0.05324146281287723, 0.05324146281287723, 0.0545836430851625, 0.0545836430851625, 0.0545836430851625, 0.1395688402667321, 0.1395688402667321, 0.1395688402667321, 0.06693852141994228, 0.06693852141994228, 0.06693852141994228, 0.22134018702291092, 0.22134018702291092, 0.22134018702291092, 0.16964127007509866, 0.16964127007509866, 0.16964127007509866, 0.10854765984722703, 0.10854765984722703, 0.10854765984722703, 0.056063385569116164, 0.056063385569116164, 0.056063385569116164, 0.5065431708667353, 0.5065431708667353, 0.5065431708667353, 0.4937063131907611, 0.4937063131907611, 0.4937063131907611, 0.5123426762216357, 0.5123426762216357, 0.5123426762216357, 0.1606868198784447, 0.1606868198784447, 0.1606868198784447, 0.13735228368598096, 0.13735228368598096, 0.13735228368598096, 0.1117564102585793, 0.1117564102585793, 0.1117564102585793, 0.23130743993398406, 0.23130743993398406, 0.23130743993398406, 0.18278489640456408, 0.18278489640456408, 0.18278489640456408, 0.3655003287552415, 0.3655003287552415, 0.3655003287552415, 0.3347281897822797, 0.3347281897822797, 0.3347281897822797, 0.3609055168021359, 0.3609055168021359, 0.3609055168021359, 0.4097281005190886, 0.4097281005190886, 0.4097281005190886, 0.29198801442616706, 0.29198801442616706, 0.29198801442616706, 0.22406921661621526, 0.22406921661621526, 0.22406921661621526, 0.20054824237285573, 0.20054824237285573, 0.20054824237285573, 0.18604405838175953, 0.18604405838175953, 0.18604405838175953, 0.21032800172109323, 0.21032800172109323, 0.21032800172109323, 0.19941601620425142, 0.19941601620425142, 0.19941601620425142, 0.18669218143741628, 0.18669218143741628, 0.18669218143741628, 0.23359481647632352, 0.23359481647632352, 0.23359481647632352, 0.3858506879691199, 0.3858506879691199, 0.3858506879691199, 0.8596568202874606, 0.8596568202874606, 0.8596568202874606, 0.16336119700933072, 0.16336119700933072, 0.16336119700933072, 0.16080004086557476, 0.16080004086557476, 0.16080004086557476, 0.16674224910528046, 0.16674224910528046, 0.16674224910528046, 0.20539043656553735, 0.20539043656553735, 0.20539043656553735, 0.19388040372637227, 0.19388040372637227, 0.19388040372637227, 0.18939349308545184, 0.18939349308545184, 0.18939349308545184, 0.20059231881802364, 0.20059231881802364, 0.20059231881802364, 0.19243905393939909, 0.19243905393939909, 0.19243905393939909, 0.0781173685526273, 0.0781173685526273, 0.0781173685526273, 0.07776410995802474, 0.07776410995802474, 0.07776410995802474, 0.13190907129049245, 0.13190907129049245, 0.13190907129049245]}, "mutation_prompt": null}
{"id": "7273ee1e-3071-40c3-8a94-5db6c719db31", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.8 + evaluations/self.budget * 1.5  # Slightly enhanced social coefficient\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Slightly enhance the global best influence in PSO by adjusting the social coefficient.", "configspace": "", "generation": 24, "fitness": 0.3057878516012987, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.25.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.7935391739179221, 0.7935391739179221, 0.7935391739179221, 0.8088305743145511, 0.8088305743145511, 0.8088305743145511, 0.8335920310176639, 0.8335920310176639, 0.8335920310176639, 0.5626398401190272, 0.5626398401190272, 0.5626398401190272, 0.525088911529447, 0.525088911529447, 0.525088911529447, 0.5571810535082766, 0.5571810535082766, 0.5571810535082766, 0.14116950560187358, 0.14116950560187358, 0.14116950560187358, 0.12365767456915766, 0.12365767456915766, 0.12365767456915766, 0.14612256915823651, 0.14612256915823651, 0.14612256915823651, 0.11792426501302655, 0.11792426501302655, 0.11792426501302655, 0.12882905782939746, 0.12882905782939746, 0.12882905782939746, 0.14240770646798206, 0.14240770646798206, 0.14240770646798206, 0.9802714178440955, 0.9802714178440955, 0.9802714178440955, 0.9792795652931523, 0.9792795652931523, 0.9792795652931523, 0.9730941678947357, 0.9730941678947357, 0.9730941678947357, 0.5181817301288123, 0.5181817301288123, 0.5181817301288123, 0.4417925169401198, 0.4417925169401198, 0.4417925169401198, 0.494539309570173, 0.494539309570173, 0.494539309570173, 0.20055439422436705, 0.20055439422436705, 0.20055439422436705, 0.19013183406467804, 0.19013183406467804, 0.19013183406467804, 0.7388204244848617, 0.7388204244848617, 0.7388204244848617, 0.18315183528675205, 0.18315183528675205, 0.18315183528675205, 0.17026850301846375, 0.17026850301846375, 0.17026850301846375, 0.19172261091321086, 0.19172261091321086, 0.19172261091321086, 0.17877610935059352, 0.17877610935059352, 0.17877610935059352, 0.21346253896421363, 0.21346253896421363, 0.21346253896421363, 0.21910430127285307, 0.21910430127285307, 0.21910430127285307, 0.013355483362077925, 0.013355483362077925, 0.013355483362077925, 0.032629797157568086, 0.032629797157568086, 0.032629797157568086, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09599453687508375, 0.09599453687508375, 0.09599453687508375, 0.05316864139706379, 0.05316864139706379, 0.05316864139706379, 0.04682097976531019, 0.04682097976531019, 0.04682097976531019, 0.1112115134981917, 0.1112115134981917, 0.1112115134981917, 0.11494137102122659, 0.11494137102122659, 0.11494137102122659, 0.20152212829322724, 0.20152212829322724, 0.20152212829322724, 0.1657579318638669, 0.1657579318638669, 0.1657579318638669, 0.19068184188901838, 0.19068184188901838, 0.19068184188901838, 0.0532314438513507, 0.0532314438513507, 0.0532314438513507, 0.5351647797228951, 0.5351647797228951, 0.5351647797228951, 0.543577027180273, 0.543577027180273, 0.543577027180273, 0.5353726898428266, 0.5353726898428266, 0.5353726898428266, 0.17728607008117325, 0.17728607008117325, 0.17728607008117325, 0.12467458052022029, 0.12467458052022029, 0.12467458052022029, 0.1260160116344985, 0.1260160116344985, 0.1260160116344985, 0.184451558584401, 0.184451558584401, 0.184451558584401, 0.2038484876419986, 0.2038484876419986, 0.2038484876419986, 0.2704143024664749, 0.2704143024664749, 0.2704143024664749, 0.34337653262322, 0.34337653262322, 0.34337653262322, 0.35507676188705606, 0.35507676188705606, 0.35507676188705606, 0.45934159969939214, 0.45934159969939214, 0.45934159969939214, 0.25948758516901393, 0.25948758516901393, 0.25948758516901393, 0.24404603800385316, 0.24404603800385316, 0.24404603800385316, 0.20741735717630805, 0.20741735717630805, 0.20741735717630805, 0.23841537687009584, 0.23841537687009584, 0.23841537687009584, 0.2138385328036534, 0.2138385328036534, 0.2138385328036534, 0.22705609065370314, 0.22705609065370314, 0.22705609065370314, 0.5317080054804499, 0.5317080054804499, 0.5317080054804499, 0.45073444778898875, 0.45073444778898875, 0.45073444778898875, 0.5655800853929388, 0.5655800853929388, 0.5655800853929388, 0.8739564787840793, 0.8739564787840793, 0.8739564787840793, 0.16730627661132125, 0.16730627661132125, 0.16730627661132125, 0.165165177459904, 0.165165177459904, 0.165165177459904, 0.16768536784178267, 0.16768536784178267, 0.16768536784178267, 0.2110446862927523, 0.2110446862927523, 0.2110446862927523, 0.16217039873954886, 0.16217039873954886, 0.16217039873954886, 0.1840361145616689, 0.1840361145616689, 0.1840361145616689, 0.2046295003451033, 0.2046295003451033, 0.2046295003451033, 0.18769005071400813, 0.18769005071400813, 0.18769005071400813, 0.09108996960122973, 0.09108996960122973, 0.09108996960122973, 0.08990299374165023, 0.08990299374165023, 0.08990299374165023, 0.08161508810538909, 0.08161508810538909, 0.08161508810538909]}, "mutation_prompt": null}
{"id": "f3bbac8d-3f5a-441e-a5c1-ddbfbc33c75b", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                self.F = 0.4 + 0.6 * (evaluations / self.budget)  # Dynamically adjust F\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced differential mutation strategy by dynamically adjusting the scaling factor 'F' based on budget utilization.", "configspace": "", "generation": 25, "fitness": 0.33212113883298816, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.25.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.849639886943142, 0.849639886943142, 0.849639886943142, 0.8237007388227564, 0.8237007388227564, 0.8237007388227564, 0.8612159765283683, 0.8612159765283683, 0.8612159765283683, 0.5721628891640964, 0.5721628891640964, 0.5721628891640964, 0.6237613477855065, 0.6237613477855065, 0.6237613477855065, 0.6194702374256891, 0.6194702374256891, 0.6194702374256891, 0.1302688037144446, 0.1302688037144446, 0.1302688037144446, 0.49236777383289265, 0.49236777383289265, 0.49236777383289265, 0.43301929810848905, 0.43301929810848905, 0.43301929810848905, 0.14238777091380694, 0.14238777091380694, 0.14238777091380694, 0.13292895449725017, 0.13292895449725017, 0.13292895449725017, 0.10646109848541929, 0.10646109848541929, 0.10646109848541929, 0.9747375510665076, 0.9747375510665076, 0.9747375510665076, 0.9716862731149585, 0.9716862731149585, 0.9716862731149585, 0.965791783806242, 0.965791783806242, 0.965791783806242, 0.6039566089028902, 0.6039566089028902, 0.6039566089028902, 0.5375633964747251, 0.5375633964747251, 0.5375633964747251, 0.5906667393647989, 0.5906667393647989, 0.5906667393647989, 0.7622699164996345, 0.7622699164996345, 0.7622699164996345, 0.27056728452158696, 0.27056728452158696, 0.27056728452158696, 0.6783641702225931, 0.6783641702225931, 0.6783641702225931, 0.20498046819797244, 0.20498046819797244, 0.20498046819797244, 0.244078780601783, 0.244078780601783, 0.244078780601783, 0.20199023582161169, 0.20199023582161169, 0.20199023582161169, 0.1736141289087485, 0.1736141289087485, 0.1736141289087485, 0.23393725308078905, 0.23393725308078905, 0.23393725308078905, 0.12212851247780887, 0.12212851247780887, 0.12212851247780887, 0.04923959401869471, 0.04923959401869471, 0.04923959401869471, 0.0918701799021292, 0.0918701799021292, 0.0918701799021292, 0.08473768466558917, 0.08473768466558917, 0.08473768466558917, 0.12200250545973523, 0.12200250545973523, 0.12200250545973523, 0.04303649781799046, 0.04303649781799046, 0.04303649781799046, 0.10867464767279167, 0.10867464767279167, 0.10867464767279167, 0.1534088897299174, 0.1534088897299174, 0.1534088897299174, 0.28469905974559273, 0.28469905974559273, 0.28469905974559273, 0.11333138778010621, 0.11333138778010621, 0.11333138778010621, 0.3543025489690247, 0.3543025489690247, 0.3543025489690247, 0.16355916592495856, 0.16355916592495856, 0.16355916592495856, 0.3171414058703378, 0.3171414058703378, 0.3171414058703378, 0.5212887516225877, 0.5212887516225877, 0.5212887516225877, 0.5335128569577134, 0.5335128569577134, 0.5335128569577134, 0.55170191776576, 0.55170191776576, 0.55170191776576, 0.10764910286451757, 0.10764910286451757, 0.10764910286451757, 0.1411446903645186, 0.1411446903645186, 0.1411446903645186, 0.12919412687003062, 0.12919412687003062, 0.12919412687003062, 0.17583148497697987, 0.17583148497697987, 0.17583148497697987, 0.17641311269853321, 0.17641311269853321, 0.17641311269853321, 0.24444972045461422, 0.24444972045461422, 0.24444972045461422, 0.36715642749981325, 0.36715642749981325, 0.36715642749981325, 0.3702834351980071, 0.3702834351980071, 0.3702834351980071, 0.47314496691937613, 0.47314496691937613, 0.47314496691937613, 0.29779178020079344, 0.29779178020079344, 0.29779178020079344, 0.18398176063801785, 0.18398176063801785, 0.18398176063801785, 0.27388484353338927, 0.27388484353338927, 0.27388484353338927, 0.21905762965101472, 0.21905762965101472, 0.21905762965101472, 0.21494603242274168, 0.21494603242274168, 0.21494603242274168, 0.23125964527687204, 0.23125964527687204, 0.23125964527687204, 0.19211738385604682, 0.19211738385604682, 0.19211738385604682, 0.201205310011085, 0.201205310011085, 0.201205310011085, 0.5449205209285508, 0.5449205209285508, 0.5449205209285508, 0.8475782653582895, 0.8475782653582895, 0.8475782653582895, 0.16258520746849559, 0.16258520746849559, 0.16258520746849559, 0.16088940903384485, 0.16088940903384485, 0.16088940903384485, 0.1665856873579714, 0.1665856873579714, 0.1665856873579714, 0.2086924010591552, 0.2086924010591552, 0.2086924010591552, 0.16583880688684838, 0.16583880688684838, 0.16583880688684838, 0.17887375725656962, 0.17887375725656962, 0.17887375725656962, 0.19690911080562234, 0.19690911080562234, 0.19690911080562234, 0.1958243736867631, 0.1958243736867631, 0.1958243736867631, 0.08558285574103652, 0.08558285574103652, 0.08558285574103652, 0.08612585126978578, 0.08612585126978578, 0.08612585126978578, 0.09657932249841938, 0.09657932249841938, 0.09657932249841938]}, "mutation_prompt": null}
{"id": "f116edef-dfa7-434a-b40d-54bc456366bf", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.95  # Increased Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced AdaptiveHybridGA by increasing the crossover probability for greater exploration.", "configspace": "", "generation": 26, "fitness": 0.3080909906491439, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.25.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.8512429270926203, 0.8512429270926203, 0.8512429270926203, 0.8110170278841441, 0.8110170278841441, 0.8110170278841441, 0.8654003038796636, 0.8654003038796636, 0.8654003038796636, 0.5417670407471725, 0.5417670407471725, 0.5417670407471725, 0.6327905116179211, 0.6327905116179211, 0.6327905116179211, 0.5923096988388641, 0.5923096988388641, 0.5923096988388641, 0.1418577098489966, 0.1418577098489966, 0.1418577098489966, 0.15178520742016044, 0.15178520742016044, 0.15178520742016044, 0.15815706685768094, 0.15815706685768094, 0.15815706685768094, 0.10664801055550766, 0.10664801055550766, 0.10664801055550766, 0.14155097703610242, 0.14155097703610242, 0.14155097703610242, 0.10170476427057207, 0.10170476427057207, 0.10170476427057207, 0.9734499615749884, 0.9734499615749884, 0.9734499615749884, 0.9730992635395849, 0.9730992635395849, 0.9730992635395849, 0.9669362337772861, 0.9669362337772861, 0.9669362337772861, 0.622551116426078, 0.622551116426078, 0.622551116426078, 0.5635329788853336, 0.5635329788853336, 0.5635329788853336, 0.5596411203608083, 0.5596411203608083, 0.5596411203608083, 0.21462295110859608, 0.21462295110859608, 0.21462295110859608, 0.26609409706619624, 0.26609409706619624, 0.26609409706619624, 0.2259811942485762, 0.2259811942485762, 0.2259811942485762, 0.24279761581754544, 0.24279761581754544, 0.24279761581754544, 0.20101729772008126, 0.20101729772008126, 0.20101729772008126, 0.2205049002979076, 0.2205049002979076, 0.2205049002979076, 0.13035539525948503, 0.13035539525948503, 0.13035539525948503, 0.13004661826897557, 0.13004661826897557, 0.13004661826897557, 0.23428359299710988, 0.23428359299710988, 0.23428359299710988, 0.0009183338010348985, 0.0009183338010348985, 0.0009183338010348985, 0.05246758449728406, 0.05246758449728406, 0.05246758449728406, 0.039718381026713545, 0.039718381026713545, 0.039718381026713545, 0.13948469312652356, 0.13948469312652356, 0.13948469312652356, 0.07244391122092309, 0.07244391122092309, 0.07244391122092309, 0.09168911292619741, 0.09168911292619741, 0.09168911292619741, 0.10671217031380953, 0.10671217031380953, 0.10671217031380953, 0.13353927213950612, 0.13353927213950612, 0.13353927213950612, 0.13399968566250176, 0.13399968566250176, 0.13399968566250176, 0.13347718386912233, 0.13347718386912233, 0.13347718386912233, 0.14789969531562497, 0.14789969531562497, 0.14789969531562497, 0.2322015431586406, 0.2322015431586406, 0.2322015431586406, 0.563163072549367, 0.563163072549367, 0.563163072549367, 0.5597707058416503, 0.5597707058416503, 0.5597707058416503, 0.5560075488152016, 0.5560075488152016, 0.5560075488152016, 0.1296492843485959, 0.1296492843485959, 0.1296492843485959, 0.1552925746034689, 0.1552925746034689, 0.1552925746034689, 0.09755028942073318, 0.09755028942073318, 0.09755028942073318, 0.20364137351952127, 0.20364137351952127, 0.20364137351952127, 0.2282597427192472, 0.2282597427192472, 0.2282597427192472, 0.1607218101208553, 0.1607218101208553, 0.1607218101208553, 0.3862770593664653, 0.3862770593664653, 0.3862770593664653, 0.3319185039459065, 0.3319185039459065, 0.3319185039459065, 0.3995844106298273, 0.3995844106298273, 0.3995844106298273, 0.24532360880322435, 0.24532360880322435, 0.24532360880322435, 0.1943416877261197, 0.1943416877261197, 0.1943416877261197, 0.25080782920615985, 0.25080782920615985, 0.25080782920615985, 0.1969300617525288, 0.1969300617525288, 0.1969300617525288, 0.22802891383902757, 0.22802891383902757, 0.22802891383902757, 0.21727429203520032, 0.21727429203520032, 0.21727429203520032, 0.21743358716614525, 0.21743358716614525, 0.21743358716614525, 0.20439235737631478, 0.20439235737631478, 0.20439235737631478, 0.20771588584520828, 0.20771588584520828, 0.20771588584520828, 0.8007972408654306, 0.8007972408654306, 0.8007972408654306, 0.5975949730317056, 0.5975949730317056, 0.5975949730317056, 0.7612943776208971, 0.7612943776208971, 0.7612943776208971, 0.16825907356267122, 0.16825907356267122, 0.16825907356267122, 0.2078811425747461, 0.2078811425747461, 0.2078811425747461, 0.16525423444349674, 0.16525423444349674, 0.16525423444349674, 0.18437447067970514, 0.18437447067970514, 0.18437447067970514, 0.18614763524435385, 0.18614763524435385, 0.18614763524435385, 0.2046445346082837, 0.2046445346082837, 0.2046445346082837, 0.08973795287247444, 0.08973795287247444, 0.08973795287247444, 0.0887286419618516, 0.0887286419618516, 0.0887286419618516, 0.08805529918613697, 0.08805529918613697, 0.08805529918613697]}, "mutation_prompt": null}
{"id": "8b879d52-f68a-4a53-9089-cd78771cab29", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                self.w = 0.9 - 0.4 * (evaluations / self.budget)  # Dynamically adjust inertia weight\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhance exploitation by dynamically adjusting the inertia weight in PSO.", "configspace": "", "generation": 27, "fitness": 0.1905985125195022, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.437605286148927, 0.437605286148927, 0.437605286148927, 0.4548483346002523, 0.4548483346002523, 0.4548483346002523, 0.4807776073732434, 0.4807776073732434, 0.4807776073732434, 0.10137514983641505, 0.10137514983641505, 0.10137514983641505, 0.049834645307488046, 0.049834645307488046, 0.049834645307488046, 0.02628286255110235, 0.02628286255110235, 0.02628286255110235, 0.0844780636365755, 0.0844780636365755, 0.0844780636365755, 0.08766721836909674, 0.08766721836909674, 0.08766721836909674, 0.08502418371943421, 0.08502418371943421, 0.08502418371943421, 0.07705562381719444, 0.07705562381719444, 0.07705562381719444, 0.07472857816598899, 0.07472857816598899, 0.07472857816598899, 0.08061123337641407, 0.08061123337641407, 0.08061123337641407, 0.975652090494761, 0.975652090494761, 0.975652090494761, 0.9790366890189451, 0.9790366890189451, 0.9790366890189451, 0.9736664876013109, 0.9736664876013109, 0.9736664876013109, 0.281429548677698, 0.281429548677698, 0.281429548677698, 0.19621990574529247, 0.19621990574529247, 0.19621990574529247, 0.2096629104369263, 0.2096629104369263, 0.2096629104369263, 0.18701423690835983, 0.18701423690835983, 0.18701423690835983, 0.18332241035662344, 0.18332241035662344, 0.18332241035662344, 0.1991846570435214, 0.1991846570435214, 0.1991846570435214, 0.12333134526260581, 0.12333134526260581, 0.12333134526260581, 0.13085889400922657, 0.13085889400922657, 0.13085889400922657, 0.12340971554608982, 0.12340971554608982, 0.12340971554608982, 0.019550142587097974, 0.019550142587097974, 0.019550142587097974, 0.10950163133381119, 0.10950163133381119, 0.10950163133381119, 0.1177956983214784, 0.1177956983214784, 0.1177956983214784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00950637459719128, 0.00950637459719128, 0.00950637459719128, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10106885035602009, 0.10106885035602009, 0.10106885035602009, 0.04465698958158304, 0.04465698958158304, 0.04465698958158304, 0.07258536355953182, 0.07258536355953182, 0.07258536355953182, 0.013005801850459853, 0.013005801850459853, 0.013005801850459853, 0.006472194279493304, 0.006472194279493304, 0.006472194279493304, 0.02355355952731175, 0.02355355952731175, 0.02355355952731175, 0.03591986374834777, 0.03591986374834777, 0.03591986374834777, 0.04411588696491331, 0.04411588696491331, 0.04411588696491331, 0.08604786458357705, 0.08604786458357705, 0.08604786458357705, 0.3721972396434816, 0.3721972396434816, 0.3721972396434816, 0.32785117041377165, 0.32785117041377165, 0.32785117041377165, 0.3191748871910909, 0.3191748871910909, 0.3191748871910909, 0.08459005096922123, 0.08459005096922123, 0.08459005096922123, 0.10192835821712865, 0.10192835821712865, 0.10192835821712865, 0.09248598957574816, 0.09248598957574816, 0.09248598957574816, 0.16439007814830298, 0.16439007814830298, 0.16439007814830298, 0.16513681059269092, 0.16513681059269092, 0.16513681059269092, 0.1481488140498476, 0.1481488140498476, 0.1481488140498476, 0.261510016304523, 0.261510016304523, 0.261510016304523, 0.23815083626712874, 0.23815083626712874, 0.23815083626712874, 0.2543841551111472, 0.2543841551111472, 0.2543841551111472, 0.22006955393172245, 0.22006955393172245, 0.22006955393172245, 0.16858121251514335, 0.16858121251514335, 0.16858121251514335, 0.18557368929442108, 0.18557368929442108, 0.18557368929442108, 0.1824320921383441, 0.1824320921383441, 0.1824320921383441, 0.19769733786703114, 0.19769733786703114, 0.19769733786703114, 0.19230837653923083, 0.19230837653923083, 0.19230837653923083, 0.17570374458313687, 0.17570374458313687, 0.17570374458313687, 0.20251793593804024, 0.20251793593804024, 0.20251793593804024, 0.16434101028399106, 0.16434101028399106, 0.16434101028399106, 0.5047688863531201, 0.5047688863531201, 0.5047688863531201, 0.19016039680171526, 0.19016039680171526, 0.19016039680171526, 0.17640693852197142, 0.17640693852197142, 0.17640693852197142, 0.19621505054565602, 0.19621505054565602, 0.19621505054565602, 0.19381752126562424, 0.19381752126562424, 0.19381752126562424, 0.20035116540292175, 0.20035116540292175, 0.20035116540292175, 0.18453816311407745, 0.18453816311407745, 0.18453816311407745, 0.1709701339416373, 0.1709701339416373, 0.1709701339416373, 0.19104830268622186, 0.19104830268622186, 0.19104830268622186, 0.07310600968431136, 0.07310600968431136, 0.07310600968431136, 0.06854543834691518, 0.06854543834691518, 0.06854543834691518, 0.06693363587053258, 0.06693363587053258, 0.06693363587053258]}, "mutation_prompt": null}
{"id": "6457c3ea-e3ee-4322-8095-34b767f4ad08", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                self.w = 0.9 - 0.4 * evaluations/self.budget  # Dynamically decrease inertia weight\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhance exploration by decreasing inertia weight dynamically over time in PSO.", "configspace": "", "generation": 28, "fitness": 0.1905985125195021, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.43760528614889704, 0.43760528614889704, 0.43760528614889704, 0.4548483346002805, 0.4548483346002805, 0.4548483346002805, 0.48077760737330144, 0.48077760737330144, 0.48077760737330144, 0.10137514983634555, 0.10137514983634555, 0.10137514983634555, 0.049834645307449854, 0.049834645307449854, 0.049834645307449854, 0.02628286255110235, 0.02628286255110235, 0.02628286255110235, 0.08447806363658816, 0.08447806363658816, 0.08447806363658816, 0.08766721836909674, 0.08766721836909674, 0.08766721836909674, 0.08502418371943421, 0.08502418371943421, 0.08502418371943421, 0.07705562381719444, 0.07705562381719444, 0.07705562381719444, 0.07472857816598899, 0.07472857816598899, 0.07472857816598899, 0.08061123337641407, 0.08061123337641407, 0.08061123337641407, 0.975652090494761, 0.975652090494761, 0.975652090494761, 0.9790366890189451, 0.9790366890189451, 0.9790366890189451, 0.9736664876013109, 0.9736664876013109, 0.9736664876013109, 0.281429548677698, 0.281429548677698, 0.281429548677698, 0.1962199057452797, 0.1962199057452797, 0.1962199057452797, 0.2096629104369263, 0.2096629104369263, 0.2096629104369263, 0.18701423690835983, 0.18701423690835983, 0.18701423690835983, 0.18332241035662344, 0.18332241035662344, 0.18332241035662344, 0.1991846570435214, 0.1991846570435214, 0.1991846570435214, 0.12333134526260581, 0.12333134526260581, 0.12333134526260581, 0.13085889400922657, 0.13085889400922657, 0.13085889400922657, 0.12340971554608982, 0.12340971554608982, 0.12340971554608982, 0.019550142587097974, 0.019550142587097974, 0.019550142587097974, 0.10950163133379887, 0.10950163133379887, 0.10950163133379887, 0.1177956983214784, 0.1177956983214784, 0.1177956983214784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009506374597191058, 0.009506374597191058, 0.009506374597191058, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10106885035602009, 0.10106885035602009, 0.10106885035602009, 0.04465698958158304, 0.04465698958158304, 0.04465698958158304, 0.07258536355953182, 0.07258536355953182, 0.07258536355953182, 0.013005801850459853, 0.013005801850459853, 0.013005801850459853, 0.006472194279493304, 0.006472194279493304, 0.006472194279493304, 0.023553559527312085, 0.023553559527312085, 0.023553559527312085, 0.03591986374834666, 0.03591986374834666, 0.03591986374834666, 0.04411588696491331, 0.04411588696491331, 0.04411588696491331, 0.08604786458360791, 0.08604786458360791, 0.08604786458360791, 0.3721972396434816, 0.3721972396434816, 0.3721972396434816, 0.3278511704137629, 0.3278511704137629, 0.3278511704137629, 0.31917488719109766, 0.31917488719109766, 0.31917488719109766, 0.08459005096922123, 0.08459005096922123, 0.08459005096922123, 0.10192835821712865, 0.10192835821712865, 0.10192835821712865, 0.09248598957574816, 0.09248598957574816, 0.09248598957574816, 0.164390078148123, 0.164390078148123, 0.164390078148123, 0.16513681059269092, 0.16513681059269092, 0.16513681059269092, 0.1481488140498476, 0.1481488140498476, 0.1481488140498476, 0.26151001630457626, 0.26151001630457626, 0.26151001630457626, 0.23815083626708955, 0.23815083626708955, 0.23815083626708955, 0.2543841551111472, 0.2543841551111472, 0.2543841551111472, 0.220069553931728, 0.220069553931728, 0.220069553931728, 0.16858121251522085, 0.16858121251522085, 0.16858121251522085, 0.18557368929442108, 0.18557368929442108, 0.18557368929442108, 0.18243209213840306, 0.18243209213840306, 0.18243209213840306, 0.19769733786703114, 0.19769733786703114, 0.19769733786703114, 0.19230837653923083, 0.19230837653923083, 0.19230837653923083, 0.17570374458313687, 0.17570374458313687, 0.17570374458313687, 0.20251793593804024, 0.20251793593804024, 0.20251793593804024, 0.16434101028399106, 0.16434101028399106, 0.16434101028399106, 0.5047688863531723, 0.5047688863531723, 0.5047688863531723, 0.19016039680171526, 0.19016039680171526, 0.19016039680171526, 0.17640693852197142, 0.17640693852197142, 0.17640693852197142, 0.19621505054565602, 0.19621505054565602, 0.19621505054565602, 0.19381752126562424, 0.19381752126562424, 0.19381752126562424, 0.20035116540292175, 0.20035116540292175, 0.20035116540292175, 0.18453816311407745, 0.18453816311407745, 0.18453816311407745, 0.1709701339416373, 0.1709701339416373, 0.1709701339416373, 0.19104830268622186, 0.19104830268622186, 0.19104830268622186, 0.07310600968431136, 0.07310600968431136, 0.07310600968431136, 0.06854543834691518, 0.06854543834691518, 0.06854543834691518, 0.06693363587053258, 0.06693363587053258, 0.06693363587053258]}, "mutation_prompt": null}
{"id": "53348751-74f7-4683-8599-5640af0abacd", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the inertia weight dynamically\n                self.w = 0.9 - evaluations/self.budget * 0.5\n                self.c1 = 2.7 - evaluations/self.budget * 1.5\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Improved exploitation by adjusting the inertia weight dynamically in the PSO phase to enhance convergence.", "configspace": "", "generation": 29, "fitness": 0.20577492177781914, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.44758853118755115, 0.44758853118755115, 0.44758853118755115, 0.5466156977500924, 0.5466156977500924, 0.5466156977500924, 0.4807008716687816, 0.4807008716687816, 0.4807008716687816, 0.12366888526057884, 0.12366888526057884, 0.12366888526057884, 0.17767300616067727, 0.17767300616067727, 0.17767300616067727, 0.2065798473130781, 0.2065798473130781, 0.2065798473130781, 0.0988579180126189, 0.0988579180126189, 0.0988579180126189, 0.1081361840076337, 0.1081361840076337, 0.1081361840076337, 0.09963585736028491, 0.09963585736028491, 0.09963585736028491, 0.08109380353766449, 0.08109380353766449, 0.08109380353766449, 0.08519866607291138, 0.08519866607291138, 0.08519866607291138, 0.09163140126409886, 0.09163140126409886, 0.09163140126409886, 0.975651045096156, 0.975651045096156, 0.975651045096156, 0.9790362992505957, 0.9790362992505957, 0.9790362992505957, 0.9736668129840342, 0.9736668129840342, 0.9736668129840342, 0.2913679120706736, 0.2913679120706736, 0.2913679120706736, 0.2549019415282592, 0.2549019415282592, 0.2549019415282592, 0.2595875451798102, 0.2595875451798102, 0.2595875451798102, 0.24975608698443053, 0.24975608698443053, 0.24975608698443053, 0.16938114229449852, 0.16938114229449852, 0.16938114229449852, 0.16184508959737798, 0.16184508959737798, 0.16184508959737798, 0.09441635482944422, 0.09441635482944422, 0.09441635482944422, 0.19078210425831343, 0.19078210425831343, 0.19078210425831343, 0.19028496913239568, 0.19028496913239568, 0.19028496913239568, 0.042746067586211356, 0.042746067586211356, 0.042746067586211356, 0.11527350072230225, 0.11527350072230225, 0.11527350072230225, 0.12431717607551385, 0.12431717607551385, 0.12431717607551385, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0787400252107916, 0.0787400252107916, 0.0787400252107916, 0.06907151679223622, 0.06907151679223622, 0.06907151679223622, 0.06435206586822972, 0.06435206586822972, 0.06435206586822972, 0.017864077197967676, 0.017864077197967676, 0.017864077197967676, 0.06176875968303708, 0.06176875968303708, 0.06176875968303708, 0.03499618171061425, 0.03499618171061425, 0.03499618171061425, 0.0370664250550683, 0.0370664250550683, 0.0370664250550683, 0.0891172103226352, 0.0891172103226352, 0.0891172103226352, 0.03892962365755337, 0.03892962365755337, 0.03892962365755337, 0.3835547593022345, 0.3835547593022345, 0.3835547593022345, 0.39393277978697494, 0.39393277978697494, 0.39393277978697494, 0.3793510952057222, 0.3793510952057222, 0.3793510952057222, 0.08424628248284693, 0.08424628248284693, 0.08424628248284693, 0.09840668691393673, 0.09840668691393673, 0.09840668691393673, 0.10339739159368966, 0.10339739159368966, 0.10339739159368966, 0.17211817624461512, 0.17211817624461512, 0.17211817624461512, 0.1863635839168436, 0.1863635839168436, 0.1863635839168436, 0.15120320850345137, 0.15120320850345137, 0.15120320850345137, 0.28121285095416215, 0.28121285095416215, 0.28121285095416215, 0.26219718151078497, 0.26219718151078497, 0.26219718151078497, 0.2653662357826615, 0.2653662357826615, 0.2653662357826615, 0.18477563388248686, 0.18477563388248686, 0.18477563388248686, 0.20250773159947, 0.20250773159947, 0.20250773159947, 0.1756798866194491, 0.1756798866194491, 0.1756798866194491, 0.17662582065245247, 0.17662582065245247, 0.17662582065245247, 0.1802211752050622, 0.1802211752050622, 0.1802211752050622, 0.1862266468019117, 0.1862266468019117, 0.1862266468019117, 0.18178382476566035, 0.18178382476566035, 0.18178382476566035, 0.1887550617696726, 0.1887550617696726, 0.1887550617696726, 0.20987439864355828, 0.20987439864355828, 0.20987439864355828, 0.5613909862669498, 0.5613909862669498, 0.5613909862669498, 0.1511788111992819, 0.1511788111992819, 0.1511788111992819, 0.1791580623678275, 0.1791580623678275, 0.1791580623678275, 0.19193715196545014, 0.19193715196545014, 0.19193715196545014, 0.19660007486030728, 0.19660007486030728, 0.19660007486030728, 0.1857322973189689, 0.1857322973189689, 0.1857322973189689, 0.195319602465868, 0.195319602465868, 0.195319602465868, 0.19033097172020963, 0.19033097172020963, 0.19033097172020963, 0.1756322862540154, 0.1756322862540154, 0.1756322862540154, 0.0709170233676294, 0.0709170233676294, 0.0709170233676294, 0.07582857042875879, 0.07582857042875879, 0.07582857042875879, 0.08136751496594352, 0.08136751496594352, 0.08136751496594352]}, "mutation_prompt": null}
{"id": "d53b5629-2b7a-48b4-a08c-a6cfd1bc7585", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                self.w = 0.9 - evaluations/self.budget * 0.4  # Dynamically adjust inertia weight\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Improved convergence speed by dynamically adjusting inertia weight `w` in PSO as the budget is consumed.", "configspace": "", "generation": 30, "fitness": 0.1905985125195022, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.437605286148927, 0.437605286148927, 0.437605286148927, 0.4548483346002523, 0.4548483346002523, 0.4548483346002523, 0.4807776073732434, 0.4807776073732434, 0.4807776073732434, 0.10137514983641505, 0.10137514983641505, 0.10137514983641505, 0.049834645307488046, 0.049834645307488046, 0.049834645307488046, 0.02628286255110235, 0.02628286255110235, 0.02628286255110235, 0.0844780636365755, 0.0844780636365755, 0.0844780636365755, 0.08766721836909674, 0.08766721836909674, 0.08766721836909674, 0.08502418371943421, 0.08502418371943421, 0.08502418371943421, 0.07705562381719444, 0.07705562381719444, 0.07705562381719444, 0.07472857816598899, 0.07472857816598899, 0.07472857816598899, 0.08061123337641407, 0.08061123337641407, 0.08061123337641407, 0.975652090494761, 0.975652090494761, 0.975652090494761, 0.9790366890189451, 0.9790366890189451, 0.9790366890189451, 0.9736664876013109, 0.9736664876013109, 0.9736664876013109, 0.281429548677698, 0.281429548677698, 0.281429548677698, 0.19621990574529247, 0.19621990574529247, 0.19621990574529247, 0.2096629104369263, 0.2096629104369263, 0.2096629104369263, 0.18701423690835983, 0.18701423690835983, 0.18701423690835983, 0.18332241035662344, 0.18332241035662344, 0.18332241035662344, 0.1991846570435214, 0.1991846570435214, 0.1991846570435214, 0.12333134526260581, 0.12333134526260581, 0.12333134526260581, 0.13085889400922657, 0.13085889400922657, 0.13085889400922657, 0.12340971554608982, 0.12340971554608982, 0.12340971554608982, 0.019550142587097974, 0.019550142587097974, 0.019550142587097974, 0.10950163133381119, 0.10950163133381119, 0.10950163133381119, 0.1177956983214784, 0.1177956983214784, 0.1177956983214784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00950637459719128, 0.00950637459719128, 0.00950637459719128, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10106885035602009, 0.10106885035602009, 0.10106885035602009, 0.04465698958158304, 0.04465698958158304, 0.04465698958158304, 0.07258536355953182, 0.07258536355953182, 0.07258536355953182, 0.013005801850459853, 0.013005801850459853, 0.013005801850459853, 0.006472194279493304, 0.006472194279493304, 0.006472194279493304, 0.02355355952731175, 0.02355355952731175, 0.02355355952731175, 0.03591986374834777, 0.03591986374834777, 0.03591986374834777, 0.04411588696491331, 0.04411588696491331, 0.04411588696491331, 0.08604786458357705, 0.08604786458357705, 0.08604786458357705, 0.3721972396434816, 0.3721972396434816, 0.3721972396434816, 0.32785117041377165, 0.32785117041377165, 0.32785117041377165, 0.3191748871910909, 0.3191748871910909, 0.3191748871910909, 0.08459005096922123, 0.08459005096922123, 0.08459005096922123, 0.10192835821712865, 0.10192835821712865, 0.10192835821712865, 0.09248598957574816, 0.09248598957574816, 0.09248598957574816, 0.16439007814830298, 0.16439007814830298, 0.16439007814830298, 0.16513681059269092, 0.16513681059269092, 0.16513681059269092, 0.1481488140498476, 0.1481488140498476, 0.1481488140498476, 0.261510016304523, 0.261510016304523, 0.261510016304523, 0.23815083626712874, 0.23815083626712874, 0.23815083626712874, 0.2543841551111472, 0.2543841551111472, 0.2543841551111472, 0.22006955393172245, 0.22006955393172245, 0.22006955393172245, 0.16858121251514335, 0.16858121251514335, 0.16858121251514335, 0.18557368929442108, 0.18557368929442108, 0.18557368929442108, 0.1824320921383441, 0.1824320921383441, 0.1824320921383441, 0.19769733786703114, 0.19769733786703114, 0.19769733786703114, 0.19230837653923083, 0.19230837653923083, 0.19230837653923083, 0.17570374458313687, 0.17570374458313687, 0.17570374458313687, 0.20251793593804024, 0.20251793593804024, 0.20251793593804024, 0.16434101028399106, 0.16434101028399106, 0.16434101028399106, 0.5047688863531201, 0.5047688863531201, 0.5047688863531201, 0.19016039680171526, 0.19016039680171526, 0.19016039680171526, 0.17640693852197142, 0.17640693852197142, 0.17640693852197142, 0.19621505054565602, 0.19621505054565602, 0.19621505054565602, 0.19381752126562424, 0.19381752126562424, 0.19381752126562424, 0.20035116540292175, 0.20035116540292175, 0.20035116540292175, 0.18453816311407745, 0.18453816311407745, 0.18453816311407745, 0.1709701339416373, 0.1709701339416373, 0.1709701339416373, 0.19104830268622186, 0.19104830268622186, 0.19104830268622186, 0.07310600968431136, 0.07310600968431136, 0.07310600968431136, 0.06854543834691518, 0.06854543834691518, 0.06854543834691518, 0.06693363587053258, 0.06693363587053258, 0.06693363587053258]}, "mutation_prompt": null}
{"id": "320e187b-e3fb-4e4b-9ec3-8e0103509b6b", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.6  # Inertia weight for PSO, slight increase for exploration\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced exploration by slightly increasing the inertia weight in PSO.", "configspace": "", "generation": 31, "fitness": 0.2797633581038645, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.23.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.7749319254847502, 0.7749319254847502, 0.7749319254847502, 0.7587484578443413, 0.7587484578443413, 0.7587484578443413, 0.7978635231988749, 0.7978635231988749, 0.7978635231988749, 0.4439637678128827, 0.4439637678128827, 0.4439637678128827, 0.4445003520696983, 0.4445003520696983, 0.4445003520696983, 0.2942508039327506, 0.2942508039327506, 0.2942508039327506, 0.13014604240515093, 0.13014604240515093, 0.13014604240515093, 0.1497182183100938, 0.1497182183100938, 0.1497182183100938, 0.13663223051302198, 0.13663223051302198, 0.13663223051302198, 0.13186116070199716, 0.13186116070199716, 0.13186116070199716, 0.09731148283043822, 0.09731148283043822, 0.09731148283043822, 0.11394990384542703, 0.11394990384542703, 0.11394990384542703, 0.9734237863293943, 0.9734237863293943, 0.9734237863293943, 0.9739704831338388, 0.9739704831338388, 0.9739704831338388, 0.9702329832334816, 0.9702329832334816, 0.9702329832334816, 0.44156411476993496, 0.44156411476993496, 0.44156411476993496, 0.4107148703423873, 0.4107148703423873, 0.4107148703423873, 0.4671670964483595, 0.4671670964483595, 0.4671670964483595, 0.5370005212694076, 0.5370005212694076, 0.5370005212694076, 0.21193338043049492, 0.21193338043049492, 0.21193338043049492, 0.2294670974525964, 0.2294670974525964, 0.2294670974525964, 0.1788270761033829, 0.1788270761033829, 0.1788270761033829, 0.186727006497306, 0.186727006497306, 0.186727006497306, 0.17891800136124925, 0.17891800136124925, 0.17891800136124925, 0.189526929226139, 0.189526929226139, 0.189526929226139, 0.19433655004047012, 0.19433655004047012, 0.19433655004047012, 0.21524852184964094, 0.21524852184964094, 0.21524852184964094, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006557029308984941, 0.006557029308984941, 0.006557029308984941, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08742355152447412, 0.08742355152447412, 0.08742355152447412, 0.05324146281287723, 0.05324146281287723, 0.05324146281287723, 0.0545836430851625, 0.0545836430851625, 0.0545836430851625, 0.1395688402667321, 0.1395688402667321, 0.1395688402667321, 0.06693852141994228, 0.06693852141994228, 0.06693852141994228, 0.22134018702291092, 0.22134018702291092, 0.22134018702291092, 0.16964127007509866, 0.16964127007509866, 0.16964127007509866, 0.10854765984722703, 0.10854765984722703, 0.10854765984722703, 0.056063385569116164, 0.056063385569116164, 0.056063385569116164, 0.5065431708667353, 0.5065431708667353, 0.5065431708667353, 0.4937063131907611, 0.4937063131907611, 0.4937063131907611, 0.5123426762216357, 0.5123426762216357, 0.5123426762216357, 0.1606868198784447, 0.1606868198784447, 0.1606868198784447, 0.13735228368598096, 0.13735228368598096, 0.13735228368598096, 0.1117564102585793, 0.1117564102585793, 0.1117564102585793, 0.23130743993398406, 0.23130743993398406, 0.23130743993398406, 0.18278489640456408, 0.18278489640456408, 0.18278489640456408, 0.3655003287552415, 0.3655003287552415, 0.3655003287552415, 0.3347281897822797, 0.3347281897822797, 0.3347281897822797, 0.3609055168021359, 0.3609055168021359, 0.3609055168021359, 0.4097281005190886, 0.4097281005190886, 0.4097281005190886, 0.29198801442616706, 0.29198801442616706, 0.29198801442616706, 0.22406921661621526, 0.22406921661621526, 0.22406921661621526, 0.20054824237285573, 0.20054824237285573, 0.20054824237285573, 0.18604405838175953, 0.18604405838175953, 0.18604405838175953, 0.21032800172109323, 0.21032800172109323, 0.21032800172109323, 0.19941601620425142, 0.19941601620425142, 0.19941601620425142, 0.18669218143741628, 0.18669218143741628, 0.18669218143741628, 0.23359481647632352, 0.23359481647632352, 0.23359481647632352, 0.3858506879691199, 0.3858506879691199, 0.3858506879691199, 0.8596568202874606, 0.8596568202874606, 0.8596568202874606, 0.16336119700933072, 0.16336119700933072, 0.16336119700933072, 0.16080004086557476, 0.16080004086557476, 0.16080004086557476, 0.16674224910528046, 0.16674224910528046, 0.16674224910528046, 0.20539043656553735, 0.20539043656553735, 0.20539043656553735, 0.19388040372637227, 0.19388040372637227, 0.19388040372637227, 0.18939349308545184, 0.18939349308545184, 0.18939349308545184, 0.20059231881802364, 0.20059231881802364, 0.20059231881802364, 0.19243905393939909, 0.19243905393939909, 0.19243905393939909, 0.0781173685526273, 0.0781173685526273, 0.0781173685526273, 0.07776410995802474, 0.07776410995802474, 0.07776410995802474, 0.13190907129049245, 0.13190907129049245, 0.13190907129049245]}, "mutation_prompt": null}
{"id": "09ed8d36-f0f8-4e55-9db7-c082959a261a", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                # Adjusted inertia weight for better exploration\n                self.w = 0.9 - 0.4 * (evaluations / self.budget)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhance exploration by linearly decreasing the inertia weight in the PSO step.", "configspace": "", "generation": 32, "fitness": 0.1905985125195022, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.437605286148927, 0.437605286148927, 0.437605286148927, 0.4548483346002523, 0.4548483346002523, 0.4548483346002523, 0.4807776073732434, 0.4807776073732434, 0.4807776073732434, 0.10137514983641505, 0.10137514983641505, 0.10137514983641505, 0.049834645307488046, 0.049834645307488046, 0.049834645307488046, 0.02628286255110235, 0.02628286255110235, 0.02628286255110235, 0.0844780636365755, 0.0844780636365755, 0.0844780636365755, 0.08766721836909674, 0.08766721836909674, 0.08766721836909674, 0.08502418371943421, 0.08502418371943421, 0.08502418371943421, 0.07705562381719444, 0.07705562381719444, 0.07705562381719444, 0.07472857816598899, 0.07472857816598899, 0.07472857816598899, 0.08061123337641407, 0.08061123337641407, 0.08061123337641407, 0.975652090494761, 0.975652090494761, 0.975652090494761, 0.9790366890189451, 0.9790366890189451, 0.9790366890189451, 0.9736664876013109, 0.9736664876013109, 0.9736664876013109, 0.281429548677698, 0.281429548677698, 0.281429548677698, 0.19621990574529247, 0.19621990574529247, 0.19621990574529247, 0.2096629104369263, 0.2096629104369263, 0.2096629104369263, 0.18701423690835983, 0.18701423690835983, 0.18701423690835983, 0.18332241035662344, 0.18332241035662344, 0.18332241035662344, 0.1991846570435214, 0.1991846570435214, 0.1991846570435214, 0.12333134526260581, 0.12333134526260581, 0.12333134526260581, 0.13085889400922657, 0.13085889400922657, 0.13085889400922657, 0.12340971554608982, 0.12340971554608982, 0.12340971554608982, 0.019550142587097974, 0.019550142587097974, 0.019550142587097974, 0.10950163133381119, 0.10950163133381119, 0.10950163133381119, 0.1177956983214784, 0.1177956983214784, 0.1177956983214784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00950637459719128, 0.00950637459719128, 0.00950637459719128, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10106885035602009, 0.10106885035602009, 0.10106885035602009, 0.04465698958158304, 0.04465698958158304, 0.04465698958158304, 0.07258536355953182, 0.07258536355953182, 0.07258536355953182, 0.013005801850459853, 0.013005801850459853, 0.013005801850459853, 0.006472194279493304, 0.006472194279493304, 0.006472194279493304, 0.02355355952731175, 0.02355355952731175, 0.02355355952731175, 0.03591986374834777, 0.03591986374834777, 0.03591986374834777, 0.04411588696491331, 0.04411588696491331, 0.04411588696491331, 0.08604786458357705, 0.08604786458357705, 0.08604786458357705, 0.3721972396434816, 0.3721972396434816, 0.3721972396434816, 0.32785117041377165, 0.32785117041377165, 0.32785117041377165, 0.3191748871910909, 0.3191748871910909, 0.3191748871910909, 0.08459005096922123, 0.08459005096922123, 0.08459005096922123, 0.10192835821712865, 0.10192835821712865, 0.10192835821712865, 0.09248598957574816, 0.09248598957574816, 0.09248598957574816, 0.16439007814830298, 0.16439007814830298, 0.16439007814830298, 0.16513681059269092, 0.16513681059269092, 0.16513681059269092, 0.1481488140498476, 0.1481488140498476, 0.1481488140498476, 0.261510016304523, 0.261510016304523, 0.261510016304523, 0.23815083626712874, 0.23815083626712874, 0.23815083626712874, 0.2543841551111472, 0.2543841551111472, 0.2543841551111472, 0.22006955393172245, 0.22006955393172245, 0.22006955393172245, 0.16858121251514335, 0.16858121251514335, 0.16858121251514335, 0.18557368929442108, 0.18557368929442108, 0.18557368929442108, 0.1824320921383441, 0.1824320921383441, 0.1824320921383441, 0.19769733786703114, 0.19769733786703114, 0.19769733786703114, 0.19230837653923083, 0.19230837653923083, 0.19230837653923083, 0.17570374458313687, 0.17570374458313687, 0.17570374458313687, 0.20251793593804024, 0.20251793593804024, 0.20251793593804024, 0.16434101028399106, 0.16434101028399106, 0.16434101028399106, 0.5047688863531201, 0.5047688863531201, 0.5047688863531201, 0.19016039680171526, 0.19016039680171526, 0.19016039680171526, 0.17640693852197142, 0.17640693852197142, 0.17640693852197142, 0.19621505054565602, 0.19621505054565602, 0.19621505054565602, 0.19381752126562424, 0.19381752126562424, 0.19381752126562424, 0.20035116540292175, 0.20035116540292175, 0.20035116540292175, 0.18453816311407745, 0.18453816311407745, 0.18453816311407745, 0.1709701339416373, 0.1709701339416373, 0.1709701339416373, 0.19104830268622186, 0.19104830268622186, 0.19104830268622186, 0.07310600968431136, 0.07310600968431136, 0.07310600968431136, 0.06854543834691518, 0.06854543834691518, 0.06854543834691518, 0.06693363587053258, 0.06693363587053258, 0.06693363587053258]}, "mutation_prompt": null}
{"id": "95c63bbf-1b98-4be8-a410-bad0df24228b", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Initial inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.w = 0.9 - evaluations/self.budget * 0.4  # Adaptive inertia weight\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced velocity update by introducing adaptive inertia weight in PSO.", "configspace": "", "generation": 33, "fitness": 0.1905985125195022, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.437605286148927, 0.437605286148927, 0.437605286148927, 0.4548483346002523, 0.4548483346002523, 0.4548483346002523, 0.4807776073732434, 0.4807776073732434, 0.4807776073732434, 0.10137514983641505, 0.10137514983641505, 0.10137514983641505, 0.049834645307488046, 0.049834645307488046, 0.049834645307488046, 0.02628286255110235, 0.02628286255110235, 0.02628286255110235, 0.0844780636365755, 0.0844780636365755, 0.0844780636365755, 0.08766721836909674, 0.08766721836909674, 0.08766721836909674, 0.08502418371943421, 0.08502418371943421, 0.08502418371943421, 0.07705562381719444, 0.07705562381719444, 0.07705562381719444, 0.07472857816598899, 0.07472857816598899, 0.07472857816598899, 0.08061123337641407, 0.08061123337641407, 0.08061123337641407, 0.975652090494761, 0.975652090494761, 0.975652090494761, 0.9790366890189451, 0.9790366890189451, 0.9790366890189451, 0.9736664876013109, 0.9736664876013109, 0.9736664876013109, 0.281429548677698, 0.281429548677698, 0.281429548677698, 0.19621990574529247, 0.19621990574529247, 0.19621990574529247, 0.2096629104369263, 0.2096629104369263, 0.2096629104369263, 0.18701423690835983, 0.18701423690835983, 0.18701423690835983, 0.18332241035662344, 0.18332241035662344, 0.18332241035662344, 0.1991846570435214, 0.1991846570435214, 0.1991846570435214, 0.12333134526260581, 0.12333134526260581, 0.12333134526260581, 0.13085889400922657, 0.13085889400922657, 0.13085889400922657, 0.12340971554608982, 0.12340971554608982, 0.12340971554608982, 0.019550142587097974, 0.019550142587097974, 0.019550142587097974, 0.10950163133381119, 0.10950163133381119, 0.10950163133381119, 0.1177956983214784, 0.1177956983214784, 0.1177956983214784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00950637459719128, 0.00950637459719128, 0.00950637459719128, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10106885035602009, 0.10106885035602009, 0.10106885035602009, 0.04465698958158304, 0.04465698958158304, 0.04465698958158304, 0.07258536355953182, 0.07258536355953182, 0.07258536355953182, 0.013005801850459853, 0.013005801850459853, 0.013005801850459853, 0.006472194279493304, 0.006472194279493304, 0.006472194279493304, 0.02355355952731175, 0.02355355952731175, 0.02355355952731175, 0.03591986374834777, 0.03591986374834777, 0.03591986374834777, 0.04411588696491331, 0.04411588696491331, 0.04411588696491331, 0.08604786458357705, 0.08604786458357705, 0.08604786458357705, 0.3721972396434816, 0.3721972396434816, 0.3721972396434816, 0.32785117041377165, 0.32785117041377165, 0.32785117041377165, 0.3191748871910909, 0.3191748871910909, 0.3191748871910909, 0.08459005096922123, 0.08459005096922123, 0.08459005096922123, 0.10192835821712865, 0.10192835821712865, 0.10192835821712865, 0.09248598957574816, 0.09248598957574816, 0.09248598957574816, 0.16439007814830298, 0.16439007814830298, 0.16439007814830298, 0.16513681059269092, 0.16513681059269092, 0.16513681059269092, 0.1481488140498476, 0.1481488140498476, 0.1481488140498476, 0.261510016304523, 0.261510016304523, 0.261510016304523, 0.23815083626712874, 0.23815083626712874, 0.23815083626712874, 0.2543841551111472, 0.2543841551111472, 0.2543841551111472, 0.22006955393172245, 0.22006955393172245, 0.22006955393172245, 0.16858121251514335, 0.16858121251514335, 0.16858121251514335, 0.18557368929442108, 0.18557368929442108, 0.18557368929442108, 0.1824320921383441, 0.1824320921383441, 0.1824320921383441, 0.19769733786703114, 0.19769733786703114, 0.19769733786703114, 0.19230837653923083, 0.19230837653923083, 0.19230837653923083, 0.17570374458313687, 0.17570374458313687, 0.17570374458313687, 0.20251793593804024, 0.20251793593804024, 0.20251793593804024, 0.16434101028399106, 0.16434101028399106, 0.16434101028399106, 0.5047688863531201, 0.5047688863531201, 0.5047688863531201, 0.19016039680171526, 0.19016039680171526, 0.19016039680171526, 0.17640693852197142, 0.17640693852197142, 0.17640693852197142, 0.19621505054565602, 0.19621505054565602, 0.19621505054565602, 0.19381752126562424, 0.19381752126562424, 0.19381752126562424, 0.20035116540292175, 0.20035116540292175, 0.20035116540292175, 0.18453816311407745, 0.18453816311407745, 0.18453816311407745, 0.1709701339416373, 0.1709701339416373, 0.1709701339416373, 0.19104830268622186, 0.19104830268622186, 0.19104830268622186, 0.07310600968431136, 0.07310600968431136, 0.07310600968431136, 0.06854543834691518, 0.06854543834691518, 0.06854543834691518, 0.06693363587053258, 0.06693363587053258, 0.06693363587053258]}, "mutation_prompt": null}
{"id": "de9776f5-5eac-49fa-8184-e22888b92ebf", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.9  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = ((0.9 - evaluations/self.budget * 0.4) * velocities[i] +  # Dynamic inertia weight\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Improved AdaptiveHybridGA by dynamically adjusting the inertia weight of PSO for better exploration and exploitation balance.", "configspace": "", "generation": 34, "fitness": 0.1905985125195022, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.437605286148927, 0.437605286148927, 0.437605286148927, 0.4548483346002523, 0.4548483346002523, 0.4548483346002523, 0.4807776073732434, 0.4807776073732434, 0.4807776073732434, 0.10137514983641505, 0.10137514983641505, 0.10137514983641505, 0.049834645307488046, 0.049834645307488046, 0.049834645307488046, 0.02628286255110235, 0.02628286255110235, 0.02628286255110235, 0.0844780636365755, 0.0844780636365755, 0.0844780636365755, 0.08766721836909674, 0.08766721836909674, 0.08766721836909674, 0.08502418371943421, 0.08502418371943421, 0.08502418371943421, 0.07705562381719444, 0.07705562381719444, 0.07705562381719444, 0.07472857816598899, 0.07472857816598899, 0.07472857816598899, 0.08061123337641407, 0.08061123337641407, 0.08061123337641407, 0.975652090494761, 0.975652090494761, 0.975652090494761, 0.9790366890189451, 0.9790366890189451, 0.9790366890189451, 0.9736664876013109, 0.9736664876013109, 0.9736664876013109, 0.281429548677698, 0.281429548677698, 0.281429548677698, 0.19621990574529247, 0.19621990574529247, 0.19621990574529247, 0.2096629104369263, 0.2096629104369263, 0.2096629104369263, 0.18701423690835983, 0.18701423690835983, 0.18701423690835983, 0.18332241035662344, 0.18332241035662344, 0.18332241035662344, 0.1991846570435214, 0.1991846570435214, 0.1991846570435214, 0.12333134526260581, 0.12333134526260581, 0.12333134526260581, 0.13085889400922657, 0.13085889400922657, 0.13085889400922657, 0.12340971554608982, 0.12340971554608982, 0.12340971554608982, 0.019550142587097974, 0.019550142587097974, 0.019550142587097974, 0.10950163133381119, 0.10950163133381119, 0.10950163133381119, 0.1177956983214784, 0.1177956983214784, 0.1177956983214784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00950637459719128, 0.00950637459719128, 0.00950637459719128, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10106885035602009, 0.10106885035602009, 0.10106885035602009, 0.04465698958158304, 0.04465698958158304, 0.04465698958158304, 0.07258536355953182, 0.07258536355953182, 0.07258536355953182, 0.013005801850459853, 0.013005801850459853, 0.013005801850459853, 0.006472194279493304, 0.006472194279493304, 0.006472194279493304, 0.02355355952731175, 0.02355355952731175, 0.02355355952731175, 0.03591986374834777, 0.03591986374834777, 0.03591986374834777, 0.04411588696491331, 0.04411588696491331, 0.04411588696491331, 0.08604786458357705, 0.08604786458357705, 0.08604786458357705, 0.3721972396434816, 0.3721972396434816, 0.3721972396434816, 0.32785117041377165, 0.32785117041377165, 0.32785117041377165, 0.3191748871910909, 0.3191748871910909, 0.3191748871910909, 0.08459005096922123, 0.08459005096922123, 0.08459005096922123, 0.10192835821712865, 0.10192835821712865, 0.10192835821712865, 0.09248598957574816, 0.09248598957574816, 0.09248598957574816, 0.16439007814830298, 0.16439007814830298, 0.16439007814830298, 0.16513681059269092, 0.16513681059269092, 0.16513681059269092, 0.1481488140498476, 0.1481488140498476, 0.1481488140498476, 0.261510016304523, 0.261510016304523, 0.261510016304523, 0.23815083626712874, 0.23815083626712874, 0.23815083626712874, 0.2543841551111472, 0.2543841551111472, 0.2543841551111472, 0.22006955393172245, 0.22006955393172245, 0.22006955393172245, 0.16858121251514335, 0.16858121251514335, 0.16858121251514335, 0.18557368929442108, 0.18557368929442108, 0.18557368929442108, 0.1824320921383441, 0.1824320921383441, 0.1824320921383441, 0.19769733786703114, 0.19769733786703114, 0.19769733786703114, 0.19230837653923083, 0.19230837653923083, 0.19230837653923083, 0.17570374458313687, 0.17570374458313687, 0.17570374458313687, 0.20251793593804024, 0.20251793593804024, 0.20251793593804024, 0.16434101028399106, 0.16434101028399106, 0.16434101028399106, 0.5047688863531201, 0.5047688863531201, 0.5047688863531201, 0.19016039680171526, 0.19016039680171526, 0.19016039680171526, 0.17640693852197142, 0.17640693852197142, 0.17640693852197142, 0.19621505054565602, 0.19621505054565602, 0.19621505054565602, 0.19381752126562424, 0.19381752126562424, 0.19381752126562424, 0.20035116540292175, 0.20035116540292175, 0.20035116540292175, 0.18453816311407745, 0.18453816311407745, 0.18453816311407745, 0.1709701339416373, 0.1709701339416373, 0.1709701339416373, 0.19104830268622186, 0.19104830268622186, 0.19104830268622186, 0.07310600968431136, 0.07310600968431136, 0.07310600968431136, 0.06854543834691518, 0.06854543834691518, 0.06854543834691518, 0.06693363587053258, 0.06693363587053258, 0.06693363587053258]}, "mutation_prompt": null}
{"id": "cadf4b81-9bf0-43ae-a3e9-ae33c25c9712", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-2, 2, (self.pop_size, self.dim))  # Changed here\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced exploration by increasing the range of initial velocities in PSO.", "configspace": "", "generation": 35, "fitness": 0.3286610855315044, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.26.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.8435158022527977, 0.8435158022527977, 0.8435158022527977, 0.8516622017550641, 0.8516622017550641, 0.8516622017550641, 0.8466074700312376, 0.8466074700312376, 0.8466074700312376, 0.6312635903599708, 0.6312635903599708, 0.6312635903599708, 0.5805379718924969, 0.5805379718924969, 0.5805379718924969, 0.6326822166793538, 0.6326822166793538, 0.6326822166793538, 0.16027362159657987, 0.16027362159657987, 0.16027362159657987, 0.13401339553253344, 0.13401339553253344, 0.13401339553253344, 0.3214549596028735, 0.3214549596028735, 0.3214549596028735, 0.12791233673504643, 0.12791233673504643, 0.12791233673504643, 0.16383399385967368, 0.16383399385967368, 0.16383399385967368, 0.1266286868191091, 0.1266286868191091, 0.1266286868191091, 0.9733309129506003, 0.9733309129506003, 0.9733309129506003, 0.9739673216908493, 0.9739673216908493, 0.9739673216908493, 0.969832718197978, 0.969832718197978, 0.969832718197978, 0.5980334289949106, 0.5980334289949106, 0.5980334289949106, 0.5915685196562899, 0.5915685196562899, 0.5915685196562899, 0.5925787320318406, 0.5925787320318406, 0.5925787320318406, 0.2228007797048649, 0.2228007797048649, 0.2228007797048649, 0.2662202185261484, 0.2662202185261484, 0.2662202185261484, 0.6816948782457006, 0.6816948782457006, 0.6816948782457006, 0.20223928236475663, 0.20223928236475663, 0.20223928236475663, 0.23372047944994057, 0.23372047944994057, 0.23372047944994057, 0.1310253528902735, 0.1310253528902735, 0.1310253528902735, 0.2247251695342296, 0.2247251695342296, 0.2247251695342296, 0.1308573603186225, 0.1308573603186225, 0.1308573603186225, 0.2413142183884358, 0.2413142183884358, 0.2413142183884358, 0.09796560281053712, 0.09796560281053712, 0.09796560281053712, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.022433257054627398, 0.022433257054627398, 0.022433257054627398, 0.11414631554485422, 0.11414631554485422, 0.11414631554485422, 0.07516831462237228, 0.07516831462237228, 0.07516831462237228, 0.12014226323320965, 0.12014226323320965, 0.12014226323320965, 0.11280443089092496, 0.11280443089092496, 0.11280443089092496, 0.08043269124539199, 0.08043269124539199, 0.08043269124539199, 0.27567528983534106, 0.27567528983534106, 0.27567528983534106, 0.11546015945239596, 0.11546015945239596, 0.11546015945239596, 0.07237605786415402, 0.07237605786415402, 0.07237605786415402, 0.12711433479097722, 0.12711433479097722, 0.12711433479097722, 0.5322715550241699, 0.5322715550241699, 0.5322715550241699, 0.5617461905971499, 0.5617461905971499, 0.5617461905971499, 0.5350918626806347, 0.5350918626806347, 0.5350918626806347, 0.12686648160069003, 0.12686648160069003, 0.12686648160069003, 0.14049021741523482, 0.14049021741523482, 0.14049021741523482, 0.13322972757842688, 0.13322972757842688, 0.13322972757842688, 0.265568804190188, 0.265568804190188, 0.265568804190188, 0.22891553346104643, 0.22891553346104643, 0.22891553346104643, 0.1735886362398914, 0.1735886362398914, 0.1735886362398914, 0.5029881471143371, 0.5029881471143371, 0.5029881471143371, 0.2682858419979087, 0.2682858419979087, 0.2682858419979087, 0.47457602833091606, 0.47457602833091606, 0.47457602833091606, 0.2606848096039407, 0.2606848096039407, 0.2606848096039407, 0.3150593264552286, 0.3150593264552286, 0.3150593264552286, 0.21190397253033177, 0.21190397253033177, 0.21190397253033177, 0.2388877716061455, 0.2388877716061455, 0.2388877716061455, 0.2022627948392477, 0.2022627948392477, 0.2022627948392477, 0.220007465261564, 0.220007465261564, 0.220007465261564, 0.2339680783723218, 0.2339680783723218, 0.2339680783723218, 0.18504273840476126, 0.18504273840476126, 0.18504273840476126, 0.5299149907879814, 0.5299149907879814, 0.5299149907879814, 0.8344574571148264, 0.8344574571148264, 0.8344574571148264, 0.15630556603958157, 0.15630556603958157, 0.15630556603958157, 0.7502557861945547, 0.7502557861945547, 0.7502557861945547, 0.16640932760697758, 0.16640932760697758, 0.16640932760697758, 0.6614203236000468, 0.6614203236000468, 0.6614203236000468, 0.18870630892646, 0.18870630892646, 0.18870630892646, 0.1985146898918696, 0.1985146898918696, 0.1985146898918696, 0.21019789055689064, 0.21019789055689064, 0.21019789055689064, 0.21294210553912252, 0.21294210553912252, 0.21294210553912252, 0.09294167861245262, 0.09294167861245262, 0.09294167861245262, 0.09517126006120447, 0.09517126006120447, 0.09517126006120447, 0.08681045262525255, 0.08681045262525255, 0.08681045262525255]}, "mutation_prompt": null}
{"id": "1e5a8566-0863-4d8b-92e1-7dc901c98b7b", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.4  # Inertia weight for PSO, slightly decreased for enhanced exploration\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced global exploration by slightly decreasing the inertia weight `w` for better convergence.", "configspace": "", "generation": 36, "fitness": 0.33308908405122006, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.27.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.8682919441315117, 0.8682919441315117, 0.8682919441315117, 0.8628832829568409, 0.8628832829568409, 0.8628832829568409, 0.8685005116909561, 0.8685005116909561, 0.8685005116909561, 0.6558929723750376, 0.6558929723750376, 0.6558929723750376, 0.7110825414484588, 0.7110825414484588, 0.7110825414484588, 0.7046091739452267, 0.7046091739452267, 0.7046091739452267, 0.14288466442342507, 0.14288466442342507, 0.14288466442342507, 0.14903908875433247, 0.14903908875433247, 0.14903908875433247, 0.16314049568179778, 0.16314049568179778, 0.16314049568179778, 0.1299002478096294, 0.1299002478096294, 0.1299002478096294, 0.15362629915019366, 0.15362629915019366, 0.15362629915019366, 0.12619584759287483, 0.12619584759287483, 0.12619584759287483, 0.9679006513643851, 0.9679006513643851, 0.9679006513643851, 0.9664474462980268, 0.9664474462980268, 0.9664474462980268, 0.9657581579495835, 0.9657581579495835, 0.9657581579495835, 0.6783863260269809, 0.6783863260269809, 0.6783863260269809, 0.6456206902136437, 0.6456206902136437, 0.6456206902136437, 0.6823354043778977, 0.6823354043778977, 0.6823354043778977, 0.21360202266249984, 0.21360202266249984, 0.21360202266249984, 0.21080745449514127, 0.21080745449514127, 0.21080745449514127, 0.7313881142372136, 0.7313881142372136, 0.7313881142372136, 0.19789013566961489, 0.19789013566961489, 0.19789013566961489, 0.1288144428503336, 0.1288144428503336, 0.1288144428503336, 0.2201729516657922, 0.2201729516657922, 0.2201729516657922, 0.2392449775440938, 0.2392449775440938, 0.2392449775440938, 0.24130709889283097, 0.24130709889283097, 0.24130709889283097, 0.2933103420985169, 0.2933103420985169, 0.2933103420985169, 0.0016852426411992916, 0.0016852426411992916, 0.0016852426411992916, 0.03886071112610823, 0.03886071112610823, 0.03886071112610823, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10073457363455329, 0.10073457363455329, 0.10073457363455329, 0.066066373364291, 0.066066373364291, 0.066066373364291, 0.11225274884175762, 0.11225274884175762, 0.11225274884175762, 0.10053367634157495, 0.10053367634157495, 0.10053367634157495, 0.1690318339259015, 0.1690318339259015, 0.1690318339259015, 0.46236450524833295, 0.46236450524833295, 0.46236450524833295, 0.2443612243249501, 0.2443612243249501, 0.2443612243249501, 0.11343075935707148, 0.11343075935707148, 0.11343075935707148, 0.1589669771565002, 0.1589669771565002, 0.1589669771565002, 0.5505209658270975, 0.5505209658270975, 0.5505209658270975, 0.5523070965390919, 0.5523070965390919, 0.5523070965390919, 0.5513150043296985, 0.5513150043296985, 0.5513150043296985, 0.10545923980640726, 0.10545923980640726, 0.10545923980640726, 0.1371353891361078, 0.1371353891361078, 0.1371353891361078, 0.13064709253233864, 0.13064709253233864, 0.13064709253233864, 0.2113246412291031, 0.2113246412291031, 0.2113246412291031, 0.18174237178563513, 0.18174237178563513, 0.18174237178563513, 0.16675867438069725, 0.16675867438069725, 0.16675867438069725, 0.31838918405077765, 0.31838918405077765, 0.31838918405077765, 0.3723509878657907, 0.3723509878657907, 0.3723509878657907, 0.5665598277742812, 0.5665598277742812, 0.5665598277742812, 0.3180837706824209, 0.3180837706824209, 0.3180837706824209, 0.20267322910577423, 0.20267322910577423, 0.20267322910577423, 0.25463710638140724, 0.25463710638140724, 0.25463710638140724, 0.203880738336629, 0.203880738336629, 0.203880738336629, 0.22840172795799218, 0.22840172795799218, 0.22840172795799218, 0.23146627555401722, 0.23146627555401722, 0.23146627555401722, 0.20908371191800557, 0.20908371191800557, 0.20908371191800557, 0.20346098301618254, 0.20346098301618254, 0.20346098301618254, 0.22161736381414, 0.22161736381414, 0.22161736381414, 0.8706145275941957, 0.8706145275941957, 0.8706145275941957, 0.16225660057812508, 0.16225660057812508, 0.16225660057812508, 0.8083054870433658, 0.8083054870433658, 0.8083054870433658, 0.20473778422790956, 0.20473778422790956, 0.20473778422790956, 0.5243058570487342, 0.5243058570487342, 0.5243058570487342, 0.1664227782695623, 0.1664227782695623, 0.1664227782695623, 0.18210597349363644, 0.18210597349363644, 0.18210597349363644, 0.18252669287086876, 0.18252669287086876, 0.18252669287086876, 0.19291979905920076, 0.19291979905920076, 0.19291979905920076, 0.08065964498729705, 0.08065964498729705, 0.08065964498729705, 0.08405571994109595, 0.08405571994109595, 0.08405571994109595, 0.1182658922811779, 0.1182658922811779, 0.1182658922811779]}, "mutation_prompt": null}
{"id": "df2d8239-b5bc-4be4-8419-e815d5975d48", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.8 - evaluations/self.budget * 1.5  # Slight increase in cognitive coefficient\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Improved exploitation further by slightly increasing the influence of personal best in PSO.", "configspace": "", "generation": 37, "fitness": 0.2994333951779838, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.25.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.8555554186457387, 0.8555554186457387, 0.8555554186457387, 0.7734176700345727, 0.7734176700345727, 0.7734176700345727, 0.8444301943105081, 0.8444301943105081, 0.8444301943105081, 0.539573746755656, 0.539573746755656, 0.539573746755656, 0.5656492450505906, 0.5656492450505906, 0.5656492450505906, 0.5998529029944732, 0.5998529029944732, 0.5998529029944732, 0.13371725554641112, 0.13371725554641112, 0.13371725554641112, 0.12400312255813695, 0.12400312255813695, 0.12400312255813695, 0.16125097756180518, 0.16125097756180518, 0.16125097756180518, 0.12811344910312927, 0.12811344910312927, 0.12811344910312927, 0.12345554015585691, 0.12345554015585691, 0.12345554015585691, 0.1094464725520724, 0.1094464725520724, 0.1094464725520724, 0.9735885026334474, 0.9735885026334474, 0.9735885026334474, 0.9738681488499084, 0.9738681488499084, 0.9738681488499084, 0.9698522033192349, 0.9698522033192349, 0.9698522033192349, 0.5529458804759355, 0.5529458804759355, 0.5529458804759355, 0.5295619396780276, 0.5295619396780276, 0.5295619396780276, 0.5573776599577379, 0.5573776599577379, 0.5573776599577379, 0.4933274375424238, 0.4933274375424238, 0.4933274375424238, 0.7859843958040105, 0.7859843958040105, 0.7859843958040105, 0.2440189603331524, 0.2440189603331524, 0.2440189603331524, 0.20616028899114813, 0.20616028899114813, 0.20616028899114813, 0.1911991083070581, 0.1911991083070581, 0.1911991083070581, 0.19496290739746314, 0.19496290739746314, 0.19496290739746314, 0.1954189668045868, 0.1954189668045868, 0.1954189668045868, 0.1304837155368419, 0.1304837155368419, 0.1304837155368419, 0.22608193779520513, 0.22608193779520513, 0.22608193779520513, 0.03068062325276044, 0.03068062325276044, 0.03068062325276044, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13385339864156176, 0.13385339864156176, 0.13385339864156176, 0.07832559537511219, 0.07832559537511219, 0.07832559537511219, 0.06359273715634628, 0.06359273715634628, 0.06359273715634628, 0.09719828465103142, 0.09719828465103142, 0.09719828465103142, 0.2111186730620901, 0.2111186730620901, 0.2111186730620901, 0.14940854699583128, 0.14940854699583128, 0.14940854699583128, 0.07688323275725384, 0.07688323275725384, 0.07688323275725384, 0.18872693399379503, 0.18872693399379503, 0.18872693399379503, 0.05908606894128676, 0.05908606894128676, 0.05908606894128676, 0.5392753918166326, 0.5392753918166326, 0.5392753918166326, 0.5460225691091569, 0.5460225691091569, 0.5460225691091569, 0.5336210230910001, 0.5336210230910001, 0.5336210230910001, 0.11756242180998089, 0.11756242180998089, 0.11756242180998089, 0.1458022334265261, 0.1458022334265261, 0.1458022334265261, 0.13174710601834927, 0.13174710601834927, 0.13174710601834927, 0.15252882419429514, 0.15252882419429514, 0.15252882419429514, 0.24542173506641618, 0.24542173506641618, 0.24542173506641618, 0.2128704023891772, 0.2128704023891772, 0.2128704023891772, 0.30752097455756133, 0.30752097455756133, 0.30752097455756133, 0.3905754351050382, 0.3905754351050382, 0.3905754351050382, 0.3367399893780132, 0.3367399893780132, 0.3367399893780132, 0.3150131719098709, 0.3150131719098709, 0.3150131719098709, 0.2212006534854689, 0.2212006534854689, 0.2212006534854689, 0.1839905624536753, 0.1839905624536753, 0.1839905624536753, 0.20007358941197062, 0.20007358941197062, 0.20007358941197062, 0.22314341271546156, 0.22314341271546156, 0.22314341271546156, 0.19839547466742447, 0.19839547466742447, 0.19839547466742447, 0.19933549471156187, 0.19933549471156187, 0.19933549471156187, 0.22857455951731454, 0.22857455951731454, 0.22857455951731454, 0.19304489248404877, 0.19304489248404877, 0.19304489248404877, 0.861601203817816, 0.861601203817816, 0.861601203817816, 0.16340933664635449, 0.16340933664635449, 0.16340933664635449, 0.19568834011776348, 0.19568834011776348, 0.19568834011776348, 0.1680982196513593, 0.1680982196513593, 0.1680982196513593, 0.20765656195287852, 0.20765656195287852, 0.20765656195287852, 0.19326882745092966, 0.19326882745092966, 0.19326882745092966, 0.19155335880015223, 0.19155335880015223, 0.19155335880015223, 0.1881236776895544, 0.1881236776895544, 0.1881236776895544, 0.2249925938293994, 0.2249925938293994, 0.2249925938293994, 0.09132723187967329, 0.09132723187967329, 0.09132723187967329, 0.09760137497082977, 0.09760137497082977, 0.09760137497082977, 0.08105166516697826, 0.08105166516697826, 0.08105166516697826]}, "mutation_prompt": null}
{"id": "be8cf4cb-08d0-4d97-b4a0-269ccb34a276", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]) +\n                                 0.1 * np.random.randn(self.dim)) # Added additional randomness\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Improved exploration by increasing the random component in the PSO update.", "configspace": "", "generation": 38, "fitness": 0.2101204524657499, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.3897530972173342, 0.3897530972173342, 0.3897530972173342, 0.3923594950109639, 0.3923594950109639, 0.3923594950109639, 0.3887242732448366, 0.3887242732448366, 0.3887242732448366, 0.0022119001398733795, 0.0022119001398733795, 0.0022119001398733795, 0.027533429352573857, 0.027533429352573857, 0.027533429352573857, 0.022810975371525655, 0.022810975371525655, 0.022810975371525655, 0.10086220635564425, 0.10086220635564425, 0.10086220635564425, 0.12916057489939703, 0.12916057489939703, 0.12916057489939703, 0.09783986727152427, 0.09783986727152427, 0.09783986727152427, 0.0846926460904005, 0.0846926460904005, 0.0846926460904005, 0.08270906269959943, 0.08270906269959943, 0.08270906269959943, 0.09022331676251993, 0.09022331676251993, 0.09022331676251993, 0.967397906824407, 0.967397906824407, 0.967397906824407, 0.9679932045578736, 0.9679932045578736, 0.9679932045578736, 0.9688520694033309, 0.9688520694033309, 0.9688520694033309, 0.273267758895006, 0.273267758895006, 0.273267758895006, 0.25205728870769495, 0.25205728870769495, 0.25205728870769495, 0.2780110647502181, 0.2780110647502181, 0.2780110647502181, 0.3011729565946092, 0.3011729565946092, 0.3011729565946092, 0.2940611578437681, 0.2940611578437681, 0.2940611578437681, 0.3167336774360201, 0.3167336774360201, 0.3167336774360201, 0.1414596887409385, 0.1414596887409385, 0.1414596887409385, 0.1388295365148028, 0.1388295365148028, 0.1388295365148028, 0.15486313301539834, 0.15486313301539834, 0.15486313301539834, 0.10171337867336372, 0.10171337867336372, 0.10171337867336372, 0.1837967412439273, 0.1837967412439273, 0.1837967412439273, 0.15124949966589707, 0.15124949966589707, 0.15124949966589707, 0.03642486006886758, 0.03642486006886758, 0.03642486006886758, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06584598775711115, 0.06584598775711115, 0.06584598775711115, 0.07483914145315662, 0.07483914145315662, 0.07483914145315662, 0.10378671114207061, 0.10378671114207061, 0.10378671114207061, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08770269553690724, 0.08770269553690724, 0.08770269553690724, 0.04897857640691272, 0.04897857640691272, 0.04897857640691272, 0.07185250148834021, 0.07185250148834021, 0.07185250148834021, 0.38361519198206184, 0.38361519198206184, 0.38361519198206184, 0.3638807918611382, 0.3638807918611382, 0.3638807918611382, 0.411121187173086, 0.411121187173086, 0.411121187173086, 0.10546501547965237, 0.10546501547965237, 0.10546501547965237, 0.1102843202642132, 0.1102843202642132, 0.1102843202642132, 0.09912833908417573, 0.09912833908417573, 0.09912833908417573, 0.1557584205640674, 0.1557584205640674, 0.1557584205640674, 0.2333365121281218, 0.2333365121281218, 0.2333365121281218, 0.17369081793283658, 0.17369081793283658, 0.17369081793283658, 0.2677349466369051, 0.2677349466369051, 0.2677349466369051, 0.26075455610057885, 0.26075455610057885, 0.26075455610057885, 0.28081198855014067, 0.28081198855014067, 0.28081198855014067, 0.22679526592834176, 0.22679526592834176, 0.22679526592834176, 0.21835938014861334, 0.21835938014861334, 0.21835938014861334, 0.2118106679948265, 0.2118106679948265, 0.2118106679948265, 0.20328138800758888, 0.20328138800758888, 0.20328138800758888, 0.2111134476731158, 0.2111134476731158, 0.2111134476731158, 0.20275733304117072, 0.20275733304117072, 0.20275733304117072, 0.21785538594981047, 0.21785538594981047, 0.21785538594981047, 0.19042022617990095, 0.19042022617990095, 0.19042022617990095, 0.1870568193634109, 0.1870568193634109, 0.1870568193634109, 0.552569665702362, 0.552569665702362, 0.552569665702362, 0.1651266439145298, 0.1651266439145298, 0.1651266439145298, 0.16467779584018027, 0.16467779584018027, 0.16467779584018027, 0.3290391185041118, 0.3290391185041118, 0.3290391185041118, 0.4000537465218419, 0.4000537465218419, 0.4000537465218419, 0.20858716859917203, 0.20858716859917203, 0.20858716859917203, 0.18056769823921937, 0.18056769823921937, 0.18056769823921937, 0.18224281082670946, 0.18224281082670946, 0.18224281082670946, 0.19896157410135884, 0.19896157410135884, 0.19896157410135884, 0.0795176396246785, 0.0795176396246785, 0.0795176396246785, 0.08057186585488108, 0.08057186585488108, 0.08057186585488108, 0.08145446662437628, 0.08145446662437628, 0.08145446662437628]}, "mutation_prompt": null}
{"id": "46e34553-f41d-4fac-a1ab-02476036b90e", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                self.w = 0.9 - 0.4 * (evaluations/self.budget)  # Dynamic inertia weight\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Introduce a dynamic adjustment to the inertia weight (w) in PSO to balance exploration and exploitation more effectively.", "configspace": "", "generation": 39, "fitness": 0.1905985125195022, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.437605286148927, 0.437605286148927, 0.437605286148927, 0.4548483346002523, 0.4548483346002523, 0.4548483346002523, 0.4807776073732434, 0.4807776073732434, 0.4807776073732434, 0.10137514983641505, 0.10137514983641505, 0.10137514983641505, 0.049834645307488046, 0.049834645307488046, 0.049834645307488046, 0.02628286255110235, 0.02628286255110235, 0.02628286255110235, 0.0844780636365755, 0.0844780636365755, 0.0844780636365755, 0.08766721836909674, 0.08766721836909674, 0.08766721836909674, 0.08502418371943421, 0.08502418371943421, 0.08502418371943421, 0.07705562381719444, 0.07705562381719444, 0.07705562381719444, 0.07472857816598899, 0.07472857816598899, 0.07472857816598899, 0.08061123337641407, 0.08061123337641407, 0.08061123337641407, 0.975652090494761, 0.975652090494761, 0.975652090494761, 0.9790366890189451, 0.9790366890189451, 0.9790366890189451, 0.9736664876013109, 0.9736664876013109, 0.9736664876013109, 0.281429548677698, 0.281429548677698, 0.281429548677698, 0.19621990574529247, 0.19621990574529247, 0.19621990574529247, 0.2096629104369263, 0.2096629104369263, 0.2096629104369263, 0.18701423690835983, 0.18701423690835983, 0.18701423690835983, 0.18332241035662344, 0.18332241035662344, 0.18332241035662344, 0.1991846570435214, 0.1991846570435214, 0.1991846570435214, 0.12333134526260581, 0.12333134526260581, 0.12333134526260581, 0.13085889400922657, 0.13085889400922657, 0.13085889400922657, 0.12340971554608982, 0.12340971554608982, 0.12340971554608982, 0.019550142587097974, 0.019550142587097974, 0.019550142587097974, 0.10950163133381119, 0.10950163133381119, 0.10950163133381119, 0.1177956983214784, 0.1177956983214784, 0.1177956983214784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00950637459719128, 0.00950637459719128, 0.00950637459719128, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10106885035602009, 0.10106885035602009, 0.10106885035602009, 0.04465698958158304, 0.04465698958158304, 0.04465698958158304, 0.07258536355953182, 0.07258536355953182, 0.07258536355953182, 0.013005801850459853, 0.013005801850459853, 0.013005801850459853, 0.006472194279493304, 0.006472194279493304, 0.006472194279493304, 0.02355355952731175, 0.02355355952731175, 0.02355355952731175, 0.03591986374834777, 0.03591986374834777, 0.03591986374834777, 0.04411588696491331, 0.04411588696491331, 0.04411588696491331, 0.08604786458357705, 0.08604786458357705, 0.08604786458357705, 0.3721972396434816, 0.3721972396434816, 0.3721972396434816, 0.32785117041377165, 0.32785117041377165, 0.32785117041377165, 0.3191748871910909, 0.3191748871910909, 0.3191748871910909, 0.08459005096922123, 0.08459005096922123, 0.08459005096922123, 0.10192835821712865, 0.10192835821712865, 0.10192835821712865, 0.09248598957574816, 0.09248598957574816, 0.09248598957574816, 0.16439007814830298, 0.16439007814830298, 0.16439007814830298, 0.16513681059269092, 0.16513681059269092, 0.16513681059269092, 0.1481488140498476, 0.1481488140498476, 0.1481488140498476, 0.261510016304523, 0.261510016304523, 0.261510016304523, 0.23815083626712874, 0.23815083626712874, 0.23815083626712874, 0.2543841551111472, 0.2543841551111472, 0.2543841551111472, 0.22006955393172245, 0.22006955393172245, 0.22006955393172245, 0.16858121251514335, 0.16858121251514335, 0.16858121251514335, 0.18557368929442108, 0.18557368929442108, 0.18557368929442108, 0.1824320921383441, 0.1824320921383441, 0.1824320921383441, 0.19769733786703114, 0.19769733786703114, 0.19769733786703114, 0.19230837653923083, 0.19230837653923083, 0.19230837653923083, 0.17570374458313687, 0.17570374458313687, 0.17570374458313687, 0.20251793593804024, 0.20251793593804024, 0.20251793593804024, 0.16434101028399106, 0.16434101028399106, 0.16434101028399106, 0.5047688863531201, 0.5047688863531201, 0.5047688863531201, 0.19016039680171526, 0.19016039680171526, 0.19016039680171526, 0.17640693852197142, 0.17640693852197142, 0.17640693852197142, 0.19621505054565602, 0.19621505054565602, 0.19621505054565602, 0.19381752126562424, 0.19381752126562424, 0.19381752126562424, 0.20035116540292175, 0.20035116540292175, 0.20035116540292175, 0.18453816311407745, 0.18453816311407745, 0.18453816311407745, 0.1709701339416373, 0.1709701339416373, 0.1709701339416373, 0.19104830268622186, 0.19104830268622186, 0.19104830268622186, 0.07310600968431136, 0.07310600968431136, 0.07310600968431136, 0.06854543834691518, 0.06854543834691518, 0.06854543834691518, 0.06693363587053258, 0.06693363587053258, 0.06693363587053258]}, "mutation_prompt": null}
{"id": "8605de83-ae88-4ab2-bc28-71120d753992", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                self.w = max(0.1, self.w - 0.1 * evaluations/self.budget)  # Dynamic inertia weight adjustment\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced exploitation by modifying the inertia weight dynamically in PSO.", "configspace": "", "generation": 40, "fitness": 0.3137817986792731, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.27.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.8783040248110265, 0.8783040248110265, 0.8783040248110265, 0.8800994800269231, 0.8800994800269231, 0.8800994800269231, 0.8704911096106823, 0.8704911096106823, 0.8704911096106823, 0.7510564524628331, 0.7510564524628331, 0.7510564524628331, 0.7349064639175333, 0.7349064639175333, 0.7349064639175333, 0.7330646529819806, 0.7330646529819806, 0.7330646529819806, 0.16694187707883434, 0.16694187707883434, 0.16694187707883434, 0.16862963234657746, 0.16862963234657746, 0.16862963234657746, 0.13459419271884798, 0.13459419271884798, 0.13459419271884798, 0.098817110759854, 0.098817110759854, 0.098817110759854, 0.12605139776223517, 0.12605139776223517, 0.12605139776223517, 0.11583977960882985, 0.11583977960882985, 0.11583977960882985, 0.9674506605730133, 0.9674506605730133, 0.9674506605730133, 0.9663841184150835, 0.9663841184150835, 0.9663841184150835, 0.9497554373696258, 0.9497554373696258, 0.9497554373696258, 0.7242722383128979, 0.7242722383128979, 0.7242722383128979, 0.6534649225671307, 0.6534649225671307, 0.6534649225671307, 0.6970977587349405, 0.6970977587349405, 0.6970977587349405, 0.35124827646422274, 0.35124827646422274, 0.35124827646422274, 0.3734108161314149, 0.3734108161314149, 0.3734108161314149, 0.22271391591277834, 0.22271391591277834, 0.22271391591277834, 0.18267845552022377, 0.18267845552022377, 0.18267845552022377, 0.12835673569609574, 0.12835673569609574, 0.12835673569609574, 0.18391463926346374, 0.18391463926346374, 0.18391463926346374, 0.2056049978441381, 0.2056049978441381, 0.2056049978441381, 0.19778688908666153, 0.19778688908666153, 0.19778688908666153, 0.20808179373842706, 0.20808179373842706, 0.20808179373842706, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05591214275782763, 0.05591214275782763, 0.05591214275782763, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13611356476775105, 0.13611356476775105, 0.13611356476775105, 0.05515210976746243, 0.05515210976746243, 0.05515210976746243, 0.09740285080048106, 0.09740285080048106, 0.09740285080048106, 0.048036785298556595, 0.048036785298556595, 0.048036785298556595, 0.15351713291377767, 0.15351713291377767, 0.15351713291377767, 0.2035601975486322, 0.2035601975486322, 0.2035601975486322, 0.17878027650921324, 0.17878027650921324, 0.17878027650921324, 0.22091427391678697, 0.22091427391678697, 0.22091427391678697, 0.2285040706783935, 0.2285040706783935, 0.2285040706783935, 0.5859940683287106, 0.5859940683287106, 0.5859940683287106, 0.5996672787847668, 0.5996672787847668, 0.5996672787847668, 0.5632603872348247, 0.5632603872348247, 0.5632603872348247, 0.10426406238575359, 0.10426406238575359, 0.10426406238575359, 0.12083102421014136, 0.12083102421014136, 0.12083102421014136, 0.13357600055866625, 0.13357600055866625, 0.13357600055866625, 0.16552416917192425, 0.16552416917192425, 0.16552416917192425, 0.20999656226626084, 0.20999656226626084, 0.20999656226626084, 0.15900435829117032, 0.15900435829117032, 0.15900435829117032, 0.37244648432300487, 0.37244648432300487, 0.37244648432300487, 0.37275224058054734, 0.37275224058054734, 0.37275224058054734, 0.5215744935933908, 0.5215744935933908, 0.5215744935933908, 0.2245189226104497, 0.2245189226104497, 0.2245189226104497, 0.16651580769387164, 0.16651580769387164, 0.16651580769387164, 0.21889701881214008, 0.21889701881214008, 0.21889701881214008, 0.2525412917219989, 0.2525412917219989, 0.2525412917219989, 0.23637731296345688, 0.23637731296345688, 0.23637731296345688, 0.24566918481703448, 0.24566918481703448, 0.24566918481703448, 0.19041737857397456, 0.19041737857397456, 0.19041737857397456, 0.2128554191704325, 0.2128554191704325, 0.2128554191704325, 0.21508169379044095, 0.21508169379044095, 0.21508169379044095, 0.8612848841115284, 0.8612848841115284, 0.8612848841115284, 0.19444363512315976, 0.19444363512315976, 0.19444363512315976, 0.20043988621217945, 0.20043988621217945, 0.20043988621217945, 0.1680242939200869, 0.1680242939200869, 0.1680242939200869, 0.20593066475736455, 0.20593066475736455, 0.20593066475736455, 0.16691925626248083, 0.16691925626248083, 0.16691925626248083, 0.1961923183843266, 0.1961923183843266, 0.1961923183843266, 0.20051536096688494, 0.20051536096688494, 0.20051536096688494, 0.18630856508185867, 0.18630856508185867, 0.18630856508185867, 0.09601919043353535, 0.09601919043353535, 0.09601919043353535, 0.08746775171981613, 0.08746775171981613, 0.08746775171981613, 0.10786730337632722, 0.10786730337632722, 0.10786730337632722]}, "mutation_prompt": null}
{"id": "f0bf297b-2743-4973-bb84-db9830756b56", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.7  # Adjusted inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Improved exploration by slightly adjusting inertia weight in PSO for better convergence.", "configspace": "", "generation": 41, "fitness": 0.23027722903962633, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.21.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.489729205805689, 0.489729205805689, 0.489729205805689, 0.5426552892751138, 0.5426552892751138, 0.5426552892751138, 0.6281938628935912, 0.6281938628935912, 0.6281938628935912, 0.20336190931602294, 0.20336190931602294, 0.20336190931602294, 0.1750066485456202, 0.1750066485456202, 0.1750066485456202, 0.15020290901802713, 0.15020290901802713, 0.15020290901802713, 0.10092311299552403, 0.10092311299552403, 0.10092311299552403, 0.10942387865492642, 0.10942387865492642, 0.10942387865492642, 0.11912067278485905, 0.11912067278485905, 0.11912067278485905, 0.11855767850548704, 0.11855767850548704, 0.11855767850548704, 0.08488838868775384, 0.08488838868775384, 0.08488838868775384, 0.0830985945148881, 0.0830985945148881, 0.0830985945148881, 0.9734673280437594, 0.9734673280437594, 0.9734673280437594, 0.974364824184331, 0.974364824184331, 0.974364824184331, 0.9706870579976348, 0.9706870579976348, 0.9706870579976348, 0.3563561240235462, 0.3563561240235462, 0.3563561240235462, 0.2728774232533493, 0.2728774232533493, 0.2728774232533493, 0.2586712726086188, 0.2586712726086188, 0.2586712726086188, 0.531160130141563, 0.531160130141563, 0.531160130141563, 0.3488397310774267, 0.3488397310774267, 0.3488397310774267, 0.2536980720246065, 0.2536980720246065, 0.2536980720246065, 0.13249074835779706, 0.13249074835779706, 0.13249074835779706, 0.1374711617156943, 0.1374711617156943, 0.1374711617156943, 0.16992449843516932, 0.16992449843516932, 0.16992449843516932, 0.13035153609958983, 0.13035153609958983, 0.13035153609958983, 0.17884352176540397, 0.17884352176540397, 0.17884352176540397, 0.1475526823636648, 0.1475526823636648, 0.1475526823636648, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0749234688928615, 0.0749234688928615, 0.0749234688928615, 0.05776169488488081, 0.05776169488488081, 0.05776169488488081, 0.09528670968925779, 0.09528670968925779, 0.09528670968925779, 0.03746753801241742, 0.03746753801241742, 0.03746753801241742, 0.05245242971203423, 0.05245242971203423, 0.05245242971203423, 0.04123472893399738, 0.04123472893399738, 0.04123472893399738, 0.08422024857633281, 0.08422024857633281, 0.08422024857633281, 0.10205854995893737, 0.10205854995893737, 0.10205854995893737, 0.048020762165913444, 0.048020762165913444, 0.048020762165913444, 0.44628113735584396, 0.44628113735584396, 0.44628113735584396, 0.4308062171183108, 0.4308062171183108, 0.4308062171183108, 0.44454170829426054, 0.44454170829426054, 0.44454170829426054, 0.10698287453180799, 0.10698287453180799, 0.10698287453180799, 0.08317236551805274, 0.08317236551805274, 0.08317236551805274, 0.08263604016863924, 0.08263604016863924, 0.08263604016863924, 0.2234054720756966, 0.2234054720756966, 0.2234054720756966, 0.15171228727299513, 0.15171228727299513, 0.15171228727299513, 0.2275126955372977, 0.2275126955372977, 0.2275126955372977, 0.2963259685927947, 0.2963259685927947, 0.2963259685927947, 0.27410936075347825, 0.27410936075347825, 0.27410936075347825, 0.31337908827202654, 0.31337908827202654, 0.31337908827202654, 0.22165365990574737, 0.22165365990574737, 0.22165365990574737, 0.15667601793509678, 0.15667601793509678, 0.15667601793509678, 0.16546079797764557, 0.16546079797764557, 0.16546079797764557, 0.18129352843804725, 0.18129352843804725, 0.18129352843804725, 0.20470000042502556, 0.20470000042502556, 0.20470000042502556, 0.19332652648150683, 0.19332652648150683, 0.19332652648150683, 0.17497099351408485, 0.17497099351408485, 0.17497099351408485, 0.20713223818776938, 0.20713223818776938, 0.20713223818776938, 0.2669256518188128, 0.2669256518188128, 0.2669256518188128, 0.715924221196987, 0.715924221196987, 0.715924221196987, 0.1986015333120167, 0.1986015333120167, 0.1986015333120167, 0.1644702249307125, 0.1644702249307125, 0.1644702249307125, 0.16615189207200798, 0.16615189207200798, 0.16615189207200798, 0.20595887891121423, 0.20595887891121423, 0.20595887891121423, 0.19996848969653125, 0.19996848969653125, 0.19996848969653125, 0.19498600936416155, 0.19498600936416155, 0.19498600936416155, 0.19001180105203752, 0.19001180105203752, 0.19001180105203752, 0.19092316267931697, 0.19092316267931697, 0.19092316267931697, 0.09565757846555822, 0.09565757846555822, 0.09565757846555822, 0.08260274507029408, 0.08260274507029408, 0.08260274507029408, 0.08605493001102771, 0.08605493001102771, 0.08605493001102771]}, "mutation_prompt": null}
{"id": "c754de46-dea6-4a6d-8932-d0f3ffb43618", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                self.w = 0.9 - (0.5 * evaluations / self.budget)  # Dynamically adjust inertia weight\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhance balance between exploration and exploitation by adjusting the inertia weight dynamically in PSO.", "configspace": "", "generation": 42, "fitness": 0.20577492177781914, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.44758853118755115, 0.44758853118755115, 0.44758853118755115, 0.5466156977500924, 0.5466156977500924, 0.5466156977500924, 0.4807008716687816, 0.4807008716687816, 0.4807008716687816, 0.12366888526057884, 0.12366888526057884, 0.12366888526057884, 0.17767300616067727, 0.17767300616067727, 0.17767300616067727, 0.2065798473130781, 0.2065798473130781, 0.2065798473130781, 0.0988579180126189, 0.0988579180126189, 0.0988579180126189, 0.1081361840076337, 0.1081361840076337, 0.1081361840076337, 0.09963585736028491, 0.09963585736028491, 0.09963585736028491, 0.08109380353766449, 0.08109380353766449, 0.08109380353766449, 0.08519866607291138, 0.08519866607291138, 0.08519866607291138, 0.09163140126409886, 0.09163140126409886, 0.09163140126409886, 0.975651045096156, 0.975651045096156, 0.975651045096156, 0.9790362992505957, 0.9790362992505957, 0.9790362992505957, 0.9736668129840342, 0.9736668129840342, 0.9736668129840342, 0.2913679120706736, 0.2913679120706736, 0.2913679120706736, 0.2549019415282592, 0.2549019415282592, 0.2549019415282592, 0.2595875451798102, 0.2595875451798102, 0.2595875451798102, 0.24975608698443053, 0.24975608698443053, 0.24975608698443053, 0.16938114229449852, 0.16938114229449852, 0.16938114229449852, 0.16184508959737798, 0.16184508959737798, 0.16184508959737798, 0.09441635482944422, 0.09441635482944422, 0.09441635482944422, 0.19078210425831343, 0.19078210425831343, 0.19078210425831343, 0.19028496913239568, 0.19028496913239568, 0.19028496913239568, 0.042746067586211356, 0.042746067586211356, 0.042746067586211356, 0.11527350072230225, 0.11527350072230225, 0.11527350072230225, 0.12431717607551385, 0.12431717607551385, 0.12431717607551385, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0787400252107916, 0.0787400252107916, 0.0787400252107916, 0.06907151679223622, 0.06907151679223622, 0.06907151679223622, 0.06435206586822972, 0.06435206586822972, 0.06435206586822972, 0.017864077197967676, 0.017864077197967676, 0.017864077197967676, 0.06176875968303708, 0.06176875968303708, 0.06176875968303708, 0.03499618171061425, 0.03499618171061425, 0.03499618171061425, 0.0370664250550683, 0.0370664250550683, 0.0370664250550683, 0.0891172103226352, 0.0891172103226352, 0.0891172103226352, 0.03892962365755337, 0.03892962365755337, 0.03892962365755337, 0.3835547593022345, 0.3835547593022345, 0.3835547593022345, 0.39393277978697494, 0.39393277978697494, 0.39393277978697494, 0.3793510952057222, 0.3793510952057222, 0.3793510952057222, 0.08424628248284693, 0.08424628248284693, 0.08424628248284693, 0.09840668691393673, 0.09840668691393673, 0.09840668691393673, 0.10339739159368966, 0.10339739159368966, 0.10339739159368966, 0.17211817624461512, 0.17211817624461512, 0.17211817624461512, 0.1863635839168436, 0.1863635839168436, 0.1863635839168436, 0.15120320850345137, 0.15120320850345137, 0.15120320850345137, 0.28121285095416215, 0.28121285095416215, 0.28121285095416215, 0.26219718151078497, 0.26219718151078497, 0.26219718151078497, 0.2653662357826615, 0.2653662357826615, 0.2653662357826615, 0.18477563388248686, 0.18477563388248686, 0.18477563388248686, 0.20250773159947, 0.20250773159947, 0.20250773159947, 0.1756798866194491, 0.1756798866194491, 0.1756798866194491, 0.17662582065245247, 0.17662582065245247, 0.17662582065245247, 0.1802211752050622, 0.1802211752050622, 0.1802211752050622, 0.1862266468019117, 0.1862266468019117, 0.1862266468019117, 0.18178382476566035, 0.18178382476566035, 0.18178382476566035, 0.1887550617696726, 0.1887550617696726, 0.1887550617696726, 0.20987439864355828, 0.20987439864355828, 0.20987439864355828, 0.5613909862669498, 0.5613909862669498, 0.5613909862669498, 0.1511788111992819, 0.1511788111992819, 0.1511788111992819, 0.1791580623678275, 0.1791580623678275, 0.1791580623678275, 0.19193715196545014, 0.19193715196545014, 0.19193715196545014, 0.19660007486030728, 0.19660007486030728, 0.19660007486030728, 0.1857322973189689, 0.1857322973189689, 0.1857322973189689, 0.195319602465868, 0.195319602465868, 0.195319602465868, 0.19033097172020963, 0.19033097172020963, 0.19033097172020963, 0.1756322862540154, 0.1756322862540154, 0.1756322862540154, 0.0709170233676294, 0.0709170233676294, 0.0709170233676294, 0.07582857042875879, 0.07582857042875879, 0.07582857042875879, 0.08136751496594352, 0.08136751496594352, 0.08136751496594352]}, "mutation_prompt": null}
{"id": "439e4f29-3d0c-42ed-957e-bc10efd2d4b6", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                self.w = 0.9 - evaluations/self.budget * 0.4  # Dynamic inertia weight for better balance\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Introduce a dynamic inertia weight in PSO to balance exploration and exploitation.", "configspace": "", "generation": 43, "fitness": 0.1905985125195022, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.437605286148927, 0.437605286148927, 0.437605286148927, 0.4548483346002523, 0.4548483346002523, 0.4548483346002523, 0.4807776073732434, 0.4807776073732434, 0.4807776073732434, 0.10137514983641505, 0.10137514983641505, 0.10137514983641505, 0.049834645307488046, 0.049834645307488046, 0.049834645307488046, 0.02628286255110235, 0.02628286255110235, 0.02628286255110235, 0.0844780636365755, 0.0844780636365755, 0.0844780636365755, 0.08766721836909674, 0.08766721836909674, 0.08766721836909674, 0.08502418371943421, 0.08502418371943421, 0.08502418371943421, 0.07705562381719444, 0.07705562381719444, 0.07705562381719444, 0.07472857816598899, 0.07472857816598899, 0.07472857816598899, 0.08061123337641407, 0.08061123337641407, 0.08061123337641407, 0.975652090494761, 0.975652090494761, 0.975652090494761, 0.9790366890189451, 0.9790366890189451, 0.9790366890189451, 0.9736664876013109, 0.9736664876013109, 0.9736664876013109, 0.281429548677698, 0.281429548677698, 0.281429548677698, 0.19621990574529247, 0.19621990574529247, 0.19621990574529247, 0.2096629104369263, 0.2096629104369263, 0.2096629104369263, 0.18701423690835983, 0.18701423690835983, 0.18701423690835983, 0.18332241035662344, 0.18332241035662344, 0.18332241035662344, 0.1991846570435214, 0.1991846570435214, 0.1991846570435214, 0.12333134526260581, 0.12333134526260581, 0.12333134526260581, 0.13085889400922657, 0.13085889400922657, 0.13085889400922657, 0.12340971554608982, 0.12340971554608982, 0.12340971554608982, 0.019550142587097974, 0.019550142587097974, 0.019550142587097974, 0.10950163133381119, 0.10950163133381119, 0.10950163133381119, 0.1177956983214784, 0.1177956983214784, 0.1177956983214784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00950637459719128, 0.00950637459719128, 0.00950637459719128, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10106885035602009, 0.10106885035602009, 0.10106885035602009, 0.04465698958158304, 0.04465698958158304, 0.04465698958158304, 0.07258536355953182, 0.07258536355953182, 0.07258536355953182, 0.013005801850459853, 0.013005801850459853, 0.013005801850459853, 0.006472194279493304, 0.006472194279493304, 0.006472194279493304, 0.02355355952731175, 0.02355355952731175, 0.02355355952731175, 0.03591986374834777, 0.03591986374834777, 0.03591986374834777, 0.04411588696491331, 0.04411588696491331, 0.04411588696491331, 0.08604786458357705, 0.08604786458357705, 0.08604786458357705, 0.3721972396434816, 0.3721972396434816, 0.3721972396434816, 0.32785117041377165, 0.32785117041377165, 0.32785117041377165, 0.3191748871910909, 0.3191748871910909, 0.3191748871910909, 0.08459005096922123, 0.08459005096922123, 0.08459005096922123, 0.10192835821712865, 0.10192835821712865, 0.10192835821712865, 0.09248598957574816, 0.09248598957574816, 0.09248598957574816, 0.16439007814830298, 0.16439007814830298, 0.16439007814830298, 0.16513681059269092, 0.16513681059269092, 0.16513681059269092, 0.1481488140498476, 0.1481488140498476, 0.1481488140498476, 0.261510016304523, 0.261510016304523, 0.261510016304523, 0.23815083626712874, 0.23815083626712874, 0.23815083626712874, 0.2543841551111472, 0.2543841551111472, 0.2543841551111472, 0.22006955393172245, 0.22006955393172245, 0.22006955393172245, 0.16858121251514335, 0.16858121251514335, 0.16858121251514335, 0.18557368929442108, 0.18557368929442108, 0.18557368929442108, 0.1824320921383441, 0.1824320921383441, 0.1824320921383441, 0.19769733786703114, 0.19769733786703114, 0.19769733786703114, 0.19230837653923083, 0.19230837653923083, 0.19230837653923083, 0.17570374458313687, 0.17570374458313687, 0.17570374458313687, 0.20251793593804024, 0.20251793593804024, 0.20251793593804024, 0.16434101028399106, 0.16434101028399106, 0.16434101028399106, 0.5047688863531201, 0.5047688863531201, 0.5047688863531201, 0.19016039680171526, 0.19016039680171526, 0.19016039680171526, 0.17640693852197142, 0.17640693852197142, 0.17640693852197142, 0.19621505054565602, 0.19621505054565602, 0.19621505054565602, 0.19381752126562424, 0.19381752126562424, 0.19381752126562424, 0.20035116540292175, 0.20035116540292175, 0.20035116540292175, 0.18453816311407745, 0.18453816311407745, 0.18453816311407745, 0.1709701339416373, 0.1709701339416373, 0.1709701339416373, 0.19104830268622186, 0.19104830268622186, 0.19104830268622186, 0.07310600968431136, 0.07310600968431136, 0.07310600968431136, 0.06854543834691518, 0.06854543834691518, 0.06854543834691518, 0.06693363587053258, 0.06693363587053258, 0.06693363587053258]}, "mutation_prompt": null}
{"id": "b216fb3b-c210-4a67-aa8f-c4d730ad9268", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                self.w = 0.9 - 0.8 * evaluations / self.budget  # Adjusted inertia weight to be dynamic\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Adjusted the inertia weight in PSO dynamically to enhance exploration early and exploitation later.", "configspace": "", "generation": 44, "fitness": 0.24988909753589622, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.22.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.553829921700768, 0.553829921700768, 0.553829921700768, 0.6377486007054844, 0.6377486007054844, 0.6377486007054844, 0.6163634059700487, 0.6163634059700487, 0.6163634059700487, 0.4318791403763388, 0.4318791403763388, 0.4318791403763388, 0.35990420577827564, 0.35990420577827564, 0.35990420577827564, 0.34767905319990755, 0.34767905319990755, 0.34767905319990755, 0.11059169196984608, 0.11059169196984608, 0.11059169196984608, 0.11281109466470696, 0.11281109466470696, 0.11281109466470696, 0.12489686389060861, 0.12489686389060861, 0.12489686389060861, 0.09426130283897038, 0.09426130283897038, 0.09426130283897038, 0.08719811907099151, 0.08719811907099151, 0.08719811907099151, 0.09917049462748806, 0.09917049462748806, 0.09917049462748806, 0.9776659535002061, 0.9776659535002061, 0.9776659535002061, 0.9790351370124958, 0.9790351370124958, 0.9790351370124958, 0.973667786657649, 0.973667786657649, 0.973667786657649, 0.445990727304004, 0.445990727304004, 0.445990727304004, 0.42902107583239235, 0.42902107583239235, 0.42902107583239235, 0.38566225846606417, 0.38566225846606417, 0.38566225846606417, 0.16335253357557145, 0.16335253357557145, 0.16335253357557145, 0.2880182929594812, 0.2880182929594812, 0.2880182929594812, 0.4857279990239778, 0.4857279990239778, 0.4857279990239778, 0.13445794744665784, 0.13445794744665784, 0.13445794744665784, 0.16221992581662636, 0.16221992581662636, 0.16221992581662636, 0.2137491942435048, 0.2137491942435048, 0.2137491942435048, 0.040289713973251984, 0.040289713973251984, 0.040289713973251984, 0.16805259094753966, 0.16805259094753966, 0.16805259094753966, 0.1647450826027569, 0.1647450826027569, 0.1647450826027569, 0.021309412013663653, 0.021309412013663653, 0.021309412013663653, 0.023828467970789413, 0.023828467970789413, 0.023828467970789413, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08510462368943117, 0.08510462368943117, 0.08510462368943117, 0.04643176855024156, 0.04643176855024156, 0.04643176855024156, 0.1017045753357605, 0.1017045753357605, 0.1017045753357605, 0.05442338716947448, 0.05442338716947448, 0.05442338716947448, 0.05658605667349437, 0.05658605667349437, 0.05658605667349437, 0.05875095709556377, 0.05875095709556377, 0.05875095709556377, 0.07859597069509505, 0.07859597069509505, 0.07859597069509505, 0.0709012653519634, 0.0709012653519634, 0.0709012653519634, 0.08450660534961629, 0.08450660534961629, 0.08450660534961629, 0.4262313856332133, 0.4262313856332133, 0.4262313856332133, 0.4552516228020397, 0.4552516228020397, 0.4552516228020397, 0.46708231776581366, 0.46708231776581366, 0.46708231776581366, 0.12156578580280308, 0.12156578580280308, 0.12156578580280308, 0.11956570516574372, 0.11956570516574372, 0.11956570516574372, 0.12262920157578194, 0.12262920157578194, 0.12262920157578194, 0.18866768475011664, 0.18866768475011664, 0.18866768475011664, 0.21078291856755893, 0.21078291856755893, 0.21078291856755893, 0.20480235348503228, 0.20480235348503228, 0.20480235348503228, 0.24421893669227246, 0.24421893669227246, 0.24421893669227246, 0.3412065888453033, 0.3412065888453033, 0.3412065888453033, 0.3431310461254117, 0.3431310461254117, 0.3431310461254117, 0.22263095437857283, 0.22263095437857283, 0.22263095437857283, 0.16541794240130747, 0.16541794240130747, 0.16541794240130747, 0.21926730586148047, 0.21926730586148047, 0.21926730586148047, 0.22179219030132413, 0.22179219030132413, 0.22179219030132413, 0.2017918154472712, 0.2017918154472712, 0.2017918154472712, 0.18004193148040026, 0.18004193148040026, 0.18004193148040026, 0.1874613133978008, 0.1874613133978008, 0.1874613133978008, 0.4162738296686521, 0.4162738296686521, 0.4162738296686521, 0.19279538582637112, 0.19279538582637112, 0.19279538582637112, 0.6731514691891585, 0.6731514691891585, 0.6731514691891585, 0.19532956597327444, 0.19532956597327444, 0.19532956597327444, 0.16553901701378781, 0.16553901701378781, 0.16553901701378781, 0.19665918553669848, 0.19665918553669848, 0.19665918553669848, 0.19490589346656984, 0.19490589346656984, 0.19490589346656984, 0.18608921386228516, 0.18608921386228516, 0.18608921386228516, 0.19899932784457042, 0.19899932784457042, 0.19899932784457042, 0.224894278517754, 0.224894278517754, 0.224894278517754, 0.1985193725440395, 0.1985193725440395, 0.1985193725440395, 0.08621718826736047, 0.08621718826736047, 0.08621718826736047, 0.07524810974469687, 0.07524810974469687, 0.07524810974469687, 0.07362098059935285, 0.07362098059935285, 0.07362098059935285]}, "mutation_prompt": null}
{"id": "6461a9ee-b9fe-4653-abe9-1dc3bf0c575e", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                self.w = 0.9 - 0.5 * (evaluations / self.budget)  # Dynamic inertia weight adjustment\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Introduced a dynamic inertia weight adjustment in the PSO to enhance convergence speed and accuracy.", "configspace": "", "generation": 45, "fitness": 0.20577492177781914, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.44758853118755115, 0.44758853118755115, 0.44758853118755115, 0.5466156977500924, 0.5466156977500924, 0.5466156977500924, 0.4807008716687816, 0.4807008716687816, 0.4807008716687816, 0.12366888526057884, 0.12366888526057884, 0.12366888526057884, 0.17767300616067727, 0.17767300616067727, 0.17767300616067727, 0.2065798473130781, 0.2065798473130781, 0.2065798473130781, 0.0988579180126189, 0.0988579180126189, 0.0988579180126189, 0.1081361840076337, 0.1081361840076337, 0.1081361840076337, 0.09963585736028491, 0.09963585736028491, 0.09963585736028491, 0.08109380353766449, 0.08109380353766449, 0.08109380353766449, 0.08519866607291138, 0.08519866607291138, 0.08519866607291138, 0.09163140126409886, 0.09163140126409886, 0.09163140126409886, 0.975651045096156, 0.975651045096156, 0.975651045096156, 0.9790362992505957, 0.9790362992505957, 0.9790362992505957, 0.9736668129840342, 0.9736668129840342, 0.9736668129840342, 0.2913679120706736, 0.2913679120706736, 0.2913679120706736, 0.2549019415282592, 0.2549019415282592, 0.2549019415282592, 0.2595875451798102, 0.2595875451798102, 0.2595875451798102, 0.24975608698443053, 0.24975608698443053, 0.24975608698443053, 0.16938114229449852, 0.16938114229449852, 0.16938114229449852, 0.16184508959737798, 0.16184508959737798, 0.16184508959737798, 0.09441635482944422, 0.09441635482944422, 0.09441635482944422, 0.19078210425831343, 0.19078210425831343, 0.19078210425831343, 0.19028496913239568, 0.19028496913239568, 0.19028496913239568, 0.042746067586211356, 0.042746067586211356, 0.042746067586211356, 0.11527350072230225, 0.11527350072230225, 0.11527350072230225, 0.12431717607551385, 0.12431717607551385, 0.12431717607551385, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0787400252107916, 0.0787400252107916, 0.0787400252107916, 0.06907151679223622, 0.06907151679223622, 0.06907151679223622, 0.06435206586822972, 0.06435206586822972, 0.06435206586822972, 0.017864077197967676, 0.017864077197967676, 0.017864077197967676, 0.06176875968303708, 0.06176875968303708, 0.06176875968303708, 0.03499618171061425, 0.03499618171061425, 0.03499618171061425, 0.0370664250550683, 0.0370664250550683, 0.0370664250550683, 0.0891172103226352, 0.0891172103226352, 0.0891172103226352, 0.03892962365755337, 0.03892962365755337, 0.03892962365755337, 0.3835547593022345, 0.3835547593022345, 0.3835547593022345, 0.39393277978697494, 0.39393277978697494, 0.39393277978697494, 0.3793510952057222, 0.3793510952057222, 0.3793510952057222, 0.08424628248284693, 0.08424628248284693, 0.08424628248284693, 0.09840668691393673, 0.09840668691393673, 0.09840668691393673, 0.10339739159368966, 0.10339739159368966, 0.10339739159368966, 0.17211817624461512, 0.17211817624461512, 0.17211817624461512, 0.1863635839168436, 0.1863635839168436, 0.1863635839168436, 0.15120320850345137, 0.15120320850345137, 0.15120320850345137, 0.28121285095416215, 0.28121285095416215, 0.28121285095416215, 0.26219718151078497, 0.26219718151078497, 0.26219718151078497, 0.2653662357826615, 0.2653662357826615, 0.2653662357826615, 0.18477563388248686, 0.18477563388248686, 0.18477563388248686, 0.20250773159947, 0.20250773159947, 0.20250773159947, 0.1756798866194491, 0.1756798866194491, 0.1756798866194491, 0.17662582065245247, 0.17662582065245247, 0.17662582065245247, 0.1802211752050622, 0.1802211752050622, 0.1802211752050622, 0.1862266468019117, 0.1862266468019117, 0.1862266468019117, 0.18178382476566035, 0.18178382476566035, 0.18178382476566035, 0.1887550617696726, 0.1887550617696726, 0.1887550617696726, 0.20987439864355828, 0.20987439864355828, 0.20987439864355828, 0.5613909862669498, 0.5613909862669498, 0.5613909862669498, 0.1511788111992819, 0.1511788111992819, 0.1511788111992819, 0.1791580623678275, 0.1791580623678275, 0.1791580623678275, 0.19193715196545014, 0.19193715196545014, 0.19193715196545014, 0.19660007486030728, 0.19660007486030728, 0.19660007486030728, 0.1857322973189689, 0.1857322973189689, 0.1857322973189689, 0.195319602465868, 0.195319602465868, 0.195319602465868, 0.19033097172020963, 0.19033097172020963, 0.19033097172020963, 0.1756322862540154, 0.1756322862540154, 0.1756322862540154, 0.0709170233676294, 0.0709170233676294, 0.0709170233676294, 0.07582857042875879, 0.07582857042875879, 0.07582857042875879, 0.08136751496594352, 0.08136751496594352, 0.08136751496594352]}, "mutation_prompt": null}
{"id": "2d30b883-4387-442d-a098-a5d86b04ee58", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.6  # Inertia weight for PSO, increased by 0.1\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Slightly increase the inertia weight `w` for better exploration and balance between exploration and exploitation.", "configspace": "", "generation": 46, "fitness": 0.2797633581038645, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.23.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.7749319254847502, 0.7749319254847502, 0.7749319254847502, 0.7587484578443413, 0.7587484578443413, 0.7587484578443413, 0.7978635231988749, 0.7978635231988749, 0.7978635231988749, 0.4439637678128827, 0.4439637678128827, 0.4439637678128827, 0.4445003520696983, 0.4445003520696983, 0.4445003520696983, 0.2942508039327506, 0.2942508039327506, 0.2942508039327506, 0.13014604240515093, 0.13014604240515093, 0.13014604240515093, 0.1497182183100938, 0.1497182183100938, 0.1497182183100938, 0.13663223051302198, 0.13663223051302198, 0.13663223051302198, 0.13186116070199716, 0.13186116070199716, 0.13186116070199716, 0.09731148283043822, 0.09731148283043822, 0.09731148283043822, 0.11394990384542703, 0.11394990384542703, 0.11394990384542703, 0.9734237863293943, 0.9734237863293943, 0.9734237863293943, 0.9739704831338388, 0.9739704831338388, 0.9739704831338388, 0.9702329832334816, 0.9702329832334816, 0.9702329832334816, 0.44156411476993496, 0.44156411476993496, 0.44156411476993496, 0.4107148703423873, 0.4107148703423873, 0.4107148703423873, 0.4671670964483595, 0.4671670964483595, 0.4671670964483595, 0.5370005212694076, 0.5370005212694076, 0.5370005212694076, 0.21193338043049492, 0.21193338043049492, 0.21193338043049492, 0.2294670974525964, 0.2294670974525964, 0.2294670974525964, 0.1788270761033829, 0.1788270761033829, 0.1788270761033829, 0.186727006497306, 0.186727006497306, 0.186727006497306, 0.17891800136124925, 0.17891800136124925, 0.17891800136124925, 0.189526929226139, 0.189526929226139, 0.189526929226139, 0.19433655004047012, 0.19433655004047012, 0.19433655004047012, 0.21524852184964094, 0.21524852184964094, 0.21524852184964094, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006557029308984941, 0.006557029308984941, 0.006557029308984941, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08742355152447412, 0.08742355152447412, 0.08742355152447412, 0.05324146281287723, 0.05324146281287723, 0.05324146281287723, 0.0545836430851625, 0.0545836430851625, 0.0545836430851625, 0.1395688402667321, 0.1395688402667321, 0.1395688402667321, 0.06693852141994228, 0.06693852141994228, 0.06693852141994228, 0.22134018702291092, 0.22134018702291092, 0.22134018702291092, 0.16964127007509866, 0.16964127007509866, 0.16964127007509866, 0.10854765984722703, 0.10854765984722703, 0.10854765984722703, 0.056063385569116164, 0.056063385569116164, 0.056063385569116164, 0.5065431708667353, 0.5065431708667353, 0.5065431708667353, 0.4937063131907611, 0.4937063131907611, 0.4937063131907611, 0.5123426762216357, 0.5123426762216357, 0.5123426762216357, 0.1606868198784447, 0.1606868198784447, 0.1606868198784447, 0.13735228368598096, 0.13735228368598096, 0.13735228368598096, 0.1117564102585793, 0.1117564102585793, 0.1117564102585793, 0.23130743993398406, 0.23130743993398406, 0.23130743993398406, 0.18278489640456408, 0.18278489640456408, 0.18278489640456408, 0.3655003287552415, 0.3655003287552415, 0.3655003287552415, 0.3347281897822797, 0.3347281897822797, 0.3347281897822797, 0.3609055168021359, 0.3609055168021359, 0.3609055168021359, 0.4097281005190886, 0.4097281005190886, 0.4097281005190886, 0.29198801442616706, 0.29198801442616706, 0.29198801442616706, 0.22406921661621526, 0.22406921661621526, 0.22406921661621526, 0.20054824237285573, 0.20054824237285573, 0.20054824237285573, 0.18604405838175953, 0.18604405838175953, 0.18604405838175953, 0.21032800172109323, 0.21032800172109323, 0.21032800172109323, 0.19941601620425142, 0.19941601620425142, 0.19941601620425142, 0.18669218143741628, 0.18669218143741628, 0.18669218143741628, 0.23359481647632352, 0.23359481647632352, 0.23359481647632352, 0.3858506879691199, 0.3858506879691199, 0.3858506879691199, 0.8596568202874606, 0.8596568202874606, 0.8596568202874606, 0.16336119700933072, 0.16336119700933072, 0.16336119700933072, 0.16080004086557476, 0.16080004086557476, 0.16080004086557476, 0.16674224910528046, 0.16674224910528046, 0.16674224910528046, 0.20539043656553735, 0.20539043656553735, 0.20539043656553735, 0.19388040372637227, 0.19388040372637227, 0.19388040372637227, 0.18939349308545184, 0.18939349308545184, 0.18939349308545184, 0.20059231881802364, 0.20059231881802364, 0.20059231881802364, 0.19243905393939909, 0.19243905393939909, 0.19243905393939909, 0.0781173685526273, 0.0781173685526273, 0.0781173685526273, 0.07776410995802474, 0.07776410995802474, 0.07776410995802474, 0.13190907129049245, 0.13190907129049245, 0.13190907129049245]}, "mutation_prompt": null}
{"id": "8fc877e1-2b96-4603-857d-8eaff9ceadaa", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.6  # Inertia weight for PSO (changed from 0.5)\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced global exploration by slightly adjusting the inertia weight in PSO.", "configspace": "", "generation": 47, "fitness": 0.2797633581038645, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.23.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.7749319254847502, 0.7749319254847502, 0.7749319254847502, 0.7587484578443413, 0.7587484578443413, 0.7587484578443413, 0.7978635231988749, 0.7978635231988749, 0.7978635231988749, 0.4439637678128827, 0.4439637678128827, 0.4439637678128827, 0.4445003520696983, 0.4445003520696983, 0.4445003520696983, 0.2942508039327506, 0.2942508039327506, 0.2942508039327506, 0.13014604240515093, 0.13014604240515093, 0.13014604240515093, 0.1497182183100938, 0.1497182183100938, 0.1497182183100938, 0.13663223051302198, 0.13663223051302198, 0.13663223051302198, 0.13186116070199716, 0.13186116070199716, 0.13186116070199716, 0.09731148283043822, 0.09731148283043822, 0.09731148283043822, 0.11394990384542703, 0.11394990384542703, 0.11394990384542703, 0.9734237863293943, 0.9734237863293943, 0.9734237863293943, 0.9739704831338388, 0.9739704831338388, 0.9739704831338388, 0.9702329832334816, 0.9702329832334816, 0.9702329832334816, 0.44156411476993496, 0.44156411476993496, 0.44156411476993496, 0.4107148703423873, 0.4107148703423873, 0.4107148703423873, 0.4671670964483595, 0.4671670964483595, 0.4671670964483595, 0.5370005212694076, 0.5370005212694076, 0.5370005212694076, 0.21193338043049492, 0.21193338043049492, 0.21193338043049492, 0.2294670974525964, 0.2294670974525964, 0.2294670974525964, 0.1788270761033829, 0.1788270761033829, 0.1788270761033829, 0.186727006497306, 0.186727006497306, 0.186727006497306, 0.17891800136124925, 0.17891800136124925, 0.17891800136124925, 0.189526929226139, 0.189526929226139, 0.189526929226139, 0.19433655004047012, 0.19433655004047012, 0.19433655004047012, 0.21524852184964094, 0.21524852184964094, 0.21524852184964094, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006557029308984941, 0.006557029308984941, 0.006557029308984941, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08742355152447412, 0.08742355152447412, 0.08742355152447412, 0.05324146281287723, 0.05324146281287723, 0.05324146281287723, 0.0545836430851625, 0.0545836430851625, 0.0545836430851625, 0.1395688402667321, 0.1395688402667321, 0.1395688402667321, 0.06693852141994228, 0.06693852141994228, 0.06693852141994228, 0.22134018702291092, 0.22134018702291092, 0.22134018702291092, 0.16964127007509866, 0.16964127007509866, 0.16964127007509866, 0.10854765984722703, 0.10854765984722703, 0.10854765984722703, 0.056063385569116164, 0.056063385569116164, 0.056063385569116164, 0.5065431708667353, 0.5065431708667353, 0.5065431708667353, 0.4937063131907611, 0.4937063131907611, 0.4937063131907611, 0.5123426762216357, 0.5123426762216357, 0.5123426762216357, 0.1606868198784447, 0.1606868198784447, 0.1606868198784447, 0.13735228368598096, 0.13735228368598096, 0.13735228368598096, 0.1117564102585793, 0.1117564102585793, 0.1117564102585793, 0.23130743993398406, 0.23130743993398406, 0.23130743993398406, 0.18278489640456408, 0.18278489640456408, 0.18278489640456408, 0.3655003287552415, 0.3655003287552415, 0.3655003287552415, 0.3347281897822797, 0.3347281897822797, 0.3347281897822797, 0.3609055168021359, 0.3609055168021359, 0.3609055168021359, 0.4097281005190886, 0.4097281005190886, 0.4097281005190886, 0.29198801442616706, 0.29198801442616706, 0.29198801442616706, 0.22406921661621526, 0.22406921661621526, 0.22406921661621526, 0.20054824237285573, 0.20054824237285573, 0.20054824237285573, 0.18604405838175953, 0.18604405838175953, 0.18604405838175953, 0.21032800172109323, 0.21032800172109323, 0.21032800172109323, 0.19941601620425142, 0.19941601620425142, 0.19941601620425142, 0.18669218143741628, 0.18669218143741628, 0.18669218143741628, 0.23359481647632352, 0.23359481647632352, 0.23359481647632352, 0.3858506879691199, 0.3858506879691199, 0.3858506879691199, 0.8596568202874606, 0.8596568202874606, 0.8596568202874606, 0.16336119700933072, 0.16336119700933072, 0.16336119700933072, 0.16080004086557476, 0.16080004086557476, 0.16080004086557476, 0.16674224910528046, 0.16674224910528046, 0.16674224910528046, 0.20539043656553735, 0.20539043656553735, 0.20539043656553735, 0.19388040372637227, 0.19388040372637227, 0.19388040372637227, 0.18939349308545184, 0.18939349308545184, 0.18939349308545184, 0.20059231881802364, 0.20059231881802364, 0.20059231881802364, 0.19243905393939909, 0.19243905393939909, 0.19243905393939909, 0.0781173685526273, 0.0781173685526273, 0.0781173685526273, 0.07776410995802474, 0.07776410995802474, 0.07776410995802474, 0.13190907129049245, 0.13190907129049245, 0.13190907129049245]}, "mutation_prompt": null}
{"id": "c40afced-e0b7-43ca-9dc8-655fd27843dc", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.w = 0.5 + 0.4 * (1 - evaluations/self.budget)  # Change here\n                self.c1 = 2.7 - evaluations/self.budget * 1.5\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Slightly increase the exploration by modifying the inertia weight `w` dynamically during the PSO step.", "configspace": "", "generation": 48, "fitness": 0.19059851251948495, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.43760528614903205, 0.43760528614903205, 0.43760528614903205, 0.45484833459995444, 0.45484833459995444, 0.45484833459995444, 0.480777607373296, 0.480777607373296, 0.480777607373296, 0.10137514983636575, 0.10137514983636575, 0.10137514983636575, 0.04983464530717885, 0.04983464530717885, 0.04983464530717885, 0.02628286255110235, 0.02628286255110235, 0.02628286255110235, 0.08447806363658816, 0.08447806363658816, 0.08447806363658816, 0.08766721836916458, 0.08766721836916458, 0.08766721836916458, 0.08502418371943421, 0.08502418371943421, 0.08502418371943421, 0.07705562381724196, 0.07705562381724196, 0.07705562381724196, 0.07472857816598899, 0.07472857816598899, 0.07472857816598899, 0.08061123337641407, 0.08061123337641407, 0.08061123337641407, 0.975652090494761, 0.975652090494761, 0.975652090494761, 0.9790366890189451, 0.9790366890189451, 0.9790366890189451, 0.9736664876013109, 0.9736664876013109, 0.9736664876013109, 0.28142954867763903, 0.28142954867763903, 0.28142954867763903, 0.19621990574529335, 0.19621990574529335, 0.19621990574529335, 0.20966291043694363, 0.20966291043694363, 0.20966291043694363, 0.18701423690835983, 0.18701423690835983, 0.18701423690835983, 0.18332241035662344, 0.18332241035662344, 0.18332241035662344, 0.1991846570435214, 0.1991846570435214, 0.1991846570435214, 0.12333134526265255, 0.12333134526265255, 0.12333134526265255, 0.13085889400922657, 0.13085889400922657, 0.13085889400922657, 0.12340971554608982, 0.12340971554608982, 0.12340971554608982, 0.019550142587097974, 0.019550142587097974, 0.019550142587097974, 0.10950163133379887, 0.10950163133379887, 0.10950163133379887, 0.1177956983214784, 0.1177956983214784, 0.1177956983214784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00950637459719128, 0.00950637459719128, 0.00950637459719128, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10106885035596136, 0.10106885035596136, 0.10106885035596136, 0.04465698958158304, 0.04465698958158304, 0.04465698958158304, 0.07258536355953205, 0.07258536355953205, 0.07258536355953205, 0.013005801850459853, 0.013005801850459853, 0.013005801850459853, 0.006472194279436683, 0.006472194279436683, 0.006472194279436683, 0.023553559527354606, 0.023553559527354606, 0.023553559527354606, 0.03591986374834777, 0.03591986374834777, 0.03591986374834777, 0.04411588696491331, 0.04411588696491331, 0.04411588696491331, 0.08604786458356117, 0.08604786458356117, 0.08604786458356117, 0.3721972396435791, 0.3721972396435791, 0.3721972396435791, 0.32785117041360423, 0.32785117041360423, 0.32785117041360423, 0.3191748871910909, 0.3191748871910909, 0.3191748871910909, 0.08459005096922123, 0.08459005096922123, 0.08459005096922123, 0.10192835821712865, 0.10192835821712865, 0.10192835821712865, 0.09248598957574816, 0.09248598957574816, 0.09248598957574816, 0.164390078148123, 0.164390078148123, 0.164390078148123, 0.16513681059269092, 0.16513681059269092, 0.16513681059269092, 0.14814881404972235, 0.14814881404972235, 0.14814881404972235, 0.261510016304488, 0.261510016304488, 0.261510016304488, 0.23815083626711342, 0.23815083626711342, 0.23815083626711342, 0.2543841551111472, 0.2543841551111472, 0.2543841551111472, 0.22006955393179928, 0.22006955393179928, 0.22006955393179928, 0.16858121251520064, 0.16858121251520064, 0.16858121251520064, 0.18557368929430518, 0.18557368929430518, 0.18557368929430518, 0.18243209213810208, 0.18243209213810208, 0.18243209213810208, 0.19769733786703703, 0.19769733786703703, 0.19769733786703703, 0.19230837653931554, 0.19230837653931554, 0.19230837653931554, 0.17570374458313687, 0.17570374458313687, 0.17570374458313687, 0.20251793593804024, 0.20251793593804024, 0.20251793593804024, 0.16434101028399106, 0.16434101028399106, 0.16434101028399106, 0.5047688863531066, 0.5047688863531066, 0.5047688863531066, 0.19016039680171526, 0.19016039680171526, 0.19016039680171526, 0.17640693852197142, 0.17640693852197142, 0.17640693852197142, 0.19621505054565602, 0.19621505054565602, 0.19621505054565602, 0.19381752126562424, 0.19381752126562424, 0.19381752126562424, 0.20035116540291698, 0.20035116540291698, 0.20035116540291698, 0.18453816311407745, 0.18453816311407745, 0.18453816311407745, 0.17097013394164262, 0.17097013394164262, 0.17097013394164262, 0.19104830268622197, 0.19104830268622197, 0.19104830268622197, 0.07310600968431136, 0.07310600968431136, 0.07310600968431136, 0.06854543834690974, 0.06854543834690974, 0.06854543834690974, 0.06693363587033596, 0.06693363587033596, 0.06693363587033596]}, "mutation_prompt": null}
{"id": "4119e3b6-d1ac-493b-b502-979503b718da", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-3, 3, (self.pop_size, self.dim))  # Changed initial velocity range\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.c1 = 2.7 - evaluations/self.budget * 1.5\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhance the initial velocity range to improve population diversity early in the search process.", "configspace": "", "generation": 49, "fitness": 0.3087344134835044, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.26.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.8410148738590526, 0.8410148738590526, 0.8410148738590526, 0.866441917580737, 0.866441917580737, 0.866441917580737, 0.8417780232269657, 0.8417780232269657, 0.8417780232269657, 0.6178949856697551, 0.6178949856697551, 0.6178949856697551, 0.5697601819356579, 0.5697601819356579, 0.5697601819356579, 0.6470307429578026, 0.6470307429578026, 0.6470307429578026, 0.1441145907502731, 0.1441145907502731, 0.1441145907502731, 0.16575315171190963, 0.16575315171190963, 0.16575315171190963, 0.1626980722871334, 0.1626980722871334, 0.1626980722871334, 0.11977653970475277, 0.11977653970475277, 0.11977653970475277, 0.1298250227121689, 0.1298250227121689, 0.1298250227121689, 0.15571255519587268, 0.15571255519587268, 0.15571255519587268, 0.9669818034419639, 0.9669818034419639, 0.9669818034419639, 0.9740113874619791, 0.9740113874619791, 0.9740113874619791, 0.9671315845351345, 0.9671315845351345, 0.9671315845351345, 0.6422389750741678, 0.6422389750741678, 0.6422389750741678, 0.5739999944533529, 0.5739999944533529, 0.5739999944533529, 0.5962740408886049, 0.5962740408886049, 0.5962740408886049, 0.21778976354359292, 0.21778976354359292, 0.21778976354359292, 0.19117929726092653, 0.19117929726092653, 0.19117929726092653, 0.6591205607819547, 0.6591205607819547, 0.6591205607819547, 0.14225602388371916, 0.14225602388371916, 0.14225602388371916, 0.1295324322762117, 0.1295324322762117, 0.1295324322762117, 0.1257706053137766, 0.1257706053137766, 0.1257706053137766, 0.22103684620075614, 0.22103684620075614, 0.22103684620075614, 0.20557889763728976, 0.20557889763728976, 0.20557889763728976, 0.2349387171164875, 0.2349387171164875, 0.2349387171164875, 0.05142707740914043, 0.05142707740914043, 0.05142707740914043, 0.021095321388293398, 0.021095321388293398, 0.021095321388293398, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06545096879504486, 0.06545096879504486, 0.06545096879504486, 0.07327133597277147, 0.07327133597277147, 0.07327133597277147, 0.059754635418169166, 0.059754635418169166, 0.059754635418169166, 0.04923057844689627, 0.04923057844689627, 0.04923057844689627, 0.08508515773132697, 0.08508515773132697, 0.08508515773132697, 0.07746156630978462, 0.07746156630978462, 0.07746156630978462, 0.09736798566647253, 0.09736798566647253, 0.09736798566647253, 0.1295183617989747, 0.1295183617989747, 0.1295183617989747, 0.180226254137138, 0.180226254137138, 0.180226254137138, 0.5340717327953133, 0.5340717327953133, 0.5340717327953133, 0.5549286548492467, 0.5549286548492467, 0.5549286548492467, 0.5511728562475278, 0.5511728562475278, 0.5511728562475278, 0.1290887489166842, 0.1290887489166842, 0.1290887489166842, 0.10918647795583603, 0.10918647795583603, 0.10918647795583603, 0.12783560739958633, 0.12783560739958633, 0.12783560739958633, 0.19122193500637286, 0.19122193500637286, 0.19122193500637286, 0.15683078541780526, 0.15683078541780526, 0.15683078541780526, 0.18483281620263003, 0.18483281620263003, 0.18483281620263003, 0.34451992948497334, 0.34451992948497334, 0.34451992948497334, 0.30351589780124066, 0.30351589780124066, 0.30351589780124066, 0.4542111195285752, 0.4542111195285752, 0.4542111195285752, 0.3077835693781513, 0.3077835693781513, 0.3077835693781513, 0.2292786863974423, 0.2292786863974423, 0.2292786863974423, 0.1906543265374474, 0.1906543265374474, 0.1906543265374474, 0.2330532299075475, 0.2330532299075475, 0.2330532299075475, 0.2698658949233179, 0.2698658949233179, 0.2698658949233179, 0.2250677971764149, 0.2250677971764149, 0.2250677971764149, 0.21055327676715607, 0.21055327676715607, 0.21055327676715607, 0.1969674346837128, 0.1969674346837128, 0.1969674346837128, 0.556529145882336, 0.556529145882336, 0.556529145882336, 0.8555233911577718, 0.8555233911577718, 0.8555233911577718, 0.19177758150697743, 0.19177758150697743, 0.19177758150697743, 0.7289808813036078, 0.7289808813036078, 0.7289808813036078, 0.1686246379047459, 0.1686246379047459, 0.1686246379047459, 0.20843006377764828, 0.20843006377764828, 0.20843006377764828, 0.16325458297668027, 0.16325458297668027, 0.16325458297668027, 0.21166280859297337, 0.21166280859297337, 0.21166280859297337, 0.17851137732767997, 0.17851137732767997, 0.17851137732767997, 0.18150851740771068, 0.18150851740771068, 0.18150851740771068, 0.08863505294288321, 0.08863505294288321, 0.08863505294288321, 0.09545638916467747, 0.09545638916467747, 0.09545638916467747, 0.09571173295363045, 0.09571173295363045, 0.09571173295363045]}, "mutation_prompt": null}
{"id": "b271b694-3e87-4652-a391-643d1b9fa9fc", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.9  # Increased inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Improved exploration by adjusting the inertia weight in PSO dynamically.", "configspace": "", "generation": 50, "fitness": 0.1441720523115704, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.19.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.225530158239731, 0.225530158239731, 0.225530158239731, 0.24102549637469195, 0.24102549637469195, 0.24102549637469195, 0.2581845406140475, 0.2581845406140475, 0.2581845406140475, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0027352159426049516, 0.0027352159426049516, 0.0027352159426049516, 0.06652792487262504, 0.06652792487262504, 0.06652792487262504, 0.09314280357740623, 0.09314280357740623, 0.09314280357740623, 0.0643058491758024, 0.0643058491758024, 0.0643058491758024, 0.0536696617311716, 0.0536696617311716, 0.0536696617311716, 0.041845696290651935, 0.041845696290651935, 0.041845696290651935, 0.05183147612374672, 0.05183147612374672, 0.05183147612374672, 0.9756571342617909, 0.9756571342617909, 0.9756571342617909, 0.9790382602177335, 0.9790382602177335, 0.9790382602177335, 0.9736679903033655, 0.9736679903033655, 0.9736679903033655, 0.12934050656409524, 0.12934050656409524, 0.12934050656409524, 0.12113467616905238, 0.12113467616905238, 0.12113467616905238, 0.12605699359048428, 0.12605699359048428, 0.12605699359048428, 0.12222794623813915, 0.12222794623813915, 0.12222794623813915, 0.14197591600514592, 0.14197591600514592, 0.14197591600514592, 0.160973079062407, 0.160973079062407, 0.160973079062407, 0.0013418709746427782, 0.0013418709746427782, 0.0013418709746427782, 0.07432826777676815, 0.07432826777676815, 0.07432826777676815, 0.03683146238027257, 0.03683146238027257, 0.03683146238027257, 0.01837651789742689, 0.01837651789742689, 0.01837651789742689, 0.013969647859675027, 0.013969647859675027, 0.013969647859675027, 0.0768180469552302, 0.0768180469552302, 0.0768180469552302, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07545099388574528, 0.07545099388574528, 0.07545099388574528, 0.05521665146764321, 0.05521665146764321, 0.05521665146764321, 0.07429071738533388, 0.07429071738533388, 0.07429071738533388, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0036208562121761156, 0.0036208562121761156, 0.0036208562121761156, 0.02274439181806942, 0.02274439181806942, 0.02274439181806942, 0.03153877287855389, 0.03153877287855389, 0.03153877287855389, 0.24207348159991715, 0.24207348159991715, 0.24207348159991715, 0.21714108404647647, 0.21714108404647647, 0.21714108404647647, 0.28202609375876364, 0.28202609375876364, 0.28202609375876364, 0.06218382526240929, 0.06218382526240929, 0.06218382526240929, 0.06034204426024392, 0.06034204426024392, 0.06034204426024392, 0.05799854940050242, 0.05799854940050242, 0.05799854940050242, 0.15519055862442144, 0.15519055862442144, 0.15519055862442144, 0.1346225428558835, 0.1346225428558835, 0.1346225428558835, 0.11697966583152342, 0.11697966583152342, 0.11697966583152342, 0.1682335212822611, 0.1682335212822611, 0.1682335212822611, 0.17626923146264217, 0.17626923146264217, 0.17626923146264217, 0.1864387691783158, 0.1864387691783158, 0.1864387691783158, 0.12822001066687716, 0.12822001066687716, 0.12822001066687716, 0.131688075764407, 0.131688075764407, 0.131688075764407, 0.1194707900292129, 0.1194707900292129, 0.1194707900292129, 0.18389718750059547, 0.18389718750059547, 0.18389718750059547, 0.15301497878723513, 0.15301497878723513, 0.15301497878723513, 0.17228559530329624, 0.17228559530329624, 0.17228559530329624, 0.15909767944623654, 0.15909767944623654, 0.15909767944623654, 0.1523584853562031, 0.1523584853562031, 0.1523584853562031, 0.16438800784699947, 0.16438800784699947, 0.16438800784699947, 0.276917542264724, 0.276917542264724, 0.276917542264724, 0.1635374134925529, 0.1635374134925529, 0.1635374134925529, 0.15285421241275776, 0.15285421241275776, 0.15285421241275776, 0.1588525178648782, 0.1588525178648782, 0.1588525178648782, 0.1675899696243508, 0.1675899696243508, 0.1675899696243508, 0.19389761657404048, 0.19389761657404048, 0.19389761657404048, 0.18414155075123495, 0.18414155075123495, 0.18414155075123495, 0.1715165018747632, 0.1715165018747632, 0.1715165018747632, 0.17681228534650273, 0.17681228534650273, 0.17681228534650273, 0.07312310665594046, 0.07312310665594046, 0.07312310665594046, 0.06893903234604626, 0.06893903234604626, 0.06893903234604626, 0.05408631611462311, 0.05408631611462311, 0.05408631611462311]}, "mutation_prompt": null}
{"id": "80ac4d08-1855-48a3-982f-83b7c8e485f0", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                self.w = 0.9 - 0.5 * (evaluations / self.budget)  # Modified inertia weight\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Altered inertia weight in PSO dynamically to improve convergence stability.", "configspace": "", "generation": 51, "fitness": 0.20577492177781914, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.44758853118755115, 0.44758853118755115, 0.44758853118755115, 0.5466156977500924, 0.5466156977500924, 0.5466156977500924, 0.4807008716687816, 0.4807008716687816, 0.4807008716687816, 0.12366888526057884, 0.12366888526057884, 0.12366888526057884, 0.17767300616067727, 0.17767300616067727, 0.17767300616067727, 0.2065798473130781, 0.2065798473130781, 0.2065798473130781, 0.0988579180126189, 0.0988579180126189, 0.0988579180126189, 0.1081361840076337, 0.1081361840076337, 0.1081361840076337, 0.09963585736028491, 0.09963585736028491, 0.09963585736028491, 0.08109380353766449, 0.08109380353766449, 0.08109380353766449, 0.08519866607291138, 0.08519866607291138, 0.08519866607291138, 0.09163140126409886, 0.09163140126409886, 0.09163140126409886, 0.975651045096156, 0.975651045096156, 0.975651045096156, 0.9790362992505957, 0.9790362992505957, 0.9790362992505957, 0.9736668129840342, 0.9736668129840342, 0.9736668129840342, 0.2913679120706736, 0.2913679120706736, 0.2913679120706736, 0.2549019415282592, 0.2549019415282592, 0.2549019415282592, 0.2595875451798102, 0.2595875451798102, 0.2595875451798102, 0.24975608698443053, 0.24975608698443053, 0.24975608698443053, 0.16938114229449852, 0.16938114229449852, 0.16938114229449852, 0.16184508959737798, 0.16184508959737798, 0.16184508959737798, 0.09441635482944422, 0.09441635482944422, 0.09441635482944422, 0.19078210425831343, 0.19078210425831343, 0.19078210425831343, 0.19028496913239568, 0.19028496913239568, 0.19028496913239568, 0.042746067586211356, 0.042746067586211356, 0.042746067586211356, 0.11527350072230225, 0.11527350072230225, 0.11527350072230225, 0.12431717607551385, 0.12431717607551385, 0.12431717607551385, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0787400252107916, 0.0787400252107916, 0.0787400252107916, 0.06907151679223622, 0.06907151679223622, 0.06907151679223622, 0.06435206586822972, 0.06435206586822972, 0.06435206586822972, 0.017864077197967676, 0.017864077197967676, 0.017864077197967676, 0.06176875968303708, 0.06176875968303708, 0.06176875968303708, 0.03499618171061425, 0.03499618171061425, 0.03499618171061425, 0.0370664250550683, 0.0370664250550683, 0.0370664250550683, 0.0891172103226352, 0.0891172103226352, 0.0891172103226352, 0.03892962365755337, 0.03892962365755337, 0.03892962365755337, 0.3835547593022345, 0.3835547593022345, 0.3835547593022345, 0.39393277978697494, 0.39393277978697494, 0.39393277978697494, 0.3793510952057222, 0.3793510952057222, 0.3793510952057222, 0.08424628248284693, 0.08424628248284693, 0.08424628248284693, 0.09840668691393673, 0.09840668691393673, 0.09840668691393673, 0.10339739159368966, 0.10339739159368966, 0.10339739159368966, 0.17211817624461512, 0.17211817624461512, 0.17211817624461512, 0.1863635839168436, 0.1863635839168436, 0.1863635839168436, 0.15120320850345137, 0.15120320850345137, 0.15120320850345137, 0.28121285095416215, 0.28121285095416215, 0.28121285095416215, 0.26219718151078497, 0.26219718151078497, 0.26219718151078497, 0.2653662357826615, 0.2653662357826615, 0.2653662357826615, 0.18477563388248686, 0.18477563388248686, 0.18477563388248686, 0.20250773159947, 0.20250773159947, 0.20250773159947, 0.1756798866194491, 0.1756798866194491, 0.1756798866194491, 0.17662582065245247, 0.17662582065245247, 0.17662582065245247, 0.1802211752050622, 0.1802211752050622, 0.1802211752050622, 0.1862266468019117, 0.1862266468019117, 0.1862266468019117, 0.18178382476566035, 0.18178382476566035, 0.18178382476566035, 0.1887550617696726, 0.1887550617696726, 0.1887550617696726, 0.20987439864355828, 0.20987439864355828, 0.20987439864355828, 0.5613909862669498, 0.5613909862669498, 0.5613909862669498, 0.1511788111992819, 0.1511788111992819, 0.1511788111992819, 0.1791580623678275, 0.1791580623678275, 0.1791580623678275, 0.19193715196545014, 0.19193715196545014, 0.19193715196545014, 0.19660007486030728, 0.19660007486030728, 0.19660007486030728, 0.1857322973189689, 0.1857322973189689, 0.1857322973189689, 0.195319602465868, 0.195319602465868, 0.195319602465868, 0.19033097172020963, 0.19033097172020963, 0.19033097172020963, 0.1756322862540154, 0.1756322862540154, 0.1756322862540154, 0.0709170233676294, 0.0709170233676294, 0.0709170233676294, 0.07582857042875879, 0.07582857042875879, 0.07582857042875879, 0.08136751496594352, 0.08136751496594352, 0.08136751496594352]}, "mutation_prompt": null}
{"id": "a9989ed1-2483-4586-be84-b34826200353", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                # Adjust inertia weight dynamically\n                self.w = 0.9 - (0.5 * evaluations / self.budget)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Introduced a dynamic adjustment of inertia weight (w) in PSO to balance exploration and exploitation.", "configspace": "", "generation": 52, "fitness": 0.20577492177781914, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.44758853118755115, 0.44758853118755115, 0.44758853118755115, 0.5466156977500924, 0.5466156977500924, 0.5466156977500924, 0.4807008716687816, 0.4807008716687816, 0.4807008716687816, 0.12366888526057884, 0.12366888526057884, 0.12366888526057884, 0.17767300616067727, 0.17767300616067727, 0.17767300616067727, 0.2065798473130781, 0.2065798473130781, 0.2065798473130781, 0.0988579180126189, 0.0988579180126189, 0.0988579180126189, 0.1081361840076337, 0.1081361840076337, 0.1081361840076337, 0.09963585736028491, 0.09963585736028491, 0.09963585736028491, 0.08109380353766449, 0.08109380353766449, 0.08109380353766449, 0.08519866607291138, 0.08519866607291138, 0.08519866607291138, 0.09163140126409886, 0.09163140126409886, 0.09163140126409886, 0.975651045096156, 0.975651045096156, 0.975651045096156, 0.9790362992505957, 0.9790362992505957, 0.9790362992505957, 0.9736668129840342, 0.9736668129840342, 0.9736668129840342, 0.2913679120706736, 0.2913679120706736, 0.2913679120706736, 0.2549019415282592, 0.2549019415282592, 0.2549019415282592, 0.2595875451798102, 0.2595875451798102, 0.2595875451798102, 0.24975608698443053, 0.24975608698443053, 0.24975608698443053, 0.16938114229449852, 0.16938114229449852, 0.16938114229449852, 0.16184508959737798, 0.16184508959737798, 0.16184508959737798, 0.09441635482944422, 0.09441635482944422, 0.09441635482944422, 0.19078210425831343, 0.19078210425831343, 0.19078210425831343, 0.19028496913239568, 0.19028496913239568, 0.19028496913239568, 0.042746067586211356, 0.042746067586211356, 0.042746067586211356, 0.11527350072230225, 0.11527350072230225, 0.11527350072230225, 0.12431717607551385, 0.12431717607551385, 0.12431717607551385, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0787400252107916, 0.0787400252107916, 0.0787400252107916, 0.06907151679223622, 0.06907151679223622, 0.06907151679223622, 0.06435206586822972, 0.06435206586822972, 0.06435206586822972, 0.017864077197967676, 0.017864077197967676, 0.017864077197967676, 0.06176875968303708, 0.06176875968303708, 0.06176875968303708, 0.03499618171061425, 0.03499618171061425, 0.03499618171061425, 0.0370664250550683, 0.0370664250550683, 0.0370664250550683, 0.0891172103226352, 0.0891172103226352, 0.0891172103226352, 0.03892962365755337, 0.03892962365755337, 0.03892962365755337, 0.3835547593022345, 0.3835547593022345, 0.3835547593022345, 0.39393277978697494, 0.39393277978697494, 0.39393277978697494, 0.3793510952057222, 0.3793510952057222, 0.3793510952057222, 0.08424628248284693, 0.08424628248284693, 0.08424628248284693, 0.09840668691393673, 0.09840668691393673, 0.09840668691393673, 0.10339739159368966, 0.10339739159368966, 0.10339739159368966, 0.17211817624461512, 0.17211817624461512, 0.17211817624461512, 0.1863635839168436, 0.1863635839168436, 0.1863635839168436, 0.15120320850345137, 0.15120320850345137, 0.15120320850345137, 0.28121285095416215, 0.28121285095416215, 0.28121285095416215, 0.26219718151078497, 0.26219718151078497, 0.26219718151078497, 0.2653662357826615, 0.2653662357826615, 0.2653662357826615, 0.18477563388248686, 0.18477563388248686, 0.18477563388248686, 0.20250773159947, 0.20250773159947, 0.20250773159947, 0.1756798866194491, 0.1756798866194491, 0.1756798866194491, 0.17662582065245247, 0.17662582065245247, 0.17662582065245247, 0.1802211752050622, 0.1802211752050622, 0.1802211752050622, 0.1862266468019117, 0.1862266468019117, 0.1862266468019117, 0.18178382476566035, 0.18178382476566035, 0.18178382476566035, 0.1887550617696726, 0.1887550617696726, 0.1887550617696726, 0.20987439864355828, 0.20987439864355828, 0.20987439864355828, 0.5613909862669498, 0.5613909862669498, 0.5613909862669498, 0.1511788111992819, 0.1511788111992819, 0.1511788111992819, 0.1791580623678275, 0.1791580623678275, 0.1791580623678275, 0.19193715196545014, 0.19193715196545014, 0.19193715196545014, 0.19660007486030728, 0.19660007486030728, 0.19660007486030728, 0.1857322973189689, 0.1857322973189689, 0.1857322973189689, 0.195319602465868, 0.195319602465868, 0.195319602465868, 0.19033097172020963, 0.19033097172020963, 0.19033097172020963, 0.1756322862540154, 0.1756322862540154, 0.1756322862540154, 0.0709170233676294, 0.0709170233676294, 0.0709170233676294, 0.07582857042875879, 0.07582857042875879, 0.07582857042875879, 0.08136751496594352, 0.08136751496594352, 0.08136751496594352]}, "mutation_prompt": null}
{"id": "a0faa215-f6e8-434c-b674-0d843f75ce78", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                self.w = 0.5 + (0.9 - 0.5) * (evaluations / self.budget)  # Dynamically increasing inertia weight\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Increased the inertia weight dynamically with progress to enhance convergence.", "configspace": "", "generation": 53, "fitness": 0.27958758846011034, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.24.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.7761568741812709, 0.7761568741812709, 0.7761568741812709, 0.7794253184882145, 0.7794253184882145, 0.7794253184882145, 0.8274095971483982, 0.8274095971483982, 0.8274095971483982, 0.3160690541131811, 0.3160690541131811, 0.3160690541131811, 0.39128158675717695, 0.39128158675717695, 0.39128158675717695, 0.39865603911879666, 0.39865603911879666, 0.39865603911879666, 0.14318874655559244, 0.14318874655559244, 0.14318874655559244, 0.1765430115079123, 0.1765430115079123, 0.1765430115079123, 0.15569528909337715, 0.15569528909337715, 0.15569528909337715, 0.11407067901318846, 0.11407067901318846, 0.11407067901318846, 0.12223718669430494, 0.12223718669430494, 0.12223718669430494, 0.10482709010159819, 0.10482709010159819, 0.10482709010159819, 0.9734568646211531, 0.9734568646211531, 0.9734568646211531, 0.9738562400984027, 0.9738562400984027, 0.9738562400984027, 0.9698217203294772, 0.9698217203294772, 0.9698217203294772, 0.39226052361428254, 0.39226052361428254, 0.39226052361428254, 0.33543454894506974, 0.33543454894506974, 0.33543454894506974, 0.4262628994009817, 0.4262628994009817, 0.4262628994009817, 0.7080602112633941, 0.7080602112633941, 0.7080602112633941, 0.21354414114367082, 0.21354414114367082, 0.21354414114367082, 0.30069638018806777, 0.30069638018806777, 0.30069638018806777, 0.16272983411813224, 0.16272983411813224, 0.16272983411813224, 0.12828766809686898, 0.12828766809686898, 0.12828766809686898, 0.18458010785009749, 0.18458010785009749, 0.18458010785009749, 0.1873750955156196, 0.1873750955156196, 0.1873750955156196, 0.13213194110055482, 0.13213194110055482, 0.13213194110055482, 0.24296819187790475, 0.24296819187790475, 0.24296819187790475, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14571337058990264, 0.14571337058990264, 0.14571337058990264, 0.08193677825638801, 0.08193677825638801, 0.08193677825638801, 0.10159100284493561, 0.10159100284493561, 0.10159100284493561, 0.15765322199349707, 0.15765322199349707, 0.15765322199349707, 0.16449594965164693, 0.16449594965164693, 0.16449594965164693, 0.08646099413432262, 0.08646099413432262, 0.08646099413432262, 0.23311505313361103, 0.23311505313361103, 0.23311505313361103, 0.09767000972012452, 0.09767000972012452, 0.09767000972012452, 0.05294156000989647, 0.05294156000989647, 0.05294156000989647, 0.5234262437174964, 0.5234262437174964, 0.5234262437174964, 0.47171922583004744, 0.47171922583004744, 0.47171922583004744, 0.5401863155244455, 0.5401863155244455, 0.5401863155244455, 0.14519281251073213, 0.14519281251073213, 0.14519281251073213, 0.10526102657605729, 0.10526102657605729, 0.10526102657605729, 0.13010893709835658, 0.13010893709835658, 0.13010893709835658, 0.14413449409248225, 0.14413449409248225, 0.14413449409248225, 0.1628768800084195, 0.1628768800084195, 0.1628768800084195, 0.18026061161273577, 0.18026061161273577, 0.18026061161273577, 0.32399005806619097, 0.32399005806619097, 0.32399005806619097, 0.33455700946088396, 0.33455700946088396, 0.33455700946088396, 0.2872644322934148, 0.2872644322934148, 0.2872644322934148, 0.25702444808021996, 0.25702444808021996, 0.25702444808021996, 0.19161240012815395, 0.19161240012815395, 0.19161240012815395, 0.2299028779423583, 0.2299028779423583, 0.2299028779423583, 0.2093984623531383, 0.2093984623531383, 0.2093984623531383, 0.18264531181330135, 0.18264531181330135, 0.18264531181330135, 0.20635270186157773, 0.20635270186157773, 0.20635270186157773, 0.22452067970794765, 0.22452067970794765, 0.22452067970794765, 0.21423994566729654, 0.21423994566729654, 0.21423994566729654, 0.20787618457853896, 0.20787618457853896, 0.20787618457853896, 0.8131400751629692, 0.8131400751629692, 0.8131400751629692, 0.16340494527115024, 0.16340494527115024, 0.16340494527115024, 0.6799587043229927, 0.6799587043229927, 0.6799587043229927, 0.1680260352442643, 0.1680260352442643, 0.1680260352442643, 0.20716193560769713, 0.20716193560769713, 0.20716193560769713, 0.2045286130413192, 0.2045286130413192, 0.2045286130413192, 0.19534110060915333, 0.19534110060915333, 0.19534110060915333, 0.19686987207374362, 0.19686987207374362, 0.19686987207374362, 0.17995088054803454, 0.17995088054803454, 0.17995088054803454, 0.09697672403210833, 0.09697672403210833, 0.09697672403210833, 0.07851655314894801, 0.07851655314894801, 0.07851655314894801, 0.11497508987075689, 0.11497508987075689, 0.11497508987075689]}, "mutation_prompt": null}
{"id": "a6600163-df03-493a-a575-655884f7ea01", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.6  # Inertia weight for PSO (changed from 0.5 to 0.6)\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Slightly increase the inertia weight in PSO for better exploration.", "configspace": "", "generation": 54, "fitness": 0.2797633581038645, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.23.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.7749319254847502, 0.7749319254847502, 0.7749319254847502, 0.7587484578443413, 0.7587484578443413, 0.7587484578443413, 0.7978635231988749, 0.7978635231988749, 0.7978635231988749, 0.4439637678128827, 0.4439637678128827, 0.4439637678128827, 0.4445003520696983, 0.4445003520696983, 0.4445003520696983, 0.2942508039327506, 0.2942508039327506, 0.2942508039327506, 0.13014604240515093, 0.13014604240515093, 0.13014604240515093, 0.1497182183100938, 0.1497182183100938, 0.1497182183100938, 0.13663223051302198, 0.13663223051302198, 0.13663223051302198, 0.13186116070199716, 0.13186116070199716, 0.13186116070199716, 0.09731148283043822, 0.09731148283043822, 0.09731148283043822, 0.11394990384542703, 0.11394990384542703, 0.11394990384542703, 0.9734237863293943, 0.9734237863293943, 0.9734237863293943, 0.9739704831338388, 0.9739704831338388, 0.9739704831338388, 0.9702329832334816, 0.9702329832334816, 0.9702329832334816, 0.44156411476993496, 0.44156411476993496, 0.44156411476993496, 0.4107148703423873, 0.4107148703423873, 0.4107148703423873, 0.4671670964483595, 0.4671670964483595, 0.4671670964483595, 0.5370005212694076, 0.5370005212694076, 0.5370005212694076, 0.21193338043049492, 0.21193338043049492, 0.21193338043049492, 0.2294670974525964, 0.2294670974525964, 0.2294670974525964, 0.1788270761033829, 0.1788270761033829, 0.1788270761033829, 0.186727006497306, 0.186727006497306, 0.186727006497306, 0.17891800136124925, 0.17891800136124925, 0.17891800136124925, 0.189526929226139, 0.189526929226139, 0.189526929226139, 0.19433655004047012, 0.19433655004047012, 0.19433655004047012, 0.21524852184964094, 0.21524852184964094, 0.21524852184964094, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006557029308984941, 0.006557029308984941, 0.006557029308984941, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08742355152447412, 0.08742355152447412, 0.08742355152447412, 0.05324146281287723, 0.05324146281287723, 0.05324146281287723, 0.0545836430851625, 0.0545836430851625, 0.0545836430851625, 0.1395688402667321, 0.1395688402667321, 0.1395688402667321, 0.06693852141994228, 0.06693852141994228, 0.06693852141994228, 0.22134018702291092, 0.22134018702291092, 0.22134018702291092, 0.16964127007509866, 0.16964127007509866, 0.16964127007509866, 0.10854765984722703, 0.10854765984722703, 0.10854765984722703, 0.056063385569116164, 0.056063385569116164, 0.056063385569116164, 0.5065431708667353, 0.5065431708667353, 0.5065431708667353, 0.4937063131907611, 0.4937063131907611, 0.4937063131907611, 0.5123426762216357, 0.5123426762216357, 0.5123426762216357, 0.1606868198784447, 0.1606868198784447, 0.1606868198784447, 0.13735228368598096, 0.13735228368598096, 0.13735228368598096, 0.1117564102585793, 0.1117564102585793, 0.1117564102585793, 0.23130743993398406, 0.23130743993398406, 0.23130743993398406, 0.18278489640456408, 0.18278489640456408, 0.18278489640456408, 0.3655003287552415, 0.3655003287552415, 0.3655003287552415, 0.3347281897822797, 0.3347281897822797, 0.3347281897822797, 0.3609055168021359, 0.3609055168021359, 0.3609055168021359, 0.4097281005190886, 0.4097281005190886, 0.4097281005190886, 0.29198801442616706, 0.29198801442616706, 0.29198801442616706, 0.22406921661621526, 0.22406921661621526, 0.22406921661621526, 0.20054824237285573, 0.20054824237285573, 0.20054824237285573, 0.18604405838175953, 0.18604405838175953, 0.18604405838175953, 0.21032800172109323, 0.21032800172109323, 0.21032800172109323, 0.19941601620425142, 0.19941601620425142, 0.19941601620425142, 0.18669218143741628, 0.18669218143741628, 0.18669218143741628, 0.23359481647632352, 0.23359481647632352, 0.23359481647632352, 0.3858506879691199, 0.3858506879691199, 0.3858506879691199, 0.8596568202874606, 0.8596568202874606, 0.8596568202874606, 0.16336119700933072, 0.16336119700933072, 0.16336119700933072, 0.16080004086557476, 0.16080004086557476, 0.16080004086557476, 0.16674224910528046, 0.16674224910528046, 0.16674224910528046, 0.20539043656553735, 0.20539043656553735, 0.20539043656553735, 0.19388040372637227, 0.19388040372637227, 0.19388040372637227, 0.18939349308545184, 0.18939349308545184, 0.18939349308545184, 0.20059231881802364, 0.20059231881802364, 0.20059231881802364, 0.19243905393939909, 0.19243905393939909, 0.19243905393939909, 0.0781173685526273, 0.0781173685526273, 0.0781173685526273, 0.07776410995802474, 0.07776410995802474, 0.07776410995802474, 0.13190907129049245, 0.13190907129049245, 0.13190907129049245]}, "mutation_prompt": null}
{"id": "92d43a3f-ba0a-47e9-bb62-4902a7f7b248", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.9  # Dynamic inertia weight for PSO (changed from 0.5 to 0.9)\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Adjusted the inertia weight `w` in PSO to dynamically increase exploration capability.", "configspace": "", "generation": 55, "fitness": 0.1441720523115704, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.19.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.225530158239731, 0.225530158239731, 0.225530158239731, 0.24102549637469195, 0.24102549637469195, 0.24102549637469195, 0.2581845406140475, 0.2581845406140475, 0.2581845406140475, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0027352159426049516, 0.0027352159426049516, 0.0027352159426049516, 0.06652792487262504, 0.06652792487262504, 0.06652792487262504, 0.09314280357740623, 0.09314280357740623, 0.09314280357740623, 0.0643058491758024, 0.0643058491758024, 0.0643058491758024, 0.0536696617311716, 0.0536696617311716, 0.0536696617311716, 0.041845696290651935, 0.041845696290651935, 0.041845696290651935, 0.05183147612374672, 0.05183147612374672, 0.05183147612374672, 0.9756571342617909, 0.9756571342617909, 0.9756571342617909, 0.9790382602177335, 0.9790382602177335, 0.9790382602177335, 0.9736679903033655, 0.9736679903033655, 0.9736679903033655, 0.12934050656409524, 0.12934050656409524, 0.12934050656409524, 0.12113467616905238, 0.12113467616905238, 0.12113467616905238, 0.12605699359048428, 0.12605699359048428, 0.12605699359048428, 0.12222794623813915, 0.12222794623813915, 0.12222794623813915, 0.14197591600514592, 0.14197591600514592, 0.14197591600514592, 0.160973079062407, 0.160973079062407, 0.160973079062407, 0.0013418709746427782, 0.0013418709746427782, 0.0013418709746427782, 0.07432826777676815, 0.07432826777676815, 0.07432826777676815, 0.03683146238027257, 0.03683146238027257, 0.03683146238027257, 0.01837651789742689, 0.01837651789742689, 0.01837651789742689, 0.013969647859675027, 0.013969647859675027, 0.013969647859675027, 0.0768180469552302, 0.0768180469552302, 0.0768180469552302, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07545099388574528, 0.07545099388574528, 0.07545099388574528, 0.05521665146764321, 0.05521665146764321, 0.05521665146764321, 0.07429071738533388, 0.07429071738533388, 0.07429071738533388, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0036208562121761156, 0.0036208562121761156, 0.0036208562121761156, 0.02274439181806942, 0.02274439181806942, 0.02274439181806942, 0.03153877287855389, 0.03153877287855389, 0.03153877287855389, 0.24207348159991715, 0.24207348159991715, 0.24207348159991715, 0.21714108404647647, 0.21714108404647647, 0.21714108404647647, 0.28202609375876364, 0.28202609375876364, 0.28202609375876364, 0.06218382526240929, 0.06218382526240929, 0.06218382526240929, 0.06034204426024392, 0.06034204426024392, 0.06034204426024392, 0.05799854940050242, 0.05799854940050242, 0.05799854940050242, 0.15519055862442144, 0.15519055862442144, 0.15519055862442144, 0.1346225428558835, 0.1346225428558835, 0.1346225428558835, 0.11697966583152342, 0.11697966583152342, 0.11697966583152342, 0.1682335212822611, 0.1682335212822611, 0.1682335212822611, 0.17626923146264217, 0.17626923146264217, 0.17626923146264217, 0.1864387691783158, 0.1864387691783158, 0.1864387691783158, 0.12822001066687716, 0.12822001066687716, 0.12822001066687716, 0.131688075764407, 0.131688075764407, 0.131688075764407, 0.1194707900292129, 0.1194707900292129, 0.1194707900292129, 0.18389718750059547, 0.18389718750059547, 0.18389718750059547, 0.15301497878723513, 0.15301497878723513, 0.15301497878723513, 0.17228559530329624, 0.17228559530329624, 0.17228559530329624, 0.15909767944623654, 0.15909767944623654, 0.15909767944623654, 0.1523584853562031, 0.1523584853562031, 0.1523584853562031, 0.16438800784699947, 0.16438800784699947, 0.16438800784699947, 0.276917542264724, 0.276917542264724, 0.276917542264724, 0.1635374134925529, 0.1635374134925529, 0.1635374134925529, 0.15285421241275776, 0.15285421241275776, 0.15285421241275776, 0.1588525178648782, 0.1588525178648782, 0.1588525178648782, 0.1675899696243508, 0.1675899696243508, 0.1675899696243508, 0.19389761657404048, 0.19389761657404048, 0.19389761657404048, 0.18414155075123495, 0.18414155075123495, 0.18414155075123495, 0.1715165018747632, 0.1715165018747632, 0.1715165018747632, 0.17681228534650273, 0.17681228534650273, 0.17681228534650273, 0.07312310665594046, 0.07312310665594046, 0.07312310665594046, 0.06893903234604626, 0.06893903234604626, 0.06893903234604626, 0.05408631611462311, 0.05408631611462311, 0.05408631611462311]}, "mutation_prompt": null}
{"id": "41e31266-55d8-40f9-9225-cd643ecea45b", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.9  # Inertia weight for PSO, increased for better exploration\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Improved AdaptiveHybridGA by fine-tuning the inertia weight dynamically to enhance convergence.", "configspace": "", "generation": 56, "fitness": 0.1441720523115704, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.19.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.225530158239731, 0.225530158239731, 0.225530158239731, 0.24102549637469195, 0.24102549637469195, 0.24102549637469195, 0.2581845406140475, 0.2581845406140475, 0.2581845406140475, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0027352159426049516, 0.0027352159426049516, 0.0027352159426049516, 0.06652792487262504, 0.06652792487262504, 0.06652792487262504, 0.09314280357740623, 0.09314280357740623, 0.09314280357740623, 0.0643058491758024, 0.0643058491758024, 0.0643058491758024, 0.0536696617311716, 0.0536696617311716, 0.0536696617311716, 0.041845696290651935, 0.041845696290651935, 0.041845696290651935, 0.05183147612374672, 0.05183147612374672, 0.05183147612374672, 0.9756571342617909, 0.9756571342617909, 0.9756571342617909, 0.9790382602177335, 0.9790382602177335, 0.9790382602177335, 0.9736679903033655, 0.9736679903033655, 0.9736679903033655, 0.12934050656409524, 0.12934050656409524, 0.12934050656409524, 0.12113467616905238, 0.12113467616905238, 0.12113467616905238, 0.12605699359048428, 0.12605699359048428, 0.12605699359048428, 0.12222794623813915, 0.12222794623813915, 0.12222794623813915, 0.14197591600514592, 0.14197591600514592, 0.14197591600514592, 0.160973079062407, 0.160973079062407, 0.160973079062407, 0.0013418709746427782, 0.0013418709746427782, 0.0013418709746427782, 0.07432826777676815, 0.07432826777676815, 0.07432826777676815, 0.03683146238027257, 0.03683146238027257, 0.03683146238027257, 0.01837651789742689, 0.01837651789742689, 0.01837651789742689, 0.013969647859675027, 0.013969647859675027, 0.013969647859675027, 0.0768180469552302, 0.0768180469552302, 0.0768180469552302, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07545099388574528, 0.07545099388574528, 0.07545099388574528, 0.05521665146764321, 0.05521665146764321, 0.05521665146764321, 0.07429071738533388, 0.07429071738533388, 0.07429071738533388, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0036208562121761156, 0.0036208562121761156, 0.0036208562121761156, 0.02274439181806942, 0.02274439181806942, 0.02274439181806942, 0.03153877287855389, 0.03153877287855389, 0.03153877287855389, 0.24207348159991715, 0.24207348159991715, 0.24207348159991715, 0.21714108404647647, 0.21714108404647647, 0.21714108404647647, 0.28202609375876364, 0.28202609375876364, 0.28202609375876364, 0.06218382526240929, 0.06218382526240929, 0.06218382526240929, 0.06034204426024392, 0.06034204426024392, 0.06034204426024392, 0.05799854940050242, 0.05799854940050242, 0.05799854940050242, 0.15519055862442144, 0.15519055862442144, 0.15519055862442144, 0.1346225428558835, 0.1346225428558835, 0.1346225428558835, 0.11697966583152342, 0.11697966583152342, 0.11697966583152342, 0.1682335212822611, 0.1682335212822611, 0.1682335212822611, 0.17626923146264217, 0.17626923146264217, 0.17626923146264217, 0.1864387691783158, 0.1864387691783158, 0.1864387691783158, 0.12822001066687716, 0.12822001066687716, 0.12822001066687716, 0.131688075764407, 0.131688075764407, 0.131688075764407, 0.1194707900292129, 0.1194707900292129, 0.1194707900292129, 0.18389718750059547, 0.18389718750059547, 0.18389718750059547, 0.15301497878723513, 0.15301497878723513, 0.15301497878723513, 0.17228559530329624, 0.17228559530329624, 0.17228559530329624, 0.15909767944623654, 0.15909767944623654, 0.15909767944623654, 0.1523584853562031, 0.1523584853562031, 0.1523584853562031, 0.16438800784699947, 0.16438800784699947, 0.16438800784699947, 0.276917542264724, 0.276917542264724, 0.276917542264724, 0.1635374134925529, 0.1635374134925529, 0.1635374134925529, 0.15285421241275776, 0.15285421241275776, 0.15285421241275776, 0.1588525178648782, 0.1588525178648782, 0.1588525178648782, 0.1675899696243508, 0.1675899696243508, 0.1675899696243508, 0.19389761657404048, 0.19389761657404048, 0.19389761657404048, 0.18414155075123495, 0.18414155075123495, 0.18414155075123495, 0.1715165018747632, 0.1715165018747632, 0.1715165018747632, 0.17681228534650273, 0.17681228534650273, 0.17681228534650273, 0.07312310665594046, 0.07312310665594046, 0.07312310665594046, 0.06893903234604626, 0.06893903234604626, 0.06893903234604626, 0.05408631611462311, 0.05408631611462311, 0.05408631611462311]}, "mutation_prompt": null}
{"id": "de3e3ced-b982-408b-9c06-445ac1f0810e", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.6  # Inertia weight for PSO (changed from 0.5 to 0.6)\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Slightly increased inertia weight for better exploration in PSO.", "configspace": "", "generation": 57, "fitness": 0.2797633581038645, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.23.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.7749319254847502, 0.7749319254847502, 0.7749319254847502, 0.7587484578443413, 0.7587484578443413, 0.7587484578443413, 0.7978635231988749, 0.7978635231988749, 0.7978635231988749, 0.4439637678128827, 0.4439637678128827, 0.4439637678128827, 0.4445003520696983, 0.4445003520696983, 0.4445003520696983, 0.2942508039327506, 0.2942508039327506, 0.2942508039327506, 0.13014604240515093, 0.13014604240515093, 0.13014604240515093, 0.1497182183100938, 0.1497182183100938, 0.1497182183100938, 0.13663223051302198, 0.13663223051302198, 0.13663223051302198, 0.13186116070199716, 0.13186116070199716, 0.13186116070199716, 0.09731148283043822, 0.09731148283043822, 0.09731148283043822, 0.11394990384542703, 0.11394990384542703, 0.11394990384542703, 0.9734237863293943, 0.9734237863293943, 0.9734237863293943, 0.9739704831338388, 0.9739704831338388, 0.9739704831338388, 0.9702329832334816, 0.9702329832334816, 0.9702329832334816, 0.44156411476993496, 0.44156411476993496, 0.44156411476993496, 0.4107148703423873, 0.4107148703423873, 0.4107148703423873, 0.4671670964483595, 0.4671670964483595, 0.4671670964483595, 0.5370005212694076, 0.5370005212694076, 0.5370005212694076, 0.21193338043049492, 0.21193338043049492, 0.21193338043049492, 0.2294670974525964, 0.2294670974525964, 0.2294670974525964, 0.1788270761033829, 0.1788270761033829, 0.1788270761033829, 0.186727006497306, 0.186727006497306, 0.186727006497306, 0.17891800136124925, 0.17891800136124925, 0.17891800136124925, 0.189526929226139, 0.189526929226139, 0.189526929226139, 0.19433655004047012, 0.19433655004047012, 0.19433655004047012, 0.21524852184964094, 0.21524852184964094, 0.21524852184964094, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006557029308984941, 0.006557029308984941, 0.006557029308984941, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08742355152447412, 0.08742355152447412, 0.08742355152447412, 0.05324146281287723, 0.05324146281287723, 0.05324146281287723, 0.0545836430851625, 0.0545836430851625, 0.0545836430851625, 0.1395688402667321, 0.1395688402667321, 0.1395688402667321, 0.06693852141994228, 0.06693852141994228, 0.06693852141994228, 0.22134018702291092, 0.22134018702291092, 0.22134018702291092, 0.16964127007509866, 0.16964127007509866, 0.16964127007509866, 0.10854765984722703, 0.10854765984722703, 0.10854765984722703, 0.056063385569116164, 0.056063385569116164, 0.056063385569116164, 0.5065431708667353, 0.5065431708667353, 0.5065431708667353, 0.4937063131907611, 0.4937063131907611, 0.4937063131907611, 0.5123426762216357, 0.5123426762216357, 0.5123426762216357, 0.1606868198784447, 0.1606868198784447, 0.1606868198784447, 0.13735228368598096, 0.13735228368598096, 0.13735228368598096, 0.1117564102585793, 0.1117564102585793, 0.1117564102585793, 0.23130743993398406, 0.23130743993398406, 0.23130743993398406, 0.18278489640456408, 0.18278489640456408, 0.18278489640456408, 0.3655003287552415, 0.3655003287552415, 0.3655003287552415, 0.3347281897822797, 0.3347281897822797, 0.3347281897822797, 0.3609055168021359, 0.3609055168021359, 0.3609055168021359, 0.4097281005190886, 0.4097281005190886, 0.4097281005190886, 0.29198801442616706, 0.29198801442616706, 0.29198801442616706, 0.22406921661621526, 0.22406921661621526, 0.22406921661621526, 0.20054824237285573, 0.20054824237285573, 0.20054824237285573, 0.18604405838175953, 0.18604405838175953, 0.18604405838175953, 0.21032800172109323, 0.21032800172109323, 0.21032800172109323, 0.19941601620425142, 0.19941601620425142, 0.19941601620425142, 0.18669218143741628, 0.18669218143741628, 0.18669218143741628, 0.23359481647632352, 0.23359481647632352, 0.23359481647632352, 0.3858506879691199, 0.3858506879691199, 0.3858506879691199, 0.8596568202874606, 0.8596568202874606, 0.8596568202874606, 0.16336119700933072, 0.16336119700933072, 0.16336119700933072, 0.16080004086557476, 0.16080004086557476, 0.16080004086557476, 0.16674224910528046, 0.16674224910528046, 0.16674224910528046, 0.20539043656553735, 0.20539043656553735, 0.20539043656553735, 0.19388040372637227, 0.19388040372637227, 0.19388040372637227, 0.18939349308545184, 0.18939349308545184, 0.18939349308545184, 0.20059231881802364, 0.20059231881802364, 0.20059231881802364, 0.19243905393939909, 0.19243905393939909, 0.19243905393939909, 0.0781173685526273, 0.0781173685526273, 0.0781173685526273, 0.07776410995802474, 0.07776410995802474, 0.07776410995802474, 0.13190907129049245, 0.13190907129049245, 0.13190907129049245]}, "mutation_prompt": null}
{"id": "cd6dfd4e-43ad-4f8d-86b3-6d91fde4b742", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.7  # Inertia weight for PSO, slightly increased for exploration\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhance global exploitation by slightly increasing the inertia weight in PSO.", "configspace": "", "generation": 58, "fitness": 0.23027722903962633, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.21.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.489729205805689, 0.489729205805689, 0.489729205805689, 0.5426552892751138, 0.5426552892751138, 0.5426552892751138, 0.6281938628935912, 0.6281938628935912, 0.6281938628935912, 0.20336190931602294, 0.20336190931602294, 0.20336190931602294, 0.1750066485456202, 0.1750066485456202, 0.1750066485456202, 0.15020290901802713, 0.15020290901802713, 0.15020290901802713, 0.10092311299552403, 0.10092311299552403, 0.10092311299552403, 0.10942387865492642, 0.10942387865492642, 0.10942387865492642, 0.11912067278485905, 0.11912067278485905, 0.11912067278485905, 0.11855767850548704, 0.11855767850548704, 0.11855767850548704, 0.08488838868775384, 0.08488838868775384, 0.08488838868775384, 0.0830985945148881, 0.0830985945148881, 0.0830985945148881, 0.9734673280437594, 0.9734673280437594, 0.9734673280437594, 0.974364824184331, 0.974364824184331, 0.974364824184331, 0.9706870579976348, 0.9706870579976348, 0.9706870579976348, 0.3563561240235462, 0.3563561240235462, 0.3563561240235462, 0.2728774232533493, 0.2728774232533493, 0.2728774232533493, 0.2586712726086188, 0.2586712726086188, 0.2586712726086188, 0.531160130141563, 0.531160130141563, 0.531160130141563, 0.3488397310774267, 0.3488397310774267, 0.3488397310774267, 0.2536980720246065, 0.2536980720246065, 0.2536980720246065, 0.13249074835779706, 0.13249074835779706, 0.13249074835779706, 0.1374711617156943, 0.1374711617156943, 0.1374711617156943, 0.16992449843516932, 0.16992449843516932, 0.16992449843516932, 0.13035153609958983, 0.13035153609958983, 0.13035153609958983, 0.17884352176540397, 0.17884352176540397, 0.17884352176540397, 0.1475526823636648, 0.1475526823636648, 0.1475526823636648, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0749234688928615, 0.0749234688928615, 0.0749234688928615, 0.05776169488488081, 0.05776169488488081, 0.05776169488488081, 0.09528670968925779, 0.09528670968925779, 0.09528670968925779, 0.03746753801241742, 0.03746753801241742, 0.03746753801241742, 0.05245242971203423, 0.05245242971203423, 0.05245242971203423, 0.04123472893399738, 0.04123472893399738, 0.04123472893399738, 0.08422024857633281, 0.08422024857633281, 0.08422024857633281, 0.10205854995893737, 0.10205854995893737, 0.10205854995893737, 0.048020762165913444, 0.048020762165913444, 0.048020762165913444, 0.44628113735584396, 0.44628113735584396, 0.44628113735584396, 0.4308062171183108, 0.4308062171183108, 0.4308062171183108, 0.44454170829426054, 0.44454170829426054, 0.44454170829426054, 0.10698287453180799, 0.10698287453180799, 0.10698287453180799, 0.08317236551805274, 0.08317236551805274, 0.08317236551805274, 0.08263604016863924, 0.08263604016863924, 0.08263604016863924, 0.2234054720756966, 0.2234054720756966, 0.2234054720756966, 0.15171228727299513, 0.15171228727299513, 0.15171228727299513, 0.2275126955372977, 0.2275126955372977, 0.2275126955372977, 0.2963259685927947, 0.2963259685927947, 0.2963259685927947, 0.27410936075347825, 0.27410936075347825, 0.27410936075347825, 0.31337908827202654, 0.31337908827202654, 0.31337908827202654, 0.22165365990574737, 0.22165365990574737, 0.22165365990574737, 0.15667601793509678, 0.15667601793509678, 0.15667601793509678, 0.16546079797764557, 0.16546079797764557, 0.16546079797764557, 0.18129352843804725, 0.18129352843804725, 0.18129352843804725, 0.20470000042502556, 0.20470000042502556, 0.20470000042502556, 0.19332652648150683, 0.19332652648150683, 0.19332652648150683, 0.17497099351408485, 0.17497099351408485, 0.17497099351408485, 0.20713223818776938, 0.20713223818776938, 0.20713223818776938, 0.2669256518188128, 0.2669256518188128, 0.2669256518188128, 0.715924221196987, 0.715924221196987, 0.715924221196987, 0.1986015333120167, 0.1986015333120167, 0.1986015333120167, 0.1644702249307125, 0.1644702249307125, 0.1644702249307125, 0.16615189207200798, 0.16615189207200798, 0.16615189207200798, 0.20595887891121423, 0.20595887891121423, 0.20595887891121423, 0.19996848969653125, 0.19996848969653125, 0.19996848969653125, 0.19498600936416155, 0.19498600936416155, 0.19498600936416155, 0.19001180105203752, 0.19001180105203752, 0.19001180105203752, 0.19092316267931697, 0.19092316267931697, 0.19092316267931697, 0.09565757846555822, 0.09565757846555822, 0.09565757846555822, 0.08260274507029408, 0.08260274507029408, 0.08260274507029408, 0.08605493001102771, 0.08605493001102771, 0.08605493001102771]}, "mutation_prompt": null}
{"id": "4b3e0982-3149-4fe0-af1d-1080b2ecb201", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                self.w = 0.9 - 0.4 * (evaluations / self.budget)  # Time-adaptive inertia weight\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced PSO by introducing time-adaptive inertia weight for improved convergence.", "configspace": "", "generation": 59, "fitness": 0.1905985125195022, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.437605286148927, 0.437605286148927, 0.437605286148927, 0.4548483346002523, 0.4548483346002523, 0.4548483346002523, 0.4807776073732434, 0.4807776073732434, 0.4807776073732434, 0.10137514983641505, 0.10137514983641505, 0.10137514983641505, 0.049834645307488046, 0.049834645307488046, 0.049834645307488046, 0.02628286255110235, 0.02628286255110235, 0.02628286255110235, 0.0844780636365755, 0.0844780636365755, 0.0844780636365755, 0.08766721836909674, 0.08766721836909674, 0.08766721836909674, 0.08502418371943421, 0.08502418371943421, 0.08502418371943421, 0.07705562381719444, 0.07705562381719444, 0.07705562381719444, 0.07472857816598899, 0.07472857816598899, 0.07472857816598899, 0.08061123337641407, 0.08061123337641407, 0.08061123337641407, 0.975652090494761, 0.975652090494761, 0.975652090494761, 0.9790366890189451, 0.9790366890189451, 0.9790366890189451, 0.9736664876013109, 0.9736664876013109, 0.9736664876013109, 0.281429548677698, 0.281429548677698, 0.281429548677698, 0.19621990574529247, 0.19621990574529247, 0.19621990574529247, 0.2096629104369263, 0.2096629104369263, 0.2096629104369263, 0.18701423690835983, 0.18701423690835983, 0.18701423690835983, 0.18332241035662344, 0.18332241035662344, 0.18332241035662344, 0.1991846570435214, 0.1991846570435214, 0.1991846570435214, 0.12333134526260581, 0.12333134526260581, 0.12333134526260581, 0.13085889400922657, 0.13085889400922657, 0.13085889400922657, 0.12340971554608982, 0.12340971554608982, 0.12340971554608982, 0.019550142587097974, 0.019550142587097974, 0.019550142587097974, 0.10950163133381119, 0.10950163133381119, 0.10950163133381119, 0.1177956983214784, 0.1177956983214784, 0.1177956983214784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00950637459719128, 0.00950637459719128, 0.00950637459719128, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10106885035602009, 0.10106885035602009, 0.10106885035602009, 0.04465698958158304, 0.04465698958158304, 0.04465698958158304, 0.07258536355953182, 0.07258536355953182, 0.07258536355953182, 0.013005801850459853, 0.013005801850459853, 0.013005801850459853, 0.006472194279493304, 0.006472194279493304, 0.006472194279493304, 0.02355355952731175, 0.02355355952731175, 0.02355355952731175, 0.03591986374834777, 0.03591986374834777, 0.03591986374834777, 0.04411588696491331, 0.04411588696491331, 0.04411588696491331, 0.08604786458357705, 0.08604786458357705, 0.08604786458357705, 0.3721972396434816, 0.3721972396434816, 0.3721972396434816, 0.32785117041377165, 0.32785117041377165, 0.32785117041377165, 0.3191748871910909, 0.3191748871910909, 0.3191748871910909, 0.08459005096922123, 0.08459005096922123, 0.08459005096922123, 0.10192835821712865, 0.10192835821712865, 0.10192835821712865, 0.09248598957574816, 0.09248598957574816, 0.09248598957574816, 0.16439007814830298, 0.16439007814830298, 0.16439007814830298, 0.16513681059269092, 0.16513681059269092, 0.16513681059269092, 0.1481488140498476, 0.1481488140498476, 0.1481488140498476, 0.261510016304523, 0.261510016304523, 0.261510016304523, 0.23815083626712874, 0.23815083626712874, 0.23815083626712874, 0.2543841551111472, 0.2543841551111472, 0.2543841551111472, 0.22006955393172245, 0.22006955393172245, 0.22006955393172245, 0.16858121251514335, 0.16858121251514335, 0.16858121251514335, 0.18557368929442108, 0.18557368929442108, 0.18557368929442108, 0.1824320921383441, 0.1824320921383441, 0.1824320921383441, 0.19769733786703114, 0.19769733786703114, 0.19769733786703114, 0.19230837653923083, 0.19230837653923083, 0.19230837653923083, 0.17570374458313687, 0.17570374458313687, 0.17570374458313687, 0.20251793593804024, 0.20251793593804024, 0.20251793593804024, 0.16434101028399106, 0.16434101028399106, 0.16434101028399106, 0.5047688863531201, 0.5047688863531201, 0.5047688863531201, 0.19016039680171526, 0.19016039680171526, 0.19016039680171526, 0.17640693852197142, 0.17640693852197142, 0.17640693852197142, 0.19621505054565602, 0.19621505054565602, 0.19621505054565602, 0.19381752126562424, 0.19381752126562424, 0.19381752126562424, 0.20035116540292175, 0.20035116540292175, 0.20035116540292175, 0.18453816311407745, 0.18453816311407745, 0.18453816311407745, 0.1709701339416373, 0.1709701339416373, 0.1709701339416373, 0.19104830268622186, 0.19104830268622186, 0.19104830268622186, 0.07310600968431136, 0.07310600968431136, 0.07310600968431136, 0.06854543834691518, 0.06854543834691518, 0.06854543834691518, 0.06693363587053258, 0.06693363587053258, 0.06693363587053258]}, "mutation_prompt": null}
{"id": "4f1fb7e8-0a37-4ea9-9b1a-14c2a7d4f756", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                self.w = 0.9 - 0.4 * (evaluations / self.budget)  # Dynamic inertia weight\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced AdaptiveHybridGA by refining inertia weight to dynamically adjust exploration-exploitation balance.", "configspace": "", "generation": 60, "fitness": 0.1905985125195022, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.437605286148927, 0.437605286148927, 0.437605286148927, 0.4548483346002523, 0.4548483346002523, 0.4548483346002523, 0.4807776073732434, 0.4807776073732434, 0.4807776073732434, 0.10137514983641505, 0.10137514983641505, 0.10137514983641505, 0.049834645307488046, 0.049834645307488046, 0.049834645307488046, 0.02628286255110235, 0.02628286255110235, 0.02628286255110235, 0.0844780636365755, 0.0844780636365755, 0.0844780636365755, 0.08766721836909674, 0.08766721836909674, 0.08766721836909674, 0.08502418371943421, 0.08502418371943421, 0.08502418371943421, 0.07705562381719444, 0.07705562381719444, 0.07705562381719444, 0.07472857816598899, 0.07472857816598899, 0.07472857816598899, 0.08061123337641407, 0.08061123337641407, 0.08061123337641407, 0.975652090494761, 0.975652090494761, 0.975652090494761, 0.9790366890189451, 0.9790366890189451, 0.9790366890189451, 0.9736664876013109, 0.9736664876013109, 0.9736664876013109, 0.281429548677698, 0.281429548677698, 0.281429548677698, 0.19621990574529247, 0.19621990574529247, 0.19621990574529247, 0.2096629104369263, 0.2096629104369263, 0.2096629104369263, 0.18701423690835983, 0.18701423690835983, 0.18701423690835983, 0.18332241035662344, 0.18332241035662344, 0.18332241035662344, 0.1991846570435214, 0.1991846570435214, 0.1991846570435214, 0.12333134526260581, 0.12333134526260581, 0.12333134526260581, 0.13085889400922657, 0.13085889400922657, 0.13085889400922657, 0.12340971554608982, 0.12340971554608982, 0.12340971554608982, 0.019550142587097974, 0.019550142587097974, 0.019550142587097974, 0.10950163133381119, 0.10950163133381119, 0.10950163133381119, 0.1177956983214784, 0.1177956983214784, 0.1177956983214784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00950637459719128, 0.00950637459719128, 0.00950637459719128, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10106885035602009, 0.10106885035602009, 0.10106885035602009, 0.04465698958158304, 0.04465698958158304, 0.04465698958158304, 0.07258536355953182, 0.07258536355953182, 0.07258536355953182, 0.013005801850459853, 0.013005801850459853, 0.013005801850459853, 0.006472194279493304, 0.006472194279493304, 0.006472194279493304, 0.02355355952731175, 0.02355355952731175, 0.02355355952731175, 0.03591986374834777, 0.03591986374834777, 0.03591986374834777, 0.04411588696491331, 0.04411588696491331, 0.04411588696491331, 0.08604786458357705, 0.08604786458357705, 0.08604786458357705, 0.3721972396434816, 0.3721972396434816, 0.3721972396434816, 0.32785117041377165, 0.32785117041377165, 0.32785117041377165, 0.3191748871910909, 0.3191748871910909, 0.3191748871910909, 0.08459005096922123, 0.08459005096922123, 0.08459005096922123, 0.10192835821712865, 0.10192835821712865, 0.10192835821712865, 0.09248598957574816, 0.09248598957574816, 0.09248598957574816, 0.16439007814830298, 0.16439007814830298, 0.16439007814830298, 0.16513681059269092, 0.16513681059269092, 0.16513681059269092, 0.1481488140498476, 0.1481488140498476, 0.1481488140498476, 0.261510016304523, 0.261510016304523, 0.261510016304523, 0.23815083626712874, 0.23815083626712874, 0.23815083626712874, 0.2543841551111472, 0.2543841551111472, 0.2543841551111472, 0.22006955393172245, 0.22006955393172245, 0.22006955393172245, 0.16858121251514335, 0.16858121251514335, 0.16858121251514335, 0.18557368929442108, 0.18557368929442108, 0.18557368929442108, 0.1824320921383441, 0.1824320921383441, 0.1824320921383441, 0.19769733786703114, 0.19769733786703114, 0.19769733786703114, 0.19230837653923083, 0.19230837653923083, 0.19230837653923083, 0.17570374458313687, 0.17570374458313687, 0.17570374458313687, 0.20251793593804024, 0.20251793593804024, 0.20251793593804024, 0.16434101028399106, 0.16434101028399106, 0.16434101028399106, 0.5047688863531201, 0.5047688863531201, 0.5047688863531201, 0.19016039680171526, 0.19016039680171526, 0.19016039680171526, 0.17640693852197142, 0.17640693852197142, 0.17640693852197142, 0.19621505054565602, 0.19621505054565602, 0.19621505054565602, 0.19381752126562424, 0.19381752126562424, 0.19381752126562424, 0.20035116540292175, 0.20035116540292175, 0.20035116540292175, 0.18453816311407745, 0.18453816311407745, 0.18453816311407745, 0.1709701339416373, 0.1709701339416373, 0.1709701339416373, 0.19104830268622186, 0.19104830268622186, 0.19104830268622186, 0.07310600968431136, 0.07310600968431136, 0.07310600968431136, 0.06854543834691518, 0.06854543834691518, 0.06854543834691518, 0.06693363587053258, 0.06693363587053258, 0.06693363587053258]}, "mutation_prompt": null}
{"id": "71eead27-11bd-4454-bd3e-f488d5597409", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.w = 0.9 - evaluations/self.budget * 0.4  # Dynamic inertia weight\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced exploration-exploitation balance by adjusting the inertia weight dynamically in PSO.", "configspace": "", "generation": 61, "fitness": 0.1905985125195022, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.437605286148927, 0.437605286148927, 0.437605286148927, 0.4548483346002523, 0.4548483346002523, 0.4548483346002523, 0.4807776073732434, 0.4807776073732434, 0.4807776073732434, 0.10137514983641505, 0.10137514983641505, 0.10137514983641505, 0.049834645307488046, 0.049834645307488046, 0.049834645307488046, 0.02628286255110235, 0.02628286255110235, 0.02628286255110235, 0.0844780636365755, 0.0844780636365755, 0.0844780636365755, 0.08766721836909674, 0.08766721836909674, 0.08766721836909674, 0.08502418371943421, 0.08502418371943421, 0.08502418371943421, 0.07705562381719444, 0.07705562381719444, 0.07705562381719444, 0.07472857816598899, 0.07472857816598899, 0.07472857816598899, 0.08061123337641407, 0.08061123337641407, 0.08061123337641407, 0.975652090494761, 0.975652090494761, 0.975652090494761, 0.9790366890189451, 0.9790366890189451, 0.9790366890189451, 0.9736664876013109, 0.9736664876013109, 0.9736664876013109, 0.281429548677698, 0.281429548677698, 0.281429548677698, 0.19621990574529247, 0.19621990574529247, 0.19621990574529247, 0.2096629104369263, 0.2096629104369263, 0.2096629104369263, 0.18701423690835983, 0.18701423690835983, 0.18701423690835983, 0.18332241035662344, 0.18332241035662344, 0.18332241035662344, 0.1991846570435214, 0.1991846570435214, 0.1991846570435214, 0.12333134526260581, 0.12333134526260581, 0.12333134526260581, 0.13085889400922657, 0.13085889400922657, 0.13085889400922657, 0.12340971554608982, 0.12340971554608982, 0.12340971554608982, 0.019550142587097974, 0.019550142587097974, 0.019550142587097974, 0.10950163133381119, 0.10950163133381119, 0.10950163133381119, 0.1177956983214784, 0.1177956983214784, 0.1177956983214784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00950637459719128, 0.00950637459719128, 0.00950637459719128, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10106885035602009, 0.10106885035602009, 0.10106885035602009, 0.04465698958158304, 0.04465698958158304, 0.04465698958158304, 0.07258536355953182, 0.07258536355953182, 0.07258536355953182, 0.013005801850459853, 0.013005801850459853, 0.013005801850459853, 0.006472194279493304, 0.006472194279493304, 0.006472194279493304, 0.02355355952731175, 0.02355355952731175, 0.02355355952731175, 0.03591986374834777, 0.03591986374834777, 0.03591986374834777, 0.04411588696491331, 0.04411588696491331, 0.04411588696491331, 0.08604786458357705, 0.08604786458357705, 0.08604786458357705, 0.3721972396434816, 0.3721972396434816, 0.3721972396434816, 0.32785117041377165, 0.32785117041377165, 0.32785117041377165, 0.3191748871910909, 0.3191748871910909, 0.3191748871910909, 0.08459005096922123, 0.08459005096922123, 0.08459005096922123, 0.10192835821712865, 0.10192835821712865, 0.10192835821712865, 0.09248598957574816, 0.09248598957574816, 0.09248598957574816, 0.16439007814830298, 0.16439007814830298, 0.16439007814830298, 0.16513681059269092, 0.16513681059269092, 0.16513681059269092, 0.1481488140498476, 0.1481488140498476, 0.1481488140498476, 0.261510016304523, 0.261510016304523, 0.261510016304523, 0.23815083626712874, 0.23815083626712874, 0.23815083626712874, 0.2543841551111472, 0.2543841551111472, 0.2543841551111472, 0.22006955393172245, 0.22006955393172245, 0.22006955393172245, 0.16858121251514335, 0.16858121251514335, 0.16858121251514335, 0.18557368929442108, 0.18557368929442108, 0.18557368929442108, 0.1824320921383441, 0.1824320921383441, 0.1824320921383441, 0.19769733786703114, 0.19769733786703114, 0.19769733786703114, 0.19230837653923083, 0.19230837653923083, 0.19230837653923083, 0.17570374458313687, 0.17570374458313687, 0.17570374458313687, 0.20251793593804024, 0.20251793593804024, 0.20251793593804024, 0.16434101028399106, 0.16434101028399106, 0.16434101028399106, 0.5047688863531201, 0.5047688863531201, 0.5047688863531201, 0.19016039680171526, 0.19016039680171526, 0.19016039680171526, 0.17640693852197142, 0.17640693852197142, 0.17640693852197142, 0.19621505054565602, 0.19621505054565602, 0.19621505054565602, 0.19381752126562424, 0.19381752126562424, 0.19381752126562424, 0.20035116540292175, 0.20035116540292175, 0.20035116540292175, 0.18453816311407745, 0.18453816311407745, 0.18453816311407745, 0.1709701339416373, 0.1709701339416373, 0.1709701339416373, 0.19104830268622186, 0.19104830268622186, 0.19104830268622186, 0.07310600968431136, 0.07310600968431136, 0.07310600968431136, 0.06854543834691518, 0.06854543834691518, 0.06854543834691518, 0.06693363587053258, 0.06693363587053258, 0.06693363587053258]}, "mutation_prompt": null}
{"id": "02a01db5-ba1a-4a0f-8d74-dc5fb67f1153", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.w = 0.9 - evaluations/self.budget * 0.4  # Dynamic inertia weight adjustment\n                self.c1 = 2.7 - evaluations/self.budget * 1.5\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "AdaptiveHybridGA with dynamic inertia weight in PSO for better exploration and exploitation trade-off.", "configspace": "", "generation": 62, "fitness": 0.1905985125195022, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.437605286148927, 0.437605286148927, 0.437605286148927, 0.4548483346002523, 0.4548483346002523, 0.4548483346002523, 0.4807776073732434, 0.4807776073732434, 0.4807776073732434, 0.10137514983641505, 0.10137514983641505, 0.10137514983641505, 0.049834645307488046, 0.049834645307488046, 0.049834645307488046, 0.02628286255110235, 0.02628286255110235, 0.02628286255110235, 0.0844780636365755, 0.0844780636365755, 0.0844780636365755, 0.08766721836909674, 0.08766721836909674, 0.08766721836909674, 0.08502418371943421, 0.08502418371943421, 0.08502418371943421, 0.07705562381719444, 0.07705562381719444, 0.07705562381719444, 0.07472857816598899, 0.07472857816598899, 0.07472857816598899, 0.08061123337641407, 0.08061123337641407, 0.08061123337641407, 0.975652090494761, 0.975652090494761, 0.975652090494761, 0.9790366890189451, 0.9790366890189451, 0.9790366890189451, 0.9736664876013109, 0.9736664876013109, 0.9736664876013109, 0.281429548677698, 0.281429548677698, 0.281429548677698, 0.19621990574529247, 0.19621990574529247, 0.19621990574529247, 0.2096629104369263, 0.2096629104369263, 0.2096629104369263, 0.18701423690835983, 0.18701423690835983, 0.18701423690835983, 0.18332241035662344, 0.18332241035662344, 0.18332241035662344, 0.1991846570435214, 0.1991846570435214, 0.1991846570435214, 0.12333134526260581, 0.12333134526260581, 0.12333134526260581, 0.13085889400922657, 0.13085889400922657, 0.13085889400922657, 0.12340971554608982, 0.12340971554608982, 0.12340971554608982, 0.019550142587097974, 0.019550142587097974, 0.019550142587097974, 0.10950163133381119, 0.10950163133381119, 0.10950163133381119, 0.1177956983214784, 0.1177956983214784, 0.1177956983214784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00950637459719128, 0.00950637459719128, 0.00950637459719128, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10106885035602009, 0.10106885035602009, 0.10106885035602009, 0.04465698958158304, 0.04465698958158304, 0.04465698958158304, 0.07258536355953182, 0.07258536355953182, 0.07258536355953182, 0.013005801850459853, 0.013005801850459853, 0.013005801850459853, 0.006472194279493304, 0.006472194279493304, 0.006472194279493304, 0.02355355952731175, 0.02355355952731175, 0.02355355952731175, 0.03591986374834777, 0.03591986374834777, 0.03591986374834777, 0.04411588696491331, 0.04411588696491331, 0.04411588696491331, 0.08604786458357705, 0.08604786458357705, 0.08604786458357705, 0.3721972396434816, 0.3721972396434816, 0.3721972396434816, 0.32785117041377165, 0.32785117041377165, 0.32785117041377165, 0.3191748871910909, 0.3191748871910909, 0.3191748871910909, 0.08459005096922123, 0.08459005096922123, 0.08459005096922123, 0.10192835821712865, 0.10192835821712865, 0.10192835821712865, 0.09248598957574816, 0.09248598957574816, 0.09248598957574816, 0.16439007814830298, 0.16439007814830298, 0.16439007814830298, 0.16513681059269092, 0.16513681059269092, 0.16513681059269092, 0.1481488140498476, 0.1481488140498476, 0.1481488140498476, 0.261510016304523, 0.261510016304523, 0.261510016304523, 0.23815083626712874, 0.23815083626712874, 0.23815083626712874, 0.2543841551111472, 0.2543841551111472, 0.2543841551111472, 0.22006955393172245, 0.22006955393172245, 0.22006955393172245, 0.16858121251514335, 0.16858121251514335, 0.16858121251514335, 0.18557368929442108, 0.18557368929442108, 0.18557368929442108, 0.1824320921383441, 0.1824320921383441, 0.1824320921383441, 0.19769733786703114, 0.19769733786703114, 0.19769733786703114, 0.19230837653923083, 0.19230837653923083, 0.19230837653923083, 0.17570374458313687, 0.17570374458313687, 0.17570374458313687, 0.20251793593804024, 0.20251793593804024, 0.20251793593804024, 0.16434101028399106, 0.16434101028399106, 0.16434101028399106, 0.5047688863531201, 0.5047688863531201, 0.5047688863531201, 0.19016039680171526, 0.19016039680171526, 0.19016039680171526, 0.17640693852197142, 0.17640693852197142, 0.17640693852197142, 0.19621505054565602, 0.19621505054565602, 0.19621505054565602, 0.19381752126562424, 0.19381752126562424, 0.19381752126562424, 0.20035116540292175, 0.20035116540292175, 0.20035116540292175, 0.18453816311407745, 0.18453816311407745, 0.18453816311407745, 0.1709701339416373, 0.1709701339416373, 0.1709701339416373, 0.19104830268622186, 0.19104830268622186, 0.19104830268622186, 0.07310600968431136, 0.07310600968431136, 0.07310600968431136, 0.06854543834691518, 0.06854543834691518, 0.06854543834691518, 0.06693363587053258, 0.06693363587053258, 0.06693363587053258]}, "mutation_prompt": null}
{"id": "8ac0fe66-4afd-4237-be6d-1a5e452c63e0", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.c1 = 2.7 - evaluations/self.budget * 1.5\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                self.w = 0.9 - evaluations/self.budget * 0.4  # Change: Dynamic inertia weight\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced convergence by adjusting the inertia weight dynamically in PSO.", "configspace": "", "generation": 63, "fitness": 0.1905985125195022, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.437605286148927, 0.437605286148927, 0.437605286148927, 0.4548483346002523, 0.4548483346002523, 0.4548483346002523, 0.4807776073732434, 0.4807776073732434, 0.4807776073732434, 0.10137514983641505, 0.10137514983641505, 0.10137514983641505, 0.049834645307488046, 0.049834645307488046, 0.049834645307488046, 0.02628286255110235, 0.02628286255110235, 0.02628286255110235, 0.0844780636365755, 0.0844780636365755, 0.0844780636365755, 0.08766721836909674, 0.08766721836909674, 0.08766721836909674, 0.08502418371943421, 0.08502418371943421, 0.08502418371943421, 0.07705562381719444, 0.07705562381719444, 0.07705562381719444, 0.07472857816598899, 0.07472857816598899, 0.07472857816598899, 0.08061123337641407, 0.08061123337641407, 0.08061123337641407, 0.975652090494761, 0.975652090494761, 0.975652090494761, 0.9790366890189451, 0.9790366890189451, 0.9790366890189451, 0.9736664876013109, 0.9736664876013109, 0.9736664876013109, 0.281429548677698, 0.281429548677698, 0.281429548677698, 0.19621990574529247, 0.19621990574529247, 0.19621990574529247, 0.2096629104369263, 0.2096629104369263, 0.2096629104369263, 0.18701423690835983, 0.18701423690835983, 0.18701423690835983, 0.18332241035662344, 0.18332241035662344, 0.18332241035662344, 0.1991846570435214, 0.1991846570435214, 0.1991846570435214, 0.12333134526260581, 0.12333134526260581, 0.12333134526260581, 0.13085889400922657, 0.13085889400922657, 0.13085889400922657, 0.12340971554608982, 0.12340971554608982, 0.12340971554608982, 0.019550142587097974, 0.019550142587097974, 0.019550142587097974, 0.10950163133381119, 0.10950163133381119, 0.10950163133381119, 0.1177956983214784, 0.1177956983214784, 0.1177956983214784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00950637459719128, 0.00950637459719128, 0.00950637459719128, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10106885035602009, 0.10106885035602009, 0.10106885035602009, 0.04465698958158304, 0.04465698958158304, 0.04465698958158304, 0.07258536355953182, 0.07258536355953182, 0.07258536355953182, 0.013005801850459853, 0.013005801850459853, 0.013005801850459853, 0.006472194279493304, 0.006472194279493304, 0.006472194279493304, 0.02355355952731175, 0.02355355952731175, 0.02355355952731175, 0.03591986374834777, 0.03591986374834777, 0.03591986374834777, 0.04411588696491331, 0.04411588696491331, 0.04411588696491331, 0.08604786458357705, 0.08604786458357705, 0.08604786458357705, 0.3721972396434816, 0.3721972396434816, 0.3721972396434816, 0.32785117041377165, 0.32785117041377165, 0.32785117041377165, 0.3191748871910909, 0.3191748871910909, 0.3191748871910909, 0.08459005096922123, 0.08459005096922123, 0.08459005096922123, 0.10192835821712865, 0.10192835821712865, 0.10192835821712865, 0.09248598957574816, 0.09248598957574816, 0.09248598957574816, 0.16439007814830298, 0.16439007814830298, 0.16439007814830298, 0.16513681059269092, 0.16513681059269092, 0.16513681059269092, 0.1481488140498476, 0.1481488140498476, 0.1481488140498476, 0.261510016304523, 0.261510016304523, 0.261510016304523, 0.23815083626712874, 0.23815083626712874, 0.23815083626712874, 0.2543841551111472, 0.2543841551111472, 0.2543841551111472, 0.22006955393172245, 0.22006955393172245, 0.22006955393172245, 0.16858121251514335, 0.16858121251514335, 0.16858121251514335, 0.18557368929442108, 0.18557368929442108, 0.18557368929442108, 0.1824320921383441, 0.1824320921383441, 0.1824320921383441, 0.19769733786703114, 0.19769733786703114, 0.19769733786703114, 0.19230837653923083, 0.19230837653923083, 0.19230837653923083, 0.17570374458313687, 0.17570374458313687, 0.17570374458313687, 0.20251793593804024, 0.20251793593804024, 0.20251793593804024, 0.16434101028399106, 0.16434101028399106, 0.16434101028399106, 0.5047688863531201, 0.5047688863531201, 0.5047688863531201, 0.19016039680171526, 0.19016039680171526, 0.19016039680171526, 0.17640693852197142, 0.17640693852197142, 0.17640693852197142, 0.19621505054565602, 0.19621505054565602, 0.19621505054565602, 0.19381752126562424, 0.19381752126562424, 0.19381752126562424, 0.20035116540292175, 0.20035116540292175, 0.20035116540292175, 0.18453816311407745, 0.18453816311407745, 0.18453816311407745, 0.1709701339416373, 0.1709701339416373, 0.1709701339416373, 0.19104830268622186, 0.19104830268622186, 0.19104830268622186, 0.07310600968431136, 0.07310600968431136, 0.07310600968431136, 0.06854543834691518, 0.06854543834691518, 0.06854543834691518, 0.06693363587053258, 0.06693363587053258, 0.06693363587053258]}, "mutation_prompt": null}
{"id": "63b9cddf-f118-422b-8aca-27db1890c911", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.8  # Adjusted Crossover probability for better performance\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced differential evolution by adjusting crossover probability for better exploration-exploitation balance.", "configspace": "", "generation": 64, "fitness": 0.30601817331726155, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.25.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.8531488426013425, 0.8531488426013425, 0.8531488426013425, 0.8222198183659161, 0.8222198183659161, 0.8222198183659161, 0.8544691329446247, 0.8544691329446247, 0.8544691329446247, 0.6606220315725173, 0.6606220315725173, 0.6606220315725173, 0.6336096896444923, 0.6336096896444923, 0.6336096896444923, 0.6325815281776626, 0.6325815281776626, 0.6325815281776626, 0.1600730996923958, 0.1600730996923958, 0.1600730996923958, 0.1420099395745359, 0.1420099395745359, 0.1420099395745359, 0.16291694415500546, 0.16291694415500546, 0.16291694415500546, 0.10684701924322015, 0.10684701924322015, 0.10684701924322015, 0.14298544183590944, 0.14298544183590944, 0.14298544183590944, 0.11837362493645465, 0.11837362493645465, 0.11837362493645465, 0.9742327525896703, 0.9742327525896703, 0.9742327525896703, 0.9718226253468596, 0.9718226253468596, 0.9718226253468596, 0.9732012094042678, 0.9732012094042678, 0.9732012094042678, 0.590443413091793, 0.590443413091793, 0.590443413091793, 0.5898460682171927, 0.5898460682171927, 0.5898460682171927, 0.5648668207530185, 0.5648668207530185, 0.5648668207530185, 0.3434610143938408, 0.3434610143938408, 0.3434610143938408, 0.2684189425450647, 0.2684189425450647, 0.2684189425450647, 0.2295342646126599, 0.2295342646126599, 0.2295342646126599, 0.1960524089982283, 0.1960524089982283, 0.1960524089982283, 0.3094456187394772, 0.3094456187394772, 0.3094456187394772, 0.20165369089410123, 0.20165369089410123, 0.20165369089410123, 0.2004312052205489, 0.2004312052205489, 0.2004312052205489, 0.21495759996745623, 0.21495759996745623, 0.21495759996745623, 0.20947752729816227, 0.20947752729816227, 0.20947752729816227, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036474454487080976, 0.036474454487080976, 0.036474454487080976, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09402961527308162, 0.09402961527308162, 0.09402961527308162, 0.09463723644740185, 0.09463723644740185, 0.09463723644740185, 0.0844562458358985, 0.0844562458358985, 0.0844562458358985, 0.1971529288819791, 0.1971529288819791, 0.1971529288819791, 0.11986319569516568, 0.11986319569516568, 0.11986319569516568, 0.28162351826154075, 0.28162351826154075, 0.28162351826154075, 0.04334275981958691, 0.04334275981958691, 0.04334275981958691, 0.20155772833054253, 0.20155772833054253, 0.20155772833054253, 0.17295905499028208, 0.17295905499028208, 0.17295905499028208, 0.5333738409727373, 0.5333738409727373, 0.5333738409727373, 0.5197380223039412, 0.5197380223039412, 0.5197380223039412, 0.5531137406027364, 0.5531137406027364, 0.5531137406027364, 0.1173346675852468, 0.1173346675852468, 0.1173346675852468, 0.1259650633574687, 0.1259650633574687, 0.1259650633574687, 0.10307476619083411, 0.10307476619083411, 0.10307476619083411, 0.18913272845081563, 0.18913272845081563, 0.18913272845081563, 0.23797477752543605, 0.23797477752543605, 0.23797477752543605, 0.22030579586309063, 0.22030579586309063, 0.22030579586309063, 0.2611158849959765, 0.2611158849959765, 0.2611158849959765, 0.3589134603029509, 0.3589134603029509, 0.3589134603029509, 0.4925090717651899, 0.4925090717651899, 0.4925090717651899, 0.2333719495980373, 0.2333719495980373, 0.2333719495980373, 0.18857144221209687, 0.18857144221209687, 0.18857144221209687, 0.18527843059565807, 0.18527843059565807, 0.18527843059565807, 0.2131023533411187, 0.2131023533411187, 0.2131023533411187, 0.21668437751475045, 0.21668437751475045, 0.21668437751475045, 0.21053985628590455, 0.21053985628590455, 0.21053985628590455, 0.23381289484570578, 0.23381289484570578, 0.23381289484570578, 0.20207305463583913, 0.20207305463583913, 0.20207305463583913, 0.20771318713311782, 0.20771318713311782, 0.20771318713311782, 0.8018295542693258, 0.8018295542693258, 0.8018295542693258, 0.1646504718833135, 0.1646504718833135, 0.1646504718833135, 0.19815986698915422, 0.19815986698915422, 0.19815986698915422, 0.16738908516117823, 0.16738908516117823, 0.16738908516117823, 0.2078890053683068, 0.2078890053683068, 0.2078890053683068, 0.5973556240519929, 0.5973556240519929, 0.5973556240519929, 0.19977121890620952, 0.19977121890620952, 0.19977121890620952, 0.1758643227144837, 0.1758643227144837, 0.1758643227144837, 0.18889038444973494, 0.18889038444973494, 0.18889038444973494, 0.08790930628483706, 0.08790930628483706, 0.08790930628483706, 0.09398725945429853, 0.09398725945429853, 0.09398725945429853, 0.09191400039236342, 0.09191400039236342, 0.09191400039236342]}, "mutation_prompt": null}
{"id": "8a89ef01-b5c5-4535-88cf-83870e6b23e2", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.w = 0.5 - evaluations/self.budget * 0.2  # Reduced inertia weight over time\n                self.c1 = 2.7 - evaluations/self.budget * 1.5\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Improved exploration by decreasing the inertia weight in PSO over time.", "configspace": "", "generation": 65, "fitness": 0.33110368842080995, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.27.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.876493515963535, 0.876493515963535, 0.876493515963535, 0.8303843868697173, 0.8303843868697173, 0.8303843868697173, 0.872578711188317, 0.872578711188317, 0.872578711188317, 0.6086627130044071, 0.6086627130044071, 0.6086627130044071, 0.6729879674592012, 0.6729879674592012, 0.6729879674592012, 0.7050276225260206, 0.7050276225260206, 0.7050276225260206, 0.14350860597281445, 0.14350860597281445, 0.14350860597281445, 0.12697358740999154, 0.12697358740999154, 0.12697358740999154, 0.17172273120633363, 0.17172273120633363, 0.17172273120633363, 0.10640613853395664, 0.10640613853395664, 0.10640613853395664, 0.1064487495959977, 0.1064487495959977, 0.1064487495959977, 0.10817365932044065, 0.10817365932044065, 0.10817365932044065, 0.9734596502822292, 0.9734596502822292, 0.9734596502822292, 0.9738446618166262, 0.9738446618166262, 0.9738446618166262, 0.9697871321048367, 0.9697871321048367, 0.9697871321048367, 0.6443272724794095, 0.6443272724794095, 0.6443272724794095, 0.5998595102296125, 0.5998595102296125, 0.5998595102296125, 0.6370868989347864, 0.6370868989347864, 0.6370868989347864, 0.7651455407167205, 0.7651455407167205, 0.7651455407167205, 0.275801549428886, 0.275801549428886, 0.275801549428886, 0.6901004186323346, 0.6901004186323346, 0.6901004186323346, 0.23812525465176282, 0.23812525465176282, 0.23812525465176282, 0.1297581561846206, 0.1297581561846206, 0.1297581561846206, 0.21522167729546848, 0.21522167729546848, 0.21522167729546848, 0.22412377626510127, 0.22412377626510127, 0.22412377626510127, 0.1293251702798427, 0.1293251702798427, 0.1293251702798427, 0.23676577987113845, 0.23676577987113845, 0.23676577987113845, 0.015536240093935727, 0.015536240093935727, 0.015536240093935727, 0.0004976966376402103, 0.0004976966376402103, 0.0004976966376402103, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11910180862286757, 0.11910180862286757, 0.11910180862286757, 0.05891125206670822, 0.05891125206670822, 0.05891125206670822, 0.1210438122985259, 0.1210438122985259, 0.1210438122985259, 0.14413800774207886, 0.14413800774207886, 0.14413800774207886, 0.39347814517963464, 0.39347814517963464, 0.39347814517963464, 0.1952500968116675, 0.1952500968116675, 0.1952500968116675, 0.17395947930812816, 0.17395947930812816, 0.17395947930812816, 0.3002258130457357, 0.3002258130457357, 0.3002258130457357, 0.057317661639749495, 0.057317661639749495, 0.057317661639749495, 0.5253204823666957, 0.5253204823666957, 0.5253204823666957, 0.5452077163677069, 0.5452077163677069, 0.5452077163677069, 0.5388889227120738, 0.5388889227120738, 0.5388889227120738, 0.116702714990224, 0.116702714990224, 0.116702714990224, 0.10747046857383413, 0.10747046857383413, 0.10747046857383413, 0.1480155293839669, 0.1480155293839669, 0.1480155293839669, 0.22740498013864208, 0.22740498013864208, 0.22740498013864208, 0.14181065286708583, 0.14181065286708583, 0.14181065286708583, 0.24713495525570084, 0.24713495525570084, 0.24713495525570084, 0.41013842402443634, 0.41013842402443634, 0.41013842402443634, 0.4591128854339618, 0.4591128854339618, 0.4591128854339618, 0.4909842246816004, 0.4909842246816004, 0.4909842246816004, 0.29094378300162627, 0.29094378300162627, 0.29094378300162627, 0.23298531550941193, 0.23298531550941193, 0.23298531550941193, 0.2884877058640335, 0.2884877058640335, 0.2884877058640335, 0.22083611025062788, 0.22083611025062788, 0.22083611025062788, 0.19779723596552112, 0.19779723596552112, 0.19779723596552112, 0.25492146501801405, 0.25492146501801405, 0.25492146501801405, 0.19529608517618047, 0.19529608517618047, 0.19529608517618047, 0.20202110477438728, 0.20202110477438728, 0.20202110477438728, 0.20647421020082934, 0.20647421020082934, 0.20647421020082934, 0.8375314773985202, 0.8375314773985202, 0.8375314773985202, 0.1634259258583003, 0.1634259258583003, 0.1634259258583003, 0.697128201403767, 0.697128201403767, 0.697128201403767, 0.16803269976278334, 0.16803269976278334, 0.16803269976278334, 0.20737189285466695, 0.20737189285466695, 0.20737189285466695, 0.20741564238396837, 0.20741564238396837, 0.20741564238396837, 0.20246909373325528, 0.20246909373325528, 0.20246909373325528, 0.20760251886906012, 0.20760251886906012, 0.20760251886906012, 0.1994741090666875, 0.1994741090666875, 0.1994741090666875, 0.09527979865828862, 0.09527979865828862, 0.09527979865828862, 0.09156978881024802, 0.09156978881024802, 0.09156978881024802, 0.10254859327142984, 0.10254859327142984, 0.10254859327142984]}, "mutation_prompt": null}
{"id": "d3ec0bf4-8ca6-48f4-9fd4-24b815371ca3", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        # self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.w = 0.9 - (0.9 - 0.4) * (evaluations / self.budget)  # Dynamic inertia weight\n                self.c1 = 2.7 - evaluations/self.budget * 1.5\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Introduce a dynamic inertia weight adjustment in PSO for better exploration-exploitation balance.", "configspace": "", "generation": 66, "fitness": 0.20577492177781914, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.44758853118755115, 0.44758853118755115, 0.44758853118755115, 0.5466156977500924, 0.5466156977500924, 0.5466156977500924, 0.4807008716687816, 0.4807008716687816, 0.4807008716687816, 0.12366888526057884, 0.12366888526057884, 0.12366888526057884, 0.17767300616067727, 0.17767300616067727, 0.17767300616067727, 0.2065798473130781, 0.2065798473130781, 0.2065798473130781, 0.0988579180126189, 0.0988579180126189, 0.0988579180126189, 0.1081361840076337, 0.1081361840076337, 0.1081361840076337, 0.09963585736028491, 0.09963585736028491, 0.09963585736028491, 0.08109380353766449, 0.08109380353766449, 0.08109380353766449, 0.08519866607291138, 0.08519866607291138, 0.08519866607291138, 0.09163140126409886, 0.09163140126409886, 0.09163140126409886, 0.975651045096156, 0.975651045096156, 0.975651045096156, 0.9790362992505957, 0.9790362992505957, 0.9790362992505957, 0.9736668129840342, 0.9736668129840342, 0.9736668129840342, 0.2913679120706736, 0.2913679120706736, 0.2913679120706736, 0.2549019415282592, 0.2549019415282592, 0.2549019415282592, 0.2595875451798102, 0.2595875451798102, 0.2595875451798102, 0.24975608698443053, 0.24975608698443053, 0.24975608698443053, 0.16938114229449852, 0.16938114229449852, 0.16938114229449852, 0.16184508959737798, 0.16184508959737798, 0.16184508959737798, 0.09441635482944422, 0.09441635482944422, 0.09441635482944422, 0.19078210425831343, 0.19078210425831343, 0.19078210425831343, 0.19028496913239568, 0.19028496913239568, 0.19028496913239568, 0.042746067586211356, 0.042746067586211356, 0.042746067586211356, 0.11527350072230225, 0.11527350072230225, 0.11527350072230225, 0.12431717607551385, 0.12431717607551385, 0.12431717607551385, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0787400252107916, 0.0787400252107916, 0.0787400252107916, 0.06907151679223622, 0.06907151679223622, 0.06907151679223622, 0.06435206586822972, 0.06435206586822972, 0.06435206586822972, 0.017864077197967676, 0.017864077197967676, 0.017864077197967676, 0.06176875968303708, 0.06176875968303708, 0.06176875968303708, 0.03499618171061425, 0.03499618171061425, 0.03499618171061425, 0.0370664250550683, 0.0370664250550683, 0.0370664250550683, 0.0891172103226352, 0.0891172103226352, 0.0891172103226352, 0.03892962365755337, 0.03892962365755337, 0.03892962365755337, 0.3835547593022345, 0.3835547593022345, 0.3835547593022345, 0.39393277978697494, 0.39393277978697494, 0.39393277978697494, 0.3793510952057222, 0.3793510952057222, 0.3793510952057222, 0.08424628248284693, 0.08424628248284693, 0.08424628248284693, 0.09840668691393673, 0.09840668691393673, 0.09840668691393673, 0.10339739159368966, 0.10339739159368966, 0.10339739159368966, 0.17211817624461512, 0.17211817624461512, 0.17211817624461512, 0.1863635839168436, 0.1863635839168436, 0.1863635839168436, 0.15120320850345137, 0.15120320850345137, 0.15120320850345137, 0.28121285095416215, 0.28121285095416215, 0.28121285095416215, 0.26219718151078497, 0.26219718151078497, 0.26219718151078497, 0.2653662357826615, 0.2653662357826615, 0.2653662357826615, 0.18477563388248686, 0.18477563388248686, 0.18477563388248686, 0.20250773159947, 0.20250773159947, 0.20250773159947, 0.1756798866194491, 0.1756798866194491, 0.1756798866194491, 0.17662582065245247, 0.17662582065245247, 0.17662582065245247, 0.1802211752050622, 0.1802211752050622, 0.1802211752050622, 0.1862266468019117, 0.1862266468019117, 0.1862266468019117, 0.18178382476566035, 0.18178382476566035, 0.18178382476566035, 0.1887550617696726, 0.1887550617696726, 0.1887550617696726, 0.20987439864355828, 0.20987439864355828, 0.20987439864355828, 0.5613909862669498, 0.5613909862669498, 0.5613909862669498, 0.1511788111992819, 0.1511788111992819, 0.1511788111992819, 0.1791580623678275, 0.1791580623678275, 0.1791580623678275, 0.19193715196545014, 0.19193715196545014, 0.19193715196545014, 0.19660007486030728, 0.19660007486030728, 0.19660007486030728, 0.1857322973189689, 0.1857322973189689, 0.1857322973189689, 0.195319602465868, 0.195319602465868, 0.195319602465868, 0.19033097172020963, 0.19033097172020963, 0.19033097172020963, 0.1756322862540154, 0.1756322862540154, 0.1756322862540154, 0.0709170233676294, 0.0709170233676294, 0.0709170233676294, 0.07582857042875879, 0.07582857042875879, 0.07582857042875879, 0.08136751496594352, 0.08136751496594352, 0.08136751496594352]}, "mutation_prompt": null}
{"id": "c3c9b7d9-89cf-47cb-8d3c-7a3b1ee71971", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.6  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced exploration by slightly increasing the differential evolution mutation factor.", "configspace": "", "generation": 67, "fitness": 0.3282104894661493, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.27.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.8519741438328772, 0.8519741438328772, 0.8519741438328772, 0.8522232729402333, 0.8522232729402333, 0.8522232729402333, 0.8716537146579036, 0.8716537146579036, 0.8716537146579036, 0.5938755616911529, 0.5938755616911529, 0.5938755616911529, 0.6347477094250065, 0.6347477094250065, 0.6347477094250065, 0.645366152370004, 0.645366152370004, 0.645366152370004, 0.14805126111338973, 0.14805126111338973, 0.14805126111338973, 0.15561870599481753, 0.15561870599481753, 0.15561870599481753, 0.13749608685890158, 0.13749608685890158, 0.13749608685890158, 0.11101595148291943, 0.11101595148291943, 0.11101595148291943, 0.12560222304408541, 0.12560222304408541, 0.12560222304408541, 0.11768101500154848, 0.11768101500154848, 0.11768101500154848, 0.9737729386068896, 0.9737729386068896, 0.9737729386068896, 0.9717227899301932, 0.9717227899301932, 0.9717227899301932, 0.9699333372574342, 0.9699333372574342, 0.9699333372574342, 0.6012529666705773, 0.6012529666705773, 0.6012529666705773, 0.5598586336410543, 0.5598586336410543, 0.5598586336410543, 0.5737566673849597, 0.5737566673849597, 0.5737566673849597, 0.6652179915178237, 0.6652179915178237, 0.6652179915178237, 0.5625705490401767, 0.5625705490401767, 0.5625705490401767, 0.5206460660957841, 0.5206460660957841, 0.5206460660957841, 0.21096662586000747, 0.21096662586000747, 0.21096662586000747, 0.23234065337763754, 0.23234065337763754, 0.23234065337763754, 0.13055149276655553, 0.13055149276655553, 0.13055149276655553, 0.19126400964882262, 0.19126400964882262, 0.19126400964882262, 0.23178004281940578, 0.23178004281940578, 0.23178004281940578, 0.21634564122982314, 0.21634564122982314, 0.21634564122982314, 0.011018369516471838, 0.011018369516471838, 0.011018369516471838, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07628567475946402, 0.07628567475946402, 0.07628567475946402, 0.04577023734441277, 0.04577023734441277, 0.04577023734441277, 0.0463952273900341, 0.0463952273900341, 0.0463952273900341, 0.04684347765028796, 0.04684347765028796, 0.04684347765028796, 0.11524310858608311, 0.11524310858608311, 0.11524310858608311, 0.17443770576349094, 0.17443770576349094, 0.17443770576349094, 0.12848492670217415, 0.12848492670217415, 0.12848492670217415, 0.08627428670970572, 0.08627428670970572, 0.08627428670970572, 0.060632934957143725, 0.060632934957143725, 0.060632934957143725, 0.5160686659032837, 0.5160686659032837, 0.5160686659032837, 0.5258287042647534, 0.5258287042647534, 0.5258287042647534, 0.5633471549684006, 0.5633471549684006, 0.5633471549684006, 0.12184911571248935, 0.12184911571248935, 0.12184911571248935, 0.14717044565793058, 0.14717044565793058, 0.14717044565793058, 0.12536996722979765, 0.12536996722979765, 0.12536996722979765, 0.1718073317929033, 0.1718073317929033, 0.1718073317929033, 0.21566019484398258, 0.21566019484398258, 0.21566019484398258, 0.21234288628452025, 0.21234288628452025, 0.21234288628452025, 0.47998250600961745, 0.47998250600961745, 0.47998250600961745, 0.48990524234828947, 0.48990524234828947, 0.48990524234828947, 0.42902101305167084, 0.42902101305167084, 0.42902101305167084, 0.22753949459305767, 0.22753949459305767, 0.22753949459305767, 0.2224878010904915, 0.2224878010904915, 0.2224878010904915, 0.2051621466004533, 0.2051621466004533, 0.2051621466004533, 0.22176979125645158, 0.22176979125645158, 0.22176979125645158, 0.22277818914159164, 0.22277818914159164, 0.22277818914159164, 0.21244402777535054, 0.21244402777535054, 0.21244402777535054, 0.18887979639897912, 0.18887979639897912, 0.18887979639897912, 0.21524848010984088, 0.21524848010984088, 0.21524848010984088, 0.21184513350231637, 0.21184513350231637, 0.21184513350231637, 0.8630674223679039, 0.8630674223679039, 0.8630674223679039, 0.16350862170902414, 0.16350862170902414, 0.16350862170902414, 0.19475736807897792, 0.19475736807897792, 0.19475736807897792, 0.6361580249552758, 0.6361580249552758, 0.6361580249552758, 0.6375543428505228, 0.6375543428505228, 0.6375543428505228, 0.6769254155405378, 0.6769254155405378, 0.6769254155405378, 0.1868332209529151, 0.1868332209529151, 0.1868332209529151, 0.1851520338909204, 0.1851520338909204, 0.1851520338909204, 0.22205451632085693, 0.22205451632085693, 0.22205451632085693, 0.08860476967864361, 0.08860476967864361, 0.08860476967864361, 0.09027986585121761, 0.09027986585121761, 0.09027986585121761, 0.11087939719052498, 0.11087939719052498, 0.11087939719052498]}, "mutation_prompt": null}
{"id": "ff1457a0-2878-4ebc-a5a3-e737fd2d13e6", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Increase the inertia weight to enhance exploration in the PSO step.", "configspace": "", "generation": 68, "fitness": 0.23027722903962633, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.21.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.489729205805689, 0.489729205805689, 0.489729205805689, 0.5426552892751138, 0.5426552892751138, 0.5426552892751138, 0.6281938628935912, 0.6281938628935912, 0.6281938628935912, 0.20336190931602294, 0.20336190931602294, 0.20336190931602294, 0.1750066485456202, 0.1750066485456202, 0.1750066485456202, 0.15020290901802713, 0.15020290901802713, 0.15020290901802713, 0.10092311299552403, 0.10092311299552403, 0.10092311299552403, 0.10942387865492642, 0.10942387865492642, 0.10942387865492642, 0.11912067278485905, 0.11912067278485905, 0.11912067278485905, 0.11855767850548704, 0.11855767850548704, 0.11855767850548704, 0.08488838868775384, 0.08488838868775384, 0.08488838868775384, 0.0830985945148881, 0.0830985945148881, 0.0830985945148881, 0.9734673280437594, 0.9734673280437594, 0.9734673280437594, 0.974364824184331, 0.974364824184331, 0.974364824184331, 0.9706870579976348, 0.9706870579976348, 0.9706870579976348, 0.3563561240235462, 0.3563561240235462, 0.3563561240235462, 0.2728774232533493, 0.2728774232533493, 0.2728774232533493, 0.2586712726086188, 0.2586712726086188, 0.2586712726086188, 0.531160130141563, 0.531160130141563, 0.531160130141563, 0.3488397310774267, 0.3488397310774267, 0.3488397310774267, 0.2536980720246065, 0.2536980720246065, 0.2536980720246065, 0.13249074835779706, 0.13249074835779706, 0.13249074835779706, 0.1374711617156943, 0.1374711617156943, 0.1374711617156943, 0.16992449843516932, 0.16992449843516932, 0.16992449843516932, 0.13035153609958983, 0.13035153609958983, 0.13035153609958983, 0.17884352176540397, 0.17884352176540397, 0.17884352176540397, 0.1475526823636648, 0.1475526823636648, 0.1475526823636648, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0749234688928615, 0.0749234688928615, 0.0749234688928615, 0.05776169488488081, 0.05776169488488081, 0.05776169488488081, 0.09528670968925779, 0.09528670968925779, 0.09528670968925779, 0.03746753801241742, 0.03746753801241742, 0.03746753801241742, 0.05245242971203423, 0.05245242971203423, 0.05245242971203423, 0.04123472893399738, 0.04123472893399738, 0.04123472893399738, 0.08422024857633281, 0.08422024857633281, 0.08422024857633281, 0.10205854995893737, 0.10205854995893737, 0.10205854995893737, 0.048020762165913444, 0.048020762165913444, 0.048020762165913444, 0.44628113735584396, 0.44628113735584396, 0.44628113735584396, 0.4308062171183108, 0.4308062171183108, 0.4308062171183108, 0.44454170829426054, 0.44454170829426054, 0.44454170829426054, 0.10698287453180799, 0.10698287453180799, 0.10698287453180799, 0.08317236551805274, 0.08317236551805274, 0.08317236551805274, 0.08263604016863924, 0.08263604016863924, 0.08263604016863924, 0.2234054720756966, 0.2234054720756966, 0.2234054720756966, 0.15171228727299513, 0.15171228727299513, 0.15171228727299513, 0.2275126955372977, 0.2275126955372977, 0.2275126955372977, 0.2963259685927947, 0.2963259685927947, 0.2963259685927947, 0.27410936075347825, 0.27410936075347825, 0.27410936075347825, 0.31337908827202654, 0.31337908827202654, 0.31337908827202654, 0.22165365990574737, 0.22165365990574737, 0.22165365990574737, 0.15667601793509678, 0.15667601793509678, 0.15667601793509678, 0.16546079797764557, 0.16546079797764557, 0.16546079797764557, 0.18129352843804725, 0.18129352843804725, 0.18129352843804725, 0.20470000042502556, 0.20470000042502556, 0.20470000042502556, 0.19332652648150683, 0.19332652648150683, 0.19332652648150683, 0.17497099351408485, 0.17497099351408485, 0.17497099351408485, 0.20713223818776938, 0.20713223818776938, 0.20713223818776938, 0.2669256518188128, 0.2669256518188128, 0.2669256518188128, 0.715924221196987, 0.715924221196987, 0.715924221196987, 0.1986015333120167, 0.1986015333120167, 0.1986015333120167, 0.1644702249307125, 0.1644702249307125, 0.1644702249307125, 0.16615189207200798, 0.16615189207200798, 0.16615189207200798, 0.20595887891121423, 0.20595887891121423, 0.20595887891121423, 0.19996848969653125, 0.19996848969653125, 0.19996848969653125, 0.19498600936416155, 0.19498600936416155, 0.19498600936416155, 0.19001180105203752, 0.19001180105203752, 0.19001180105203752, 0.19092316267931697, 0.19092316267931697, 0.19092316267931697, 0.09565757846555822, 0.09565757846555822, 0.09565757846555822, 0.08260274507029408, 0.08260274507029408, 0.08260274507029408, 0.08605493001102771, 0.08605493001102771, 0.08605493001102771]}, "mutation_prompt": null}
{"id": "e0b72ddb-ca4f-4581-9934-ffc0e516b3f0", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))  # Changed range from (-1, 1) to (-0.5, 0.5)\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Fine-tuned the initial velocity range for improved exploration in the AdaptiveHybridGA.", "configspace": "", "generation": 69, "fitness": 0.3276063314332687, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.26.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.8448366279308651, 0.8448366279308651, 0.8448366279308651, 0.7933987729735995, 0.7933987729735995, 0.7933987729735995, 0.8461589837737662, 0.8461589837737662, 0.8461589837737662, 0.5409392469138109, 0.5409392469138109, 0.5409392469138109, 0.6391546862646531, 0.6391546862646531, 0.6391546862646531, 0.6155419390791013, 0.6155419390791013, 0.6155419390791013, 0.16095357044150438, 0.16095357044150438, 0.16095357044150438, 0.15140734713715032, 0.15140734713715032, 0.15140734713715032, 0.12563727694413973, 0.12563727694413973, 0.12563727694413973, 0.12005950799782417, 0.12005950799782417, 0.12005950799782417, 0.12279856932079092, 0.12279856932079092, 0.12279856932079092, 0.12842418992872118, 0.12842418992872118, 0.12842418992872118, 0.9738709223402577, 0.9738709223402577, 0.9738709223402577, 0.9737649861464599, 0.9737649861464599, 0.9737649861464599, 0.9714913697152239, 0.9714913697152239, 0.9714913697152239, 0.5820298840457682, 0.5820298840457682, 0.5820298840457682, 0.6247892281789509, 0.6247892281789509, 0.6247892281789509, 0.5865610301508632, 0.5865610301508632, 0.5865610301508632, 0.21492403748034983, 0.21492403748034983, 0.21492403748034983, 0.25664265420022425, 0.25664265420022425, 0.25664265420022425, 0.6428948443214313, 0.6428948443214313, 0.6428948443214313, 0.19410912043020534, 0.19410912043020534, 0.19410912043020534, 0.21424819798346784, 0.21424819798346784, 0.21424819798346784, 0.2142974766633321, 0.2142974766633321, 0.2142974766633321, 0.22120375558222605, 0.22120375558222605, 0.22120375558222605, 0.22823001451699443, 0.22823001451699443, 0.22823001451699443, 0.21910647214699241, 0.21910647214699241, 0.21910647214699241, 0.0006295001021086044, 0.0006295001021086044, 0.0006295001021086044, 0.00044879471744063704, 0.00044879471744063704, 0.00044879471744063704, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10332753762775682, 0.10332753762775682, 0.10332753762775682, 0.09851488905938299, 0.09851488905938299, 0.09851488905938299, 0.0721977154135649, 0.0721977154135649, 0.0721977154135649, 0.10336969878454061, 0.10336969878454061, 0.10336969878454061, 0.18898890372730903, 0.18898890372730903, 0.18898890372730903, 0.2844189835780805, 0.2844189835780805, 0.2844189835780805, 0.2709119639505967, 0.2709119639505967, 0.2709119639505967, 0.07746473701272849, 0.07746473701272849, 0.07746473701272849, 0.20107340880781677, 0.20107340880781677, 0.20107340880781677, 0.5141161969716661, 0.5141161969716661, 0.5141161969716661, 0.5680765720894786, 0.5680765720894786, 0.5680765720894786, 0.5529045455365664, 0.5529045455365664, 0.5529045455365664, 0.10924698516259579, 0.10924698516259579, 0.10924698516259579, 0.1347788500172925, 0.1347788500172925, 0.1347788500172925, 0.12069825388218614, 0.12069825388218614, 0.12069825388218614, 0.21586681548319364, 0.21586681548319364, 0.21586681548319364, 0.21055051603280694, 0.21055051603280694, 0.21055051603280694, 0.16369744026468636, 0.16369744026468636, 0.16369744026468636, 0.2934779529445035, 0.2934779529445035, 0.2934779529445035, 0.4631040950307609, 0.4631040950307609, 0.4631040950307609, 0.4354650686940077, 0.4354650686940077, 0.4354650686940077, 0.3434131010737661, 0.3434131010737661, 0.3434131010737661, 0.24223752282830224, 0.24223752282830224, 0.24223752282830224, 0.20807977716939563, 0.20807977716939563, 0.20807977716939563, 0.23704350778562133, 0.23704350778562133, 0.23704350778562133, 0.2030815280370749, 0.2030815280370749, 0.2030815280370749, 0.25322962708175834, 0.25322962708175834, 0.25322962708175834, 0.203399777839106, 0.203399777839106, 0.203399777839106, 0.21473041412536598, 0.21473041412536598, 0.21473041412536598, 0.597747640981775, 0.597747640981775, 0.597747640981775, 0.8332050247724446, 0.8332050247724446, 0.8332050247724446, 0.16405174173554737, 0.16405174173554737, 0.16405174173554737, 0.7516758787226409, 0.7516758787226409, 0.7516758787226409, 0.5220421842369234, 0.5220421842369234, 0.5220421842369234, 0.4015947394454904, 0.4015947394454904, 0.4015947394454904, 0.1649512626873233, 0.1649512626873233, 0.1649512626873233, 0.18900776036948963, 0.18900776036948963, 0.18900776036948963, 0.18508566858005637, 0.18508566858005637, 0.18508566858005637, 0.20476386727925744, 0.20476386727925744, 0.20476386727925744, 0.08764418895213422, 0.08764418895213422, 0.08764418895213422, 0.08729322939938189, 0.08729322939938189, 0.08729322939938189, 0.10247328259274857, 0.10247328259274857, 0.10247328259274857]}, "mutation_prompt": null}
{"id": "48eaa5e2-d4b3-4297-90f8-fdfc8883a2a3", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.6  # Inertia weight for PSO, increased from 0.5\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Slightly increase the inertia weight (w) to enhance exploration and improve convergence.", "configspace": "", "generation": 70, "fitness": 0.2797633581038645, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.23.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.7749319254847502, 0.7749319254847502, 0.7749319254847502, 0.7587484578443413, 0.7587484578443413, 0.7587484578443413, 0.7978635231988749, 0.7978635231988749, 0.7978635231988749, 0.4439637678128827, 0.4439637678128827, 0.4439637678128827, 0.4445003520696983, 0.4445003520696983, 0.4445003520696983, 0.2942508039327506, 0.2942508039327506, 0.2942508039327506, 0.13014604240515093, 0.13014604240515093, 0.13014604240515093, 0.1497182183100938, 0.1497182183100938, 0.1497182183100938, 0.13663223051302198, 0.13663223051302198, 0.13663223051302198, 0.13186116070199716, 0.13186116070199716, 0.13186116070199716, 0.09731148283043822, 0.09731148283043822, 0.09731148283043822, 0.11394990384542703, 0.11394990384542703, 0.11394990384542703, 0.9734237863293943, 0.9734237863293943, 0.9734237863293943, 0.9739704831338388, 0.9739704831338388, 0.9739704831338388, 0.9702329832334816, 0.9702329832334816, 0.9702329832334816, 0.44156411476993496, 0.44156411476993496, 0.44156411476993496, 0.4107148703423873, 0.4107148703423873, 0.4107148703423873, 0.4671670964483595, 0.4671670964483595, 0.4671670964483595, 0.5370005212694076, 0.5370005212694076, 0.5370005212694076, 0.21193338043049492, 0.21193338043049492, 0.21193338043049492, 0.2294670974525964, 0.2294670974525964, 0.2294670974525964, 0.1788270761033829, 0.1788270761033829, 0.1788270761033829, 0.186727006497306, 0.186727006497306, 0.186727006497306, 0.17891800136124925, 0.17891800136124925, 0.17891800136124925, 0.189526929226139, 0.189526929226139, 0.189526929226139, 0.19433655004047012, 0.19433655004047012, 0.19433655004047012, 0.21524852184964094, 0.21524852184964094, 0.21524852184964094, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006557029308984941, 0.006557029308984941, 0.006557029308984941, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08742355152447412, 0.08742355152447412, 0.08742355152447412, 0.05324146281287723, 0.05324146281287723, 0.05324146281287723, 0.0545836430851625, 0.0545836430851625, 0.0545836430851625, 0.1395688402667321, 0.1395688402667321, 0.1395688402667321, 0.06693852141994228, 0.06693852141994228, 0.06693852141994228, 0.22134018702291092, 0.22134018702291092, 0.22134018702291092, 0.16964127007509866, 0.16964127007509866, 0.16964127007509866, 0.10854765984722703, 0.10854765984722703, 0.10854765984722703, 0.056063385569116164, 0.056063385569116164, 0.056063385569116164, 0.5065431708667353, 0.5065431708667353, 0.5065431708667353, 0.4937063131907611, 0.4937063131907611, 0.4937063131907611, 0.5123426762216357, 0.5123426762216357, 0.5123426762216357, 0.1606868198784447, 0.1606868198784447, 0.1606868198784447, 0.13735228368598096, 0.13735228368598096, 0.13735228368598096, 0.1117564102585793, 0.1117564102585793, 0.1117564102585793, 0.23130743993398406, 0.23130743993398406, 0.23130743993398406, 0.18278489640456408, 0.18278489640456408, 0.18278489640456408, 0.3655003287552415, 0.3655003287552415, 0.3655003287552415, 0.3347281897822797, 0.3347281897822797, 0.3347281897822797, 0.3609055168021359, 0.3609055168021359, 0.3609055168021359, 0.4097281005190886, 0.4097281005190886, 0.4097281005190886, 0.29198801442616706, 0.29198801442616706, 0.29198801442616706, 0.22406921661621526, 0.22406921661621526, 0.22406921661621526, 0.20054824237285573, 0.20054824237285573, 0.20054824237285573, 0.18604405838175953, 0.18604405838175953, 0.18604405838175953, 0.21032800172109323, 0.21032800172109323, 0.21032800172109323, 0.19941601620425142, 0.19941601620425142, 0.19941601620425142, 0.18669218143741628, 0.18669218143741628, 0.18669218143741628, 0.23359481647632352, 0.23359481647632352, 0.23359481647632352, 0.3858506879691199, 0.3858506879691199, 0.3858506879691199, 0.8596568202874606, 0.8596568202874606, 0.8596568202874606, 0.16336119700933072, 0.16336119700933072, 0.16336119700933072, 0.16080004086557476, 0.16080004086557476, 0.16080004086557476, 0.16674224910528046, 0.16674224910528046, 0.16674224910528046, 0.20539043656553735, 0.20539043656553735, 0.20539043656553735, 0.19388040372637227, 0.19388040372637227, 0.19388040372637227, 0.18939349308545184, 0.18939349308545184, 0.18939349308545184, 0.20059231881802364, 0.20059231881802364, 0.20059231881802364, 0.19243905393939909, 0.19243905393939909, 0.19243905393939909, 0.0781173685526273, 0.0781173685526273, 0.0781173685526273, 0.07776410995802474, 0.07776410995802474, 0.07776410995802474, 0.13190907129049245, 0.13190907129049245, 0.13190907129049245]}, "mutation_prompt": null}
{"id": "a50f5ab9-063a-4746-b820-5c0893bc37c5", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                self.w = 0.9 - 0.5 * (evaluations / self.budget)  # Dynamically adjust inertia weight\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced global exploration by dynamically adjusting PSO inertia weight.", "configspace": "", "generation": 71, "fitness": 0.20577492177781914, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.20.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.44758853118755115, 0.44758853118755115, 0.44758853118755115, 0.5466156977500924, 0.5466156977500924, 0.5466156977500924, 0.4807008716687816, 0.4807008716687816, 0.4807008716687816, 0.12366888526057884, 0.12366888526057884, 0.12366888526057884, 0.17767300616067727, 0.17767300616067727, 0.17767300616067727, 0.2065798473130781, 0.2065798473130781, 0.2065798473130781, 0.0988579180126189, 0.0988579180126189, 0.0988579180126189, 0.1081361840076337, 0.1081361840076337, 0.1081361840076337, 0.09963585736028491, 0.09963585736028491, 0.09963585736028491, 0.08109380353766449, 0.08109380353766449, 0.08109380353766449, 0.08519866607291138, 0.08519866607291138, 0.08519866607291138, 0.09163140126409886, 0.09163140126409886, 0.09163140126409886, 0.975651045096156, 0.975651045096156, 0.975651045096156, 0.9790362992505957, 0.9790362992505957, 0.9790362992505957, 0.9736668129840342, 0.9736668129840342, 0.9736668129840342, 0.2913679120706736, 0.2913679120706736, 0.2913679120706736, 0.2549019415282592, 0.2549019415282592, 0.2549019415282592, 0.2595875451798102, 0.2595875451798102, 0.2595875451798102, 0.24975608698443053, 0.24975608698443053, 0.24975608698443053, 0.16938114229449852, 0.16938114229449852, 0.16938114229449852, 0.16184508959737798, 0.16184508959737798, 0.16184508959737798, 0.09441635482944422, 0.09441635482944422, 0.09441635482944422, 0.19078210425831343, 0.19078210425831343, 0.19078210425831343, 0.19028496913239568, 0.19028496913239568, 0.19028496913239568, 0.042746067586211356, 0.042746067586211356, 0.042746067586211356, 0.11527350072230225, 0.11527350072230225, 0.11527350072230225, 0.12431717607551385, 0.12431717607551385, 0.12431717607551385, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0787400252107916, 0.0787400252107916, 0.0787400252107916, 0.06907151679223622, 0.06907151679223622, 0.06907151679223622, 0.06435206586822972, 0.06435206586822972, 0.06435206586822972, 0.017864077197967676, 0.017864077197967676, 0.017864077197967676, 0.06176875968303708, 0.06176875968303708, 0.06176875968303708, 0.03499618171061425, 0.03499618171061425, 0.03499618171061425, 0.0370664250550683, 0.0370664250550683, 0.0370664250550683, 0.0891172103226352, 0.0891172103226352, 0.0891172103226352, 0.03892962365755337, 0.03892962365755337, 0.03892962365755337, 0.3835547593022345, 0.3835547593022345, 0.3835547593022345, 0.39393277978697494, 0.39393277978697494, 0.39393277978697494, 0.3793510952057222, 0.3793510952057222, 0.3793510952057222, 0.08424628248284693, 0.08424628248284693, 0.08424628248284693, 0.09840668691393673, 0.09840668691393673, 0.09840668691393673, 0.10339739159368966, 0.10339739159368966, 0.10339739159368966, 0.17211817624461512, 0.17211817624461512, 0.17211817624461512, 0.1863635839168436, 0.1863635839168436, 0.1863635839168436, 0.15120320850345137, 0.15120320850345137, 0.15120320850345137, 0.28121285095416215, 0.28121285095416215, 0.28121285095416215, 0.26219718151078497, 0.26219718151078497, 0.26219718151078497, 0.2653662357826615, 0.2653662357826615, 0.2653662357826615, 0.18477563388248686, 0.18477563388248686, 0.18477563388248686, 0.20250773159947, 0.20250773159947, 0.20250773159947, 0.1756798866194491, 0.1756798866194491, 0.1756798866194491, 0.17662582065245247, 0.17662582065245247, 0.17662582065245247, 0.1802211752050622, 0.1802211752050622, 0.1802211752050622, 0.1862266468019117, 0.1862266468019117, 0.1862266468019117, 0.18178382476566035, 0.18178382476566035, 0.18178382476566035, 0.1887550617696726, 0.1887550617696726, 0.1887550617696726, 0.20987439864355828, 0.20987439864355828, 0.20987439864355828, 0.5613909862669498, 0.5613909862669498, 0.5613909862669498, 0.1511788111992819, 0.1511788111992819, 0.1511788111992819, 0.1791580623678275, 0.1791580623678275, 0.1791580623678275, 0.19193715196545014, 0.19193715196545014, 0.19193715196545014, 0.19660007486030728, 0.19660007486030728, 0.19660007486030728, 0.1857322973189689, 0.1857322973189689, 0.1857322973189689, 0.195319602465868, 0.195319602465868, 0.195319602465868, 0.19033097172020963, 0.19033097172020963, 0.19033097172020963, 0.1756322862540154, 0.1756322862540154, 0.1756322862540154, 0.0709170233676294, 0.0709170233676294, 0.0709170233676294, 0.07582857042875879, 0.07582857042875879, 0.07582857042875879, 0.08136751496594352, 0.08136751496594352, 0.08136751496594352]}, "mutation_prompt": null}
{"id": "e7afd631-ba83-4a98-b4cb-315dd9aee219", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.9 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced exploitation by increasing the cognitive coefficient in the PSO step.", "configspace": "", "generation": 72, "fitness": 0.3025035258183895, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.25.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.834292041460053, 0.834292041460053, 0.834292041460053, 0.8148460806080551, 0.8148460806080551, 0.8148460806080551, 0.8556321611380246, 0.8556321611380246, 0.8556321611380246, 0.5966882887015984, 0.5966882887015984, 0.5966882887015984, 0.5709984235792103, 0.5709984235792103, 0.5709984235792103, 0.5844368751583005, 0.5844368751583005, 0.5844368751583005, 0.14118081145861527, 0.14118081145861527, 0.14118081145861527, 0.15123592548536913, 0.15123592548536913, 0.15123592548536913, 0.1367530097130264, 0.1367530097130264, 0.1367530097130264, 0.1269472351941493, 0.1269472351941493, 0.1269472351941493, 0.11618305796914152, 0.11618305796914152, 0.11618305796914152, 0.13370920762160354, 0.13370920762160354, 0.13370920762160354, 0.9736345169670241, 0.9736345169670241, 0.9736345169670241, 0.9716749196618847, 0.9716749196618847, 0.9716749196618847, 0.9699950595454134, 0.9699950595454134, 0.9699950595454134, 0.5622194941839129, 0.5622194941839129, 0.5622194941839129, 0.4846673914588576, 0.4846673914588576, 0.4846673914588576, 0.5234880671398334, 0.5234880671398334, 0.5234880671398334, 0.7039070314443454, 0.7039070314443454, 0.7039070314443454, 0.25609593044006307, 0.25609593044006307, 0.25609593044006307, 0.6491627081139668, 0.6491627081139668, 0.6491627081139668, 0.19380618646902836, 0.19380618646902836, 0.19380618646902836, 0.18154531656721307, 0.18154531656721307, 0.18154531656721307, 0.19339494449622363, 0.19339494449622363, 0.19339494449622363, 0.21211006833712276, 0.21211006833712276, 0.21211006833712276, 0.13015567546846707, 0.13015567546846707, 0.13015567546846707, 0.17640199945195434, 0.17640199945195434, 0.17640199945195434, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016903769991441386, 0.016903769991441386, 0.016903769991441386, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07656466291826469, 0.07656466291826469, 0.07656466291826469, 0.09270816267318382, 0.09270816267318382, 0.09270816267318382, 0.08461563687642426, 0.08461563687642426, 0.08461563687642426, 0.22636339485590273, 0.22636339485590273, 0.22636339485590273, 0.21843257523273674, 0.21843257523273674, 0.21843257523273674, 0.1579214761182377, 0.1579214761182377, 0.1579214761182377, 0.07707277622586639, 0.07707277622586639, 0.07707277622586639, 0.16681694943656744, 0.16681694943656744, 0.16681694943656744, 0.05427977911616477, 0.05427977911616477, 0.05427977911616477, 0.5015841616423931, 0.5015841616423931, 0.5015841616423931, 0.5431427088073582, 0.5431427088073582, 0.5431427088073582, 0.5442112170274204, 0.5442112170274204, 0.5442112170274204, 0.11918540915738862, 0.11918540915738862, 0.11918540915738862, 0.10023324718787208, 0.10023324718787208, 0.10023324718787208, 0.12889325712692223, 0.12889325712692223, 0.12889325712692223, 0.2107896880695337, 0.2107896880695337, 0.2107896880695337, 0.1890769133608048, 0.1890769133608048, 0.1890769133608048, 0.24205641166262404, 0.24205641166262404, 0.24205641166262404, 0.3472486386730702, 0.3472486386730702, 0.3472486386730702, 0.19546412483653508, 0.19546412483653508, 0.19546412483653508, 0.39560123376262535, 0.39560123376262535, 0.39560123376262535, 0.25381001650804524, 0.25381001650804524, 0.25381001650804524, 0.1772112907229737, 0.1772112907229737, 0.1772112907229737, 0.2024141528798542, 0.2024141528798542, 0.2024141528798542, 0.20935166205062183, 0.20935166205062183, 0.20935166205062183, 0.2062341303722831, 0.2062341303722831, 0.2062341303722831, 0.21062482193525445, 0.21062482193525445, 0.21062482193525445, 0.23202001316745613, 0.23202001316745613, 0.23202001316745613, 0.21619469651462264, 0.21619469651462264, 0.21619469651462264, 0.23105842228584683, 0.23105842228584683, 0.23105842228584683, 0.8468257392549073, 0.8468257392549073, 0.8468257392549073, 0.16328444377781637, 0.16328444377781637, 0.16328444377781637, 0.15640675945624627, 0.15640675945624627, 0.15640675945624627, 0.48059622233935384, 0.48059622233935384, 0.48059622233935384, 0.2072818873419413, 0.2072818873419413, 0.2072818873419413, 0.2051793968344664, 0.2051793968344664, 0.2051793968344664, 0.18790545729834507, 0.18790545729834507, 0.18790545729834507, 0.20041144914190878, 0.20041144914190878, 0.20041144914190878, 0.20068885739545805, 0.20068885739545805, 0.20068885739545805, 0.0888078224616673, 0.0888078224616673, 0.0888078224616673, 0.08579476186964807, 0.08579476186964807, 0.08579476186964807, 0.08362323272353644, 0.08362323272353644, 0.08362323272353644]}, "mutation_prompt": null}
{"id": "e9cac217-7d3a-404d-b58a-3f72ecf5f505", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.7 - evaluations/self.budget * 1.5  # Increased cognitive coefficient slightly\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                self.w = 0.4 + 0.6 * (evaluations / self.budget)  # Gradually increasing inertia weight\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Improved adaptive exploratory factor by gradually increasing the inertia weight in PSO.", "configspace": "", "generation": 73, "fitness": 0.2965035090393915, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.24.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.8232793469880233, 0.8232793469880233, 0.8232793469880233, 0.8090259531509637, 0.8090259531509637, 0.8090259531509637, 0.8677628995424838, 0.8677628995424838, 0.8677628995424838, 0.34656866656066354, 0.34656866656066354, 0.34656866656066354, 0.471942153806721, 0.471942153806721, 0.471942153806721, 0.31602889592962313, 0.31602889592962313, 0.31602889592962313, 0.12964956240056857, 0.12964956240056857, 0.12964956240056857, 0.11471616886729574, 0.11471616886729574, 0.11471616886729574, 0.160656600045039, 0.160656600045039, 0.160656600045039, 0.10549584655604227, 0.10549584655604227, 0.10549584655604227, 0.13299061134941315, 0.13299061134941315, 0.13299061134941315, 0.13043289472963693, 0.13043289472963693, 0.13043289472963693, 0.9731572564359027, 0.9731572564359027, 0.9731572564359027, 0.9664344926369822, 0.9664344926369822, 0.9664344926369822, 0.9669127490991593, 0.9669127490991593, 0.9669127490991593, 0.4809249551491176, 0.4809249551491176, 0.4809249551491176, 0.381198758978869, 0.381198758978869, 0.381198758978869, 0.4499010319843153, 0.4499010319843153, 0.4499010319843153, 0.22892518091355063, 0.22892518091355063, 0.22892518091355063, 0.34123535300604135, 0.34123535300604135, 0.34123535300604135, 0.5799851114176129, 0.5799851114176129, 0.5799851114176129, 0.1849152896424051, 0.1849152896424051, 0.1849152896424051, 0.19924263104079132, 0.19924263104079132, 0.19924263104079132, 0.20189845444467014, 0.20189845444467014, 0.20189845444467014, 0.20065255954836325, 0.20065255954836325, 0.20065255954836325, 0.20645213818714414, 0.20645213818714414, 0.20645213818714414, 0.2773852551144542, 0.2773852551144542, 0.2773852551144542, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009276971444445503, 0.009276971444445503, 0.009276971444445503, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13424530492748454, 0.13424530492748454, 0.13424530492748454, 0.07246933037597503, 0.07246933037597503, 0.07246933037597503, 0.05935711813078959, 0.05935711813078959, 0.05935711813078959, 0.09718621301452535, 0.09718621301452535, 0.09718621301452535, 0.20305128132981864, 0.20305128132981864, 0.20305128132981864, 0.19957406396786914, 0.19957406396786914, 0.19957406396786914, 0.21114453592582605, 0.21114453592582605, 0.21114453592582605, 0.07192848085974524, 0.07192848085974524, 0.07192848085974524, 0.04819853840646682, 0.04819853840646682, 0.04819853840646682, 0.506508612037883, 0.506508612037883, 0.506508612037883, 0.5315264833704825, 0.5315264833704825, 0.5315264833704825, 0.5454444998279665, 0.5454444998279665, 0.5454444998279665, 0.1542285447578986, 0.1542285447578986, 0.1542285447578986, 0.13838098087062245, 0.13838098087062245, 0.13838098087062245, 0.1479813297919369, 0.1479813297919369, 0.1479813297919369, 0.22620411904081872, 0.22620411904081872, 0.22620411904081872, 0.18943620230263836, 0.18943620230263836, 0.18943620230263836, 0.2406011927270867, 0.2406011927270867, 0.2406011927270867, 0.3145623362286636, 0.3145623362286636, 0.3145623362286636, 0.30139931992256386, 0.30139931992256386, 0.30139931992256386, 0.34971961216555214, 0.34971961216555214, 0.34971961216555214, 0.2651611526671369, 0.2651611526671369, 0.2651611526671369, 0.1901514513158865, 0.1901514513158865, 0.1901514513158865, 0.1861991243467792, 0.1861991243467792, 0.1861991243467792, 0.23709502782132308, 0.23709502782132308, 0.23709502782132308, 0.20991667084713395, 0.20991667084713395, 0.20991667084713395, 0.20958368171964992, 0.20958368171964992, 0.20958368171964992, 0.18424053209318325, 0.18424053209318325, 0.18424053209318325, 0.21491642673721467, 0.21491642673721467, 0.21491642673721467, 0.21822573123467892, 0.21822573123467892, 0.21822573123467892, 0.8225744088283806, 0.8225744088283806, 0.8225744088283806, 0.16037301786489666, 0.16037301786489666, 0.16037301786489666, 0.8150792628245911, 0.8150792628245911, 0.8150792628245911, 0.3502913548206792, 0.3502913548206792, 0.3502913548206792, 0.4248871669251957, 0.4248871669251957, 0.4248871669251957, 0.1666428131710812, 0.1666428131710812, 0.1666428131710812, 0.20087658088223004, 0.20087658088223004, 0.20087658088223004, 0.2012465456227901, 0.2012465456227901, 0.2012465456227901, 0.20919890235887784, 0.20919890235887784, 0.20919890235887784, 0.08979696304422491, 0.08979696304422491, 0.08979696304422491, 0.08178486598950929, 0.08178486598950929, 0.08178486598950929, 0.10961508076783155, 0.10961508076783155, 0.10961508076783155]}, "mutation_prompt": null}
{"id": "58187d2a-bd28-4363-b65e-cfa24129e19b", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 1.5 + evaluations/self.budget * 1.2  # Adjusted cognitive coefficient dynamics\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced the cognitive coefficient dynamics to boost exploration at early stages and exploitation at later stages.", "configspace": "", "generation": 74, "fitness": 0.34118121094905857, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.28.", "error": "", "parent_id": "6b596f42-7aa7-4ca8-b036-b493807f160f", "metadata": {"aucs": [0.8661957598423304, 0.8661957598423304, 0.8661957598423304, 0.8683212418369242, 0.8683212418369242, 0.8683212418369242, 0.8809347949086314, 0.8809347949086314, 0.8809347949086314, 0.5296997133668748, 0.5296997133668748, 0.5296997133668748, 0.6834928906766067, 0.6834928906766067, 0.6834928906766067, 0.585469456266009, 0.585469456266009, 0.585469456266009, 0.21332510820618056, 0.21332510820618056, 0.21332510820618056, 0.15431491481104764, 0.15431491481104764, 0.15431491481104764, 0.1356989250908449, 0.1356989250908449, 0.1356989250908449, 0.14884933615035656, 0.14884933615035656, 0.14884933615035656, 0.09184138566243638, 0.09184138566243638, 0.09184138566243638, 0.12772252828640285, 0.12772252828640285, 0.12772252828640285, 0.9708201088782159, 0.9708201088782159, 0.9708201088782159, 0.9669221025402288, 0.9669221025402288, 0.9669221025402288, 0.9683352787608122, 0.9683352787608122, 0.9683352787608122, 0.7150217780957182, 0.7150217780957182, 0.7150217780957182, 0.6603524138414523, 0.6603524138414523, 0.6603524138414523, 0.6711674767012006, 0.6711674767012006, 0.6711674767012006, 0.3668836743535435, 0.3668836743535435, 0.3668836743535435, 0.77931167204328, 0.77931167204328, 0.77931167204328, 0.23470959127350755, 0.23470959127350755, 0.23470959127350755, 0.21561649032918662, 0.21561649032918662, 0.21561649032918662, 0.20539397775053514, 0.20539397775053514, 0.20539397775053514, 0.2090618251224854, 0.2090618251224854, 0.2090618251224854, 0.26394150679376494, 0.26394150679376494, 0.26394150679376494, 0.21087152320474511, 0.21087152320474511, 0.21087152320474511, 0.20573971047816875, 0.20573971047816875, 0.20573971047816875, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06082638967555709, 0.06082638967555709, 0.06082638967555709, 0.0062396781849749505, 0.0062396781849749505, 0.0062396781849749505, 0.12738113196403011, 0.12738113196403011, 0.12738113196403011, 0.0651857522249456, 0.0651857522249456, 0.0651857522249456, 0.07099568318811655, 0.07099568318811655, 0.07099568318811655, 0.06479764660130971, 0.06479764660130971, 0.06479764660130971, 0.18200651996398287, 0.18200651996398287, 0.18200651996398287, 0.1673944563091222, 0.1673944563091222, 0.1673944563091222, 0.13871058372415068, 0.13871058372415068, 0.13871058372415068, 0.12504360793557767, 0.12504360793557767, 0.12504360793557767, 0.28632021563301524, 0.28632021563301524, 0.28632021563301524, 0.5463058919898964, 0.5463058919898964, 0.5463058919898964, 0.61296178121293, 0.61296178121293, 0.61296178121293, 0.5934801703105972, 0.5934801703105972, 0.5934801703105972, 0.11676841826812723, 0.11676841826812723, 0.11676841826812723, 0.12787868402216607, 0.12787868402216607, 0.12787868402216607, 0.14952735153509344, 0.14952735153509344, 0.14952735153509344, 0.1836629163562694, 0.1836629163562694, 0.1836629163562694, 0.18263801667732538, 0.18263801667732538, 0.18263801667732538, 0.26294933422327327, 0.26294933422327327, 0.26294933422327327, 0.3927490568699459, 0.3927490568699459, 0.3927490568699459, 0.49037921481021396, 0.49037921481021396, 0.49037921481021396, 0.5322568562785719, 0.5322568562785719, 0.5322568562785719, 0.298536751321712, 0.298536751321712, 0.298536751321712, 0.26555501184832975, 0.26555501184832975, 0.26555501184832975, 0.228719691933991, 0.228719691933991, 0.228719691933991, 0.22914172482978024, 0.22914172482978024, 0.22914172482978024, 0.23464929629813958, 0.23464929629813958, 0.23464929629813958, 0.22626087821063323, 0.22626087821063323, 0.22626087821063323, 0.22116850585275838, 0.22116850585275838, 0.22116850585275838, 0.20010171121084797, 0.20010171121084797, 0.20010171121084797, 0.2019073914929974, 0.2019073914929974, 0.2019073914929974, 0.8647568202682899, 0.8647568202682899, 0.8647568202682899, 0.877103179875555, 0.877103179875555, 0.877103179875555, 0.1935619014764819, 0.1935619014764819, 0.1935619014764819, 0.8415070010688837, 0.8415070010688837, 0.8415070010688837, 0.1678782377640966, 0.1678782377640966, 0.1678782377640966, 0.16582631034230344, 0.16582631034230344, 0.16582631034230344, 0.17972361408758986, 0.17972361408758986, 0.17972361408758986, 0.22442742246441882, 0.22442742246441882, 0.22442742246441882, 0.21826252053328743, 0.21826252053328743, 0.21826252053328743, 0.08980344300422871, 0.08980344300422871, 0.08980344300422871, 0.08832329704651676, 0.08832329704651676, 0.08832329704651676, 0.13125793417069032, 0.13125793417069032, 0.13125793417069032]}, "mutation_prompt": null}
{"id": "510dea2b-97b7-4eaf-8d24-ba40d501d5e0", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.5  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 1.5 + evaluations/self.budget * 1.2  # Adjusted cognitive coefficient dynamics\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                self.w = 0.5 + 0.2 * (1 - evaluations/self.budget)  # Adaptive inertia weight dynamics\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Introduced adaptive inertia weight dynamics to balance exploration and exploitation effectively.", "configspace": "", "generation": 75, "fitness": 0.30129627719559277, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.24.", "error": "", "parent_id": "58187d2a-bd28-4363-b65e-cfa24129e19b", "metadata": {"aucs": [0.758655396275433, 0.758655396275433, 0.758655396275433, 0.7715516213171226, 0.7715516213171226, 0.7715516213171226, 0.729473949006961, 0.729473949006961, 0.729473949006961, 0.3144146447063405, 0.3144146447063405, 0.3144146447063405, 0.36123057177562257, 0.36123057177562257, 0.36123057177562257, 0.4863413123089666, 0.4863413123089666, 0.4863413123089666, 0.15953908646512305, 0.15953908646512305, 0.15953908646512305, 0.1380224582762557, 0.1380224582762557, 0.1380224582762557, 0.11915147324882291, 0.11915147324882291, 0.11915147324882291, 0.12293832736840227, 0.12293832736840227, 0.12293832736840227, 0.10066690265971523, 0.10066690265971523, 0.10066690265971523, 0.1261985878267987, 0.1261985878267987, 0.1261985878267987, 0.9739218697799829, 0.9739218697799829, 0.9739218697799829, 0.9724984089530713, 0.9724984089530713, 0.9724984089530713, 0.9679453853757272, 0.9679453853757272, 0.9679453853757272, 0.4742479051994969, 0.4742479051994969, 0.4742479051994969, 0.5142672364563408, 0.5142672364563408, 0.5142672364563408, 0.42252588394812185, 0.42252588394812185, 0.42252588394812185, 0.5034347232698773, 0.5034347232698773, 0.5034347232698773, 0.7638211643534223, 0.7638211643534223, 0.7638211643534223, 0.746974150413068, 0.746974150413068, 0.746974150413068, 0.3081076911826799, 0.3081076911826799, 0.3081076911826799, 0.18296269581671143, 0.18296269581671143, 0.18296269581671143, 0.14841672211540424, 0.14841672211540424, 0.14841672211540424, 0.20055818642643009, 0.20055818642643009, 0.20055818642643009, 0.19372123541661956, 0.19372123541661956, 0.19372123541661956, 0.19362752966281416, 0.19362752966281416, 0.19362752966281416, 0.0048437967435563944, 0.0048437967435563944, 0.0048437967435563944, 0.02609754653830698, 0.02609754653830698, 0.02609754653830698, 0.05901722077640115, 0.05901722077640115, 0.05901722077640115, 0.07560041204558987, 0.07560041204558987, 0.07560041204558987, 0.0787406890810406, 0.0787406890810406, 0.0787406890810406, 0.10688916735422516, 0.10688916735422516, 0.10688916735422516, 0.13249356325171213, 0.13249356325171213, 0.13249356325171213, 0.14615452351995495, 0.14615452351995495, 0.14615452351995495, 0.15844144102248814, 0.15844144102248814, 0.15844144102248814, 0.24221489989754041, 0.24221489989754041, 0.24221489989754041, 0.1656634906885256, 0.1656634906885256, 0.1656634906885256, 0.09142417746592213, 0.09142417746592213, 0.09142417746592213, 0.513486339104924, 0.513486339104924, 0.513486339104924, 0.5272187791476934, 0.5272187791476934, 0.5272187791476934, 0.49374110606291355, 0.49374110606291355, 0.49374110606291355, 0.16254005393561877, 0.16254005393561877, 0.16254005393561877, 0.16405492519123277, 0.16405492519123277, 0.16405492519123277, 0.12602225899462172, 0.12602225899462172, 0.12602225899462172, 0.1584394731586286, 0.1584394731586286, 0.1584394731586286, 0.178555659642347, 0.178555659642347, 0.178555659642347, 0.2125733998026158, 0.2125733998026158, 0.2125733998026158, 0.3507659139260383, 0.3507659139260383, 0.3507659139260383, 0.36804231598071646, 0.36804231598071646, 0.36804231598071646, 0.3490617368899057, 0.3490617368899057, 0.3490617368899057, 0.2962510000329508, 0.2962510000329508, 0.2962510000329508, 0.25836342804022583, 0.25836342804022583, 0.25836342804022583, 0.19543955790875478, 0.19543955790875478, 0.19543955790875478, 0.21740562848199374, 0.21740562848199374, 0.21740562848199374, 0.23956937045636317, 0.23956937045636317, 0.23956937045636317, 0.21701227879935336, 0.21701227879935336, 0.21701227879935336, 0.28798233378478455, 0.28798233378478455, 0.28798233378478455, 0.2266861402675403, 0.2266861402675403, 0.2266861402675403, 0.18774001629638937, 0.18774001629638937, 0.18774001629638937, 0.7991689349381117, 0.7991689349381117, 0.7991689349381117, 0.17370886178418277, 0.17370886178418277, 0.17370886178418277, 0.19156436878698135, 0.19156436878698135, 0.19156436878698135, 0.1671740930834127, 0.1671740930834127, 0.1671740930834127, 0.48626050900241, 0.48626050900241, 0.48626050900241, 0.20710582426762492, 0.20710582426762492, 0.20710582426762492, 0.1958902736709116, 0.1958902736709116, 0.1958902736709116, 0.19789319343343537, 0.19789319343343537, 0.19789319343343537, 0.2087889585035394, 0.2087889585035394, 0.2087889585035394, 0.08852921615080611, 0.08852921615080611, 0.08852921615080611, 0.09498945250836444, 0.09498945250836444, 0.09498945250836444, 0.10851050805669149, 0.10851050805669149, 0.10851050805669149]}, "mutation_prompt": null}
{"id": "0881dd46-5fee-4599-81ed-157c912dd85d", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.6  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 1.5 + evaluations/self.budget * 1.2  # Adjusted cognitive coefficient dynamics\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Slightly increased the mutation step size in the Differential Evolution phase to enhance exploration.", "configspace": "", "generation": 76, "fitness": 0.3416334025101016, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.28.", "error": "", "parent_id": "58187d2a-bd28-4363-b65e-cfa24129e19b", "metadata": {"aucs": [0.8709485359933328, 0.8709485359933328, 0.8709485359933328, 0.8612502498275036, 0.8612502498275036, 0.8612502498275036, 0.8674098965166026, 0.8674098965166026, 0.8674098965166026, 0.6757937824730048, 0.6757937824730048, 0.6757937824730048, 0.6240628908961487, 0.6240628908961487, 0.6240628908961487, 0.7072849070392755, 0.7072849070392755, 0.7072849070392755, 0.1501580557978921, 0.1501580557978921, 0.1501580557978921, 0.15323784951443542, 0.15323784951443542, 0.15323784951443542, 0.1714724910987857, 0.1714724910987857, 0.1714724910987857, 0.13857027436191094, 0.13857027436191094, 0.13857027436191094, 0.10421525284941124, 0.10421525284941124, 0.10421525284941124, 0.11897148438568894, 0.11897148438568894, 0.11897148438568894, 0.9619460144617804, 0.9619460144617804, 0.9619460144617804, 0.9658051783693526, 0.9658051783693526, 0.9658051783693526, 0.965023004026735, 0.965023004026735, 0.965023004026735, 0.7301518438784514, 0.7301518438784514, 0.7301518438784514, 0.6044505991158391, 0.6044505991158391, 0.6044505991158391, 0.6502203892062611, 0.6502203892062611, 0.6502203892062611, 0.5218338208719937, 0.5218338208719937, 0.5218338208719937, 0.21114038488048215, 0.21114038488048215, 0.21114038488048215, 0.7796855936176428, 0.7796855936176428, 0.7796855936176428, 0.20388881996669728, 0.20388881996669728, 0.20388881996669728, 0.20989421696900734, 0.20989421696900734, 0.20989421696900734, 0.20029299142712165, 0.20029299142712165, 0.20029299142712165, 0.21883611878757292, 0.21883611878757292, 0.21883611878757292, 0.23640954106376344, 0.23640954106376344, 0.23640954106376344, 0.2460339838986959, 0.2460339838986959, 0.2460339838986959, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09453612449262416, 0.09453612449262416, 0.09453612449262416, 0.05631466975739896, 0.05631466975739896, 0.05631466975739896, 0.09669727435184416, 0.09669727435184416, 0.09669727435184416, 0.048697232575701355, 0.048697232575701355, 0.048697232575701355, 0.07706918810571772, 0.07706918810571772, 0.07706918810571772, 0.12610170879292693, 0.12610170879292693, 0.12610170879292693, 0.20366699810014688, 0.20366699810014688, 0.20366699810014688, 0.1444682572041498, 0.1444682572041498, 0.1444682572041498, 0.14161145458847035, 0.14161145458847035, 0.14161145458847035, 0.5570732964790465, 0.5570732964790465, 0.5570732964790465, 0.6020536534950285, 0.6020536534950285, 0.6020536534950285, 0.5807734980721561, 0.5807734980721561, 0.5807734980721561, 0.10215602930546086, 0.10215602930546086, 0.10215602930546086, 0.14085904889950596, 0.14085904889950596, 0.14085904889950596, 0.16812329384729963, 0.16812329384729963, 0.16812329384729963, 0.2096554575780768, 0.2096554575780768, 0.2096554575780768, 0.2774125873443247, 0.2774125873443247, 0.2774125873443247, 0.17509939089198356, 0.17509939089198356, 0.17509939089198356, 0.5200680032370801, 0.5200680032370801, 0.5200680032370801, 0.26412810677487886, 0.26412810677487886, 0.26412810677487886, 0.45255929556770347, 0.45255929556770347, 0.45255929556770347, 0.24448101412404322, 0.24448101412404322, 0.24448101412404322, 0.2828742519704006, 0.2828742519704006, 0.2828742519704006, 0.18084761911461733, 0.18084761911461733, 0.18084761911461733, 0.21675508842310032, 0.21675508842310032, 0.21675508842310032, 0.21381152517650137, 0.21381152517650137, 0.21381152517650137, 0.23785799404856445, 0.23785799404856445, 0.23785799404856445, 0.6393722468743508, 0.6393722468743508, 0.6393722468743508, 0.2368467340897118, 0.2368467340897118, 0.2368467340897118, 0.21540700756166176, 0.21540700756166176, 0.21540700756166176, 0.8720292880602885, 0.8720292880602885, 0.8720292880602885, 0.8239647544296788, 0.8239647544296788, 0.8239647544296788, 0.8679095189941786, 0.8679095189941786, 0.8679095189941786, 0.16681431052718654, 0.16681431052718654, 0.16681431052718654, 0.16809795745161138, 0.16809795745161138, 0.16809795745161138, 0.16691636505396978, 0.16691636505396978, 0.16691636505396978, 0.1803178030166378, 0.1803178030166378, 0.1803178030166378, 0.17511641105035491, 0.17511641105035491, 0.17511641105035491, 0.20215782384611714, 0.20215782384611714, 0.20215782384611714, 0.07965694861769856, 0.07965694861769856, 0.07965694861769856, 0.10700462939427235, 0.10700462939427235, 0.10700462939427235, 0.13095294814545433, 0.13095294814545433, 0.13095294814545433]}, "mutation_prompt": null}
{"id": "44e99d6d-51a4-4978-94a7-9a61fab2dcbd", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.6  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r = np.random.choice(self.pop_size, 3, replace=False)\n                while i in r:\n                    r = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[r]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 1.5 + evaluations/self.budget * 1.2  # Adjusted cognitive coefficient dynamics\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced exploration by refining the selection of base vectors in the Differential Evolution phase for better diversity.", "configspace": "", "generation": 77, "fitness": 0.3416334025101016, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.28.", "error": "", "parent_id": "0881dd46-5fee-4599-81ed-157c912dd85d", "metadata": {"aucs": [0.8709485359933328, 0.8709485359933328, 0.8709485359933328, 0.8612502498275036, 0.8612502498275036, 0.8612502498275036, 0.8674098965166026, 0.8674098965166026, 0.8674098965166026, 0.6757937824730048, 0.6757937824730048, 0.6757937824730048, 0.6240628908961487, 0.6240628908961487, 0.6240628908961487, 0.7072849070392755, 0.7072849070392755, 0.7072849070392755, 0.1501580557978921, 0.1501580557978921, 0.1501580557978921, 0.15323784951443542, 0.15323784951443542, 0.15323784951443542, 0.1714724910987857, 0.1714724910987857, 0.1714724910987857, 0.13857027436191094, 0.13857027436191094, 0.13857027436191094, 0.10421525284941124, 0.10421525284941124, 0.10421525284941124, 0.11897148438568894, 0.11897148438568894, 0.11897148438568894, 0.9619460144617804, 0.9619460144617804, 0.9619460144617804, 0.9658051783693526, 0.9658051783693526, 0.9658051783693526, 0.965023004026735, 0.965023004026735, 0.965023004026735, 0.7301518438784514, 0.7301518438784514, 0.7301518438784514, 0.6044505991158391, 0.6044505991158391, 0.6044505991158391, 0.6502203892062611, 0.6502203892062611, 0.6502203892062611, 0.5218338208719937, 0.5218338208719937, 0.5218338208719937, 0.21114038488048215, 0.21114038488048215, 0.21114038488048215, 0.7796855936176428, 0.7796855936176428, 0.7796855936176428, 0.20388881996669728, 0.20388881996669728, 0.20388881996669728, 0.20989421696900734, 0.20989421696900734, 0.20989421696900734, 0.20029299142712165, 0.20029299142712165, 0.20029299142712165, 0.21883611878757292, 0.21883611878757292, 0.21883611878757292, 0.23640954106376344, 0.23640954106376344, 0.23640954106376344, 0.2460339838986959, 0.2460339838986959, 0.2460339838986959, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09453612449262416, 0.09453612449262416, 0.09453612449262416, 0.05631466975739896, 0.05631466975739896, 0.05631466975739896, 0.09669727435184416, 0.09669727435184416, 0.09669727435184416, 0.048697232575701355, 0.048697232575701355, 0.048697232575701355, 0.07706918810571772, 0.07706918810571772, 0.07706918810571772, 0.12610170879292693, 0.12610170879292693, 0.12610170879292693, 0.20366699810014688, 0.20366699810014688, 0.20366699810014688, 0.1444682572041498, 0.1444682572041498, 0.1444682572041498, 0.14161145458847035, 0.14161145458847035, 0.14161145458847035, 0.5570732964790465, 0.5570732964790465, 0.5570732964790465, 0.6020536534950285, 0.6020536534950285, 0.6020536534950285, 0.5807734980721561, 0.5807734980721561, 0.5807734980721561, 0.10215602930546086, 0.10215602930546086, 0.10215602930546086, 0.14085904889950596, 0.14085904889950596, 0.14085904889950596, 0.16812329384729963, 0.16812329384729963, 0.16812329384729963, 0.2096554575780768, 0.2096554575780768, 0.2096554575780768, 0.2774125873443247, 0.2774125873443247, 0.2774125873443247, 0.17509939089198356, 0.17509939089198356, 0.17509939089198356, 0.5200680032370801, 0.5200680032370801, 0.5200680032370801, 0.26412810677487886, 0.26412810677487886, 0.26412810677487886, 0.45255929556770347, 0.45255929556770347, 0.45255929556770347, 0.24448101412404322, 0.24448101412404322, 0.24448101412404322, 0.2828742519704006, 0.2828742519704006, 0.2828742519704006, 0.18084761911461733, 0.18084761911461733, 0.18084761911461733, 0.21675508842310032, 0.21675508842310032, 0.21675508842310032, 0.21381152517650137, 0.21381152517650137, 0.21381152517650137, 0.23785799404856445, 0.23785799404856445, 0.23785799404856445, 0.6393722468743508, 0.6393722468743508, 0.6393722468743508, 0.2368467340897118, 0.2368467340897118, 0.2368467340897118, 0.21540700756166176, 0.21540700756166176, 0.21540700756166176, 0.8720292880602885, 0.8720292880602885, 0.8720292880602885, 0.8239647544296788, 0.8239647544296788, 0.8239647544296788, 0.8679095189941786, 0.8679095189941786, 0.8679095189941786, 0.16681431052718654, 0.16681431052718654, 0.16681431052718654, 0.16809795745161138, 0.16809795745161138, 0.16809795745161138, 0.16691636505396978, 0.16691636505396978, 0.16691636505396978, 0.1803178030166378, 0.1803178030166378, 0.1803178030166378, 0.17511641105035491, 0.17511641105035491, 0.17511641105035491, 0.20215782384611714, 0.20215782384611714, 0.20215782384611714, 0.07965694861769856, 0.07965694861769856, 0.07965694861769856, 0.10700462939427235, 0.10700462939427235, 0.10700462939427235, 0.13095294814545433, 0.13095294814545433, 0.13095294814545433]}, "mutation_prompt": null}
{"id": "d1ea02f5-3a2d-4a1a-9f3c-ba7e6da1b4e7", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.6  # Differential Evolution parameter\n        self.CR = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 2.0 + evaluations/self.budget * 1.2  # Adjusted cognitive coefficient dynamics\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Increased the cognitive coefficient adjustment to enhance individual learning during PSO.", "configspace": "", "generation": 78, "fitness": 0.3164261425969735, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.26.", "error": "", "parent_id": "0881dd46-5fee-4599-81ed-157c912dd85d", "metadata": {"aucs": [0.8628771449614627, 0.8628771449614627, 0.8628771449614627, 0.8483100556930662, 0.8483100556930662, 0.8483100556930662, 0.851437363748894, 0.851437363748894, 0.851437363748894, 0.6036227659948004, 0.6036227659948004, 0.6036227659948004, 0.43730401325501866, 0.43730401325501866, 0.43730401325501866, 0.6680184253785507, 0.6680184253785507, 0.6680184253785507, 0.176982628897554, 0.176982628897554, 0.176982628897554, 0.3416126909615862, 0.3416126909615862, 0.3416126909615862, 0.12488964996845786, 0.12488964996845786, 0.12488964996845786, 0.14772593690945102, 0.14772593690945102, 0.14772593690945102, 0.13845186958989086, 0.13845186958989086, 0.13845186958989086, 0.1270034492916977, 0.1270034492916977, 0.1270034492916977, 0.9666365180288132, 0.9666365180288132, 0.9666365180288132, 0.9679347376315173, 0.9679347376315173, 0.9679347376315173, 0.9670425016406985, 0.9670425016406985, 0.9670425016406985, 0.5531491682344157, 0.5531491682344157, 0.5531491682344157, 0.4572794407933568, 0.4572794407933568, 0.4572794407933568, 0.5963320170271654, 0.5963320170271654, 0.5963320170271654, 0.37443981829088446, 0.37443981829088446, 0.37443981829088446, 0.7099418368620913, 0.7099418368620913, 0.7099418368620913, 0.8431070254110253, 0.8431070254110253, 0.8431070254110253, 0.1801020956835806, 0.1801020956835806, 0.1801020956835806, 0.19234018611888581, 0.19234018611888581, 0.19234018611888581, 0.18868224727129446, 0.18868224727129446, 0.18868224727129446, 0.20628126269045965, 0.20628126269045965, 0.20628126269045965, 0.19541992750478365, 0.19541992750478365, 0.19541992750478365, 0.13088477926550912, 0.13088477926550912, 0.13088477926550912, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08005548660602202, 0.08005548660602202, 0.08005548660602202, 0.06331025001207724, 0.06331025001207724, 0.06331025001207724, 0.0818346840514298, 0.0818346840514298, 0.0818346840514298, 0.22331973679021855, 0.22331973679021855, 0.22331973679021855, 0.19332954140105663, 0.19332954140105663, 0.19332954140105663, 0.17236524217537386, 0.17236524217537386, 0.17236524217537386, 0.14162035311632915, 0.14162035311632915, 0.14162035311632915, 0.08593649780139445, 0.08593649780139445, 0.08593649780139445, 0.1501773011484101, 0.1501773011484101, 0.1501773011484101, 0.5230894722592525, 0.5230894722592525, 0.5230894722592525, 0.5424994711129099, 0.5424994711129099, 0.5424994711129099, 0.5520300971515626, 0.5520300971515626, 0.5520300971515626, 0.20414628243486688, 0.20414628243486688, 0.20414628243486688, 0.12693949312272101, 0.12693949312272101, 0.12693949312272101, 0.12316587528684719, 0.12316587528684719, 0.12316587528684719, 0.2334714616248722, 0.2334714616248722, 0.2334714616248722, 0.2576499481313641, 0.2576499481313641, 0.2576499481313641, 0.24460028736867567, 0.24460028736867567, 0.24460028736867567, 0.37080336090419064, 0.37080336090419064, 0.37080336090419064, 0.3331783241270363, 0.3331783241270363, 0.3331783241270363, 0.49641332293615614, 0.49641332293615614, 0.49641332293615614, 0.29333119652631034, 0.29333119652631034, 0.29333119652631034, 0.18880324687502192, 0.18880324687502192, 0.18880324687502192, 0.19556674377645344, 0.19556674377645344, 0.19556674377645344, 0.2279778473386851, 0.2279778473386851, 0.2279778473386851, 0.21241359389444348, 0.21241359389444348, 0.21241359389444348, 0.19844900362419382, 0.19844900362419382, 0.19844900362419382, 0.23558902363862655, 0.23558902363862655, 0.23558902363862655, 0.21386937761702285, 0.21386937761702285, 0.21386937761702285, 0.21545304679496136, 0.21545304679496136, 0.21545304679496136, 0.1761352346408699, 0.1761352346408699, 0.1761352346408699, 0.16228740723340507, 0.16228740723340507, 0.16228740723340507, 0.7768637132280004, 0.7768637132280004, 0.7768637132280004, 0.16577550145837394, 0.16577550145837394, 0.16577550145837394, 0.42320988398630954, 0.42320988398630954, 0.42320988398630954, 0.16665719832964465, 0.16665719832964465, 0.16665719832964465, 0.2045273573890407, 0.2045273573890407, 0.2045273573890407, 0.18149042245235492, 0.18149042245235492, 0.18149042245235492, 0.2052704108266018, 0.2052704108266018, 0.2052704108266018, 0.08625254919235181, 0.08625254919235181, 0.08625254919235181, 0.08418661495636948, 0.08418661495636948, 0.08418661495636948, 0.11052684653537692, 0.11052684653537692, 0.11052684653537692]}, "mutation_prompt": null}
{"id": "5986b421-8cd5-474e-98d3-00c739ad7bba", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.6  # Differential Evolution parameter\n        self.CR = 0.95  # Crossover probability, increased from 0.9 to 0.95\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 1.5 + evaluations/self.budget * 1.2  # Adjusted cognitive coefficient dynamics\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Slightly increase the crossover probability (CR) to enhance exploration during the Differential Evolution phase.", "configspace": "", "generation": 79, "fitness": 0.34684745952790186, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.", "error": "", "parent_id": "0881dd46-5fee-4599-81ed-157c912dd85d", "metadata": {"aucs": [0.8704091151136393, 0.8704091151136393, 0.8704091151136393, 0.8633906258654734, 0.8633906258654734, 0.8633906258654734, 0.871978773890632, 0.871978773890632, 0.871978773890632, 0.7225804004261842, 0.7225804004261842, 0.7225804004261842, 0.665222637386911, 0.665222637386911, 0.665222637386911, 0.6313987890515101, 0.6313987890515101, 0.6313987890515101, 0.4246583051579462, 0.4246583051579462, 0.4246583051579462, 0.1501412690914482, 0.1501412690914482, 0.1501412690914482, 0.1521114346037632, 0.1521114346037632, 0.1521114346037632, 0.10635414929886133, 0.10635414929886133, 0.10635414929886133, 0.12696601666274687, 0.12696601666274687, 0.12696601666274687, 0.09606895636392276, 0.09606895636392276, 0.09606895636392276, 0.9615259777762317, 0.9615259777762317, 0.9615259777762317, 0.9682958190802436, 0.9682958190802436, 0.9682958190802436, 0.9651384941290244, 0.9651384941290244, 0.9651384941290244, 0.7057389531512631, 0.7057389531512631, 0.7057389531512631, 0.664224059032549, 0.664224059032549, 0.664224059032549, 0.6732094741217906, 0.6732094741217906, 0.6732094741217906, 0.7572053257851998, 0.7572053257851998, 0.7572053257851998, 0.27767395917536497, 0.27767395917536497, 0.27767395917536497, 0.7974785533393529, 0.7974785533393529, 0.7974785533393529, 0.20666143958095007, 0.20666143958095007, 0.20666143958095007, 0.22007992260215392, 0.22007992260215392, 0.22007992260215392, 0.2537576614984425, 0.2537576614984425, 0.2537576614984425, 0.2258605748468906, 0.2258605748468906, 0.2258605748468906, 0.21040218517430975, 0.21040218517430975, 0.21040218517430975, 0.20923538412072107, 0.20923538412072107, 0.20923538412072107, 0.04217032245935115, 0.04217032245935115, 0.04217032245935115, 0.012243649261256762, 0.012243649261256762, 0.012243649261256762, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0944609904138608, 0.0944609904138608, 0.0944609904138608, 0.06713725815905813, 0.06713725815905813, 0.06713725815905813, 0.11113455504086234, 0.11113455504086234, 0.11113455504086234, 0.05540690541581683, 0.05540690541581683, 0.05540690541581683, 0.10342371349569457, 0.10342371349569457, 0.10342371349569457, 0.15097582468619364, 0.15097582468619364, 0.15097582468619364, 0.21025159012811478, 0.21025159012811478, 0.21025159012811478, 0.07609469487065346, 0.07609469487065346, 0.07609469487065346, 0.19754689331394093, 0.19754689331394093, 0.19754689331394093, 0.5479884746117532, 0.5479884746117532, 0.5479884746117532, 0.5626319563140794, 0.5626319563140794, 0.5626319563140794, 0.6227482797217598, 0.6227482797217598, 0.6227482797217598, 0.13348947662233246, 0.13348947662233246, 0.13348947662233246, 0.1305206456697381, 0.1305206456697381, 0.1305206456697381, 0.13545226022214252, 0.13545226022214252, 0.13545226022214252, 0.16165807077944772, 0.16165807077944772, 0.16165807077944772, 0.2225596958338979, 0.2225596958338979, 0.2225596958338979, 0.17410918284550025, 0.17410918284550025, 0.17410918284550025, 0.2829736583746434, 0.2829736583746434, 0.2829736583746434, 0.2818223720470725, 0.2818223720470725, 0.2818223720470725, 0.5564256634377089, 0.5564256634377089, 0.5564256634377089, 0.2968775644635582, 0.2968775644635582, 0.2968775644635582, 0.2758366986051831, 0.2758366986051831, 0.2758366986051831, 0.1784758482580302, 0.1784758482580302, 0.1784758482580302, 0.20552725746387646, 0.20552725746387646, 0.20552725746387646, 0.21867513980692643, 0.21867513980692643, 0.21867513980692643, 0.19885122965384194, 0.19885122965384194, 0.19885122965384194, 0.19298554313912142, 0.19298554313912142, 0.19298554313912142, 0.21591246578948764, 0.21591246578948764, 0.21591246578948764, 0.20276786757595444, 0.20276786757595444, 0.20276786757595444, 0.8585748230231292, 0.8585748230231292, 0.8585748230231292, 0.8214340758069951, 0.8214340758069951, 0.8214340758069951, 0.8880431259355561, 0.8880431259355561, 0.8880431259355561, 0.16742201708633542, 0.16742201708633542, 0.16742201708633542, 0.49326399345678973, 0.49326399345678973, 0.49326399345678973, 0.1657984972526958, 0.1657984972526958, 0.1657984972526958, 0.18351864738641543, 0.18351864738641543, 0.18351864738641543, 0.21430722128929525, 0.21430722128929525, 0.21430722128929525, 0.19673375853862607, 0.19673375853862607, 0.19673375853862607, 0.08512306122448643, 0.08512306122448643, 0.08512306122448643, 0.08598871462758562, 0.08598871462758562, 0.08598871462758562, 0.11580514557263488, 0.11580514557263488, 0.11580514557263488]}, "mutation_prompt": null}
{"id": "0993474f-2c19-4b04-bb6f-3566215b700f", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.6  # Differential Evolution parameter\n        self.CR = 0.95  # Crossover probability, increased from 0.9 to 0.95\n        self.w = 0.4  # Inertia weight for PSO, decreased from 0.5 to 0.4\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 1.5 + evaluations/self.budget * 1.2  # Adjusted cognitive coefficient dynamics\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Slightly decrease the inertia weight to enhance convergence speed during the Particle Swarm Optimization phase.", "configspace": "", "generation": 80, "fitness": 0.3465615393446556, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.", "error": "", "parent_id": "5986b421-8cd5-474e-98d3-00c739ad7bba", "metadata": {"aucs": [0.8872746094081826, 0.8872746094081826, 0.8872746094081826, 0.8839824073496763, 0.8839824073496763, 0.8839824073496763, 0.881244068039745, 0.881244068039745, 0.881244068039745, 0.7541651384367973, 0.7541651384367973, 0.7541651384367973, 0.7530822900076428, 0.7530822900076428, 0.7530822900076428, 0.7376020965777116, 0.7376020965777116, 0.7376020965777116, 0.1787221824261116, 0.1787221824261116, 0.1787221824261116, 0.1490827175476046, 0.1490827175476046, 0.1490827175476046, 0.17614357680937953, 0.17614357680937953, 0.17614357680937953, 0.10699870314440973, 0.10699870314440973, 0.10699870314440973, 0.1147215026502818, 0.1147215026502818, 0.1147215026502818, 0.11243987843183201, 0.11243987843183201, 0.11243987843183201, 0.9556730741577514, 0.9556730741577514, 0.9556730741577514, 0.9622444003389673, 0.9622444003389673, 0.9622444003389673, 0.9554617466102139, 0.9554617466102139, 0.9554617466102139, 0.7750309720906856, 0.7750309720906856, 0.7750309720906856, 0.6952312510694387, 0.6952312510694387, 0.6952312510694387, 0.7404723823898972, 0.7404723823898972, 0.7404723823898972, 0.2219323211017633, 0.2219323211017633, 0.2219323211017633, 0.21078758418550825, 0.21078758418550825, 0.21078758418550825, 0.8330149262810276, 0.8330149262810276, 0.8330149262810276, 0.2335616409108614, 0.2335616409108614, 0.2335616409108614, 0.24050344306778182, 0.24050344306778182, 0.24050344306778182, 0.2175870823815379, 0.2175870823815379, 0.2175870823815379, 0.2167729077067132, 0.2167729077067132, 0.2167729077067132, 0.20789224651975557, 0.20789224651975557, 0.20789224651975557, 0.2202506919974173, 0.2202506919974173, 0.2202506919974173, 0.1173502225434877, 0.1173502225434877, 0.1173502225434877, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005173734549508868, 0.005173734549508868, 0.005173734549508868, 0.06902504310588398, 0.06902504310588398, 0.06902504310588398, 0.08279440000351646, 0.08279440000351646, 0.08279440000351646, 0.08418410058456627, 0.08418410058456627, 0.08418410058456627, 0.07262357727090352, 0.07262357727090352, 0.07262357727090352, 0.11939494992860367, 0.11939494992860367, 0.11939494992860367, 0.10278719216782373, 0.10278719216782373, 0.10278719216782373, 0.16348676712976284, 0.16348676712976284, 0.16348676712976284, 0.11383600616277634, 0.11383600616277634, 0.11383600616277634, 0.13475011905249268, 0.13475011905249268, 0.13475011905249268, 0.5371972747157615, 0.5371972747157615, 0.5371972747157615, 0.5715750112973449, 0.5715750112973449, 0.5715750112973449, 0.6105446447777788, 0.6105446447777788, 0.6105446447777788, 0.10451714819143598, 0.10451714819143598, 0.10451714819143598, 0.15552015507429695, 0.15552015507429695, 0.15552015507429695, 0.12263494046955425, 0.12263494046955425, 0.12263494046955425, 0.19286355540203493, 0.19286355540203493, 0.19286355540203493, 0.17352621241071065, 0.17352621241071065, 0.17352621241071065, 0.20737073226888836, 0.20737073226888836, 0.20737073226888836, 0.3562037835870083, 0.3562037835870083, 0.3562037835870083, 0.4903568039909827, 0.4903568039909827, 0.4903568039909827, 0.5583849927350047, 0.5583849927350047, 0.5583849927350047, 0.21761558908516476, 0.21761558908516476, 0.21761558908516476, 0.40255496176622274, 0.40255496176622274, 0.40255496176622274, 0.2112153287204458, 0.2112153287204458, 0.2112153287204458, 0.22955269911197895, 0.22955269911197895, 0.22955269911197895, 0.2196353609354995, 0.2196353609354995, 0.2196353609354995, 0.2478462209576473, 0.2478462209576473, 0.2478462209576473, 0.1835394993849816, 0.1835394993849816, 0.1835394993849816, 0.22208825111721153, 0.22208825111721153, 0.22208825111721153, 0.22141918206762323, 0.22141918206762323, 0.22141918206762323, 0.8976262056021751, 0.8976262056021751, 0.8976262056021751, 0.1643438882406565, 0.1643438882406565, 0.1643438882406565, 0.8833520430534968, 0.8833520430534968, 0.8833520430534968, 0.7431817413481112, 0.7431817413481112, 0.7431817413481112, 0.506301790157072, 0.506301790157072, 0.506301790157072, 0.16656639391578043, 0.16656639391578043, 0.16656639391578043, 0.18655223373980556, 0.18655223373980556, 0.18655223373980556, 0.19290032237637156, 0.19290032237637156, 0.19290032237637156, 0.196982395814432, 0.196982395814432, 0.196982395814432, 0.09094105751029691, 0.09094105751029691, 0.09094105751029691, 0.08994011139208036, 0.08994011139208036, 0.08994011139208036, 0.11019834745933199, 0.11019834745933199, 0.11019834745933199]}, "mutation_prompt": null}
{"id": "b8b18bd4-7ccb-4eeb-9e19-608c8bf70e18", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.6  # Differential Evolution parameter\n        self.CR = 0.97  # Crossover probability, increased from 0.95 to 0.97\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 1.5 + evaluations/self.budget * 1.2  # Adjusted cognitive coefficient dynamics\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Further increase crossover probability (CR) to 0.97 for enhanced exploration in Differential Evolution.", "configspace": "", "generation": 81, "fitness": 0.3570452946459688, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.29.", "error": "", "parent_id": "5986b421-8cd5-474e-98d3-00c739ad7bba", "metadata": {"aucs": [0.8676665283668262, 0.8676665283668262, 0.8676665283668262, 0.8456805155552082, 0.8456805155552082, 0.8456805155552082, 0.8673925517693419, 0.8673925517693419, 0.8673925517693419, 0.6048641124260673, 0.6048641124260673, 0.6048641124260673, 0.6770953398725752, 0.6770953398725752, 0.6770953398725752, 0.6493260218375922, 0.6493260218375922, 0.6493260218375922, 0.13368685460462237, 0.13368685460462237, 0.13368685460462237, 0.14622798831108064, 0.14622798831108064, 0.14622798831108064, 0.14369570927666642, 0.14369570927666642, 0.14369570927666642, 0.1238340277022677, 0.1238340277022677, 0.1238340277022677, 0.11215272448826363, 0.11215272448826363, 0.11215272448826363, 0.11804397742605321, 0.11804397742605321, 0.11804397742605321, 0.9674668240617131, 0.9674668240617131, 0.9674668240617131, 0.9736273658736956, 0.9736273658736956, 0.9736273658736956, 0.9647963782403199, 0.9647963782403199, 0.9647963782403199, 0.6725676871292758, 0.6725676871292758, 0.6725676871292758, 0.5526948300901936, 0.5526948300901936, 0.5526948300901936, 0.7078960014194504, 0.7078960014194504, 0.7078960014194504, 0.7615933340981615, 0.7615933340981615, 0.7615933340981615, 0.8121881028700573, 0.8121881028700573, 0.8121881028700573, 0.7941937921021927, 0.7941937921021927, 0.7941937921021927, 0.24598038969980884, 0.24598038969980884, 0.24598038969980884, 0.2414499228016007, 0.2414499228016007, 0.2414499228016007, 0.20709699999176723, 0.20709699999176723, 0.20709699999176723, 0.21941434433844098, 0.21941434433844098, 0.21941434433844098, 0.23467866084128564, 0.23467866084128564, 0.23467866084128564, 0.250754755892575, 0.250754755892575, 0.250754755892575, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00874974536784734, 0.00874974536784734, 0.00874974536784734, 0.030971614469281983, 0.030971614469281983, 0.030971614469281983, 0.07844058860689651, 0.07844058860689651, 0.07844058860689651, 0.06961144329127567, 0.06961144329127567, 0.06961144329127567, 0.0760031709153387, 0.0760031709153387, 0.0760031709153387, 0.06706207463422709, 0.06706207463422709, 0.06706207463422709, 0.15340740560829202, 0.15340740560829202, 0.15340740560829202, 0.14525346884496326, 0.14525346884496326, 0.14525346884496326, 0.17758312816699418, 0.17758312816699418, 0.17758312816699418, 0.15816645323770862, 0.15816645323770862, 0.15816645323770862, 0.10464754430949741, 0.10464754430949741, 0.10464754430949741, 0.547920761238148, 0.547920761238148, 0.547920761238148, 0.5634473212525704, 0.5634473212525704, 0.5634473212525704, 0.5565382182711432, 0.5565382182711432, 0.5565382182711432, 0.12850089835208123, 0.12850089835208123, 0.12850089835208123, 0.14755516527832058, 0.14755516527832058, 0.14755516527832058, 0.1550406334169453, 0.1550406334169453, 0.1550406334169453, 0.14965095990699284, 0.14965095990699284, 0.14965095990699284, 0.1822849426315546, 0.1822849426315546, 0.1822849426315546, 0.19076145040901682, 0.19076145040901682, 0.19076145040901682, 0.5025895753481617, 0.5025895753481617, 0.5025895753481617, 0.3886781365425501, 0.3886781365425501, 0.3886781365425501, 0.5601832454856777, 0.5601832454856777, 0.5601832454856777, 0.23627918355280375, 0.23627918355280375, 0.23627918355280375, 0.30735998371886986, 0.30735998371886986, 0.30735998371886986, 0.3093285911623981, 0.3093285911623981, 0.3093285911623981, 0.21097211491525036, 0.21097211491525036, 0.21097211491525036, 0.2272728216760479, 0.2272728216760479, 0.2272728216760479, 0.1966252365612774, 0.1966252365612774, 0.1966252365612774, 0.22385500840481865, 0.22385500840481865, 0.22385500840481865, 0.20340174781860254, 0.20340174781860254, 0.20340174781860254, 0.22371616499359648, 0.22371616499359648, 0.22371616499359648, 0.8695189710613291, 0.8695189710613291, 0.8695189710613291, 0.831355157062807, 0.831355157062807, 0.831355157062807, 0.8995961021246518, 0.8995961021246518, 0.8995961021246518, 0.1674201195692866, 0.1674201195692866, 0.1674201195692866, 0.748333158946563, 0.748333158946563, 0.748333158946563, 0.16666554270442901, 0.16666554270442901, 0.16666554270442901, 0.19463855341888048, 0.19463855341888048, 0.19463855341888048, 0.18893232444472496, 0.18893232444472496, 0.18893232444472496, 0.18497056831931302, 0.18497056831931302, 0.18497056831931302, 0.08052178369150809, 0.08052178369150809, 0.08052178369150809, 0.0876704485249935, 0.0876704485249935, 0.0876704485249935, 0.10961394516501333, 0.10961394516501333, 0.10961394516501333]}, "mutation_prompt": null}
{"id": "4fd1d8b0-d432-4367-8f63-85e8ea1f45cd", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.7  # Differential Evolution parameter, increased from 0.6 to 0.7\n        self.CR = 0.97  # Crossover probability, increased from 0.95 to 0.97\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 1.5 + evaluations/self.budget * 1.2  # Adjusted cognitive coefficient dynamics\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Further optimize exploration by increasing the mutation factor F to 0.7 in Differential Evolution.", "configspace": "", "generation": 82, "fitness": 0.35160506681326836, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.28.", "error": "", "parent_id": "b8b18bd4-7ccb-4eeb-9e19-608c8bf70e18", "metadata": {"aucs": [0.8660559157806937, 0.8660559157806937, 0.8660559157806937, 0.8778594875479423, 0.8778594875479423, 0.8778594875479423, 0.8691199846192574, 0.8691199846192574, 0.8691199846192574, 0.6412739561803067, 0.6412739561803067, 0.6412739561803067, 0.6917572915521075, 0.6917572915521075, 0.6917572915521075, 0.7065846547996602, 0.7065846547996602, 0.7065846547996602, 0.17314125656193302, 0.17314125656193302, 0.17314125656193302, 0.14584878831194636, 0.14584878831194636, 0.14584878831194636, 0.3087599119943396, 0.3087599119943396, 0.3087599119943396, 0.13662072041554296, 0.13662072041554296, 0.13662072041554296, 0.1462410289326963, 0.1462410289326963, 0.1462410289326963, 0.11118665678843609, 0.11118665678843609, 0.11118665678843609, 0.9678445367208653, 0.9678445367208653, 0.9678445367208653, 0.9728557721012743, 0.9728557721012743, 0.9728557721012743, 0.964844969429068, 0.964844969429068, 0.964844969429068, 0.6508839516001819, 0.6508839516001819, 0.6508839516001819, 0.69709479067612, 0.69709479067612, 0.69709479067612, 0.606513656133362, 0.606513656133362, 0.606513656133362, 0.7159530579781659, 0.7159530579781659, 0.7159530579781659, 0.21049632302054344, 0.21049632302054344, 0.21049632302054344, 0.8275328676148967, 0.8275328676148967, 0.8275328676148967, 0.22610365750688988, 0.22610365750688988, 0.22610365750688988, 0.23283620730687105, 0.23283620730687105, 0.23283620730687105, 0.21588370881053598, 0.21588370881053598, 0.21588370881053598, 0.21874316480652778, 0.21874316480652778, 0.21874316480652778, 0.23342251129917146, 0.23342251129917146, 0.23342251129917146, 0.2580628784227402, 0.2580628784227402, 0.2580628784227402, 0.05036230005975506, 0.05036230005975506, 0.05036230005975506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06016929820316108, 0.06016929820316108, 0.06016929820316108, 0.17619702864934572, 0.17619702864934572, 0.17619702864934572, 0.07115766665382839, 0.07115766665382839, 0.07115766665382839, 0.09394091953912798, 0.09394091953912798, 0.09394091953912798, 0.04789450349695268, 0.04789450349695268, 0.04789450349695268, 0.10467690151205311, 0.10467690151205311, 0.10467690151205311, 0.08348432264842542, 0.08348432264842542, 0.08348432264842542, 0.1284385897537399, 0.1284385897537399, 0.1284385897537399, 0.08494244215603086, 0.08494244215603086, 0.08494244215603086, 0.12545058448166524, 0.12545058448166524, 0.12545058448166524, 0.5214310436694249, 0.5214310436694249, 0.5214310436694249, 0.606032908580461, 0.606032908580461, 0.606032908580461, 0.5472077265223156, 0.5472077265223156, 0.5472077265223156, 0.13080439418767842, 0.13080439418767842, 0.13080439418767842, 0.12983255195414878, 0.12983255195414878, 0.12983255195414878, 0.12283697812989214, 0.12283697812989214, 0.12283697812989214, 0.28649846423977066, 0.28649846423977066, 0.28649846423977066, 0.15356000794294178, 0.15356000794294178, 0.15356000794294178, 0.24187574175318605, 0.24187574175318605, 0.24187574175318605, 0.4118481662015151, 0.4118481662015151, 0.4118481662015151, 0.24293546692020362, 0.24293546692020362, 0.24293546692020362, 0.5582610173626672, 0.5582610173626672, 0.5582610173626672, 0.24290267632605833, 0.24290267632605833, 0.24290267632605833, 0.36299416770598414, 0.36299416770598414, 0.36299416770598414, 0.3851206865527026, 0.3851206865527026, 0.3851206865527026, 0.20765869221964983, 0.20765869221964983, 0.20765869221964983, 0.2798862938874278, 0.2798862938874278, 0.2798862938874278, 0.2158448795819129, 0.2158448795819129, 0.2158448795819129, 0.18241912414581152, 0.18241912414581152, 0.18241912414581152, 0.19794950450446247, 0.19794950450446247, 0.19794950450446247, 0.6013510534659994, 0.6013510534659994, 0.6013510534659994, 0.874901625388377, 0.874901625388377, 0.874901625388377, 0.19145192770252806, 0.19145192770252806, 0.19145192770252806, 0.8582167045500066, 0.8582167045500066, 0.8582167045500066, 0.8585021137487044, 0.8585021137487044, 0.8585021137487044, 0.16653813085791858, 0.16653813085791858, 0.16653813085791858, 0.16785232631159364, 0.16785232631159364, 0.16785232631159364, 0.2071769090037231, 0.2071769090037231, 0.2071769090037231, 0.1872308583556902, 0.1872308583556902, 0.1872308583556902, 0.19748153706761729, 0.19748153706761729, 0.19748153706761729, 0.09249127734156559, 0.09249127734156559, 0.09249127734156559, 0.09225858956737887, 0.09225858956737887, 0.09225858956737887, 0.0918750007398419, 0.0918750007398419, 0.0918750007398419]}, "mutation_prompt": null}
{"id": "0b6f9680-30ec-4734-a36a-0a2681125022", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.6  # Differential Evolution parameter\n        self.CR = 0.97  # Crossover probability, increased from 0.95 to 0.97\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 1.5 + evaluations/self.budget * 1.2  # Adjusted cognitive coefficient dynamics\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                self.w = 0.9 - 0.4 * (evaluations / self.budget)  # Dynamic inertia weight\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Introduce dynamic adjustment of inertia weight to balance exploration and exploitation in Particle Swarm Optimization.", "configspace": "", "generation": 83, "fitness": 0.20020366044184235, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.20.", "error": "", "parent_id": "b8b18bd4-7ccb-4eeb-9e19-608c8bf70e18", "metadata": {"aucs": [0.41066234259825696, 0.41066234259825696, 0.41066234259825696, 0.4505011342709756, 0.4505011342709756, 0.4505011342709756, 0.4322986284101352, 0.4322986284101352, 0.4322986284101352, 0.06281137338699538, 0.06281137338699538, 0.06281137338699538, 0.06351158863706619, 0.06351158863706619, 0.06351158863706619, 0.001931960225047491, 0.001931960225047491, 0.001931960225047491, 0.08419047918947375, 0.08419047918947375, 0.08419047918947375, 0.1095326527016055, 0.1095326527016055, 0.1095326527016055, 0.10602478515237401, 0.10602478515237401, 0.10602478515237401, 0.07713712972382258, 0.07713712972382258, 0.07713712972382258, 0.06790761878405704, 0.06790761878405704, 0.06790761878405704, 0.08563525893373913, 0.08563525893373913, 0.08563525893373913, 0.9799891612268984, 0.9799891612268984, 0.9799891612268984, 0.9756144212693711, 0.9756144212693711, 0.9756144212693711, 0.9672880412569445, 0.9672880412569445, 0.9672880412569445, 0.24755262242428888, 0.24755262242428888, 0.24755262242428888, 0.22227112551846973, 0.22227112551846973, 0.22227112551846973, 0.25704186802918116, 0.25704186802918116, 0.25704186802918116, 0.18653099754532676, 0.18653099754532676, 0.18653099754532676, 0.2745242181857197, 0.2745242181857197, 0.2745242181857197, 0.21907339796200664, 0.21907339796200664, 0.21907339796200664, 0.12253685165379269, 0.12253685165379269, 0.12253685165379269, 0.1037066724820872, 0.1037066724820872, 0.1037066724820872, 0.12427986662161361, 0.12427986662161361, 0.12427986662161361, 0.13170031357521494, 0.13170031357521494, 0.13170031357521494, 0.08301363811462348, 0.08301363811462348, 0.08301363811462348, 0.08800671001990212, 0.08800671001990212, 0.08800671001990212, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.038373842485863285, 0.038373842485863285, 0.038373842485863285, 0.08045826574114201, 0.08045826574114201, 0.08045826574114201, 0.07797814978829354, 0.07797814978829354, 0.07797814978829354, 0.00021511552428510328, 0.00021511552428510328, 0.00021511552428510328, 0.028939694807742278, 0.028939694807742278, 0.028939694807742278, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06202503335176024, 0.06202503335176024, 0.06202503335176024, 0.03276043689420172, 0.03276043689420172, 0.03276043689420172, 0.05674237666464521, 0.05674237666464521, 0.05674237666464521, 0.34969471306764, 0.34969471306764, 0.34969471306764, 0.4051807044723439, 0.4051807044723439, 0.4051807044723439, 0.36319745132692327, 0.36319745132692327, 0.36319745132692327, 0.09228655412897957, 0.09228655412897957, 0.09228655412897957, 0.09147072302596049, 0.09147072302596049, 0.09147072302596049, 0.115132022257459, 0.115132022257459, 0.115132022257459, 0.20351401588574958, 0.20351401588574958, 0.20351401588574958, 0.1387063671619626, 0.1387063671619626, 0.1387063671619626, 0.18235940697740438, 0.18235940697740438, 0.18235940697740438, 0.22885777622174897, 0.22885777622174897, 0.22885777622174897, 0.218885395847513, 0.218885395847513, 0.218885395847513, 0.2858531313602557, 0.2858531313602557, 0.2858531313602557, 0.16596269474513647, 0.16596269474513647, 0.16596269474513647, 0.18534446488317957, 0.18534446488317957, 0.18534446488317957, 0.17471917087309285, 0.17471917087309285, 0.17471917087309285, 0.20616828941874987, 0.20616828941874987, 0.20616828941874987, 0.21272542742383072, 0.21272542742383072, 0.21272542742383072, 0.1912590459924719, 0.1912590459924719, 0.1912590459924719, 0.17387495221908833, 0.17387495221908833, 0.17387495221908833, 0.17217204626952676, 0.17217204626952676, 0.17217204626952676, 0.2122502291027426, 0.2122502291027426, 0.2122502291027426, 0.5256639976826345, 0.5256639976826345, 0.5256639976826345, 0.17069863114227024, 0.17069863114227024, 0.17069863114227024, 0.4976625834042364, 0.4976625834042364, 0.4976625834042364, 0.2830875759649034, 0.2830875759649034, 0.2830875759649034, 0.3103818622221257, 0.3103818622221257, 0.3103818622221257, 0.15739171518481088, 0.15739171518481088, 0.15739171518481088, 0.17665355249579584, 0.17665355249579584, 0.17665355249579584, 0.17322820073414347, 0.17322820073414347, 0.17322820073414347, 0.18794555662747991, 0.18794555662747991, 0.18794555662747991, 0.08237596470943831, 0.08237596470943831, 0.08237596470943831, 0.08179437215273488, 0.08179437215273488, 0.08179437215273488, 0.08499718367339282, 0.08499718367339282, 0.08499718367339282]}, "mutation_prompt": null}
{"id": "5740d129-77a6-4933-b5b3-fa616bb1323b", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.6  # Differential Evolution parameter\n        self.CR = 0.97  # Crossover probability, increased from 0.95 to 0.97\n        self.w = 0.55  # Inertia weight for PSO, increased from 0.5 to 0.55\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.c1 = 1.5 + evaluations/self.budget * 1.2\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Slightly increase the inertia weight for PSO to 0.55 to enhance exploration.", "configspace": "", "generation": 84, "fitness": 0.3340107655462923, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.27.", "error": "", "parent_id": "b8b18bd4-7ccb-4eeb-9e19-608c8bf70e18", "metadata": {"aucs": [0.8475031517771844, 0.8475031517771844, 0.8475031517771844, 0.8585073091435949, 0.8585073091435949, 0.8585073091435949, 0.8639865322810322, 0.8639865322810322, 0.8639865322810322, 0.5910299430660713, 0.5910299430660713, 0.5910299430660713, 0.5663814319945901, 0.5663814319945901, 0.5663814319945901, 0.5669556923006706, 0.5669556923006706, 0.5669556923006706, 0.17216211268746007, 0.17216211268746007, 0.17216211268746007, 0.15083207840666457, 0.15083207840666457, 0.15083207840666457, 0.15175263672239558, 0.15175263672239558, 0.15175263672239558, 0.13648244224788197, 0.13648244224788197, 0.13648244224788197, 0.11274397101898448, 0.11274397101898448, 0.11274397101898448, 0.11123430564485881, 0.11123430564485881, 0.11123430564485881, 0.9686994815958914, 0.9686994815958914, 0.9686994815958914, 0.9705262845073548, 0.9705262845073548, 0.9705262845073548, 0.964701805876064, 0.964701805876064, 0.964701805876064, 0.6279235218386423, 0.6279235218386423, 0.6279235218386423, 0.6042578512394703, 0.6042578512394703, 0.6042578512394703, 0.6030227801355914, 0.6030227801355914, 0.6030227801355914, 0.21426000393366285, 0.21426000393366285, 0.21426000393366285, 0.21812530228684268, 0.21812530228684268, 0.21812530228684268, 0.7200482355196012, 0.7200482355196012, 0.7200482355196012, 0.2021084918096231, 0.2021084918096231, 0.2021084918096231, 0.20221025811784876, 0.20221025811784876, 0.20221025811784876, 0.18885535672257492, 0.18885535672257492, 0.18885535672257492, 0.2437692511520798, 0.2437692511520798, 0.2437692511520798, 0.22580535620195608, 0.22580535620195608, 0.22580535620195608, 0.24662607561772065, 0.24662607561772065, 0.24662607561772065, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.014182242069056938, 0.014182242069056938, 0.014182242069056938, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15634696593685726, 0.15634696593685726, 0.15634696593685726, 0.08571269634911183, 0.08571269634911183, 0.08571269634911183, 0.10137271828278882, 0.10137271828278882, 0.10137271828278882, 0.11231127175480726, 0.11231127175480726, 0.11231127175480726, 0.15547748869507583, 0.15547748869507583, 0.15547748869507583, 0.12740219837701494, 0.12740219837701494, 0.12740219837701494, 0.11084688265903753, 0.11084688265903753, 0.11084688265903753, 0.10189458178307975, 0.10189458178307975, 0.10189458178307975, 0.15535187941712558, 0.15535187941712558, 0.15535187941712558, 0.5803806473954212, 0.5803806473954212, 0.5803806473954212, 0.5470495942968286, 0.5470495942968286, 0.5470495942968286, 0.5688894188339185, 0.5688894188339185, 0.5688894188339185, 0.10701335150194846, 0.10701335150194846, 0.10701335150194846, 0.09213803906392659, 0.09213803906392659, 0.09213803906392659, 0.1357122385278965, 0.1357122385278965, 0.1357122385278965, 0.16768759124363497, 0.16768759124363497, 0.16768759124363497, 0.1463400401939512, 0.1463400401939512, 0.1463400401939512, 0.23691726584128892, 0.23691726584128892, 0.23691726584128892, 0.41601442980968795, 0.41601442980968795, 0.41601442980968795, 0.35291872542087244, 0.35291872542087244, 0.35291872542087244, 0.5009562776600701, 0.5009562776600701, 0.5009562776600701, 0.25080550136029967, 0.25080550136029967, 0.25080550136029967, 0.2290708263302581, 0.2290708263302581, 0.2290708263302581, 0.20400753118590154, 0.20400753118590154, 0.20400753118590154, 0.23626588740581023, 0.23626588740581023, 0.23626588740581023, 0.2972299160741326, 0.2972299160741326, 0.2972299160741326, 0.22395854942508853, 0.22395854942508853, 0.22395854942508853, 0.1867425289017588, 0.1867425289017588, 0.1867425289017588, 0.1863657505819596, 0.1863657505819596, 0.1863657505819596, 0.24685885571111743, 0.24685885571111743, 0.24685885571111743, 0.8738593487684904, 0.8738593487684904, 0.8738593487684904, 0.6781588110340773, 0.6781588110340773, 0.6781588110340773, 0.8792538703394455, 0.8792538703394455, 0.8792538703394455, 0.6135928950108094, 0.6135928950108094, 0.6135928950108094, 0.5292854792625235, 0.5292854792625235, 0.5292854792625235, 0.16496859540808895, 0.16496859540808895, 0.16496859540808895, 0.18919852786861335, 0.18919852786861335, 0.18919852786861335, 0.20951773592082046, 0.20951773592082046, 0.20951773592082046, 0.253816114457015, 0.253816114457015, 0.253816114457015, 0.08926731014740397, 0.08926731014740397, 0.08926731014740397, 0.08441494759518009, 0.08441494759518009, 0.08441494759518009, 0.11850792758453699, 0.11850792758453699, 0.11850792758453699]}, "mutation_prompt": null}
{"id": "9afb16f4-cb52-40ff-b331-60fdbf4c8784", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.75  # Differential Evolution parameter, increased from 0.6 to 0.75\n        self.CR = 0.97  # Crossover probability, increased from 0.95 to 0.97\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 1.5 + evaluations/self.budget * 1.2  # Adjusted cognitive coefficient dynamics\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Increase mutation factor in Differential Evolution to 0.75 for improved diversity and exploitation balance.", "configspace": "", "generation": 85, "fitness": 0.3380904117088346, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.28.", "error": "", "parent_id": "b8b18bd4-7ccb-4eeb-9e19-608c8bf70e18", "metadata": {"aucs": [0.8726481035504206, 0.8726481035504206, 0.8726481035504206, 0.8656409589517507, 0.8656409589517507, 0.8656409589517507, 0.8805125834838513, 0.8805125834838513, 0.8805125834838513, 0.6618337074082717, 0.6618337074082717, 0.6618337074082717, 0.6835830467429981, 0.6835830467429981, 0.6835830467429981, 0.6695541406310772, 0.6695541406310772, 0.6695541406310772, 0.10927936453987641, 0.10927936453987641, 0.10927936453987641, 0.13955314474277436, 0.13955314474277436, 0.13955314474277436, 0.405558535427313, 0.405558535427313, 0.405558535427313, 0.1583126134163052, 0.1583126134163052, 0.1583126134163052, 0.15283586838977348, 0.15283586838977348, 0.15283586838977348, 0.13848477406212678, 0.13848477406212678, 0.13848477406212678, 0.9727707657937069, 0.9727707657937069, 0.9727707657937069, 0.9743929496241729, 0.9743929496241729, 0.9743929496241729, 0.9668716782575228, 0.9668716782575228, 0.9668716782575228, 0.707704905023044, 0.707704905023044, 0.707704905023044, 0.6195086462919128, 0.6195086462919128, 0.6195086462919128, 0.6359818809366979, 0.6359818809366979, 0.6359818809366979, 0.5874017331051433, 0.5874017331051433, 0.5874017331051433, 0.35683750617195287, 0.35683750617195287, 0.35683750617195287, 0.8226056664512422, 0.8226056664512422, 0.8226056664512422, 0.23394771596694908, 0.23394771596694908, 0.23394771596694908, 0.24190223895409801, 0.24190223895409801, 0.24190223895409801, 0.13058711280548996, 0.13058711280548996, 0.13058711280548996, 0.2847979154605308, 0.2847979154605308, 0.2847979154605308, 0.2012507444666699, 0.2012507444666699, 0.2012507444666699, 0.22500916229708212, 0.22500916229708212, 0.22500916229708212, 0.008521584345468014, 0.008521584345468014, 0.008521584345468014, 0.020332260528517665, 0.020332260528517665, 0.020332260528517665, 0.08417071101134721, 0.08417071101134721, 0.08417071101134721, 0.1061796962056234, 0.1061796962056234, 0.1061796962056234, 0.07539701717474423, 0.07539701717474423, 0.07539701717474423, 0.07646945292003549, 0.07646945292003549, 0.07646945292003549, 0.08090046882456703, 0.08090046882456703, 0.08090046882456703, 0.09426881086961314, 0.09426881086961314, 0.09426881086961314, 0.0689383499287789, 0.0689383499287789, 0.0689383499287789, 0.15929602304488522, 0.15929602304488522, 0.15929602304488522, 0.05268508903215152, 0.05268508903215152, 0.05268508903215152, 0.05604213751997922, 0.05604213751997922, 0.05604213751997922, 0.5778748353442935, 0.5778748353442935, 0.5778748353442935, 0.5707471696368118, 0.5707471696368118, 0.5707471696368118, 0.5380303459030756, 0.5380303459030756, 0.5380303459030756, 0.15333566400443865, 0.15333566400443865, 0.15333566400443865, 0.13308184153514035, 0.13308184153514035, 0.13308184153514035, 0.12778557535700164, 0.12778557535700164, 0.12778557535700164, 0.20381056086955684, 0.20381056086955684, 0.20381056086955684, 0.24788454030560803, 0.24788454030560803, 0.24788454030560803, 0.17413943571533796, 0.17413943571533796, 0.17413943571533796, 0.3871317338697924, 0.3871317338697924, 0.3871317338697924, 0.31033845576548724, 0.31033845576548724, 0.31033845576548724, 0.44780642768541434, 0.44780642768541434, 0.44780642768541434, 0.22060437270081157, 0.22060437270081157, 0.22060437270081157, 0.3255248712419804, 0.3255248712419804, 0.3255248712419804, 0.21568972759890126, 0.21568972759890126, 0.21568972759890126, 0.22436428271521391, 0.22436428271521391, 0.22436428271521391, 0.2129097372480977, 0.2129097372480977, 0.2129097372480977, 0.20789583184106997, 0.20789583184106997, 0.20789583184106997, 0.22511763695160658, 0.22511763695160658, 0.22511763695160658, 0.21829953099147192, 0.21829953099147192, 0.21829953099147192, 0.7338415733312886, 0.7338415733312886, 0.7338415733312886, 0.8785702489117968, 0.8785702489117968, 0.8785702489117968, 0.19566828549773363, 0.19566828549773363, 0.19566828549773363, 0.8619409203138213, 0.8619409203138213, 0.8619409203138213, 0.16740984745055199, 0.16740984745055199, 0.16740984745055199, 0.1658187659423329, 0.1658187659423329, 0.1658187659423329, 0.1681260919065133, 0.1681260919065133, 0.1681260919065133, 0.17679288875508103, 0.17679288875508103, 0.17679288875508103, 0.22693687746932056, 0.22693687746932056, 0.22693687746932056, 0.1983024317357639, 0.1983024317357639, 0.1983024317357639, 0.08804681479872545, 0.08804681479872545, 0.08804681479872545, 0.07941999457356475, 0.07941999457356475, 0.07941999457356475, 0.09669326071002105, 0.09669326071002105, 0.09669326071002105]}, "mutation_prompt": null}
{"id": "cbae8c9b-526a-470c-925c-f13ad9714a54", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.6  # Differential Evolution parameter\n        self.CR = 0.97  # Crossover probability, increased from 0.95 to 0.97\n        self.w = 0.8  # Inertia weight for PSO, increased from 0.5 to 0.8\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 1.5 + evaluations/self.budget * 1.2  # Adjusted cognitive coefficient dynamics\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Increase inertia weight (w) to 0.8 for better exploration in Particle Swarm Optimization.", "configspace": "", "generation": 86, "fitness": 0.19061719618993875, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.20.", "error": "", "parent_id": "b8b18bd4-7ccb-4eeb-9e19-608c8bf70e18", "metadata": {"aucs": [0.3619272920288229, 0.3619272920288229, 0.3619272920288229, 0.4039723665861471, 0.4039723665861471, 0.4039723665861471, 0.4554903749425798, 0.4554903749425798, 0.4554903749425798, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02460848592003695, 0.02460848592003695, 0.02460848592003695, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08500803186393224, 0.08500803186393224, 0.08500803186393224, 0.09433123897606166, 0.09433123897606166, 0.09433123897606166, 0.09855595805659834, 0.09855595805659834, 0.09855595805659834, 0.08637454534276279, 0.08637454534276279, 0.08637454534276279, 0.09827244366864762, 0.09827244366864762, 0.09827244366864762, 0.05693407527892336, 0.05693407527892336, 0.05693407527892336, 0.9741763414324087, 0.9741763414324087, 0.9741763414324087, 0.9754136363306767, 0.9754136363306767, 0.9754136363306767, 0.9616424301710438, 0.9616424301710438, 0.9616424301710438, 0.2952399856152088, 0.2952399856152088, 0.2952399856152088, 0.18761457895831557, 0.18761457895831557, 0.18761457895831557, 0.24563881536381116, 0.24563881536381116, 0.24563881536381116, 0.18613195457265463, 0.18613195457265463, 0.18613195457265463, 0.26427907719993005, 0.26427907719993005, 0.26427907719993005, 0.24192945613903905, 0.24192945613903905, 0.24192945613903905, 0.11572989203504969, 0.11572989203504969, 0.11572989203504969, 0.11018617421053367, 0.11018617421053367, 0.11018617421053367, 0.14628992362320092, 0.14628992362320092, 0.14628992362320092, 0.12093421997326737, 0.12093421997326737, 0.12093421997326737, 0.14002036224920555, 0.14002036224920555, 0.14002036224920555, 0.10326717433605936, 0.10326717433605936, 0.10326717433605936, 0.019781716024333984, 0.019781716024333984, 0.019781716024333984, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06118383389241755, 0.06118383389241755, 0.06118383389241755, 0.07490486419552522, 0.07490486419552522, 0.07490486419552522, 0.025680609006418886, 0.025680609006418886, 0.025680609006418886, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04587317827100068, 0.04587317827100068, 0.04587317827100068, 0.044060371222975125, 0.044060371222975125, 0.044060371222975125, 0.05195412363857632, 0.05195412363857632, 0.05195412363857632, 0.3728719741821145, 0.3728719741821145, 0.3728719741821145, 0.35421273111770346, 0.35421273111770346, 0.35421273111770346, 0.3636041699647402, 0.3636041699647402, 0.3636041699647402, 0.0683406040885437, 0.0683406040885437, 0.0683406040885437, 0.08233120721189002, 0.08233120721189002, 0.08233120721189002, 0.082833526031452, 0.082833526031452, 0.082833526031452, 0.14199126271048512, 0.14199126271048512, 0.14199126271048512, 0.1773102088788786, 0.1773102088788786, 0.1773102088788786, 0.16087090934051995, 0.16087090934051995, 0.16087090934051995, 0.22565473954705928, 0.22565473954705928, 0.22565473954705928, 0.2798008105590629, 0.2798008105590629, 0.2798008105590629, 0.2442304709627321, 0.2442304709627321, 0.2442304709627321, 0.1717584107096667, 0.1717584107096667, 0.1717584107096667, 0.16334380149876526, 0.16334380149876526, 0.16334380149876526, 0.18883643169411335, 0.18883643169411335, 0.18883643169411335, 0.20335685617491273, 0.20335685617491273, 0.20335685617491273, 0.19557826444342374, 0.19557826444342374, 0.19557826444342374, 0.24191643197726098, 0.24191643197726098, 0.24191643197726098, 0.23423171979517654, 0.23423171979517654, 0.23423171979517654, 0.18525602712577238, 0.18525602712577238, 0.18525602712577238, 0.1924505518237395, 0.1924505518237395, 0.1924505518237395, 0.2672323014224849, 0.2672323014224849, 0.2672323014224849, 0.1703824658623604, 0.1703824658623604, 0.1703824658623604, 0.33767042984673545, 0.33767042984673545, 0.33767042984673545, 0.269091402403432, 0.269091402403432, 0.269091402403432, 0.25842804757917903, 0.25842804757917903, 0.25842804757917903, 0.1592248985689606, 0.1592248985689606, 0.1592248985689606, 0.18824484491367288, 0.18824484491367288, 0.18824484491367288, 0.18020504346890176, 0.18020504346890176, 0.18020504346890176, 0.17823760247682707, 0.17823760247682707, 0.17823760247682707, 0.0730890126287781, 0.0730890126287781, 0.0730890126287781, 0.061305520307913475, 0.061305520307913475, 0.061305520307913475, 0.0924379152321686, 0.0924379152321686, 0.0924379152321686]}, "mutation_prompt": null}
{"id": "52b5b805-fb97-456b-9f1f-c4b6b990cc62", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.6  # Differential Evolution parameter\n        self.CR = 0.97  # Crossover probability, increased from 0.95 to 0.97\n        self.w = 0.4  # Inertia weight for PSO, decreased from 0.5 to 0.4\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 1.5 + evaluations/self.budget * 1.2  # Adjusted cognitive coefficient dynamics\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Decrease inertia weight (w) to 0.4 for improved convergence in Particle Swarm Optimization.", "configspace": "", "generation": 87, "fitness": 0.3623334319867504, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.29.", "error": "", "parent_id": "b8b18bd4-7ccb-4eeb-9e19-608c8bf70e18", "metadata": {"aucs": [0.8839670795450805, 0.8839670795450805, 0.8839670795450805, 0.8823146094144184, 0.8823146094144184, 0.8823146094144184, 0.8917987196224962, 0.8917987196224962, 0.8917987196224962, 0.744878800678962, 0.744878800678962, 0.744878800678962, 0.7679551547337575, 0.7679551547337575, 0.7679551547337575, 0.738947687558912, 0.738947687558912, 0.738947687558912, 0.16956195975036192, 0.16956195975036192, 0.16956195975036192, 0.14209733490480614, 0.14209733490480614, 0.14209733490480614, 0.5304966303697211, 0.5304966303697211, 0.5304966303697211, 0.10699842639837265, 0.10699842639837265, 0.10699842639837265, 0.1110875602921878, 0.1110875602921878, 0.1110875602921878, 0.10128936870634242, 0.10128936870634242, 0.10128936870634242, 0.9674849409319265, 0.9674849409319265, 0.9674849409319265, 0.966056748229467, 0.966056748229467, 0.966056748229467, 0.955699964569795, 0.955699964569795, 0.955699964569795, 0.7584342726830151, 0.7584342726830151, 0.7584342726830151, 0.7506826960673391, 0.7506826960673391, 0.7506826960673391, 0.731630647414635, 0.731630647414635, 0.731630647414635, 0.6901127195577001, 0.6901127195577001, 0.6901127195577001, 0.269446757785619, 0.269446757785619, 0.269446757785619, 0.7826609001122246, 0.7826609001122246, 0.7826609001122246, 0.22141121032981848, 0.22141121032981848, 0.22141121032981848, 0.21758094628706215, 0.21758094628706215, 0.21758094628706215, 0.24502712284545058, 0.24502712284545058, 0.24502712284545058, 0.22111830501155438, 0.22111830501155438, 0.22111830501155438, 0.22726195628108048, 0.22726195628108048, 0.22726195628108048, 0.25492431573717533, 0.25492431573717533, 0.25492431573717533, 0.06199689419589771, 0.06199689419589771, 0.06199689419589771, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00898004013338849, 0.00898004013338849, 0.00898004013338849, 0.08122152744115263, 0.08122152744115263, 0.08122152744115263, 0.0641937477482839, 0.0641937477482839, 0.0641937477482839, 0.07250582061660171, 0.07250582061660171, 0.07250582061660171, 0.07143064663235887, 0.07143064663235887, 0.07143064663235887, 0.1102084902246655, 0.1102084902246655, 0.1102084902246655, 0.14019148868427567, 0.14019148868427567, 0.14019148868427567, 0.20951649797101057, 0.20951649797101057, 0.20951649797101057, 0.10190916634845215, 0.10190916634845215, 0.10190916634845215, 0.08192949027457308, 0.08192949027457308, 0.08192949027457308, 0.5451105380098407, 0.5451105380098407, 0.5451105380098407, 0.5407305614184444, 0.5407305614184444, 0.5407305614184444, 0.597867463617721, 0.597867463617721, 0.597867463617721, 0.13109882119009075, 0.13109882119009075, 0.13109882119009075, 0.155734898840863, 0.155734898840863, 0.155734898840863, 0.13770072103550046, 0.13770072103550046, 0.13770072103550046, 0.21265011086685248, 0.21265011086685248, 0.21265011086685248, 0.2880048843300388, 0.2880048843300388, 0.2880048843300388, 0.2404978595023728, 0.2404978595023728, 0.2404978595023728, 0.3980520314152908, 0.3980520314152908, 0.3980520314152908, 0.3830665259738195, 0.3830665259738195, 0.3830665259738195, 0.3588075991780344, 0.3588075991780344, 0.3588075991780344, 0.22339580147918092, 0.22339580147918092, 0.22339580147918092, 0.2635331104816674, 0.2635331104816674, 0.2635331104816674, 0.2325445092648104, 0.2325445092648104, 0.2325445092648104, 0.22750510536850543, 0.22750510536850543, 0.22750510536850543, 0.22006646219097814, 0.22006646219097814, 0.22006646219097814, 0.23146463638196446, 0.23146463638196446, 0.23146463638196446, 0.2197803117663587, 0.2197803117663587, 0.2197803117663587, 0.22275136381793625, 0.22275136381793625, 0.22275136381793625, 0.2450953262099017, 0.2450953262099017, 0.2450953262099017, 0.9002577781208215, 0.9002577781208215, 0.9002577781208215, 0.8748758109816056, 0.8748758109816056, 0.8748758109816056, 0.8895422869228423, 0.8895422869228423, 0.8895422869228423, 0.7005561501490719, 0.7005561501490719, 0.7005561501490719, 0.2081462106477172, 0.2081462106477172, 0.2081462106477172, 0.16680092916414146, 0.16680092916414146, 0.16680092916414146, 0.20778670271900368, 0.20778670271900368, 0.20778670271900368, 0.21800326743909915, 0.21800326743909915, 0.21800326743909915, 0.18111835072510662, 0.18111835072510662, 0.18111835072510662, 0.0965420623655946, 0.0965420623655946, 0.0965420623655946, 0.10103307014952312, 0.10103307014952312, 0.10103307014952312, 0.13277519523138692, 0.13277519523138692, 0.13277519523138692]}, "mutation_prompt": null}
{"id": "45194136-dc88-4966-85ff-806ab7450603", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.6  # Differential Evolution parameter\n        self.CR = 0.97  # Crossover probability, increased from 0.95 to 0.97\n        self.w = 0.5  # Inertia weight for PSO, increased from 0.4 to 0.5\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 1.5 + evaluations/self.budget * 1.2  # Adjusted cognitive coefficient dynamics\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Improved AdaptiveHybridGA with increased inertia weight to enhance exploration capability.", "configspace": "", "generation": 88, "fitness": 0.3570452946459688, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.29.", "error": "", "parent_id": "52b5b805-fb97-456b-9f1f-c4b6b990cc62", "metadata": {"aucs": [0.8676665283668262, 0.8676665283668262, 0.8676665283668262, 0.8456805155552082, 0.8456805155552082, 0.8456805155552082, 0.8673925517693419, 0.8673925517693419, 0.8673925517693419, 0.6048641124260673, 0.6048641124260673, 0.6048641124260673, 0.6770953398725752, 0.6770953398725752, 0.6770953398725752, 0.6493260218375922, 0.6493260218375922, 0.6493260218375922, 0.13368685460462237, 0.13368685460462237, 0.13368685460462237, 0.14622798831108064, 0.14622798831108064, 0.14622798831108064, 0.14369570927666642, 0.14369570927666642, 0.14369570927666642, 0.1238340277022677, 0.1238340277022677, 0.1238340277022677, 0.11215272448826363, 0.11215272448826363, 0.11215272448826363, 0.11804397742605321, 0.11804397742605321, 0.11804397742605321, 0.9674668240617131, 0.9674668240617131, 0.9674668240617131, 0.9736273658736956, 0.9736273658736956, 0.9736273658736956, 0.9647963782403199, 0.9647963782403199, 0.9647963782403199, 0.6725676871292758, 0.6725676871292758, 0.6725676871292758, 0.5526948300901936, 0.5526948300901936, 0.5526948300901936, 0.7078960014194504, 0.7078960014194504, 0.7078960014194504, 0.7615933340981615, 0.7615933340981615, 0.7615933340981615, 0.8121881028700573, 0.8121881028700573, 0.8121881028700573, 0.7941937921021927, 0.7941937921021927, 0.7941937921021927, 0.24598038969980884, 0.24598038969980884, 0.24598038969980884, 0.2414499228016007, 0.2414499228016007, 0.2414499228016007, 0.20709699999176723, 0.20709699999176723, 0.20709699999176723, 0.21941434433844098, 0.21941434433844098, 0.21941434433844098, 0.23467866084128564, 0.23467866084128564, 0.23467866084128564, 0.250754755892575, 0.250754755892575, 0.250754755892575, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00874974536784734, 0.00874974536784734, 0.00874974536784734, 0.030971614469281983, 0.030971614469281983, 0.030971614469281983, 0.07844058860689651, 0.07844058860689651, 0.07844058860689651, 0.06961144329127567, 0.06961144329127567, 0.06961144329127567, 0.0760031709153387, 0.0760031709153387, 0.0760031709153387, 0.06706207463422709, 0.06706207463422709, 0.06706207463422709, 0.15340740560829202, 0.15340740560829202, 0.15340740560829202, 0.14525346884496326, 0.14525346884496326, 0.14525346884496326, 0.17758312816699418, 0.17758312816699418, 0.17758312816699418, 0.15816645323770862, 0.15816645323770862, 0.15816645323770862, 0.10464754430949741, 0.10464754430949741, 0.10464754430949741, 0.547920761238148, 0.547920761238148, 0.547920761238148, 0.5634473212525704, 0.5634473212525704, 0.5634473212525704, 0.5565382182711432, 0.5565382182711432, 0.5565382182711432, 0.12850089835208123, 0.12850089835208123, 0.12850089835208123, 0.14755516527832058, 0.14755516527832058, 0.14755516527832058, 0.1550406334169453, 0.1550406334169453, 0.1550406334169453, 0.14965095990699284, 0.14965095990699284, 0.14965095990699284, 0.1822849426315546, 0.1822849426315546, 0.1822849426315546, 0.19076145040901682, 0.19076145040901682, 0.19076145040901682, 0.5025895753481617, 0.5025895753481617, 0.5025895753481617, 0.3886781365425501, 0.3886781365425501, 0.3886781365425501, 0.5601832454856777, 0.5601832454856777, 0.5601832454856777, 0.23627918355280375, 0.23627918355280375, 0.23627918355280375, 0.30735998371886986, 0.30735998371886986, 0.30735998371886986, 0.3093285911623981, 0.3093285911623981, 0.3093285911623981, 0.21097211491525036, 0.21097211491525036, 0.21097211491525036, 0.2272728216760479, 0.2272728216760479, 0.2272728216760479, 0.1966252365612774, 0.1966252365612774, 0.1966252365612774, 0.22385500840481865, 0.22385500840481865, 0.22385500840481865, 0.20340174781860254, 0.20340174781860254, 0.20340174781860254, 0.22371616499359648, 0.22371616499359648, 0.22371616499359648, 0.8695189710613291, 0.8695189710613291, 0.8695189710613291, 0.831355157062807, 0.831355157062807, 0.831355157062807, 0.8995961021246518, 0.8995961021246518, 0.8995961021246518, 0.1674201195692866, 0.1674201195692866, 0.1674201195692866, 0.748333158946563, 0.748333158946563, 0.748333158946563, 0.16666554270442901, 0.16666554270442901, 0.16666554270442901, 0.19463855341888048, 0.19463855341888048, 0.19463855341888048, 0.18893232444472496, 0.18893232444472496, 0.18893232444472496, 0.18497056831931302, 0.18497056831931302, 0.18497056831931302, 0.08052178369150809, 0.08052178369150809, 0.08052178369150809, 0.0876704485249935, 0.0876704485249935, 0.0876704485249935, 0.10961394516501333, 0.10961394516501333, 0.10961394516501333]}, "mutation_prompt": null}
{"id": "a9af4694-8003-467d-a537-240d6db9affd", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.65  # Differential Evolution parameter, increased from 0.6 to 0.65\n        self.CR = 0.97  # Crossover probability, increased from 0.95 to 0.97\n        self.w = 0.4  # Inertia weight for PSO, decreased from 0.5 to 0.4\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 1.5 + evaluations/self.budget * 1.2  # Adjusted cognitive coefficient dynamics\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhance exploration by slightly increasing the Differential Evolution parameter F from 0.6 to 0.65.", "configspace": "", "generation": 89, "fitness": 0.3765386502399241, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.30.", "error": "", "parent_id": "52b5b805-fb97-456b-9f1f-c4b6b990cc62", "metadata": {"aucs": [0.8893596448149119, 0.8893596448149119, 0.8893596448149119, 0.8920693460899549, 0.8920693460899549, 0.8920693460899549, 0.8884016000714136, 0.8884016000714136, 0.8884016000714136, 0.7333438518886665, 0.7333438518886665, 0.7333438518886665, 0.7600098016291019, 0.7600098016291019, 0.7600098016291019, 0.6463426427488571, 0.6463426427488571, 0.6463426427488571, 0.1809201751895385, 0.1809201751895385, 0.1809201751895385, 0.1306838979271251, 0.1306838979271251, 0.1306838979271251, 0.12899051850681864, 0.12899051850681864, 0.12899051850681864, 0.10493678024934738, 0.10493678024934738, 0.10493678024934738, 0.11994150288733274, 0.11994150288733274, 0.11994150288733274, 0.13183243208186501, 0.13183243208186501, 0.13183243208186501, 0.9672230493286496, 0.9672230493286496, 0.9672230493286496, 0.9682265207245869, 0.9682265207245869, 0.9682265207245869, 0.9647199202171559, 0.9647199202171559, 0.9647199202171559, 0.7533289411627433, 0.7533289411627433, 0.7533289411627433, 0.7065271188193453, 0.7065271188193453, 0.7065271188193453, 0.7268523870292116, 0.7268523870292116, 0.7268523870292116, 0.8467872123551017, 0.8467872123551017, 0.8467872123551017, 0.8293141439885298, 0.8293141439885298, 0.8293141439885298, 0.8444498651893355, 0.8444498651893355, 0.8444498651893355, 0.23527152544866925, 0.23527152544866925, 0.23527152544866925, 0.23551511746460574, 0.23551511746460574, 0.23551511746460574, 0.23478531060918484, 0.23478531060918484, 0.23478531060918484, 0.22602667083125438, 0.22602667083125438, 0.22602667083125438, 0.2833932502516717, 0.2833932502516717, 0.2833932502516717, 0.24442913277786005, 0.24442913277786005, 0.24442913277786005, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01432030104344717, 0.01432030104344717, 0.01432030104344717, 0.04599721525730238, 0.04599721525730238, 0.04599721525730238, 0.0931986812468405, 0.0931986812468405, 0.0931986812468405, 0.0531110225944198, 0.0531110225944198, 0.0531110225944198, 0.0672852718459952, 0.0672852718459952, 0.0672852718459952, 0.0953593821715536, 0.0953593821715536, 0.0953593821715536, 0.10928272153849616, 0.10928272153849616, 0.10928272153849616, 0.3107617938518863, 0.3107617938518863, 0.3107617938518863, 0.2556229335982112, 0.2556229335982112, 0.2556229335982112, 0.10730012410734346, 0.10730012410734346, 0.10730012410734346, 0.09064429134506913, 0.09064429134506913, 0.09064429134506913, 0.552579074057894, 0.552579074057894, 0.552579074057894, 0.5606974743790856, 0.5606974743790856, 0.5606974743790856, 0.5900312420012185, 0.5900312420012185, 0.5900312420012185, 0.12801417267810444, 0.12801417267810444, 0.12801417267810444, 0.11884447189352265, 0.11884447189352265, 0.11884447189352265, 0.13431566060056144, 0.13431566060056144, 0.13431566060056144, 0.22419689261607212, 0.22419689261607212, 0.22419689261607212, 0.17789714192895922, 0.17789714192895922, 0.17789714192895922, 0.2111673008725894, 0.2111673008725894, 0.2111673008725894, 0.3787891189145072, 0.3787891189145072, 0.3787891189145072, 0.4955272794457056, 0.4955272794457056, 0.4955272794457056, 0.6013378968194083, 0.6013378968194083, 0.6013378968194083, 0.25029967976198253, 0.25029967976198253, 0.25029967976198253, 0.2831853165500654, 0.2831853165500654, 0.2831853165500654, 0.22690585140169928, 0.22690585140169928, 0.22690585140169928, 0.21255278194822602, 0.21255278194822602, 0.21255278194822602, 0.18941496655385004, 0.18941496655385004, 0.18941496655385004, 0.2651724092003268, 0.2651724092003268, 0.2651724092003268, 0.18711320712030177, 0.18711320712030177, 0.18711320712030177, 0.19697235180150607, 0.19697235180150607, 0.19697235180150607, 0.20851994453665512, 0.20851994453665512, 0.20851994453665512, 0.9046028572310476, 0.9046028572310476, 0.9046028572310476, 0.8212600083668484, 0.8212600083668484, 0.8212600083668484, 0.8886742760074517, 0.8886742760074517, 0.8886742760074517, 0.6394371647879068, 0.6394371647879068, 0.6394371647879068, 0.2081481032121526, 0.2081481032121526, 0.2081481032121526, 0.6845125728139694, 0.6845125728139694, 0.6845125728139694, 0.19490833083911963, 0.19490833083911963, 0.19490833083911963, 0.19152415688525337, 0.19152415688525337, 0.19152415688525337, 0.19122738271276707, 0.19122738271276707, 0.19122738271276707, 0.09368342799766671, 0.09368342799766671, 0.09368342799766671, 0.09482947531153418, 0.09482947531153418, 0.09482947531153418, 0.08777472714317469, 0.08777472714317469, 0.08777472714317469]}, "mutation_prompt": null}
{"id": "4013305a-16e4-4713-b33a-b7c4ed4774a5", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.65  # Differential Evolution parameter, increased from 0.6 to 0.65\n        self.CR = 0.97  # Crossover probability, increased from 0.95 to 0.97\n        self.w = 0.45  # Inertia weight for PSO, increased from 0.4 to 0.45\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 1.5 + evaluations/self.budget * 1.2  # Adjusted cognitive coefficient dynamics\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced exploration by slightly increasing the inertia weight for PSO from 0.4 to 0.45.", "configspace": "", "generation": 90, "fitness": 0.36166218368969816, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.29.", "error": "", "parent_id": "a9af4694-8003-467d-a537-240d6db9affd", "metadata": {"aucs": [0.8867255314784517, 0.8867255314784517, 0.8867255314784517, 0.8787936377974804, 0.8787936377974804, 0.8787936377974804, 0.88778489681316, 0.88778489681316, 0.88778489681316, 0.7245154841140424, 0.7245154841140424, 0.7245154841140424, 0.6852888153327693, 0.6852888153327693, 0.6852888153327693, 0.6934658200847207, 0.6934658200847207, 0.6934658200847207, 0.17827050404161549, 0.17827050404161549, 0.17827050404161549, 0.1525364468475915, 0.1525364468475915, 0.1525364468475915, 0.13455300854299967, 0.13455300854299967, 0.13455300854299967, 0.10427436909787446, 0.10427436909787446, 0.10427436909787446, 0.09248619956317394, 0.09248619956317394, 0.09248619956317394, 0.13676157373745756, 0.13676157373745756, 0.13676157373745756, 0.9676402923174341, 0.9676402923174341, 0.9676402923174341, 0.9725433027774918, 0.9725433027774918, 0.9725433027774918, 0.9647926126697022, 0.9647926126697022, 0.9647926126697022, 0.7068044447177644, 0.7068044447177644, 0.7068044447177644, 0.7234004708038713, 0.7234004708038713, 0.7234004708038713, 0.6672870892634751, 0.6672870892634751, 0.6672870892634751, 0.2659936301214767, 0.2659936301214767, 0.2659936301214767, 0.8767075045488131, 0.8767075045488131, 0.8767075045488131, 0.8186097293596917, 0.8186097293596917, 0.8186097293596917, 0.2087979423191364, 0.2087979423191364, 0.2087979423191364, 0.24242253261467572, 0.24242253261467572, 0.24242253261467572, 0.22214845795794413, 0.22214845795794413, 0.22214845795794413, 0.21166039827072614, 0.21166039827072614, 0.21166039827072614, 0.25475007200116195, 0.25475007200116195, 0.25475007200116195, 0.2469798045451469, 0.2469798045451469, 0.2469798045451469, 0.02378422985814921, 0.02378422985814921, 0.02378422985814921, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1085895809757561, 0.1085895809757561, 0.1085895809757561, 0.0570541136986521, 0.0570541136986521, 0.0570541136986521, 0.10613018997463419, 0.10613018997463419, 0.10613018997463419, 0.0925836281761363, 0.0925836281761363, 0.0925836281761363, 0.11886668556105995, 0.11886668556105995, 0.11886668556105995, 0.15580470627005583, 0.15580470627005583, 0.15580470627005583, 0.18234394769497253, 0.18234394769497253, 0.18234394769497253, 0.09400646777871402, 0.09400646777871402, 0.09400646777871402, 0.19971170414991635, 0.19971170414991635, 0.19971170414991635, 0.5515222252423344, 0.5515222252423344, 0.5515222252423344, 0.5765189345606829, 0.5765189345606829, 0.5765189345606829, 0.6091623713588339, 0.6091623713588339, 0.6091623713588339, 0.15818206063636586, 0.15818206063636586, 0.15818206063636586, 0.1531505509045452, 0.1531505509045452, 0.1531505509045452, 0.10540789254624228, 0.10540789254624228, 0.10540789254624228, 0.31859959250335157, 0.31859959250335157, 0.31859959250335157, 0.24836010520329876, 0.24836010520329876, 0.24836010520329876, 0.20535930365550215, 0.20535930365550215, 0.20535930365550215, 0.2925004606620335, 0.2925004606620335, 0.2925004606620335, 0.3871350734275475, 0.3871350734275475, 0.3871350734275475, 0.5328854466947566, 0.5328854466947566, 0.5328854466947566, 0.2648451653742514, 0.2648451653742514, 0.2648451653742514, 0.24322549342607402, 0.24322549342607402, 0.24322549342607402, 0.22263319800184977, 0.22263319800184977, 0.22263319800184977, 0.2242044602465827, 0.2242044602465827, 0.2242044602465827, 0.23995987500553373, 0.23995987500553373, 0.23995987500553373, 0.2369377620362435, 0.2369377620362435, 0.2369377620362435, 0.1928680106895494, 0.1928680106895494, 0.1928680106895494, 0.6583077556824344, 0.6583077556824344, 0.6583077556824344, 0.20075342500778592, 0.20075342500778592, 0.20075342500778592, 0.8754816652188817, 0.8754816652188817, 0.8754816652188817, 0.8376238386004279, 0.8376238386004279, 0.8376238386004279, 0.8699163078855146, 0.8699163078855146, 0.8699163078855146, 0.5229624537423596, 0.5229624537423596, 0.5229624537423596, 0.20599338788758792, 0.20599338788758792, 0.20599338788758792, 0.16644548158224493, 0.16644548158224493, 0.16644548158224493, 0.20712116415551618, 0.20712116415551618, 0.20712116415551618, 0.20296830917894237, 0.20296830917894237, 0.20296830917894237, 0.18719313330015197, 0.18719313330015197, 0.18719313330015197, 0.0931687052249095, 0.0931687052249095, 0.0931687052249095, 0.09782798894623634, 0.09782798894623634, 0.09782798894623634, 0.10538580119179697, 0.10538580119179697, 0.10538580119179697]}, "mutation_prompt": null}
{"id": "0f677926-d57f-4ab0-94da-d94176d166b1", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.65  # Differential Evolution parameter, increased from 0.6 to 0.65\n        self.CR = 0.97  # Crossover probability, increased from 0.95 to 0.97\n        self.w = 0.45  # Inertia weight for PSO, increased from 0.4 to 0.45\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 1.5 + evaluations/self.budget * 1.2  # Adjusted cognitive coefficient dynamics\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Slightly adjust the inertia weight from 0.4 to 0.45 to enhance the balance between exploration and exploitation.", "configspace": "", "generation": 91, "fitness": 0.36166218368969816, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.29.", "error": "", "parent_id": "a9af4694-8003-467d-a537-240d6db9affd", "metadata": {"aucs": [0.8867255314784517, 0.8867255314784517, 0.8867255314784517, 0.8787936377974804, 0.8787936377974804, 0.8787936377974804, 0.88778489681316, 0.88778489681316, 0.88778489681316, 0.7245154841140424, 0.7245154841140424, 0.7245154841140424, 0.6852888153327693, 0.6852888153327693, 0.6852888153327693, 0.6934658200847207, 0.6934658200847207, 0.6934658200847207, 0.17827050404161549, 0.17827050404161549, 0.17827050404161549, 0.1525364468475915, 0.1525364468475915, 0.1525364468475915, 0.13455300854299967, 0.13455300854299967, 0.13455300854299967, 0.10427436909787446, 0.10427436909787446, 0.10427436909787446, 0.09248619956317394, 0.09248619956317394, 0.09248619956317394, 0.13676157373745756, 0.13676157373745756, 0.13676157373745756, 0.9676402923174341, 0.9676402923174341, 0.9676402923174341, 0.9725433027774918, 0.9725433027774918, 0.9725433027774918, 0.9647926126697022, 0.9647926126697022, 0.9647926126697022, 0.7068044447177644, 0.7068044447177644, 0.7068044447177644, 0.7234004708038713, 0.7234004708038713, 0.7234004708038713, 0.6672870892634751, 0.6672870892634751, 0.6672870892634751, 0.2659936301214767, 0.2659936301214767, 0.2659936301214767, 0.8767075045488131, 0.8767075045488131, 0.8767075045488131, 0.8186097293596917, 0.8186097293596917, 0.8186097293596917, 0.2087979423191364, 0.2087979423191364, 0.2087979423191364, 0.24242253261467572, 0.24242253261467572, 0.24242253261467572, 0.22214845795794413, 0.22214845795794413, 0.22214845795794413, 0.21166039827072614, 0.21166039827072614, 0.21166039827072614, 0.25475007200116195, 0.25475007200116195, 0.25475007200116195, 0.2469798045451469, 0.2469798045451469, 0.2469798045451469, 0.02378422985814921, 0.02378422985814921, 0.02378422985814921, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1085895809757561, 0.1085895809757561, 0.1085895809757561, 0.0570541136986521, 0.0570541136986521, 0.0570541136986521, 0.10613018997463419, 0.10613018997463419, 0.10613018997463419, 0.0925836281761363, 0.0925836281761363, 0.0925836281761363, 0.11886668556105995, 0.11886668556105995, 0.11886668556105995, 0.15580470627005583, 0.15580470627005583, 0.15580470627005583, 0.18234394769497253, 0.18234394769497253, 0.18234394769497253, 0.09400646777871402, 0.09400646777871402, 0.09400646777871402, 0.19971170414991635, 0.19971170414991635, 0.19971170414991635, 0.5515222252423344, 0.5515222252423344, 0.5515222252423344, 0.5765189345606829, 0.5765189345606829, 0.5765189345606829, 0.6091623713588339, 0.6091623713588339, 0.6091623713588339, 0.15818206063636586, 0.15818206063636586, 0.15818206063636586, 0.1531505509045452, 0.1531505509045452, 0.1531505509045452, 0.10540789254624228, 0.10540789254624228, 0.10540789254624228, 0.31859959250335157, 0.31859959250335157, 0.31859959250335157, 0.24836010520329876, 0.24836010520329876, 0.24836010520329876, 0.20535930365550215, 0.20535930365550215, 0.20535930365550215, 0.2925004606620335, 0.2925004606620335, 0.2925004606620335, 0.3871350734275475, 0.3871350734275475, 0.3871350734275475, 0.5328854466947566, 0.5328854466947566, 0.5328854466947566, 0.2648451653742514, 0.2648451653742514, 0.2648451653742514, 0.24322549342607402, 0.24322549342607402, 0.24322549342607402, 0.22263319800184977, 0.22263319800184977, 0.22263319800184977, 0.2242044602465827, 0.2242044602465827, 0.2242044602465827, 0.23995987500553373, 0.23995987500553373, 0.23995987500553373, 0.2369377620362435, 0.2369377620362435, 0.2369377620362435, 0.1928680106895494, 0.1928680106895494, 0.1928680106895494, 0.6583077556824344, 0.6583077556824344, 0.6583077556824344, 0.20075342500778592, 0.20075342500778592, 0.20075342500778592, 0.8754816652188817, 0.8754816652188817, 0.8754816652188817, 0.8376238386004279, 0.8376238386004279, 0.8376238386004279, 0.8699163078855146, 0.8699163078855146, 0.8699163078855146, 0.5229624537423596, 0.5229624537423596, 0.5229624537423596, 0.20599338788758792, 0.20599338788758792, 0.20599338788758792, 0.16644548158224493, 0.16644548158224493, 0.16644548158224493, 0.20712116415551618, 0.20712116415551618, 0.20712116415551618, 0.20296830917894237, 0.20296830917894237, 0.20296830917894237, 0.18719313330015197, 0.18719313330015197, 0.18719313330015197, 0.0931687052249095, 0.0931687052249095, 0.0931687052249095, 0.09782798894623634, 0.09782798894623634, 0.09782798894623634, 0.10538580119179697, 0.10538580119179697, 0.10538580119179697]}, "mutation_prompt": null}
{"id": "19536b8f-0857-46fa-a73c-8c70435fa527", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.65  # Differential Evolution parameter, increased from 0.6 to 0.65\n        self.CR = 0.97  # Crossover probability, increased from 0.95 to 0.97\n        self.w = 0.35  # Inertia weight for PSO, decreased from 0.4 to 0.35\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 1.5 + evaluations/self.budget * 1.2  # Adjusted cognitive coefficient dynamics\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhance exploration by reducing inertia weight for PSO from 0.4 to 0.35.", "configspace": "", "generation": 92, "fitness": 0.38353907155567735, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.31.", "error": "", "parent_id": "a9af4694-8003-467d-a537-240d6db9affd", "metadata": {"aucs": [0.8926164085773836, 0.8926164085773836, 0.8926164085773836, 0.8943733775862441, 0.8943733775862441, 0.8943733775862441, 0.8982193953653236, 0.8982193953653236, 0.8982193953653236, 0.7690543663875731, 0.7690543663875731, 0.7690543663875731, 0.7723187488434563, 0.7723187488434563, 0.7723187488434563, 0.7776032228939533, 0.7776032228939533, 0.7776032228939533, 0.14179092237775826, 0.14179092237775826, 0.14179092237775826, 0.13685930181616712, 0.13685930181616712, 0.13685930181616712, 0.6492661279614711, 0.6492661279614711, 0.6492661279614711, 0.11327801527620052, 0.11327801527620052, 0.11327801527620052, 0.12059522522204302, 0.12059522522204302, 0.12059522522204302, 0.11186491091675399, 0.11186491091675399, 0.11186491091675399, 0.9624834442112653, 0.9624834442112653, 0.9624834442112653, 0.9678390104850915, 0.9678390104850915, 0.9678390104850915, 0.9555588824034629, 0.9555588824034629, 0.9555588824034629, 0.7594569837927372, 0.7594569837927372, 0.7594569837927372, 0.7336694405544077, 0.7336694405544077, 0.7336694405544077, 0.7616457947120227, 0.7616457947120227, 0.7616457947120227, 0.4175210100376635, 0.4175210100376635, 0.4175210100376635, 0.8437393086600616, 0.8437393086600616, 0.8437393086600616, 0.8345061430859815, 0.8345061430859815, 0.8345061430859815, 0.21689048827753865, 0.21689048827753865, 0.21689048827753865, 0.21155301760207856, 0.21155301760207856, 0.21155301760207856, 0.22716198665960907, 0.22716198665960907, 0.22716198665960907, 0.22986263746221947, 0.22986263746221947, 0.22986263746221947, 0.2692165011878317, 0.2692165011878317, 0.2692165011878317, 0.25124426068787586, 0.25124426068787586, 0.25124426068787586, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04697923497775769, 0.04697923497775769, 0.04697923497775769, 0.055568048090646194, 0.055568048090646194, 0.055568048090646194, 0.14351603583527672, 0.14351603583527672, 0.14351603583527672, 0.0679305256952708, 0.0679305256952708, 0.0679305256952708, 0.09373116022905159, 0.09373116022905159, 0.09373116022905159, 0.1406796765417907, 0.1406796765417907, 0.1406796765417907, 0.09911073133867687, 0.09911073133867687, 0.09911073133867687, 0.1058695749605284, 0.1058695749605284, 0.1058695749605284, 0.17052689329932313, 0.17052689329932313, 0.17052689329932313, 0.12372072701459236, 0.12372072701459236, 0.12372072701459236, 0.0899368848151022, 0.0899368848151022, 0.0899368848151022, 0.5336139876647694, 0.5336139876647694, 0.5336139876647694, 0.5505879110296203, 0.5505879110296203, 0.5505879110296203, 0.597169692849437, 0.597169692849437, 0.597169692849437, 0.1016264098391293, 0.1016264098391293, 0.1016264098391293, 0.1261875921933956, 0.1261875921933956, 0.1261875921933956, 0.1063275711056535, 0.1063275711056535, 0.1063275711056535, 0.2218883161810049, 0.2218883161810049, 0.2218883161810049, 0.1891689137099608, 0.1891689137099608, 0.1891689137099608, 0.18315970625307776, 0.18315970625307776, 0.18315970625307776, 0.2576234676003315, 0.2576234676003315, 0.2576234676003315, 0.37925378051038783, 0.37925378051038783, 0.37925378051038783, 0.6157089554020252, 0.6157089554020252, 0.6157089554020252, 0.3321048508660074, 0.3321048508660074, 0.3321048508660074, 0.30918569416906616, 0.30918569416906616, 0.30918569416906616, 0.201009699227924, 0.201009699227924, 0.201009699227924, 0.2320873997901528, 0.2320873997901528, 0.2320873997901528, 0.1906471785990178, 0.1906471785990178, 0.1906471785990178, 0.24883613275909333, 0.24883613275909333, 0.24883613275909333, 0.19634946975336132, 0.19634946975336132, 0.19634946975336132, 0.21877089698826702, 0.21877089698826702, 0.21877089698826702, 0.21482399465793056, 0.21482399465793056, 0.21482399465793056, 0.8934602951295267, 0.8934602951295267, 0.8934602951295267, 0.8341171426670997, 0.8341171426670997, 0.8341171426670997, 0.8734216442564389, 0.8734216442564389, 0.8734216442564389, 0.7958745541225937, 0.7958745541225937, 0.7958745541225937, 0.48583677452684393, 0.48583677452684393, 0.48583677452684393, 0.7846754976519322, 0.7846754976519322, 0.7846754976519322, 0.18274662244593542, 0.18274662244593542, 0.18274662244593542, 0.1825496913688366, 0.1825496913688366, 0.1825496913688366, 0.2291151961216381, 0.2291151961216381, 0.2291151961216381, 0.08742679454935354, 0.08742679454935354, 0.08742679454935354, 0.09791716416143759, 0.09791716416143759, 0.09791716416143759, 0.1036817280153286, 0.1036817280153286, 0.1036817280153286]}, "mutation_prompt": null}
{"id": "95b024aa-52f0-4956-818c-aeea73295cf5", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.65  # Differential Evolution parameter, increased from 0.6 to 0.65\n        self.CR = 0.97  # Crossover probability, increased from 0.95 to 0.97\n        self.w = 0.35  # Inertia weight for PSO, decreased from 0.4 to 0.35\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.pop_size, self.dim))  # Changed from -1,1 to -0.5,0.5\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 1.5 + evaluations/self.budget * 1.2  # Adjusted cognitive coefficient dynamics\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhance exploration by reducing velocity randomness in PSO to improve convergence stability.", "configspace": "", "generation": 93, "fitness": 0.3686129687624156, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.30.", "error": "", "parent_id": "19536b8f-0857-46fa-a73c-8c70435fa527", "metadata": {"aucs": [0.8793616079920744, 0.8793616079920744, 0.8793616079920744, 0.8809989692358955, 0.8809989692358955, 0.8809989692358955, 0.9001336851328067, 0.9001336851328067, 0.9001336851328067, 0.7901430359807068, 0.7901430359807068, 0.7901430359807068, 0.7672214266696314, 0.7672214266696314, 0.7672214266696314, 0.7976937982753991, 0.7976937982753991, 0.7976937982753991, 0.15976933361882328, 0.15976933361882328, 0.15976933361882328, 0.15132830668137098, 0.15132830668137098, 0.15132830668137098, 0.10968507684917694, 0.10968507684917694, 0.10968507684917694, 0.10953678947191636, 0.10953678947191636, 0.10953678947191636, 0.1011078274316658, 0.1011078274316658, 0.1011078274316658, 0.10243426356709628, 0.10243426356709628, 0.10243426356709628, 0.9624609208618825, 0.9624609208618825, 0.9624609208618825, 0.9677867596950184, 0.9677867596950184, 0.9677867596950184, 0.9557196681798225, 0.9557196681798225, 0.9557196681798225, 0.7652950818234954, 0.7652950818234954, 0.7652950818234954, 0.7463353320871453, 0.7463353320871453, 0.7463353320871453, 0.7266003551453555, 0.7266003551453555, 0.7266003551453555, 0.8094734021512646, 0.8094734021512646, 0.8094734021512646, 0.2123935868215442, 0.2123935868215442, 0.2123935868215442, 0.7067916036844455, 0.7067916036844455, 0.7067916036844455, 0.21381004890069943, 0.21381004890069943, 0.21381004890069943, 0.22878850978424703, 0.22878850978424703, 0.22878850978424703, 0.22432372242952037, 0.22432372242952037, 0.22432372242952037, 0.17163694526982876, 0.17163694526982876, 0.17163694526982876, 0.22878412791639124, 0.22878412791639124, 0.22878412791639124, 0.23019236947997734, 0.23019236947997734, 0.23019236947997734, 0.06259998255196675, 0.06259998255196675, 0.06259998255196675, 0.08476976989222218, 0.08476976989222218, 0.08476976989222218, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14472115178386868, 0.14472115178386868, 0.14472115178386868, 0.07834255417026759, 0.07834255417026759, 0.07834255417026759, 0.09409914465453495, 0.09409914465453495, 0.09409914465453495, 0.11732813983381019, 0.11732813983381019, 0.11732813983381019, 0.15375966732436464, 0.15375966732436464, 0.15375966732436464, 0.07416272781124444, 0.07416272781124444, 0.07416272781124444, 0.16269172453918324, 0.16269172453918324, 0.16269172453918324, 0.2297443111234716, 0.2297443111234716, 0.2297443111234716, 0.11910056651545442, 0.11910056651545442, 0.11910056651545442, 0.5792860546774237, 0.5792860546774237, 0.5792860546774237, 0.6023429606373152, 0.6023429606373152, 0.6023429606373152, 0.5947494970779401, 0.5947494970779401, 0.5947494970779401, 0.7193132536984015, 0.7193132536984015, 0.7193132536984015, 0.13017425666408633, 0.13017425666408633, 0.13017425666408633, 0.10849544291536295, 0.10849544291536295, 0.10849544291536295, 0.1864310418618823, 0.1864310418618823, 0.1864310418618823, 0.27561500666412475, 0.27561500666412475, 0.27561500666412475, 0.2568911674807576, 0.2568911674807576, 0.2568911674807576, 0.5999640074187356, 0.5999640074187356, 0.5999640074187356, 0.4121460539357764, 0.4121460539357764, 0.4121460539357764, 0.35777137938263104, 0.35777137938263104, 0.35777137938263104, 0.2401493155629396, 0.2401493155629396, 0.2401493155629396, 0.2037272898788035, 0.2037272898788035, 0.2037272898788035, 0.31734126251651684, 0.31734126251651684, 0.31734126251651684, 0.2455137082048391, 0.2455137082048391, 0.2455137082048391, 0.24667551153562217, 0.24667551153562217, 0.24667551153562217, 0.1991639973723578, 0.1991639973723578, 0.1991639973723578, 0.24380494840143618, 0.24380494840143618, 0.24380494840143618, 0.19508073628634304, 0.19508073628634304, 0.19508073628634304, 0.636078933219109, 0.636078933219109, 0.636078933219109, 0.8744040382293046, 0.8744040382293046, 0.8744040382293046, 0.16307232482101697, 0.16307232482101697, 0.16307232482101697, 0.8874106782383857, 0.8874106782383857, 0.8874106782383857, 0.8138539058000798, 0.8138539058000798, 0.8138539058000798, 0.1673912685874146, 0.1673912685874146, 0.1673912685874146, 0.167520634741275, 0.167520634741275, 0.167520634741275, 0.18535286076878377, 0.18535286076878377, 0.18535286076878377, 0.19343270647944977, 0.19343270647944977, 0.19343270647944977, 0.1912462734133169, 0.1912462734133169, 0.1912462734133169, 0.1011451501709435, 0.1011451501709435, 0.1011451501709435, 0.09512570137789844, 0.09512570137789844, 0.09512570137789844, 0.12823608753606186, 0.12823608753606186, 0.12823608753606186]}, "mutation_prompt": null}
{"id": "f49c4554-beca-4da3-9aeb-bdb59f2d6f64", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.65  # Differential Evolution parameter, increased from 0.6 to 0.65\n        self.CR = 0.98  # Crossover probability, increased from 0.97 to 0.98\n        self.w = 0.35  # Inertia weight for PSO, decreased from 0.4 to 0.35\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 1.5 + evaluations/self.budget * 1.2  # Adjusted cognitive coefficient dynamics\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhanced by increasing the differential evolution crossover probability (CR) from 0.97 to 0.98.", "configspace": "", "generation": 94, "fitness": 0.3544911029122899, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.", "error": "", "parent_id": "19536b8f-0857-46fa-a73c-8c70435fa527", "metadata": {"aucs": [0.8952037089535672, 0.8952037089535672, 0.8952037089535672, 0.8929690077508776, 0.8929690077508776, 0.8929690077508776, 0.9014270864306818, 0.9014270864306818, 0.9014270864306818, 0.7412330251316696, 0.7412330251316696, 0.7412330251316696, 0.7846769081782677, 0.7846769081782677, 0.7846769081782677, 0.7455993770807275, 0.7455993770807275, 0.7455993770807275, 0.15518486830195544, 0.15518486830195544, 0.15518486830195544, 0.17080206118050445, 0.17080206118050445, 0.17080206118050445, 0.16706202361272204, 0.16706202361272204, 0.16706202361272204, 0.1312005703454806, 0.1312005703454806, 0.1312005703454806, 0.11435406161932882, 0.11435406161932882, 0.11435406161932882, 0.14597998316061744, 0.14597998316061744, 0.14597998316061744, 0.9592046730072353, 0.9592046730072353, 0.9592046730072353, 0.9628549381684007, 0.9628549381684007, 0.9628549381684007, 0.9547132047442862, 0.9547132047442862, 0.9547132047442862, 0.7623737566046512, 0.7623737566046512, 0.7623737566046512, 0.7467158744045664, 0.7467158744045664, 0.7467158744045664, 0.7398390363777703, 0.7398390363777703, 0.7398390363777703, 0.37798166281344725, 0.37798166281344725, 0.37798166281344725, 0.21899683897747746, 0.21899683897747746, 0.21899683897747746, 0.23220809444687285, 0.23220809444687285, 0.23220809444687285, 0.20438474085390368, 0.20438474085390368, 0.20438474085390368, 0.13040353378561065, 0.13040353378561065, 0.13040353378561065, 0.1299066437337324, 0.1299066437337324, 0.1299066437337324, 0.22968867070149324, 0.22968867070149324, 0.22968867070149324, 0.26375788488428786, 0.26375788488428786, 0.26375788488428786, 0.25645577067953296, 0.25645577067953296, 0.25645577067953296, 0.03419772008131772, 0.03419772008131772, 0.03419772008131772, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.015617775128938916, 0.015617775128938916, 0.015617775128938916, 0.09093108961668384, 0.09093108961668384, 0.09093108961668384, 0.10749273299930484, 0.10749273299930484, 0.10749273299930484, 0.077095405928848, 0.077095405928848, 0.077095405928848, 0.11073926725445304, 0.11073926725445304, 0.11073926725445304, 0.1611302908402793, 0.1611302908402793, 0.1611302908402793, 0.11968404354871054, 0.11968404354871054, 0.11968404354871054, 0.1688511217904365, 0.1688511217904365, 0.1688511217904365, 0.11974515277421638, 0.11974515277421638, 0.11974515277421638, 0.07723643320875362, 0.07723643320875362, 0.07723643320875362, 0.5550947598073642, 0.5550947598073642, 0.5550947598073642, 0.5716047472737139, 0.5716047472737139, 0.5716047472737139, 0.5765201284941008, 0.5765201284941008, 0.5765201284941008, 0.11729559541913748, 0.11729559541913748, 0.11729559541913748, 0.12196190224324288, 0.12196190224324288, 0.12196190224324288, 0.13983019137650265, 0.13983019137650265, 0.13983019137650265, 0.28942829155911054, 0.28942829155911054, 0.28942829155911054, 0.2128243121939024, 0.2128243121939024, 0.2128243121939024, 0.1755656483711684, 0.1755656483711684, 0.1755656483711684, 0.2442020008201492, 0.2442020008201492, 0.2442020008201492, 0.36014578726104707, 0.36014578726104707, 0.36014578726104707, 0.4672528777157793, 0.4672528777157793, 0.4672528777157793, 0.29665322153155604, 0.29665322153155604, 0.29665322153155604, 0.3136810723579341, 0.3136810723579341, 0.3136810723579341, 0.22134437586729583, 0.22134437586729583, 0.22134437586729583, 0.24568785654600955, 0.24568785654600955, 0.24568785654600955, 0.23275928761694564, 0.23275928761694564, 0.23275928761694564, 0.21428399852357216, 0.21428399852357216, 0.21428399852357216, 0.21551977320810656, 0.21551977320810656, 0.21551977320810656, 0.205281743714694, 0.205281743714694, 0.205281743714694, 0.2148239946579561, 0.2148239946579561, 0.2148239946579561, 0.8712894956279245, 0.8712894956279245, 0.8712894956279245, 0.8367736656902665, 0.8367736656902665, 0.8367736656902665, 0.8848578913323651, 0.8848578913323651, 0.8848578913323651, 0.6170505324363419, 0.6170505324363419, 0.6170505324363419, 0.5872101767707532, 0.5872101767707532, 0.5872101767707532, 0.7567952670885347, 0.7567952670885347, 0.7567952670885347, 0.19476171861064795, 0.19476171861064795, 0.19476171861064795, 0.20130485563239364, 0.20130485563239364, 0.20130485563239364, 0.2062519585743754, 0.2062519585743754, 0.2062519585743754, 0.08971163963299167, 0.08971163963299167, 0.08971163963299167, 0.09627785598806693, 0.09627785598806693, 0.09627785598806693, 0.09131374663931457, 0.09131374663931457, 0.09131374663931457]}, "mutation_prompt": null}
{"id": "baf4aa2e-7523-45c3-9724-05e4cc88194e", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.65  # Differential Evolution parameter, increased from 0.6 to 0.65\n        self.CR = 0.97  # Crossover probability, increased from 0.95 to 0.97\n        self.w = 0.34  # Inertia weight for PSO, decreased from 0.35 to 0.34\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 1.5 + evaluations/self.budget * 1.2  # Adjusted cognitive coefficient dynamics\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhance convergence by slightly decreasing the inertia weight for PSO from 0.35 to 0.34.", "configspace": "", "generation": 95, "fitness": 0.356562749711003, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.30.", "error": "", "parent_id": "19536b8f-0857-46fa-a73c-8c70435fa527", "metadata": {"aucs": [0.897564368016196, 0.897564368016196, 0.897564368016196, 0.8831791973870396, 0.8831791973870396, 0.8831791973870396, 0.9022988422703867, 0.9022988422703867, 0.9022988422703867, 0.7547325513871621, 0.7547325513871621, 0.7547325513871621, 0.7547708467213838, 0.7547708467213838, 0.7547708467213838, 0.7321174941231069, 0.7321174941231069, 0.7321174941231069, 0.15238429739754988, 0.15238429739754988, 0.15238429739754988, 0.1559652157233662, 0.1559652157233662, 0.1559652157233662, 0.14424891836465448, 0.14424891836465448, 0.14424891836465448, 0.13969670855547833, 0.13969670855547833, 0.13969670855547833, 0.09782998612656213, 0.09782998612656213, 0.09782998612656213, 0.13500374283360395, 0.13500374283360395, 0.13500374283360395, 0.9617300087460461, 0.9617300087460461, 0.9617300087460461, 0.9678259667460427, 0.9678259667460427, 0.9678259667460427, 0.9554227741844482, 0.9554227741844482, 0.9554227741844482, 0.7829547597753685, 0.7829547597753685, 0.7829547597753685, 0.7286240609967355, 0.7286240609967355, 0.7286240609967355, 0.7718522248453826, 0.7718522248453826, 0.7718522248453826, 0.22490484073944406, 0.22490484073944406, 0.22490484073944406, 0.36911193861027036, 0.36911193861027036, 0.36911193861027036, 0.4480840830150483, 0.4480840830150483, 0.4480840830150483, 0.20647678907656353, 0.20647678907656353, 0.20647678907656353, 0.2130098101563127, 0.2130098101563127, 0.2130098101563127, 0.23156337503678093, 0.23156337503678093, 0.23156337503678093, 0.1311860537360322, 0.1311860537360322, 0.1311860537360322, 0.2531800615751425, 0.2531800615751425, 0.2531800615751425, 0.24320252623032934, 0.24320252623032934, 0.24320252623032934, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.022625787672723496, 0.022625787672723496, 0.022625787672723496, 0.04844191942415943, 0.04844191942415943, 0.04844191942415943, 0.10183944117222277, 0.10183944117222277, 0.10183944117222277, 0.06684777865972868, 0.06684777865972868, 0.06684777865972868, 0.11708810892142318, 0.11708810892142318, 0.11708810892142318, 0.0723792451687526, 0.0723792451687526, 0.0723792451687526, 0.10886673615167186, 0.10886673615167186, 0.10886673615167186, 0.11602005176870811, 0.11602005176870811, 0.11602005176870811, 0.13507331734001693, 0.13507331734001693, 0.13507331734001693, 0.0966206839377377, 0.0966206839377377, 0.0966206839377377, 0.09644760601304991, 0.09644760601304991, 0.09644760601304991, 0.559470631293972, 0.559470631293972, 0.559470631293972, 0.5721825651968919, 0.5721825651968919, 0.5721825651968919, 0.5830988882267103, 0.5830988882267103, 0.5830988882267103, 0.12272125065207051, 0.12272125065207051, 0.12272125065207051, 0.12855646370183027, 0.12855646370183027, 0.12855646370183027, 0.1429109179938216, 0.1429109179938216, 0.1429109179938216, 0.2344507263149942, 0.2344507263149942, 0.2344507263149942, 0.1509107215061114, 0.1509107215061114, 0.1509107215061114, 0.1696633578328709, 0.1696633578328709, 0.1696633578328709, 0.3847256341736204, 0.3847256341736204, 0.3847256341736204, 0.5738535791079338, 0.5738535791079338, 0.5738535791079338, 0.6257322483411465, 0.6257322483411465, 0.6257322483411465, 0.21489677697277154, 0.21489677697277154, 0.21489677697277154, 0.2383642988069986, 0.2383642988069986, 0.2383642988069986, 0.21656924556161372, 0.21656924556161372, 0.21656924556161372, 0.2483943522619999, 0.2483943522619999, 0.2483943522619999, 0.2296706796844813, 0.2296706796844813, 0.2296706796844813, 0.21556227043936893, 0.21556227043936893, 0.21556227043936893, 0.1896932130194512, 0.1896932130194512, 0.1896932130194512, 0.19086243514600465, 0.19086243514600465, 0.19086243514600465, 0.22118504762368563, 0.22118504762368563, 0.22118504762368563, 0.8738089157597089, 0.8738089157597089, 0.8738089157597089, 0.8469176430442626, 0.8469176430442626, 0.8469176430442626, 0.8997036899216235, 0.8997036899216235, 0.8997036899216235, 0.7703434911682258, 0.7703434911682258, 0.7703434911682258, 0.2068640584598197, 0.2068640584598197, 0.2068640584598197, 0.7806594541571867, 0.7806594541571867, 0.7806594541571867, 0.1911676576664587, 0.1911676576664587, 0.1911676576664587, 0.2112226088102641, 0.2112226088102641, 0.2112226088102641, 0.18442956149996315, 0.18442956149996315, 0.18442956149996315, 0.10012020477901329, 0.10012020477901329, 0.10012020477901329, 0.08482212949955625, 0.08482212949955625, 0.08482212949955625, 0.08771114196115226, 0.08771114196115226, 0.08771114196115226]}, "mutation_prompt": null}
{"id": "3dc68439-4539-4686-b660-2c111acf0528", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.65  # Differential Evolution parameter, increased from 0.6 to 0.65\n        self.CR = 0.99  # Crossover probability, increased from 0.97 to 0.99\n        self.w = 0.35  # Inertia weight for PSO, decreased from 0.4 to 0.35\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 1.5 + evaluations/self.budget * 1.2  # Adjusted cognitive coefficient dynamics\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Improve convergence by further increasing the crossover probability in Differential Evolution from 0.97 to 0.99.", "configspace": "", "generation": 96, "fitness": 0.3562851597382422, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.29.", "error": "", "parent_id": "19536b8f-0857-46fa-a73c-8c70435fa527", "metadata": {"aucs": [0.8962186765426237, 0.8962186765426237, 0.8962186765426237, 0.8974770252125182, 0.8974770252125182, 0.8974770252125182, 0.894351836173501, 0.894351836173501, 0.894351836173501, 0.7040314985724909, 0.7040314985724909, 0.7040314985724909, 0.7745084325314215, 0.7745084325314215, 0.7745084325314215, 0.7437063843687786, 0.7437063843687786, 0.7437063843687786, 0.16762965733203472, 0.16762965733203472, 0.16762965733203472, 0.15468965785767175, 0.15468965785767175, 0.15468965785767175, 0.1465566505134024, 0.1465566505134024, 0.1465566505134024, 0.14536837960286086, 0.14536837960286086, 0.14536837960286086, 0.12722505668295359, 0.12722505668295359, 0.12722505668295359, 0.13614232511554114, 0.13614232511554114, 0.13614232511554114, 0.9628251476856509, 0.9628251476856509, 0.9628251476856509, 0.9677463270753255, 0.9677463270753255, 0.9677463270753255, 0.9500855771635713, 0.9500855771635713, 0.9500855771635713, 0.7438107447904518, 0.7438107447904518, 0.7438107447904518, 0.7237391128440669, 0.7237391128440669, 0.7237391128440669, 0.7068622810228234, 0.7068622810228234, 0.7068622810228234, 0.22614586057150443, 0.22614586057150443, 0.22614586057150443, 0.2734086687177335, 0.2734086687177335, 0.2734086687177335, 0.6116471288999328, 0.6116471288999328, 0.6116471288999328, 0.21819183163377853, 0.21819183163377853, 0.21819183163377853, 0.30064841866983794, 0.30064841866983794, 0.30064841866983794, 0.20955941714924864, 0.20955941714924864, 0.20955941714924864, 0.2114568304260359, 0.2114568304260359, 0.2114568304260359, 0.23334722791141116, 0.23334722791141116, 0.23334722791141116, 0.2596344091776712, 0.2596344091776712, 0.2596344091776712, 0.1001235776503514, 0.1001235776503514, 0.1001235776503514, 0.023838865222462702, 0.023838865222462702, 0.023838865222462702, 0.015344071595578157, 0.015344071595578157, 0.015344071595578157, 0.09865097578817583, 0.09865097578817583, 0.09865097578817583, 0.08491520243733286, 0.08491520243733286, 0.08491520243733286, 0.10798789343626536, 0.10798789343626536, 0.10798789343626536, 0.12209359567916289, 0.12209359567916289, 0.12209359567916289, 0.29382840998951165, 0.29382840998951165, 0.29382840998951165, 0.11989771398373372, 0.11989771398373372, 0.11989771398373372, 0.15994484903597617, 0.15994484903597617, 0.15994484903597617, 0.11955236981533968, 0.11955236981533968, 0.11955236981533968, 0.07678509629310959, 0.07678509629310959, 0.07678509629310959, 0.621251201522724, 0.621251201522724, 0.621251201522724, 0.5449357240891985, 0.5449357240891985, 0.5449357240891985, 0.544369332286377, 0.544369332286377, 0.544369332286377, 0.16031493911318173, 0.16031493911318173, 0.16031493911318173, 0.12238423865211212, 0.12238423865211212, 0.12238423865211212, 0.12112045148384476, 0.12112045148384476, 0.12112045148384476, 0.2579494021992481, 0.2579494021992481, 0.2579494021992481, 0.36040496582726755, 0.36040496582726755, 0.36040496582726755, 0.1635026456916936, 0.1635026456916936, 0.1635026456916936, 0.2541281166706756, 0.2541281166706756, 0.2541281166706756, 0.4109946442229423, 0.4109946442229423, 0.4109946442229423, 0.5822963297645136, 0.5822963297645136, 0.5822963297645136, 0.28200587011037637, 0.28200587011037637, 0.28200587011037637, 0.3128162444915866, 0.3128162444915866, 0.3128162444915866, 0.2632951041707058, 0.2632951041707058, 0.2632951041707058, 0.2144961434740762, 0.2144961434740762, 0.2144961434740762, 0.22748655573681498, 0.22748655573681498, 0.22748655573681498, 0.20960590072878804, 0.20960590072878804, 0.20960590072878804, 0.2328161619721496, 0.2328161619721496, 0.2328161619721496, 0.20822061923132518, 0.20822061923132518, 0.20822061923132518, 0.1998600393705109, 0.1998600393705109, 0.1998600393705109, 0.9023798038066769, 0.9023798038066769, 0.9023798038066769, 0.8199035481287862, 0.8199035481287862, 0.8199035481287862, 0.8921865780701181, 0.8921865780701181, 0.8921865780701181, 0.15364301103398992, 0.15364301103398992, 0.15364301103398992, 0.20673465849069306, 0.20673465849069306, 0.20673465849069306, 0.8326817149446151, 0.8326817149446151, 0.8326817149446151, 0.21091127913476604, 0.21091127913476604, 0.21091127913476604, 0.19234129564071523, 0.19234129564071523, 0.19234129564071523, 0.18521613824132388, 0.18521613824132388, 0.18521613824132388, 0.0909249991099167, 0.0909249991099167, 0.0909249991099167, 0.07567816142119721, 0.07567816142119721, 0.07567816142119721, 0.0856984971486845, 0.0856984971486845, 0.0856984971486845]}, "mutation_prompt": null}
{"id": "4ad615a7-a013-4554-95bc-6acaa25905f6", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.65  # Differential Evolution parameter, increased from 0.6 to 0.65\n        self.CR = 0.97  # Crossover probability, increased from 0.95 to 0.97\n        self.w = 0.33  # Inertia weight for PSO, decreased from 0.35 to 0.33\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 1.5 + evaluations/self.budget * 1.2  # Adjusted cognitive coefficient dynamics\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Fine-tune the Particle Swarm Optimization's inertia weight for better balance between exploration and exploitation.", "configspace": "", "generation": 97, "fitness": 0.3680961805232805, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.30.", "error": "", "parent_id": "19536b8f-0857-46fa-a73c-8c70435fa527", "metadata": {"aucs": [0.904699870466196, 0.904699870466196, 0.904699870466196, 0.9020782113681307, 0.9020782113681307, 0.9020782113681307, 0.9009601198375361, 0.9009601198375361, 0.9009601198375361, 0.7387715883123469, 0.7387715883123469, 0.7387715883123469, 0.7865233081180216, 0.7865233081180216, 0.7865233081180216, 0.7861566683962342, 0.7861566683962342, 0.7861566683962342, 0.18203162099232884, 0.18203162099232884, 0.18203162099232884, 0.17537821867728487, 0.17537821867728487, 0.17537821867728487, 0.1516152519446261, 0.1516152519446261, 0.1516152519446261, 0.12146546895347876, 0.12146546895347876, 0.12146546895347876, 0.11117708039099872, 0.11117708039099872, 0.11117708039099872, 0.12741149615935532, 0.12741149615935532, 0.12741149615935532, 0.9615532381267232, 0.9615532381267232, 0.9615532381267232, 0.9678099545074065, 0.9678099545074065, 0.9678099545074065, 0.9503164811757431, 0.9503164811757431, 0.9503164811757431, 0.7675795002968544, 0.7675795002968544, 0.7675795002968544, 0.7387896707605585, 0.7387896707605585, 0.7387896707605585, 0.7592355931396266, 0.7592355931396266, 0.7592355931396266, 0.22678913189500005, 0.22678913189500005, 0.22678913189500005, 0.2727493794247199, 0.2727493794247199, 0.2727493794247199, 0.7983206451716187, 0.7983206451716187, 0.7983206451716187, 0.20790601487133775, 0.20790601487133775, 0.20790601487133775, 0.21312369101664108, 0.21312369101664108, 0.21312369101664108, 0.21507125591509269, 0.21507125591509269, 0.21507125591509269, 0.2263668823081142, 0.2263668823081142, 0.2263668823081142, 0.13191523075618383, 0.13191523075618383, 0.13191523075618383, 0.2331258481968469, 0.2331258481968469, 0.2331258481968469, 0.0749329951070491, 0.0749329951070491, 0.0749329951070491, 0.06977043745642386, 0.06977043745642386, 0.06977043745642386, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1165920900310965, 0.1165920900310965, 0.1165920900310965, 0.07915817832698269, 0.07915817832698269, 0.07915817832698269, 0.08673760062025615, 0.08673760062025615, 0.08673760062025615, 0.07566809106103922, 0.07566809106103922, 0.07566809106103922, 0.11026251680185761, 0.11026251680185761, 0.11026251680185761, 0.10016782254761913, 0.10016782254761913, 0.10016782254761913, 0.21918395241819766, 0.21918395241819766, 0.21918395241819766, 0.1688840882198942, 0.1688840882198942, 0.1688840882198942, 0.12283136463959143, 0.12283136463959143, 0.12283136463959143, 0.5578026086399024, 0.5578026086399024, 0.5578026086399024, 0.5561638415755004, 0.5561638415755004, 0.5561638415755004, 0.5761015556999625, 0.5761015556999625, 0.5761015556999625, 0.13763238844284953, 0.13763238844284953, 0.13763238844284953, 0.11720984529951384, 0.11720984529951384, 0.11720984529951384, 0.14871769542320257, 0.14871769542320257, 0.14871769542320257, 0.25503480023132086, 0.25503480023132086, 0.25503480023132086, 0.19044619867817159, 0.19044619867817159, 0.19044619867817159, 0.1617505928407128, 0.1617505928407128, 0.1617505928407128, 0.4996102734936637, 0.4996102734936637, 0.4996102734936637, 0.45932461170426697, 0.45932461170426697, 0.45932461170426697, 0.4142268205564872, 0.4142268205564872, 0.4142268205564872, 0.22197561793945497, 0.22197561793945497, 0.22197561793945497, 0.22977139044509098, 0.22977139044509098, 0.22977139044509098, 0.20714143109392946, 0.20714143109392946, 0.20714143109392946, 0.23694744407311108, 0.23694744407311108, 0.23694744407311108, 0.21985727164078572, 0.21985727164078572, 0.21985727164078572, 0.23177260725453153, 0.23177260725453153, 0.23177260725453153, 0.7557357528314819, 0.7557357528314819, 0.7557357528314819, 0.20465897880050843, 0.20465897880050843, 0.20465897880050843, 0.21495109455476602, 0.21495109455476602, 0.21495109455476602, 0.8729027395232072, 0.8729027395232072, 0.8729027395232072, 0.8316923274931387, 0.8316923274931387, 0.8316923274931387, 0.8778871918096451, 0.8778871918096451, 0.8778871918096451, 0.7859816875107983, 0.7859816875107983, 0.7859816875107983, 0.2048461764358881, 0.2048461764358881, 0.2048461764358881, 0.7039324221330823, 0.7039324221330823, 0.7039324221330823, 0.18818555793637648, 0.18818555793637648, 0.18818555793637648, 0.20788664897835873, 0.20788664897835873, 0.20788664897835873, 0.189059841382469, 0.189059841382469, 0.189059841382469, 0.08856672783722375, 0.08856672783722375, 0.08856672783722375, 0.08840142164853315, 0.08840142164853315, 0.08840142164853315, 0.08353887535924986, 0.08353887535924986, 0.08353887535924986]}, "mutation_prompt": null}
{"id": "8e051665-ebe9-4233-912e-160f0dabaa63", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.65  # Differential Evolution parameter, increased from 0.6 to 0.65\n        self.CR = 0.97  # Crossover probability, increased from 0.95 to 0.97\n        self.w = 0.36  # Inertia weight for PSO, increased from 0.35 to 0.36\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 1.5 + evaluations/self.budget * 1.2  # Adjusted cognitive coefficient dynamics\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhance global convergence by slightly increasing the inertia weight for PSO from 0.35 to 0.36.", "configspace": "", "generation": 98, "fitness": 0.37099687393623304, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.31.", "error": "", "parent_id": "19536b8f-0857-46fa-a73c-8c70435fa527", "metadata": {"aucs": [0.9009855245866576, 0.9009855245866576, 0.9009855245866576, 0.8869780511094173, 0.8869780511094173, 0.8869780511094173, 0.8947377409578042, 0.8947377409578042, 0.8947377409578042, 0.766501068185544, 0.766501068185544, 0.766501068185544, 0.7728750011508674, 0.7728750011508674, 0.7728750011508674, 0.7556583758511239, 0.7556583758511239, 0.7556583758511239, 0.669097667404195, 0.669097667404195, 0.669097667404195, 0.17544710400082242, 0.17544710400082242, 0.17544710400082242, 0.1124653250024279, 0.1124653250024279, 0.1124653250024279, 0.11160632598251685, 0.11160632598251685, 0.11160632598251685, 0.11233309308234296, 0.11233309308234296, 0.11233309308234296, 0.11224904319136553, 0.11224904319136553, 0.11224904319136553, 0.9629400049280205, 0.9629400049280205, 0.9629400049280205, 0.967855991815568, 0.967855991815568, 0.967855991815568, 0.9558292589638545, 0.9558292589638545, 0.9558292589638545, 0.7317213826251945, 0.7317213826251945, 0.7317213826251945, 0.7458451155333237, 0.7458451155333237, 0.7458451155333237, 0.7478507300329411, 0.7478507300329411, 0.7478507300329411, 0.22367656428890392, 0.22367656428890392, 0.22367656428890392, 0.8384985785458725, 0.8384985785458725, 0.8384985785458725, 0.8876411344346966, 0.8876411344346966, 0.8876411344346966, 0.19807933727982152, 0.19807933727982152, 0.19807933727982152, 0.1307859463014085, 0.1307859463014085, 0.1307859463014085, 0.2603797855845319, 0.2603797855845319, 0.2603797855845319, 0.21905872643005675, 0.21905872643005675, 0.21905872643005675, 0.2663541024946561, 0.2663541024946561, 0.2663541024946561, 0.25218114287303606, 0.25218114287303606, 0.25218114287303606, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03402208926083983, 0.03402208926083983, 0.03402208926083983, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.25785651834523304, 0.25785651834523304, 0.25785651834523304, 0.056980299895287634, 0.056980299895287634, 0.056980299895287634, 0.07763648065901985, 0.07763648065901985, 0.07763648065901985, 0.09399736080915577, 0.09399736080915577, 0.09399736080915577, 0.11429439012193465, 0.11429439012193465, 0.11429439012193465, 0.0939618338441589, 0.0939618338441589, 0.0939618338441589, 0.1627400931070766, 0.1627400931070766, 0.1627400931070766, 0.10836675009787611, 0.10836675009787611, 0.10836675009787611, 0.08192628008659153, 0.08192628008659153, 0.08192628008659153, 0.5360546189838116, 0.5360546189838116, 0.5360546189838116, 0.6153873888600736, 0.6153873888600736, 0.6153873888600736, 0.6018627023413465, 0.6018627023413465, 0.6018627023413465, 0.10488094171165063, 0.10488094171165063, 0.10488094171165063, 0.14985188529378413, 0.14985188529378413, 0.14985188529378413, 0.15405348308065292, 0.15405348308065292, 0.15405348308065292, 0.1741241333639416, 0.1741241333639416, 0.1741241333639416, 0.1655415711901611, 0.1655415711901611, 0.1655415711901611, 0.19234150999733046, 0.19234150999733046, 0.19234150999733046, 0.2484804968702875, 0.2484804968702875, 0.2484804968702875, 0.4434423348805201, 0.4434423348805201, 0.4434423348805201, 0.35587458776037406, 0.35587458776037406, 0.35587458776037406, 0.21788448766491342, 0.21788448766491342, 0.21788448766491342, 0.2808583346856678, 0.2808583346856678, 0.2808583346856678, 0.34961270257926025, 0.34961270257926025, 0.34961270257926025, 0.19934861669089676, 0.19934861669089676, 0.19934861669089676, 0.23575040534837854, 0.23575040534837854, 0.23575040534837854, 0.21134176462766663, 0.21134176462766663, 0.21134176462766663, 0.19932440460252643, 0.19932440460252643, 0.19932440460252643, 0.21960219162004957, 0.21960219162004957, 0.21960219162004957, 0.2207375135576991, 0.2207375135576991, 0.2207375135576991, 0.9039116034449328, 0.9039116034449328, 0.9039116034449328, 0.8256623868133623, 0.8256623868133623, 0.8256623868133623, 0.8898823434668156, 0.8898823434668156, 0.8898823434668156, 0.701506090019573, 0.701506090019573, 0.701506090019573, 0.20621585899542894, 0.20621585899542894, 0.20621585899542894, 0.6880144685798273, 0.6880144685798273, 0.6880144685798273, 0.19782744349458747, 0.19782744349458747, 0.19782744349458747, 0.18043256771624816, 0.18043256771624816, 0.18043256771624816, 0.18342038118268533, 0.18342038118268533, 0.18342038118268533, 0.10705110687324215, 0.10705110687324215, 0.10705110687324215, 0.08349525799135171, 0.08349525799135171, 0.08349525799135171, 0.1263851202555808, 0.1263851202555808, 0.1263851202555808]}, "mutation_prompt": null}
{"id": "e3aec6df-22c7-4513-a891-56dcc23e35f5", "solution": "import numpy as np\n\nclass AdaptiveHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20 + 3 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.68  # Differential Evolution parameter, increased from 0.65 to 0.68\n        self.CR = 0.97  # Crossover probability, increased from 0.95 to 0.97\n        self.w = 0.35  # Inertia weight for PSO, decreased from 0.4 to 0.35\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_pos = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in personal_best_pos])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_pos = personal_best_pos[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        evaluations = self.pop_size\n\n        while evaluations < self.budget:\n            # Differential Evolution Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                \n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                trial = np.copy(pop[i])\n                \n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == jrand:\n                        trial[j] = mutant[j]\n                        \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_pos[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_pos = trial\n                \n            # Particle Swarm Optimization Step\n            for i in range(self.pop_size):\n                if evaluations >= self.budget:\n                    break\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Modifying the cognitive and social coefficients with time-varying factors\n                self.c1 = 1.5 + evaluations/self.budget * 1.2  # Adjusted cognitive coefficient dynamics\n                self.c2 = 0.5 + evaluations/self.budget * 1.5\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_pos[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_pos - pop[i]))\n                pop[i] = pop[i] + velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n                \n                score = func(pop[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pop[i]\n                \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pop[i]\n        \n        return global_best_pos, global_best_score", "name": "AdaptiveHybridGA", "description": "Enhance exploration by slightly increasing the differential weight for DE from 0.65 to 0.68.", "configspace": "", "generation": 99, "fitness": 0.36686697074812114, "feedback": "The algorithm AdaptiveHybridGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.30.", "error": "", "parent_id": "19536b8f-0857-46fa-a73c-8c70435fa527", "metadata": {"aucs": [0.888059585951704, 0.888059585951704, 0.888059585951704, 0.8795692859936701, 0.8795692859936701, 0.8795692859936701, 0.8922332691990397, 0.8922332691990397, 0.8922332691990397, 0.7630798615413167, 0.7630798615413167, 0.7630798615413167, 0.7744183941909251, 0.7744183941909251, 0.7744183941909251, 0.7806869358733496, 0.7806869358733496, 0.7806869358733496, 0.6533410838187097, 0.6533410838187097, 0.6533410838187097, 0.1754889570023943, 0.1754889570023943, 0.1754889570023943, 0.1322249765151552, 0.1322249765151552, 0.1322249765151552, 0.10758583486211848, 0.10758583486211848, 0.10758583486211848, 0.1104097157305558, 0.1104097157305558, 0.1104097157305558, 0.12563696947785008, 0.12563696947785008, 0.12563696947785008, 0.9672180625837336, 0.9672180625837336, 0.9672180625837336, 0.9699675661960246, 0.9699675661960246, 0.9699675661960246, 0.9541760830902463, 0.9541760830902463, 0.9541760830902463, 0.7759084886886161, 0.7759084886886161, 0.7759084886886161, 0.7906241414171998, 0.7906241414171998, 0.7906241414171998, 0.7491802412105406, 0.7491802412105406, 0.7491802412105406, 0.4110200206205239, 0.4110200206205239, 0.4110200206205239, 0.8432511572189687, 0.8432511572189687, 0.8432511572189687, 0.8027653139144226, 0.8027653139144226, 0.8027653139144226, 0.2144473074941048, 0.2144473074941048, 0.2144473074941048, 0.22305330665696843, 0.22305330665696843, 0.22305330665696843, 0.22251764994451506, 0.22251764994451506, 0.22251764994451506, 0.20215044063713583, 0.20215044063713583, 0.20215044063713583, 0.2525329776044667, 0.2525329776044667, 0.2525329776044667, 0.24624568511222222, 0.24624568511222222, 0.24624568511222222, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09333745069752164, 0.09333745069752164, 0.09333745069752164, 0.0399962372731032, 0.0399962372731032, 0.0399962372731032, 0.13669937700995194, 0.13669937700995194, 0.13669937700995194, 0.06762762023056546, 0.06762762023056546, 0.06762762023056546, 0.07917990750459025, 0.07917990750459025, 0.07917990750459025, 0.10842270907815654, 0.10842270907815654, 0.10842270907815654, 0.1013383754196373, 0.1013383754196373, 0.1013383754196373, 0.09703809037863864, 0.09703809037863864, 0.09703809037863864, 0.13417217212495947, 0.13417217212495947, 0.13417217212495947, 0.12364354121568888, 0.12364354121568888, 0.12364354121568888, 0.1455403362505504, 0.1455403362505504, 0.1455403362505504, 0.5614326176667415, 0.5614326176667415, 0.5614326176667415, 0.5387298839981174, 0.5387298839981174, 0.5387298839981174, 0.6017843518621449, 0.6017843518621449, 0.6017843518621449, 0.17151592920827408, 0.17151592920827408, 0.17151592920827408, 0.14930918103922974, 0.14930918103922974, 0.14930918103922974, 0.13710028265671348, 0.13710028265671348, 0.13710028265671348, 0.15845834684329552, 0.15845834684329552, 0.15845834684329552, 0.21138318215617635, 0.21138318215617635, 0.21138318215617635, 0.1541946153001189, 0.1541946153001189, 0.1541946153001189, 0.33163866097037376, 0.33163866097037376, 0.33163866097037376, 0.6059730413424509, 0.6059730413424509, 0.6059730413424509, 0.5417700827934111, 0.5417700827934111, 0.5417700827934111, 0.22601931703813793, 0.22601931703813793, 0.22601931703813793, 0.26381118372027823, 0.26381118372027823, 0.26381118372027823, 0.22752168127401207, 0.22752168127401207, 0.22752168127401207, 0.2424816638048144, 0.2424816638048144, 0.2424816638048144, 0.2195093021457868, 0.2195093021457868, 0.2195093021457868, 0.2451711385491553, 0.2451711385491553, 0.2451711385491553, 0.20435940962243615, 0.20435940962243615, 0.20435940962243615, 0.22100337777799306, 0.22100337777799306, 0.22100337777799306, 0.2110967763887076, 0.2110967763887076, 0.2110967763887076, 0.8994670110856741, 0.8994670110856741, 0.8994670110856741, 0.19508784580962857, 0.19508784580962857, 0.19508784580962857, 0.8897267349637638, 0.8897267349637638, 0.8897267349637638, 0.8691015722263197, 0.8691015722263197, 0.8691015722263197, 0.2056909566611279, 0.2056909566611279, 0.2056909566611279, 0.16712408091453235, 0.16712408091453235, 0.16712408091453235, 0.20266419455186857, 0.20266419455186857, 0.20266419455186857, 0.20667276707828552, 0.20667276707828552, 0.20667276707828552, 0.22436042258123223, 0.22436042258123223, 0.22436042258123223, 0.10617922272029645, 0.10617922272029645, 0.10617922272029645, 0.09634547528853743, 0.09634547528853743, 0.09634547528853743, 0.09284845409524589, 0.09284845409524589, 0.09284845409524589]}, "mutation_prompt": null}

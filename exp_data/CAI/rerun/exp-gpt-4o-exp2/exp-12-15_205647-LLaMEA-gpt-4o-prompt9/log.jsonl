{"id": "b98bf557-af6c-46bf-96b0-4013466e39aa", "solution": "import numpy as np\n\nclass ADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate current positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n            \n            # Dynamic adjustment of coefficients\n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            # Update velocities and positions\n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "ADSA", "description": "Adaptive Dynamic Swarming Algorithm (ADSA) combines dynamic particle swarms with adaptive learning rates to efficiently explore and exploit the search space.", "configspace": "", "generation": 0, "fitness": 0.302456293687255, "feedback": "The algorithm ADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.25.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8134811636506802, 0.8134811636506802, 0.8134811636506802, 0.8318486863548685, 0.8318486863548685, 0.8318486863548685, 0.8157493676829822, 0.8157493676829822, 0.8157493676829822, 0.5027118338526819, 0.5027118338526819, 0.5027118338526819, 0.540191490277628, 0.540191490277628, 0.540191490277628, 0.5637384298464898, 0.5637384298464898, 0.5637384298464898, 0.2846339956010594, 0.2846339956010594, 0.2846339956010594, 0.16535101049894052, 0.16535101049894052, 0.16535101049894052, 0.19602645147897546, 0.19602645147897546, 0.19602645147897546, 0.1526404208876998, 0.1526404208876998, 0.1526404208876998, 0.14461960595842716, 0.14461960595842716, 0.14461960595842716, 0.1267611713451866, 0.1267611713451866, 0.1267611713451866, 0.9832742595358082, 0.9832742595358082, 0.9832742595358082, 0.9831159186431598, 0.9831159186431598, 0.9831159186431598, 0.9774428746949677, 0.9774428746949677, 0.9774428746949677, 0.47318520307629974, 0.47318520307629974, 0.47318520307629974, 0.5344814428805208, 0.5344814428805208, 0.5344814428805208, 0.5179665396379158, 0.5179665396379158, 0.5179665396379158, 0.7538205840604596, 0.7538205840604596, 0.7538205840604596, 0.1598855327703752, 0.1598855327703752, 0.1598855327703752, 0.2338771029326997, 0.2338771029326997, 0.2338771029326997, 0.1842697456893626, 0.1842697456893626, 0.1842697456893626, 0.19346011460087142, 0.19346011460087142, 0.19346011460087142, 0.1883833097931491, 0.1883833097931491, 0.1883833097931491, 0.19633113195307939, 0.19633113195307939, 0.19633113195307939, 0.2073228555584976, 0.2073228555584976, 0.2073228555584976, 0.1876053038958604, 0.1876053038958604, 0.1876053038958604, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0003321273054082141, 0.0003321273054082141, 0.0003321273054082141, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07386270996611621, 0.07386270996611621, 0.07386270996611621, 0.04568883988224004, 0.04568883988224004, 0.04568883988224004, 0.07388649528916236, 0.07388649528916236, 0.07388649528916236, 0.0456940516957145, 0.0456940516957145, 0.0456940516957145, 0.11998442329227998, 0.11998442329227998, 0.11998442329227998, 0.303683497909341, 0.303683497909341, 0.303683497909341, 0.10067180398730347, 0.10067180398730347, 0.10067180398730347, 0.037649734300729376, 0.037649734300729376, 0.037649734300729376, 0.08146867759139076, 0.08146867759139076, 0.08146867759139076, 0.5436084668841406, 0.5436084668841406, 0.5436084668841406, 0.5688450164176146, 0.5688450164176146, 0.5688450164176146, 0.5418918625227598, 0.5418918625227598, 0.5418918625227598, 0.1748858226111668, 0.1748858226111668, 0.1748858226111668, 0.1324790091316026, 0.1324790091316026, 0.1324790091316026, 0.141657102824838, 0.141657102824838, 0.141657102824838, 0.19723296846510308, 0.19723296846510308, 0.19723296846510308, 0.18335409921040668, 0.18335409921040668, 0.18335409921040668, 0.2776781789557524, 0.2776781789557524, 0.2776781789557524, 0.33814875708019976, 0.33814875708019976, 0.33814875708019976, 0.37152696491490755, 0.37152696491490755, 0.37152696491490755, 0.4132973389650213, 0.4132973389650213, 0.4132973389650213, 0.15665781842923876, 0.15665781842923876, 0.15665781842923876, 0.21742041264788026, 0.21742041264788026, 0.21742041264788026, 0.23205847626239062, 0.23205847626239062, 0.23205847626239062, 0.23164163891845768, 0.23164163891845768, 0.23164163891845768, 0.2083743605946332, 0.2083743605946332, 0.2083743605946332, 0.22537627241347102, 0.22537627241347102, 0.22537627241347102, 0.21305827965963353, 0.21305827965963353, 0.21305827965963353, 0.19609925940138195, 0.19609925940138195, 0.19609925940138195, 0.447753350959495, 0.447753350959495, 0.447753350959495, 0.8618797989728315, 0.8618797989728315, 0.8618797989728315, 0.15766759920469198, 0.15766759920469198, 0.15766759920469198, 0.16835877658729514, 0.16835877658729514, 0.16835877658729514, 0.21088073511191074, 0.21088073511191074, 0.21088073511191074, 0.21213896923879838, 0.21213896923879838, 0.21213896923879838, 0.4904619256244487, 0.4904619256244487, 0.4904619256244487, 0.21142470559139515, 0.21142470559139515, 0.21142470559139515, 0.1730999355403786, 0.1730999355403786, 0.1730999355403786, 0.21597167787975735, 0.21597167787975735, 0.21597167787975735, 0.08729611852502184, 0.08729611852502184, 0.08729611852502184, 0.0827836872900023, 0.0827836872900023, 0.0827836872900023, 0.09654585026740448, 0.09654585026740448, 0.09654585026740448]}, "mutation_prompt": null}
{"id": "8d1e34f8-9365-4923-99f7-9d6750319ab5", "solution": "import numpy as np\n\nclass ADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Evaluate current positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n            \n            # Adaptive inertia weight\n            inertia_weight = self.inertia_weight_initial - (self.inertia_weight_initial - self.inertia_weight_final) * (eval_count / self.budget)\n\n            # Dynamic adjustment of coefficients\n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            # Update velocities and positions\n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (inertia_weight * velocities + cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "ADSA", "description": "Enhanced ADSA with adaptive inertia weight for improved convergence rate.", "configspace": "", "generation": 1, "fitness": 0.27141240332627514, "feedback": "The algorithm ADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.24.", "error": "", "parent_id": "b98bf557-af6c-46bf-96b0-4013466e39aa", "metadata": {"aucs": [0.7312796657038932, 0.7312796657038932, 0.7312796657038932, 0.7593392452123575, 0.7593392452123575, 0.7593392452123575, 0.7164404792450423, 0.7164404792450423, 0.7164404792450423, 0.3890433263093882, 0.3890433263093882, 0.3890433263093882, 0.4498100278856829, 0.4498100278856829, 0.4498100278856829, 0.3573451117797608, 0.3573451117797608, 0.3573451117797608, 0.13863250863968057, 0.13863250863968057, 0.13863250863968057, 0.16021579654019003, 0.16021579654019003, 0.16021579654019003, 0.16056505643681507, 0.16056505643681507, 0.16056505643681507, 0.1224738023378924, 0.1224738023378924, 0.1224738023378924, 0.136625962081229, 0.136625962081229, 0.136625962081229, 0.1179038238264074, 0.1179038238264074, 0.1179038238264074, 0.9835426132153212, 0.9835426132153212, 0.9835426132153212, 0.9831892134844558, 0.9831892134844558, 0.9831892134844558, 0.9806689849315061, 0.9806689849315061, 0.9806689849315061, 0.4597521978181993, 0.4597521978181993, 0.4597521978181993, 0.46524292123244915, 0.46524292123244915, 0.46524292123244915, 0.4861747023398467, 0.4861747023398467, 0.4861747023398467, 0.6890097495717106, 0.6890097495717106, 0.6890097495717106, 0.1780192218072736, 0.1780192218072736, 0.1780192218072736, 0.18045293930622486, 0.18045293930622486, 0.18045293930622486, 0.16779419974623344, 0.16779419974623344, 0.16779419974623344, 0.12620412526422042, 0.12620412526422042, 0.12620412526422042, 0.17870799906848933, 0.17870799906848933, 0.17870799906848933, 0.20832269965899752, 0.20832269965899752, 0.20832269965899752, 0.1122699643749262, 0.1122699643749262, 0.1122699643749262, 0.18767818954817939, 0.18767818954817939, 0.18767818954817939, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08165596039979517, 0.08165596039979517, 0.08165596039979517, 0.022303288582060432, 0.022303288582060432, 0.022303288582060432, 0.06129522924761621, 0.06129522924761621, 0.06129522924761621, 0.09539190475098058, 0.09539190475098058, 0.09539190475098058, 0.05635062689621917, 0.05635062689621917, 0.05635062689621917, 0.15344468785734877, 0.15344468785734877, 0.15344468785734877, 0.08639489199210915, 0.08639489199210915, 0.08639489199210915, 0.036093456214086994, 0.036093456214086994, 0.036093456214086994, 0.07523004015169932, 0.07523004015169932, 0.07523004015169932, 0.4744200470392529, 0.4744200470392529, 0.4744200470392529, 0.4516685242522709, 0.4516685242522709, 0.4516685242522709, 0.5019741281348391, 0.5019741281348391, 0.5019741281348391, 0.14885573117768458, 0.14885573117768458, 0.14885573117768458, 0.11197927779112238, 0.11197927779112238, 0.11197927779112238, 0.10954859320005539, 0.10954859320005539, 0.10954859320005539, 0.21588408951235094, 0.21588408951235094, 0.21588408951235094, 0.20356742129550398, 0.20356742129550398, 0.20356742129550398, 0.25280376722236064, 0.25280376722236064, 0.25280376722236064, 0.3039766511935008, 0.3039766511935008, 0.3039766511935008, 0.33184404296174275, 0.33184404296174275, 0.33184404296174275, 0.31614045306246197, 0.31614045306246197, 0.31614045306246197, 0.20261999170031786, 0.20261999170031786, 0.20261999170031786, 0.2791314528584117, 0.2791314528584117, 0.2791314528584117, 0.11811342819277981, 0.11811342819277981, 0.11811342819277981, 0.23036764874789117, 0.23036764874789117, 0.23036764874789117, 0.21274803149969834, 0.21274803149969834, 0.21274803149969834, 0.1997898276557527, 0.1997898276557527, 0.1997898276557527, 0.23931840549140504, 0.23931840549140504, 0.23931840549140504, 0.2020111615949468, 0.2020111615949468, 0.2020111615949468, 0.5402447636610552, 0.5402447636610552, 0.5402447636610552, 0.77989606489914, 0.77989606489914, 0.77989606489914, 0.15695225683786052, 0.15695225683786052, 0.15695225683786052, 0.16796812606598266, 0.16796812606598266, 0.16796812606598266, 0.16097925496202448, 0.16097925496202448, 0.16097925496202448, 0.2109535184207908, 0.2109535184207908, 0.2109535184207908, 0.24338549276926946, 0.24338549276926946, 0.24338549276926946, 0.186489149996528, 0.186489149996528, 0.186489149996528, 0.19683202161681634, 0.19683202161681634, 0.19683202161681634, 0.1907616316819818, 0.1907616316819818, 0.1907616316819818, 0.08910250482809079, 0.08910250482809079, 0.08910250482809079, 0.08363655939916148, 0.08363655939916148, 0.08363655939916148, 0.13256440631046829, 0.13256440631046829, 0.13256440631046829]}, "mutation_prompt": null}
{"id": "31896dc8-27b9-4908-8d5a-2cb390bb1b1e", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            # Evaluate current positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            # Adjust inertia weight based on improvement\n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)\n            \n            # Dynamic adjustment of coefficients\n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            # Update velocities and positions\n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Enhanced ADSA with adaptive inertia and convergence monitoring for improved exploration and convergence speed.", "configspace": "", "generation": 2, "fitness": 0.3124328397261319, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.26.", "error": "", "parent_id": "b98bf557-af6c-46bf-96b0-4013466e39aa", "metadata": {"aucs": [0.8466774834531997, 0.8466774834531997, 0.8466774834531997, 0.8573684385097167, 0.8573684385097167, 0.8573684385097167, 0.8442539939926887, 0.8442539939926887, 0.8442539939926887, 0.6549805549271507, 0.6549805549271507, 0.6549805549271507, 0.6551998348480856, 0.6551998348480856, 0.6551998348480856, 0.0178308073273713, 0.0178308073273713, 0.0178308073273713, 0.4791430056959124, 0.4791430056959124, 0.4791430056959124, 0.18145196603327918, 0.18145196603327918, 0.18145196603327918, 0.5843425857575806, 0.5843425857575806, 0.5843425857575806, 0.12675905301694224, 0.12675905301694224, 0.12675905301694224, 0.11683865561961626, 0.11683865561961626, 0.11683865561961626, 0.12540245741641998, 0.12540245741641998, 0.12540245741641998, 0.9832742595358082, 0.9832742595358082, 0.9832742595358082, 0.9831159186431598, 0.9831159186431598, 0.9831159186431598, 0.9774428746949677, 0.9774428746949677, 0.9774428746949677, 0.6210253400436211, 0.6210253400436211, 0.6210253400436211, 0.6235599536079135, 0.6235599536079135, 0.6235599536079135, 0.6725718941508352, 0.6725718941508352, 0.6725718941508352, 0.21949014499811215, 0.21949014499811215, 0.21949014499811215, 0.1598855327703752, 0.1598855327703752, 0.1598855327703752, 0.23317785422128368, 0.23317785422128368, 0.23317785422128368, 0.19650759395393436, 0.19650759395393436, 0.19650759395393436, 0.20018461938963705, 0.20018461938963705, 0.20018461938963705, 0.21652850797796874, 0.21652850797796874, 0.21652850797796874, 0.22485184367151323, 0.22485184367151323, 0.22485184367151323, 0.3685932956700644, 0.3685932956700644, 0.3685932956700644, 0.23877793265799885, 0.23877793265799885, 0.23877793265799885, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09040344171813486, 0.09040344171813486, 0.09040344171813486, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07681880809356212, 0.07681880809356212, 0.07681880809356212, 0.04385112045397532, 0.04385112045397532, 0.04385112045397532, 0.10299293442114299, 0.10299293442114299, 0.10299293442114299, 0.06846312635414886, 0.06846312635414886, 0.06846312635414886, 0.12196719483274088, 0.12196719483274088, 0.12196719483274088, 0.27602851383308935, 0.27602851383308935, 0.27602851383308935, 0.08943505798615092, 0.08943505798615092, 0.08943505798615092, 0.03807988697150777, 0.03807988697150777, 0.03807988697150777, 0.08196268662712358, 0.08196268662712358, 0.08196268662712358, 0.5760039394430045, 0.5760039394430045, 0.5760039394430045, 0.5606893048058681, 0.5606893048058681, 0.5606893048058681, 0.5551888377363007, 0.5551888377363007, 0.5551888377363007, 0.15690974783382738, 0.15690974783382738, 0.15690974783382738, 0.14903988439971705, 0.14903988439971705, 0.14903988439971705, 0.12041502609387644, 0.12041502609387644, 0.12041502609387644, 0.24154714324122883, 0.24154714324122883, 0.24154714324122883, 0.19145734054629815, 0.19145734054629815, 0.19145734054629815, 0.3102950370651425, 0.3102950370651425, 0.3102950370651425, 0.4301734022396698, 0.4301734022396698, 0.4301734022396698, 0.2900961728714673, 0.2900961728714673, 0.2900961728714673, 0.42545164289824977, 0.42545164289824977, 0.42545164289824977, 0.15600832605418147, 0.15600832605418147, 0.15600832605418147, 0.1847223643051592, 0.1847223643051592, 0.1847223643051592, 0.14655999800643926, 0.14655999800643926, 0.14655999800643926, 0.21328157168356454, 0.21328157168356454, 0.21328157168356454, 0.23472514603932593, 0.23472514603932593, 0.23472514603932593, 0.24812600994796874, 0.24812600994796874, 0.24812600994796874, 0.2042020011311182, 0.2042020011311182, 0.2042020011311182, 0.22673213028378292, 0.22673213028378292, 0.22673213028378292, 0.22750561081050646, 0.22750561081050646, 0.22750561081050646, 0.914770691753632, 0.914770691753632, 0.914770691753632, 0.1576506402026806, 0.1576506402026806, 0.1576506402026806, 0.1683834897775408, 0.1683834897775408, 0.1683834897775408, 0.21093967554669923, 0.21093967554669923, 0.21093967554669923, 0.212211320704503, 0.212211320704503, 0.212211320704503, 0.6510969369659961, 0.6510969369659961, 0.6510969369659961, 0.21783588287313882, 0.21783588287313882, 0.21783588287313882, 0.1875585852326236, 0.1875585852326236, 0.1875585852326236, 0.1956153670699049, 0.1956153670699049, 0.1956153670699049, 0.10095186357656816, 0.10095186357656816, 0.10095186357656816, 0.08757775841765436, 0.08757775841765436, 0.08757775841765436, 0.14200243684712444, 0.14200243684712444, 0.14200243684712444]}, "mutation_prompt": null}
{"id": "d72eaa72-185b-4041-9011-c03ae897f0ee", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, budget // 10)\n        self.population_size = self.initial_population_size\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            # Evaluate current positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            # Adjust inertia weight based on stochastic factor\n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * (0.98 + 0.04 * np.random.rand()))\n            \n            # Dynamic adjustment of coefficients\n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            # Dynamic resizing of population\n            if eval_count > self.budget * 0.5:\n                self.population_size = max(self.initial_population_size // 2, 10)\n            \n            # Update velocities and positions\n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "EnhancedADSA with dynamic population resizing and stochastic inertia adjustment for improved convergence speed.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (25,5) (50,5) ').", "error": "ValueError('operands could not be broadcast together with shapes (25,5) (50,5) ')", "parent_id": "31896dc8-27b9-4908-8d5a-2cb390bb1b1e", "metadata": {}, "mutation_prompt": null}
{"id": "5c62c17e-3179-4c37-8d3e-342f7a143292", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.5 + np.random.rand() * 0.5  # Randomized inertia for diversification\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.de_mutation_factor = 0.8\n        self.de_crossover_prob = 0.7\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            # Evaluate current positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            # Dynamic adjustment of inertia weight\n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.1, self.inertia_weight * 0.95)\n            \n            # Dynamic adjustment of coefficients\n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            # Hybrid PSO and DE update\n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            \n            de_indices = np.random.choice(self.population_size, size=(self.population_size, 3), replace=False)\n            de_mutant_vectors = (positions[de_indices[:, 0]] +\n                                 self.de_mutation_factor * (positions[de_indices[:, 1]] - positions[de_indices[:, 2]]))\n            \n            de_cross_mask = np.random.rand(self.population_size, self.dim) < self.de_crossover_prob\n            positions = np.where(de_cross_mask, de_mutant_vectors, positions + velocities)\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Hybrid Particle Swarm Optimization with Adaptive Differential Evolution for enhanced convergence through dynamic search strategies.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_id": "31896dc8-27b9-4908-8d5a-2cb390bb1b1e", "metadata": {}, "mutation_prompt": null}
{"id": "03113eb4-51bc-4317-a3cd-266686b1beb3", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.success_threshold = 0.1  # New parameter for success-based adaptation\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            # Evaluate current positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            # Adjust inertia weight and coefficients based on improvement\n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)\n                if (global_best_score - scores[min_score_idx]) / max(np.abs(global_best_score), 1e-9) < self.success_threshold:\n                    self.cognitive_coef *= 1.02\n                    self.social_coef *= 0.98\n            \n            # Dynamic adjustment of coefficients\n            self.cognitive_coef = max(1.2, min(1.7, self.cognitive_coef))\n            self.social_coef = max(1.2, min(1.7, self.social_coef))\n            \n            # Update velocities and positions\n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Enhanced inertia and coefficient adaptation using success-based strategy for accelerated convergence.", "configspace": "", "generation": 5, "fitness": 0.29329900044190915, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.27.", "error": "", "parent_id": "31896dc8-27b9-4908-8d5a-2cb390bb1b1e", "metadata": {"aucs": [0.8551349769200907, 0.8551349769200907, 0.8551349769200907, 0.8382575347068275, 0.8382575347068275, 0.8382575347068275, 0.8457072827800719, 0.8457072827800719, 0.8457072827800719, 0.038502218787018094, 0.038502218787018094, 0.038502218787018094, 0.6251729807657506, 0.6251729807657506, 0.6251729807657506, 0.6368643756940588, 0.6368643756940588, 0.6368643756940588, 0.14982354193621683, 0.14982354193621683, 0.14982354193621683, 0.14629500896335634, 0.14629500896335634, 0.14629500896335634, 0.17884147264098738, 0.17884147264098738, 0.17884147264098738, 0.13840951511474964, 0.13840951511474964, 0.13840951511474964, 0.11014055447028803, 0.11014055447028803, 0.11014055447028803, 0.11383501905804083, 0.11383501905804083, 0.11383501905804083, 0.9851402313042281, 0.9851402313042281, 0.9851402313042281, 0.9861233168252972, 0.9861233168252972, 0.9861233168252972, 0.9854193954986934, 0.9854193954986934, 0.9854193954986934, 0.7044066104297124, 0.7044066104297124, 0.7044066104297124, 0.6807822234797288, 0.6807822234797288, 0.6807822234797288, 0.675307193168142, 0.675307193168142, 0.675307193168142, 0.13986694564068114, 0.13986694564068114, 0.13986694564068114, 0.1611533152270178, 0.1611533152270178, 0.1611533152270178, 0.2419809261334681, 0.2419809261334681, 0.2419809261334681, 0.21788151962288416, 0.21788151962288416, 0.21788151962288416, 0.13182419663658562, 0.13182419663658562, 0.13182419663658562, 0.21027154076738508, 0.21027154076738508, 0.21027154076738508, 0.21284492439480995, 0.21284492439480995, 0.21284492439480995, 0.21814894882862312, 0.21814894882862312, 0.21814894882862312, 0.24270390119873841, 0.24270390119873841, 0.24270390119873841, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02317344265516763, 0.02317344265516763, 0.02317344265516763, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07509668814944415, 0.07509668814944415, 0.07509668814944415, 0.016485442996942545, 0.016485442996942545, 0.016485442996942545, 0.04655450229716063, 0.04655450229716063, 0.04655450229716063, 0.04792176275468807, 0.04792176275468807, 0.04792176275468807, 0.10833973814824438, 0.10833973814824438, 0.10833973814824438, 0.09505698431296294, 0.09505698431296294, 0.09505698431296294, 0.14652161380751716, 0.14652161380751716, 0.14652161380751716, 0.0383148895368991, 0.0383148895368991, 0.0383148895368991, 0.07988118544802669, 0.07988118544802669, 0.07988118544802669, 0.5298711974360606, 0.5298711974360606, 0.5298711974360606, 0.5481962709291135, 0.5481962709291135, 0.5481962709291135, 0.573193252476554, 0.573193252476554, 0.573193252476554, 0.14020745324913186, 0.14020745324913186, 0.14020745324913186, 0.1521418464267299, 0.1521418464267299, 0.1521418464267299, 0.08610336283056708, 0.08610336283056708, 0.08610336283056708, 0.21137017453976203, 0.21137017453976203, 0.21137017453976203, 0.2695166414196948, 0.2695166414196948, 0.2695166414196948, 0.20235575226464608, 0.20235575226464608, 0.20235575226464608, 0.35880053741259266, 0.35880053741259266, 0.35880053741259266, 0.43425131354152247, 0.43425131354152247, 0.43425131354152247, 0.5520300514440679, 0.5520300514440679, 0.5520300514440679, 0.265040465817705, 0.265040465817705, 0.265040465817705, 0.34218787171545173, 0.34218787171545173, 0.34218787171545173, 0.17875038414528321, 0.17875038414528321, 0.17875038414528321, 0.2895555757394648, 0.2895555757394648, 0.2895555757394648, 0.25466328797006654, 0.25466328797006654, 0.25466328797006654, 0.20235482350325162, 0.20235482350325162, 0.20235482350325162, 0.2222522811699429, 0.2222522811699429, 0.2222522811699429, 0.24631137695417005, 0.24631137695417005, 0.24631137695417005, 0.233180036713328, 0.233180036713328, 0.233180036713328, 0.8971669660741711, 0.8971669660741711, 0.8971669660741711, 0.1581240872695695, 0.1581240872695695, 0.1581240872695695, 0.17001323257649714, 0.17001323257649714, 0.17001323257649714, 0.16030367693279945, 0.16030367693279945, 0.16030367693279945, 0.21256254495081184, 0.21256254495081184, 0.21256254495081184, 0.1554063752697582, 0.1554063752697582, 0.1554063752697582, 0.19573970687144981, 0.19573970687144981, 0.19573970687144981, 0.22168220958424623, 0.22168220958424623, 0.22168220958424623, 0.20704595427955685, 0.20704595427955685, 0.20704595427955685, 0.09816293242751839, 0.09816293242751839, 0.09816293242751839, 0.0997955119999635, 0.0997955119999635, 0.0997955119999635, 0.10080495478150275, 0.10080495478150275, 0.10080495478150275]}, "mutation_prompt": null}
{"id": "e7c3edd3-a75c-4ba3-b1f0-cba98e0c2b3e", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.1  # New adaptive learning rate\n        self.momentum = 0.9       # Incorporates momentum\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            # Evaluate current positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            # Adjust inertia weight based on improvement\n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)\n            \n            # Dynamic adjustment of coefficients\n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            # Update velocities and positions with momentum and learning rate\n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Enhanced ADSA with adaptive learning rates and momentum for improved convergence and exploration balance.", "configspace": "", "generation": 6, "fitness": 0.33509349039960096, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.28.", "error": "", "parent_id": "31896dc8-27b9-4908-8d5a-2cb390bb1b1e", "metadata": {"aucs": [0.8694833664033087, 0.8694833664033087, 0.8694833664033087, 0.8697615568149442, 0.8697615568149442, 0.8697615568149442, 0.8689349864838745, 0.8689349864838745, 0.8689349864838745, 0.6926654620684354, 0.6926654620684354, 0.6926654620684354, 0.7376838952142948, 0.7376838952142948, 0.7376838952142948, 0.7491367033850843, 0.7491367033850843, 0.7491367033850843, 0.14440426869739387, 0.14440426869739387, 0.14440426869739387, 0.17774529834574804, 0.17774529834574804, 0.17774529834574804, 0.5042974139297127, 0.5042974139297127, 0.5042974139297127, 0.11564675010071956, 0.11564675010071956, 0.11564675010071956, 0.14486071210028473, 0.14486071210028473, 0.14486071210028473, 0.1340345260073651, 0.1340345260073651, 0.1340345260073651, 0.9800550200959466, 0.9800550200959466, 0.9800550200959466, 0.9796950402729983, 0.9796950402729983, 0.9796950402729983, 0.977047082586043, 0.977047082586043, 0.977047082586043, 0.687950039382897, 0.687950039382897, 0.687950039382897, 0.664668484772114, 0.664668484772114, 0.664668484772114, 0.6773929691294454, 0.6773929691294454, 0.6773929691294454, 0.3756645703237457, 0.3756645703237457, 0.3756645703237457, 0.2097841501503619, 0.2097841501503619, 0.2097841501503619, 0.1720538274348159, 0.1720538274348159, 0.1720538274348159, 0.21074455977176454, 0.21074455977176454, 0.21074455977176454, 0.13170287226039856, 0.13170287226039856, 0.13170287226039856, 0.20743445279459227, 0.20743445279459227, 0.20743445279459227, 0.2335803312835386, 0.2335803312835386, 0.2335803312835386, 0.22257532840655958, 0.22257532840655958, 0.22257532840655958, 0.25612772572207854, 0.25612772572207854, 0.25612772572207854, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04638542162628034, 0.04638542162628034, 0.04638542162628034, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.058673253779398915, 0.058673253779398915, 0.058673253779398915, 0.018059767479094435, 0.018059767479094435, 0.018059767479094435, 0.08785591692218908, 0.08785591692218908, 0.08785591692218908, 0.06086924645572511, 0.06086924645572511, 0.06086924645572511, 0.16296703314885708, 0.16296703314885708, 0.16296703314885708, 0.22092493158171322, 0.22092493158171322, 0.22092493158171322, 0.22015196146300375, 0.22015196146300375, 0.22015196146300375, 0.03910936091752415, 0.03910936091752415, 0.03910936091752415, 0.08381805517613938, 0.08381805517613938, 0.08381805517613938, 0.5238774034271062, 0.5238774034271062, 0.5238774034271062, 0.5393163239881251, 0.5393163239881251, 0.5393163239881251, 0.5417201715580249, 0.5417201715580249, 0.5417201715580249, 0.14035032304868367, 0.14035032304868367, 0.14035032304868367, 0.12977755083033593, 0.12977755083033593, 0.12977755083033593, 0.15427676313409178, 0.15427676313409178, 0.15427676313409178, 0.5007031100948048, 0.5007031100948048, 0.5007031100948048, 0.22496327622556023, 0.22496327622556023, 0.22496327622556023, 0.3371832444577504, 0.3371832444577504, 0.3371832444577504, 0.2985610484407475, 0.2985610484407475, 0.2985610484407475, 0.3173519331580671, 0.3173519331580671, 0.3173519331580671, 0.443284117775563, 0.443284117775563, 0.443284117775563, 0.22302069699126814, 0.22302069699126814, 0.22302069699126814, 0.2547737096741174, 0.2547737096741174, 0.2547737096741174, 0.14265922720474955, 0.14265922720474955, 0.14265922720474955, 0.22318683698099773, 0.22318683698099773, 0.22318683698099773, 0.21850995676670215, 0.21850995676670215, 0.21850995676670215, 0.26526565117731704, 0.26526565117731704, 0.26526565117731704, 0.7823078049827076, 0.7823078049827076, 0.7823078049827076, 0.2236636996716045, 0.2236636996716045, 0.2236636996716045, 0.2085545584654407, 0.2085545584654407, 0.2085545584654407, 0.9183469803730785, 0.9183469803730785, 0.9183469803730785, 0.1580387720275257, 0.1580387720275257, 0.1580387720275257, 0.16872272803788346, 0.16872272803788346, 0.16872272803788346, 0.2110026895378635, 0.2110026895378635, 0.2110026895378635, 0.2121207134011911, 0.2121207134011911, 0.2121207134011911, 0.8252049675660784, 0.8252049675660784, 0.8252049675660784, 0.19530796741907275, 0.19530796741907275, 0.19530796741907275, 0.20440662944203547, 0.20440662944203547, 0.20440662944203547, 0.18931242277281768, 0.18931242277281768, 0.18931242277281768, 0.11296153678997511, 0.11296153678997511, 0.11296153678997511, 0.10084694462007415, 0.10084694462007415, 0.10084694462007415, 0.14300520624151358, 0.14300520624151358, 0.14300520624151358]}, "mutation_prompt": null}
{"id": "19db730d-9b2f-4777-81a5-35555bb21a9c", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 8)  # Dynamic population size adjustment\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.1\n        self.momentum = 0.9\n        self.noise_reduction_factor = 0.99  # New noise reduction strategy\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * self.noise_reduction_factor)\n            \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Enhanced ADSA with adaptive noise reduction strategy and dynamic population size for improved convergence speed.", "configspace": "", "generation": 7, "fitness": 0.32177050601001483, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.27.", "error": "", "parent_id": "e7c3edd3-a75c-4ba3-b1f0-cba98e0c2b3e", "metadata": {"aucs": [0.8692102898181768, 0.8692102898181768, 0.8692102898181768, 0.8589807820076203, 0.8589807820076203, 0.8589807820076203, 0.8638435124968378, 0.8638435124968378, 0.8638435124968378, 0.7122142232497775, 0.7122142232497775, 0.7122142232497775, 0.6477781705014445, 0.6477781705014445, 0.6477781705014445, 0.7157337183842901, 0.7157337183842901, 0.7157337183842901, 0.16938910957562425, 0.16938910957562425, 0.16938910957562425, 0.1552153992948221, 0.1552153992948221, 0.1552153992948221, 0.1520281899709024, 0.1520281899709024, 0.1520281899709024, 0.11529066584629111, 0.11529066584629111, 0.11529066584629111, 0.11160249039828796, 0.11160249039828796, 0.11160249039828796, 0.12483413111486952, 0.12483413111486952, 0.12483413111486952, 0.9800550200959466, 0.9800550200959466, 0.9800550200959466, 0.9796950402729983, 0.9796950402729983, 0.9796950402729983, 0.977047082586043, 0.977047082586043, 0.977047082586043, 0.6831053461318803, 0.6831053461318803, 0.6831053461318803, 0.6712166591968828, 0.6712166591968828, 0.6712166591968828, 0.6694237735919386, 0.6694237735919386, 0.6694237735919386, 0.22176994130026617, 0.22176994130026617, 0.22176994130026617, 0.20992636450252133, 0.20992636450252133, 0.20992636450252133, 0.14996779338283728, 0.14996779338283728, 0.14996779338283728, 0.2169727416201811, 0.2169727416201811, 0.2169727416201811, 0.18899338817668754, 0.18899338817668754, 0.18899338817668754, 0.21249235128079114, 0.21249235128079114, 0.21249235128079114, 0.23623457435487294, 0.23623457435487294, 0.23623457435487294, 0.22782863919501073, 0.22782863919501073, 0.22782863919501073, 0.2354299649413265, 0.2354299649413265, 0.2354299649413265, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10845656605840703, 0.10845656605840703, 0.10845656605840703, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09695177891076967, 0.09695177891076967, 0.09695177891076967, 0.025636129992089418, 0.025636129992089418, 0.025636129992089418, 0.1397479196729039, 0.1397479196729039, 0.1397479196729039, 0.058759162750290805, 0.058759162750290805, 0.058759162750290805, 0.17769629593981795, 0.17769629593981795, 0.17769629593981795, 0.18026501465076705, 0.18026501465076705, 0.18026501465076705, 0.1762527157280085, 0.1762527157280085, 0.1762527157280085, 0.03909172005186756, 0.03909172005186756, 0.03909172005186756, 0.08366231843849148, 0.08366231843849148, 0.08366231843849148, 0.5280229110308713, 0.5280229110308713, 0.5280229110308713, 0.587057086606382, 0.587057086606382, 0.587057086606382, 0.5564184199502111, 0.5564184199502111, 0.5564184199502111, 0.14385453537082815, 0.14385453537082815, 0.14385453537082815, 0.09538838885603962, 0.09538838885603962, 0.09538838885603962, 0.11268781381744153, 0.11268781381744153, 0.11268781381744153, 0.45747375754696606, 0.45747375754696606, 0.45747375754696606, 0.4312916042376692, 0.4312916042376692, 0.4312916042376692, 0.2281762901100849, 0.2281762901100849, 0.2281762901100849, 0.43296630028483074, 0.43296630028483074, 0.43296630028483074, 0.38704770931839017, 0.38704770931839017, 0.38704770931839017, 0.4138332832444698, 0.4138332832444698, 0.4138332832444698, 0.2712322484315375, 0.2712322484315375, 0.2712322484315375, 0.21886730702363422, 0.21886730702363422, 0.21886730702363422, 0.14167938331425012, 0.14167938331425012, 0.14167938331425012, 0.21360430397788988, 0.21360430397788988, 0.21360430397788988, 0.272855884888613, 0.272855884888613, 0.272855884888613, 0.20010071758214, 0.20010071758214, 0.20010071758214, 0.21537623817763019, 0.21537623817763019, 0.21537623817763019, 0.22292806236132834, 0.22292806236132834, 0.22292806236132834, 0.18775816057425432, 0.18775816057425432, 0.18775816057425432, 0.9211704271548821, 0.9211704271548821, 0.9211704271548821, 0.1580323932916614, 0.1580323932916614, 0.1580323932916614, 0.16872029789623266, 0.16872029789623266, 0.16872029789623266, 0.21091071787151805, 0.21091071787151805, 0.21091071787151805, 0.21216488906020736, 0.21216488906020736, 0.21216488906020736, 0.7980610128836961, 0.7980610128836961, 0.7980610128836961, 0.21128512801718935, 0.21128512801718935, 0.21128512801718935, 0.19805993188546533, 0.19805993188546533, 0.19805993188546533, 0.21294228021627593, 0.21294228021627593, 0.21294228021627593, 0.11273717681518369, 0.11273717681518369, 0.11273717681518369, 0.08613583382187262, 0.08613583382187262, 0.08613583382187262, 0.11563695161888632, 0.11563695161888632, 0.11563695161888632]}, "mutation_prompt": null}
{"id": "5275ecab-17ea-4cf7-9cb4-c0f8b00ffee7", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.1\n        self.momentum = 0.9\n        self.mutation_probability = 0.05  # New mutation probability\n        self.mutation_scale = 0.1         # New mutation scale\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)\n            \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n\n            # Apply mutation operator\n            mutation_mask = np.random.rand(self.population_size, self.dim) < self.mutation_probability\n            positions += mutation_mask * np.random.normal(0, self.mutation_scale, (self.population_size, self.dim))\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Enhanced ADSA with dynamic self-adaptive mutation to improve exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.3004693637893899, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.25.", "error": "", "parent_id": "e7c3edd3-a75c-4ba3-b1f0-cba98e0c2b3e", "metadata": {"aucs": [0.8234881714020013, 0.8234881714020013, 0.8234881714020013, 0.8339469311111729, 0.8339469311111729, 0.8339469311111729, 0.8082898207758381, 0.8082898207758381, 0.8082898207758381, 0.4828768464088271, 0.4828768464088271, 0.4828768464088271, 0.4920955854109167, 0.4920955854109167, 0.4920955854109167, 0.4572237831690462, 0.4572237831690462, 0.4572237831690462, 0.25378745255699153, 0.25378745255699153, 0.25378745255699153, 0.17717994800379333, 0.17717994800379333, 0.17717994800379333, 0.1007123536989395, 0.1007123536989395, 0.1007123536989395, 0.11817762071360649, 0.11817762071360649, 0.11817762071360649, 0.09732904939666243, 0.09732904939666243, 0.09732904939666243, 0.13152622847441453, 0.13152622847441453, 0.13152622847441453, 0.9832246927186691, 0.9832246927186691, 0.9832246927186691, 0.9775062930102231, 0.9775062930102231, 0.9775062930102231, 0.9703331201969181, 0.9703331201969181, 0.9703331201969181, 0.5196291341622605, 0.5196291341622605, 0.5196291341622605, 0.518919315452276, 0.518919315452276, 0.518919315452276, 0.5324954427436848, 0.5324954427436848, 0.5324954427436848, 0.3602263736924397, 0.3602263736924397, 0.3602263736924397, 0.1616868317500566, 0.1616868317500566, 0.1616868317500566, 0.15672892028720564, 0.15672892028720564, 0.15672892028720564, 0.2044744022679288, 0.2044744022679288, 0.2044744022679288, 0.31126491322008265, 0.31126491322008265, 0.31126491322008265, 0.19088351991435648, 0.19088351991435648, 0.19088351991435648, 0.21144021021077997, 0.21144021021077997, 0.21144021021077997, 0.21169333411379765, 0.21169333411379765, 0.21169333411379765, 0.18980495158227484, 0.18980495158227484, 0.18980495158227484, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.059510324156432204, 0.059510324156432204, 0.059510324156432204, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.16401518190354836, 0.16401518190354836, 0.16401518190354836, 0.013679905797138403, 0.013679905797138403, 0.013679905797138403, 0.11149053236820783, 0.11149053236820783, 0.11149053236820783, 0.047568455044445734, 0.047568455044445734, 0.047568455044445734, 0.2224016444505289, 0.2224016444505289, 0.2224016444505289, 0.12461115218040286, 0.12461115218040286, 0.12461115218040286, 0.18144843877001582, 0.18144843877001582, 0.18144843877001582, 0.0753593037175091, 0.0753593037175091, 0.0753593037175091, 0.08183237155806933, 0.08183237155806933, 0.08183237155806933, 0.5347491844130503, 0.5347491844130503, 0.5347491844130503, 0.5691056017155756, 0.5691056017155756, 0.5691056017155756, 0.5558932152883651, 0.5558932152883651, 0.5558932152883651, 0.1588545004683698, 0.1588545004683698, 0.1588545004683698, 0.13892302334765572, 0.13892302334765572, 0.13892302334765572, 0.12033072862985594, 0.12033072862985594, 0.12033072862985594, 0.19656024775078418, 0.19656024775078418, 0.19656024775078418, 0.28788417386987486, 0.28788417386987486, 0.28788417386987486, 0.15094331396968352, 0.15094331396968352, 0.15094331396968352, 0.4179276016053336, 0.4179276016053336, 0.4179276016053336, 0.4470926213054941, 0.4470926213054941, 0.4470926213054941, 0.44804511459172514, 0.44804511459172514, 0.44804511459172514, 0.22855105904388995, 0.22855105904388995, 0.22855105904388995, 0.26262525533065006, 0.26262525533065006, 0.26262525533065006, 0.15127334811760595, 0.15127334811760595, 0.15127334811760595, 0.1989669822936151, 0.1989669822936151, 0.1989669822936151, 0.208180457650175, 0.208180457650175, 0.208180457650175, 0.19963653603193132, 0.19963653603193132, 0.19963653603193132, 0.22739503370454095, 0.22739503370454095, 0.22739503370454095, 0.2195413895411631, 0.2195413895411631, 0.2195413895411631, 0.20447510023612991, 0.20447510023612991, 0.20447510023612991, 0.903843264404162, 0.903843264404162, 0.903843264404162, 0.15814959102425086, 0.15814959102425086, 0.15814959102425086, 0.8118001344723307, 0.8118001344723307, 0.8118001344723307, 0.16839433148461957, 0.16839433148461957, 0.16839433148461957, 0.21254852512239475, 0.21254852512239475, 0.21254852512239475, 0.15590277328308655, 0.15590277328308655, 0.15590277328308655, 0.21366875268388807, 0.21366875268388807, 0.21366875268388807, 0.19815421742354933, 0.19815421742354933, 0.19815421742354933, 0.20121162439767915, 0.20121162439767915, 0.20121162439767915, 0.10205045011871239, 0.10205045011871239, 0.10205045011871239, 0.090737016065227, 0.090737016065227, 0.090737016065227, 0.13131646705924394, 0.13131646705924394, 0.13131646705924394]}, "mutation_prompt": null}
{"id": "bb6f010d-bc93-480a-8718-8c5e1a09853f", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.1  \n        self.momentum = 0.9       \n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)\n            \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            # Dynamic learning rate scaling based on convergence progress\n            progress = 1 - (eval_count / self.budget)\n            adjusted_learning_rate = self.learning_rate * (0.5 + 0.5 * progress)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + adjusted_learning_rate * (cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Enhanced ADSA with dynamic learning rate scaling based on convergence progress to improve convergence speed and balance exploration-exploitation more effectively.", "configspace": "", "generation": 9, "fitness": 0.3219723286882637, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.27.", "error": "", "parent_id": "e7c3edd3-a75c-4ba3-b1f0-cba98e0c2b3e", "metadata": {"aucs": [0.8673359485955042, 0.8673359485955042, 0.8673359485955042, 0.8709135993990431, 0.8709135993990431, 0.8709135993990431, 0.8642194799121642, 0.8642194799121642, 0.8642194799121642, 0.7340288327297556, 0.7340288327297556, 0.7340288327297556, 0.7267626051615017, 0.7267626051615017, 0.7267626051615017, 0.7292050514977568, 0.7292050514977568, 0.7292050514977568, 0.1780528408934442, 0.1780528408934442, 0.1780528408934442, 0.15579831344795403, 0.15579831344795403, 0.15579831344795403, 0.17322686722875147, 0.17322686722875147, 0.17322686722875147, 0.14826457384456515, 0.14826457384456515, 0.14826457384456515, 0.12621208362069902, 0.12621208362069902, 0.12621208362069902, 0.13652674839092505, 0.13652674839092505, 0.13652674839092505, 0.9800518432395783, 0.9800518432395783, 0.9800518432395783, 0.9796934885692667, 0.9796934885692667, 0.9796934885692667, 0.9770464253925233, 0.9770464253925233, 0.9770464253925233, 0.6216549636908859, 0.6216549636908859, 0.6216549636908859, 0.6367005265499328, 0.6367005265499328, 0.6367005265499328, 0.6873296235307408, 0.6873296235307408, 0.6873296235307408, 0.2208155318716395, 0.2208155318716395, 0.2208155318716395, 0.20958587844635468, 0.20958587844635468, 0.20958587844635468, 0.16525045008694683, 0.16525045008694683, 0.16525045008694683, 0.21014110986359102, 0.21014110986359102, 0.21014110986359102, 0.13172204768447882, 0.13172204768447882, 0.13172204768447882, 0.2078022323741372, 0.2078022323741372, 0.2078022323741372, 0.23289901177167516, 0.23289901177167516, 0.23289901177167516, 0.23364666488393404, 0.23364666488393404, 0.23364666488393404, 0.2630402215863483, 0.2630402215863483, 0.2630402215863483, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04551930875553756, 0.04551930875553756, 0.04551930875553756, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08928312625314705, 0.08928312625314705, 0.08928312625314705, 0.024504313807013567, 0.024504313807013567, 0.024504313807013567, 0.07093648784380602, 0.07093648784380602, 0.07093648784380602, 0.05992972507473404, 0.05992972507473404, 0.05992972507473404, 0.17674236928018328, 0.17674236928018328, 0.17674236928018328, 0.1871629716584563, 0.1871629716584563, 0.1871629716584563, 0.2908406569569132, 0.2908406569569132, 0.2908406569569132, 0.0390865882865401, 0.0390865882865401, 0.0390865882865401, 0.08375924305315985, 0.08375924305315985, 0.08375924305315985, 0.5455377182456522, 0.5455377182456522, 0.5455377182456522, 0.536245502639852, 0.536245502639852, 0.536245502639852, 0.5547560244957086, 0.5547560244957086, 0.5547560244957086, 0.14304849659157093, 0.14304849659157093, 0.14304849659157093, 0.17670435924700956, 0.17670435924700956, 0.17670435924700956, 0.08230322073745644, 0.08230322073745644, 0.08230322073745644, 0.5225869956478364, 0.5225869956478364, 0.5225869956478364, 0.2101751680746362, 0.2101751680746362, 0.2101751680746362, 0.27946679482973746, 0.27946679482973746, 0.27946679482973746, 0.3557588687080936, 0.3557588687080936, 0.3557588687080936, 0.40865991375069044, 0.40865991375069044, 0.40865991375069044, 0.5805602540825229, 0.5805602540825229, 0.5805602540825229, 0.2579869487100451, 0.2579869487100451, 0.2579869487100451, 0.21463313666204487, 0.21463313666204487, 0.21463313666204487, 0.14231976778514543, 0.14231976778514543, 0.14231976778514543, 0.2301781301667084, 0.2301781301667084, 0.2301781301667084, 0.2591829803109096, 0.2591829803109096, 0.2591829803109096, 0.1998673270595226, 0.1998673270595226, 0.1998673270595226, 0.21071975074894922, 0.21071975074894922, 0.21071975074894922, 0.22421747023575256, 0.22421747023575256, 0.22421747023575256, 0.1959478323276359, 0.1959478323276359, 0.1959478323276359, 0.9230008846642684, 0.9230008846642684, 0.9230008846642684, 0.1580414697749304, 0.1580414697749304, 0.1580414697749304, 0.16871357577909707, 0.16871357577909707, 0.16871357577909707, 0.21151837774625215, 0.21151837774625215, 0.21151837774625215, 0.21212424844668476, 0.21212424844668476, 0.21212424844668476, 0.7277226321782835, 0.7277226321782835, 0.7277226321782835, 0.22667050565627045, 0.22667050565627045, 0.22667050565627045, 0.18460297341388865, 0.18460297341388865, 0.18460297341388865, 0.20265090655215723, 0.20265090655215723, 0.20265090655215723, 0.10848450731279502, 0.10848450731279502, 0.10848450731279502, 0.0863112456922932, 0.0863112456922932, 0.0863112456922932, 0.10541792204699996, 0.10541792204699996, 0.10541792204699996]}, "mutation_prompt": null}
{"id": "cc46092d-8676-4cac-8332-88ce11af403c", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.1  # New adaptive learning rate\n        self.momentum = 0.9       # Incorporates momentum\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            # Evaluate current positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            # Adjust inertia weight based on improvement\n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)\n            \n            # Dynamic adjustment of coefficients\n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            # Dynamic step size scaling\n            step_scaling = 1 + 0.5 * (eval_count / self.budget)\n            \n            # Update velocities and positions with momentum and learning rate\n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity) * step_scaling\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Introduce a dynamic step size scaling based on evaluation progress to enhance convergence speed in Enhanced ADSA.", "configspace": "", "generation": 10, "fitness": 0.32113605607493295, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.28.", "error": "", "parent_id": "e7c3edd3-a75c-4ba3-b1f0-cba98e0c2b3e", "metadata": {"aucs": [0.8764642450594607, 0.8764642450594607, 0.8764642450594607, 0.866087472877947, 0.866087472877947, 0.866087472877947, 0.8706353392030727, 0.8706353392030727, 0.8706353392030727, 0.701433612427691, 0.701433612427691, 0.701433612427691, 0.7218122598664432, 0.7218122598664432, 0.7218122598664432, 0.7304509820830107, 0.7304509820830107, 0.7304509820830107, 0.16207637669888064, 0.16207637669888064, 0.16207637669888064, 0.1684380331214268, 0.1684380331214268, 0.1684380331214268, 0.17817119757882594, 0.17817119757882594, 0.17817119757882594, 0.12203539522549745, 0.12203539522549745, 0.12203539522549745, 0.12137297075184084, 0.12137297075184084, 0.12137297075184084, 0.09640525468213856, 0.09640525468213856, 0.09640525468213856, 0.9800583803516518, 0.9800583803516518, 0.9800583803516518, 0.979696603379996, 0.979696603379996, 0.979696603379996, 0.9770477406762961, 0.9770477406762961, 0.9770477406762961, 0.7167034489823432, 0.7167034489823432, 0.7167034489823432, 0.720138412649405, 0.720138412649405, 0.720138412649405, 0.6693414365981931, 0.6693414365981931, 0.6693414365981931, 0.3631026799632091, 0.3631026799632091, 0.3631026799632091, 0.1915450098548983, 0.1915450098548983, 0.1915450098548983, 0.17016689109880156, 0.17016689109880156, 0.17016689109880156, 0.21956683451724346, 0.21956683451724346, 0.21956683451724346, 0.13168760479152097, 0.13168760479152097, 0.13168760479152097, 0.2167680602022528, 0.2167680602022528, 0.2167680602022528, 0.2285638917604319, 0.2285638917604319, 0.2285638917604319, 0.26078616162906276, 0.26078616162906276, 0.26078616162906276, 0.25608920472105745, 0.25608920472105745, 0.25608920472105745, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04335340442650648, 0.04335340442650648, 0.04335340442650648, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14685246340172975, 0.14685246340172975, 0.14685246340172975, 0.010167558081228933, 0.010167558081228933, 0.010167558081228933, 0.08786833119587423, 0.08786833119587423, 0.08786833119587423, 0.06197657456706296, 0.06197657456706296, 0.06197657456706296, 0.14795091744304645, 0.14795091744304645, 0.14795091744304645, 0.21225309394331504, 0.21225309394331504, 0.21225309394331504, 0.1856856057108004, 0.1856856057108004, 0.1856856057108004, 0.0390747254717968, 0.0390747254717968, 0.0390747254717968, 0.0839653664144907, 0.0839653664144907, 0.0839653664144907, 0.5521364355673906, 0.5521364355673906, 0.5521364355673906, 0.5500481916003472, 0.5500481916003472, 0.5500481916003472, 0.543712171776155, 0.543712171776155, 0.543712171776155, 0.11694086017530225, 0.11694086017530225, 0.11694086017530225, 0.13176459034545784, 0.13176459034545784, 0.13176459034545784, 0.0796529599725807, 0.0796529599725807, 0.0796529599725807, 0.6001572582169226, 0.6001572582169226, 0.6001572582169226, 0.2057698114846609, 0.2057698114846609, 0.2057698114846609, 0.20422427154831035, 0.20422427154831035, 0.20422427154831035, 0.26965179138553763, 0.26965179138553763, 0.26965179138553763, 0.41027491940158045, 0.41027491940158045, 0.41027491940158045, 0.47642208393364094, 0.47642208393364094, 0.47642208393364094, 0.22337875291961617, 0.22337875291961617, 0.22337875291961617, 0.2459779581769369, 0.2459779581769369, 0.2459779581769369, 0.2037945306010145, 0.2037945306010145, 0.2037945306010145, 0.26434651758523064, 0.26434651758523064, 0.26434651758523064, 0.2179798619967841, 0.2179798619967841, 0.2179798619967841, 0.22329403027011707, 0.22329403027011707, 0.22329403027011707, 0.20496617553728624, 0.20496617553728624, 0.20496617553728624, 0.19719276495160232, 0.19719276495160232, 0.19719276495160232, 0.2070229602125241, 0.2070229602125241, 0.2070229602125241, 0.9176849979105035, 0.9176849979105035, 0.9176849979105035, 0.15804009947168873, 0.15804009947168873, 0.15804009947168873, 0.16872360170367318, 0.16872360170367318, 0.16872360170367318, 0.21097788271254447, 0.21097788271254447, 0.21097788271254447, 0.21220646288594036, 0.21220646288594036, 0.21220646288594036, 0.7204099709272628, 0.7204099709272628, 0.7204099709272628, 0.19494356409974456, 0.19494356409974456, 0.19494356409974456, 0.19205367641051774, 0.19205367641051774, 0.19205367641051774, 0.17794076250375201, 0.17794076250375201, 0.17794076250375201, 0.09101380409674131, 0.09101380409674131, 0.09101380409674131, 0.09539788938437321, 0.09539788938437321, 0.09539788938437321, 0.13770088622097842, 0.13770088622097842, 0.13770088622097842]}, "mutation_prompt": null}
{"id": "bc13cbfa-c64b-4be9-8210-c96703a6f565", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.1\n        self.momentum = 0.9\n        self.dynamic_population_adjustment()\n\n    def dynamic_population_adjustment(self):\n        # Dynamically adjust population size based on budget\n        if self.budget > 1000:\n            self.population_size = min(100, self.budget // 20)\n        \n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)\n            \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Enhanced ADSA with dynamic population size adjustment for improved convergence speed. ", "configspace": "", "generation": 11, "fitness": 0.3113238107823815, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.25.", "error": "", "parent_id": "e7c3edd3-a75c-4ba3-b1f0-cba98e0c2b3e", "metadata": {"aucs": [0.7816107972541423, 0.7816107972541423, 0.7816107972541423, 0.7619815629898685, 0.7619815629898685, 0.7619815629898685, 0.7603375644821139, 0.7603375644821139, 0.7603375644821139, 0.4075211600806672, 0.4075211600806672, 0.4075211600806672, 0.5404811517243624, 0.5404811517243624, 0.5404811517243624, 0.4325484411589724, 0.4325484411589724, 0.4325484411589724, 0.34975596568310996, 0.34975596568310996, 0.34975596568310996, 0.36085062075071317, 0.36085062075071317, 0.36085062075071317, 0.13178637238435853, 0.13178637238435853, 0.13178637238435853, 0.1278869235891903, 0.1278869235891903, 0.1278869235891903, 0.11912745683679438, 0.11912745683679438, 0.11912745683679438, 0.15471068850879732, 0.15471068850879732, 0.15471068850879732, 0.9629293161273249, 0.9629293161273249, 0.9629293161273249, 0.9685333564760681, 0.9685333564760681, 0.9685333564760681, 0.9707328759316354, 0.9707328759316354, 0.9707328759316354, 0.4621419575442375, 0.4621419575442375, 0.4621419575442375, 0.4873912762350894, 0.4873912762350894, 0.4873912762350894, 0.4656846701703725, 0.4656846701703725, 0.4656846701703725, 0.22122197520109588, 0.22122197520109588, 0.22122197520109588, 0.18462923352221883, 0.18462923352221883, 0.18462923352221883, 0.2229968683562572, 0.2229968683562572, 0.2229968683562572, 0.16841761960496693, 0.16841761960496693, 0.16841761960496693, 0.18448181174828793, 0.18448181174828793, 0.18448181174828793, 0.18982348862199394, 0.18982348862199394, 0.18982348862199394, 0.23004812279438824, 0.23004812279438824, 0.23004812279438824, 0.22554167465241703, 0.22554167465241703, 0.22554167465241703, 0.21843630599154107, 0.21843630599154107, 0.21843630599154107, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04978803124761344, 0.04978803124761344, 0.04978803124761344, 0.05282216390166883, 0.05282216390166883, 0.05282216390166883, 0.02179594527433515, 0.02179594527433515, 0.02179594527433515, 0.07479375255401066, 0.07479375255401066, 0.07479375255401066, 0.040889448868528966, 0.040889448868528966, 0.040889448868528966, 0.14227746782810935, 0.14227746782810935, 0.14227746782810935, 0.06725253423452449, 0.06725253423452449, 0.06725253423452449, 0.09691662911069743, 0.09691662911069743, 0.09691662911069743, 0.2714915672249558, 0.2714915672249558, 0.2714915672249558, 0.1107040468287892, 0.1107040468287892, 0.1107040468287892, 0.5239072042870621, 0.5239072042870621, 0.5239072042870621, 0.5340464715217903, 0.5340464715217903, 0.5340464715217903, 0.5371604319399075, 0.5371604319399075, 0.5371604319399075, 0.13470411804346583, 0.13470411804346583, 0.13470411804346583, 0.15298119261998855, 0.15298119261998855, 0.15298119261998855, 0.17182551783641176, 0.17182551783641176, 0.17182551783641176, 0.20480056484717568, 0.20480056484717568, 0.20480056484717568, 0.2002193605354743, 0.2002193605354743, 0.2002193605354743, 0.1748752378201356, 0.1748752378201356, 0.1748752378201356, 0.35996299667883636, 0.35996299667883636, 0.35996299667883636, 0.3370636743577309, 0.3370636743577309, 0.3370636743577309, 0.49048087123656114, 0.49048087123656114, 0.49048087123656114, 0.20853422741501093, 0.20853422741501093, 0.20853422741501093, 0.31560513109153077, 0.31560513109153077, 0.31560513109153077, 0.14151131320580002, 0.14151131320580002, 0.14151131320580002, 0.17673127199370553, 0.17673127199370553, 0.17673127199370553, 0.22991996831660633, 0.22991996831660633, 0.22991996831660633, 0.2221655266252437, 0.2221655266252437, 0.2221655266252437, 0.21688730371086729, 0.21688730371086729, 0.21688730371086729, 0.19706722354547512, 0.19706722354547512, 0.19706722354547512, 0.6023455037787774, 0.6023455037787774, 0.6023455037787774, 0.8809551293541137, 0.8809551293541137, 0.8809551293541137, 0.15787807216578098, 0.15787807216578098, 0.15787807216578098, 0.8049955239255723, 0.8049955239255723, 0.8049955239255723, 0.6468926672324944, 0.6468926672324944, 0.6468926672324944, 0.20940299292618247, 0.20940299292618247, 0.20940299292618247, 0.6992869420703636, 0.6992869420703636, 0.6992869420703636, 0.1948753670573209, 0.1948753670573209, 0.1948753670573209, 0.17928754296016702, 0.17928754296016702, 0.17928754296016702, 0.19603420984299869, 0.19603420984299869, 0.19603420984299869, 0.08642948714134635, 0.08642948714134635, 0.08642948714134635, 0.08688203714351639, 0.08688203714351639, 0.08688203714351639, 0.11905844760983786, 0.11905844760983786, 0.11905844760983786]}, "mutation_prompt": null}
{"id": "aa175aeb-700e-4904-919f-fce6de75ce47", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.1\n        self.momentum = 0.9\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)\n            \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            # Hybrid exploration: Introduce random walk step\n            exploration_mask = np.random.rand(self.population_size) < 0.1\n            random_walk = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            positions[exploration_mask] += self.learning_rate * random_walk[exploration_mask]\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Enhanced ADSA with hybrid exploration using random walks and adaptive inertia for faster convergence.", "configspace": "", "generation": 12, "fitness": 0.2980361933151244, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.26.", "error": "", "parent_id": "e7c3edd3-a75c-4ba3-b1f0-cba98e0c2b3e", "metadata": {"aucs": [0.8218986678213955, 0.8218986678213955, 0.8218986678213955, 0.8383906049052043, 0.8383906049052043, 0.8383906049052043, 0.8402993504319103, 0.8402993504319103, 0.8402993504319103, 0.20309237217866272, 0.20309237217866272, 0.20309237217866272, 0.5761183168845867, 0.5761183168845867, 0.5761183168845867, 0.5287010664861767, 0.5287010664861767, 0.5287010664861767, 0.16987092702464213, 0.16987092702464213, 0.16987092702464213, 0.14604577814696162, 0.14604577814696162, 0.14604577814696162, 0.17677150413693832, 0.17677150413693832, 0.17677150413693832, 0.1518268767516151, 0.1518268767516151, 0.1518268767516151, 0.144084426463174, 0.144084426463174, 0.144084426463174, 0.1232933939672608, 0.1232933939672608, 0.1232933939672608, 0.9846327060213184, 0.9846327060213184, 0.9846327060213184, 0.9793627562110142, 0.9793627562110142, 0.9793627562110142, 0.9778317520534995, 0.9778317520534995, 0.9778317520534995, 0.5407569000678754, 0.5407569000678754, 0.5407569000678754, 0.456596864070539, 0.456596864070539, 0.456596864070539, 0.5256608243237475, 0.5256608243237475, 0.5256608243237475, 0.2232253209962609, 0.2232253209962609, 0.2232253209962609, 0.16068917286581563, 0.16068917286581563, 0.16068917286581563, 0.17571128329547514, 0.17571128329547514, 0.17571128329547514, 0.18307279740421578, 0.18307279740421578, 0.18307279740421578, 0.12714379623847583, 0.12714379623847583, 0.12714379623847583, 0.18616075231139462, 0.18616075231139462, 0.18616075231139462, 0.1259470074322686, 0.1259470074322686, 0.1259470074322686, 0.18799932952347886, 0.18799932952347886, 0.18799932952347886, 0.21038436030805918, 0.21038436030805918, 0.21038436030805918, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.033582763750433564, 0.033582763750433564, 0.033582763750433564, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06716492828873655, 0.06716492828873655, 0.06716492828873655, 0.011595318104436259, 0.011595318104436259, 0.011595318104436259, 0.09548503394371655, 0.09548503394371655, 0.09548503394371655, 0.04429801537971745, 0.04429801537971745, 0.04429801537971745, 0.14509672089802228, 0.14509672089802228, 0.14509672089802228, 0.17579228613682518, 0.17579228613682518, 0.17579228613682518, 0.15241486958234396, 0.15241486958234396, 0.15241486958234396, 0.06592668549657354, 0.06592668549657354, 0.06592668549657354, 0.08108213857797486, 0.08108213857797486, 0.08108213857797486, 0.5709724744656386, 0.5709724744656386, 0.5709724744656386, 0.5181308465519574, 0.5181308465519574, 0.5181308465519574, 0.5672204939899337, 0.5672204939899337, 0.5672204939899337, 0.12055488562683381, 0.12055488562683381, 0.12055488562683381, 0.13709775042163252, 0.13709775042163252, 0.13709775042163252, 0.13027597442701622, 0.13027597442701622, 0.13027597442701622, 0.2998217956190712, 0.2998217956190712, 0.2998217956190712, 0.2867539207559363, 0.2867539207559363, 0.2867539207559363, 0.19699906022795455, 0.19699906022795455, 0.19699906022795455, 0.37668997244554336, 0.37668997244554336, 0.37668997244554336, 0.41040613554047367, 0.41040613554047367, 0.41040613554047367, 0.47097310987355534, 0.47097310987355534, 0.47097310987355534, 0.21639805330704653, 0.21639805330704653, 0.21639805330704653, 0.2725092601952831, 0.2725092601952831, 0.2725092601952831, 0.1278054359069678, 0.1278054359069678, 0.1278054359069678, 0.2492029394908284, 0.2492029394908284, 0.2492029394908284, 0.2737896617523343, 0.2737896617523343, 0.2737896617523343, 0.20889989400766795, 0.20889989400766795, 0.20889989400766795, 0.2249532085563002, 0.2249532085563002, 0.2249532085563002, 0.6537630791806023, 0.6537630791806023, 0.6537630791806023, 0.2061903494632561, 0.2061903494632561, 0.2061903494632561, 0.9093614991661958, 0.9093614991661958, 0.9093614991661958, 0.1578192912593207, 0.1578192912593207, 0.1578192912593207, 0.2297653121182075, 0.2297653121182075, 0.2297653121182075, 0.20910913894145355, 0.20910913894145355, 0.20910913894145355, 0.708332929895668, 0.708332929895668, 0.708332929895668, 0.15634510167350946, 0.15634510167350946, 0.15634510167350946, 0.21554479054533626, 0.21554479054533626, 0.21554479054533626, 0.1992479411386291, 0.1992479411386291, 0.1992479411386291, 0.18400088416946325, 0.18400088416946325, 0.18400088416946325, 0.10221392197068657, 0.10221392197068657, 0.10221392197068657, 0.11089658265016367, 0.11089658265016367, 0.11089658265016367, 0.11835255487374197, 0.11835255487374197, 0.11835255487374197]}, "mutation_prompt": null}
{"id": "517dce45-3c29-4df0-807c-bfb76acfef0e", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.1  # Scaled adaptive learning rate\n        self.momentum = 0.9\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.97)\n            \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity * 0.95)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Enhanced ADSA with an adaptive inertia weight decay and learning rate scaling for improved convergence speed.", "configspace": "", "generation": 13, "fitness": 0.3200480461276502, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.27.", "error": "", "parent_id": "e7c3edd3-a75c-4ba3-b1f0-cba98e0c2b3e", "metadata": {"aucs": [0.8745776332816864, 0.8745776332816864, 0.8745776332816864, 0.8819026156280563, 0.8819026156280563, 0.8819026156280563, 0.869819401995355, 0.869819401995355, 0.869819401995355, 0.6146748382014933, 0.6146748382014933, 0.6146748382014933, 0.7582104271191723, 0.7582104271191723, 0.7582104271191723, 0.7626894570402867, 0.7626894570402867, 0.7626894570402867, 0.15767868760468684, 0.15767868760468684, 0.15767868760468684, 0.12298676688331112, 0.12298676688331112, 0.12298676688331112, 0.14928051391625685, 0.14928051391625685, 0.14928051391625685, 0.15874031992820115, 0.15874031992820115, 0.15874031992820115, 0.10891413014209816, 0.10891413014209816, 0.10891413014209816, 0.14577759675212565, 0.14577759675212565, 0.14577759675212565, 0.9811343230110271, 0.9811343230110271, 0.9811343230110271, 0.979678032370163, 0.979678032370163, 0.979678032370163, 0.976977702677174, 0.976977702677174, 0.976977702677174, 0.6390416451435466, 0.6390416451435466, 0.6390416451435466, 0.7223838911861885, 0.7223838911861885, 0.7223838911861885, 0.6869615000270899, 0.6869615000270899, 0.6869615000270899, 0.3532370555144758, 0.3532370555144758, 0.3532370555144758, 0.19156558626421882, 0.19156558626421882, 0.19156558626421882, 0.15045532311008536, 0.15045532311008536, 0.15045532311008536, 0.20893351996430942, 0.20893351996430942, 0.20893351996430942, 0.1290304309184498, 0.1290304309184498, 0.1290304309184498, 0.22040596185017525, 0.22040596185017525, 0.22040596185017525, 0.23746495394828215, 0.23746495394828215, 0.23746495394828215, 0.20064345287534868, 0.20064345287534868, 0.20064345287534868, 0.2520146348692356, 0.2520146348692356, 0.2520146348692356, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08893809034378641, 0.08893809034378641, 0.08893809034378641, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1265280745842854, 0.1265280745842854, 0.1265280745842854, 0.01400673628773641, 0.01400673628773641, 0.01400673628773641, 0.09402374913004974, 0.09402374913004974, 0.09402374913004974, 0.060595545269642614, 0.060595545269642614, 0.060595545269642614, 0.21621675922467187, 0.21621675922467187, 0.21621675922467187, 0.22400154879492207, 0.22400154879492207, 0.22400154879492207, 0.2652412341416597, 0.2652412341416597, 0.2652412341416597, 0.039176032943801564, 0.039176032943801564, 0.039176032943801564, 0.08366104023322096, 0.08366104023322096, 0.08366104023322096, 0.5642492530857254, 0.5642492530857254, 0.5642492530857254, 0.5437880661745913, 0.5437880661745913, 0.5437880661745913, 0.5870253165107157, 0.5870253165107157, 0.5870253165107157, 0.11664242484588683, 0.11664242484588683, 0.11664242484588683, 0.12183947887362123, 0.12183947887362123, 0.12183947887362123, 0.13851235353481228, 0.13851235353481228, 0.13851235353481228, 0.2722960368537941, 0.2722960368537941, 0.2722960368537941, 0.26601851588198766, 0.26601851588198766, 0.26601851588198766, 0.18985666157555092, 0.18985666157555092, 0.18985666157555092, 0.4216161599084679, 0.4216161599084679, 0.4216161599084679, 0.30062519089148554, 0.30062519089148554, 0.30062519089148554, 0.43784085346377644, 0.43784085346377644, 0.43784085346377644, 0.2179205188741825, 0.2179205188741825, 0.2179205188741825, 0.2568802929045406, 0.2568802929045406, 0.2568802929045406, 0.1389563404427243, 0.1389563404427243, 0.1389563404427243, 0.2531229383900515, 0.2531229383900515, 0.2531229383900515, 0.2751860302729926, 0.2751860302729926, 0.2751860302729926, 0.22985586800779767, 0.22985586800779767, 0.22985586800779767, 0.2049864206665285, 0.2049864206665285, 0.2049864206665285, 0.22458394785041957, 0.22458394785041957, 0.22458394785041957, 0.2068399753594251, 0.2068399753594251, 0.2068399753594251, 0.925863956581492, 0.925863956581492, 0.925863956581492, 0.15798382514218756, 0.15798382514218756, 0.15798382514218756, 0.16870463097959543, 0.16870463097959543, 0.16870463097959543, 0.21086614342888987, 0.21086614342888987, 0.21086614342888987, 0.21232141075344102, 0.21232141075344102, 0.21232141075344102, 0.7145866952314155, 0.7145866952314155, 0.7145866952314155, 0.22435552482563614, 0.22435552482563614, 0.22435552482563614, 0.18184907917421156, 0.18184907917421156, 0.18184907917421156, 0.20873629308820674, 0.20873629308820674, 0.20873629308820674, 0.10135727763704383, 0.10135727763704383, 0.10135727763704383, 0.08994787789851766, 0.08994787789851766, 0.08994787789851766, 0.13047474890482025, 0.13047474890482025, 0.13047474890482025]}, "mutation_prompt": null}
{"id": "04c36df8-7709-458c-b005-fbffe2367e6e", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.1\n        self.momentum = 0.9\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.96)\n            \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            scaled_social_velocity = self.social_coef * (0.5 + np.random.rand()) * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_velocity + scaled_social_velocity\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + scaled_social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Enhanced Adaptive Differential Swarm Algorithm (EnhancedADSA) with adaptive inertia weight decay and stochastic component scaling for improved convergence.", "configspace": "", "generation": 14, "fitness": 0.3266401870057099, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.28.", "error": "", "parent_id": "e7c3edd3-a75c-4ba3-b1f0-cba98e0c2b3e", "metadata": {"aucs": [0.8930202484817433, 0.8930202484817433, 0.8930202484817433, 0.8847027754658221, 0.8847027754658221, 0.8847027754658221, 0.8730340049707628, 0.8730340049707628, 0.8730340049707628, 0.709296117327356, 0.709296117327356, 0.709296117327356, 0.7005002861674745, 0.7005002861674745, 0.7005002861674745, 0.7323259014531895, 0.7323259014531895, 0.7323259014531895, 0.18206265549269018, 0.18206265549269018, 0.18206265549269018, 0.14051925722308367, 0.14051925722308367, 0.14051925722308367, 0.14664438286983927, 0.14664438286983927, 0.14664438286983927, 0.16590924000515583, 0.16590924000515583, 0.16590924000515583, 0.13718891168615588, 0.13718891168615588, 0.13718891168615588, 0.14923479999410316, 0.14923479999410316, 0.14923479999410316, 0.9762102805352277, 0.9762102805352277, 0.9762102805352277, 0.9793108258153873, 0.9793108258153873, 0.9793108258153873, 0.9724749767422276, 0.9724749767422276, 0.9724749767422276, 0.7108659330395288, 0.7108659330395288, 0.7108659330395288, 0.16872884487170214, 0.16872884487170214, 0.16872884487170214, 0.7314140893495371, 0.7314140893495371, 0.7314140893495371, 0.1697879713177637, 0.1697879713177637, 0.1697879713177637, 0.16175171675861388, 0.16175171675861388, 0.16175171675861388, 0.3082152015626468, 0.3082152015626468, 0.3082152015626468, 0.19651392005977408, 0.19651392005977408, 0.19651392005977408, 0.13076638992510814, 0.13076638992510814, 0.13076638992510814, 0.21172377874985826, 0.21172377874985826, 0.21172377874985826, 0.22845990876933708, 0.22845990876933708, 0.22845990876933708, 0.21635260286171232, 0.21635260286171232, 0.21635260286171232, 0.13071116120377668, 0.13071116120377668, 0.13071116120377668, 0.0009873035832596022, 0.0009873035832596022, 0.0009873035832596022, 0.021250613000406204, 0.021250613000406204, 0.021250613000406204, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12549138731765708, 0.12549138731765708, 0.12549138731765708, 0.03069183216598481, 0.03069183216598481, 0.03069183216598481, 0.1499723661811213, 0.1499723661811213, 0.1499723661811213, 0.27873023233826666, 0.27873023233826666, 0.27873023233826666, 0.12954661915129095, 0.12954661915129095, 0.12954661915129095, 0.16081307605851214, 0.16081307605851214, 0.16081307605851214, 0.17460556261594795, 0.17460556261594795, 0.17460556261594795, 0.1603624012856686, 0.1603624012856686, 0.1603624012856686, 0.1737006364540361, 0.1737006364540361, 0.1737006364540361, 0.5645097757837343, 0.5645097757837343, 0.5645097757837343, 0.5543304535874733, 0.5543304535874733, 0.5543304535874733, 0.5656877948736059, 0.5656877948736059, 0.5656877948736059, 0.10124958037706033, 0.10124958037706033, 0.10124958037706033, 0.10028953951369624, 0.10028953951369624, 0.10028953951369624, 0.11424212906018694, 0.11424212906018694, 0.11424212906018694, 0.2625478481812801, 0.2625478481812801, 0.2625478481812801, 0.1894677956747851, 0.1894677956747851, 0.1894677956747851, 0.17235273072490542, 0.17235273072490542, 0.17235273072490542, 0.4445979925365333, 0.4445979925365333, 0.4445979925365333, 0.4395232998347558, 0.4395232998347558, 0.4395232998347558, 0.5138777819478333, 0.5138777819478333, 0.5138777819478333, 0.21548753641632568, 0.21548753641632568, 0.21548753641632568, 0.19131646769780097, 0.19131646769780097, 0.19131646769780097, 0.19562910271958278, 0.19562910271958278, 0.19562910271958278, 0.2573184244948534, 0.2573184244948534, 0.2573184244948534, 0.22357420303329567, 0.22357420303329567, 0.22357420303329567, 0.20050109597327292, 0.20050109597327292, 0.20050109597327292, 0.731277121189748, 0.731277121189748, 0.731277121189748, 0.21264922285855492, 0.21264922285855492, 0.21264922285855492, 0.20384576151550815, 0.20384576151550815, 0.20384576151550815, 0.9280533752234972, 0.9280533752234972, 0.9280533752234972, 0.16412906768141566, 0.16412906768141566, 0.16412906768141566, 0.8526216000795811, 0.8526216000795811, 0.8526216000795811, 0.1544592750998639, 0.1544592750998639, 0.1544592750998639, 0.2131066847584009, 0.2131066847584009, 0.2131066847584009, 0.4126482487548474, 0.4126482487548474, 0.4126482487548474, 0.20079107967909582, 0.20079107967909582, 0.20079107967909582, 0.2119103573439831, 0.2119103573439831, 0.2119103573439831, 0.18373222717392435, 0.18373222717392435, 0.18373222717392435, 0.10011767444267661, 0.10011767444267661, 0.10011767444267661, 0.09289881668019495, 0.09289881668019495, 0.09289881668019495, 0.13537118664711156, 0.13537118664711156, 0.13537118664711156]}, "mutation_prompt": null}
{"id": "6ad56ca0-6ede-4d68-8482-a9b59df40673", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.8   # Increased initial inertia weight for exploration\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.12   # Slightly increased adaptive learning rate\n        self.momentum = 0.85        # Slightly reduced momentum\n        \n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.97)  # More aggressive inertia reduction\n            \n            self.cognitive_coef = 1.494 + 0.6 * (1 - eval_count / self.budget)  # More adaptive\n            self.social_coef = 1.494 - 0.4 * (1 - eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_velocity + social_velocity\n            \n            positions += velocities * (0.9 + 0.2 * np.random.random())  # Adding velocity scaling\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Advanced Particle Exploration (APE) with adaptive velocity scaling and dynamic inertia to enhance exploration and exploitation balance.", "configspace": "", "generation": 15, "fitness": 0.3226921442493053, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.27.", "error": "", "parent_id": "e7c3edd3-a75c-4ba3-b1f0-cba98e0c2b3e", "metadata": {"aucs": [0.8408668171983462, 0.8408668171983462, 0.8408668171983462, 0.8534139691532228, 0.8534139691532228, 0.8534139691532228, 0.8259106268514922, 0.8259106268514922, 0.8259106268514922, 0.7042998385806911, 0.7042998385806911, 0.7042998385806911, 0.696182872281585, 0.696182872281585, 0.696182872281585, 0.7195875699788705, 0.7195875699788705, 0.7195875699788705, 0.15818005438290217, 0.15818005438290217, 0.15818005438290217, 0.5166369824696898, 0.5166369824696898, 0.5166369824696898, 0.1725614297084147, 0.1725614297084147, 0.1725614297084147, 0.12207869635175772, 0.12207869635175772, 0.12207869635175772, 0.13201024552580365, 0.13201024552580365, 0.13201024552580365, 0.13877774532879594, 0.13877774532879594, 0.13877774532879594, 0.9836808008307404, 0.9836808008307404, 0.9836808008307404, 0.9812985867005078, 0.9812985867005078, 0.9812985867005078, 0.9813960395383832, 0.9813960395383832, 0.9813960395383832, 0.571592277615694, 0.571592277615694, 0.571592277615694, 0.6989533489936877, 0.6989533489936877, 0.6989533489936877, 0.6603457783177271, 0.6603457783177271, 0.6603457783177271, 0.32800110059243304, 0.32800110059243304, 0.32800110059243304, 0.16078192788011203, 0.16078192788011203, 0.16078192788011203, 0.36254694348257344, 0.36254694348257344, 0.36254694348257344, 0.2013452022935961, 0.2013452022935961, 0.2013452022935961, 0.27774548507010377, 0.27774548507010377, 0.27774548507010377, 0.18267888461948334, 0.18267888461948334, 0.18267888461948334, 0.2272473128793685, 0.2272473128793685, 0.2272473128793685, 0.12564518460805651, 0.12564518460805651, 0.12564518460805651, 0.22993559882668235, 0.22993559882668235, 0.22993559882668235, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.031864939435230055, 0.031864939435230055, 0.031864939435230055, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14758685075078015, 0.14758685075078015, 0.14758685075078015, 0.016358068274633486, 0.016358068274633486, 0.016358068274633486, 0.11548804363886633, 0.11548804363886633, 0.11548804363886633, 0.046537883261880575, 0.046537883261880575, 0.046537883261880575, 0.0722656232352914, 0.0722656232352914, 0.0722656232352914, 0.16256029501534208, 0.16256029501534208, 0.16256029501534208, 0.09218406533944234, 0.09218406533944234, 0.09218406533944234, 0.09134377484696654, 0.09134377484696654, 0.09134377484696654, 0.08015267049099861, 0.08015267049099861, 0.08015267049099861, 0.5116383757521481, 0.5116383757521481, 0.5116383757521481, 0.5191428221530466, 0.5191428221530466, 0.5191428221530466, 0.5504059110099802, 0.5504059110099802, 0.5504059110099802, 0.12033445110480645, 0.12033445110480645, 0.12033445110480645, 0.12614537414050464, 0.12614537414050464, 0.12614537414050464, 0.15050378649096596, 0.15050378649096596, 0.15050378649096596, 0.3003196175033437, 0.3003196175033437, 0.3003196175033437, 0.20118218681952627, 0.20118218681952627, 0.20118218681952627, 0.19078084507741655, 0.19078084507741655, 0.19078084507741655, 0.3713588312127175, 0.3713588312127175, 0.3713588312127175, 0.43293616937817037, 0.43293616937817037, 0.43293616937817037, 0.39335043851040885, 0.39335043851040885, 0.39335043851040885, 0.20738137110138544, 0.20738137110138544, 0.20738137110138544, 0.1936795353570102, 0.1936795353570102, 0.1936795353570102, 0.21051476506118283, 0.21051476506118283, 0.21051476506118283, 0.23586972319202526, 0.23586972319202526, 0.23586972319202526, 0.2429629685405651, 0.2429629685405651, 0.2429629685405651, 0.23109516256056573, 0.23109516256056573, 0.23109516256056573, 0.2427788611490349, 0.2427788611490349, 0.2427788611490349, 0.7182376837394016, 0.7182376837394016, 0.7182376837394016, 0.21856358953151778, 0.21856358953151778, 0.21856358953151778, 0.897418630022083, 0.897418630022083, 0.897418630022083, 0.1585089426481876, 0.1585089426481876, 0.1585089426481876, 0.1675809531137593, 0.1675809531137593, 0.1675809531137593, 0.16763152466518527, 0.16763152466518527, 0.16763152466518527, 0.2114166914915515, 0.2114166914915515, 0.2114166914915515, 0.6295813990172708, 0.6295813990172708, 0.6295813990172708, 0.22137224646990195, 0.22137224646990195, 0.22137224646990195, 0.19787716270696487, 0.19787716270696487, 0.19787716270696487, 0.18603962805347252, 0.18603962805347252, 0.18603962805347252, 0.09196488819870774, 0.09196488819870774, 0.09196488819870774, 0.11299272907833435, 0.11299272907833435, 0.11299272907833435, 0.11202358674868373, 0.11202358674868373, 0.11202358674868373]}, "mutation_prompt": null}
{"id": "f4a8bedf-9696-481d-ba76-81242ba957ea", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.1\n        self.momentum = 0.9\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98 + 0.01 * np.sin(2 * np.pi * eval_count / self.budget))\n            \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            stochastic_explosion = np.random.uniform(0.9, 1.1, size=velocities.shape)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity) * stochastic_explosion\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Incorporate adaptive inertia weight oscillation and stochastic velocity explosion control to enhance exploration and convergence in the search space.", "configspace": "", "generation": 16, "fitness": 0.3295244528469813, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.28.", "error": "", "parent_id": "e7c3edd3-a75c-4ba3-b1f0-cba98e0c2b3e", "metadata": {"aucs": [0.8611928416620841, 0.8611928416620841, 0.8611928416620841, 0.8759983785484757, 0.8759983785484757, 0.8759983785484757, 0.8830444422394632, 0.8830444422394632, 0.8830444422394632, 0.7037058004866598, 0.7037058004866598, 0.7037058004866598, 0.7253084473308573, 0.7253084473308573, 0.7253084473308573, 0.7209793029049327, 0.7209793029049327, 0.7209793029049327, 0.15777196240498959, 0.15777196240498959, 0.15777196240498959, 0.1739043760607707, 0.1739043760607707, 0.1739043760607707, 0.7431486375197092, 0.7431486375197092, 0.7431486375197092, 0.13410173296069294, 0.13410173296069294, 0.13410173296069294, 0.13393304745953594, 0.13393304745953594, 0.13393304745953594, 0.16063433163908736, 0.16063433163908736, 0.16063433163908736, 0.9831486068410966, 0.9831486068410966, 0.9831486068410966, 0.9776255343412669, 0.9776255343412669, 0.9776255343412669, 0.9766153890455394, 0.9766153890455394, 0.9766153890455394, 0.6825554136145355, 0.6825554136145355, 0.6825554136145355, 0.5887230611432293, 0.5887230611432293, 0.5887230611432293, 0.6708620892633052, 0.6708620892633052, 0.6708620892633052, 0.2080230337858454, 0.2080230337858454, 0.2080230337858454, 0.1619399551329176, 0.1619399551329176, 0.1619399551329176, 0.18196281983582907, 0.18196281983582907, 0.18196281983582907, 0.23046167679228058, 0.23046167679228058, 0.23046167679228058, 0.1327192746149547, 0.1327192746149547, 0.1327192746149547, 0.1285384513379637, 0.1285384513379637, 0.1285384513379637, 0.22586601404011764, 0.22586601404011764, 0.22586601404011764, 0.23748225867371364, 0.23748225867371364, 0.23748225867371364, 0.2324493926519352, 0.2324493926519352, 0.2324493926519352, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.16823439433002862, 0.16823439433002862, 0.16823439433002862, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09574478932235708, 0.09574478932235708, 0.09574478932235708, 0.02342948246542509, 0.02342948246542509, 0.02342948246542509, 0.11679302342211884, 0.11679302342211884, 0.11679302342211884, 0.04814835896046277, 0.04814835896046277, 0.04814835896046277, 0.08907816164314974, 0.08907816164314974, 0.08907816164314974, 0.09728609495973273, 0.09728609495973273, 0.09728609495973273, 0.09373048984360999, 0.09373048984360999, 0.09373048984360999, 0.03889891235446907, 0.03889891235446907, 0.03889891235446907, 0.10724725641560251, 0.10724725641560251, 0.10724725641560251, 0.5176442926331519, 0.5176442926331519, 0.5176442926331519, 0.5597243649346804, 0.5597243649346804, 0.5597243649346804, 0.5537349635921025, 0.5537349635921025, 0.5537349635921025, 0.11390867758793555, 0.11390867758793555, 0.11390867758793555, 0.12997842615230182, 0.12997842615230182, 0.12997842615230182, 0.10398490781062897, 0.10398490781062897, 0.10398490781062897, 0.19759890575198358, 0.19759890575198358, 0.19759890575198358, 0.17939451909959847, 0.17939451909959847, 0.17939451909959847, 0.2657909484746208, 0.2657909484746208, 0.2657909484746208, 0.3979041463260262, 0.3979041463260262, 0.3979041463260262, 0.5536277638361632, 0.5536277638361632, 0.5536277638361632, 0.6601058648181571, 0.6601058648181571, 0.6601058648181571, 0.1434743195660243, 0.1434743195660243, 0.1434743195660243, 0.22135934614384545, 0.22135934614384545, 0.22135934614384545, 0.13903467512258594, 0.13903467512258594, 0.13903467512258594, 0.23968588091787246, 0.23968588091787246, 0.23968588091787246, 0.22955054165715505, 0.22955054165715505, 0.22955054165715505, 0.2052048471416158, 0.2052048471416158, 0.2052048471416158, 0.21704010494746206, 0.21704010494746206, 0.21704010494746206, 0.20092732556265402, 0.20092732556265402, 0.20092732556265402, 0.25052849151657497, 0.25052849151657497, 0.25052849151657497, 0.9161966663691817, 0.9161966663691817, 0.9161966663691817, 0.15861998409060907, 0.15861998409060907, 0.15861998409060907, 0.7628790950468072, 0.7628790950468072, 0.7628790950468072, 0.16836210465860968, 0.16836210465860968, 0.16836210465860968, 0.21226359182340904, 0.21226359182340904, 0.21226359182340904, 0.6894926182599825, 0.6894926182599825, 0.6894926182599825, 0.23003280859744413, 0.23003280859744413, 0.23003280859744413, 0.2238486939435741, 0.2238486939435741, 0.2238486939435741, 0.18703690505344928, 0.18703690505344928, 0.18703690505344928, 0.08951152364390547, 0.08951152364390547, 0.08951152364390547, 0.0804849786207571, 0.0804849786207571, 0.0804849786207571, 0.15534108523304113, 0.15534108523304113, 0.15534108523304113]}, "mutation_prompt": null}
{"id": "60c4a70a-69c1-4b49-8951-653d7019d8f1", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.learning_rate = 0.1\n        self.momentum = 0.9\n        self.adaptive_switch_threshold = 0.2  # New strategy switch parameter\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            inertia_decay = 0.99 if eval_count - last_improvement > self.population_size else 1.0\n            self.inertia_weight *= inertia_decay\n            \n            if eval_count / self.budget < self.adaptive_switch_threshold:\n                self.cognitive_coef, self.social_coef = 1.7, 1.3\n            else:\n                self.cognitive_coef, self.social_coef = 1.3, 1.7\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities) + cognitive_velocity + social_velocity\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "Hybrid PSO with Adaptive Strategy Switching for Enhanced Exploration and Exploitation.", "configspace": "", "generation": 17, "fitness": 0.3089476287952023, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.27.", "error": "", "parent_id": "e7c3edd3-a75c-4ba3-b1f0-cba98e0c2b3e", "metadata": {"aucs": [0.86959216234688, 0.86959216234688, 0.86959216234688, 0.8667382285681811, 0.8667382285681811, 0.8667382285681811, 0.8711848502456196, 0.8711848502456196, 0.8711848502456196, 0.6225279136318347, 0.6225279136318347, 0.6225279136318347, 0.6753922764531668, 0.6753922764531668, 0.6753922764531668, 0.018639943776483592, 0.018639943776483592, 0.018639943776483592, 0.1719822679881312, 0.1719822679881312, 0.1719822679881312, 0.15671803724374644, 0.15671803724374644, 0.15671803724374644, 0.1646312962093618, 0.1646312962093618, 0.1646312962093618, 0.17111142855272587, 0.17111142855272587, 0.17111142855272587, 0.14997298850986152, 0.14997298850986152, 0.14997298850986152, 0.13662763564627423, 0.13662763564627423, 0.13662763564627423, 0.9837219079426996, 0.9837219079426996, 0.9837219079426996, 0.983401834510628, 0.983401834510628, 0.983401834510628, 0.9772807828240535, 0.9772807828240535, 0.9772807828240535, 0.6495932648543004, 0.6495932648543004, 0.6495932648543004, 0.627200739757307, 0.627200739757307, 0.627200739757307, 0.7102546230783958, 0.7102546230783958, 0.7102546230783958, 0.22302126574707748, 0.22302126574707748, 0.22302126574707748, 0.16193778028211558, 0.16193778028211558, 0.16193778028211558, 0.11687797618171003, 0.11687797618171003, 0.11687797618171003, 0.30411694134764977, 0.30411694134764977, 0.30411694134764977, 0.130939043909155, 0.130939043909155, 0.130939043909155, 0.12967770256307543, 0.12967770256307543, 0.12967770256307543, 0.22991913109478457, 0.22991913109478457, 0.22991913109478457, 0.13207669821239432, 0.13207669821239432, 0.13207669821239432, 0.628578416947021, 0.628578416947021, 0.628578416947021, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03120549995538835, 0.03120549995538835, 0.03120549995538835, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08714878253528346, 0.08714878253528346, 0.08714878253528346, 0.013073319293444574, 0.013073319293444574, 0.013073319293444574, 0.10564204328040883, 0.10564204328040883, 0.10564204328040883, 0.04764144952878635, 0.04764144952878635, 0.04764144952878635, 0.14493223136224276, 0.14493223136224276, 0.14493223136224276, 0.16293447341665246, 0.16293447341665246, 0.16293447341665246, 0.1979929545733229, 0.1979929545733229, 0.1979929545733229, 0.043560254293034784, 0.043560254293034784, 0.043560254293034784, 0.08231591597772736, 0.08231591597772736, 0.08231591597772736, 0.5493266632633329, 0.5493266632633329, 0.5493266632633329, 0.5963867705063309, 0.5963867705063309, 0.5963867705063309, 0.5860927363167143, 0.5860927363167143, 0.5860927363167143, 0.16024548210798817, 0.16024548210798817, 0.16024548210798817, 0.15047885904709313, 0.15047885904709313, 0.15047885904709313, 0.1857755253421417, 0.1857755253421417, 0.1857755253421417, 0.170164105158362, 0.170164105158362, 0.170164105158362, 0.18157798758393262, 0.18157798758393262, 0.18157798758393262, 0.2577214903254761, 0.2577214903254761, 0.2577214903254761, 0.3864165275972248, 0.3864165275972248, 0.3864165275972248, 0.499124201702113, 0.499124201702113, 0.499124201702113, 0.4874972497253066, 0.4874972497253066, 0.4874972497253066, 0.2331882390721799, 0.2331882390721799, 0.2331882390721799, 0.21206391814700642, 0.21206391814700642, 0.21206391814700642, 0.2561600196746341, 0.2561600196746341, 0.2561600196746341, 0.18890084505607696, 0.18890084505607696, 0.18890084505607696, 0.20007325007801202, 0.20007325007801202, 0.20007325007801202, 0.22891509222367246, 0.22891509222367246, 0.22891509222367246, 0.21086878747837012, 0.21086878747837012, 0.21086878747837012, 0.18172297102683455, 0.18172297102683455, 0.18172297102683455, 0.21487320288903367, 0.21487320288903367, 0.21487320288903367, 0.917937504875181, 0.917937504875181, 0.917937504875181, 0.15972019238007562, 0.15972019238007562, 0.15972019238007562, 0.7001857390520818, 0.7001857390520818, 0.7001857390520818, 0.16903944749098776, 0.16903944749098776, 0.16903944749098776, 0.21101395505295928, 0.21101395505295928, 0.21101395505295928, 0.15632372248980209, 0.15632372248980209, 0.15632372248980209, 0.19989565310516477, 0.19989565310516477, 0.19989565310516477, 0.20148651952055974, 0.20148651952055974, 0.20148651952055974, 0.24656655746948775, 0.24656655746948775, 0.24656655746948775, 0.09277184784267611, 0.09277184784267611, 0.09277184784267611, 0.10574689694777262, 0.10574689694777262, 0.10574689694777262, 0.16560325006505905, 0.16560325006505905, 0.16560325006505905]}, "mutation_prompt": null}
{"id": "aebdd4ff-28a1-4aff-95f0-3e51e303b80c", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.12  # Adjusted adaptive learning rate\n        self.momentum = 0.92       # Improved adaptive momentum\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            # Evaluate current positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            # Adjust inertia weight based on improvement\n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)\n            \n            # Dynamic adjustment of coefficients\n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            # Update velocities and positions with improved momentum and learning rate\n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "EnhancedADSA with improved adaptive momentum and exploration strategy for faster convergence.", "configspace": "", "generation": 18, "fitness": 0.31523129915761633, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.26.", "error": "", "parent_id": "e7c3edd3-a75c-4ba3-b1f0-cba98e0c2b3e", "metadata": {"aucs": [0.8587342654545757, 0.8587342654545757, 0.8587342654545757, 0.8658891743242424, 0.8658891743242424, 0.8658891743242424, 0.8617875265194084, 0.8617875265194084, 0.8617875265194084, 0.6740296971570703, 0.6740296971570703, 0.6740296971570703, 0.7326200937476997, 0.7326200937476997, 0.7326200937476997, 0.7300562622776241, 0.7300562622776241, 0.7300562622776241, 0.1517172536860134, 0.1517172536860134, 0.1517172536860134, 0.166942993557038, 0.166942993557038, 0.166942993557038, 0.1491985227818584, 0.1491985227818584, 0.1491985227818584, 0.11800710852788421, 0.11800710852788421, 0.11800710852788421, 0.11148355960746992, 0.11148355960746992, 0.11148355960746992, 0.13959141279500054, 0.13959141279500054, 0.13959141279500054, 0.9812433191346065, 0.9812433191346065, 0.9812433191346065, 0.9800255272047818, 0.9800255272047818, 0.9800255272047818, 0.9771759928833614, 0.9771759928833614, 0.9771759928833614, 0.6707384599344066, 0.6707384599344066, 0.6707384599344066, 0.34096279046377453, 0.34096279046377453, 0.34096279046377453, 0.6777202087167459, 0.6777202087167459, 0.6777202087167459, 0.61512277330267, 0.61512277330267, 0.61512277330267, 0.16050371802354835, 0.16050371802354835, 0.16050371802354835, 0.21257921958700476, 0.21257921958700476, 0.21257921958700476, 0.21037534387409318, 0.21037534387409318, 0.21037534387409318, 0.19636821850924713, 0.19636821850924713, 0.19636821850924713, 0.20872702853710257, 0.20872702853710257, 0.20872702853710257, 0.17949677808749787, 0.17949677808749787, 0.17949677808749787, 0.22611135025501417, 0.22611135025501417, 0.22611135025501417, 0.2427797461752843, 0.2427797461752843, 0.2427797461752843, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04706873894847685, 0.04706873894847685, 0.04706873894847685, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09065054915320869, 0.09065054915320869, 0.09065054915320869, 0.007181249590702987, 0.007181249590702987, 0.007181249590702987, 0.09091581503637025, 0.09091581503637025, 0.09091581503637025, 0.07012908376833071, 0.07012908376833071, 0.07012908376833071, 0.19725155249213278, 0.19725155249213278, 0.19725155249213278, 0.2603762105285631, 0.2603762105285631, 0.2603762105285631, 0.17083938370184515, 0.17083938370184515, 0.17083938370184515, 0.05075462404678854, 0.05075462404678854, 0.05075462404678854, 0.08192575789679701, 0.08192575789679701, 0.08192575789679701, 0.529616559012973, 0.529616559012973, 0.529616559012973, 0.5091337543417895, 0.5091337543417895, 0.5091337543417895, 0.5705808798565835, 0.5705808798565835, 0.5705808798565835, 0.15435758731744276, 0.15435758731744276, 0.15435758731744276, 0.1765588852577583, 0.1765588852577583, 0.1765588852577583, 0.1297956898602386, 0.1297956898602386, 0.1297956898602386, 0.20216102975221506, 0.20216102975221506, 0.20216102975221506, 0.21658157052141347, 0.21658157052141347, 0.21658157052141347, 0.2448736464376, 0.2448736464376, 0.2448736464376, 0.33327730389947763, 0.33327730389947763, 0.33327730389947763, 0.34800181347913806, 0.34800181347913806, 0.34800181347913806, 0.3394375707642505, 0.3394375707642505, 0.3394375707642505, 0.2571366980193599, 0.2571366980193599, 0.2571366980193599, 0.2597325858209968, 0.2597325858209968, 0.2597325858209968, 0.16257033937888377, 0.16257033937888377, 0.16257033937888377, 0.19975457376059236, 0.19975457376059236, 0.19975457376059236, 0.23360096321697255, 0.23360096321697255, 0.23360096321697255, 0.25211003258470444, 0.25211003258470444, 0.25211003258470444, 0.20483505049120743, 0.20483505049120743, 0.20483505049120743, 0.2486269762241199, 0.2486269762241199, 0.2486269762241199, 0.21944606830913904, 0.21944606830913904, 0.21944606830913904, 0.9018060608493537, 0.9018060608493537, 0.9018060608493537, 0.15870650925552232, 0.15870650925552232, 0.15870650925552232, 0.6493432033328044, 0.6493432033328044, 0.6493432033328044, 0.16874953011659088, 0.16874953011659088, 0.16874953011659088, 0.21189409342932042, 0.21189409342932042, 0.21189409342932042, 0.3541125180049962, 0.3541125180049962, 0.3541125180049962, 0.20427281042163958, 0.20427281042163958, 0.20427281042163958, 0.19186740389148438, 0.19186740389148438, 0.19186740389148438, 0.22533217823390939, 0.22533217823390939, 0.22533217823390939, 0.0939779825238316, 0.0939779825238316, 0.0939779825238316, 0.09653689326196968, 0.09653689326196968, 0.09653689326196968, 0.14058346743185735, 0.14058346743185735, 0.14058346743185735]}, "mutation_prompt": null}
{"id": "81990e71-4250-455f-9980-286e53e710e7", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05  # Adjusted adaptive learning rate for faster convergence\n        self.momentum = 0.95      # Fine-tuned momentum for stability and exploration\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            # Evaluate current positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            # Adjust inertia weight based on improvement\n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)\n            \n            # Dynamic adjustment of coefficients\n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            # Update velocities and positions with adjusted momentum and learning rate\n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Enhanced ADSA with optimized learning rate adaptation and improved momentum handling for faster convergence.", "configspace": "", "generation": 19, "fitness": 0.33896072610117217, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.27.", "error": "", "parent_id": "e7c3edd3-a75c-4ba3-b1f0-cba98e0c2b3e", "metadata": {"aucs": [0.8576534832565132, 0.8576534832565132, 0.8576534832565132, 0.8565123398618373, 0.8565123398618373, 0.8565123398618373, 0.866921730817145, 0.866921730817145, 0.866921730817145, 0.6096206891346194, 0.6096206891346194, 0.6096206891346194, 0.6936829571061802, 0.6936829571061802, 0.6936829571061802, 0.670137144017568, 0.670137144017568, 0.670137144017568, 0.1706385931553761, 0.1706385931553761, 0.1706385931553761, 0.6024510820454506, 0.6024510820454506, 0.6024510820454506, 0.5639936404734593, 0.5639936404734593, 0.5639936404734593, 0.1592879216676072, 0.1592879216676072, 0.1592879216676072, 0.1203970080952751, 0.1203970080952751, 0.1203970080952751, 0.12333553767689609, 0.12333553767689609, 0.12333553767689609, 0.9832392391365186, 0.9832392391365186, 0.9832392391365186, 0.9799669299694973, 0.9799669299694973, 0.9799669299694973, 0.9771626317362031, 0.9771626317362031, 0.9771626317362031, 0.7115457059543228, 0.7115457059543228, 0.7115457059543228, 0.6194254835210906, 0.6194254835210906, 0.6194254835210906, 0.7099899577285885, 0.7099899577285885, 0.7099899577285885, 0.2213241086871145, 0.2213241086871145, 0.2213241086871145, 0.20879032504979356, 0.20879032504979356, 0.20879032504979356, 0.17489980678942707, 0.17489980678942707, 0.17489980678942707, 0.21288956836250839, 0.21288956836250839, 0.21288956836250839, 0.20443080957688287, 0.20443080957688287, 0.20443080957688287, 0.2702197666460785, 0.2702197666460785, 0.2702197666460785, 0.23360806451838978, 0.23360806451838978, 0.23360806451838978, 0.2798949553389921, 0.2798949553389921, 0.2798949553389921, 0.12412983486711293, 0.12412983486711293, 0.12412983486711293, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04768404938148818, 0.04768404938148818, 0.04768404938148818, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09865017604824156, 0.09865017604824156, 0.09865017604824156, 0.01283654941765966, 0.01283654941765966, 0.01283654941765966, 0.087055104716101, 0.087055104716101, 0.087055104716101, 0.04859764756339613, 0.04859764756339613, 0.04859764756339613, 0.19524326179027374, 0.19524326179027374, 0.19524326179027374, 0.21372848864515193, 0.21372848864515193, 0.21372848864515193, 0.2934979413486982, 0.2934979413486982, 0.2934979413486982, 0.07039631877084052, 0.07039631877084052, 0.07039631877084052, 0.0817202849138492, 0.0817202849138492, 0.0817202849138492, 0.5343280373133144, 0.5343280373133144, 0.5343280373133144, 0.5185168908333156, 0.5185168908333156, 0.5185168908333156, 0.5771450378282352, 0.5771450378282352, 0.5771450378282352, 0.1814759391383619, 0.1814759391383619, 0.1814759391383619, 0.14215620443010735, 0.14215620443010735, 0.14215620443010735, 0.10287063333670754, 0.10287063333670754, 0.10287063333670754, 0.3262027044554826, 0.3262027044554826, 0.3262027044554826, 0.21571429881900717, 0.21571429881900717, 0.21571429881900717, 0.2750730143597754, 0.2750730143597754, 0.2750730143597754, 0.6102248559911372, 0.6102248559911372, 0.6102248559911372, 0.4652225054669398, 0.4652225054669398, 0.4652225054669398, 0.7124168692702448, 0.7124168692702448, 0.7124168692702448, 0.21444653072904607, 0.21444653072904607, 0.21444653072904607, 0.19378114085784626, 0.19378114085784626, 0.19378114085784626, 0.21327493703289158, 0.21327493703289158, 0.21327493703289158, 0.21987243929240408, 0.21987243929240408, 0.21987243929240408, 0.2543338262403483, 0.2543338262403483, 0.2543338262403483, 0.2393454625398792, 0.2393454625398792, 0.2393454625398792, 0.24361545470979373, 0.24361545470979373, 0.24361545470979373, 0.26648485574691916, 0.26648485574691916, 0.26648485574691916, 0.20442197984791488, 0.20442197984791488, 0.20442197984791488, 0.9270764070655483, 0.9270764070655483, 0.9270764070655483, 0.15785057245808753, 0.15785057245808753, 0.15785057245808753, 0.16890486586631248, 0.16890486586631248, 0.16890486586631248, 0.21140036794731176, 0.21140036794731176, 0.21140036794731176, 0.21236171329707265, 0.21236171329707265, 0.21236171329707265, 0.7604696693933294, 0.7604696693933294, 0.7604696693933294, 0.20324040447231118, 0.20324040447231118, 0.20324040447231118, 0.21622468812793372, 0.21622468812793372, 0.21622468812793372, 0.19518027508236524, 0.19518027508236524, 0.19518027508236524, 0.09553449695286365, 0.09553449695286365, 0.09553449695286365, 0.07138838406490267, 0.07138838406490267, 0.07138838406490267, 0.1188576785305353, 0.1188576785305353, 0.1188576785305353]}, "mutation_prompt": null}
{"id": "d976f7b5-9583-4f7e-b4cd-448b20dc90b1", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05  # Adjusted adaptive learning rate for faster convergence\n        self.momentum = 0.95      # Fine-tuned momentum for stability and exploration\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            # Evaluate current positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            # Adaptive learning rate based on improvement\n            if eval_count - last_improvement > self.population_size:\n                self.learning_rate = max(0.01, self.learning_rate * 1.02)\n            \n            # Nonlinear inertia weight decay for faster convergence\n            self.inertia_weight = 0.729 - 0.329 * (eval_count / self.budget)**0.5\n            \n            # Dynamic adjustment of coefficients\n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            # Update velocities and positions with adjusted momentum and learning rate\n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "EnhancedADSA with adaptive learning rate adjustment and nonlinear inertia decay for improved convergence speed.", "configspace": "", "generation": 20, "fitness": 0.3370661343954744, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.28.", "error": "", "parent_id": "81990e71-4250-455f-9980-286e53e710e7", "metadata": {"aucs": [0.8826346806941869, 0.8826346806941869, 0.8826346806941869, 0.8808585734751765, 0.8808585734751765, 0.8808585734751765, 0.8832324847747102, 0.8832324847747102, 0.8832324847747102, 0.734589276604563, 0.734589276604563, 0.734589276604563, 0.7359218745916567, 0.7359218745916567, 0.7359218745916567, 0.7669829463087694, 0.7669829463087694, 0.7669829463087694, 0.17214146511414785, 0.17214146511414785, 0.17214146511414785, 0.6212825038660038, 0.6212825038660038, 0.6212825038660038, 0.5376191182967858, 0.5376191182967858, 0.5376191182967858, 0.12951577482962784, 0.12951577482962784, 0.12951577482962784, 0.10445741296181299, 0.10445741296181299, 0.10445741296181299, 0.16562224315871266, 0.16562224315871266, 0.16562224315871266, 0.9800778410913699, 0.9800778410913699, 0.9800778410913699, 0.9797085390570852, 0.9797085390570852, 0.9797085390570852, 0.977048935430005, 0.977048935430005, 0.977048935430005, 0.7319835233154766, 0.7319835233154766, 0.7319835233154766, 0.6575708048157496, 0.6575708048157496, 0.6575708048157496, 0.725184683708594, 0.725184683708594, 0.725184683708594, 0.22349706804819058, 0.22349706804819058, 0.22349706804819058, 0.1914348013813767, 0.1914348013813767, 0.1914348013813767, 0.15069499718234836, 0.15069499718234836, 0.15069499718234836, 0.18555270459085282, 0.18555270459085282, 0.18555270459085282, 0.129313016372546, 0.129313016372546, 0.129313016372546, 0.1954860343592001, 0.1954860343592001, 0.1954860343592001, 0.23086885763667997, 0.23086885763667997, 0.23086885763667997, 0.2579861936515865, 0.2579861936515865, 0.2579861936515865, 0.12962912051051734, 0.12962912051051734, 0.12962912051051734, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05711115473910977, 0.05711115473910977, 0.05711115473910977, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09665010445452937, 0.09665010445452937, 0.09665010445452937, 0.043870755378130566, 0.043870755378130566, 0.043870755378130566, 0.09404125431444499, 0.09404125431444499, 0.09404125431444499, 0.06011822263959421, 0.06011822263959421, 0.06011822263959421, 0.2720340713653796, 0.2720340713653796, 0.2720340713653796, 0.2684830446722998, 0.2684830446722998, 0.2684830446722998, 0.16189514094809532, 0.16189514094809532, 0.16189514094809532, 0.03907965790965029, 0.03907965790965029, 0.03907965790965029, 0.08373397538941862, 0.08373397538941862, 0.08373397538941862, 0.5422085841106616, 0.5422085841106616, 0.5422085841106616, 0.5606921323806984, 0.5606921323806984, 0.5606921323806984, 0.5819697179462515, 0.5819697179462515, 0.5819697179462515, 0.1778612760837066, 0.1778612760837066, 0.1778612760837066, 0.1199755492593495, 0.1199755492593495, 0.1199755492593495, 0.08533493131390735, 0.08533493131390735, 0.08533493131390735, 0.33457510781605526, 0.33457510781605526, 0.33457510781605526, 0.2753300177770841, 0.2753300177770841, 0.2753300177770841, 0.23640712382134166, 0.23640712382134166, 0.23640712382134166, 0.5697825629289941, 0.5697825629289941, 0.5697825629289941, 0.419074952472151, 0.419074952472151, 0.419074952472151, 0.5822677449268985, 0.5822677449268985, 0.5822677449268985, 0.24463168853753958, 0.24463168853753958, 0.24463168853753958, 0.18561556911449983, 0.18561556911449983, 0.18561556911449983, 0.1438772791172005, 0.1438772791172005, 0.1438772791172005, 0.21499910738225814, 0.21499910738225814, 0.21499910738225814, 0.23952210285853348, 0.23952210285853348, 0.23952210285853348, 0.23353433777378108, 0.23353433777378108, 0.23353433777378108, 0.24805552251810992, 0.24805552251810992, 0.24805552251810992, 0.22323265729127206, 0.22323265729127206, 0.22323265729127206, 0.19639909270256561, 0.19639909270256561, 0.19639909270256561, 0.9213762115856367, 0.9213762115856367, 0.9213762115856367, 0.15815186452729646, 0.15815186452729646, 0.15815186452729646, 0.16866640266584143, 0.16866640266584143, 0.16866640266584143, 0.2110995275418145, 0.2110995275418145, 0.2110995275418145, 0.21254822509966775, 0.21254822509966775, 0.21254822509966775, 0.7202759877960017, 0.7202759877960017, 0.7202759877960017, 0.21047389791341342, 0.21047389791341342, 0.21047389791341342, 0.2061155888522067, 0.2061155888522067, 0.2061155888522067, 0.19428753072345006, 0.19428753072345006, 0.19428753072345006, 0.09853504848286865, 0.09853504848286865, 0.09853504848286865, 0.11092157645516931, 0.11092157645516931, 0.11092157645516931, 0.10284989905954611, 0.10284989905954611, 0.10284989905954611]}, "mutation_prompt": null}
{"id": "938f81d8-626d-479b-8065-b67d79aff9e8", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 12)  # Changed from //10 to //12 for adaptive size\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * (0.98 ** 1.05))  # Non-linear decay\n            \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Enhanced ADSA with adaptive population size and non-linear inertia weight decay for improved convergence.", "configspace": "", "generation": 21, "fitness": 0.3250885914863887, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.27.", "error": "", "parent_id": "81990e71-4250-455f-9980-286e53e710e7", "metadata": {"aucs": [0.8558953866087484, 0.8558953866087484, 0.8558953866087484, 0.8639155109902766, 0.8639155109902766, 0.8639155109902766, 0.8625145222191122, 0.8625145222191122, 0.8625145222191122, 0.17220236250286014, 0.17220236250286014, 0.17220236250286014, 0.6767204337999271, 0.6767204337999271, 0.6767204337999271, 0.6688208668361204, 0.6688208668361204, 0.6688208668361204, 0.15521839150008998, 0.15521839150008998, 0.15521839150008998, 0.16695673763165164, 0.16695673763165164, 0.16695673763165164, 0.17991231665442686, 0.17991231665442686, 0.17991231665442686, 0.17855142227705822, 0.17855142227705822, 0.17855142227705822, 0.12033154401619539, 0.12033154401619539, 0.12033154401619539, 0.17436354616280914, 0.17436354616280914, 0.17436354616280914, 0.9832392391365186, 0.9832392391365186, 0.9832392391365186, 0.9799669299694973, 0.9799669299694973, 0.9799669299694973, 0.9771626317362031, 0.9771626317362031, 0.9771626317362031, 0.688858615360618, 0.688858615360618, 0.688858615360618, 0.6056455247206342, 0.6056455247206342, 0.6056455247206342, 0.6572887700390035, 0.6572887700390035, 0.6572887700390035, 0.2234929226211445, 0.2234929226211445, 0.2234929226211445, 0.2146453870456153, 0.2146453870456153, 0.2146453870456153, 0.17489980678942707, 0.17489980678942707, 0.17489980678942707, 0.2081401296849127, 0.2081401296849127, 0.2081401296849127, 0.20225081585053972, 0.20225081585053972, 0.20225081585053972, 0.2698724171718887, 0.2698724171718887, 0.2698724171718887, 0.2388450092665475, 0.2388450092665475, 0.2388450092665475, 0.26383015613113925, 0.26383015613113925, 0.26383015613113925, 0.21287117139818845, 0.21287117139818845, 0.21287117139818845, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06323256607244898, 0.06323256607244898, 0.06323256607244898, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0810033538463335, 0.0810033538463335, 0.0810033538463335, 0.007732442300249387, 0.007732442300249387, 0.007732442300249387, 0.07726682827134024, 0.07726682827134024, 0.07726682827134024, 0.047233651878801575, 0.047233651878801575, 0.047233651878801575, 0.1818987634184589, 0.1818987634184589, 0.1818987634184589, 0.21864611073799367, 0.21864611073799367, 0.21864611073799367, 0.281735347745551, 0.281735347745551, 0.281735347745551, 0.06176400935732451, 0.06176400935732451, 0.06176400935732451, 0.08163895632634799, 0.08163895632634799, 0.08163895632634799, 0.5536610627756774, 0.5536610627756774, 0.5536610627756774, 0.5153712613607697, 0.5153712613607697, 0.5153712613607697, 0.6438235445765439, 0.6438235445765439, 0.6438235445765439, 0.18133119399634245, 0.18133119399634245, 0.18133119399634245, 0.14230591751634292, 0.14230591751634292, 0.14230591751634292, 0.09425234328934462, 0.09425234328934462, 0.09425234328934462, 0.20978345489855632, 0.20978345489855632, 0.20978345489855632, 0.2435736968193145, 0.2435736968193145, 0.2435736968193145, 0.2677213681191334, 0.2677213681191334, 0.2677213681191334, 0.537928535449426, 0.537928535449426, 0.537928535449426, 0.4388487618663227, 0.4388487618663227, 0.4388487618663227, 0.7192835581581776, 0.7192835581581776, 0.7192835581581776, 0.2050132579867615, 0.2050132579867615, 0.2050132579867615, 0.23208368242049227, 0.23208368242049227, 0.23208368242049227, 0.16551111526730022, 0.16551111526730022, 0.16551111526730022, 0.20331972836785484, 0.20331972836785484, 0.20331972836785484, 0.26512147250093965, 0.26512147250093965, 0.26512147250093965, 0.19957111494348123, 0.19957111494348123, 0.19957111494348123, 0.24875103411357824, 0.24875103411357824, 0.24875103411357824, 0.22694707874267916, 0.22694707874267916, 0.22694707874267916, 0.699632727714147, 0.699632727714147, 0.699632727714147, 0.9305761314964893, 0.9305761314964893, 0.9305761314964893, 0.15785237125678797, 0.15785237125678797, 0.15785237125678797, 0.1689046347469515, 0.1689046347469515, 0.1689046347469515, 0.21136766566482068, 0.21136766566482068, 0.21136766566482068, 0.21236177249959842, 0.21236177249959842, 0.21236177249959842, 0.7831672693102354, 0.7831672693102354, 0.7831672693102354, 0.1877469386280557, 0.1877469386280557, 0.1877469386280557, 0.20227260377760703, 0.20227260377760703, 0.20227260377760703, 0.19171995559618205, 0.19171995559618205, 0.19171995559618205, 0.10915291120665893, 0.10915291120665893, 0.10915291120665893, 0.0766028295426322, 0.0766028295426322, 0.0766028295426322, 0.10205299433477921, 0.10205299433477921, 0.10205299433477921]}, "mutation_prompt": null}
{"id": "8c8aa8fb-010f-4101-aecd-3df581bf9751", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n        self.damping_factor = 0.99  # New adaptive damping factor for velocity\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)\n            \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            # Apply adaptive damping factor\n            velocities *= self.damping_factor\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Enhanced ADSA with adaptive damping factor and diversified exploration for improved convergence.", "configspace": "", "generation": 22, "fitness": 0.3222095378844988, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.27.", "error": "", "parent_id": "81990e71-4250-455f-9980-286e53e710e7", "metadata": {"aucs": [0.8565671022167081, 0.8565671022167081, 0.8565671022167081, 0.8761510922831688, 0.8761510922831688, 0.8761510922831688, 0.8661717805032044, 0.8661717805032044, 0.8661717805032044, 0.6781089574691884, 0.6781089574691884, 0.6781089574691884, 0.7086762717515805, 0.7086762717515805, 0.7086762717515805, 0.6947552562710606, 0.6947552562710606, 0.6947552562710606, 0.12763288062173306, 0.12763288062173306, 0.12763288062173306, 0.1586009187157611, 0.1586009187157611, 0.1586009187157611, 0.16563681867795765, 0.16563681867795765, 0.16563681867795765, 0.15586676229226415, 0.15586676229226415, 0.15586676229226415, 0.11635930035734787, 0.11635930035734787, 0.11635930035734787, 0.14363183883813968, 0.14363183883813968, 0.14363183883813968, 0.9831917441833544, 0.9831917441833544, 0.9831917441833544, 0.9798048485879631, 0.9798048485879631, 0.9798048485879631, 0.9771135533309468, 0.9771135533309468, 0.9771135533309468, 0.6294746444775687, 0.6294746444775687, 0.6294746444775687, 0.665368438388177, 0.665368438388177, 0.665368438388177, 0.697688641874364, 0.697688641874364, 0.697688641874364, 0.21940272806621974, 0.21940272806621974, 0.21940272806621974, 0.160528795009237, 0.160528795009237, 0.160528795009237, 0.241087535809287, 0.241087535809287, 0.241087535809287, 0.2182240831852661, 0.2182240831852661, 0.2182240831852661, 0.20358342937916774, 0.20358342937916774, 0.20358342937916774, 0.2106131653821891, 0.2106131653821891, 0.2106131653821891, 0.24159309004137197, 0.24159309004137197, 0.24159309004137197, 0.22763522161621452, 0.22763522161621452, 0.22763522161621452, 0.1257282236172499, 0.1257282236172499, 0.1257282236172499, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.014360129382894438, 0.014360129382894438, 0.014360129382894438, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11559594069928136, 0.11559594069928136, 0.11559594069928136, 0.021192935419792946, 0.021192935419792946, 0.021192935419792946, 0.09510295658325907, 0.09510295658325907, 0.09510295658325907, 0.08319583416397236, 0.08319583416397236, 0.08319583416397236, 0.2563882928309662, 0.2563882928309662, 0.2563882928309662, 0.15986957190483808, 0.15986957190483808, 0.15986957190483808, 0.20983146384436135, 0.20983146384436135, 0.20983146384436135, 0.03865912947624217, 0.03865912947624217, 0.03865912947624217, 0.08344395519241665, 0.08344395519241665, 0.08344395519241665, 0.5347695622620474, 0.5347695622620474, 0.5347695622620474, 0.5823453484529431, 0.5823453484529431, 0.5823453484529431, 0.555580218570427, 0.555580218570427, 0.555580218570427, 0.10654728470463593, 0.10654728470463593, 0.10654728470463593, 0.10876372881012997, 0.10876372881012997, 0.10876372881012997, 0.11447658834796859, 0.11447658834796859, 0.11447658834796859, 0.5431412689887685, 0.5431412689887685, 0.5431412689887685, 0.16718611895988866, 0.16718611895988866, 0.16718611895988866, 0.21743021178489175, 0.21743021178489175, 0.21743021178489175, 0.3731441814003372, 0.3731441814003372, 0.3731441814003372, 0.4734159822646895, 0.4734159822646895, 0.4734159822646895, 0.43227045379740414, 0.43227045379740414, 0.43227045379740414, 0.22527606966069003, 0.22527606966069003, 0.22527606966069003, 0.3518405331055584, 0.3518405331055584, 0.3518405331055584, 0.30303589640741135, 0.30303589640741135, 0.30303589640741135, 0.19761277146041523, 0.19761277146041523, 0.19761277146041523, 0.2765684580157256, 0.2765684580157256, 0.2765684580157256, 0.21427616774077973, 0.21427616774077973, 0.21427616774077973, 0.24193346878292832, 0.24193346878292832, 0.24193346878292832, 0.2027865218832069, 0.2027865218832069, 0.2027865218832069, 0.2183947134319324, 0.2183947134319324, 0.2183947134319324, 0.9234781620082666, 0.9234781620082666, 0.9234781620082666, 0.1578631385811985, 0.1578631385811985, 0.1578631385811985, 0.16887365950048083, 0.16887365950048083, 0.16887365950048083, 0.21190552170912802, 0.21190552170912802, 0.21190552170912802, 0.2120130018184403, 0.2120130018184403, 0.2120130018184403, 0.7739509354840935, 0.7739509354840935, 0.7739509354840935, 0.206423785544407, 0.206423785544407, 0.206423785544407, 0.22290882337997664, 0.22290882337997664, 0.22290882337997664, 0.1889868807439793, 0.1889868807439793, 0.1889868807439793, 0.08267994517750721, 0.08267994517750721, 0.08267994517750721, 0.09680264089070278, 0.09680264089070278, 0.09680264089070278, 0.10536735156823929, 0.10536735156823929, 0.10536735156823929]}, "mutation_prompt": null}
{"id": "c24b2667-aba8-4601-a9e4-c02960a57bf3", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05  # Adjusted adaptive learning rate for faster convergence\n        self.momentum = 0.95      # Fine-tuned momentum for stability and exploration\n        self.mutation_rate = 0.01  # Introduce mutation mechanism\n\n    def mutate(self, positions):\n        mutations = np.random.uniform(-0.1, 0.1, positions.shape)\n        mutation_mask = np.random.rand(*positions.shape) < self.mutation_rate\n        positions[mutation_mask] += mutations[mutation_mask]\n        return np.clip(positions, self.lower_bound, self.upper_bound)\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            # Evaluate current positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            # Adjust inertia weight based on improvement\n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)\n            \n            # Dynamic adjustment of coefficients\n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            # Update velocities and positions with adjusted momentum and learning rate\n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = self.mutate(positions)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Enhanced ADSA with adaptive population size and improved convergence strategy through adaptive learning rate and mutation mechanism.", "configspace": "", "generation": 23, "fitness": 0.3026707861043133, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.27.", "error": "", "parent_id": "81990e71-4250-455f-9980-286e53e710e7", "metadata": {"aucs": [0.8298384310565544, 0.8298384310565544, 0.8298384310565544, 0.8486865166712755, 0.8486865166712755, 0.8486865166712755, 0.857266937347357, 0.857266937347357, 0.857266937347357, 0.6545399188954166, 0.6545399188954166, 0.6545399188954166, 0.6450304021406286, 0.6450304021406286, 0.6450304021406286, 0.7537465716411259, 0.7537465716411259, 0.7537465716411259, 0.15294066497557302, 0.15294066497557302, 0.15294066497557302, 0.1757492571381314, 0.1757492571381314, 0.1757492571381314, 0.13777045677988153, 0.13777045677988153, 0.13777045677988153, 0.13569289343999957, 0.13569289343999957, 0.13569289343999957, 0.1400705714752366, 0.1400705714752366, 0.1400705714752366, 0.1210907482584136, 0.1210907482584136, 0.1210907482584136, 0.9832052828460718, 0.9832052828460718, 0.9832052828460718, 0.9797876949024011, 0.9797876949024011, 0.9797876949024011, 0.9724086814908527, 0.9724086814908527, 0.9724086814908527, 0.5231661286217868, 0.5231661286217868, 0.5231661286217868, 0.6213903957310865, 0.6213903957310865, 0.6213903957310865, 0.6090803638419091, 0.6090803638419091, 0.6090803638419091, 0.22414074934797823, 0.22414074934797823, 0.22414074934797823, 0.19144538901324792, 0.19144538901324792, 0.19144538901324792, 0.23500907626159506, 0.23500907626159506, 0.23500907626159506, 0.22146898338854804, 0.22146898338854804, 0.22146898338854804, 0.22371842095058825, 0.22371842095058825, 0.22371842095058825, 0.21569393294802308, 0.21569393294802308, 0.21569393294802308, 0.21628503725568893, 0.21628503725568893, 0.21628503725568893, 0.11986805744686557, 0.11986805744686557, 0.11986805744686557, 0.13186089362998643, 0.13186089362998643, 0.13186089362998643, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01244517823141833, 0.01244517823141833, 0.01244517823141833, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11506336098810754, 0.11506336098810754, 0.11506336098810754, 0.025817472659306673, 0.025817472659306673, 0.025817472659306673, 0.0866352358161695, 0.0866352358161695, 0.0866352358161695, 0.04825886828975112, 0.04825886828975112, 0.04825886828975112, 0.07529434636111032, 0.07529434636111032, 0.07529434636111032, 0.19556940477781726, 0.19556940477781726, 0.19556940477781726, 0.10121623384081646, 0.10121623384081646, 0.10121623384081646, 0.04204189025121363, 0.04204189025121363, 0.04204189025121363, 0.09579465319847857, 0.09579465319847857, 0.09579465319847857, 0.5671072515397557, 0.5671072515397557, 0.5671072515397557, 0.5434566664125582, 0.5434566664125582, 0.5434566664125582, 0.5666935611465891, 0.5666935611465891, 0.5666935611465891, 0.11520731800433492, 0.11520731800433492, 0.11520731800433492, 0.15571836449957388, 0.15571836449957388, 0.15571836449957388, 0.10840119752504507, 0.10840119752504507, 0.10840119752504507, 0.2556923257031398, 0.2556923257031398, 0.2556923257031398, 0.18744106856611653, 0.18744106856611653, 0.18744106856611653, 0.19733218042972855, 0.19733218042972855, 0.19733218042972855, 0.3615721588495405, 0.3615721588495405, 0.3615721588495405, 0.4949177569505082, 0.4949177569505082, 0.4949177569505082, 0.27634737940755216, 0.27634737940755216, 0.27634737940755216, 0.19928893077700938, 0.19928893077700938, 0.19928893077700938, 0.2384486726759555, 0.2384486726759555, 0.2384486726759555, 0.12373238659259389, 0.12373238659259389, 0.12373238659259389, 0.2142302013455667, 0.2142302013455667, 0.2142302013455667, 0.21012962203291186, 0.21012962203291186, 0.21012962203291186, 0.2208072731149623, 0.2208072731149623, 0.2208072731149623, 0.23595952519654473, 0.23595952519654473, 0.23595952519654473, 0.2211427256895775, 0.2211427256895775, 0.2211427256895775, 0.6546304372239125, 0.6546304372239125, 0.6546304372239125, 0.9127893986945056, 0.9127893986945056, 0.9127893986945056, 0.20307727130001685, 0.20307727130001685, 0.20307727130001685, 0.13634781517908523, 0.13634781517908523, 0.13634781517908523, 0.1685633497183957, 0.1685633497183957, 0.1685633497183957, 0.2118184205419923, 0.2118184205419923, 0.2118184205419923, 0.37296843741510366, 0.37296843741510366, 0.37296843741510366, 0.21288238380592817, 0.21288238380592817, 0.21288238380592817, 0.18588270873383517, 0.18588270873383517, 0.18588270873383517, 0.194346510720813, 0.194346510720813, 0.194346510720813, 0.08765378243097166, 0.08765378243097166, 0.08765378243097166, 0.09715493614594184, 0.09715493614594184, 0.09715493614594184, 0.1412654792300837, 0.1412654792300837, 0.1412654792300837]}, "mutation_prompt": null}
{"id": "d5a9e2c7-4d46-4f9a-954e-c091934ba90c", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.9  # Increased initial inertia weight\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n        self.velocity_threshold = 1e-3  # New adaptive velocity threshold\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            # Evaluate current positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            # Adjust inertia weight and velocity threshold\n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)\n            \n            # Dynamic adjustment of coefficients\n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            # Update velocities and positions with adjusted momentum and learning rate\n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = np.where(np.abs(velocities) < self.velocity_threshold, 0, velocities)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Enhanced ADSA with dynamic inertia weight adaptation and adaptive velocity threshold for improved convergence.", "configspace": "", "generation": 24, "fitness": 0.27952096723219905, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.24.", "error": "", "parent_id": "81990e71-4250-455f-9980-286e53e710e7", "metadata": {"aucs": [0.8060890078866755, 0.8060890078866755, 0.8060890078866755, 0.7878044252913905, 0.7878044252913905, 0.7878044252913905, 0.7965734436149385, 0.7965734436149385, 0.7965734436149385, 0.3221986539551487, 0.3221986539551487, 0.3221986539551487, 0.36735015806312776, 0.36735015806312776, 0.36735015806312776, 0.3926874257714491, 0.3926874257714491, 0.3926874257714491, 0.14749515633682952, 0.14749515633682952, 0.14749515633682952, 0.12396962511077914, 0.12396962511077914, 0.12396962511077914, 0.17175580873028262, 0.17175580873028262, 0.17175580873028262, 0.17103196891213102, 0.17103196891213102, 0.17103196891213102, 0.1152641895874289, 0.1152641895874289, 0.1152641895874289, 0.1340683996426878, 0.1340683996426878, 0.1340683996426878, 0.9835132834311102, 0.9835132834311102, 0.9835132834311102, 0.983168407839175, 0.983168407839175, 0.983168407839175, 0.9806306350558245, 0.9806306350558245, 0.9806306350558245, 0.54059905049351, 0.54059905049351, 0.54059905049351, 0.4981455631780257, 0.4981455631780257, 0.4981455631780257, 0.5072964864895622, 0.5072964864895622, 0.5072964864895622, 0.36264054618749775, 0.36264054618749775, 0.36264054618749775, 0.18776422024066386, 0.18776422024066386, 0.18776422024066386, 0.21398048436421657, 0.21398048436421657, 0.21398048436421657, 0.2507718537359841, 0.2507718537359841, 0.2507718537359841, 0.12043931022520304, 0.12043931022520304, 0.12043931022520304, 0.19872770560876196, 0.19872770560876196, 0.19872770560876196, 0.2110874902354185, 0.2110874902354185, 0.2110874902354185, 0.19341185314259934, 0.19341185314259934, 0.19341185314259934, 0.15318580912617652, 0.15318580912617652, 0.15318580912617652, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0747136261610909, 0.0747136261610909, 0.0747136261610909, 0.024014956739531357, 0.024014956739531357, 0.024014956739531357, 0.14846940996501945, 0.14846940996501945, 0.14846940996501945, 0.06930055881617592, 0.06930055881617592, 0.06930055881617592, 0.1728388792345955, 0.1728388792345955, 0.1728388792345955, 0.3292821004123653, 0.3292821004123653, 0.3292821004123653, 0.1172385528397748, 0.1172385528397748, 0.1172385528397748, 0.036574009446412536, 0.036574009446412536, 0.036574009446412536, 0.07970723943128144, 0.07970723943128144, 0.07970723943128144, 0.5387563343538941, 0.5387563343538941, 0.5387563343538941, 0.5431536012179687, 0.5431536012179687, 0.5431536012179687, 0.5426484303019443, 0.5426484303019443, 0.5426484303019443, 0.11431471927956116, 0.11431471927956116, 0.11431471927956116, 0.11761394460622143, 0.11761394460622143, 0.11761394460622143, 0.11927152905379224, 0.11927152905379224, 0.11927152905379224, 0.22231850106025852, 0.22231850106025852, 0.22231850106025852, 0.20548161670180465, 0.20548161670180465, 0.20548161670180465, 0.16137168249295097, 0.16137168249295097, 0.16137168249295097, 0.4232640277997627, 0.4232640277997627, 0.4232640277997627, 0.4276284816449093, 0.4276284816449093, 0.4276284816449093, 0.40351312031956954, 0.40351312031956954, 0.40351312031956954, 0.24109373894802666, 0.24109373894802666, 0.24109373894802666, 0.16801798371128263, 0.16801798371128263, 0.16801798371128263, 0.24123211165293057, 0.24123211165293057, 0.24123211165293057, 0.18545895801738266, 0.18545895801738266, 0.18545895801738266, 0.21806237965103725, 0.21806237965103725, 0.21806237965103725, 0.24067872531953027, 0.24067872531953027, 0.24067872531953027, 0.21490655561809058, 0.21490655561809058, 0.21490655561809058, 0.20638182025815222, 0.20638182025815222, 0.20638182025815222, 0.1952376659950945, 0.1952376659950945, 0.1952376659950945, 0.875356612831809, 0.875356612831809, 0.875356612831809, 0.15656268855726063, 0.15656268855726063, 0.15656268855726063, 0.1673086251353485, 0.1673086251353485, 0.1673086251353485, 0.16714987586051155, 0.16714987586051155, 0.16714987586051155, 0.21057261862754872, 0.21057261862754872, 0.21057261862754872, 0.15549129052545452, 0.15549129052545452, 0.15549129052545452, 0.17871557709948227, 0.17871557709948227, 0.17871557709948227, 0.20446867286770654, 0.20446867286770654, 0.20446867286770654, 0.2096801821108235, 0.2096801821108235, 0.2096801821108235, 0.10000688262190272, 0.10000688262190272, 0.10000688262190272, 0.10088325405020027, 0.10088325405020027, 0.10088325405020027, 0.09481713712327033, 0.09481713712327033, 0.09481713712327033]}, "mutation_prompt": null}
{"id": "7ad1f297-36f0-455e-b1b3-ee48b050233d", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05  # Adaptive learning rate for faster convergence\n        self.momentum = 0.95      # Fine-tuned momentum for stability and exploration\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles with diverse distribution\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.normal(0, 0.1, (self.population_size, self.dim))  # Small perturbation for diversity\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            # Evaluate current positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            # Adjust inertia weight based on improvement\n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)\n            \n            # Dynamic adjustment of coefficients\n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            # Adaptive learning rate scaling\n            adaptive_lr = self.learning_rate * (1.0 + (0.5 * (self.budget - eval_count) / self.budget))\n            \n            # Update velocities and positions with adjusted momentum and learning rate\n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + adaptive_lr * (cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Introduced adaptive learning rate scaling based on convergence progress and improved initialization for faster convergence.", "configspace": "", "generation": 25, "fitness": 0.31446974263594457, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.27.", "error": "", "parent_id": "81990e71-4250-455f-9980-286e53e710e7", "metadata": {"aucs": [0.8678959409973467, 0.8678959409973467, 0.8678959409973467, 0.861121122700629, 0.861121122700629, 0.861121122700629, 0.8656548266911966, 0.8656548266911966, 0.8656548266911966, 0.7283127597082522, 0.7283127597082522, 0.7283127597082522, 0.7180854706968451, 0.7180854706968451, 0.7180854706968451, 0.649736385477488, 0.649736385477488, 0.649736385477488, 0.5904134754709769, 0.5904134754709769, 0.5904134754709769, 0.17817472584662974, 0.17817472584662974, 0.17817472584662974, 0.11618119648243797, 0.11618119648243797, 0.11618119648243797, 0.17431670895408002, 0.17431670895408002, 0.17431670895408002, 0.10662208306569176, 0.10662208306569176, 0.10662208306569176, 0.11961426348469117, 0.11961426348469117, 0.11961426348469117, 0.9789180727864486, 0.9789180727864486, 0.9789180727864486, 0.9774459937054656, 0.9774459937054656, 0.9774459937054656, 0.9806211854395945, 0.9806211854395945, 0.9806211854395945, 0.731567005714954, 0.731567005714954, 0.731567005714954, 0.6686247089138747, 0.6686247089138747, 0.6686247089138747, 0.6402438960167596, 0.6402438960167596, 0.6402438960167596, 0.2130151036393937, 0.2130151036393937, 0.2130151036393937, 0.27916018069242987, 0.27916018069242987, 0.27916018069242987, 0.23334718092449325, 0.23334718092449325, 0.23334718092449325, 0.2114725215363149, 0.2114725215363149, 0.2114725215363149, 0.13120101057361666, 0.13120101057361666, 0.13120101057361666, 0.20375850961560982, 0.20375850961560982, 0.20375850961560982, 0.22000433148296183, 0.22000433148296183, 0.22000433148296183, 0.15652341561011185, 0.15652341561011185, 0.15652341561011185, 0.24459449023866042, 0.24459449023866042, 0.24459449023866042, 0.061527991096662515, 0.061527991096662515, 0.061527991096662515, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1011501501938934, 0.1011501501938934, 0.1011501501938934, 0.02520659361551747, 0.02520659361551747, 0.02520659361551747, 0.07852562489583792, 0.07852562489583792, 0.07852562489583792, 0.056712403729296645, 0.056712403729296645, 0.056712403729296645, 0.07497927461563503, 0.07497927461563503, 0.07497927461563503, 0.09514468693800104, 0.09514468693800104, 0.09514468693800104, 0.16080031207117296, 0.16080031207117296, 0.16080031207117296, 0.202583123367588, 0.202583123367588, 0.202583123367588, 0.1403973080921822, 0.1403973080921822, 0.1403973080921822, 0.5228487877780326, 0.5228487877780326, 0.5228487877780326, 0.5771022269680632, 0.5771022269680632, 0.5771022269680632, 0.5683378334736107, 0.5683378334736107, 0.5683378334736107, 0.1422408155877969, 0.1422408155877969, 0.1422408155877969, 0.14141826727014728, 0.14141826727014728, 0.14141826727014728, 0.1099977383954629, 0.1099977383954629, 0.1099977383954629, 0.18989671230128535, 0.18989671230128535, 0.18989671230128535, 0.28846206429510846, 0.28846206429510846, 0.28846206429510846, 0.2006745807042063, 0.2006745807042063, 0.2006745807042063, 0.3342679682685147, 0.3342679682685147, 0.3342679682685147, 0.3512252853464226, 0.3512252853464226, 0.3512252853464226, 0.3270119055653915, 0.3270119055653915, 0.3270119055653915, 0.19075991064852071, 0.19075991064852071, 0.19075991064852071, 0.18142934228156282, 0.18142934228156282, 0.18142934228156282, 0.24751934115094953, 0.24751934115094953, 0.24751934115094953, 0.26780591340592796, 0.26780591340592796, 0.26780591340592796, 0.22180908852829528, 0.22180908852829528, 0.22180908852829528, 0.2152396962580546, 0.2152396962580546, 0.2152396962580546, 0.20615185610026565, 0.20615185610026565, 0.20615185610026565, 0.19475198266283023, 0.19475198266283023, 0.19475198266283023, 0.2057545671663361, 0.2057545671663361, 0.2057545671663361, 0.8863185476190341, 0.8863185476190341, 0.8863185476190341, 0.15851153637393267, 0.15851153637393267, 0.15851153637393267, 0.16075779586800232, 0.16075779586800232, 0.16075779586800232, 0.5876611924527803, 0.5876611924527803, 0.5876611924527803, 0.21269784061625818, 0.21269784061625818, 0.21269784061625818, 0.20953344659254958, 0.20953344659254958, 0.20953344659254958, 0.17813505318480038, 0.17813505318480038, 0.17813505318480038, 0.19679433132275626, 0.19679433132275626, 0.19679433132275626, 0.20757900065770885, 0.20757900065770885, 0.20757900065770885, 0.09286901189538654, 0.09286901189538654, 0.09286901189538654, 0.09850571570011835, 0.09850571570011835, 0.09850571570011835, 0.12389807826515642, 0.12389807826515642, 0.12389807826515642]}, "mutation_prompt": null}
{"id": "262ca2c0-0a6a-41ff-9231-e46a1de91739", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n        self.max_velocity = 0.1 * (self.upper_bound - self.lower_bound)  # Velocity clamping\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            # Adaptive inertia weight\n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)\n            else:\n                self.inertia_weight = min(0.9, self.inertia_weight * 1.02)\n            \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            # Velocity clamping\n            velocities = np.clip(velocities, -self.max_velocity, self.max_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "EnhancedADSA with adaptive inertia weight and velocity clamping for improved convergence.", "configspace": "", "generation": 26, "fitness": 0.3000182637421532, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.24.", "error": "", "parent_id": "81990e71-4250-455f-9980-286e53e710e7", "metadata": {"aucs": [0.7891394019672568, 0.7891394019672568, 0.7891394019672568, 0.776864604857658, 0.776864604857658, 0.776864604857658, 0.7365492835089157, 0.7365492835089157, 0.7365492835089157, 0.4207036458803741, 0.4207036458803741, 0.4207036458803741, 0.3328892555937215, 0.3328892555937215, 0.3328892555937215, 0.43723845141330064, 0.43723845141330064, 0.43723845141330064, 0.3562144506319661, 0.3562144506319661, 0.3562144506319661, 0.15518919804059095, 0.15518919804059095, 0.15518919804059095, 0.15345594638836757, 0.15345594638836757, 0.15345594638836757, 0.12098871031485392, 0.12098871031485392, 0.12098871031485392, 0.11243464909921497, 0.11243464909921497, 0.11243464909921497, 0.16394541243775784, 0.16394541243775784, 0.16394541243775784, 0.940177134834496, 0.940177134834496, 0.940177134834496, 0.9366173294474271, 0.9366173294474271, 0.9366173294474271, 0.9275971569887775, 0.9275971569887775, 0.9275971569887775, 0.38148651027521685, 0.38148651027521685, 0.38148651027521685, 0.46197292933422107, 0.46197292933422107, 0.46197292933422107, 0.46631991921621074, 0.46631991921621074, 0.46631991921621074, 0.2129222623638165, 0.2129222623638165, 0.2129222623638165, 0.2071740082682234, 0.2071740082682234, 0.2071740082682234, 0.6400427993445031, 0.6400427993445031, 0.6400427993445031, 0.18861071832995635, 0.18861071832995635, 0.18861071832995635, 0.1295730351934159, 0.1295730351934159, 0.1295730351934159, 0.20173386877294086, 0.20173386877294086, 0.20173386877294086, 0.1880967358962372, 0.1880967358962372, 0.1880967358962372, 0.19066717901630414, 0.19066717901630414, 0.19066717901630414, 0.20202538892776345, 0.20202538892776345, 0.20202538892776345, 0.058607031724883574, 0.058607031724883574, 0.058607031724883574, 0.025263439635905494, 0.025263439635905494, 0.025263439635905494, 0.1179064646270046, 0.1179064646270046, 0.1179064646270046, 0.08861888055531231, 0.08861888055531231, 0.08861888055531231, 0.031015060279821927, 0.031015060279821927, 0.031015060279821927, 0.12350581277117967, 0.12350581277117967, 0.12350581277117967, 0.043194284860737175, 0.043194284860737175, 0.043194284860737175, 0.07276007465504841, 0.07276007465504841, 0.07276007465504841, 0.09356056969166238, 0.09356056969166238, 0.09356056969166238, 0.22208289004479054, 0.22208289004479054, 0.22208289004479054, 0.04657630207386576, 0.04657630207386576, 0.04657630207386576, 0.1169045436858509, 0.1169045436858509, 0.1169045436858509, 0.533998527642825, 0.533998527642825, 0.533998527642825, 0.5141699785626447, 0.5141699785626447, 0.5141699785626447, 0.5516566012735067, 0.5516566012735067, 0.5516566012735067, 0.13694992307246756, 0.13694992307246756, 0.13694992307246756, 0.10551921845125345, 0.10551921845125345, 0.10551921845125345, 0.12264028788326542, 0.12264028788326542, 0.12264028788326542, 0.2181630782981866, 0.2181630782981866, 0.2181630782981866, 0.21242733579173012, 0.21242733579173012, 0.21242733579173012, 0.3414691395607815, 0.3414691395607815, 0.3414691395607815, 0.3542165045613388, 0.3542165045613388, 0.3542165045613388, 0.36099071023496876, 0.36099071023496876, 0.36099071023496876, 0.4880988776849752, 0.4880988776849752, 0.4880988776849752, 0.15874812465011945, 0.15874812465011945, 0.15874812465011945, 0.2663454344802668, 0.2663454344802668, 0.2663454344802668, 0.14017829561659934, 0.14017829561659934, 0.14017829561659934, 0.20436453239399366, 0.20436453239399366, 0.20436453239399366, 0.2497048283900325, 0.2497048283900325, 0.2497048283900325, 0.283623081519327, 0.283623081519327, 0.283623081519327, 0.19671528305062747, 0.19671528305062747, 0.19671528305062747, 0.2154939451873994, 0.2154939451873994, 0.2154939451873994, 0.552487738091351, 0.552487738091351, 0.552487738091351, 0.8517569599988517, 0.8517569599988517, 0.8517569599988517, 0.15715785760847045, 0.15715785760847045, 0.15715785760847045, 0.13613633819070925, 0.13613633819070925, 0.13613633819070925, 0.5649221992820876, 0.5649221992820876, 0.5649221992820876, 0.21276039201822228, 0.21276039201822228, 0.21276039201822228, 0.615172128980203, 0.615172128980203, 0.615172128980203, 0.19281932211609032, 0.19281932211609032, 0.19281932211609032, 0.1889623298950469, 0.1889623298950469, 0.1889623298950469, 0.2413090710781619, 0.2413090710781619, 0.2413090710781619, 0.10627784418625219, 0.10627784418625219, 0.10627784418625219, 0.10235255468409465, 0.10235255468409465, 0.10235255468409465, 0.15310120404962713, 0.15310120404962713, 0.15310120404962713]}, "mutation_prompt": null}
{"id": "365d570d-c0aa-479e-a389-5445b550a24c", "solution": "import numpy as np\n\nclass ImprovedEnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.initial_learning_rate = 0.05\n        self.learning_rate_decay = 0.99  # New adaptive learning rate decay\n        self.initial_momentum = 0.95\n        self.momentum_decay = 0.98  # Dynamic momentum adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        momentum = self.initial_momentum\n        learning_rate = self.initial_learning_rate\n        \n        while eval_count < self.budget:\n            # Evaluate current positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            # Adjust inertia weight based on improvement\n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)\n                momentum *= self.momentum_decay  # Adjust momentum when no improvement\n\n            # Dynamic adjustment of coefficients\n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            # Update velocities and positions with adjusted momentum and learning rate\n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = momentum * velocities + learning_rate * (cognitive_velocity + social_velocity)\n\n            learning_rate *= self.learning_rate_decay  # Decay learning rate over time\n\n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "ImprovedEnhancedADSA", "description": "Improved EnhancedADSA with adaptive learning rate decay and dynamic momentum adjustment for enhanced convergence speed.", "configspace": "", "generation": 27, "fitness": 0.3067275237669326, "feedback": "The algorithm ImprovedEnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.27.", "error": "", "parent_id": "81990e71-4250-455f-9980-286e53e710e7", "metadata": {"aucs": [0.8793759843280065, 0.8793759843280065, 0.8793759843280065, 0.8850870930777632, 0.8850870930777632, 0.8850870930777632, 0.8780473293536919, 0.8780473293536919, 0.8780473293536919, 0.038889967349790666, 0.038889967349790666, 0.038889967349790666, 0.7529567246769607, 0.7529567246769607, 0.7529567246769607, 0.017984781752444556, 0.017984781752444556, 0.017984781752444556, 0.12374557407858211, 0.12374557407858211, 0.12374557407858211, 0.18421512365037185, 0.18421512365037185, 0.18421512365037185, 0.6955026877548878, 0.6955026877548878, 0.6955026877548878, 0.13654236131245412, 0.13654236131245412, 0.13654236131245412, 0.10007207324279765, 0.10007207324279765, 0.10007207324279765, 0.1126075675783883, 0.1126075675783883, 0.1126075675783883, 0.9832389221433232, 0.9832389221433232, 0.9832389221433232, 0.9799612491206476, 0.9799612491206476, 0.9799612491206476, 0.9771618664064232, 0.9771618664064232, 0.9771618664064232, 0.6543286431226338, 0.6543286431226338, 0.6543286431226338, 0.6992059052402319, 0.6992059052402319, 0.6992059052402319, 0.6046976825205097, 0.6046976825205097, 0.6046976825205097, 0.2246561008181278, 0.2246561008181278, 0.2246561008181278, 0.18936025889885522, 0.18936025889885522, 0.18936025889885522, 0.1757207517685223, 0.1757207517685223, 0.1757207517685223, 0.20374583842011018, 0.20374583842011018, 0.20374583842011018, 0.21006698112590316, 0.21006698112590316, 0.21006698112590316, 0.2666685830179374, 0.2666685830179374, 0.2666685830179374, 0.22816504083293843, 0.22816504083293843, 0.22816504083293843, 0.3059980041510363, 0.3059980041510363, 0.3059980041510363, 0.1267714868976193, 0.1267714868976193, 0.1267714868976193, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.060030474351344454, 0.060030474351344454, 0.060030474351344454, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10206921861595308, 0.10206921861595308, 0.10206921861595308, 0.021372511772619562, 0.021372511772619562, 0.021372511772619562, 0.11727016955319303, 0.11727016955319303, 0.11727016955319303, 0.07375234534343378, 0.07375234534343378, 0.07375234534343378, 0.1905342486483369, 0.1905342486483369, 0.1905342486483369, 0.22813364144931303, 0.22813364144931303, 0.22813364144931303, 0.16993369520645052, 0.16993369520645052, 0.16993369520645052, 0.06263733397235649, 0.06263733397235649, 0.06263733397235649, 0.08191260236550912, 0.08191260236550912, 0.08191260236550912, 0.5698582871587334, 0.5698582871587334, 0.5698582871587334, 0.5294765014908108, 0.5294765014908108, 0.5294765014908108, 0.6014887432024689, 0.6014887432024689, 0.6014887432024689, 0.1578021255271489, 0.1578021255271489, 0.1578021255271489, 0.13164585960523834, 0.13164585960523834, 0.13164585960523834, 0.11926671248758813, 0.11926671248758813, 0.11926671248758813, 0.15956866490695976, 0.15956866490695976, 0.15956866490695976, 0.3174407649989266, 0.3174407649989266, 0.3174407649989266, 0.21004377057709733, 0.21004377057709733, 0.21004377057709733, 0.3906195159905289, 0.3906195159905289, 0.3906195159905289, 0.35034079612385793, 0.35034079612385793, 0.35034079612385793, 0.64403733119953, 0.64403733119953, 0.64403733119953, 0.2538652760511573, 0.2538652760511573, 0.2538652760511573, 0.20704795999898185, 0.20704795999898185, 0.20704795999898185, 0.15028728584835405, 0.15028728584835405, 0.15028728584835405, 0.21048564796429947, 0.21048564796429947, 0.21048564796429947, 0.21419065601935317, 0.21419065601935317, 0.21419065601935317, 0.20721287943506983, 0.20721287943506983, 0.20721287943506983, 0.18794900534374803, 0.18794900534374803, 0.18794900534374803, 0.22765344922008823, 0.22765344922008823, 0.22765344922008823, 0.19409430168916286, 0.19409430168916286, 0.19409430168916286, 0.9295723020945001, 0.9295723020945001, 0.9295723020945001, 0.15775823173901338, 0.15775823173901338, 0.15775823173901338, 0.1689074285412756, 0.1689074285412756, 0.1689074285412756, 0.2116182094931054, 0.2116182094931054, 0.2116182094931054, 0.21232653517025502, 0.21232653517025502, 0.21232653517025502, 0.7286792398124764, 0.7286792398124764, 0.7286792398124764, 0.17629809542094244, 0.17629809542094244, 0.17629809542094244, 0.19598011817884686, 0.19598011817884686, 0.19598011817884686, 0.23356016570469684, 0.23356016570469684, 0.23356016570469684, 0.10339367314895442, 0.10339367314895442, 0.10339367314895442, 0.08751103290857587, 0.08751103290857587, 0.08751103290857587, 0.10178032024793304, 0.10178032024793304, 0.10178032024793304]}, "mutation_prompt": null}
{"id": "12977a70-2b47-4f5f-a019-1e1b926692e8", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, budget // 10)\n        self.population_size = self.initial_population_size\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            # Evaluate current positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            # Adjust inertia weight based on improvement\n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)\n            \n            # Dynamic adjustment of coefficients\n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            # Update velocities and positions with adjusted momentum and learning rate\n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + 0.1 * social_velocity)  # Adjusted scaling factor\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            # Dynamic population adjustment\n            self.population_size = max(20, int(self.initial_population_size * (self.budget - eval_count) / self.budget))\n            positions = positions[:self.population_size]\n            velocities = velocities[:self.population_size]\n            personal_best_positions = personal_best_positions[:self.population_size]\n            personal_best_scores = personal_best_scores[:self.population_size]\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "EnhancedADSA with dynamic population resizing and adaptive velocity scaling for improved convergence.", "configspace": "", "generation": 28, "fitness": 0.32118795425656, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.28.", "error": "", "parent_id": "81990e71-4250-455f-9980-286e53e710e7", "metadata": {"aucs": [0.8774855453705074, 0.8774855453705074, 0.8774855453705074, 0.8829629510465202, 0.8829629510465202, 0.8829629510465202, 0.8738318248513476, 0.8738318248513476, 0.8738318248513476, 0.7330551394734628, 0.7330551394734628, 0.7330551394734628, 0.6369308497249866, 0.6369308497249866, 0.6369308497249866, 0.7125641986966512, 0.7125641986966512, 0.7125641986966512, 0.13882246043887259, 0.13882246043887259, 0.13882246043887259, 0.17348776972125257, 0.17348776972125257, 0.17348776972125257, 0.14831142696529387, 0.14831142696529387, 0.14831142696529387, 0.13962413383755645, 0.13962413383755645, 0.13962413383755645, 0.11514876421757692, 0.11514876421757692, 0.11514876421757692, 0.16034016879721424, 0.16034016879721424, 0.16034016879721424, 0.9806843983077081, 0.9806843983077081, 0.9806843983077081, 0.981350539008449, 0.981350539008449, 0.981350539008449, 0.973873445685234, 0.973873445685234, 0.973873445685234, 0.7598132175173606, 0.7598132175173606, 0.7598132175173606, 0.7389846752176481, 0.7389846752176481, 0.7389846752176481, 0.6813529845687304, 0.6813529845687304, 0.6813529845687304, 0.2249849017710358, 0.2249849017710358, 0.2249849017710358, 0.16143486905948012, 0.16143486905948012, 0.16143486905948012, 0.17764823197613222, 0.17764823197613222, 0.17764823197613222, 0.18774792836943266, 0.18774792836943266, 0.18774792836943266, 0.1835980437202167, 0.1835980437202167, 0.1835980437202167, 0.2915426800822025, 0.2915426800822025, 0.2915426800822025, 0.21847794998822023, 0.21847794998822023, 0.21847794998822023, 0.20176176895061748, 0.20176176895061748, 0.20176176895061748, 0.18390010690098746, 0.18390010690098746, 0.18390010690098746, 0.03780257539970333, 0.03780257539970333, 0.03780257539970333, 0.06937209465400151, 0.06937209465400151, 0.06937209465400151, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09868010065214128, 0.09868010065214128, 0.09868010065214128, 0.06754983553310634, 0.06754983553310634, 0.06754983553310634, 0.10067815649576273, 0.10067815649576273, 0.10067815649576273, 0.04939634585434105, 0.04939634585434105, 0.04939634585434105, 0.14812035392590028, 0.14812035392590028, 0.14812035392590028, 0.22394100936764605, 0.22394100936764605, 0.22394100936764605, 0.08701037716549331, 0.08701037716549331, 0.08701037716549331, 0.0385722473824992, 0.0385722473824992, 0.0385722473824992, 0.08439216586450327, 0.08439216586450327, 0.08439216586450327, 0.6024388837741672, 0.6024388837741672, 0.6024388837741672, 0.5572354975355995, 0.5572354975355995, 0.5572354975355995, 0.6339821194344504, 0.6339821194344504, 0.6339821194344504, 0.09631434287389751, 0.09631434287389751, 0.09631434287389751, 0.10378557349825368, 0.10378557349825368, 0.10378557349825368, 0.13813912134691486, 0.13813912134691486, 0.13813912134691486, 0.5728786332103645, 0.5728786332103645, 0.5728786332103645, 0.18337485854648672, 0.18337485854648672, 0.18337485854648672, 0.2180875003018803, 0.2180875003018803, 0.2180875003018803, 0.2931666413466665, 0.2931666413466665, 0.2931666413466665, 0.2855065187574001, 0.2855065187574001, 0.2855065187574001, 0.3740038183383194, 0.3740038183383194, 0.3740038183383194, 0.2305268288089013, 0.2305268288089013, 0.2305268288089013, 0.41056599783143444, 0.41056599783143444, 0.41056599783143444, 0.1357054149867385, 0.1357054149867385, 0.1357054149867385, 0.24457937859258505, 0.24457937859258505, 0.24457937859258505, 0.2056811729659821, 0.2056811729659821, 0.2056811729659821, 0.2712467224626267, 0.2712467224626267, 0.2712467224626267, 0.18276350300852096, 0.18276350300852096, 0.18276350300852096, 0.2501403483173429, 0.2501403483173429, 0.2501403483173429, 0.24813281924808328, 0.24813281924808328, 0.24813281924808328, 0.9336593626092106, 0.9336593626092106, 0.9336593626092106, 0.15820414507700187, 0.15820414507700187, 0.15820414507700187, 0.7928841849494691, 0.7928841849494691, 0.7928841849494691, 0.16893232268908798, 0.16893232268908798, 0.16893232268908798, 0.21199271862867142, 0.21199271862867142, 0.21199271862867142, 0.15589530449892008, 0.15589530449892008, 0.15589530449892008, 0.20810162628108875, 0.20810162628108875, 0.20810162628108875, 0.1948565530397156, 0.1948565530397156, 0.1948565530397156, 0.2010685397108707, 0.2010685397108707, 0.2010685397108707, 0.10554215211771767, 0.10554215211771767, 0.10554215211771767, 0.09563624502078327, 0.09563624502078327, 0.09563624502078327, 0.11516762010336812, 0.11516762010336812, 0.11516762010336812]}, "mutation_prompt": null}
{"id": "de364c69-10f3-4e4b-9f0d-bbe6273ab4ef", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n        self.f_scale = 0.5  # Scaling factor for differential evolution\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            # Evaluate current positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            # Adjust inertia weight and velocity scaling\n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)\n            \n            # Dynamic adjustment of coefficients with scaling factor\n            self.cognitive_coef = (1.494 + 0.5 * (1 - eval_count / self.budget)) * self.f_scale\n            self.social_coef = (1.494 - 0.5 * (1 - eval_count / self.budget)) * self.f_scale\n            \n            # Update velocities and positions with differential evolution crossover\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant_vector = np.clip(a + self.f_scale * (b - c), self.lower_bound, self.upper_bound)\n                r = np.random.rand(self.dim)\n                trial_vector = np.where(r < 0.5, mutant_vector, positions[i])\n                \n                r1, r2 = np.random.uniform(size=(2, self.dim))\n                cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions[i] - trial_vector)\n                social_velocity = self.social_coef * r2 * (global_best_position - trial_vector)\n                velocities[i] = (self.inertia_weight * velocities[i] + cognitive_velocity + social_velocity)\n                velocities[i] = self.momentum * velocities[i] + self.learning_rate * (cognitive_velocity + social_velocity)\n                \n                positions[i] = np.clip(trial_vector + velocities[i], self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Introducing adaptive velocity scaling and differential evolution crossover to enhance exploration and convergence speed.", "configspace": "", "generation": 29, "fitness": 0.31352894502079254, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.26.", "error": "", "parent_id": "81990e71-4250-455f-9980-286e53e710e7", "metadata": {"aucs": [0.785978572143987, 0.785978572143987, 0.785978572143987, 0.7981564447466432, 0.7981564447466432, 0.7981564447466432, 0.7883983116079812, 0.7883983116079812, 0.7883983116079812, 0.594755046641884, 0.594755046641884, 0.594755046641884, 0.6445523516205143, 0.6445523516205143, 0.6445523516205143, 0.6536029462370702, 0.6536029462370702, 0.6536029462370702, 0.09910489084091445, 0.09910489084091445, 0.09910489084091445, 0.10141870945185039, 0.10141870945185039, 0.10141870945185039, 0.10620445463445194, 0.10620445463445194, 0.10620445463445194, 0.09589365618727719, 0.09589365618727719, 0.09589365618727719, 0.09009800358637587, 0.09009800358637587, 0.09009800358637587, 0.1098298861491468, 0.1098298861491468, 0.1098298861491468, 0.9748849592612003, 0.9748849592612003, 0.9748849592612003, 0.9626740790536007, 0.9626740790536007, 0.9626740790536007, 0.9810760473048622, 0.9810760473048622, 0.9810760473048622, 0.6554833748297124, 0.6554833748297124, 0.6554833748297124, 0.6186647227332005, 0.6186647227332005, 0.6186647227332005, 0.6145857880230314, 0.6145857880230314, 0.6145857880230314, 0.6856802302697723, 0.6856802302697723, 0.6856802302697723, 0.7782941005754836, 0.7782941005754836, 0.7782941005754836, 0.5291920641939205, 0.5291920641939205, 0.5291920641939205, 0.1588789498487817, 0.1588789498487817, 0.1588789498487817, 0.18752861120098874, 0.18752861120098874, 0.18752861120098874, 0.19401101895194317, 0.19401101895194317, 0.19401101895194317, 0.18574551426520225, 0.18574551426520225, 0.18574551426520225, 0.13560960650054055, 0.13560960650054055, 0.13560960650054055, 0.17290595096045525, 0.17290595096045525, 0.17290595096045525, 0.01368876279143516, 0.01368876279143516, 0.01368876279143516, 0.023219237178820684, 0.023219237178820684, 0.023219237178820684, 0.03564289648841168, 0.03564289648841168, 0.03564289648841168, 0.07351914071729682, 0.07351914071729682, 0.07351914071729682, 0.07797005544456859, 0.07797005544456859, 0.07797005544456859, 0.0847928215895215, 0.0847928215895215, 0.0847928215895215, 0.06332070609296347, 0.06332070609296347, 0.06332070609296347, 0.0654655998924305, 0.0654655998924305, 0.0654655998924305, 0.16039869853973998, 0.16039869853973998, 0.16039869853973998, 0.1728581764699898, 0.1728581764699898, 0.1728581764699898, 0.05446947574273164, 0.05446947574273164, 0.05446947574273164, 0.09784311540404256, 0.09784311540404256, 0.09784311540404256, 0.5382915314909498, 0.5382915314909498, 0.5382915314909498, 0.5526466776938468, 0.5526466776938468, 0.5526466776938468, 0.5563284701801844, 0.5563284701801844, 0.5563284701801844, 0.1057893316346803, 0.1057893316346803, 0.1057893316346803, 0.10836627379783947, 0.10836627379783947, 0.10836627379783947, 0.1150906666617546, 0.1150906666617546, 0.1150906666617546, 0.1479353335881073, 0.1479353335881073, 0.1479353335881073, 0.14077102282747622, 0.14077102282747622, 0.14077102282747622, 0.23008622961105574, 0.23008622961105574, 0.23008622961105574, 0.34921895780429946, 0.34921895780429946, 0.34921895780429946, 0.41875377002542946, 0.41875377002542946, 0.41875377002542946, 0.4831837543505648, 0.4831837543505648, 0.4831837543505648, 0.23288934894162916, 0.23288934894162916, 0.23288934894162916, 0.26270721804116437, 0.26270721804116437, 0.26270721804116437, 0.2635331558742371, 0.2635331558742371, 0.2635331558742371, 0.21380399166612896, 0.21380399166612896, 0.21380399166612896, 0.207920121923304, 0.207920121923304, 0.207920121923304, 0.2031185677593227, 0.2031185677593227, 0.2031185677593227, 0.3699549410079169, 0.3699549410079169, 0.3699549410079169, 0.20736549384432068, 0.20736549384432068, 0.20736549384432068, 0.44260739794382675, 0.44260739794382675, 0.44260739794382675, 0.5628063493165743, 0.5628063493165743, 0.5628063493165743, 0.5206297434045435, 0.5206297434045435, 0.5206297434045435, 0.15044984235662318, 0.15044984235662318, 0.15044984235662318, 0.165448219932117, 0.165448219932117, 0.165448219932117, 0.1988452342450403, 0.1988452342450403, 0.1988452342450403, 0.37454470108038884, 0.37454470108038884, 0.37454470108038884, 0.18397724082780342, 0.18397724082780342, 0.18397724082780342, 0.19461705829735743, 0.19461705829735743, 0.19461705829735743, 0.18993599437431252, 0.18993599437431252, 0.18993599437431252, 0.08012946072522242, 0.08012946072522242, 0.08012946072522242, 0.0823270968962464, 0.0823270968962464, 0.0823270968962464, 0.09361386520004922, 0.09361386520004922, 0.09361386520004922]}, "mutation_prompt": null}
{"id": "23d31384-b2bb-4429-a03a-2ca3d1636150", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)\n            \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            # Adaptive learning rate based on progress\n            if (eval_count / self.budget) > 0.8:\n                self.learning_rate *= 0.9\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Enhanced ADSA with adaptive inertia weight decay and dynamic learning rate for improved convergence speed.", "configspace": "", "generation": 30, "fitness": 0.33892337788159954, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.27.", "error": "", "parent_id": "81990e71-4250-455f-9980-286e53e710e7", "metadata": {"aucs": [0.8576534832565132, 0.8576534832565132, 0.8576534832565132, 0.8565123398618373, 0.8565123398618373, 0.8565123398618373, 0.866921730817145, 0.866921730817145, 0.866921730817145, 0.6096206891346194, 0.6096206891346194, 0.6096206891346194, 0.6936829571061802, 0.6936829571061802, 0.6936829571061802, 0.670137144017568, 0.670137144017568, 0.670137144017568, 0.1706385931553761, 0.1706385931553761, 0.1706385931553761, 0.6024510820454506, 0.6024510820454506, 0.6024510820454506, 0.5639936404734593, 0.5639936404734593, 0.5639936404734593, 0.15928792166857564, 0.15928792166857564, 0.15928792166857564, 0.12039700809329956, 0.12039700809329956, 0.12039700809329956, 0.12333553767689609, 0.12333553767689609, 0.12333553767689609, 0.9832392391365186, 0.9832392391365186, 0.9832392391365186, 0.9799669299694973, 0.9799669299694973, 0.9799669299694973, 0.9771626317362031, 0.9771626317362031, 0.9771626317362031, 0.7115457059543228, 0.7115457059543228, 0.7115457059543228, 0.6194254835210906, 0.6194254835210906, 0.6194254835210906, 0.7099899577285885, 0.7099899577285885, 0.7099899577285885, 0.2213241086871145, 0.2213241086871145, 0.2213241086871145, 0.20879032504979356, 0.20879032504979356, 0.20879032504979356, 0.17489980678942707, 0.17489980678942707, 0.17489980678942707, 0.21284905543154553, 0.21284905543154553, 0.21284905543154553, 0.20441240515963333, 0.20441240515963333, 0.20441240515963333, 0.2700018878168031, 0.2700018878168031, 0.2700018878168031, 0.2336648004103955, 0.2336648004103955, 0.2336648004103955, 0.28066155462699605, 0.28066155462699605, 0.28066155462699605, 0.12422031705179615, 0.12422031705179615, 0.12422031705179615, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04769867939458983, 0.04769867939458983, 0.04769867939458983, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09774172550821036, 0.09774172550821036, 0.09774172550821036, 0.012811988300279853, 0.012811988300279853, 0.012811988300279853, 0.08705858743699768, 0.08705858743699768, 0.08705858743699768, 0.04859764756339613, 0.04859764756339613, 0.04859764756339613, 0.1952432566845147, 0.1952432566845147, 0.1952432566845147, 0.21372848670387112, 0.21372848670387112, 0.21372848670387112, 0.2934979413486891, 0.2934979413486891, 0.2934979413486891, 0.07039634146317442, 0.07039634146317442, 0.07039634146317442, 0.0817202849138492, 0.0817202849138492, 0.0817202849138492, 0.5338925125637803, 0.5338925125637803, 0.5338925125637803, 0.5179860150762206, 0.5179860150762206, 0.5179860150762206, 0.5768504876552596, 0.5768504876552596, 0.5768504876552596, 0.1814759391383619, 0.1814759391383619, 0.1814759391383619, 0.14215620443010735, 0.14215620443010735, 0.14215620443010735, 0.10287063333670754, 0.10287063333670754, 0.10287063333670754, 0.32620270436475884, 0.32620270436475884, 0.32620270436475884, 0.21571499487423829, 0.21571499487423829, 0.21571499487423829, 0.27507300726512984, 0.27507300726512984, 0.27507300726512984, 0.6102248491951041, 0.6102248491951041, 0.6102248491951041, 0.4652277983560451, 0.4652277983560451, 0.4652277983560451, 0.7124168692702448, 0.7124168692702448, 0.7124168692702448, 0.21444653253320678, 0.21444653253320678, 0.21444653253320678, 0.1937811398408994, 0.1937811398408994, 0.1937811398408994, 0.21327245194411704, 0.21327245194411704, 0.21327245194411704, 0.21987243929240408, 0.21987243929240408, 0.21987243929240408, 0.25437313776864523, 0.25437313776864523, 0.25437313776864523, 0.23934542363906686, 0.23934542363906686, 0.23934542363906686, 0.24361545470979373, 0.24361545470979373, 0.24361545470979373, 0.26524805061372503, 0.26524805061372503, 0.26524805061372503, 0.20442197984791488, 0.20442197984791488, 0.20442197984791488, 0.9270764070655483, 0.9270764070655483, 0.9270764070655483, 0.15785057245808753, 0.15785057245808753, 0.15785057245808753, 0.16890486586631248, 0.16890486586631248, 0.16890486586631248, 0.21140036794731176, 0.21140036794731176, 0.21140036794731176, 0.21236171329707265, 0.21236171329707265, 0.21236171329707265, 0.7604696693933294, 0.7604696693933294, 0.7604696693933294, 0.20324040447231118, 0.20324040447231118, 0.20324040447231118, 0.21626874088181125, 0.21626874088181125, 0.21626874088181125, 0.1951749332817403, 0.1951749332817403, 0.1951749332817403, 0.09553369905077491, 0.09553369905077491, 0.09553369905077491, 0.07139161194935917, 0.07139161194935917, 0.07139161194935917, 0.11886032040155747, 0.11886032040155747, 0.11886032040155747]}, "mutation_prompt": null}
{"id": "17b47019-9e46-4016-8c89-eb19eafde551", "solution": "import numpy as np\n\nclass AdaptiveLSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.07  # Enhanced adaptive learning rate for better convergence\n        self.momentum = 0.93      # Fine-tuned momentum for improved exploration capability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            # Evaluate current positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            # Adjust inertia weight based on improvement\n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.3, self.inertia_weight * 0.99)\n            \n            # Dynamic adjustment of coefficients\n            self.cognitive_coef = 1.494 + 0.3 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.3 * (1 - eval_count / self.budget)\n            \n            # Update velocities and positions with adjusted momentum and learning rate\n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "AdaptiveLSA", "description": "Adaptive LSA (Learning and Selection Adaptation) with enhanced learning rate scheduling and selective exploration for improved convergence.", "configspace": "", "generation": 31, "fitness": 0.3129217419235245, "feedback": "The algorithm AdaptiveLSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.27.", "error": "", "parent_id": "81990e71-4250-455f-9980-286e53e710e7", "metadata": {"aucs": [0.855728023307313, 0.855728023307313, 0.855728023307313, 0.876159421212241, 0.876159421212241, 0.876159421212241, 0.8670478010796534, 0.8670478010796534, 0.8670478010796534, 0.4395677101376809, 0.4395677101376809, 0.4395677101376809, 0.6832127000629594, 0.6832127000629594, 0.6832127000629594, 0.6629582491555808, 0.6629582491555808, 0.6629582491555808, 0.1477094093956557, 0.1477094093956557, 0.1477094093956557, 0.14211918920772337, 0.14211918920772337, 0.14211918920772337, 0.1806633773935027, 0.1806633773935027, 0.1806633773935027, 0.16680584675112697, 0.16680584675112697, 0.16680584675112697, 0.14084879673292472, 0.14084879673292472, 0.14084879673292472, 0.13313444888742287, 0.13313444888742287, 0.13313444888742287, 0.9842759936567888, 0.9842759936567888, 0.9842759936567888, 0.983236352600764, 0.983236352600764, 0.983236352600764, 0.9769845333195896, 0.9769845333195896, 0.9769845333195896, 0.6728409773386785, 0.6728409773386785, 0.6728409773386785, 0.6387798139547629, 0.6387798139547629, 0.6387798139547629, 0.6701479846180756, 0.6701479846180756, 0.6701479846180756, 0.6695235723087771, 0.6695235723087771, 0.6695235723087771, 0.16115212142976887, 0.16115212142976887, 0.16115212142976887, 0.2358922056335533, 0.2358922056335533, 0.2358922056335533, 0.18733292089055364, 0.18733292089055364, 0.18733292089055364, 0.13078039882484427, 0.13078039882484427, 0.13078039882484427, 0.20908844495648127, 0.20908844495648127, 0.20908844495648127, 0.12567827541408838, 0.12567827541408838, 0.12567827541408838, 0.23345903158723413, 0.23345903158723413, 0.23345903158723413, 0.23712953389381597, 0.23712953389381597, 0.23712953389381597, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0218948677467814, 0.0218948677467814, 0.0218948677467814, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12301298385299031, 0.12301298385299031, 0.12301298385299031, 0.031209949597712505, 0.031209949597712505, 0.031209949597712505, 0.0893722001431797, 0.0893722001431797, 0.0893722001431797, 0.0480993381220054, 0.0480993381220054, 0.0480993381220054, 0.2639437952884699, 0.2639437952884699, 0.2639437952884699, 0.1373436912975372, 0.1373436912975372, 0.1373436912975372, 0.048675902376084546, 0.048675902376084546, 0.048675902376084546, 0.048857100330612746, 0.048857100330612746, 0.048857100330612746, 0.08240094995058878, 0.08240094995058878, 0.08240094995058878, 0.5224687415710703, 0.5224687415710703, 0.5224687415710703, 0.6003475397411775, 0.6003475397411775, 0.6003475397411775, 0.6389909839878776, 0.6389909839878776, 0.6389909839878776, 0.127794454273659, 0.127794454273659, 0.127794454273659, 0.10887144147443595, 0.10887144147443595, 0.10887144147443595, 0.09428228046786358, 0.09428228046786358, 0.09428228046786358, 0.4673785363140057, 0.4673785363140057, 0.4673785363140057, 0.1970442311282461, 0.1970442311282461, 0.1970442311282461, 0.15932903435937062, 0.15932903435937062, 0.15932903435937062, 0.41174996598655234, 0.41174996598655234, 0.41174996598655234, 0.529059815227712, 0.529059815227712, 0.529059815227712, 0.583055088890475, 0.583055088890475, 0.583055088890475, 0.27411919721166, 0.27411919721166, 0.27411919721166, 0.20479346798887987, 0.20479346798887987, 0.20479346798887987, 0.18844218594701656, 0.18844218594701656, 0.18844218594701656, 0.24279259359009697, 0.24279259359009697, 0.24279259359009697, 0.21278798432435886, 0.21278798432435886, 0.21278798432435886, 0.1872789098264036, 0.1872789098264036, 0.1872789098264036, 0.2181684318951499, 0.2181684318951499, 0.2181684318951499, 0.2242353101819814, 0.2242353101819814, 0.2242353101819814, 0.20968727112062735, 0.20968727112062735, 0.20968727112062735, 0.8993836314139849, 0.8993836314139849, 0.8993836314139849, 0.15880999553082276, 0.15880999553082276, 0.15880999553082276, 0.17061701217233327, 0.17061701217233327, 0.17061701217233327, 0.16895051874221845, 0.16895051874221845, 0.16895051874221845, 0.21168464433456557, 0.21168464433456557, 0.21168464433456557, 0.2623705369213428, 0.2623705369213428, 0.2623705369213428, 0.17576652189690745, 0.17576652189690745, 0.17576652189690745, 0.2007119743788336, 0.2007119743788336, 0.2007119743788336, 0.249821957756182, 0.249821957756182, 0.249821957756182, 0.09868304147025941, 0.09868304147025941, 0.09868304147025941, 0.08538433500159559, 0.08538433500159559, 0.08538433500159559, 0.1382358709085716, 0.1382358709085716, 0.1382358709085716]}, "mutation_prompt": null}
{"id": "3bb670a6-bec5-460f-ba47-e62dee82c4f3", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n        self.mutation_prob = 0.1  # New adaptive mutation probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)\n            \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            mutation_mask = np.random.rand(self.population_size, self.dim) < self.mutation_prob\n            mutation_values = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n            positions = np.where(mutation_mask, mutation_values, positions + velocities)\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Incorporate adaptive mutation and exploration strategy to enhance convergence speed.", "configspace": "", "generation": 32, "fitness": 0.22108964226935152, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "81990e71-4250-455f-9980-286e53e710e7", "metadata": {"aucs": [0.45452152063298434, 0.45452152063298434, 0.45452152063298434, 0.4448557107946711, 0.4448557107946711, 0.4448557107946711, 0.47736456026240925, 0.47736456026240925, 0.47736456026240925, 0.1608939730182909, 0.1608939730182909, 0.1608939730182909, 0.13148243896228118, 0.13148243896228118, 0.13148243896228118, 0.12252546975871847, 0.12252546975871847, 0.12252546975871847, 0.1088936285206521, 0.1088936285206521, 0.1088936285206521, 0.11664673272216408, 0.11664673272216408, 0.11664673272216408, 0.10095267769564542, 0.10095267769564542, 0.10095267769564542, 0.10366192097777094, 0.10366192097777094, 0.10366192097777094, 0.12242840877769379, 0.12242840877769379, 0.12242840877769379, 0.08833077878053208, 0.08833077878053208, 0.08833077878053208, 0.9805415800553464, 0.9805415800553464, 0.9805415800553464, 0.9727794987055296, 0.9727794987055296, 0.9727794987055296, 0.9740055949079368, 0.9740055949079368, 0.9740055949079368, 0.2520028692591947, 0.2520028692591947, 0.2520028692591947, 0.23176293009553417, 0.23176293009553417, 0.23176293009553417, 0.2525033256713173, 0.2525033256713173, 0.2525033256713173, 0.2558577709627008, 0.2558577709627008, 0.2558577709627008, 0.1963367639386886, 0.1963367639386886, 0.1963367639386886, 0.2108882254490897, 0.2108882254490897, 0.2108882254490897, 0.13557458963608027, 0.13557458963608027, 0.13557458963608027, 0.12785169234681837, 0.12785169234681837, 0.12785169234681837, 0.1308695801905334, 0.1308695801905334, 0.1308695801905334, 0.11961136016871898, 0.11961136016871898, 0.11961136016871898, 0.16045462422002843, 0.16045462422002843, 0.16045462422002843, 0.10508856929034704, 0.10508856929034704, 0.10508856929034704, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.059580655985297604, 0.059580655985297604, 0.059580655985297604, 0.027820963846041935, 0.027820963846041935, 0.027820963846041935, 0.09614030543948537, 0.09614030543948537, 0.09614030543948537, 0.005888115440580433, 0.005888115440580433, 0.005888115440580433, 0.009899337186047297, 0.009899337186047297, 0.009899337186047297, 0.02607166998214694, 0.02607166998214694, 0.02607166998214694, 0.07272206177069762, 0.07272206177069762, 0.07272206177069762, 0.0950260613629007, 0.0950260613629007, 0.0950260613629007, 0.08225459976022087, 0.08225459976022087, 0.08225459976022087, 0.3827615836337953, 0.3827615836337953, 0.3827615836337953, 0.3959236232818021, 0.3959236232818021, 0.3959236232818021, 0.3931130969699461, 0.3931130969699461, 0.3931130969699461, 0.1056244189412382, 0.1056244189412382, 0.1056244189412382, 0.09749674906403472, 0.09749674906403472, 0.09749674906403472, 0.07971498458122206, 0.07971498458122206, 0.07971498458122206, 0.262903112484834, 0.262903112484834, 0.262903112484834, 0.17270621880426407, 0.17270621880426407, 0.17270621880426407, 0.1688743989780156, 0.1688743989780156, 0.1688743989780156, 0.2941291793663696, 0.2941291793663696, 0.2941291793663696, 0.2701012827535225, 0.2701012827535225, 0.2701012827535225, 0.2797009795446399, 0.2797009795446399, 0.2797009795446399, 0.2242862469341832, 0.2242862469341832, 0.2242862469341832, 0.2290630795199764, 0.2290630795199764, 0.2290630795199764, 0.19582706102268943, 0.19582706102268943, 0.19582706102268943, 0.19173327906043947, 0.19173327906043947, 0.19173327906043947, 0.21612016054154792, 0.21612016054154792, 0.21612016054154792, 0.199409404014956, 0.199409404014956, 0.199409404014956, 0.2012128208265268, 0.2012128208265268, 0.2012128208265268, 0.2114604954522431, 0.2114604954522431, 0.2114604954522431, 0.18594357475262557, 0.18594357475262557, 0.18594357475262557, 0.6517430659071022, 0.6517430659071022, 0.6517430659071022, 0.15691289062564462, 0.15691289062564462, 0.15691289062564462, 0.47991752128499465, 0.47991752128499465, 0.47991752128499465, 0.4645444231950351, 0.4645444231950351, 0.4645444231950351, 0.3298310292540515, 0.3298310292540515, 0.3298310292540515, 0.25539636591021664, 0.25539636591021664, 0.25539636591021664, 0.2067524756947251, 0.2067524756947251, 0.2067524756947251, 0.17931561610699098, 0.17931561610699098, 0.17931561610699098, 0.18184876950764206, 0.18184876950764206, 0.18184876950764206, 0.078910439310803, 0.078910439310803, 0.078910439310803, 0.07015515773773817, 0.07015515773773817, 0.07015515773773817, 0.09063017175439403, 0.09063017175439403, 0.09063017175439403]}, "mutation_prompt": null}
{"id": "5de4a380-3d7d-4310-88a1-d417b4376739", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            # Evaluate current positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            # Adaptive inertia weight based on improvement\n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.3, self.inertia_weight * 0.99)\n            else:\n                self.inertia_weight = min(0.9, self.inertia_weight * 1.01)\n\n            # Dynamic adjustment of coefficients\n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            # Update velocities and positions with adjusted momentum and learning rate\n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Enhanced ADSA with adaptive learning rate and adaptive inertia weight for improved convergence.", "configspace": "", "generation": 33, "fitness": 0.2761398421788677, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.24.", "error": "", "parent_id": "81990e71-4250-455f-9980-286e53e710e7", "metadata": {"aucs": [0.7483624241094705, 0.7483624241094705, 0.7483624241094705, 0.6953030893927084, 0.6953030893927084, 0.6953030893927084, 0.7617706633268496, 0.7617706633268496, 0.7617706633268496, 0.032969937068759836, 0.032969937068759836, 0.032969937068759836, 0.4260357220626342, 0.4260357220626342, 0.4260357220626342, 0.4405340367786351, 0.4405340367786351, 0.4405340367786351, 0.14802865240455465, 0.14802865240455465, 0.14802865240455465, 0.16641485974214376, 0.16641485974214376, 0.16641485974214376, 0.15538356649395735, 0.15538356649395735, 0.15538356649395735, 0.15968670225642123, 0.15968670225642123, 0.15968670225642123, 0.1438064555064671, 0.1438064555064671, 0.1438064555064671, 0.14024078667639517, 0.14024078667639517, 0.14024078667639517, 0.9832541887546651, 0.9832541887546651, 0.9832541887546651, 0.9801911995103733, 0.9801911995103733, 0.9801911995103733, 0.9772616161065272, 0.9772616161065272, 0.9772616161065272, 0.3583337950921144, 0.3583337950921144, 0.3583337950921144, 0.41876017494589424, 0.41876017494589424, 0.41876017494589424, 0.35181873562034194, 0.35181873562034194, 0.35181873562034194, 0.20589757349276938, 0.20589757349276938, 0.20589757349276938, 0.16083157441617657, 0.16083157441617657, 0.16083157441617657, 0.33863458488962406, 0.33863458488962406, 0.33863458488962406, 0.16225720099545216, 0.16225720099545216, 0.16225720099545216, 0.16758733554349947, 0.16758733554349947, 0.16758733554349947, 0.165640424365589, 0.165640424365589, 0.165640424365589, 0.20562685801648228, 0.20562685801648228, 0.20562685801648228, 0.21340528401157755, 0.21340528401157755, 0.21340528401157755, 0.13180888536273994, 0.13180888536273994, 0.13180888536273994, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0501206209060574, 0.0501206209060574, 0.0501206209060574, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09871410168882488, 0.09871410168882488, 0.09871410168882488, 0.013294527172693082, 0.013294527172693082, 0.013294527172693082, 0.09482584223894697, 0.09482584223894697, 0.09482584223894697, 0.056551773300949626, 0.056551773300949626, 0.056551773300949626, 0.10284224141308418, 0.10284224141308418, 0.10284224141308418, 0.11114368369366912, 0.11114368369366912, 0.11114368369366912, 0.19555164775232592, 0.19555164775232592, 0.19555164775232592, 0.0571226216855133, 0.0571226216855133, 0.0571226216855133, 0.07785066004780816, 0.07785066004780816, 0.07785066004780816, 0.5271213490543518, 0.5271213490543518, 0.5271213490543518, 0.5142164048465097, 0.5142164048465097, 0.5142164048465097, 0.56107272150529, 0.56107272150529, 0.56107272150529, 0.15154671465330627, 0.15154671465330627, 0.15154671465330627, 0.11587858828374442, 0.11587858828374442, 0.11587858828374442, 0.10491390302393266, 0.10491390302393266, 0.10491390302393266, 0.23886328754592123, 0.23886328754592123, 0.23886328754592123, 0.41109470493505884, 0.41109470493505884, 0.41109470493505884, 0.2396484658053013, 0.2396484658053013, 0.2396484658053013, 0.26427446217494033, 0.26427446217494033, 0.26427446217494033, 0.41569497592337235, 0.41569497592337235, 0.41569497592337235, 0.47444910420291175, 0.47444910420291175, 0.47444910420291175, 0.20611763960393004, 0.20611763960393004, 0.20611763960393004, 0.20722511566959478, 0.20722511566959478, 0.20722511566959478, 0.207340165818947, 0.207340165818947, 0.207340165818947, 0.2366613087916959, 0.2366613087916959, 0.2366613087916959, 0.22588233938641822, 0.22588233938641822, 0.22588233938641822, 0.24410441153030504, 0.24410441153030504, 0.24410441153030504, 0.2183066813353195, 0.2183066813353195, 0.2183066813353195, 0.24071982949719128, 0.24071982949719128, 0.24071982949719128, 0.1988744921109422, 0.1988744921109422, 0.1988744921109422, 0.8745817457281843, 0.8745817457281843, 0.8745817457281843, 0.15769961088006335, 0.15769961088006335, 0.15769961088006335, 0.16857685546965617, 0.16857685546965617, 0.16857685546965617, 0.21037751386986703, 0.21037751386986703, 0.21037751386986703, 0.21187043109346138, 0.21187043109346138, 0.21187043109346138, 0.6815137295077112, 0.6815137295077112, 0.6815137295077112, 0.19466324829349269, 0.19466324829349269, 0.19466324829349269, 0.18164833551610793, 0.18164833551610793, 0.18164833551610793, 0.20366311637553802, 0.20366311637553802, 0.20366311637553802, 0.08830158745285321, 0.08830158745285321, 0.08830158745285321, 0.09027896211520603, 0.09027896211520603, 0.09027896211520603, 0.11682278803465507, 0.11682278803465507, 0.11682278803465507]}, "mutation_prompt": null}
{"id": "6118c4dd-6eb8-4574-b038-fe447903a17a", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 9)  # Increased initial population size for exploration\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.3, self.inertia_weight * 0.97)  # Faster inertia weight decay\n            \n            self.cognitive_coef = 1.494 + 0.4 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.4 * (1 - eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Advanced ADSA with enhanced inertia weight decay and adaptive population resizing for accelerated convergence.", "configspace": "", "generation": 34, "fitness": 0.3108317823531961, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.27.", "error": "", "parent_id": "81990e71-4250-455f-9980-286e53e710e7", "metadata": {"aucs": [0.8445040682293329, 0.8445040682293329, 0.8445040682293329, 0.8399296568308058, 0.8399296568308058, 0.8399296568308058, 0.8430905112033373, 0.8430905112033373, 0.8430905112033373, 0.7007260260974348, 0.7007260260974348, 0.7007260260974348, 0.6282409914040572, 0.6282409914040572, 0.6282409914040572, 0.05205968451597687, 0.05205968451597687, 0.05205968451597687, 0.1808923083292232, 0.1808923083292232, 0.1808923083292232, 0.16266423154412113, 0.16266423154412113, 0.16266423154412113, 0.38927724206373937, 0.38927724206373937, 0.38927724206373937, 0.15223785439117998, 0.15223785439117998, 0.15223785439117998, 0.14370760455210296, 0.14370760455210296, 0.14370760455210296, 0.1597143012599156, 0.1597143012599156, 0.1597143012599156, 0.9827363992507433, 0.9827363992507433, 0.9827363992507433, 0.9803238326505974, 0.9803238326505974, 0.9803238326505974, 0.9730153750471863, 0.9730153750471863, 0.9730153750471863, 0.641013779388127, 0.641013779388127, 0.641013779388127, 0.15072192959087827, 0.15072192959087827, 0.15072192959087827, 0.6787117149738565, 0.6787117149738565, 0.6787117149738565, 0.29185527123245847, 0.29185527123245847, 0.29185527123245847, 0.19055953517709612, 0.19055953517709612, 0.19055953517709612, 0.1494025022872193, 0.1494025022872193, 0.1494025022872193, 0.15464477764742746, 0.15464477764742746, 0.15464477764742746, 0.13288859073615245, 0.13288859073615245, 0.13288859073615245, 0.23805469308464489, 0.23805469308464489, 0.23805469308464489, 0.20796596435533998, 0.20796596435533998, 0.20796596435533998, 0.12286264496800525, 0.12286264496800525, 0.12286264496800525, 0.23418743840114808, 0.23418743840114808, 0.23418743840114808, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02102575132005091, 0.02102575132005091, 0.02102575132005091, 0.0013839507349286961, 0.0013839507349286961, 0.0013839507349286961, 0.07839084562013632, 0.07839084562013632, 0.07839084562013632, 0.03791810155842956, 0.03791810155842956, 0.03791810155842956, 0.06525918285822296, 0.06525918285822296, 0.06525918285822296, 0.04710324693516199, 0.04710324693516199, 0.04710324693516199, 0.07421245059928638, 0.07421245059928638, 0.07421245059928638, 0.1369314412566497, 0.1369314412566497, 0.1369314412566497, 0.20972172686904078, 0.20972172686904078, 0.20972172686904078, 0.07508129117804385, 0.07508129117804385, 0.07508129117804385, 0.1883880954976518, 0.1883880954976518, 0.1883880954976518, 0.5215610905228719, 0.5215610905228719, 0.5215610905228719, 0.5287613246445264, 0.5287613246445264, 0.5287613246445264, 0.5454975651101698, 0.5454975651101698, 0.5454975651101698, 0.15776333669398168, 0.15776333669398168, 0.15776333669398168, 0.10633037909281351, 0.10633037909281351, 0.10633037909281351, 0.1789316148959309, 0.1789316148959309, 0.1789316148959309, 0.28531521206354316, 0.28531521206354316, 0.28531521206354316, 0.25129200846420996, 0.25129200846420996, 0.25129200846420996, 0.1957344763469696, 0.1957344763469696, 0.1957344763469696, 0.4836273387209412, 0.4836273387209412, 0.4836273387209412, 0.5392520270470725, 0.5392520270470725, 0.5392520270470725, 0.3521719755501116, 0.3521719755501116, 0.3521719755501116, 0.1769466847444925, 0.1769466847444925, 0.1769466847444925, 0.23649308662148782, 0.23649308662148782, 0.23649308662148782, 0.17198254473735342, 0.17198254473735342, 0.17198254473735342, 0.2622018289299093, 0.2622018289299093, 0.2622018289299093, 0.22531307805740153, 0.22531307805740153, 0.22531307805740153, 0.2295141081908184, 0.2295141081908184, 0.2295141081908184, 0.38942337717130504, 0.38942337717130504, 0.38942337717130504, 0.22033690943430662, 0.22033690943430662, 0.22033690943430662, 0.2495069507047305, 0.2495069507047305, 0.2495069507047305, 0.9014996218950635, 0.9014996218950635, 0.9014996218950635, 0.1591138751887058, 0.1591138751887058, 0.1591138751887058, 0.8769989462695513, 0.8769989462695513, 0.8769989462695513, 0.7050823878540212, 0.7050823878540212, 0.7050823878540212, 0.2116592950621915, 0.2116592950621915, 0.2116592950621915, 0.155277923087624, 0.155277923087624, 0.155277923087624, 0.2024194536247964, 0.2024194536247964, 0.2024194536247964, 0.21952920575226742, 0.21952920575226742, 0.21952920575226742, 0.18924556196590836, 0.18924556196590836, 0.18924556196590836, 0.08906665212526421, 0.08906665212526421, 0.08906665212526421, 0.08867559486272425, 0.08867559486272425, 0.08867559486272425, 0.1118578803573379, 0.1118578803573379, 0.1118578803573379]}, "mutation_prompt": null}
{"id": "9057d8ea-8c73-4208-8529-afdd2a202081", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n        self.velocity_clamp = (self.lower_bound - self.upper_bound) * 0.1  # Adaptive velocity clamping factor\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)\n            \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            velocities = np.clip(velocities, -self.velocity_clamp, self.velocity_clamp)  # Velocity clamping\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "EnhancedADSA with adaptive velocity clamping to balance exploration and exploitation for improved optimization performance. ", "configspace": "", "generation": 35, "fitness": 0.051043921482497534, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.05.", "error": "", "parent_id": "81990e71-4250-455f-9980-286e53e710e7", "metadata": {"aucs": [0.12608768438487894, 0.12608768438487894, 0.12608768438487894, 0.07882767020726278, 0.07882767020726278, 0.07882767020726278, 0.1485258502054243, 0.1485258502054243, 0.1485258502054243, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.021109511458604957, 0.021109511458604957, 0.021109511458604957, 0.0035816949912935714, 0.0035816949912935714, 0.0035816949912935714, 0.012036276089079312, 0.012036276089079312, 0.012036276089079312, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.038689851251296536, 0.038689851251296536, 0.038689851251296536, 0.04500273753284112, 0.04500273753284112, 0.04500273753284112, 0.05932003314200174, 0.05932003314200174, 0.05932003314200174, 0.022157838853799183, 0.022157838853799183, 0.022157838853799183, 0.05845187410373587, 0.05845187410373587, 0.05845187410373587, 0.051485473513365965, 0.051485473513365965, 0.051485473513365965, 0.06503405438765963, 0.06503405438765963, 0.06503405438765963, 0.0759855248987158, 0.0759855248987158, 0.0759855248987158, 0.07477471253200019, 0.07477471253200019, 0.07477471253200019, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02213735278908191, 0.02213735278908191, 0.02213735278908191, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1738992314838229, 0.1738992314838229, 0.1738992314838229, 0.09622392263345192, 0.09622392263345192, 0.09622392263345192, 0.11780070251052932, 0.11780070251052932, 0.11780070251052932, 0.015657901744312586, 0.015657901744312586, 0.015657901744312586, 0.019269824074709896, 0.019269824074709896, 0.019269824074709896, 0.01834307366616672, 0.01834307366616672, 0.01834307366616672, 0.1047363702319406, 0.1047363702319406, 0.1047363702319406, 0.07854074255478849, 0.07854074255478849, 0.07854074255478849, 0.10581894370406242, 0.10581894370406242, 0.10581894370406242, 0.1237439565995665, 0.1237439565995665, 0.1237439565995665, 0.12081072329581, 0.12081072329581, 0.12081072329581, 0.11977341637330263, 0.11977341637330263, 0.11977341637330263, 0.06951524531921693, 0.06951524531921693, 0.06951524531921693, 0.05199346637338986, 0.05199346637338986, 0.05199346637338986, 0.07624108805157481, 0.07624108805157481, 0.07624108805157481, 0.108094487024055, 0.108094487024055, 0.108094487024055, 0.13343705780708803, 0.13343705780708803, 0.13343705780708803, 0.10475640183589008, 0.10475640183589008, 0.10475640183589008, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1303692316653443, 0.1303692316653443, 0.1303692316653443, 0.08341855862812331, 0.08341855862812331, 0.08341855862812331, 0.08335040390431658, 0.08335040390431658, 0.08335040390431658, 0.06591160297489729, 0.06591160297489729, 0.06591160297489729, 0.11557847092361462, 0.11557847092361462, 0.11557847092361462, 0.06983454846960668, 0.06983454846960668, 0.06983454846960668, 0.17239512464886853, 0.17239512464886853, 0.17239512464886853, 0.1629849323617122, 0.1629849323617122, 0.1629849323617122, 0.1521765977630214, 0.1521765977630214, 0.1521765977630214, 0.03681995327163823, 0.03681995327163823, 0.03681995327163823, 0.02604055330433075, 0.02604055330433075, 0.02604055330433075, 0.03181767319962803, 0.03181767319962803, 0.03181767319962803]}, "mutation_prompt": null}
{"id": "3e7c6de8-d1f5-410b-971e-2cb5a0389636", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, max(10, budget // 20))  # Adaptive population size scaling\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.95)  # Improved inertia weight decay\n            \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Introduced adaptive population size scaling and improved inertia weight decay for optimized convergence.", "configspace": "", "generation": 36, "fitness": 0.31959470961083086, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.28.", "error": "", "parent_id": "81990e71-4250-455f-9980-286e53e710e7", "metadata": {"aucs": [0.8812884860440207, 0.8812884860440207, 0.8812884860440207, 0.8859618270434502, 0.8859618270434502, 0.8859618270434502, 0.8754796214446218, 0.8754796214446218, 0.8754796214446218, 0.0409321113682628, 0.0409321113682628, 0.0409321113682628, 0.77869921743472, 0.77869921743472, 0.77869921743472, 0.7794436089464819, 0.7794436089464819, 0.7794436089464819, 0.6438995658010815, 0.6438995658010815, 0.6438995658010815, 0.15774638814255304, 0.15774638814255304, 0.15774638814255304, 0.17696165261856767, 0.17696165261856767, 0.17696165261856767, 0.14467857890784785, 0.14467857890784785, 0.14467857890784785, 0.15291471415886282, 0.15291471415886282, 0.15291471415886282, 0.10645513255555028, 0.10645513255555028, 0.10645513255555028, 0.9832392391365186, 0.9832392391365186, 0.9832392391365186, 0.9799669299694973, 0.9799669299694973, 0.9799669299694973, 0.9771626317362031, 0.9771626317362031, 0.9771626317362031, 0.6875460614014192, 0.6875460614014192, 0.6875460614014192, 0.6788840969303094, 0.6788840969303094, 0.6788840969303094, 0.7117680801128403, 0.7117680801128403, 0.7117680801128403, 0.2774126018646049, 0.2774126018646049, 0.2774126018646049, 0.18579047712345387, 0.18579047712345387, 0.18579047712345387, 0.17490607875712172, 0.17490607875712172, 0.17490607875712172, 0.18918001609477386, 0.18918001609477386, 0.18918001609477386, 0.19405261639842875, 0.19405261639842875, 0.19405261639842875, 0.28358627980967244, 0.28358627980967244, 0.28358627980967244, 0.20502019832338858, 0.20502019832338858, 0.20502019832338858, 0.2907014721190959, 0.2907014721190959, 0.2907014721190959, 0.14537637528371483, 0.14537637528371483, 0.14537637528371483, 0.009594739259631724, 0.009594739259631724, 0.009594739259631724, 0.0761498261986373, 0.0761498261986373, 0.0761498261986373, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06391418256600123, 0.06391418256600123, 0.06391418256600123, 0.018447295144501386, 0.018447295144501386, 0.018447295144501386, 0.08699736859156948, 0.08699736859156948, 0.08699736859156948, 0.05454409978010555, 0.05454409978010555, 0.05454409978010555, 0.13999337343106966, 0.13999337343106966, 0.13999337343106966, 0.23579622835868252, 0.23579622835868252, 0.23579622835868252, 0.17984449699738836, 0.17984449699738836, 0.17984449699738836, 0.05276267346591945, 0.05276267346591945, 0.05276267346591945, 0.08228307253704714, 0.08228307253704714, 0.08228307253704714, 0.5753433936615879, 0.5753433936615879, 0.5753433936615879, 0.5296633649644076, 0.5296633649644076, 0.5296633649644076, 0.5889945054911386, 0.5889945054911386, 0.5889945054911386, 0.15229802024675831, 0.15229802024675831, 0.15229802024675831, 0.14294070596575825, 0.14294070596575825, 0.14294070596575825, 0.11198552492887082, 0.11198552492887082, 0.11198552492887082, 0.1830021801564362, 0.1830021801564362, 0.1830021801564362, 0.16892747017048337, 0.16892747017048337, 0.16892747017048337, 0.20294538511048443, 0.20294538511048443, 0.20294538511048443, 0.505337967441416, 0.505337967441416, 0.505337967441416, 0.442305045029016, 0.442305045029016, 0.442305045029016, 0.5711405050940395, 0.5711405050940395, 0.5711405050940395, 0.2468760042083702, 0.2468760042083702, 0.2468760042083702, 0.21320015352695143, 0.21320015352695143, 0.21320015352695143, 0.17540454366633307, 0.17540454366633307, 0.17540454366633307, 0.2429138713141863, 0.2429138713141863, 0.2429138713141863, 0.19653847807457836, 0.19653847807457836, 0.19653847807457836, 0.29607968160387443, 0.29607968160387443, 0.29607968160387443, 0.2007066545765006, 0.2007066545765006, 0.2007066545765006, 0.24808368824024696, 0.24808368824024696, 0.24808368824024696, 0.2046513259642656, 0.2046513259642656, 0.2046513259642656, 0.9332323837053994, 0.9332323837053994, 0.9332323837053994, 0.15762592336107095, 0.15762592336107095, 0.15762592336107095, 0.16889916651507497, 0.16889916651507497, 0.16889916651507497, 0.21150101902671903, 0.21150101902671903, 0.21150101902671903, 0.2123484276225528, 0.2123484276225528, 0.2123484276225528, 0.6468257895449154, 0.6468257895449154, 0.6468257895449154, 0.1859979730087724, 0.1859979730087724, 0.1859979730087724, 0.1940078344437588, 0.1940078344437588, 0.1940078344437588, 0.1947578656909521, 0.1947578656909521, 0.1947578656909521, 0.11399341410175279, 0.11399341410175279, 0.11399341410175279, 0.0861884381802851, 0.0861884381802851, 0.0861884381802851, 0.11662097148524897, 0.11662097148524897, 0.11662097148524897]}, "mutation_prompt": null}
{"id": "7cebf441-ca9e-4b53-b2fa-dfbf252bfb7f", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, budget // 10)\n        self.population_size = self.initial_population_size\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            # Evaluate current positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            # Adjust inertia weight using exponential decay\n            self.inertia_weight = 0.729 * (0.9 ** (eval_count / self.budget))\n            \n            # Dynamic adjustment of coefficients\n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            # Adapt population size based on progress\n            self.population_size = max(10, self.initial_population_size - int(10 * (eval_count / self.budget)))\n            positions = positions[:self.population_size]\n            velocities = velocities[:self.population_size]\n            personal_best_positions = personal_best_positions[:self.population_size]\n            personal_best_scores = personal_best_scores[:self.population_size]\n            \n            # Update velocities and positions with adjusted momentum and learning rate\n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Optimized ADSA with adaptive population resizing and non-linear inertia weight decay for enhanced convergence speed.", "configspace": "", "generation": 37, "fitness": 0.310858365175586, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.26.", "error": "", "parent_id": "81990e71-4250-455f-9980-286e53e710e7", "metadata": {"aucs": [0.8455883363212018, 0.8455883363212018, 0.8455883363212018, 0.8529924010755031, 0.8529924010755031, 0.8529924010755031, 0.8459810501624824, 0.8459810501624824, 0.8459810501624824, 0.03607928445078301, 0.03607928445078301, 0.03607928445078301, 0.6540879571577456, 0.6540879571577456, 0.6540879571577456, 0.6463013943698855, 0.6463013943698855, 0.6463013943698855, 0.15117359600631064, 0.15117359600631064, 0.15117359600631064, 0.15709787311251389, 0.15709787311251389, 0.15709787311251389, 0.15049171663310223, 0.15049171663310223, 0.15049171663310223, 0.14168562148857688, 0.14168562148857688, 0.14168562148857688, 0.13294939142295903, 0.13294939142295903, 0.13294939142295903, 0.11917298203659832, 0.11917298203659832, 0.11917298203659832, 0.981085068744794, 0.981085068744794, 0.981085068744794, 0.9799537015387831, 0.9799537015387831, 0.9799537015387831, 0.9771586044339735, 0.9771586044339735, 0.9771586044339735, 0.6302241576881741, 0.6302241576881741, 0.6302241576881741, 0.5625425019523254, 0.5625425019523254, 0.5625425019523254, 0.6621325740519469, 0.6621325740519469, 0.6621325740519469, 0.5623000588759016, 0.5623000588759016, 0.5623000588759016, 0.16059604834425878, 0.16059604834425878, 0.16059604834425878, 0.20331288298387562, 0.20331288298387562, 0.20331288298387562, 0.20528961468548923, 0.20528961468548923, 0.20528961468548923, 0.19617218316570983, 0.19617218316570983, 0.19617218316570983, 0.1966423826398498, 0.1966423826398498, 0.1966423826398498, 0.232786051141332, 0.232786051141332, 0.232786051141332, 0.29768686551392165, 0.29768686551392165, 0.29768686551392165, 0.125615417784125, 0.125615417784125, 0.125615417784125, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06905147539095247, 0.06905147539095247, 0.06905147539095247, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11029308226992962, 0.11029308226992962, 0.11029308226992962, 0.03060656195990663, 0.03060656195990663, 0.03060656195990663, 0.11226176186613468, 0.11226176186613468, 0.11226176186613468, 0.06530949629237548, 0.06530949629237548, 0.06530949629237548, 0.15649172685677026, 0.15649172685677026, 0.15649172685677026, 0.2932618800446968, 0.2932618800446968, 0.2932618800446968, 0.16453761696631353, 0.16453761696631353, 0.16453761696631353, 0.05784942629750678, 0.05784942629750678, 0.05784942629750678, 0.08175007289795011, 0.08175007289795011, 0.08175007289795011, 0.5249906821638834, 0.5249906821638834, 0.5249906821638834, 0.5568034769815062, 0.5568034769815062, 0.5568034769815062, 0.5475006657520696, 0.5475006657520696, 0.5475006657520696, 0.13822359345073731, 0.13822359345073731, 0.13822359345073731, 0.11006278921986745, 0.11006278921986745, 0.11006278921986745, 0.09380738894094409, 0.09380738894094409, 0.09380738894094409, 0.20816916719780343, 0.20816916719780343, 0.20816916719780343, 0.16169002009479594, 0.16169002009479594, 0.16169002009479594, 0.4058410585289036, 0.4058410585289036, 0.4058410585289036, 0.4791034956251988, 0.4791034956251988, 0.4791034956251988, 0.27909977460040714, 0.27909977460040714, 0.27909977460040714, 0.550900670581006, 0.550900670581006, 0.550900670581006, 0.22364898542432732, 0.22364898542432732, 0.22364898542432732, 0.2110835784084234, 0.2110835784084234, 0.2110835784084234, 0.146806623361751, 0.146806623361751, 0.146806623361751, 0.22197635562607965, 0.22197635562607965, 0.22197635562607965, 0.2465521891597635, 0.2465521891597635, 0.2465521891597635, 0.24516516764384355, 0.24516516764384355, 0.24516516764384355, 0.18944072968542625, 0.18944072968542625, 0.18944072968542625, 0.5791281853930095, 0.5791281853930095, 0.5791281853930095, 0.290440287270479, 0.290440287270479, 0.290440287270479, 0.8984157352870961, 0.8984157352870961, 0.8984157352870961, 0.15789952713363742, 0.15789952713363742, 0.15789952713363742, 0.16890597893810466, 0.16890597893810466, 0.16890597893810466, 0.21125269689589776, 0.21125269689589776, 0.21125269689589776, 0.21231691854954993, 0.21231691854954993, 0.21231691854954993, 0.6133571881270026, 0.6133571881270026, 0.6133571881270026, 0.2034951048166509, 0.2034951048166509, 0.2034951048166509, 0.2024317221005505, 0.2024317221005505, 0.2024317221005505, 0.17365923442686904, 0.17365923442686904, 0.17365923442686904, 0.09270168454977412, 0.09270168454977412, 0.09270168454977412, 0.08730332019604192, 0.08730332019604192, 0.08730332019604192, 0.10091547788613275, 0.10091547788613275, 0.10091547788613275]}, "mutation_prompt": null}
{"id": "e180a53b-0bbb-49fe-9a71-125883f54799", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.initial_learning_rate = 0.05\n        self.learning_rate = self.initial_learning_rate\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            # Evaluate current positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            # Adjust inertia weight based on improvement\n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)\n            \n            # Dynamic adjustment of coefficients\n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            # Non-linear learning rate decay\n            self.learning_rate = self.initial_learning_rate * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))\n            \n            # Update velocities and positions with adjusted momentum and learning rate\n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Introduced a non-linear decay to the learning rate and inertia weight for better adaptation over iterations, aiming for faster convergence.", "configspace": "", "generation": 38, "fitness": 0.3198131705088285, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.27.", "error": "", "parent_id": "81990e71-4250-455f-9980-286e53e710e7", "metadata": {"aucs": [0.8528493522495103, 0.8528493522495103, 0.8528493522495103, 0.8601640844835754, 0.8601640844835754, 0.8601640844835754, 0.8645046691230078, 0.8645046691230078, 0.8645046691230078, 0.569373983904085, 0.569373983904085, 0.569373983904085, 0.6889105237096089, 0.6889105237096089, 0.6889105237096089, 0.6849421558969422, 0.6849421558969422, 0.6849421558969422, 0.15433659807792266, 0.15433659807792266, 0.15433659807792266, 0.17339237139325503, 0.17339237139325503, 0.17339237139325503, 0.17967533390237334, 0.17967533390237334, 0.17967533390237334, 0.17622042735705978, 0.17622042735705978, 0.17622042735705978, 0.12532989860721777, 0.12532989860721777, 0.12532989860721777, 0.13821556654982137, 0.13821556654982137, 0.13821556654982137, 0.9832392264554861, 0.9832392264554861, 0.9832392264554861, 0.9799667558175633, 0.9799667558175633, 0.9799667558175633, 0.9771626090490926, 0.9771626090490926, 0.9771626090490926, 0.6710540801895793, 0.6710540801895793, 0.6710540801895793, 0.5587154144587605, 0.5587154144587605, 0.5587154144587605, 0.6735945138420697, 0.6735945138420697, 0.6735945138420697, 0.22332578633061761, 0.22332578633061761, 0.22332578633061761, 0.21282635411324546, 0.21282635411324546, 0.21282635411324546, 0.21633301784695436, 0.21633301784695436, 0.21633301784695436, 0.2177656549378303, 0.2177656549378303, 0.2177656549378303, 0.20159691994818085, 0.20159691994818085, 0.20159691994818085, 0.2764643485064896, 0.2764643485064896, 0.2764643485064896, 0.24006546122686057, 0.24006546122686057, 0.24006546122686057, 0.2769489532431245, 0.2769489532431245, 0.2769489532431245, 0.22184105486570171, 0.22184105486570171, 0.22184105486570171, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.052399529739890593, 0.052399529739890593, 0.052399529739890593, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15710266772351789, 0.15710266772351789, 0.15710266772351789, 0.011217601072931238, 0.011217601072931238, 0.011217601072931238, 0.12061791842908154, 0.12061791842908154, 0.12061791842908154, 0.04806030181887655, 0.04806030181887655, 0.04806030181887655, 0.1921326372968588, 0.1921326372968588, 0.1921326372968588, 0.21651061224498025, 0.21651061224498025, 0.21651061224498025, 0.19419938906738377, 0.19419938906738377, 0.19419938906738377, 0.051125653118059056, 0.051125653118059056, 0.051125653118059056, 0.0817439431550423, 0.0817439431550423, 0.0817439431550423, 0.5692697759308288, 0.5692697759308288, 0.5692697759308288, 0.6381452339983437, 0.6381452339983437, 0.6381452339983437, 0.5539620844259074, 0.5539620844259074, 0.5539620844259074, 0.18146344058899666, 0.18146344058899666, 0.18146344058899666, 0.14198965576602318, 0.14198965576602318, 0.14198965576602318, 0.09986498635271435, 0.09986498635271435, 0.09986498635271435, 0.1456427743552554, 0.1456427743552554, 0.1456427743552554, 0.17180732280791056, 0.17180732280791056, 0.17180732280791056, 0.262189826403171, 0.262189826403171, 0.262189826403171, 0.45674328409766374, 0.45674328409766374, 0.45674328409766374, 0.37997570339844533, 0.37997570339844533, 0.37997570339844533, 0.5692607716032649, 0.5692607716032649, 0.5692607716032649, 0.22451092299878384, 0.22451092299878384, 0.22451092299878384, 0.209781575139511, 0.209781575139511, 0.209781575139511, 0.22227641235185136, 0.22227641235185136, 0.22227641235185136, 0.2520421384185402, 0.2520421384185402, 0.2520421384185402, 0.2074550857257068, 0.2074550857257068, 0.2074550857257068, 0.2069351650428486, 0.2069351650428486, 0.2069351650428486, 0.24491859781229208, 0.24491859781229208, 0.24491859781229208, 0.22659955263461629, 0.22659955263461629, 0.22659955263461629, 0.19937062763038993, 0.19937062763038993, 0.19937062763038993, 0.9259587240801685, 0.9259587240801685, 0.9259587240801685, 0.1578505970317523, 0.1578505970317523, 0.1578505970317523, 0.1689047745818536, 0.1689047745818536, 0.1689047745818536, 0.2114009182406158, 0.2114009182406158, 0.2114009182406158, 0.21233426830601854, 0.21233426830601854, 0.21233426830601854, 0.7677976817532994, 0.7677976817532994, 0.7677976817532994, 0.19271279662105711, 0.19271279662105711, 0.19271279662105711, 0.231969470214743, 0.231969470214743, 0.231969470214743, 0.19450176685089104, 0.19450176685089104, 0.19450176685089104, 0.08928124637208112, 0.08928124637208112, 0.08928124637208112, 0.06642887470278946, 0.06642887470278946, 0.06642887470278946, 0.1190768506447557, 0.1190768506447557, 0.1190768506447557]}, "mutation_prompt": null}
{"id": "5e3e0676-a723-439b-9475-38d87edb3e4a", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.5, self.inertia_weight * 0.98)\n            \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            # Adaptive velocity clipping\n            max_velocity = 0.2 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Enhanced ADSA with dynamic inertia weight stabilization and adaptive velocity clipping for improved convergence.", "configspace": "", "generation": 39, "fitness": 0.3471710202676391, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.28.", "error": "", "parent_id": "81990e71-4250-455f-9980-286e53e710e7", "metadata": {"aucs": [0.8792212466117333, 0.8792212466117333, 0.8792212466117333, 0.8639595113801386, 0.8639595113801386, 0.8639595113801386, 0.8741770686497029, 0.8741770686497029, 0.8741770686497029, 0.7267724265223666, 0.7267724265223666, 0.7267724265223666, 0.6744472054541386, 0.6744472054541386, 0.6744472054541386, 0.740392298318997, 0.740392298318997, 0.740392298318997, 0.16951231476799877, 0.16951231476799877, 0.16951231476799877, 0.14915835224755392, 0.14915835224755392, 0.14915835224755392, 0.7197242589358939, 0.7197242589358939, 0.7197242589358939, 0.12928522868111758, 0.12928522868111758, 0.12928522868111758, 0.1145565397293894, 0.1145565397293894, 0.1145565397293894, 0.15754249848829494, 0.15754249848829494, 0.15754249848829494, 0.9659668648627118, 0.9659668648627118, 0.9659668648627118, 0.9724381888896716, 0.9724381888896716, 0.9724381888896716, 0.9635443719554782, 0.9635443719554782, 0.9635443719554782, 0.7095216988210085, 0.7095216988210085, 0.7095216988210085, 0.6397524460472703, 0.6397524460472703, 0.6397524460472703, 0.6577300351994583, 0.6577300351994583, 0.6577300351994583, 0.3807349604409851, 0.3807349604409851, 0.3807349604409851, 0.2109366304978777, 0.2109366304978777, 0.2109366304978777, 0.3447654732691826, 0.3447654732691826, 0.3447654732691826, 0.21717437522462302, 0.21717437522462302, 0.21717437522462302, 0.21956030725589148, 0.21956030725589148, 0.21956030725589148, 0.24982084579728459, 0.24982084579728459, 0.24982084579728459, 0.19988573406837595, 0.19988573406837595, 0.19988573406837595, 0.2323759321429275, 0.2323759321429275, 0.2323759321429275, 0.22188749738441338, 0.22188749738441338, 0.22188749738441338, 0.1030985286581454, 0.1030985286581454, 0.1030985286581454, 0.08906752317468947, 0.08906752317468947, 0.08906752317468947, 0.027350629078776945, 0.027350629078776945, 0.027350629078776945, 0.10486035557364959, 0.10486035557364959, 0.10486035557364959, 0.03211452292301198, 0.03211452292301198, 0.03211452292301198, 0.1638720451602238, 0.1638720451602238, 0.1638720451602238, 0.048184051643936465, 0.048184051643936465, 0.048184051643936465, 0.2080401717266369, 0.2080401717266369, 0.2080401717266369, 0.1228666607842448, 0.1228666607842448, 0.1228666607842448, 0.1608029333474582, 0.1608029333474582, 0.1608029333474582, 0.03866503197276849, 0.03866503197276849, 0.03866503197276849, 0.12672426694146377, 0.12672426694146377, 0.12672426694146377, 0.5875801147561405, 0.5875801147561405, 0.5875801147561405, 0.5537209559742653, 0.5537209559742653, 0.5537209559742653, 0.5701397358057991, 0.5701397358057991, 0.5701397358057991, 0.1293463129002297, 0.1293463129002297, 0.1293463129002297, 0.13665481944159985, 0.13665481944159985, 0.13665481944159985, 0.15301122361467878, 0.15301122361467878, 0.15301122361467878, 0.246534643899592, 0.246534643899592, 0.246534643899592, 0.2748949894300101, 0.2748949894300101, 0.2748949894300101, 0.21545128756527387, 0.21545128756527387, 0.21545128756527387, 0.39612924583467346, 0.39612924583467346, 0.39612924583467346, 0.6486885584345058, 0.6486885584345058, 0.6486885584345058, 0.4011492143006874, 0.4011492143006874, 0.4011492143006874, 0.21191059916309063, 0.21191059916309063, 0.21191059916309063, 0.44499802580140946, 0.44499802580140946, 0.44499802580140946, 0.14653223197700915, 0.14653223197700915, 0.14653223197700915, 0.20630386289688996, 0.20630386289688996, 0.20630386289688996, 0.2404056632868673, 0.2404056632868673, 0.2404056632868673, 0.2433413185700749, 0.2433413185700749, 0.2433413185700749, 0.23314185868990311, 0.23314185868990311, 0.23314185868990311, 0.24288199592945114, 0.24288199592945114, 0.24288199592945114, 0.19542523854313942, 0.19542523854313942, 0.19542523854313942, 0.9153885222605137, 0.9153885222605137, 0.9153885222605137, 0.15868305623842038, 0.15868305623842038, 0.15868305623842038, 0.8959235687210705, 0.8959235687210705, 0.8959235687210705, 0.6538728660012059, 0.6538728660012059, 0.6538728660012059, 0.21253657661528902, 0.21253657661528902, 0.21253657661528902, 0.15583445694561793, 0.15583445694561793, 0.15583445694561793, 0.20493070161655857, 0.20493070161655857, 0.20493070161655857, 0.20405825432223612, 0.20405825432223612, 0.20405825432223612, 0.20370729678571142, 0.20370729678571142, 0.20370729678571142, 0.09588553196190497, 0.09588553196190497, 0.09588553196190497, 0.09622359027132699, 0.09622359027132699, 0.09622359027132699, 0.11053610808537939, 0.11053610808537939, 0.11053610808537939]}, "mutation_prompt": null}
{"id": "f3579f8d-791a-45da-972f-317adf3993d0", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.07\n        self.momentum = 0.9\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.6, self.inertia_weight * 0.95)\n            \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            # Adaptive velocity clipping\n            max_velocity = 0.25 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Enhanced particle swarm optimization with adaptive learning rates and dynamic inertia weight adjustment for improved convergence.", "configspace": "", "generation": 40, "fitness": 0.3287121257459891, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.28.", "error": "", "parent_id": "5e3e0676-a723-439b-9475-38d87edb3e4a", "metadata": {"aucs": [0.8922104577715405, 0.8922104577715405, 0.8922104577715405, 0.8799758703416054, 0.8799758703416054, 0.8799758703416054, 0.9005434271043512, 0.9005434271043512, 0.9005434271043512, 0.7548284103906282, 0.7548284103906282, 0.7548284103906282, 0.6836176455737413, 0.6836176455737413, 0.6836176455737413, 0.7750323619674625, 0.7750323619674625, 0.7750323619674625, 0.17668597445557332, 0.17668597445557332, 0.17668597445557332, 0.14768845212674042, 0.14768845212674042, 0.14768845212674042, 0.13230237704768844, 0.13230237704768844, 0.13230237704768844, 0.1306019889028257, 0.1306019889028257, 0.1306019889028257, 0.12279468219421319, 0.12279468219421319, 0.12279468219421319, 0.14888987844736945, 0.14888987844736945, 0.14888987844736945, 0.9659112894126648, 0.9659112894126648, 0.9659112894126648, 0.9728142647840421, 0.9728142647840421, 0.9728142647840421, 0.9679196726515645, 0.9679196726515645, 0.9679196726515645, 0.7332548730469004, 0.7332548730469004, 0.7332548730469004, 0.7110247757375041, 0.7110247757375041, 0.7110247757375041, 0.7398745628022323, 0.7398745628022323, 0.7398745628022323, 0.8912459520037631, 0.8912459520037631, 0.8912459520037631, 0.2160041415063778, 0.2160041415063778, 0.2160041415063778, 0.33164656729305353, 0.33164656729305353, 0.33164656729305353, 0.1823189355927819, 0.1823189355927819, 0.1823189355927819, 0.1890936216671928, 0.1890936216671928, 0.1890936216671928, 0.19378967682092962, 0.19378967682092962, 0.19378967682092962, 0.16666653230369666, 0.16666653230369666, 0.16666653230369666, 0.23036953866928456, 0.23036953866928456, 0.23036953866928456, 0.2577672512215532, 0.2577672512215532, 0.2577672512215532, 0.07599416062314412, 0.07599416062314412, 0.07599416062314412, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09516446654638655, 0.09516446654638655, 0.09516446654638655, 0.039314823650077546, 0.039314823650077546, 0.039314823650077546, 0.1831599478302186, 0.1831599478302186, 0.1831599478302186, 0.0482150354546218, 0.0482150354546218, 0.0482150354546218, 0.09773004322934631, 0.09773004322934631, 0.09773004322934631, 0.24570118430276955, 0.24570118430276955, 0.24570118430276955, 0.09429092958271867, 0.09429092958271867, 0.09429092958271867, 0.14946275812688126, 0.14946275812688126, 0.14946275812688126, 0.18390307570046793, 0.18390307570046793, 0.18390307570046793, 0.563748121002247, 0.563748121002247, 0.563748121002247, 0.5885529768066677, 0.5885529768066677, 0.5885529768066677, 0.5990637201968764, 0.5990637201968764, 0.5990637201968764, 0.14375828424391335, 0.14375828424391335, 0.14375828424391335, 0.1389443779378191, 0.1389443779378191, 0.1389443779378191, 0.12721912692691562, 0.12721912692691562, 0.12721912692691562, 0.20716934223161254, 0.20716934223161254, 0.20716934223161254, 0.16500462776721814, 0.16500462776721814, 0.16500462776721814, 0.26027131751780785, 0.26027131751780785, 0.26027131751780785, 0.4289101636121361, 0.4289101636121361, 0.4289101636121361, 0.3674071685413046, 0.3674071685413046, 0.3674071685413046, 0.6821803080113744, 0.6821803080113744, 0.6821803080113744, 0.20361778167370925, 0.20361778167370925, 0.20361778167370925, 0.1927495794308206, 0.1927495794308206, 0.1927495794308206, 0.22088307064809864, 0.22088307064809864, 0.22088307064809864, 0.2175676113616012, 0.2175676113616012, 0.2175676113616012, 0.2634448584555876, 0.2634448584555876, 0.2634448584555876, 0.20091137147797156, 0.20091137147797156, 0.20091137147797156, 0.25170107942070086, 0.25170107942070086, 0.25170107942070086, 0.22455268916833415, 0.22455268916833415, 0.22455268916833415, 0.1876261491244099, 0.1876261491244099, 0.1876261491244099, 0.942581008673469, 0.942581008673469, 0.942581008673469, 0.15793241950696923, 0.15793241950696923, 0.15793241950696923, 0.16440634405889576, 0.16440634405889576, 0.16440634405889576, 0.16821525235205592, 0.16821525235205592, 0.16821525235205592, 0.2128238597884894, 0.2128238597884894, 0.2128238597884894, 0.15624641397416095, 0.15624641397416095, 0.15624641397416095, 0.22725344666626424, 0.22725344666626424, 0.22725344666626424, 0.19254653512100173, 0.19254653512100173, 0.19254653512100173, 0.21423255788808393, 0.21423255788808393, 0.21423255788808393, 0.09911846344273345, 0.09911846344273345, 0.09911846344273345, 0.0905565580389246, 0.0905565580389246, 0.0905565580389246, 0.09806686175912838, 0.09806686175912838, 0.09806686175912838]}, "mutation_prompt": null}
{"id": "e01a2670-8cce-4b82-9b6e-c7177b858a42", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.5, self.inertia_weight * 0.98)\n                self.learning_rate = min(0.1, self.learning_rate * 1.05)  # Adaptive learning rate increase\n            \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            max_velocity = 0.2 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "EnhancedADSA with adaptive learning rate adjustment based on convergence rate for improved performance.", "configspace": "", "generation": 41, "fitness": 0.33974014538374725, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.28.", "error": "", "parent_id": "5e3e0676-a723-439b-9475-38d87edb3e4a", "metadata": {"aucs": [0.8793044999939964, 0.8793044999939964, 0.8793044999939964, 0.8643580487478886, 0.8643580487478886, 0.8643580487478886, 0.8701870650617886, 0.8701870650617886, 0.8701870650617886, 0.7148918550731514, 0.7148918550731514, 0.7148918550731514, 0.6551783249119806, 0.6551783249119806, 0.6551783249119806, 0.7363499180268274, 0.7363499180268274, 0.7363499180268274, 0.1706149735830591, 0.1706149735830591, 0.1706149735830591, 0.14850511495257035, 0.14850511495257035, 0.14850511495257035, 0.17510143045585358, 0.17510143045585358, 0.17510143045585358, 0.1426674751548329, 0.1426674751548329, 0.1426674751548329, 0.11487273677014032, 0.11487273677014032, 0.11487273677014032, 0.15627569670942487, 0.15627569670942487, 0.15627569670942487, 0.9659668648627118, 0.9659668648627118, 0.9659668648627118, 0.9724381888896716, 0.9724381888896716, 0.9724381888896716, 0.9635443719554782, 0.9635443719554782, 0.9635443719554782, 0.6726039745030232, 0.6726039745030232, 0.6726039745030232, 0.6352561460966379, 0.6352561460966379, 0.6352561460966379, 0.7048969445518505, 0.7048969445518505, 0.7048969445518505, 0.38091360226510973, 0.38091360226510973, 0.38091360226510973, 0.21053925446663857, 0.21053925446663857, 0.21053925446663857, 0.6827711223553364, 0.6827711223553364, 0.6827711223553364, 0.20760731194275872, 0.20760731194275872, 0.20760731194275872, 0.2117654650594505, 0.2117654650594505, 0.2117654650594505, 0.23600503324855138, 0.23600503324855138, 0.23600503324855138, 0.21185576604906764, 0.21185576604906764, 0.21185576604906764, 0.22760307557155024, 0.22760307557155024, 0.22760307557155024, 0.2313683369129318, 0.2313683369129318, 0.2313683369129318, 0.05293475205298892, 0.05293475205298892, 0.05293475205298892, 0.042109817249377235, 0.042109817249377235, 0.042109817249377235, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15333283401227893, 0.15333283401227893, 0.15333283401227893, 0.043786259255476745, 0.043786259255476745, 0.043786259255476745, 0.20310826564162843, 0.20310826564162843, 0.20310826564162843, 0.04851582568488888, 0.04851582568488888, 0.04851582568488888, 0.21930191395713483, 0.21930191395713483, 0.21930191395713483, 0.1252506239160146, 0.1252506239160146, 0.1252506239160146, 0.16336755799135738, 0.16336755799135738, 0.16336755799135738, 0.038550386219698196, 0.038550386219698196, 0.038550386219698196, 0.12460633690054912, 0.12460633690054912, 0.12460633690054912, 0.5967128802430074, 0.5967128802430074, 0.5967128802430074, 0.5425054144901235, 0.5425054144901235, 0.5425054144901235, 0.5665770448982865, 0.5665770448982865, 0.5665770448982865, 0.11073328538863003, 0.11073328538863003, 0.11073328538863003, 0.13563250600709287, 0.13563250600709287, 0.13563250600709287, 0.14160134748500408, 0.14160134748500408, 0.14160134748500408, 0.334058844029252, 0.334058844029252, 0.334058844029252, 0.1984981176510271, 0.1984981176510271, 0.1984981176510271, 0.20090867607501728, 0.20090867607501728, 0.20090867607501728, 0.39353341630451, 0.39353341630451, 0.39353341630451, 0.36281982094154497, 0.36281982094154497, 0.36281982094154497, 0.5368982668121511, 0.5368982668121511, 0.5368982668121511, 0.21191210597158594, 0.21191210597158594, 0.21191210597158594, 0.280175117786036, 0.280175117786036, 0.280175117786036, 0.1328690884156516, 0.1328690884156516, 0.1328690884156516, 0.20571165437442007, 0.20571165437442007, 0.20571165437442007, 0.3073326093440051, 0.3073326093440051, 0.3073326093440051, 0.2557434804232831, 0.2557434804232831, 0.2557434804232831, 0.25044711576842926, 0.25044711576842926, 0.25044711576842926, 0.22591437964599004, 0.22591437964599004, 0.22591437964599004, 0.23553080491924594, 0.23553080491924594, 0.23553080491924594, 0.9084848808641058, 0.9084848808641058, 0.9084848808641058, 0.15865959850036437, 0.15865959850036437, 0.15865959850036437, 0.8909335911072146, 0.8909335911072146, 0.8909335911072146, 0.6386986423431424, 0.6386986423431424, 0.6386986423431424, 0.21250811976404527, 0.21250811976404527, 0.21250811976404527, 0.15583681783055126, 0.15583681783055126, 0.15583681783055126, 0.19373764287519435, 0.19373764287519435, 0.19373764287519435, 0.19849578459441042, 0.19849578459441042, 0.19849578459441042, 0.1927205665235865, 0.1927205665235865, 0.1927205665235865, 0.09755386171540559, 0.09755386171540559, 0.09755386171540559, 0.10378731861480661, 0.10378731861480661, 0.10378731861480661, 0.12535049486901118, 0.12535049486901118, 0.12535049486901118]}, "mutation_prompt": null}
{"id": "65188dff-eb51-4cdc-88be-11f72868205f", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n        \n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.5, self.inertia_weight * 0.98)\n            \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            \n            # Adaptive learning rate decay\n            learning_rate_decay = 0.99 ** (eval_count / self.population_size)\n            self.learning_rate = max(0.01, self.learning_rate * learning_rate_decay)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            # Adaptive velocity clipping with dynamic range\n            max_velocity = 0.2 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Introduced adaptive learning rate decay and momentum adjustment for enhanced convergence speed and stability.", "configspace": "", "generation": 42, "fitness": 0.33519980230997537, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.27.", "error": "", "parent_id": "5e3e0676-a723-439b-9475-38d87edb3e4a", "metadata": {"aucs": [0.8636711704953967, 0.8636711704953967, 0.8636711704953967, 0.8617579476063875, 0.8617579476063875, 0.8617579476063875, 0.8857949368588441, 0.8857949368588441, 0.8857949368588441, 0.6966908820170298, 0.6966908820170298, 0.6966908820170298, 0.7238076781618574, 0.7238076781618574, 0.7238076781618574, 0.7176543268395537, 0.7176543268395537, 0.7176543268395537, 0.13729472099488482, 0.13729472099488482, 0.13729472099488482, 0.17006973165807648, 0.17006973165807648, 0.17006973165807648, 0.16983354539493334, 0.16983354539493334, 0.16983354539493334, 0.11574189406389124, 0.11574189406389124, 0.11574189406389124, 0.12242454956812321, 0.12242454956812321, 0.12242454956812321, 0.14007346924705377, 0.14007346924705377, 0.14007346924705377, 0.9659661061895413, 0.9659661061895413, 0.9659661061895413, 0.9724348021552911, 0.9724348021552911, 0.9724348021552911, 0.9635455504268252, 0.9635455504268252, 0.9635455504268252, 0.6855134117281974, 0.6855134117281974, 0.6855134117281974, 0.6637800099404046, 0.6637800099404046, 0.6637800099404046, 0.7373825243226524, 0.7373825243226524, 0.7373825243226524, 0.22663775053547375, 0.22663775053547375, 0.22663775053547375, 0.19277154895238313, 0.19277154895238313, 0.19277154895238313, 0.35797139594814587, 0.35797139594814587, 0.35797139594814587, 0.20704139909012775, 0.20704139909012775, 0.20704139909012775, 0.21584078639794646, 0.21584078639794646, 0.21584078639794646, 0.1322921458436862, 0.1322921458436862, 0.1322921458436862, 0.2392088421061288, 0.2392088421061288, 0.2392088421061288, 0.23440123003459734, 0.23440123003459734, 0.23440123003459734, 0.215175819620944, 0.215175819620944, 0.215175819620944, 0.12240953930526066, 0.12240953930526066, 0.12240953930526066, 0.06643066330538372, 0.06643066330538372, 0.06643066330538372, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11492705250294799, 0.11492705250294799, 0.11492705250294799, 0.06832144104336657, 0.06832144104336657, 0.06832144104336657, 0.17254275678838582, 0.17254275678838582, 0.17254275678838582, 0.0490154712784977, 0.0490154712784977, 0.0490154712784977, 0.21879283644284142, 0.21879283644284142, 0.21879283644284142, 0.12880245013299862, 0.12880245013299862, 0.12880245013299862, 0.14872596780546832, 0.14872596780546832, 0.14872596780546832, 0.03841432888846397, 0.03841432888846397, 0.03841432888846397, 0.14024289928423517, 0.14024289928423517, 0.14024289928423517, 0.5958840267059552, 0.5958840267059552, 0.5958840267059552, 0.5586247151115273, 0.5586247151115273, 0.5586247151115273, 0.5581823000046312, 0.5581823000046312, 0.5581823000046312, 0.11652151921468235, 0.11652151921468235, 0.11652151921468235, 0.1513888210837302, 0.1513888210837302, 0.1513888210837302, 0.15143237041526358, 0.15143237041526358, 0.15143237041526358, 0.23792736705105522, 0.23792736705105522, 0.23792736705105522, 0.20772386813519672, 0.20772386813519672, 0.20772386813519672, 0.35318786065270713, 0.35318786065270713, 0.35318786065270713, 0.2992471798499521, 0.2992471798499521, 0.2992471798499521, 0.3634538221027096, 0.3634538221027096, 0.3634538221027096, 0.618506348164255, 0.618506348164255, 0.618506348164255, 0.22751995768109445, 0.22751995768109445, 0.22751995768109445, 0.3423776963095718, 0.3423776963095718, 0.3423776963095718, 0.15119177588660537, 0.15119177588660537, 0.15119177588660537, 0.2418486214590001, 0.2418486214590001, 0.2418486214590001, 0.22852178344621832, 0.22852178344621832, 0.22852178344621832, 0.21859517216645774, 0.21859517216645774, 0.21859517216645774, 0.24887433518182156, 0.24887433518182156, 0.24887433518182156, 0.2043224507308402, 0.2043224507308402, 0.2043224507308402, 0.24945699188884318, 0.24945699188884318, 0.24945699188884318, 0.9216586297304467, 0.9216586297304467, 0.9216586297304467, 0.15874951342444077, 0.15874951342444077, 0.15874951342444077, 0.8657875264523123, 0.8657875264523123, 0.8657875264523123, 0.6005477771734078, 0.6005477771734078, 0.6005477771734078, 0.2124982386559342, 0.2124982386559342, 0.2124982386559342, 0.22225550906787417, 0.22225550906787417, 0.22225550906787417, 0.22956990530834465, 0.22956990530834465, 0.22956990530834465, 0.18648851699062197, 0.18648851699062197, 0.18648851699062197, 0.19128587559852772, 0.19128587559852772, 0.19128587559852772, 0.09853831526288737, 0.09853831526288737, 0.09853831526288737, 0.10594337772643447, 0.10594337772643447, 0.10594337772643447, 0.13277001470865413, 0.13277001470865413, 0.13277001470865413]}, "mutation_prompt": null}
{"id": "e1f1057b-6da2-4c35-9ef3-d407c18c04bb", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.5, self.inertia_weight * 0.98)\n            \n            # Adaptive coefficient adjustments\n            self.cognitive_coef = 1.494 + 0.3 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.3 * (1 - eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            # Adaptive velocity clipping\n            max_velocity = 0.2 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Refined EnhancedADSA with adaptive coefficients for improved convergence control and accelerated search.", "configspace": "", "generation": 43, "fitness": 0.32538355791640317, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.27.", "error": "", "parent_id": "5e3e0676-a723-439b-9475-38d87edb3e4a", "metadata": {"aucs": [0.8662350027853158, 0.8662350027853158, 0.8662350027853158, 0.8663793689186882, 0.8663793689186882, 0.8663793689186882, 0.8676318538224069, 0.8676318538224069, 0.8676318538224069, 0.6733962745932501, 0.6733962745932501, 0.6733962745932501, 0.7142050395400804, 0.7142050395400804, 0.7142050395400804, 0.7544195555571744, 0.7544195555571744, 0.7544195555571744, 0.1591945479617941, 0.1591945479617941, 0.1591945479617941, 0.12053184708347431, 0.12053184708347431, 0.12053184708347431, 0.17673214965233475, 0.17673214965233475, 0.17673214965233475, 0.12285608059285402, 0.12285608059285402, 0.12285608059285402, 0.1373642336950044, 0.1373642336950044, 0.1373642336950044, 0.10951322684065667, 0.10951322684065667, 0.10951322684065667, 0.9597521941247759, 0.9597521941247759, 0.9597521941247759, 0.9726285454237018, 0.9726285454237018, 0.9726285454237018, 0.9636996581677907, 0.9636996581677907, 0.9636996581677907, 0.6290102036377927, 0.6290102036377927, 0.6290102036377927, 0.7227148499060062, 0.7227148499060062, 0.7227148499060062, 0.7361795913361, 0.7361795913361, 0.7361795913361, 0.8537498236019313, 0.8537498236019313, 0.8537498236019313, 0.16083004721849614, 0.16083004721849614, 0.16083004721849614, 0.16475451418164955, 0.16475451418164955, 0.16475451418164955, 0.21439227518996873, 0.21439227518996873, 0.21439227518996873, 0.20743085874029266, 0.20743085874029266, 0.20743085874029266, 0.1350546124524955, 0.1350546124524955, 0.1350546124524955, 0.1320466294346746, 0.1320466294346746, 0.1320466294346746, 0.2193804797117278, 0.2193804797117278, 0.2193804797117278, 0.2518929159223471, 0.2518929159223471, 0.2518929159223471, 0.01579352683510349, 0.01579352683510349, 0.01579352683510349, 0.05742918015209875, 0.05742918015209875, 0.05742918015209875, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1340729951914611, 0.1340729951914611, 0.1340729951914611, 0.08511180070087543, 0.08511180070087543, 0.08511180070087543, 0.05545829527786428, 0.05545829527786428, 0.05545829527786428, 0.06811760777589171, 0.06811760777589171, 0.06811760777589171, 0.267117071470925, 0.267117071470925, 0.267117071470925, 0.1252137082256446, 0.1252137082256446, 0.1252137082256446, 0.16059391477462703, 0.16059391477462703, 0.16059391477462703, 0.1542577209239313, 0.1542577209239313, 0.1542577209239313, 0.11358180080265023, 0.11358180080265023, 0.11358180080265023, 0.6025005341364009, 0.6025005341364009, 0.6025005341364009, 0.5391250603588331, 0.5391250603588331, 0.5391250603588331, 0.6035609477945837, 0.6035609477945837, 0.6035609477945837, 0.11033781769333306, 0.11033781769333306, 0.11033781769333306, 0.11709562765254411, 0.11709562765254411, 0.11709562765254411, 0.10275180036640286, 0.10275180036640286, 0.10275180036640286, 0.25238600213047435, 0.25238600213047435, 0.25238600213047435, 0.3024103071181329, 0.3024103071181329, 0.3024103071181329, 0.2915194640718498, 0.2915194640718498, 0.2915194640718498, 0.3478962484549085, 0.3478962484549085, 0.3478962484549085, 0.48580939439592175, 0.48580939439592175, 0.48580939439592175, 0.2680131016418831, 0.2680131016418831, 0.2680131016418831, 0.20148630986378335, 0.20148630986378335, 0.20148630986378335, 0.25964913604650464, 0.25964913604650464, 0.25964913604650464, 0.24022097435475087, 0.24022097435475087, 0.24022097435475087, 0.24273375485295412, 0.24273375485295412, 0.24273375485295412, 0.2593963736975049, 0.2593963736975049, 0.2593963736975049, 0.19651134410604354, 0.19651134410604354, 0.19651134410604354, 0.20885061742079847, 0.20885061742079847, 0.20885061742079847, 0.1974886181856257, 0.1974886181856257, 0.1974886181856257, 0.22018850161635073, 0.22018850161635073, 0.22018850161635073, 0.9091592464819843, 0.9091592464819843, 0.9091592464819843, 0.1588363357955075, 0.1588363357955075, 0.1588363357955075, 0.2007918611784597, 0.2007918611784597, 0.2007918611784597, 0.6104736960534174, 0.6104736960534174, 0.6104736960534174, 0.21265050181610612, 0.21265050181610612, 0.21265050181610612, 0.15635703503585296, 0.15635703503585296, 0.15635703503585296, 0.21651291328839184, 0.21651291328839184, 0.21651291328839184, 0.20197376614525986, 0.20197376614525986, 0.20197376614525986, 0.23039137418943534, 0.23039137418943534, 0.23039137418943534, 0.1028633005563393, 0.1028633005563393, 0.1028633005563393, 0.10348305782228784, 0.10348305782228784, 0.10348305782228784, 0.14536714343454127, 0.14536714343454127, 0.14536714343454127]}, "mutation_prompt": null}
{"id": "4ee4381f-a970-4bac-b812-a09fef7e6d86", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.06  # Modified learning rate\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        improvement_factor = 0.98  # Factor to modify inertia weight decay\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.5, self.inertia_weight * improvement_factor)\n            \n            self.cognitive_coef = 1.494 + 0.6 * (1 - eval_count / self.budget)  # Modified coefficient adjustment\n            self.social_coef = 1.494 - 0.4 * (1 - eval_count / self.budget)  # Modified coefficient adjustment\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            # Adaptive velocity clipping\n            max_velocity = 0.2 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Improved inertia weight adaptation and diversified learning strategy for faster convergence.", "configspace": "", "generation": 44, "fitness": 0.3168277303998001, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.26.", "error": "", "parent_id": "5e3e0676-a723-439b-9475-38d87edb3e4a", "metadata": {"aucs": [0.8479200275024567, 0.8479200275024567, 0.8479200275024567, 0.8487967308298413, 0.8487967308298413, 0.8487967308298413, 0.8599173608942758, 0.8599173608942758, 0.8599173608942758, 0.698660858541613, 0.698660858541613, 0.698660858541613, 0.7321006179232855, 0.7321006179232855, 0.7321006179232855, 0.7237849689348184, 0.7237849689348184, 0.7237849689348184, 0.1446523037268025, 0.1446523037268025, 0.1446523037268025, 0.17327905703321345, 0.17327905703321345, 0.17327905703321345, 0.17978714947443608, 0.17978714947443608, 0.17978714947443608, 0.13736530096323862, 0.13736530096323862, 0.13736530096323862, 0.14837266800884685, 0.14837266800884685, 0.14837266800884685, 0.1509369493544147, 0.1509369493544147, 0.1509369493544147, 0.9661034953142456, 0.9661034953142456, 0.9661034953142456, 0.9725713464987534, 0.9725713464987534, 0.9725713464987534, 0.963793748751779, 0.963793748751779, 0.963793748751779, 0.6197967614275247, 0.6197967614275247, 0.6197967614275247, 0.6750291789156629, 0.6750291789156629, 0.6750291789156629, 0.649416908954779, 0.649416908954779, 0.649416908954779, 0.23937230919696162, 0.23937230919696162, 0.23937230919696162, 0.18804600271473615, 0.18804600271473615, 0.18804600271473615, 0.23249057988389477, 0.23249057988389477, 0.23249057988389477, 0.21169506917686698, 0.21169506917686698, 0.21169506917686698, 0.2086839555585216, 0.2086839555585216, 0.2086839555585216, 0.1323522009631255, 0.1323522009631255, 0.1323522009631255, 0.22062592222742938, 0.22062592222742938, 0.22062592222742938, 0.13288860864310703, 0.13288860864310703, 0.13288860864310703, 0.19038945610586344, 0.19038945610586344, 0.19038945610586344, 0.09163244372297663, 0.09163244372297663, 0.09163244372297663, 0.035957481321380325, 0.035957481321380325, 0.035957481321380325, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1614207813085079, 0.1614207813085079, 0.1614207813085079, 0.054462552316536184, 0.054462552316536184, 0.054462552316536184, 0.10468890894733829, 0.10468890894733829, 0.10468890894733829, 0.05175518788346667, 0.05175518788346667, 0.05175518788346667, 0.3066862129942437, 0.3066862129942437, 0.3066862129942437, 0.08487834456047383, 0.08487834456047383, 0.08487834456047383, 0.14575881322560558, 0.14575881322560558, 0.14575881322560558, 0.06697835164684496, 0.06697835164684496, 0.06697835164684496, 0.18208127435263355, 0.18208127435263355, 0.18208127435263355, 0.546376744355962, 0.546376744355962, 0.546376744355962, 0.537501583975604, 0.537501583975604, 0.537501583975604, 0.544985130296068, 0.544985130296068, 0.544985130296068, 0.17546040435094912, 0.17546040435094912, 0.17546040435094912, 0.11698017023107876, 0.11698017023107876, 0.11698017023107876, 0.11364982320499106, 0.11364982320499106, 0.11364982320499106, 0.3275399421760038, 0.3275399421760038, 0.3275399421760038, 0.2065195770261985, 0.2065195770261985, 0.2065195770261985, 0.2480306477372557, 0.2480306477372557, 0.2480306477372557, 0.35460815656800837, 0.35460815656800837, 0.35460815656800837, 0.45112774116159216, 0.45112774116159216, 0.45112774116159216, 0.5496020071579001, 0.5496020071579001, 0.5496020071579001, 0.20906521882376905, 0.20906521882376905, 0.20906521882376905, 0.23132440643732233, 0.23132440643732233, 0.23132440643732233, 0.24961632938617972, 0.24961632938617972, 0.24961632938617972, 0.19557603204247664, 0.19557603204247664, 0.19557603204247664, 0.2521287455757595, 0.2521287455757595, 0.2521287455757595, 0.22719163766488015, 0.22719163766488015, 0.22719163766488015, 0.20939814379251498, 0.20939814379251498, 0.20939814379251498, 0.20554290410212173, 0.20554290410212173, 0.20554290410212173, 0.24922635866592568, 0.24922635866592568, 0.24922635866592568, 0.9118915009504923, 0.9118915009504923, 0.9118915009504923, 0.15832726520968243, 0.15832726520968243, 0.15832726520968243, 0.16352359198663102, 0.16352359198663102, 0.16352359198663102, 0.5836765109233828, 0.5836765109233828, 0.5836765109233828, 0.21261658390820992, 0.21261658390820992, 0.21261658390820992, 0.15608650022104664, 0.15608650022104664, 0.15608650022104664, 0.2028191511798504, 0.2028191511798504, 0.2028191511798504, 0.19602506040294143, 0.19602506040294143, 0.19602506040294143, 0.19027586588613798, 0.19027586588613798, 0.19027586588613798, 0.0783759558601198, 0.0783759558601198, 0.0783759558601198, 0.10225857002025585, 0.10225857002025585, 0.10225857002025585, 0.11903843770379441, 0.11903843770379441, 0.11903843770379441]}, "mutation_prompt": null}
{"id": "3c457daf-e1a2-40a9-a8fa-18b5f914449e", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.5, self.inertia_weight * 0.98)\n            \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            # Adaptive velocity clipping\n            max_velocity = 0.2 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            # Adaptive momentum adjustment\n            self.momentum = min(0.99, self.momentum + 0.01 * (1 - eval_count / self.budget))\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Enhanced ADSA with adaptive inertia weight and momentum adjustment for dynamic exploration-exploitation balance.", "configspace": "", "generation": 45, "fitness": 0.3331804350893981, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.27.", "error": "", "parent_id": "5e3e0676-a723-439b-9475-38d87edb3e4a", "metadata": {"aucs": [0.8661274644465837, 0.8661274644465837, 0.8661274644465837, 0.8679670515854998, 0.8679670515854998, 0.8679670515854998, 0.847846223306836, 0.847846223306836, 0.847846223306836, 0.7142700409996474, 0.7142700409996474, 0.7142700409996474, 0.6444951108195924, 0.6444951108195924, 0.6444951108195924, 0.7286506263584366, 0.7286506263584366, 0.7286506263584366, 0.17988298879209674, 0.17988298879209674, 0.17988298879209674, 0.15618565629679737, 0.15618565629679737, 0.15618565629679737, 0.17378078006319886, 0.17378078006319886, 0.17378078006319886, 0.11378471819675484, 0.11378471819675484, 0.11378471819675484, 0.1089270071202404, 0.1089270071202404, 0.1089270071202404, 0.1520836062482418, 0.1520836062482418, 0.1520836062482418, 0.9660007220612831, 0.9660007220612831, 0.9660007220612831, 0.9725500883857034, 0.9725500883857034, 0.9725500883857034, 0.9665926742932425, 0.9665926742932425, 0.9665926742932425, 0.7020739644364928, 0.7020739644364928, 0.7020739644364928, 0.3678301503893707, 0.3678301503893707, 0.3678301503893707, 0.6741956615891835, 0.6741956615891835, 0.6741956615891835, 0.22547316181074606, 0.22547316181074606, 0.22547316181074606, 0.19268819103927348, 0.19268819103927348, 0.19268819103927348, 0.2372893277538396, 0.2372893277538396, 0.2372893277538396, 0.19827156907039556, 0.19827156907039556, 0.19827156907039556, 0.2648363307916559, 0.2648363307916559, 0.2648363307916559, 0.19815456817710497, 0.19815456817710497, 0.19815456817710497, 0.22294967388524245, 0.22294967388524245, 0.22294967388524245, 0.22922562415274428, 0.22922562415274428, 0.22922562415274428, 0.13133066516012115, 0.13133066516012115, 0.13133066516012115, 0.028707129158276223, 0.028707129158276223, 0.028707129158276223, 0.09670310066858023, 0.09670310066858023, 0.09670310066858023, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08816189449439282, 0.08816189449439282, 0.08816189449439282, 0.053208580956188634, 0.053208580956188634, 0.053208580956188634, 0.18318235565715613, 0.18318235565715613, 0.18318235565715613, 0.04855053168966972, 0.04855053168966972, 0.04855053168966972, 0.21127443913521804, 0.21127443913521804, 0.21127443913521804, 0.1249364251242534, 0.1249364251242534, 0.1249364251242534, 0.26388354848281814, 0.26388354848281814, 0.26388354848281814, 0.03840116397575999, 0.03840116397575999, 0.03840116397575999, 0.18541834508332533, 0.18541834508332533, 0.18541834508332533, 0.5412441393366685, 0.5412441393366685, 0.5412441393366685, 0.5591992973304815, 0.5591992973304815, 0.5591992973304815, 0.5586048550867432, 0.5586048550867432, 0.5586048550867432, 0.08194276298429304, 0.08194276298429304, 0.08194276298429304, 0.10532968655923747, 0.10532968655923747, 0.10532968655923747, 0.15227708865429157, 0.15227708865429157, 0.15227708865429157, 0.18587480821066982, 0.18587480821066982, 0.18587480821066982, 0.2000605083471525, 0.2000605083471525, 0.2000605083471525, 0.2898468518415387, 0.2898468518415387, 0.2898468518415387, 0.511763556272878, 0.511763556272878, 0.511763556272878, 0.33869071232765025, 0.33869071232765025, 0.33869071232765025, 0.5659227182643625, 0.5659227182643625, 0.5659227182643625, 0.22463611715674292, 0.22463611715674292, 0.22463611715674292, 0.34497611588246313, 0.34497611588246313, 0.34497611588246313, 0.13991722509177051, 0.13991722509177051, 0.13991722509177051, 0.1871755119121833, 0.1871755119121833, 0.1871755119121833, 0.2481677869832305, 0.2481677869832305, 0.2481677869832305, 0.2767412909184118, 0.2767412909184118, 0.2767412909184118, 0.5047555358416348, 0.5047555358416348, 0.5047555358416348, 0.18846340447141963, 0.18846340447141963, 0.18846340447141963, 0.23067967569713566, 0.23067967569713566, 0.23067967569713566, 0.9093276907132074, 0.9093276907132074, 0.9093276907132074, 0.15846244858209557, 0.15846244858209557, 0.15846244858209557, 0.8575603518805637, 0.8575603518805637, 0.8575603518805637, 0.810279340828333, 0.810279340828333, 0.810279340828333, 0.2118644254844929, 0.2118644254844929, 0.2118644254844929, 0.28174012119029135, 0.28174012119029135, 0.28174012119029135, 0.19780886529270958, 0.19780886529270958, 0.19780886529270958, 0.1960209951312214, 0.1960209951312214, 0.1960209951312214, 0.18630696791177592, 0.18630696791177592, 0.18630696791177592, 0.09177909119616667, 0.09177909119616667, 0.09177909119616667, 0.09893293253426239, 0.09893293253426239, 0.09893293253426239, 0.12664728486461896, 0.12664728486461896, 0.12664728486461896]}, "mutation_prompt": null}
{"id": "71ab7e61-b77f-48ce-a3f7-e6f249b39333", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.5, self.inertia_weight * 0.99)\n            \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            self.learning_rate = 0.05 + 0.45 * (eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            # Adaptive velocity clipping\n            max_velocity = 0.2 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Modified EnhancedADSA with adaptive learning rate and improved inertia weight strategy for faster convergence.", "configspace": "", "generation": 46, "fitness": 0.355392725780699, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.28.", "error": "", "parent_id": "5e3e0676-a723-439b-9475-38d87edb3e4a", "metadata": {"aucs": [0.8457054715138301, 0.8457054715138301, 0.8457054715138301, 0.8464779327759129, 0.8464779327759129, 0.8464779327759129, 0.8435373236695729, 0.8435373236695729, 0.8435373236695729, 0.6434266624633573, 0.6434266624633573, 0.6434266624633573, 0.5676579385868897, 0.5676579385868897, 0.5676579385868897, 0.7205833969035975, 0.7205833969035975, 0.7205833969035975, 0.33139145891632593, 0.33139145891632593, 0.33139145891632593, 0.14546058849378374, 0.14546058849378374, 0.14546058849378374, 0.18308744801665466, 0.18308744801665466, 0.18308744801665466, 0.11528059862064088, 0.11528059862064088, 0.11528059862064088, 0.11919370893040104, 0.11919370893040104, 0.11919370893040104, 0.13631763740288894, 0.13631763740288894, 0.13631763740288894, 0.9659674281261577, 0.9659674281261577, 0.9659674281261577, 0.9724467528817047, 0.9724467528817047, 0.9724467528817047, 0.963540476697738, 0.963540476697738, 0.963540476697738, 0.5959998006411643, 0.5959998006411643, 0.5959998006411643, 0.5327335945310986, 0.5327335945310986, 0.5327335945310986, 0.5342804962464993, 0.5342804962464993, 0.5342804962464993, 0.8881790594319954, 0.8881790594319954, 0.8881790594319954, 0.21211214473251538, 0.21211214473251538, 0.21211214473251538, 0.8979254730610131, 0.8979254730610131, 0.8979254730610131, 0.19778883862892582, 0.19778883862892582, 0.19778883862892582, 0.22892038572525075, 0.22892038572525075, 0.22892038572525075, 0.1930947572366355, 0.1930947572366355, 0.1930947572366355, 0.2276391698953497, 0.2276391698953497, 0.2276391698953497, 0.20388884502886317, 0.20388884502886317, 0.20388884502886317, 0.21108884925793736, 0.21108884925793736, 0.21108884925793736, 0.045788235976957026, 0.045788235976957026, 0.045788235976957026, 0.04757073163938241, 0.04757073163938241, 0.04757073163938241, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07941578967838636, 0.07941578967838636, 0.07941578967838636, 0.052232575867415476, 0.052232575867415476, 0.052232575867415476, 0.1834821966490544, 0.1834821966490544, 0.1834821966490544, 0.046868216397554674, 0.046868216397554674, 0.046868216397554674, 0.21810778660073682, 0.21810778660073682, 0.21810778660073682, 0.12166177632467612, 0.12166177632467612, 0.12166177632467612, 0.17316302204490963, 0.17316302204490963, 0.17316302204490963, 0.03809350474679685, 0.03809350474679685, 0.03809350474679685, 0.22365188262078817, 0.22365188262078817, 0.22365188262078817, 0.5117262928748898, 0.5117262928748898, 0.5117262928748898, 0.5263036059470092, 0.5263036059470092, 0.5263036059470092, 0.5611128675319981, 0.5611128675319981, 0.5611128675319981, 0.10876225047396293, 0.10876225047396293, 0.10876225047396293, 0.17601402785621068, 0.17601402785621068, 0.17601402785621068, 0.13844903508844164, 0.13844903508844164, 0.13844903508844164, 0.35303247072902455, 0.35303247072902455, 0.35303247072902455, 0.19559104457028698, 0.19559104457028698, 0.19559104457028698, 0.21633099552504353, 0.21633099552504353, 0.21633099552504353, 0.4865834045995817, 0.4865834045995817, 0.4865834045995817, 0.5402757927544525, 0.5402757927544525, 0.5402757927544525, 0.4924213001042783, 0.4924213001042783, 0.4924213001042783, 0.16541232574149622, 0.16541232574149622, 0.16541232574149622, 0.2948712512238735, 0.2948712512238735, 0.2948712512238735, 0.14027298853297798, 0.14027298853297798, 0.14027298853297798, 0.2581009601865857, 0.2581009601865857, 0.2581009601865857, 0.24307028667825792, 0.24307028667825792, 0.24307028667825792, 0.22891479543823834, 0.22891479543823834, 0.22891479543823834, 0.7450561990806619, 0.7450561990806619, 0.7450561990806619, 0.24797592199402685, 0.24797592199402685, 0.24797592199402685, 0.7135504527488727, 0.7135504527488727, 0.7135504527488727, 0.9115141063429277, 0.9115141063429277, 0.9115141063429277, 0.15858482279336206, 0.15858482279336206, 0.15858482279336206, 0.8623642655681328, 0.8623642655681328, 0.8623642655681328, 0.49475282621799643, 0.49475282621799643, 0.49475282621799643, 0.21255283323376706, 0.21255283323376706, 0.21255283323376706, 0.15581591635765157, 0.15581591635765157, 0.15581591635765157, 0.18665198693132512, 0.18665198693132512, 0.18665198693132512, 0.1795807380981541, 0.1795807380981541, 0.1795807380981541, 0.20657943450531058, 0.20657943450531058, 0.20657943450531058, 0.09216545384979125, 0.09216545384979125, 0.09216545384979125, 0.08791101534191403, 0.08791101534191403, 0.08791101534191403, 0.1421126303264697, 0.1421126303264697, 0.1421126303264697]}, "mutation_prompt": null}
{"id": "44b9ebd5-a509-40ac-b3ad-34649091c4c1", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n        self.randomization_factor = 0.1  # Added randomization factor\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.5, self.inertia_weight * 0.99)\n            \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            self.learning_rate = 0.05 + 0.45 * (eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            # Adaptive velocity clipping\n            max_velocity = 0.2 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            # Introduce dynamic randomization for better diversity\n            rand_perturbation = np.random.uniform(-self.randomization_factor, self.randomization_factor, positions.shape)\n            positions += velocities + rand_perturbation\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Enhanced Adaptive Differential Swarm Algorithm with dynamic randomization for improved exploration and convergence.", "configspace": "", "generation": 47, "fitness": 0.22953534271745613, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.21.", "error": "", "parent_id": "71ab7e61-b77f-48ce-a3f7-e6f249b39333", "metadata": {"aucs": [0.4450589804469335, 0.4450589804469335, 0.4450589804469335, 0.4449763166991897, 0.4449763166991897, 0.4449763166991897, 0.4394819373792196, 0.4394819373792196, 0.4394819373792196, 0.06669214980958826, 0.06669214980958826, 0.06669214980958826, 0.07219875937394316, 0.07219875937394316, 0.07219875937394316, 0.07332221788327442, 0.07332221788327442, 0.07332221788327442, 0.10900561839296175, 0.10900561839296175, 0.10900561839296175, 0.125358894896472, 0.125358894896472, 0.125358894896472, 0.11811535823424402, 0.11811535823424402, 0.11811535823424402, 0.09659415557986506, 0.09659415557986506, 0.09659415557986506, 0.10112613825737371, 0.10112613825737371, 0.10112613825737371, 0.10086822460035305, 0.10086822460035305, 0.10086822460035305, 0.966273448577675, 0.966273448577675, 0.966273448577675, 0.9678708318028961, 0.9678708318028961, 0.9678708318028961, 0.9635137695929863, 0.9635137695929863, 0.9635137695929863, 0.2937794719268759, 0.2937794719268759, 0.2937794719268759, 0.29918267208528804, 0.29918267208528804, 0.29918267208528804, 0.319763045172372, 0.319763045172372, 0.319763045172372, 0.22744352945516677, 0.22744352945516677, 0.22744352945516677, 0.2695755448804128, 0.2695755448804128, 0.2695755448804128, 0.2343046330888061, 0.2343046330888061, 0.2343046330888061, 0.17327062819236394, 0.17327062819236394, 0.17327062819236394, 0.16331182470848038, 0.16331182470848038, 0.16331182470848038, 0.16075604020029255, 0.16075604020029255, 0.16075604020029255, 0.1876426912879885, 0.1876426912879885, 0.1876426912879885, 0.16803785500028223, 0.16803785500028223, 0.16803785500028223, 0.16350084482138738, 0.16350084482138738, 0.16350084482138738, 0.019484113369098832, 0.019484113369098832, 0.019484113369098832, 0.01090516433984634, 0.01090516433984634, 0.01090516433984634, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07671510032528073, 0.07671510032528073, 0.07671510032528073, 0.03111560368631472, 0.03111560368631472, 0.03111560368631472, 0.14786252415862222, 0.14786252415862222, 0.14786252415862222, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09084059242372644, 0.09084059242372644, 0.09084059242372644, 0.10823809679564089, 0.10823809679564089, 0.10823809679564089, 0.10296872206279861, 0.10296872206279861, 0.10296872206279861, 0.4354235808954059, 0.4354235808954059, 0.4354235808954059, 0.4248255756441838, 0.4248255756441838, 0.4248255756441838, 0.4200566868914728, 0.4200566868914728, 0.4200566868914728, 0.11003530367413838, 0.11003530367413838, 0.11003530367413838, 0.1440204415143166, 0.1440204415143166, 0.1440204415143166, 0.09058366615057434, 0.09058366615057434, 0.09058366615057434, 0.22772746764942375, 0.22772746764942375, 0.22772746764942375, 0.19525264302457856, 0.19525264302457856, 0.19525264302457856, 0.23656661032505621, 0.23656661032505621, 0.23656661032505621, 0.3049195662360429, 0.3049195662360429, 0.3049195662360429, 0.30356296792668214, 0.30356296792668214, 0.30356296792668214, 0.32425674065393784, 0.32425674065393784, 0.32425674065393784, 0.17489327707830749, 0.17489327707830749, 0.17489327707830749, 0.21694345841390794, 0.21694345841390794, 0.21694345841390794, 0.14704035937338755, 0.14704035937338755, 0.14704035937338755, 0.20726184641699197, 0.20726184641699197, 0.20726184641699197, 0.21903965550621596, 0.21903965550621596, 0.21903965550621596, 0.22249217561034884, 0.22249217561034884, 0.22249217561034884, 0.2401924106811828, 0.2401924106811828, 0.2401924106811828, 0.20065999698668657, 0.20065999698668657, 0.20065999698668657, 0.22138835809675717, 0.22138835809675717, 0.22138835809675717, 0.7599788432259875, 0.7599788432259875, 0.7599788432259875, 0.15832220628584492, 0.15832220628584492, 0.15832220628584492, 0.16912857169228723, 0.16912857169228723, 0.16912857169228723, 0.5499713519403875, 0.5499713519403875, 0.5499713519403875, 0.21214937300441594, 0.21214937300441594, 0.21214937300441594, 0.42371070185688786, 0.42371070185688786, 0.42371070185688786, 0.18109707814927134, 0.18109707814927134, 0.18109707814927134, 0.18503638509182696, 0.18503638509182696, 0.18503638509182696, 0.18435434558656294, 0.18435434558656294, 0.18435434558656294, 0.09575302600445756, 0.09575302600445756, 0.09575302600445756, 0.09568263132015453, 0.09568263132015453, 0.09568263132015453, 0.10466187324113885, 0.10466187324113885, 0.10466187324113885]}, "mutation_prompt": null}
{"id": "3dd9d82c-5942-4ad4-bd6a-96ab677a3ed9", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n        self.ans_factor = 0.1  # ANS exploration factor\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.5, self.inertia_weight * 0.99)\n                self.population_size = max(10, int(self.population_size * 0.9))\n            \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            self.learning_rate = 0.05 + 0.45 * (eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            # Adaptive velocity clipping\n            max_velocity = 0.2 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            # Adaptive Neighborhood Search (ANS)\n            ans_positions = positions + np.random.normal(0, self.ans_factor, positions.shape)\n            ans_positions = np.clip(ans_positions, self.lower_bound, self.upper_bound)\n            ans_scores = np.array([func(x) for x in ans_positions])\n            eval_count += self.population_size\n            \n            better_mask = ans_scores < scores\n            positions[better_mask] = ans_positions[better_mask]\n            scores[better_mask] = ans_scores[better_mask]\n\n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Introducing Adaptive Neighborhood Search (ANS) and dynamic population size adjustments for enhanced convergence.", "configspace": "", "generation": 48, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (45,5) (50,5) ').", "error": "ValueError('operands could not be broadcast together with shapes (45,5) (50,5) ')", "parent_id": "71ab7e61-b77f-48ce-a3f7-e6f249b39333", "metadata": {}, "mutation_prompt": null}
{"id": "26b9d9bf-9f0d-43bf-9416-4bc91b1575b8", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > 2 * self.population_size:  # Dynamic inertia weight reset\n                self.inertia_weight = max(0.5, self.inertia_weight * 0.95)\n            \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            self.learning_rate = 0.05 + 0.45 * (eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            # Adaptive velocity clipping\n            max_velocity = 0.2 * (self.upper_bound - self.lower_bound) * (1 - eval_count / self.budget) # Adaptive exploration-exploitation\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Modified EnhancedADSA with a dynamic inertia weight reset and adaptive exploration-exploitation balance for faster convergence.", "configspace": "", "generation": 49, "fitness": 0.34654369358303894, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.28.", "error": "", "parent_id": "71ab7e61-b77f-48ce-a3f7-e6f249b39333", "metadata": {"aucs": [0.8605878920397755, 0.8605878920397755, 0.8605878920397755, 0.8379711730636881, 0.8379711730636881, 0.8379711730636881, 0.8466193365328334, 0.8466193365328334, 0.8466193365328334, 0.6418816541111141, 0.6418816541111141, 0.6418816541111141, 0.6102807182993291, 0.6102807182993291, 0.6102807182993291, 0.765874809073771, 0.765874809073771, 0.765874809073771, 0.1826228804018799, 0.1826228804018799, 0.1826228804018799, 0.1755144854657783, 0.1755144854657783, 0.1755144854657783, 0.11739573196332509, 0.11739573196332509, 0.11739573196332509, 0.1412013131994394, 0.1412013131994394, 0.1412013131994394, 0.10782710860926548, 0.10782710860926548, 0.10782710860926548, 0.13926571990412884, 0.13926571990412884, 0.13926571990412884, 0.9658512817942967, 0.9658512817942967, 0.9658512817942967, 0.9724128961454512, 0.9724128961454512, 0.9724128961454512, 0.9637874312707806, 0.9637874312707806, 0.9637874312707806, 0.5372057260312575, 0.5372057260312575, 0.5372057260312575, 0.699351875563611, 0.699351875563611, 0.699351875563611, 0.7048547768720397, 0.7048547768720397, 0.7048547768720397, 0.8728481396644036, 0.8728481396644036, 0.8728481396644036, 0.19334895119770867, 0.19334895119770867, 0.19334895119770867, 0.8459017201943784, 0.8459017201943784, 0.8459017201943784, 0.20614223306114066, 0.20614223306114066, 0.20614223306114066, 0.19575223285394472, 0.19575223285394472, 0.19575223285394472, 0.2345043473097097, 0.2345043473097097, 0.2345043473097097, 0.22789075888701416, 0.22789075888701416, 0.22789075888701416, 0.20353533311279803, 0.20353533311279803, 0.20353533311279803, 0.21473168764683104, 0.21473168764683104, 0.21473168764683104, 0.008406126861976948, 0.008406126861976948, 0.008406126861976948, 0.0689035379637466, 0.0689035379637466, 0.0689035379637466, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13807382949159364, 0.13807382949159364, 0.13807382949159364, 0.04652388101766558, 0.04652388101766558, 0.04652388101766558, 0.12274712424558387, 0.12274712424558387, 0.12274712424558387, 0.04773075644217262, 0.04773075644217262, 0.04773075644217262, 0.2251852328397066, 0.2251852328397066, 0.2251852328397066, 0.14234982584553313, 0.14234982584553313, 0.14234982584553313, 0.18720040105098168, 0.18720040105098168, 0.18720040105098168, 0.046113069049922295, 0.046113069049922295, 0.046113069049922295, 0.2045153622957231, 0.2045153622957231, 0.2045153622957231, 0.5130635914089521, 0.5130635914089521, 0.5130635914089521, 0.5947936122517647, 0.5947936122517647, 0.5947936122517647, 0.5534702783315331, 0.5534702783315331, 0.5534702783315331, 0.14252465139816028, 0.14252465139816028, 0.14252465139816028, 0.14064804025001054, 0.14064804025001054, 0.14064804025001054, 0.102162968909016, 0.102162968909016, 0.102162968909016, 0.20931071548379998, 0.20931071548379998, 0.20931071548379998, 0.26454454874571387, 0.26454454874571387, 0.26454454874571387, 0.2484228868717695, 0.2484228868717695, 0.2484228868717695, 0.39942671307375, 0.39942671307375, 0.39942671307375, 0.38022767484803244, 0.38022767484803244, 0.38022767484803244, 0.4947680727500883, 0.4947680727500883, 0.4947680727500883, 0.17556675604724858, 0.17556675604724858, 0.17556675604724858, 0.2670822525424692, 0.2670822525424692, 0.2670822525424692, 0.13479685574619793, 0.13479685574619793, 0.13479685574619793, 0.2204587262189811, 0.2204587262189811, 0.2204587262189811, 0.22977292697731844, 0.22977292697731844, 0.22977292697731844, 0.26276171597322673, 0.26276171597322673, 0.26276171597322673, 0.2489905966487047, 0.2489905966487047, 0.2489905966487047, 0.5583349778008938, 0.5583349778008938, 0.5583349778008938, 0.23468852793966466, 0.23468852793966466, 0.23468852793966466, 0.9316075935371421, 0.9316075935371421, 0.9316075935371421, 0.15870842676551233, 0.15870842676551233, 0.15870842676551233, 0.8913260517089815, 0.8913260517089815, 0.8913260517089815, 0.5593215955307504, 0.5593215955307504, 0.5593215955307504, 0.21228902688436524, 0.21228902688436524, 0.21228902688436524, 0.15604447582028425, 0.15604447582028425, 0.15604447582028425, 0.20114579976417746, 0.20114579976417746, 0.20114579976417746, 0.21233628564500273, 0.21233628564500273, 0.21233628564500273, 0.21984337235146822, 0.21984337235146822, 0.21984337235146822, 0.10251194841422862, 0.10251194841422862, 0.10251194841422862, 0.09869423608136496, 0.09869423608136496, 0.09869423608136496, 0.12848867388392704, 0.12848867388392704, 0.12848867388392704]}, "mutation_prompt": null}
{"id": "a968c503-f4cc-4c55-9688-24a2f2a590f0", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, budget // 10)\n        self.population_size = self.initial_population_size\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.5, self.inertia_weight * 0.99)\n                # Dynamic population resizing\n                self.population_size = max(10, int(self.population_size * 0.95))\n                positions = positions[:self.population_size]\n                velocities = velocities[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n                \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            self.learning_rate = 0.05 + 0.45 * (eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            max_velocity = 0.2 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "EnhancedADSA with dynamic population resizing and focused local search for improved exploration and exploitation balance.", "configspace": "", "generation": 50, "fitness": 0.35656922891636544, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.29.", "error": "", "parent_id": "71ab7e61-b77f-48ce-a3f7-e6f249b39333", "metadata": {"aucs": [0.8924549189310796, 0.8924549189310796, 0.8924549189310796, 0.8903889431582012, 0.8903889431582012, 0.8903889431582012, 0.869721287160905, 0.869721287160905, 0.869721287160905, 0.7946773978729791, 0.7946773978729791, 0.7946773978729791, 0.7385917154355637, 0.7385917154355637, 0.7385917154355637, 0.8092633550756181, 0.8092633550756181, 0.8092633550756181, 0.13240645280504026, 0.13240645280504026, 0.13240645280504026, 0.15636713684879944, 0.15636713684879944, 0.15636713684879944, 0.7762633435687509, 0.7762633435687509, 0.7762633435687509, 0.12411228901955618, 0.12411228901955618, 0.12411228901955618, 0.15153761341246175, 0.15153761341246175, 0.15153761341246175, 0.15540845824117422, 0.15540845824117422, 0.15540845824117422, 0.9659674281261577, 0.9659674281261577, 0.9659674281261577, 0.9724467528817047, 0.9724467528817047, 0.9724467528817047, 0.963540476697738, 0.963540476697738, 0.963540476697738, 0.7226402983598437, 0.7226402983598437, 0.7226402983598437, 0.6017472643453361, 0.6017472643453361, 0.6017472643453361, 0.7468191148287837, 0.7468191148287837, 0.7468191148287837, 0.9045578759897465, 0.9045578759897465, 0.9045578759897465, 0.1935959333128765, 0.1935959333128765, 0.1935959333128765, 0.23543424668787705, 0.23543424668787705, 0.23543424668787705, 0.19551180563101456, 0.19551180563101456, 0.19551180563101456, 0.22037469139141386, 0.22037469139141386, 0.22037469139141386, 0.2646052016095005, 0.2646052016095005, 0.2646052016095005, 0.21071893644730366, 0.21071893644730366, 0.21071893644730366, 0.22009361123059956, 0.22009361123059956, 0.22009361123059956, 0.22454445344455598, 0.22454445344455598, 0.22454445344455598, 0.016381711061741577, 0.016381711061741577, 0.016381711061741577, 0.028313514392251493, 0.028313514392251493, 0.028313514392251493, 0.001638872920988077, 0.001638872920988077, 0.001638872920988077, 0.09887786225566142, 0.09887786225566142, 0.09887786225566142, 0.06038539256470299, 0.06038539256470299, 0.06038539256470299, 0.12878297969268804, 0.12878297969268804, 0.12878297969268804, 0.050284706395471224, 0.050284706395471224, 0.050284706395471224, 0.3810606792216077, 0.3810606792216077, 0.3810606792216077, 0.137966354508547, 0.137966354508547, 0.137966354508547, 0.15736527350750107, 0.15736527350750107, 0.15736527350750107, 0.03831415922201109, 0.03831415922201109, 0.03831415922201109, 0.26995053014849324, 0.26995053014849324, 0.26995053014849324, 0.5355108168049482, 0.5355108168049482, 0.5355108168049482, 0.5638386776533892, 0.5638386776533892, 0.5638386776533892, 0.5891564686103627, 0.5891564686103627, 0.5891564686103627, 0.11504475409016901, 0.11504475409016901, 0.11504475409016901, 0.1559375816230666, 0.1559375816230666, 0.1559375816230666, 0.10611671473794826, 0.10611671473794826, 0.10611671473794826, 0.23188380179173806, 0.23188380179173806, 0.23188380179173806, 0.25341574401166855, 0.25341574401166855, 0.25341574401166855, 0.2321222316480468, 0.2321222316480468, 0.2321222316480468, 0.3629110161365676, 0.3629110161365676, 0.3629110161365676, 0.27076426563264, 0.27076426563264, 0.27076426563264, 0.48642887103074817, 0.48642887103074817, 0.48642887103074817, 0.19367891222811195, 0.19367891222811195, 0.19367891222811195, 0.35899207118322685, 0.35899207118322685, 0.35899207118322685, 0.13694775814330273, 0.13694775814330273, 0.13694775814330273, 0.23737994358051473, 0.23737994358051473, 0.23737994358051473, 0.2641835256732227, 0.2641835256732227, 0.2641835256732227, 0.26071468971597267, 0.26071468971597267, 0.26071468971597267, 0.2511441295364173, 0.2511441295364173, 0.2511441295364173, 0.8027773512467775, 0.8027773512467775, 0.8027773512467775, 0.18916396344208586, 0.18916396344208586, 0.18916396344208586, 0.909650931745233, 0.909650931745233, 0.909650931745233, 0.15869225820695898, 0.15869225820695898, 0.15869225820695898, 0.8138376393991962, 0.8138376393991962, 0.8138376393991962, 0.4125142992804238, 0.4125142992804238, 0.4125142992804238, 0.21255596111209685, 0.21255596111209685, 0.21255596111209685, 0.15593811556414272, 0.15593811556414272, 0.15593811556414272, 0.20804377939529228, 0.20804377939529228, 0.20804377939529228, 0.21021060672515945, 0.21021060672515945, 0.21021060672515945, 0.19715927316259874, 0.19715927316259874, 0.19715927316259874, 0.08822991052068596, 0.08822991052068596, 0.08822991052068596, 0.08389102079582333, 0.08389102079582333, 0.08389102079582333, 0.121034359143533, 0.121034359143533, 0.121034359143533]}, "mutation_prompt": null}
{"id": "9c3dd0bb-1c00-4beb-8915-0cf6f71076bf", "solution": "import numpy as np\n\nclass AdaptiveQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(60, budget // 8)\n        self.population_size = self.initial_population_size\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.quantum_coef = 0.5\n        self.shrink_weight = 0.9\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n\n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > 2 * self.population_size:\n                self.population_size = max(20, int(self.population_size * self.shrink_weight))\n                positions = positions[:self.population_size]\n                velocities = velocities[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n\n            # Quantum-inspired potential field\n            quantum_position = global_best_position + self.quantum_coef * np.random.uniform(-1, 1, self.dim)\n            quantum_velocity = self.quantum_coef * r1 * (quantum_position - positions)\n\n            velocities = self.inertia_weight * velocities + cognitive_velocity + social_velocity + quantum_velocity\n            \n            max_velocity = 0.3 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "AdaptiveQPSO", "description": "Adaptive Quantum-inspired Particle Swarm Optimization (AQPSO) integrates quantum mechanics principles to enhance diversity and convergence speed.", "configspace": "", "generation": 51, "fitness": 0.21525906534349493, "feedback": "The algorithm AdaptiveQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "a968c503-f4cc-4c55-9688-24a2f2a590f0", "metadata": {"aucs": [0.4258669622273883, 0.4258669622273883, 0.4258669622273883, 0.4188574113410134, 0.4188574113410134, 0.4188574113410134, 0.42387812288407156, 0.42387812288407156, 0.42387812288407156, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008693667931379823, 0.008693667931379823, 0.008693667931379823, 0.008950426569696024, 0.008950426569696024, 0.008950426569696024, 0.10646855393110233, 0.10646855393110233, 0.10646855393110233, 0.11334714768072995, 0.11334714768072995, 0.11334714768072995, 0.10022471691806001, 0.10022471691806001, 0.10022471691806001, 0.11659113488878847, 0.11659113488878847, 0.11659113488878847, 0.08908042327921117, 0.08908042327921117, 0.08908042327921117, 0.10173449398952894, 0.10173449398952894, 0.10173449398952894, 0.9755249806620402, 0.9755249806620402, 0.9755249806620402, 0.9777823365756464, 0.9777823365756464, 0.9777823365756464, 0.9781121486502539, 0.9781121486502539, 0.9781121486502539, 0.2700315621272519, 0.2700315621272519, 0.2700315621272519, 0.2797008613616001, 0.2797008613616001, 0.2797008613616001, 0.28972595509543253, 0.28972595509543253, 0.28972595509543253, 0.22555965715799986, 0.22555965715799986, 0.22555965715799986, 0.1612954910930463, 0.1612954910930463, 0.1612954910930463, 0.29350513120820576, 0.29350513120820576, 0.29350513120820576, 0.14689541563292874, 0.14689541563292874, 0.14689541563292874, 0.15086723530910462, 0.15086723530910462, 0.15086723530910462, 0.19155471398443547, 0.19155471398443547, 0.19155471398443547, 0.0650202096165049, 0.0650202096165049, 0.0650202096165049, 0.13792839794674927, 0.13792839794674927, 0.13792839794674927, 0.15320526006431956, 0.15320526006431956, 0.15320526006431956, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03816591520172874, 0.03816591520172874, 0.03816591520172874, 0.1364029516392451, 0.1364029516392451, 0.1364029516392451, 0.07763515561385936, 0.07763515561385936, 0.07763515561385936, 0.053977765482774887, 0.053977765482774887, 0.053977765482774887, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12148116147198018, 0.12148116147198018, 0.12148116147198018, 0.07175861371709724, 0.07175861371709724, 0.07175861371709724, 0.0675220757727657, 0.0675220757727657, 0.0675220757727657, 0.39924892771448617, 0.39924892771448617, 0.39924892771448617, 0.3911327032570526, 0.3911327032570526, 0.3911327032570526, 0.38717876304393306, 0.38717876304393306, 0.38717876304393306, 0.10049437207404321, 0.10049437207404321, 0.10049437207404321, 0.11562929079136852, 0.11562929079136852, 0.11562929079136852, 0.1370347753292488, 0.1370347753292488, 0.1370347753292488, 0.2583396035914597, 0.2583396035914597, 0.2583396035914597, 0.24751053708578197, 0.24751053708578197, 0.24751053708578197, 0.23462939298347252, 0.23462939298347252, 0.23462939298347252, 0.2750362033656961, 0.2750362033656961, 0.2750362033656961, 0.27934836809034747, 0.27934836809034747, 0.27934836809034747, 0.28944605359977804, 0.28944605359977804, 0.28944605359977804, 0.21654083837135796, 0.21654083837135796, 0.21654083837135796, 0.21784830166377855, 0.21784830166377855, 0.21784830166377855, 0.19695852792970614, 0.19695852792970614, 0.19695852792970614, 0.21921366233449402, 0.21921366233449402, 0.21921366233449402, 0.22045476674587872, 0.22045476674587872, 0.22045476674587872, 0.2166835152601535, 0.2166835152601535, 0.2166835152601535, 0.2281255726789172, 0.2281255726789172, 0.2281255726789172, 0.2073286017378433, 0.2073286017378433, 0.2073286017378433, 0.2506806209902238, 0.2506806209902238, 0.2506806209902238, 0.5876489367414508, 0.5876489367414508, 0.5876489367414508, 0.14686851434720283, 0.14686851434720283, 0.14686851434720283, 0.16900126649073133, 0.16900126649073133, 0.16900126649073133, 0.46839485498820443, 0.46839485498820443, 0.46839485498820443, 0.21123160242692818, 0.21123160242692818, 0.21123160242692818, 0.15520567604233493, 0.15520567604233493, 0.15520567604233493, 0.20470410131908334, 0.20470410131908334, 0.20470410131908334, 0.1791924959013822, 0.1791924959013822, 0.1791924959013822, 0.1937613003678399, 0.1937613003678399, 0.1937613003678399, 0.09891084081945811, 0.09891084081945811, 0.09891084081945811, 0.09740739090576878, 0.09740739090576878, 0.09740739090576878, 0.11951626871628906, 0.11951626871628906, 0.11951626871628906]}, "mutation_prompt": null}
{"id": "2bcefd3a-717a-4dd9-92e7-11c4d4319a3b", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, budget // 10)\n        self.population_size = self.initial_population_size\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            # Adaptive inertia weight\n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.5, self.inertia_weight * (0.98 + 0.01 * np.random.rand()))\n                # Refined dynamic population resizing\n                self.population_size = max(10, int(self.population_size * (0.95 + 0.01 * np.random.rand())))\n                positions = positions[:self.population_size]\n                velocities = velocities[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n                \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            self.learning_rate = 0.05 + 0.45 * (eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            max_velocity = 0.2 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "EnhancedADSA with adaptive inertia weight and refined dynamic population resizing for improved convergence speed.", "configspace": "", "generation": 52, "fitness": 0.3473858942939337, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.28.", "error": "", "parent_id": "a968c503-f4cc-4c55-9688-24a2f2a590f0", "metadata": {"aucs": [0.8763987396047752, 0.8763987396047752, 0.8763987396047752, 0.8638766963618688, 0.8638766963618688, 0.8638766963618688, 0.8823014913704705, 0.8823014913704705, 0.8823014913704705, 0.786830225103729, 0.786830225103729, 0.786830225103729, 0.7337781886505446, 0.7337781886505446, 0.7337781886505446, 0.8135627185665972, 0.8135627185665972, 0.8135627185665972, 0.13225269264176132, 0.13225269264176132, 0.13225269264176132, 0.1236823286847708, 0.1236823286847708, 0.1236823286847708, 0.18385465321279704, 0.18385465321279704, 0.18385465321279704, 0.11076273883255339, 0.11076273883255339, 0.11076273883255339, 0.15184495992151226, 0.15184495992151226, 0.15184495992151226, 0.1554771345744228, 0.1554771345744228, 0.1554771345744228, 0.9659674281261577, 0.9659674281261577, 0.9659674281261577, 0.9724467528817047, 0.9724467528817047, 0.9724467528817047, 0.963540476697738, 0.963540476697738, 0.963540476697738, 0.7328868659124712, 0.7328868659124712, 0.7328868659124712, 0.426313951807737, 0.426313951807737, 0.426313951807737, 0.7757079641366796, 0.7757079641366796, 0.7757079641366796, 0.37907466871229567, 0.37907466871229567, 0.37907466871229567, 0.19313759401096486, 0.19313759401096486, 0.19313759401096486, 0.8685550477838271, 0.8685550477838271, 0.8685550477838271, 0.202302915293036, 0.202302915293036, 0.202302915293036, 0.24493667334248514, 0.24493667334248514, 0.24493667334248514, 0.12836617235602266, 0.12836617235602266, 0.12836617235602266, 0.22424346154544927, 0.22424346154544927, 0.22424346154544927, 0.19837440811383278, 0.19837440811383278, 0.19837440811383278, 0.23926251180393543, 0.23926251180393543, 0.23926251180393543, 0.024946679959471862, 0.024946679959471862, 0.024946679959471862, 0.03528517562032085, 0.03528517562032085, 0.03528517562032085, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12548199314122954, 0.12548199314122954, 0.12548199314122954, 0.05809526401689413, 0.05809526401689413, 0.05809526401689413, 0.20052232876151888, 0.20052232876151888, 0.20052232876151888, 0.050461620785283046, 0.050461620785283046, 0.050461620785283046, 0.28759932488707163, 0.28759932488707163, 0.28759932488707163, 0.1383940361433772, 0.1383940361433772, 0.1383940361433772, 0.14325995489152044, 0.14325995489152044, 0.14325995489152044, 0.03805663252028224, 0.03805663252028224, 0.03805663252028224, 0.20903567386332966, 0.20903567386332966, 0.20903567386332966, 0.6129060070547017, 0.6129060070547017, 0.6129060070547017, 0.5226186044352841, 0.5226186044352841, 0.5226186044352841, 0.5430163429531784, 0.5430163429531784, 0.5430163429531784, 0.13134402720214056, 0.13134402720214056, 0.13134402720214056, 0.11133775974636739, 0.11133775974636739, 0.11133775974636739, 0.12465676861376629, 0.12465676861376629, 0.12465676861376629, 0.15576025237949997, 0.15576025237949997, 0.15576025237949997, 0.2642395367829905, 0.2642395367829905, 0.2642395367829905, 0.2758111022325084, 0.2758111022325084, 0.2758111022325084, 0.40258383682637044, 0.40258383682637044, 0.40258383682637044, 0.37738962323048, 0.37738962323048, 0.37738962323048, 0.4847895481127109, 0.4847895481127109, 0.4847895481127109, 0.1910991903663971, 0.1910991903663971, 0.1910991903663971, 0.4217859517054833, 0.4217859517054833, 0.4217859517054833, 0.3005044879696762, 0.3005044879696762, 0.3005044879696762, 0.21697454534077332, 0.21697454534077332, 0.21697454534077332, 0.22757468008470294, 0.22757468008470294, 0.22757468008470294, 0.24684013995328347, 0.24684013995328347, 0.24684013995328347, 0.20941962440907602, 0.20941962440907602, 0.20941962440907602, 0.22602783634111434, 0.22602783634111434, 0.22602783634111434, 0.21524704255843352, 0.21524704255843352, 0.21524704255843352, 0.9321276359189224, 0.9321276359189224, 0.9321276359189224, 0.15859345207619424, 0.15859345207619424, 0.15859345207619424, 0.8904542790921166, 0.8904542790921166, 0.8904542790921166, 0.6530125795316999, 0.6530125795316999, 0.6530125795316999, 0.2124058699042587, 0.2124058699042587, 0.2124058699042587, 0.24979227003995186, 0.24979227003995186, 0.24979227003995186, 0.2526505605054624, 0.2526505605054624, 0.2526505605054624, 0.1764208691146092, 0.1764208691146092, 0.1764208691146092, 0.24663712182385222, 0.24663712182385222, 0.24663712182385222, 0.10427377101826185, 0.10427377101826185, 0.10427377101826185, 0.09595233809370762, 0.09595233809370762, 0.09595233809370762, 0.13655858910481133, 0.13655858910481133, 0.13655858910481133]}, "mutation_prompt": null}
{"id": "74e789c1-a90a-4e48-8740-9dd85fe51d2e", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, budget // 10)\n        self.population_size = self.initial_population_size\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.5, self.inertia_weight * 0.992)  # Slightly adjusted decay\n                self.population_size = max(10, int(self.population_size * 0.95))\n                positions = positions[:self.population_size]\n                velocities = velocities[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n                \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            self.learning_rate = 0.05 + 0.45 * (eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            max_velocity = 0.2 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "EnhancedADSA with adaptive inertia weight decay and refined velocity update for improved convergence.", "configspace": "", "generation": 53, "fitness": 0.34360302758896916, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.", "error": "", "parent_id": "a968c503-f4cc-4c55-9688-24a2f2a590f0", "metadata": {"aucs": [0.8931881195963103, 0.8931881195963103, 0.8931881195963103, 0.8864208134835172, 0.8864208134835172, 0.8864208134835172, 0.8732314440891512, 0.8732314440891512, 0.8732314440891512, 0.7593285212616664, 0.7593285212616664, 0.7593285212616664, 0.7112357358320558, 0.7112357358320558, 0.7112357358320558, 0.7895281699395621, 0.7895281699395621, 0.7895281699395621, 0.125015799013671, 0.125015799013671, 0.125015799013671, 0.11605458668211377, 0.11605458668211377, 0.11605458668211377, 0.18588305102114877, 0.18588305102114877, 0.18588305102114877, 0.11751331884620975, 0.11751331884620975, 0.11751331884620975, 0.11374890540831806, 0.11374890540831806, 0.11374890540831806, 0.15558384443491835, 0.15558384443491835, 0.15558384443491835, 0.9659674281261577, 0.9659674281261577, 0.9659674281261577, 0.9724467528817047, 0.9724467528817047, 0.9724467528817047, 0.963540476697738, 0.963540476697738, 0.963540476697738, 0.7285395135960281, 0.7285395135960281, 0.7285395135960281, 0.5063195046208273, 0.5063195046208273, 0.5063195046208273, 0.7644111927897139, 0.7644111927897139, 0.7644111927897139, 0.9027415027013149, 0.9027415027013149, 0.9027415027013149, 0.19359880714438393, 0.19359880714438393, 0.19359880714438393, 0.4968043720703369, 0.4968043720703369, 0.4968043720703369, 0.1956514495638647, 0.1956514495638647, 0.1956514495638647, 0.21831023365952407, 0.21831023365952407, 0.21831023365952407, 0.2515660843501982, 0.2515660843501982, 0.2515660843501982, 0.21032982403870515, 0.21032982403870515, 0.21032982403870515, 0.21053716715184, 0.21053716715184, 0.21053716715184, 0.2178661259354281, 0.2178661259354281, 0.2178661259354281, 0.0383098519967805, 0.0383098519967805, 0.0383098519967805, 0.03551106730705922, 0.03551106730705922, 0.03551106730705922, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10663355613614423, 0.10663355613614423, 0.10663355613614423, 0.0663209751030599, 0.0663209751030599, 0.0663209751030599, 0.11731060427606355, 0.11731060427606355, 0.11731060427606355, 0.04896713770248573, 0.04896713770248573, 0.04896713770248573, 0.3221387496149407, 0.3221387496149407, 0.3221387496149407, 0.1279537665637539, 0.1279537665637539, 0.1279537665637539, 0.15635889541978631, 0.15635889541978631, 0.15635889541978631, 0.038296421491520904, 0.038296421491520904, 0.038296421491520904, 0.2714393702733382, 0.2714393702733382, 0.2714393702733382, 0.5149422293839463, 0.5149422293839463, 0.5149422293839463, 0.5104900824521956, 0.5104900824521956, 0.5104900824521956, 0.56593392919682, 0.56593392919682, 0.56593392919682, 0.1278905511736521, 0.1278905511736521, 0.1278905511736521, 0.15737687703942194, 0.15737687703942194, 0.15737687703942194, 0.10604208499925005, 0.10604208499925005, 0.10604208499925005, 0.2607435319448771, 0.2607435319448771, 0.2607435319448771, 0.22231053999099837, 0.22231053999099837, 0.22231053999099837, 0.20108080983730758, 0.20108080983730758, 0.20108080983730758, 0.34293355680986337, 0.34293355680986337, 0.34293355680986337, 0.4301306565524947, 0.4301306565524947, 0.4301306565524947, 0.3460300086004324, 0.3460300086004324, 0.3460300086004324, 0.19141493118325703, 0.19141493118325703, 0.19141493118325703, 0.3276994796890138, 0.3276994796890138, 0.3276994796890138, 0.22071929254640654, 0.22071929254640654, 0.22071929254640654, 0.21113134488701046, 0.21113134488701046, 0.21113134488701046, 0.27939774733709233, 0.27939774733709233, 0.27939774733709233, 0.24894159281295325, 0.24894159281295325, 0.24894159281295325, 0.2513339424666605, 0.2513339424666605, 0.2513339424666605, 0.2529091675012137, 0.2529091675012137, 0.2529091675012137, 0.18908181461808604, 0.18908181461808604, 0.18908181461808604, 0.9247581947395315, 0.9247581947395315, 0.9247581947395315, 0.15869169838197883, 0.15869169838197883, 0.15869169838197883, 0.8840559414705605, 0.8840559414705605, 0.8840559414705605, 0.7048251266417638, 0.7048251266417638, 0.7048251266417638, 0.21256240207327115, 0.21256240207327115, 0.21256240207327115, 0.1559335228420694, 0.1559335228420694, 0.1559335228420694, 0.20666141715996833, 0.20666141715996833, 0.20666141715996833, 0.19287998717862742, 0.19287998717862742, 0.19287998717862742, 0.19882507087972123, 0.19882507087972123, 0.19882507087972123, 0.0965089741809757, 0.0965089741809757, 0.0965089741809757, 0.08975018654718203, 0.08975018654718203, 0.08975018654718203, 0.10072815246583267, 0.10072815246583267, 0.10072815246583267]}, "mutation_prompt": null}
{"id": "695215cd-5daa-405a-b749-9061aa49e024", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.scaling_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptation_rate = 1.0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        scores = np.array([func(x) for x in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            new_population = np.copy(population)\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[idxs]\n                mutant_vector = a + self.scaling_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < scores[i]:\n                    new_population[i] = trial_vector\n                    scores[i] = trial_score\n\n            population = new_population\n            \n            self.scaling_factor = 0.8 + 0.2 * (eval_count / self.budget)\n            self.crossover_rate = 0.9 - 0.4 * (eval_count / self.budget) + np.random.uniform(-0.1, 0.1)\n\n        best_idx = np.argmin(scores)\n        return population[best_idx], scores[best_idx]", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with strategic parameter adjustment for enhanced adaptability and convergence speed.", "configspace": "", "generation": 54, "fitness": 0.2173362612481306, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.19.", "error": "", "parent_id": "a968c503-f4cc-4c55-9688-24a2f2a590f0", "metadata": {"aucs": [0.5407955922773364, 0.5407955922773364, 0.5407955922773364, 0.5773557792135444, 0.5773557792135444, 0.5773557792135444, 0.5846427516650325, 0.5846427516650325, 0.5846427516650325, 0.31833159246735043, 0.31833159246735043, 0.31833159246735043, 0.28901753788494366, 0.28901753788494366, 0.28901753788494366, 0.2994703227549995, 0.2994703227549995, 0.2994703227549995, 0.1336257537094303, 0.1336257537094303, 0.1336257537094303, 0.1207415691446393, 0.1207415691446393, 0.1207415691446393, 0.12875000092400513, 0.12875000092400513, 0.12875000092400513, 0.12066633084393508, 0.12066633084393508, 0.12066633084393508, 0.10542215437247637, 0.10542215437247637, 0.10542215437247637, 0.11512994861997394, 0.11512994861997394, 0.11512994861997394, 0.9402728544774419, 0.9402728544774419, 0.9402728544774419, 0.9313046139743478, 0.9313046139743478, 0.9313046139743478, 0.933596494971457, 0.933596494971457, 0.933596494971457, 0.2288804083610566, 0.2288804083610566, 0.2288804083610566, 0.22392603276501788, 0.22392603276501788, 0.22392603276501788, 0.2439075628217816, 0.2439075628217816, 0.2439075628217816, 0.263358001516787, 0.263358001516787, 0.263358001516787, 0.238261211716845, 0.238261211716845, 0.238261211716845, 0.25147859313285703, 0.25147859313285703, 0.25147859313285703, 0.13716192185013354, 0.13716192185013354, 0.13716192185013354, 0.13625447615748287, 0.13625447615748287, 0.13625447615748287, 0.1286029033740228, 0.1286029033740228, 0.1286029033740228, 0.17179683517134559, 0.17179683517134559, 0.17179683517134559, 0.12384470908442435, 0.12384470908442435, 0.12384470908442435, 0.11707502558964711, 0.11707502558964711, 0.11707502558964711, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.019061513317489287, 0.019061513317489287, 0.019061513317489287, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08270120403961667, 0.08270120403961667, 0.08270120403961667, 0.09503759791144106, 0.09503759791144106, 0.09503759791144106, 0.12905317265127336, 0.12905317265127336, 0.12905317265127336, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0722785181479858, 0.0722785181479858, 0.0722785181479858, 0.09288935004051746, 0.09288935004051746, 0.09288935004051746, 0.09299476340032975, 0.09299476340032975, 0.09299476340032975, 0.40195477497994025, 0.40195477497994025, 0.40195477497994025, 0.38791582268044955, 0.38791582268044955, 0.38791582268044955, 0.38687964866761626, 0.38687964866761626, 0.38687964866761626, 0.07676599343719881, 0.07676599343719881, 0.07676599343719881, 0.08074751191123342, 0.08074751191123342, 0.08074751191123342, 0.0902005726501891, 0.0902005726501891, 0.0902005726501891, 0.14416953628121687, 0.14416953628121687, 0.14416953628121687, 0.17620580261633823, 0.17620580261633823, 0.17620580261633823, 0.15488387058374697, 0.15488387058374697, 0.15488387058374697, 0.24054078941091406, 0.24054078941091406, 0.24054078941091406, 0.21642197842320543, 0.21642197842320543, 0.21642197842320543, 0.2663733776263685, 0.2663733776263685, 0.2663733776263685, 0.1803424498764774, 0.1803424498764774, 0.1803424498764774, 0.16950702610479584, 0.16950702610479584, 0.16950702610479584, 0.18592728216042986, 0.18592728216042986, 0.18592728216042986, 0.192659418900763, 0.192659418900763, 0.192659418900763, 0.18738442361056395, 0.18738442361056395, 0.18738442361056395, 0.1784172003438973, 0.1784172003438973, 0.1784172003438973, 0.18235739432240894, 0.18235739432240894, 0.18235739432240894, 0.18580566897822892, 0.18580566897822892, 0.18580566897822892, 0.18367090106624806, 0.18367090106624806, 0.18367090106624806, 0.42570291283079165, 0.42570291283079165, 0.42570291283079165, 0.1824906665399899, 0.1824906665399899, 0.1824906665399899, 0.2244331123741915, 0.2244331123741915, 0.2244331123741915, 0.37133095267717864, 0.37133095267717864, 0.37133095267717864, 0.2186827498566729, 0.2186827498566729, 0.2186827498566729, 0.20093514653255218, 0.20093514653255218, 0.20093514653255218, 0.1827688580674901, 0.1827688580674901, 0.1827688580674901, 0.18660198562016617, 0.18660198562016617, 0.18660198562016617, 0.1909578793727118, 0.1909578793727118, 0.1909578793727118, 0.0724341209308057, 0.0724341209308057, 0.0724341209308057, 0.062467676898699365, 0.062467676898699365, 0.062467676898699365, 0.0720862051809561, 0.0720862051809561, 0.0720862051809561]}, "mutation_prompt": null}
{"id": "a0613731-bb85-4caa-b5b3-f4e40ddab295", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, budget // 10)\n        self.population_size = self.initial_population_size\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)  # Adjusted decay rate\n                # Dynamic population resizing\n                self.population_size = max(10, int(self.population_size * 0.95))\n                positions = positions[:self.population_size]\n                velocities = velocities[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n                \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            self.learning_rate = 0.05 + 0.45 * (eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            max_velocity = 0.2 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Improved EnhancedADSA with adaptive inertia weight decay and refined velocity update for faster convergence.", "configspace": "", "generation": 55, "fitness": 0.3354774723471764, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.28.", "error": "", "parent_id": "a968c503-f4cc-4c55-9688-24a2f2a590f0", "metadata": {"aucs": [0.9023462905820133, 0.9023462905820133, 0.9023462905820133, 0.8767493388413296, 0.8767493388413296, 0.8767493388413296, 0.8739691423206646, 0.8739691423206646, 0.8739691423206646, 0.7765121265069537, 0.7765121265069537, 0.7765121265069537, 0.6762991185155796, 0.6762991185155796, 0.6762991185155796, 0.8233526825018349, 0.8233526825018349, 0.8233526825018349, 0.15876425334694322, 0.15876425334694322, 0.15876425334694322, 0.12394763669109854, 0.12394763669109854, 0.12394763669109854, 0.15988793847406757, 0.15988793847406757, 0.15988793847406757, 0.13103959543625698, 0.13103959543625698, 0.13103959543625698, 0.09837723296806289, 0.09837723296806289, 0.09837723296806289, 0.1547669582094794, 0.1547669582094794, 0.1547669582094794, 0.9659674281261577, 0.9659674281261577, 0.9659674281261577, 0.9724467528817047, 0.9724467528817047, 0.9724467528817047, 0.963540476697738, 0.963540476697738, 0.963540476697738, 0.7564281605163267, 0.7564281605163267, 0.7564281605163267, 0.7447114938837736, 0.7447114938837736, 0.7447114938837736, 0.6465236486978101, 0.6465236486978101, 0.6465236486978101, 0.3522780959829138, 0.3522780959829138, 0.3522780959829138, 0.1937635244632816, 0.1937635244632816, 0.1937635244632816, 0.23567532105350397, 0.23567532105350397, 0.23567532105350397, 0.19424096496163157, 0.19424096496163157, 0.19424096496163157, 0.2297105586773267, 0.2297105586773267, 0.2297105586773267, 0.2623434786495439, 0.2623434786495439, 0.2623434786495439, 0.22120036835344659, 0.22120036835344659, 0.22120036835344659, 0.22174034292561307, 0.22174034292561307, 0.22174034292561307, 0.21645122562827945, 0.21645122562827945, 0.21645122562827945, 0.024617663716946514, 0.024617663716946514, 0.024617663716946514, 0.043089478284589644, 0.043089478284589644, 0.043089478284589644, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11233070726151617, 0.11233070726151617, 0.11233070726151617, 0.059050736879736165, 0.059050736879736165, 0.059050736879736165, 0.1070300907702334, 0.1070300907702334, 0.1070300907702334, 0.05078181913392632, 0.05078181913392632, 0.05078181913392632, 0.4215095859725969, 0.4215095859725969, 0.4215095859725969, 0.13078589721376843, 0.13078589721376843, 0.13078589721376843, 0.20719065128261638, 0.20719065128261638, 0.20719065128261638, 0.03828856483184406, 0.03828856483184406, 0.03828856483184406, 0.26708418149282875, 0.26708418149282875, 0.26708418149282875, 0.5283650522961372, 0.5283650522961372, 0.5283650522961372, 0.5679956503299439, 0.5679956503299439, 0.5679956503299439, 0.537971564517747, 0.537971564517747, 0.537971564517747, 0.15716136819913462, 0.15716136819913462, 0.15716136819913462, 0.11481234328117262, 0.11481234328117262, 0.11481234328117262, 0.10626838401692362, 0.10626838401692362, 0.10626838401692362, 0.227004828101663, 0.227004828101663, 0.227004828101663, 0.20104598737760448, 0.20104598737760448, 0.20104598737760448, 0.2603690421299232, 0.2603690421299232, 0.2603690421299232, 0.40992066827718, 0.40992066827718, 0.40992066827718, 0.4539634032463963, 0.4539634032463963, 0.4539634032463963, 0.46709133228310706, 0.46709133228310706, 0.46709133228310706, 0.21127774442873803, 0.21127774442873803, 0.21127774442873803, 0.30831158921612956, 0.30831158921612956, 0.30831158921612956, 0.13641580341842818, 0.13641580341842818, 0.13641580341842818, 0.23552944027354328, 0.23552944027354328, 0.23552944027354328, 0.21593542693390455, 0.21593542693390455, 0.21593542693390455, 0.25814027765149294, 0.25814027765149294, 0.25814027765149294, 0.2233770310483043, 0.2233770310483043, 0.2233770310483043, 0.20453972667157805, 0.20453972667157805, 0.20453972667157805, 0.1886847204819323, 0.1886847204819323, 0.1886847204819323, 0.9161473606817703, 0.9161473606817703, 0.9161473606817703, 0.15869883848816768, 0.15869883848816768, 0.15869883848816768, 0.8721857109925466, 0.8721857109925466, 0.8721857109925466, 0.5366866756966993, 0.5366866756966993, 0.5366866756966993, 0.21257157449512765, 0.21257157449512765, 0.21257157449512765, 0.1558354390912946, 0.1558354390912946, 0.1558354390912946, 0.19250942749069422, 0.19250942749069422, 0.19250942749069422, 0.18445610655622435, 0.18445610655622435, 0.18445610655622435, 0.2024315804328718, 0.2024315804328718, 0.2024315804328718, 0.09574936462909356, 0.09574936462909356, 0.09574936462909356, 0.09433347436664152, 0.09433347436664152, 0.09433347436664152, 0.12369753916064963, 0.12369753916064963, 0.12369753916064963]}, "mutation_prompt": null}
{"id": "fc815020-7a5d-4bd0-accb-b2adc5d496b6", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, budget // 10)\n        self.population_size = self.initial_population_size\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n        self.mutation_chance = 0.05  # Added for mutation\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.5, self.inertia_weight * 0.99)\n                self.population_size = max(10, int(self.population_size * 0.95))\n                positions = positions[:self.population_size]\n                velocities = velocities[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n                \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            self.learning_rate = 0.05 + 0.45 * (eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            max_velocity = 0.2 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n\n            # Introduce mutation for better exploration\n            mutation_mask = np.random.rand(self.population_size, self.dim) < self.mutation_chance\n            random_mutation = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n            positions = np.where(mutation_mask, random_mutation, positions)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "EnhancedADSA improved with adaptive mutation for faster convergence and better exploration.", "configspace": "", "generation": 56, "fitness": 0.26960664346206265, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.22.", "error": "", "parent_id": "a968c503-f4cc-4c55-9688-24a2f2a590f0", "metadata": {"aucs": [0.656203905196154, 0.656203905196154, 0.656203905196154, 0.5986588425439693, 0.5986588425439693, 0.5986588425439693, 0.5312321796588224, 0.5312321796588224, 0.5312321796588224, 0.2469802394864159, 0.2469802394864159, 0.2469802394864159, 0.26457886945219244, 0.26457886945219244, 0.26457886945219244, 0.22125909347795691, 0.22125909347795691, 0.22125909347795691, 0.19829093871398185, 0.19829093871398185, 0.19829093871398185, 0.142277977675761, 0.142277977675761, 0.142277977675761, 0.1660266252485546, 0.1660266252485546, 0.1660266252485546, 0.15756024503737864, 0.15756024503737864, 0.15756024503737864, 0.14386071713296045, 0.14386071713296045, 0.14386071713296045, 0.13452746378117386, 0.13452746378117386, 0.13452746378117386, 0.9594823984591223, 0.9594823984591223, 0.9594823984591223, 0.9677492561211027, 0.9677492561211027, 0.9677492561211027, 0.967648764211179, 0.967648764211179, 0.967648764211179, 0.3175081627658607, 0.3175081627658607, 0.3175081627658607, 0.29956976221464815, 0.29956976221464815, 0.29956976221464815, 0.35942228461621595, 0.35942228461621595, 0.35942228461621595, 0.31960414447199625, 0.31960414447199625, 0.31960414447199625, 0.275829526475337, 0.275829526475337, 0.275829526475337, 0.23362532181720774, 0.23362532181720774, 0.23362532181720774, 0.153810603424697, 0.153810603424697, 0.153810603424697, 0.18195520022722123, 0.18195520022722123, 0.18195520022722123, 0.15943318872469403, 0.15943318872469403, 0.15943318872469403, 0.19780685163222766, 0.19780685163222766, 0.19780685163222766, 0.1989222741239388, 0.1989222741239388, 0.1989222741239388, 0.2029935910768671, 0.2029935910768671, 0.2029935910768671, 0.05677647828323207, 0.05677647828323207, 0.05677647828323207, 0.05940072468240487, 0.05940072468240487, 0.05940072468240487, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14763916564814172, 0.14763916564814172, 0.14763916564814172, 0.05861238902040222, 0.05861238902040222, 0.05861238902040222, 0.09627564632303398, 0.09627564632303398, 0.09627564632303398, 0.01844412500483472, 0.01844412500483472, 0.01844412500483472, 0.016366248435851993, 0.016366248435851993, 0.016366248435851993, 0.03952711356064098, 0.03952711356064098, 0.03952711356064098, 0.14357941379401762, 0.14357941379401762, 0.14357941379401762, 0.10486929813293899, 0.10486929813293899, 0.10486929813293899, 0.09865239049200791, 0.09865239049200791, 0.09865239049200791, 0.46174104292161944, 0.46174104292161944, 0.46174104292161944, 0.42531875008483877, 0.42531875008483877, 0.42531875008483877, 0.4248763797386126, 0.4248763797386126, 0.4248763797386126, 0.11317262286384588, 0.11317262286384588, 0.11317262286384588, 0.09431835565218694, 0.09431835565218694, 0.09431835565218694, 0.1375316018101661, 0.1375316018101661, 0.1375316018101661, 0.21903485337517148, 0.21903485337517148, 0.21903485337517148, 0.2417711475620946, 0.2417711475620946, 0.2417711475620946, 0.3123258875566518, 0.3123258875566518, 0.3123258875566518, 0.34475547776193427, 0.34475547776193427, 0.34475547776193427, 0.33223250098172785, 0.33223250098172785, 0.33223250098172785, 0.3231508978408528, 0.3231508978408528, 0.3231508978408528, 0.2056185694446775, 0.2056185694446775, 0.2056185694446775, 0.24474476343558527, 0.24474476343558527, 0.24474476343558527, 0.19282421736575683, 0.19282421736575683, 0.19282421736575683, 0.20134012965892067, 0.20134012965892067, 0.20134012965892067, 0.2305280577233112, 0.2305280577233112, 0.2305280577233112, 0.2155787055852506, 0.2155787055852506, 0.2155787055852506, 0.24931669572496362, 0.24931669572496362, 0.24931669572496362, 0.22373679481609576, 0.22373679481609576, 0.22373679481609576, 0.3074811383145515, 0.3074811383145515, 0.3074811383145515, 0.7969234675944427, 0.7969234675944427, 0.7969234675944427, 0.15766632578102813, 0.15766632578102813, 0.15766632578102813, 0.8694209473263427, 0.8694209473263427, 0.8694209473263427, 0.5208688250241246, 0.5208688250241246, 0.5208688250241246, 0.2107279024305273, 0.2107279024305273, 0.2107279024305273, 0.434514199130817, 0.434514199130817, 0.434514199130817, 0.17501781451837906, 0.17501781451837906, 0.17501781451837906, 0.18433350101740775, 0.18433350101740775, 0.18433350101740775, 0.19235274949441683, 0.19235274949441683, 0.19235274949441683, 0.09105828237194402, 0.09105828237194402, 0.09105828237194402, 0.07723664295568067, 0.07723664295568067, 0.07723664295568067, 0.10309766025944156, 0.10309766025944156, 0.10309766025944156]}, "mutation_prompt": null}
{"id": "827fc8b9-d3fb-4cd7-bc19-965b69ad345d", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, budget // 10)\n        self.population_size = self.initial_population_size\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.49\n        self.social_coef = 1.49\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.5, self.inertia_weight * 0.985)  # Slightly adjusted decay rate\n                # Dynamic population resizing\n                self.population_size = max(10, int(self.population_size * 0.95))\n                positions = positions[:self.population_size]\n                velocities = velocities[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n                \n            self.cognitive_coef = 1.49 + 0.45 * (1 - eval_count / self.budget)  # Adjusted range\n            self.social_coef = 1.49 - 0.45 * (1 - eval_count / self.budget)  # Adjusted range\n            self.learning_rate = 0.05 + 0.48 * (eval_count / self.budget)  # Adjusted range\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            max_velocity = 0.2 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Improved parameter adaptation for more responsive exploration-exploitation balance throughout the search process.", "configspace": "", "generation": 57, "fitness": 0.34092583697706236, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.28.", "error": "", "parent_id": "a968c503-f4cc-4c55-9688-24a2f2a590f0", "metadata": {"aucs": [0.8926619651657698, 0.8926619651657698, 0.8926619651657698, 0.8878823637863539, 0.8878823637863539, 0.8878823637863539, 0.8603020332098525, 0.8603020332098525, 0.8603020332098525, 0.7497602694973815, 0.7497602694973815, 0.7497602694973815, 0.7986683368115064, 0.7986683368115064, 0.7986683368115064, 0.7920902227276322, 0.7920902227276322, 0.7920902227276322, 0.1322621352536908, 0.1322621352536908, 0.1322621352536908, 0.11600053414808531, 0.11600053414808531, 0.11600053414808531, 0.11736100182121278, 0.11736100182121278, 0.11736100182121278, 0.18309192924237017, 0.18309192924237017, 0.18309192924237017, 0.14038714871016078, 0.14038714871016078, 0.14038714871016078, 0.1423176356295749, 0.1423176356295749, 0.1423176356295749, 0.9661146447827746, 0.9661146447827746, 0.9661146447827746, 0.9725049144761322, 0.9725049144761322, 0.9725049144761322, 0.9634848542862502, 0.9634848542862502, 0.9634848542862502, 0.7246695294881392, 0.7246695294881392, 0.7246695294881392, 0.41038751917278093, 0.41038751917278093, 0.41038751917278093, 0.7644687107320651, 0.7644687107320651, 0.7644687107320651, 0.226889436994833, 0.226889436994833, 0.226889436994833, 0.19369633189772795, 0.19369633189772795, 0.19369633189772795, 0.2990599516522501, 0.2990599516522501, 0.2990599516522501, 0.19290771044880983, 0.19290771044880983, 0.19290771044880983, 0.27064137987973436, 0.27064137987973436, 0.27064137987973436, 0.1758053477940642, 0.1758053477940642, 0.1758053477940642, 0.2197058354268866, 0.2197058354268866, 0.2197058354268866, 0.22466579345199367, 0.22466579345199367, 0.22466579345199367, 0.23786422670021246, 0.23786422670021246, 0.23786422670021246, 0.05583800836320896, 0.05583800836320896, 0.05583800836320896, 0.041439716616362254, 0.041439716616362254, 0.041439716616362254, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08643268797979853, 0.08643268797979853, 0.08643268797979853, 0.04949277967018939, 0.04949277967018939, 0.04949277967018939, 0.08908737376558473, 0.08908737376558473, 0.08908737376558473, 0.05589247562560995, 0.05589247562560995, 0.05589247562560995, 0.3803281467307458, 0.3803281467307458, 0.3803281467307458, 0.12359587406628947, 0.12359587406628947, 0.12359587406628947, 0.31504432876323585, 0.31504432876323585, 0.31504432876323585, 0.039146300296604375, 0.039146300296604375, 0.039146300296604375, 0.2824743411183246, 0.2824743411183246, 0.2824743411183246, 0.518888703194522, 0.518888703194522, 0.518888703194522, 0.5147402795654555, 0.5147402795654555, 0.5147402795654555, 0.5966552368580836, 0.5966552368580836, 0.5966552368580836, 0.14306982245974909, 0.14306982245974909, 0.14306982245974909, 0.07799594770969376, 0.07799594770969376, 0.07799594770969376, 0.12887953871208535, 0.12887953871208535, 0.12887953871208535, 0.33483288948911394, 0.33483288948911394, 0.33483288948911394, 0.3357039385237759, 0.3357039385237759, 0.3357039385237759, 0.25983486096489317, 0.25983486096489317, 0.25983486096489317, 0.48603313752743726, 0.48603313752743726, 0.48603313752743726, 0.5162050285274484, 0.5162050285274484, 0.5162050285274484, 0.48222837748416814, 0.48222837748416814, 0.48222837748416814, 0.2080147591520024, 0.2080147591520024, 0.2080147591520024, 0.2882182816464175, 0.2882182816464175, 0.2882182816464175, 0.22774751711167085, 0.22774751711167085, 0.22774751711167085, 0.2137059133612691, 0.2137059133612691, 0.2137059133612691, 0.2979518720053883, 0.2979518720053883, 0.2979518720053883, 0.2564657395238642, 0.2564657395238642, 0.2564657395238642, 0.2523579739052261, 0.2523579739052261, 0.2523579739052261, 0.2103661496370759, 0.2103661496370759, 0.2103661496370759, 0.19242205277892066, 0.19242205277892066, 0.19242205277892066, 0.9276864204381596, 0.9276864204381596, 0.9276864204381596, 0.1588165777409527, 0.1588165777409527, 0.1588165777409527, 0.9048962832404446, 0.9048962832404446, 0.9048962832404446, 0.5588124033455366, 0.5588124033455366, 0.5588124033455366, 0.2123304855975724, 0.2123304855975724, 0.2123304855975724, 0.15762412717733898, 0.15762412717733898, 0.15762412717733898, 0.20182689888829253, 0.20182689888829253, 0.20182689888829253, 0.22944864081014205, 0.22944864081014205, 0.22944864081014205, 0.1868324489871599, 0.1868324489871599, 0.1868324489871599, 0.08354275635479402, 0.08354275635479402, 0.08354275635479402, 0.08347544616045721, 0.08347544616045721, 0.08347544616045721, 0.12452595728517901, 0.12452595728517901, 0.12452595728517901]}, "mutation_prompt": null}
{"id": "494d394e-d214-4b87-877d-c861e479aefa", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, budget // 10)\n        self.population_size = self.initial_population_size\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.5, self.inertia_weight * 0.99)\n                # Dynamic population resizing\n                self.population_size = max(10, int(self.population_size * 0.94))  # Adjusted factor for resizing\n                positions = positions[:self.population_size]\n                velocities = velocities[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n                \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            self.learning_rate = 0.05 + 0.45 * (eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            max_velocity = 0.2 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Minor adjustment to the dynamic population resizing factor to enhance convergence stability and adaptability.", "configspace": "", "generation": 58, "fitness": 0.33179569386637303, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.27.", "error": "", "parent_id": "a968c503-f4cc-4c55-9688-24a2f2a590f0", "metadata": {"aucs": [0.8989849251653708, 0.8989849251653708, 0.8989849251653708, 0.8934652525833346, 0.8934652525833346, 0.8934652525833346, 0.8810045692654382, 0.8810045692654382, 0.8810045692654382, 0.8013179262572805, 0.8013179262572805, 0.8013179262572805, 0.7567029098308465, 0.7567029098308465, 0.7567029098308465, 0.8704022042725325, 0.8704022042725325, 0.8704022042725325, 0.1882724387082031, 0.1882724387082031, 0.1882724387082031, 0.1150559273622086, 0.1150559273622086, 0.1150559273622086, 0.1860071009133092, 0.1860071009133092, 0.1860071009133092, 0.13054209447812593, 0.13054209447812593, 0.13054209447812593, 0.09515480717565439, 0.09515480717565439, 0.09515480717565439, 0.1411250992275409, 0.1411250992275409, 0.1411250992275409, 0.9659674281261577, 0.9659674281261577, 0.9659674281261577, 0.9724467528817047, 0.9724467528817047, 0.9724467528817047, 0.963540476697738, 0.963540476697738, 0.963540476697738, 0.7637381693323094, 0.7637381693323094, 0.7637381693323094, 0.5416898835652366, 0.5416898835652366, 0.5416898835652366, 0.48455134719067494, 0.48455134719067494, 0.48455134719067494, 0.5388264433968073, 0.5388264433968073, 0.5388264433968073, 0.1935946451286189, 0.1935946451286189, 0.1935946451286189, 0.34838332534756344, 0.34838332534756344, 0.34838332534756344, 0.20024644558124383, 0.20024644558124383, 0.20024644558124383, 0.21151391673446374, 0.21151391673446374, 0.21151391673446374, 0.23639947733494182, 0.23639947733494182, 0.23639947733494182, 0.22936557614079822, 0.22936557614079822, 0.22936557614079822, 0.22044092494254308, 0.22044092494254308, 0.22044092494254308, 0.21545749807400094, 0.21545749807400094, 0.21545749807400094, 0.04819495760155146, 0.04819495760155146, 0.04819495760155146, 0.044147471756810996, 0.044147471756810996, 0.044147471756810996, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15493913396985914, 0.15493913396985914, 0.15493913396985914, 0.05811598262391848, 0.05811598262391848, 0.05811598262391848, 0.11118173456071456, 0.11118173456071456, 0.11118173456071456, 0.0500182600327691, 0.0500182600327691, 0.0500182600327691, 0.31254342827580484, 0.31254342827580484, 0.31254342827580484, 0.14627775519503505, 0.14627775519503505, 0.14627775519503505, 0.14943300613863575, 0.14943300613863575, 0.14943300613863575, 0.03828726872808497, 0.03828726872808497, 0.03828726872808497, 0.2810482112197046, 0.2810482112197046, 0.2810482112197046, 0.5968293899306261, 0.5968293899306261, 0.5968293899306261, 0.49405319452589014, 0.49405319452589014, 0.49405319452589014, 0.5528222866445422, 0.5528222866445422, 0.5528222866445422, 0.10964925512032186, 0.10964925512032186, 0.10964925512032186, 0.1152971844296653, 0.1152971844296653, 0.1152971844296653, 0.12257224609357908, 0.12257224609357908, 0.12257224609357908, 0.17503111001705163, 0.17503111001705163, 0.17503111001705163, 0.1765142309352068, 0.1765142309352068, 0.1765142309352068, 0.18088399333358107, 0.18088399333358107, 0.18088399333358107, 0.523520295420898, 0.523520295420898, 0.523520295420898, 0.2747914263707262, 0.2747914263707262, 0.2747914263707262, 0.33508275173168456, 0.33508275173168456, 0.33508275173168456, 0.2034075282598422, 0.2034075282598422, 0.2034075282598422, 0.30563440011633247, 0.30563440011633247, 0.30563440011633247, 0.24928195283204946, 0.24928195283204946, 0.24928195283204946, 0.2049761230874596, 0.2049761230874596, 0.2049761230874596, 0.2523722509952001, 0.2523722509952001, 0.2523722509952001, 0.24223484218335423, 0.24223484218335423, 0.24223484218335423, 0.22387494857806878, 0.22387494857806878, 0.22387494857806878, 0.22675949640147453, 0.22675949640147453, 0.22675949640147453, 0.1888831371122317, 0.1888831371122317, 0.1888831371122317, 0.9242256076020016, 0.9242256076020016, 0.9242256076020016, 0.15867842834913937, 0.15867842834913937, 0.15867842834913937, 0.709282793810228, 0.709282793810228, 0.709282793810228, 0.4510935629701809, 0.4510935629701809, 0.4510935629701809, 0.21255651888669713, 0.21255651888669713, 0.21255651888669713, 0.2341242754834173, 0.2341242754834173, 0.2341242754834173, 0.20717889947534207, 0.20717889947534207, 0.20717889947534207, 0.22317770634316614, 0.22317770634316614, 0.22317770634316614, 0.2299471105873102, 0.2299471105873102, 0.2299471105873102, 0.10396519710641183, 0.10396519710641183, 0.10396519710641183, 0.10487102907031753, 0.10487102907031753, 0.10487102907031753, 0.1372320087573251, 0.1372320087573251, 0.1372320087573251]}, "mutation_prompt": null}
{"id": "27405576-fbad-4697-973c-52418725cc7b", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, budget // 10)\n        self.population_size = self.initial_population_size\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n        self.local_search_intensity = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n\n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)\n                self.population_size = max(10, int(self.population_size * 0.9))\n                positions = positions[:self.population_size]\n                velocities = velocities[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n                \n                # Inject diversity with random individuals\n                if np.random.rand() > 0.75:\n                    diversity_positions = np.random.uniform(self.lower_bound, self.upper_bound, (5, self.dim))\n                    positions[-5:] = diversity_positions\n\n            self.cognitive_coef = 1.494 + 0.3 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.3 * (1 - eval_count / self.budget)\n            self.learning_rate = 0.05 + 0.65 * (eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_velocity + social_velocity\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            max_velocity = 0.25 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            # Local search for best individual\n            local_search_candidate = global_best_position + self.local_search_intensity * np.random.normal(size=self.dim)\n            local_search_candidate = np.clip(local_search_candidate, self.lower_bound, self.upper_bound)\n            local_search_score = func(local_search_candidate)\n            eval_count += 1\n            if local_search_score < global_best_score:\n                global_best_score = local_search_score\n                global_best_position = local_search_candidate\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "A multi-strategy optimizer integrating adaptive learning rates, local search enhancements, and intermittent population diversity boosts for accelerated convergence.", "configspace": "", "generation": 59, "fitness": 0.28045732552221225, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.25.", "error": "", "parent_id": "a968c503-f4cc-4c55-9688-24a2f2a590f0", "metadata": {"aucs": [0.9295517425647654, 0.9295517425647654, 0.9295517425647654, 0.910936184818331, 0.910936184818331, 0.910936184818331, 0.9331790407981416, 0.9331790407981416, 0.9331790407981416, 0.31114287089322334, 0.31114287089322334, 0.31114287089322334, 0.3404840888452244, 0.3404840888452244, 0.3404840888452244, 0.2296612411105119, 0.2296612411105119, 0.2296612411105119, 0.14648288689004618, 0.14648288689004618, 0.14648288689004618, 0.16436684189152895, 0.16436684189152895, 0.16436684189152895, 0.11921755353655172, 0.11921755353655172, 0.11921755353655172, 0.1453903723273785, 0.1453903723273785, 0.1453903723273785, 0.12245097596110444, 0.12245097596110444, 0.12245097596110444, 0.1221784352927402, 0.1221784352927402, 0.1221784352927402, 0.9757999189243909, 0.9757999189243909, 0.9757999189243909, 0.9776610924856071, 0.9776610924856071, 0.9776610924856071, 0.9715343153335307, 0.9715343153335307, 0.9715343153335307, 0.37687184444896915, 0.37687184444896915, 0.37687184444896915, 0.7139743604982411, 0.7139743604982411, 0.7139743604982411, 0.4179557926758274, 0.4179557926758274, 0.4179557926758274, 0.3887488292972515, 0.3887488292972515, 0.3887488292972515, 0.16179512411766228, 0.16179512411766228, 0.16179512411766228, 0.21248256675485555, 0.21248256675485555, 0.21248256675485555, 0.13209068638565258, 0.13209068638565258, 0.13209068638565258, 0.1556520721006558, 0.1556520721006558, 0.1556520721006558, 0.17313631459808532, 0.17313631459808532, 0.17313631459808532, 0.2378324950941464, 0.2378324950941464, 0.2378324950941464, 0.16341549759761487, 0.16341549759761487, 0.16341549759761487, 0.12753587993779802, 0.12753587993779802, 0.12753587993779802, 0.05460323171006076, 0.05460323171006076, 0.05460323171006076, 0.006452760974917093, 0.006452760974917093, 0.006452760974917093, 0.09585742607416581, 0.09585742607416581, 0.09585742607416581, 0.11068546305048299, 0.11068546305048299, 0.11068546305048299, 0.04290165096206944, 0.04290165096206944, 0.04290165096206944, 0.08230947172438263, 0.08230947172438263, 0.08230947172438263, 0.052537345595919605, 0.052537345595919605, 0.052537345595919605, 0.44100303004367947, 0.44100303004367947, 0.44100303004367947, 0.31616692640667066, 0.31616692640667066, 0.31616692640667066, 0.12492896588416735, 0.12492896588416735, 0.12492896588416735, 0.08292249261439555, 0.08292249261439555, 0.08292249261439555, 0.08882585520995712, 0.08882585520995712, 0.08882585520995712, 0.5443781081300089, 0.5443781081300089, 0.5443781081300089, 0.5884706092657205, 0.5884706092657205, 0.5884706092657205, 0.528585895827253, 0.528585895827253, 0.528585895827253, 0.10441331651717078, 0.10441331651717078, 0.10441331651717078, 0.1085780148330534, 0.1085780148330534, 0.1085780148330534, 0.10228403167271627, 0.10228403167271627, 0.10228403167271627, 0.2188071166914668, 0.2188071166914668, 0.2188071166914668, 0.17510830411973854, 0.17510830411973854, 0.17510830411973854, 0.1849487407555046, 0.1849487407555046, 0.1849487407555046, 0.3975437325086296, 0.3975437325086296, 0.3975437325086296, 0.2897856869579004, 0.2897856869579004, 0.2897856869579004, 0.2978950859836623, 0.2978950859836623, 0.2978950859836623, 0.15468841459066096, 0.15468841459066096, 0.15468841459066096, 0.2809464762550853, 0.2809464762550853, 0.2809464762550853, 0.13314870764797326, 0.13314870764797326, 0.13314870764797326, 0.20814277672651338, 0.20814277672651338, 0.20814277672651338, 0.21658507491318035, 0.21658507491318035, 0.21658507491318035, 0.21853197140195169, 0.21853197140195169, 0.21853197140195169, 0.22887552123070687, 0.22887552123070687, 0.22887552123070687, 0.18503507953844145, 0.18503507953844145, 0.18503507953844145, 0.1985920311680487, 0.1985920311680487, 0.1985920311680487, 0.9397936595166388, 0.9397936595166388, 0.9397936595166388, 0.1585975017308796, 0.1585975017308796, 0.1585975017308796, 0.13666573056338238, 0.13666573056338238, 0.13666573056338238, 0.18623291773105888, 0.18623291773105888, 0.18623291773105888, 0.21291246064050617, 0.21291246064050617, 0.21291246064050617, 0.15656173481196023, 0.15656173481196023, 0.15656173481196023, 0.19348682133093542, 0.19348682133093542, 0.19348682133093542, 0.19705806777065804, 0.19705806777065804, 0.19705806777065804, 0.19976991343401063, 0.19976991343401063, 0.19976991343401063, 0.09150395146618773, 0.09150395146618773, 0.09150395146618773, 0.09430449782072059, 0.09430449782072059, 0.09430449782072059, 0.0999718386162487, 0.0999718386162487, 0.0999718386162487]}, "mutation_prompt": null}
{"id": "085a89a4-2403-4e1d-9d73-1d0c260e4b43", "solution": "import numpy as np\n\nclass EnhancedADSAV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, budget // 10)\n        self.population_size = self.initial_population_size\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.5, self.inertia_weight * 0.99)\n                # Dynamic population resizing\n                self.population_size = max(10, int(self.population_size * 0.95))\n                positions = positions[:self.population_size]\n                velocities = velocities[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n                \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            # Adaptive learning rate\n            self.learning_rate = 0.05 + 0.5 * (global_best_score / np.mean(scores))\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            max_velocity = 0.2 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            # Mutation strategy for exploration\n            if eval_count % (self.population_size * 10) == 0:\n                mutation_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n                positions[mutation_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(mutation_indices), self.dim))\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSAV2", "description": "Introducing adaptive learning rate and additional mutation strategy to improve convergence speed.", "configspace": "", "generation": 60, "fitness": 0.3142585256085193, "feedback": "The algorithm EnhancedADSAV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.26.", "error": "", "parent_id": "a968c503-f4cc-4c55-9688-24a2f2a590f0", "metadata": {"aucs": [0.8556229250452358, 0.8556229250452358, 0.8556229250452358, 0.8631952097084351, 0.8631952097084351, 0.8631952097084351, 0.8300436487668583, 0.8300436487668583, 0.8300436487668583, 0.6117094619997885, 0.6117094619997885, 0.6117094619997885, 0.6589630630371541, 0.6589630630371541, 0.6589630630371541, 0.6059972703245013, 0.6059972703245013, 0.6059972703245013, 0.15698129796435045, 0.15698129796435045, 0.15698129796435045, 0.17574794267353722, 0.17574794267353722, 0.17574794267353722, 0.76922198533509, 0.76922198533509, 0.76922198533509, 0.0832254825645028, 0.0832254825645028, 0.0832254825645028, 0.13864895658508436, 0.13864895658508436, 0.13864895658508436, 0.1741384130729421, 0.1741384130729421, 0.1741384130729421, 0.9597737092887101, 0.9597737092887101, 0.9597737092887101, 0.9726847024062489, 0.9726847024062489, 0.9726847024062489, 0.963424824912286, 0.963424824912286, 0.963424824912286, 0.6118580934790558, 0.6118580934790558, 0.6118580934790558, 0.6867180028045545, 0.6867180028045545, 0.6867180028045545, 0.3582320103837484, 0.3582320103837484, 0.3582320103837484, 0.363768800517269, 0.363768800517269, 0.363768800517269, 0.16128929089201827, 0.16128929089201827, 0.16128929089201827, 0.3972076278063168, 0.3972076278063168, 0.3972076278063168, 0.17792650506988283, 0.17792650506988283, 0.17792650506988283, 0.15306536907312962, 0.15306536907312962, 0.15306536907312962, 0.20470649698729015, 0.20470649698729015, 0.20470649698729015, 0.21459761841189695, 0.21459761841189695, 0.21459761841189695, 0.17963170686431895, 0.17963170686431895, 0.17963170686431895, 0.21432572842138908, 0.21432572842138908, 0.21432572842138908, 0.05893523792083155, 0.05893523792083155, 0.05893523792083155, 0.06660412184350661, 0.06660412184350661, 0.06660412184350661, 0.0072048829705858575, 0.0072048829705858575, 0.0072048829705858575, 0.16321471715457447, 0.16321471715457447, 0.16321471715457447, 0.023358597205010656, 0.023358597205010656, 0.023358597205010656, 0.15444007820204442, 0.15444007820204442, 0.15444007820204442, 0.049099783085725046, 0.049099783085725046, 0.049099783085725046, 0.43079660953949395, 0.43079660953949395, 0.43079660953949395, 0.1054397006239769, 0.1054397006239769, 0.1054397006239769, 0.3418202629628301, 0.3418202629628301, 0.3418202629628301, 0.09517987026003372, 0.09517987026003372, 0.09517987026003372, 0.06284614445000802, 0.06284614445000802, 0.06284614445000802, 0.4678120381630896, 0.4678120381630896, 0.4678120381630896, 0.5194006426929094, 0.5194006426929094, 0.5194006426929094, 0.4993557423359637, 0.4993557423359637, 0.4993557423359637, 0.11432475798201358, 0.11432475798201358, 0.11432475798201358, 0.10937234197544365, 0.10937234197544365, 0.10937234197544365, 0.10362613219650252, 0.10362613219650252, 0.10362613219650252, 0.5304269587255809, 0.5304269587255809, 0.5304269587255809, 0.24370592793821688, 0.24370592793821688, 0.24370592793821688, 0.31444275851371317, 0.31444275851371317, 0.31444275851371317, 0.3454820894824042, 0.3454820894824042, 0.3454820894824042, 0.34878903048264187, 0.34878903048264187, 0.34878903048264187, 0.3219195663928879, 0.3219195663928879, 0.3219195663928879, 0.16193848421891666, 0.16193848421891666, 0.16193848421891666, 0.3100009963219099, 0.3100009963219099, 0.3100009963219099, 0.1449049406505697, 0.1449049406505697, 0.1449049406505697, 0.20905422090593717, 0.20905422090593717, 0.20905422090593717, 0.2861393778219995, 0.2861393778219995, 0.2861393778219995, 0.22093966578116042, 0.22093966578116042, 0.22093966578116042, 0.19504351921594953, 0.19504351921594953, 0.19504351921594953, 0.2464457251109352, 0.2464457251109352, 0.2464457251109352, 0.1921349890703573, 0.1921349890703573, 0.1921349890703573, 0.878969126969503, 0.878969126969503, 0.878969126969503, 0.15850850194841182, 0.15850850194841182, 0.15850850194841182, 0.1685096042892099, 0.1685096042892099, 0.1685096042892099, 0.1541041679403905, 0.1541041679403905, 0.1541041679403905, 0.2114294761674178, 0.2114294761674178, 0.2114294761674178, 0.1150108639159676, 0.1150108639159676, 0.1150108639159676, 0.20001915083453703, 0.20001915083453703, 0.20001915083453703, 0.22313101693968462, 0.22313101693968462, 0.22313101693968462, 0.18477717340040178, 0.18477717340040178, 0.18477717340040178, 0.09530330920416252, 0.09530330920416252, 0.09530330920416252, 0.0979424893519717, 0.0979424893519717, 0.0979424893519717, 0.15200290625840773, 0.15200290625840773, 0.15200290625840773]}, "mutation_prompt": null}
{"id": "f100e5bf-8468-493e-a38c-14b56bcb0959", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, budget // 10)\n        self.population_size = self.initial_population_size\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.5, self.inertia_weight * 0.99)\n                self.population_size = max(10, int(self.population_size * 0.95))\n                positions = positions[:self.population_size]\n                velocities = velocities[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n                \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            self.learning_rate = 0.05 + 0.45 * (eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_velocity + social_velocity\n            velocities = np.clip(velocities, -0.2 * (self.upper_bound - self.lower_bound), 0.2 * (self.upper_bound - self.lower_bound))\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "EnhancedADSA with adaptive inertia weight for improved convergence speed through dynamic velocity adjustment.", "configspace": "", "generation": 61, "fitness": 0.3286990704526356, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.28.", "error": "", "parent_id": "a968c503-f4cc-4c55-9688-24a2f2a590f0", "metadata": {"aucs": [0.8979487873856103, 0.8979487873856103, 0.8979487873856103, 0.8769758187474179, 0.8769758187474179, 0.8769758187474179, 0.9041948746335506, 0.9041948746335506, 0.9041948746335506, 0.7410779078432596, 0.7410779078432596, 0.7410779078432596, 0.6916471988735406, 0.6916471988735406, 0.6916471988735406, 0.8286748045901733, 0.8286748045901733, 0.8286748045901733, 0.11738283114637726, 0.11738283114637726, 0.11738283114637726, 0.139219168605624, 0.139219168605624, 0.139219168605624, 0.18154435745274045, 0.18154435745274045, 0.18154435745274045, 0.13911211219746022, 0.13911211219746022, 0.13911211219746022, 0.11362514687262737, 0.11362514687262737, 0.11362514687262737, 0.13065767484318602, 0.13065767484318602, 0.13065767484318602, 0.9626718089096611, 0.9626718089096611, 0.9626718089096611, 0.9724372097572846, 0.9724372097572846, 0.9724372097572846, 0.9639786004098306, 0.9639786004098306, 0.9639786004098306, 0.792353414303445, 0.792353414303445, 0.792353414303445, 0.15206335129248616, 0.15206335129248616, 0.15206335129248616, 0.7970983017192339, 0.7970983017192339, 0.7970983017192339, 0.35172102189523624, 0.35172102189523624, 0.35172102189523624, 0.16128294677236754, 0.16128294677236754, 0.16128294677236754, 0.3562371065148324, 0.3562371065148324, 0.3562371065148324, 0.17886819589562675, 0.17886819589562675, 0.17886819589562675, 0.18506251563433063, 0.18506251563433063, 0.18506251563433063, 0.1831563328404756, 0.1831563328404756, 0.1831563328404756, 0.2371594989725485, 0.2371594989725485, 0.2371594989725485, 0.2019484534027164, 0.2019484534027164, 0.2019484534027164, 0.24344729672435128, 0.24344729672435128, 0.24344729672435128, 0.09244433010395625, 0.09244433010395625, 0.09244433010395625, 0.046148632230972875, 0.046148632230972875, 0.046148632230972875, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0951080994740865, 0.0951080994740865, 0.0951080994740865, 0.07677020027829018, 0.07677020027829018, 0.07677020027829018, 0.17782985629969694, 0.17782985629969694, 0.17782985629969694, 0.0470097603673566, 0.0470097603673566, 0.0470097603673566, 0.3773733473643931, 0.3773733473643931, 0.3773733473643931, 0.12923603424906593, 0.12923603424906593, 0.12923603424906593, 0.21193868387537462, 0.21193868387537462, 0.21193868387537462, 0.03835726022546948, 0.03835726022546948, 0.03835726022546948, 0.1875568704875703, 0.1875568704875703, 0.1875568704875703, 0.5617537188755506, 0.5617537188755506, 0.5617537188755506, 0.5636273977883471, 0.5636273977883471, 0.5636273977883471, 0.5487729052641087, 0.5487729052641087, 0.5487729052641087, 0.0999257203995414, 0.0999257203995414, 0.0999257203995414, 0.09636828769602179, 0.09636828769602179, 0.09636828769602179, 0.11660238998915118, 0.11660238998915118, 0.11660238998915118, 0.30878031956770635, 0.30878031956770635, 0.30878031956770635, 0.36126908126491786, 0.36126908126491786, 0.36126908126491786, 0.21680279319104556, 0.21680279319104556, 0.21680279319104556, 0.44451832472553965, 0.44451832472553965, 0.44451832472553965, 0.45703789035601816, 0.45703789035601816, 0.45703789035601816, 0.35658872816876286, 0.35658872816876286, 0.35658872816876286, 0.19344910706817597, 0.19344910706817597, 0.19344910706817597, 0.23740249838998695, 0.23740249838998695, 0.23740249838998695, 0.11474931327044235, 0.11474931327044235, 0.11474931327044235, 0.22133760181871753, 0.22133760181871753, 0.22133760181871753, 0.21079508842408112, 0.21079508842408112, 0.21079508842408112, 0.2138490799327929, 0.2138490799327929, 0.2138490799327929, 0.8540282422073837, 0.8540282422073837, 0.8540282422073837, 0.22589613180910761, 0.22589613180910761, 0.22589613180910761, 0.19739270279731314, 0.19739270279731314, 0.19739270279731314, 0.9201707938950437, 0.9201707938950437, 0.9201707938950437, 0.15871608627712852, 0.15871608627712852, 0.15871608627712852, 0.13619481480482376, 0.13619481480482376, 0.13619481480482376, 0.5270790415116915, 0.5270790415116915, 0.5270790415116915, 0.21290614955278653, 0.21290614955278653, 0.21290614955278653, 0.16647183110929564, 0.16647183110929564, 0.16647183110929564, 0.19669885106906226, 0.19669885106906226, 0.19669885106906226, 0.2179875465227855, 0.2179875465227855, 0.2179875465227855, 0.20190609837514262, 0.20190609837514262, 0.20190609837514262, 0.14330299123897217, 0.14330299123897217, 0.14330299123897217, 0.09815143867501375, 0.09815143867501375, 0.09815143867501375, 0.10438029336107424, 0.10438029336107424, 0.10438029336107424]}, "mutation_prompt": null}
{"id": "7e306cb1-67aa-40f4-9eb3-825748ae3792", "solution": "import numpy as np\n\nclass EnhancedADES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(60, budget // 8)  # slightly larger initial size\n        self.population_size = self.initial_population_size\n        self.inertia_weight = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.2  # adjusted coefficients\n        self.learning_rate = 0.06\n        self.momentum = 0.9  # reduced momentum\n        self.adaptive_rate = 0.99  # new adaptive rate for tuning\n        \n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.randn(self.population_size, self.dim) * 0.1  # initial velocity perturbation\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight *= self.adaptive_rate\n                self.population_size = int(self.population_size * self.adaptive_rate)\n                positions = positions[:self.population_size]\n                velocities = velocities[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n                \n            self.cognitive_coef = 1.5 + 0.4 * (1 - eval_count / self.budget)\n            self.social_coef = 1.2 - 0.4 * (1 - eval_count / self.budget)\n            self.learning_rate = 0.06 + 0.44 * (eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_velocity + social_velocity\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            max_velocity = 0.3 * (self.upper_bound - self.lower_bound)  # increase max velocity bound\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADES", "description": "Adaptive Momentum Enhanced ADES with dynamic population strategies and hybrid exploration-exploitation mechanisms for accelerated convergence.", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('attempt to get argmin of an empty sequence').", "error": "ValueError('attempt to get argmin of an empty sequence')", "parent_id": "a968c503-f4cc-4c55-9688-24a2f2a590f0", "metadata": {}, "mutation_prompt": null}
{"id": "d2a3d402-a5cc-414f-8001-e45ac04a6d2a", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, budget // 10)\n        self.population_size = self.initial_population_size\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                # Adaptive inertia weight decay\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)\n                self.population_size = max(10, int(self.population_size * 0.95))\n                positions = positions[:self.population_size]\n                velocities = velocities[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n                \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            self.learning_rate = 0.05 + 0.45 * (eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            max_velocity = 0.2 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "EnhancedADSA with adaptive inertia weight decay for improved convergence speed.", "configspace": "", "generation": 63, "fitness": 0.3354774723471764, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.28.", "error": "", "parent_id": "a968c503-f4cc-4c55-9688-24a2f2a590f0", "metadata": {"aucs": [0.9023462905820133, 0.9023462905820133, 0.9023462905820133, 0.8767493388413296, 0.8767493388413296, 0.8767493388413296, 0.8739691423206646, 0.8739691423206646, 0.8739691423206646, 0.7765121265069537, 0.7765121265069537, 0.7765121265069537, 0.6762991185155796, 0.6762991185155796, 0.6762991185155796, 0.8233526825018349, 0.8233526825018349, 0.8233526825018349, 0.15876425334694322, 0.15876425334694322, 0.15876425334694322, 0.12394763669109854, 0.12394763669109854, 0.12394763669109854, 0.15988793847406757, 0.15988793847406757, 0.15988793847406757, 0.13103959543625698, 0.13103959543625698, 0.13103959543625698, 0.09837723296806289, 0.09837723296806289, 0.09837723296806289, 0.1547669582094794, 0.1547669582094794, 0.1547669582094794, 0.9659674281261577, 0.9659674281261577, 0.9659674281261577, 0.9724467528817047, 0.9724467528817047, 0.9724467528817047, 0.963540476697738, 0.963540476697738, 0.963540476697738, 0.7564281605163267, 0.7564281605163267, 0.7564281605163267, 0.7447114938837736, 0.7447114938837736, 0.7447114938837736, 0.6465236486978101, 0.6465236486978101, 0.6465236486978101, 0.3522780959829138, 0.3522780959829138, 0.3522780959829138, 0.1937635244632816, 0.1937635244632816, 0.1937635244632816, 0.23567532105350397, 0.23567532105350397, 0.23567532105350397, 0.19424096496163157, 0.19424096496163157, 0.19424096496163157, 0.2297105586773267, 0.2297105586773267, 0.2297105586773267, 0.2623434786495439, 0.2623434786495439, 0.2623434786495439, 0.22120036835344659, 0.22120036835344659, 0.22120036835344659, 0.22174034292561307, 0.22174034292561307, 0.22174034292561307, 0.21645122562827945, 0.21645122562827945, 0.21645122562827945, 0.024617663716946514, 0.024617663716946514, 0.024617663716946514, 0.043089478284589644, 0.043089478284589644, 0.043089478284589644, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11233070726151617, 0.11233070726151617, 0.11233070726151617, 0.059050736879736165, 0.059050736879736165, 0.059050736879736165, 0.1070300907702334, 0.1070300907702334, 0.1070300907702334, 0.05078181913392632, 0.05078181913392632, 0.05078181913392632, 0.4215095859725969, 0.4215095859725969, 0.4215095859725969, 0.13078589721376843, 0.13078589721376843, 0.13078589721376843, 0.20719065128261638, 0.20719065128261638, 0.20719065128261638, 0.03828856483184406, 0.03828856483184406, 0.03828856483184406, 0.26708418149282875, 0.26708418149282875, 0.26708418149282875, 0.5283650522961372, 0.5283650522961372, 0.5283650522961372, 0.5679956503299439, 0.5679956503299439, 0.5679956503299439, 0.537971564517747, 0.537971564517747, 0.537971564517747, 0.15716136819913462, 0.15716136819913462, 0.15716136819913462, 0.11481234328117262, 0.11481234328117262, 0.11481234328117262, 0.10626838401692362, 0.10626838401692362, 0.10626838401692362, 0.227004828101663, 0.227004828101663, 0.227004828101663, 0.20104598737760448, 0.20104598737760448, 0.20104598737760448, 0.2603690421299232, 0.2603690421299232, 0.2603690421299232, 0.40992066827718, 0.40992066827718, 0.40992066827718, 0.4539634032463963, 0.4539634032463963, 0.4539634032463963, 0.46709133228310706, 0.46709133228310706, 0.46709133228310706, 0.21127774442873803, 0.21127774442873803, 0.21127774442873803, 0.30831158921612956, 0.30831158921612956, 0.30831158921612956, 0.13641580341842818, 0.13641580341842818, 0.13641580341842818, 0.23552944027354328, 0.23552944027354328, 0.23552944027354328, 0.21593542693390455, 0.21593542693390455, 0.21593542693390455, 0.25814027765149294, 0.25814027765149294, 0.25814027765149294, 0.2233770310483043, 0.2233770310483043, 0.2233770310483043, 0.20453972667157805, 0.20453972667157805, 0.20453972667157805, 0.1886847204819323, 0.1886847204819323, 0.1886847204819323, 0.9161473606817703, 0.9161473606817703, 0.9161473606817703, 0.15869883848816768, 0.15869883848816768, 0.15869883848816768, 0.8721857109925466, 0.8721857109925466, 0.8721857109925466, 0.5366866756966993, 0.5366866756966993, 0.5366866756966993, 0.21257157449512765, 0.21257157449512765, 0.21257157449512765, 0.1558354390912946, 0.1558354390912946, 0.1558354390912946, 0.19250942749069422, 0.19250942749069422, 0.19250942749069422, 0.18445610655622435, 0.18445610655622435, 0.18445610655622435, 0.2024315804328718, 0.2024315804328718, 0.2024315804328718, 0.09574936462909356, 0.09574936462909356, 0.09574936462909356, 0.09433347436664152, 0.09433347436664152, 0.09433347436664152, 0.12369753916064963, 0.12369753916064963, 0.12369753916064963]}, "mutation_prompt": null}
{"id": "179075d1-af57-44f1-be47-5857b0306f19", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, budget // 10)\n        self.population_size = self.initial_population_size\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            # Introduce adaptive inertia weight decay\n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight *= 0.985\n                # Dynamic population resizing with memory reset\n                self.population_size = max(10, int(self.population_size * 0.95))\n                positions = positions[:self.population_size]\n                velocities = velocities[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n            \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            self.learning_rate = 0.05 + 0.45 * (eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            max_velocity = 0.2 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Introducing adaptive inertia weight decay and strategic memory reset to enhance convergence speed and exploration-exploitation balance.", "configspace": "", "generation": 64, "fitness": 0.34332865993999007, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.27.", "error": "", "parent_id": "a968c503-f4cc-4c55-9688-24a2f2a590f0", "metadata": {"aucs": [0.8845968499239986, 0.8845968499239986, 0.8845968499239986, 0.8689537775676057, 0.8689537775676057, 0.8689537775676057, 0.8883772224357329, 0.8883772224357329, 0.8883772224357329, 0.7965395644215651, 0.7965395644215651, 0.7965395644215651, 0.7108125828528259, 0.7108125828528259, 0.7108125828528259, 0.807650624873459, 0.807650624873459, 0.807650624873459, 0.12457783636742004, 0.12457783636742004, 0.12457783636742004, 0.11611460731443168, 0.11611460731443168, 0.11611460731443168, 0.5246322842641331, 0.5246322842641331, 0.5246322842641331, 0.14269301396436074, 0.14269301396436074, 0.14269301396436074, 0.14647019887074297, 0.14647019887074297, 0.14647019887074297, 0.15146020071577115, 0.15146020071577115, 0.15146020071577115, 0.9659674281261577, 0.9659674281261577, 0.9659674281261577, 0.9724467528817047, 0.9724467528817047, 0.9724467528817047, 0.963540476697738, 0.963540476697738, 0.963540476697738, 0.730648038661526, 0.730648038661526, 0.730648038661526, 0.4942783383902021, 0.4942783383902021, 0.4942783383902021, 0.6679972610106956, 0.6679972610106956, 0.6679972610106956, 0.35857011394929617, 0.35857011394929617, 0.35857011394929617, 0.19372779594982137, 0.19372779594982137, 0.19372779594982137, 0.3600417170765955, 0.3600417170765955, 0.3600417170765955, 0.21678086980116507, 0.21678086980116507, 0.21678086980116507, 0.23008690403642018, 0.23008690403642018, 0.23008690403642018, 0.33202089475455965, 0.33202089475455965, 0.33202089475455965, 0.21774117265323634, 0.21774117265323634, 0.21774117265323634, 0.22234427602025109, 0.22234427602025109, 0.22234427602025109, 0.21073767755068096, 0.21073767755068096, 0.21073767755068096, 0.05076721662052952, 0.05076721662052952, 0.05076721662052952, 0.03892902830409184, 0.03892902830409184, 0.03892902830409184, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13447700357054693, 0.13447700357054693, 0.13447700357054693, 0.05001306739740485, 0.05001306739740485, 0.05001306739740485, 0.16000093084308098, 0.16000093084308098, 0.16000093084308098, 0.05002147597535478, 0.05002147597535478, 0.05002147597535478, 0.3974380889249657, 0.3974380889249657, 0.3974380889249657, 0.13674228142814848, 0.13674228142814848, 0.13674228142814848, 0.218055739330011, 0.218055739330011, 0.218055739330011, 0.03825911289538275, 0.03825911289538275, 0.03825911289538275, 0.2678079347201042, 0.2678079347201042, 0.2678079347201042, 0.5121872885063712, 0.5121872885063712, 0.5121872885063712, 0.5329472636162241, 0.5329472636162241, 0.5329472636162241, 0.5178889313351153, 0.5178889313351153, 0.5178889313351153, 0.15673247806635315, 0.15673247806635315, 0.15673247806635315, 0.11557260511799594, 0.11557260511799594, 0.11557260511799594, 0.10595147229229673, 0.10595147229229673, 0.10595147229229673, 0.2759000312935683, 0.2759000312935683, 0.2759000312935683, 0.22476446799436545, 0.22476446799436545, 0.22476446799436545, 0.2491358129617285, 0.2491358129617285, 0.2491358129617285, 0.4388128356869553, 0.4388128356869553, 0.4388128356869553, 0.3321448378232288, 0.3321448378232288, 0.3321448378232288, 0.4696171478030535, 0.4696171478030535, 0.4696171478030535, 0.22354346484769516, 0.22354346484769516, 0.22354346484769516, 0.4262932362713091, 0.4262932362713091, 0.4262932362713091, 0.14026725323398637, 0.14026725323398637, 0.14026725323398637, 0.2352150952281824, 0.2352150952281824, 0.2352150952281824, 0.22276989394818836, 0.22276989394818836, 0.22276989394818836, 0.25671164474162456, 0.25671164474162456, 0.25671164474162456, 0.21054470193522146, 0.21054470193522146, 0.21054470193522146, 0.22541228269733793, 0.22541228269733793, 0.22541228269733793, 0.18892051247491004, 0.18892051247491004, 0.18892051247491004, 0.916271250502852, 0.916271250502852, 0.916271250502852, 0.15869496909797376, 0.15869496909797376, 0.15869496909797376, 0.9017046318188694, 0.9017046318188694, 0.9017046318188694, 0.5659201710912329, 0.5659201710912329, 0.5659201710912329, 0.2125650984301466, 0.2125650984301466, 0.2125650984301466, 0.15594690771721975, 0.15594690771721975, 0.15594690771721975, 0.20895845972442062, 0.20895845972442062, 0.20895845972442062, 0.19901228568948104, 0.19901228568948104, 0.19901228568948104, 0.1787039630696161, 0.1787039630696161, 0.1787039630696161, 0.09650472771150476, 0.09650472771150476, 0.09650472771150476, 0.098320209062004, 0.098320209062004, 0.098320209062004, 0.12330722274653438, 0.12330722274653438, 0.12330722274653438]}, "mutation_prompt": null}
{"id": "2b3eaa75-ec11-43d8-8af6-3401e08525f5", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, budget // 10)\n        self.population_size = self.initial_population_size\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        temperature = 1.0  # Initial temperature for simulated annealing\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n\n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.5, self.inertia_weight * 0.99)\n                self.population_size = max(10, int(self.population_size * 0.95))\n                positions = positions[:self.population_size]\n                velocities = velocities[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n\n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            self.learning_rate = 0.05 + 0.45 * (eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n\n            max_velocity = 0.2 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n\n            # Adaptive velocity control using simulated annealing\n            acceptance_prob = np.exp(-np.abs(scores - personal_best_scores) / temperature)\n            adapt_mask = np.random.rand(self.population_size) < acceptance_prob\n            positions[adapt_mask] += velocities[adapt_mask]\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            # Decrease temperature\n            temperature *= 0.99\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Adaptive Velocity Control with Simulated Annealing for EnhancedADSA to boost convergence by dynamically adjusting exploration and exploitation.", "configspace": "", "generation": 65, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (50,) (47,) ').", "error": "ValueError('operands could not be broadcast together with shapes (50,) (47,) ')", "parent_id": "a968c503-f4cc-4c55-9688-24a2f2a590f0", "metadata": {}, "mutation_prompt": null}
{"id": "d9ef0607-1a76-435b-8787-4f4e8e6065ff", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, budget // 10)\n        self.population_size = self.initial_population_size\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                # Modified inertia weight adaptation strategy\n                self.inertia_weight = max(0.4, self.inertia_weight * 0.98)\n                # Dynamic population resizing\n                self.population_size = max(10, int(self.population_size * 0.95))\n                positions = positions[:self.population_size]\n                velocities = velocities[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n                \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            self.learning_rate = 0.05 + 0.45 * (eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            max_velocity = 0.2 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "Modified inertia weight adaptation strategy to enhance convergence speed by balancing exploration and exploitation more effectively.", "configspace": "", "generation": 66, "fitness": 0.3354774723471764, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.28.", "error": "", "parent_id": "a968c503-f4cc-4c55-9688-24a2f2a590f0", "metadata": {"aucs": [0.9023462905820133, 0.9023462905820133, 0.9023462905820133, 0.8767493388413296, 0.8767493388413296, 0.8767493388413296, 0.8739691423206646, 0.8739691423206646, 0.8739691423206646, 0.7765121265069537, 0.7765121265069537, 0.7765121265069537, 0.6762991185155796, 0.6762991185155796, 0.6762991185155796, 0.8233526825018349, 0.8233526825018349, 0.8233526825018349, 0.15876425334694322, 0.15876425334694322, 0.15876425334694322, 0.12394763669109854, 0.12394763669109854, 0.12394763669109854, 0.15988793847406757, 0.15988793847406757, 0.15988793847406757, 0.13103959543625698, 0.13103959543625698, 0.13103959543625698, 0.09837723296806289, 0.09837723296806289, 0.09837723296806289, 0.1547669582094794, 0.1547669582094794, 0.1547669582094794, 0.9659674281261577, 0.9659674281261577, 0.9659674281261577, 0.9724467528817047, 0.9724467528817047, 0.9724467528817047, 0.963540476697738, 0.963540476697738, 0.963540476697738, 0.7564281605163267, 0.7564281605163267, 0.7564281605163267, 0.7447114938837736, 0.7447114938837736, 0.7447114938837736, 0.6465236486978101, 0.6465236486978101, 0.6465236486978101, 0.3522780959829138, 0.3522780959829138, 0.3522780959829138, 0.1937635244632816, 0.1937635244632816, 0.1937635244632816, 0.23567532105350397, 0.23567532105350397, 0.23567532105350397, 0.19424096496163157, 0.19424096496163157, 0.19424096496163157, 0.2297105586773267, 0.2297105586773267, 0.2297105586773267, 0.2623434786495439, 0.2623434786495439, 0.2623434786495439, 0.22120036835344659, 0.22120036835344659, 0.22120036835344659, 0.22174034292561307, 0.22174034292561307, 0.22174034292561307, 0.21645122562827945, 0.21645122562827945, 0.21645122562827945, 0.024617663716946514, 0.024617663716946514, 0.024617663716946514, 0.043089478284589644, 0.043089478284589644, 0.043089478284589644, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11233070726151617, 0.11233070726151617, 0.11233070726151617, 0.059050736879736165, 0.059050736879736165, 0.059050736879736165, 0.1070300907702334, 0.1070300907702334, 0.1070300907702334, 0.05078181913392632, 0.05078181913392632, 0.05078181913392632, 0.4215095859725969, 0.4215095859725969, 0.4215095859725969, 0.13078589721376843, 0.13078589721376843, 0.13078589721376843, 0.20719065128261638, 0.20719065128261638, 0.20719065128261638, 0.03828856483184406, 0.03828856483184406, 0.03828856483184406, 0.26708418149282875, 0.26708418149282875, 0.26708418149282875, 0.5283650522961372, 0.5283650522961372, 0.5283650522961372, 0.5679956503299439, 0.5679956503299439, 0.5679956503299439, 0.537971564517747, 0.537971564517747, 0.537971564517747, 0.15716136819913462, 0.15716136819913462, 0.15716136819913462, 0.11481234328117262, 0.11481234328117262, 0.11481234328117262, 0.10626838401692362, 0.10626838401692362, 0.10626838401692362, 0.227004828101663, 0.227004828101663, 0.227004828101663, 0.20104598737760448, 0.20104598737760448, 0.20104598737760448, 0.2603690421299232, 0.2603690421299232, 0.2603690421299232, 0.40992066827718, 0.40992066827718, 0.40992066827718, 0.4539634032463963, 0.4539634032463963, 0.4539634032463963, 0.46709133228310706, 0.46709133228310706, 0.46709133228310706, 0.21127774442873803, 0.21127774442873803, 0.21127774442873803, 0.30831158921612956, 0.30831158921612956, 0.30831158921612956, 0.13641580341842818, 0.13641580341842818, 0.13641580341842818, 0.23552944027354328, 0.23552944027354328, 0.23552944027354328, 0.21593542693390455, 0.21593542693390455, 0.21593542693390455, 0.25814027765149294, 0.25814027765149294, 0.25814027765149294, 0.2233770310483043, 0.2233770310483043, 0.2233770310483043, 0.20453972667157805, 0.20453972667157805, 0.20453972667157805, 0.1886847204819323, 0.1886847204819323, 0.1886847204819323, 0.9161473606817703, 0.9161473606817703, 0.9161473606817703, 0.15869883848816768, 0.15869883848816768, 0.15869883848816768, 0.8721857109925466, 0.8721857109925466, 0.8721857109925466, 0.5366866756966993, 0.5366866756966993, 0.5366866756966993, 0.21257157449512765, 0.21257157449512765, 0.21257157449512765, 0.1558354390912946, 0.1558354390912946, 0.1558354390912946, 0.19250942749069422, 0.19250942749069422, 0.19250942749069422, 0.18445610655622435, 0.18445610655622435, 0.18445610655622435, 0.2024315804328718, 0.2024315804328718, 0.2024315804328718, 0.09574936462909356, 0.09574936462909356, 0.09574936462909356, 0.09433347436664152, 0.09433347436664152, 0.09433347436664152, 0.12369753916064963, 0.12369753916064963, 0.12369753916064963]}, "mutation_prompt": null}
{"id": "4f4d4033-9815-4c9f-aa87-676a06eeee38", "solution": "import numpy as np\n\nclass EnhancedADSA_2_9:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, budget // 10)\n        self.population_size = self.initial_population_size\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n        self.velocity_scaling_factor = 0.9  # New adaptive scaling factor\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.5, self.inertia_weight * 0.99)\n                self.population_size = max(10, int(self.population_size * 0.95))\n                positions = positions[:self.population_size]\n                velocities = velocities[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n                \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            self.learning_rate = 0.05 + 0.45 * (eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            max_velocity = 0.2 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity * self.velocity_scaling_factor, max_velocity * self.velocity_scaling_factor)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            # Selective resampling strategy\n            if eval_count > self.budget * 0.5 and global_best_score > 1e-5:\n                resample_mask = scores > np.median(personal_best_scores)\n                num_resample = np.sum(resample_mask)\n                if num_resample > 0:\n                    positions[resample_mask] = np.random.uniform(self.lower_bound, self.upper_bound, (num_resample, self.dim))\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA_2_9", "description": "EnhancedADSA-2.9 with adaptive velocity scaling and selective resampling for improved convergence.", "configspace": "", "generation": 67, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('boolean index did not match indexed array along dimension 0; dimension is 14 but corresponding boolean dimension is 15').", "error": "IndexError('boolean index did not match indexed array along dimension 0; dimension is 14 but corresponding boolean dimension is 15')", "parent_id": "a968c503-f4cc-4c55-9688-24a2f2a590f0", "metadata": {}, "mutation_prompt": null}
{"id": "75a51baf-2403-4797-821b-7c1fe19b6b1e", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, budget // 10)\n        self.population_size = self.initial_population_size\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.5, self.inertia_weight * 0.99)\n                self.population_size = max(10, int(self.population_size * 0.95))\n                positions = positions[:self.population_size]\n                velocities = velocities[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n                \n            self.cognitive_coef = 1.494 + 0.5 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.5 * (1 - eval_count / self.budget)\n            \n            diversity = np.mean(np.std(positions, axis=0))\n            self.learning_rate = min(0.1, self.learning_rate + 0.01 * diversity)  # Adaptive learning rate\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            max_velocity = 0.2 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "EnhancedADSA with adaptive learning rate adjustment based on population diversity for improved convergence control.", "configspace": "", "generation": 68, "fitness": 0.31670314149463213, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.28.", "error": "", "parent_id": "a968c503-f4cc-4c55-9688-24a2f2a590f0", "metadata": {"aucs": [0.8679100424405592, 0.8679100424405592, 0.8679100424405592, 0.8839175863324871, 0.8839175863324871, 0.8839175863324871, 0.885379765646766, 0.885379765646766, 0.885379765646766, 0.7655135453704333, 0.7655135453704333, 0.7655135453704333, 0.7774234978993404, 0.7774234978993404, 0.7774234978993404, 0.7851358735454694, 0.7851358735454694, 0.7851358735454694, 0.11471351907420735, 0.11471351907420735, 0.11471351907420735, 0.15673691434317338, 0.15673691434317338, 0.15673691434317338, 0.12423236107492064, 0.12423236107492064, 0.12423236107492064, 0.11436767467247189, 0.11436767467247189, 0.11436767467247189, 0.10646252363960118, 0.10646252363960118, 0.10646252363960118, 0.15346326488000084, 0.15346326488000084, 0.15346326488000084, 0.9661101416738647, 0.9661101416738647, 0.9661101416738647, 0.9725007052893628, 0.9725007052893628, 0.9725007052893628, 0.9634965354306667, 0.9634965354306667, 0.9634965354306667, 0.5881379292897332, 0.5881379292897332, 0.5881379292897332, 0.1531469850588486, 0.1531469850588486, 0.1531469850588486, 0.7192892287496674, 0.7192892287496674, 0.7192892287496674, 0.21411441705020529, 0.21411441705020529, 0.21411441705020529, 0.16106100876416607, 0.16106100876416607, 0.16106100876416607, 0.857295742479002, 0.857295742479002, 0.857295742479002, 0.21325608510352612, 0.21325608510352612, 0.21325608510352612, 0.24043034480923797, 0.24043034480923797, 0.24043034480923797, 0.2087310901846029, 0.2087310901846029, 0.2087310901846029, 0.22356060836896285, 0.22356060836896285, 0.22356060836896285, 0.21263068487169678, 0.21263068487169678, 0.21263068487169678, 0.23686653653109824, 0.23686653653109824, 0.23686653653109824, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01584522362104568, 0.01584522362104568, 0.01584522362104568, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12282453317094133, 0.12282453317094133, 0.12282453317094133, 0.0365952007385667, 0.0365952007385667, 0.0365952007385667, 0.11449449635289133, 0.11449449635289133, 0.11449449635289133, 0.05798535629009416, 0.05798535629009416, 0.05798535629009416, 0.1995382129353982, 0.1995382129353982, 0.1995382129353982, 0.11604427498425318, 0.11604427498425318, 0.11604427498425318, 0.21400795501599745, 0.21400795501599745, 0.21400795501599745, 0.03834657103219108, 0.03834657103219108, 0.03834657103219108, 0.15230072756214263, 0.15230072756214263, 0.15230072756214263, 0.5176283931455263, 0.5176283931455263, 0.5176283931455263, 0.5067989752906903, 0.5067989752906903, 0.5067989752906903, 0.5215813971904143, 0.5215813971904143, 0.5215813971904143, 0.10080553993786612, 0.10080553993786612, 0.10080553993786612, 0.11434358215756657, 0.11434358215756657, 0.11434358215756657, 0.12293782785490581, 0.12293782785490581, 0.12293782785490581, 0.3342018367797842, 0.3342018367797842, 0.3342018367797842, 0.32244065020537405, 0.32244065020537405, 0.32244065020537405, 0.19112228612458915, 0.19112228612458915, 0.19112228612458915, 0.2713445282028607, 0.2713445282028607, 0.2713445282028607, 0.3376071730007063, 0.3376071730007063, 0.3376071730007063, 0.37511491275976483, 0.37511491275976483, 0.37511491275976483, 0.16482458943942746, 0.16482458943942746, 0.16482458943942746, 0.22361451663639886, 0.22361451663639886, 0.22361451663639886, 0.14846739722570423, 0.14846739722570423, 0.14846739722570423, 0.21839294382736485, 0.21839294382736485, 0.21839294382736485, 0.2584432417667095, 0.2584432417667095, 0.2584432417667095, 0.1910185327939634, 0.1910185327939634, 0.1910185327939634, 0.22775380237760634, 0.22775380237760634, 0.22775380237760634, 0.2511190106888216, 0.2511190106888216, 0.2511190106888216, 0.19148466967216504, 0.19148466967216504, 0.19148466967216504, 0.9179342141089171, 0.9179342141089171, 0.9179342141089171, 0.15849599188222996, 0.15849599188222996, 0.15849599188222996, 0.7219572565466978, 0.7219572565466978, 0.7219572565466978, 0.41818312345742403, 0.41818312345742403, 0.41818312345742403, 0.2124249988488225, 0.2124249988488225, 0.2124249988488225, 0.1559621717654367, 0.1559621717654367, 0.1559621717654367, 0.20033927691506026, 0.20033927691506026, 0.20033927691506026, 0.18786114552145605, 0.18786114552145605, 0.18786114552145605, 0.2254024592653553, 0.2254024592653553, 0.2254024592653553, 0.09732694490773464, 0.09732694490773464, 0.09732694490773464, 0.0776372714265251, 0.0776372714265251, 0.0776372714265251, 0.10398836161204994, 0.10398836161204994, 0.10398836161204994]}, "mutation_prompt": null}
{"id": "a60610fb-6463-4bfb-b03e-df46b3891527", "solution": "import numpy as np\n\nclass EnhancedADSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = min(50, budget // 10)\n        self.population_size = self.initial_population_size\n        self.inertia_weight = 0.729\n        self.cognitive_coef = 1.494\n        self.social_coef = 1.494\n        self.learning_rate = 0.05\n        self.momentum = 0.95\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        \n        eval_count = 0\n        last_improvement = 0\n        \n        while eval_count < self.budget:\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.population_size\n            \n            better_mask = scores < personal_best_scores\n            personal_best_scores[better_mask] = scores[better_mask]\n            personal_best_positions[better_mask] = positions[better_mask]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_score_idx]\n                global_best_position = personal_best_positions[min_score_idx]\n                last_improvement = eval_count\n            \n            if eval_count - last_improvement > self.population_size:\n                self.inertia_weight = max(0.5, self.inertia_weight * 0.99)\n                # Dynamic population resizing\n                self.population_size = max(10, int(self.population_size * 0.95))\n                positions = positions[:self.population_size]\n                velocities = velocities[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n                \n            # Slightly adjust coefficients for better convergence\n            self.cognitive_coef = 1.494 + 0.45 * (1 - eval_count / self.budget)\n            self.social_coef = 1.494 - 0.45 * (1 - eval_count / self.budget)\n            self.learning_rate = 0.05 + 0.45 * (eval_count / self.budget)\n            \n            r1, r2 = np.random.uniform(size=(2, self.population_size, self.dim))\n            cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions - positions)\n            social_velocity = self.social_coef * r2 * (global_best_position - positions)\n            velocities = (self.inertia_weight * velocities + cognitive_velocity + social_velocity)\n            velocities = self.momentum * velocities + self.learning_rate * (cognitive_velocity + social_velocity)\n            \n            max_velocity = 0.2 * (self.upper_bound - self.lower_bound)\n            velocities = np.clip(velocities, -max_velocity, max_velocity)\n            \n            positions += velocities\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_score", "name": "EnhancedADSA", "description": "EnhancedADSA with adaptive cognitive and social coefficients fine-tuning for improved convergence speed.", "configspace": "", "generation": 69, "fitness": 0.3381768900078969, "feedback": "The algorithm EnhancedADSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.28.", "error": "", "parent_id": "a968c503-f4cc-4c55-9688-24a2f2a590f0", "metadata": {"aucs": [0.8802550918783614, 0.8802550918783614, 0.8802550918783614, 0.8757602937433189, 0.8757602937433189, 0.8757602937433189, 0.8523479311872487, 0.8523479311872487, 0.8523479311872487, 0.7422466809669157, 0.7422466809669157, 0.7422466809669157, 0.7547171650059233, 0.7547171650059233, 0.7547171650059233, 0.815769514245631, 0.815769514245631, 0.815769514245631, 0.11758731813971535, 0.11758731813971535, 0.11758731813971535, 0.12255348454229587, 0.12255348454229587, 0.12255348454229587, 0.14406459894736945, 0.14406459894736945, 0.14406459894736945, 0.13079585852884779, 0.13079585852884779, 0.13079585852884779, 0.09162111924000838, 0.09162111924000838, 0.09162111924000838, 0.15724533950013264, 0.15724533950013264, 0.15724533950013264, 0.9661137323346831, 0.9661137323346831, 0.9661137323346831, 0.9725097249143704, 0.9725097249143704, 0.9725097249143704, 0.9634796973494144, 0.9634796973494144, 0.9634796973494144, 0.682969557630993, 0.682969557630993, 0.682969557630993, 0.3882968564479651, 0.3882968564479651, 0.3882968564479651, 0.7784044925628204, 0.7784044925628204, 0.7784044925628204, 0.22692094053831335, 0.22692094053831335, 0.22692094053831335, 0.19320476990595303, 0.19320476990595303, 0.19320476990595303, 0.2424230504122583, 0.2424230504122583, 0.2424230504122583, 0.20937405275668852, 0.20937405275668852, 0.20937405275668852, 0.20066412203880268, 0.20066412203880268, 0.20066412203880268, 0.20390917925095553, 0.20390917925095553, 0.20390917925095553, 0.12855195469599456, 0.12855195469599456, 0.12855195469599456, 0.22278948644008512, 0.22278948644008512, 0.22278948644008512, 0.2461302392272452, 0.2461302392272452, 0.2461302392272452, 0.044991810347301375, 0.044991810347301375, 0.044991810347301375, 0.041507668865666925, 0.041507668865666925, 0.041507668865666925, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10492426406245725, 0.10492426406245725, 0.10492426406245725, 0.060040662889863206, 0.060040662889863206, 0.060040662889863206, 0.09417817623102942, 0.09417817623102942, 0.09417817623102942, 0.0497486871069468, 0.0497486871069468, 0.0497486871069468, 0.372234911594739, 0.372234911594739, 0.372234911594739, 0.1615843557402562, 0.1615843557402562, 0.1615843557402562, 0.20546382809302732, 0.20546382809302732, 0.20546382809302732, 0.038551127657116324, 0.038551127657116324, 0.038551127657116324, 0.3642008376251732, 0.3642008376251732, 0.3642008376251732, 0.5378738480196169, 0.5378738480196169, 0.5378738480196169, 0.5336242602528134, 0.5336242602528134, 0.5336242602528134, 0.5792578132301837, 0.5792578132301837, 0.5792578132301837, 0.14414907539371147, 0.14414907539371147, 0.14414907539371147, 0.1223374061185395, 0.1223374061185395, 0.1223374061185395, 0.14010335865198653, 0.14010335865198653, 0.14010335865198653, 0.22886461360991517, 0.22886461360991517, 0.22886461360991517, 0.28591589692033226, 0.28591589692033226, 0.28591589692033226, 0.25194626322075375, 0.25194626322075375, 0.25194626322075375, 0.35233368979563706, 0.35233368979563706, 0.35233368979563706, 0.4183018633150305, 0.4183018633150305, 0.4183018633150305, 0.3836152219710428, 0.3836152219710428, 0.3836152219710428, 0.194901029265374, 0.194901029265374, 0.194901029265374, 0.41606699576750006, 0.41606699576750006, 0.41606699576750006, 0.19705145425746384, 0.19705145425746384, 0.19705145425746384, 0.30672174066549074, 0.30672174066549074, 0.30672174066549074, 0.2342297883451564, 0.2342297883451564, 0.2342297883451564, 0.2263784585523716, 0.2263784585523716, 0.2263784585523716, 0.7720919284192225, 0.7720919284192225, 0.7720919284192225, 0.25149343665627233, 0.25149343665627233, 0.25149343665627233, 0.19241248847291736, 0.19241248847291736, 0.19241248847291736, 0.9231724586417016, 0.9231724586417016, 0.9231724586417016, 0.15881365366445932, 0.15881365366445932, 0.15881365366445932, 0.8873380838481868, 0.8873380838481868, 0.8873380838481868, 0.46009459276394804, 0.46009459276394804, 0.46009459276394804, 0.21233059101528606, 0.21233059101528606, 0.21233059101528606, 0.15627551510574833, 0.15627551510574833, 0.15627551510574833, 0.20344546778756123, 0.20344546778756123, 0.20344546778756123, 0.1946597388517084, 0.1946597388517084, 0.1946597388517084, 0.21035601645331203, 0.21035601645331203, 0.21035601645331203, 0.09822789978804991, 0.09822789978804991, 0.09822789978804991, 0.09072727670825576, 0.09072727670825576, 0.09072727670825576, 0.13539157239313826, 0.13539157239313826, 0.13539157239313826]}, "mutation_prompt": null}
{"id": "404fb07c-4ac8-4f1c-b06f-540790445d1d", "solution": "import numpy as np\n\nclass ADEL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 8)\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            if eval_count % (self.population_size * 2) == 0:\n                self.F = 0.4 + 0.3 * (eval_count / self.budget)\n                self.CR = 0.9 - 0.4 * (eval_count / self.budget)\n\n            # Local search on the current best\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "ADEL", "description": "Introducing Adaptive Differential Evolution with Local Search (ADEL) to dynamically adjust mutation and crossover rates for faster convergence and robust optimization.", "configspace": "", "generation": 70, "fitness": 0.3738047168005579, "feedback": "The algorithm ADEL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.25.", "error": "", "parent_id": "a968c503-f4cc-4c55-9688-24a2f2a590f0", "metadata": {"aucs": [0.7932693962045956, 0.7932693962045956, 0.7932693962045956, 0.7984891771301661, 0.7984891771301661, 0.7984891771301661, 0.8101880731782535, 0.8101880731782535, 0.8101880731782535, 0.6922867604710192, 0.6922867604710192, 0.6922867604710192, 0.6865273040032829, 0.6865273040032829, 0.6865273040032829, 0.6861743255306363, 0.6861743255306363, 0.6861743255306363, 0.14398450946239116, 0.14398450946239116, 0.14398450946239116, 0.12648531345676495, 0.12648531345676495, 0.12648531345676495, 0.10807261692193393, 0.10807261692193393, 0.10807261692193393, 0.108706535635259, 0.108706535635259, 0.108706535635259, 0.10354306047602169, 0.10354306047602169, 0.10354306047602169, 0.11079790388994826, 0.11079790388994826, 0.11079790388994826, 0.9028072412060938, 0.9028072412060938, 0.9028072412060938, 0.8558604714489566, 0.8558604714489566, 0.8558604714489566, 0.8526628041464611, 0.8526628041464611, 0.8526628041464611, 0.4802975090822369, 0.4802975090822369, 0.4802975090822369, 0.2175980218475887, 0.2175980218475887, 0.2175980218475887, 0.37513313171305895, 0.37513313171305895, 0.37513313171305895, 0.7556531047509116, 0.7556531047509116, 0.7556531047509116, 0.8113570958262977, 0.8113570958262977, 0.8113570958262977, 0.7599003176277241, 0.7599003176277241, 0.7599003176277241, 0.1643556777646551, 0.1643556777646551, 0.1643556777646551, 0.1452243956250453, 0.1452243956250453, 0.1452243956250453, 0.21243506149265745, 0.21243506149265745, 0.21243506149265745, 0.2331330198731335, 0.2331330198731335, 0.2331330198731335, 0.20155535208605357, 0.20155535208605357, 0.20155535208605357, 0.1723409423569856, 0.1723409423569856, 0.1723409423569856, 0.3457669001782898, 0.3457669001782898, 0.3457669001782898, 0.3849828451259335, 0.3849828451259335, 0.3849828451259335, 0.3497494362878695, 0.3497494362878695, 0.3497494362878695, 0.485342453638847, 0.485342453638847, 0.485342453638847, 0.48979429199513824, 0.48979429199513824, 0.48979429199513824, 0.5906510960330301, 0.5906510960330301, 0.5906510960330301, 0.16779813540690192, 0.16779813540690192, 0.16779813540690192, 0.30753604175458027, 0.30753604175458027, 0.30753604175458027, 0.13622681120480462, 0.13622681120480462, 0.13622681120480462, 0.308798392767891, 0.308798392767891, 0.308798392767891, 0.3362046220756324, 0.3362046220756324, 0.3362046220756324, 0.29768457991003217, 0.29768457991003217, 0.29768457991003217, 0.7092316777098381, 0.7092316777098381, 0.7092316777098381, 0.7195037935100641, 0.7195037935100641, 0.7195037935100641, 0.7115643656553257, 0.7115643656553257, 0.7115643656553257, 0.11595332984253004, 0.11595332984253004, 0.11595332984253004, 0.10559813656989536, 0.10559813656989536, 0.10559813656989536, 0.1081121874262555, 0.1081121874262555, 0.1081121874262555, 0.26089395192965037, 0.26089395192965037, 0.26089395192965037, 0.1634496309378748, 0.1634496309378748, 0.1634496309378748, 0.13587442678360806, 0.13587442678360806, 0.13587442678360806, 0.3843320970944628, 0.3843320970944628, 0.3843320970944628, 0.45522724570954565, 0.45522724570954565, 0.45522724570954565, 0.4908231335282245, 0.4908231335282245, 0.4908231335282245, 0.3556046070755753, 0.3556046070755753, 0.3556046070755753, 0.3341589671862256, 0.3341589671862256, 0.3341589671862256, 0.37800969813767404, 0.37800969813767404, 0.37800969813767404, 0.1935337177043175, 0.1935337177043175, 0.1935337177043175, 0.2009820436591383, 0.2009820436591383, 0.2009820436591383, 0.185121644065546, 0.185121644065546, 0.185121644065546, 0.20062739670372753, 0.20062739670372753, 0.20062739670372753, 0.24661609953775554, 0.24661609953775554, 0.24661609953775554, 0.2754250428952346, 0.2754250428952346, 0.2754250428952346, 0.8195368334750956, 0.8195368334750956, 0.8195368334750956, 0.19002126336566405, 0.19002126336566405, 0.19002126336566405, 0.6576296421798415, 0.6576296421798415, 0.6576296421798415, 0.7902183065962007, 0.7902183065962007, 0.7902183065962007, 0.19869365046178267, 0.19869365046178267, 0.19869365046178267, 0.20709622575728492, 0.20709622575728492, 0.20709622575728492, 0.19129885604409946, 0.19129885604409946, 0.19129885604409946, 0.1723046057062254, 0.1723046057062254, 0.1723046057062254, 0.19321443232153457, 0.19321443232153457, 0.19321443232153457, 0.08002682026657348, 0.08002682026657348, 0.08002682026657348, 0.08182497033196179, 0.08182497033196179, 0.08182497033196179, 0.09205607988435116, 0.09205607988435116, 0.09205607988435116]}, "mutation_prompt": null}
{"id": "7d295da7-44bf-43e9-b2ac-c0f02e8cd548", "solution": "import numpy as np\n\nclass ADEL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 8)\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.learning_rate = 0.1\n        self.adaptive_factor = 0.05  # New adaptive learning rate factor\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < (self.CR - self.adaptive_factor)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            if eval_count % (self.population_size * 2) == 0:\n                self.F = 0.4 + 0.3 * (eval_count / self.budget)\n                self.CR = 0.9 - 0.4 * (eval_count / self.budget) + self.adaptive_factor\n\n            # Local search on the current best\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate - self.adaptive_factor, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "ADEL", "description": "Introducing small-scale adaptive learning rates and crossover adjustments in ADEL for enhanced convergence efficiency.", "configspace": "", "generation": 71, "fitness": 0.371622217930835, "feedback": "The algorithm ADEL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.25.", "error": "", "parent_id": "404fb07c-4ac8-4f1c-b06f-540790445d1d", "metadata": {"aucs": [0.8236860893069289, 0.8236860893069289, 0.8236860893069289, 0.7972339539706671, 0.7972339539706671, 0.7972339539706671, 0.8210599155131725, 0.8210599155131725, 0.8210599155131725, 0.6615405385530655, 0.6615405385530655, 0.6615405385530655, 0.671044384242637, 0.671044384242637, 0.671044384242637, 0.6677608599243641, 0.6677608599243641, 0.6677608599243641, 0.12131282278593203, 0.12131282278593203, 0.12131282278593203, 0.13583385652128366, 0.13583385652128366, 0.13583385652128366, 0.12893595959002813, 0.12893595959002813, 0.12893595959002813, 0.12320702723865395, 0.12320702723865395, 0.12320702723865395, 0.13253579076040878, 0.13253579076040878, 0.13253579076040878, 0.11851591406050832, 0.11851591406050832, 0.11851591406050832, 0.9304898249365028, 0.9304898249365028, 0.9304898249365028, 0.836777253720808, 0.836777253720808, 0.836777253720808, 0.7707128891858699, 0.7707128891858699, 0.7707128891858699, 0.4034112861506155, 0.4034112861506155, 0.4034112861506155, 0.3846732571514946, 0.3846732571514946, 0.3846732571514946, 0.46544565246228553, 0.46544565246228553, 0.46544565246228553, 0.772377891423947, 0.772377891423947, 0.772377891423947, 0.8129567806668169, 0.8129567806668169, 0.8129567806668169, 0.8215538657408952, 0.8215538657408952, 0.8215538657408952, 0.2132498024670938, 0.2132498024670938, 0.2132498024670938, 0.20520937729314703, 0.20520937729314703, 0.20520937729314703, 0.18871907547915212, 0.18871907547915212, 0.18871907547915212, 0.2590989072552884, 0.2590989072552884, 0.2590989072552884, 0.18964934222526242, 0.18964934222526242, 0.18964934222526242, 0.16073416647916294, 0.16073416647916294, 0.16073416647916294, 0.3418214656364512, 0.3418214656364512, 0.3418214656364512, 0.3767189438661567, 0.3767189438661567, 0.3767189438661567, 0.4045371333304253, 0.4045371333304253, 0.4045371333304253, 0.5390027619136168, 0.5390027619136168, 0.5390027619136168, 0.5448245660027966, 0.5448245660027966, 0.5448245660027966, 0.5305741353419459, 0.5305741353419459, 0.5305741353419459, 0.14121916663775824, 0.14121916663775824, 0.14121916663775824, 0.2779370770416201, 0.2779370770416201, 0.2779370770416201, 0.24625199294523648, 0.24625199294523648, 0.24625199294523648, 0.3053558185151283, 0.3053558185151283, 0.3053558185151283, 0.3237703858479054, 0.3237703858479054, 0.3237703858479054, 0.29368078484905535, 0.29368078484905535, 0.29368078484905535, 0.7374213261127512, 0.7374213261127512, 0.7374213261127512, 0.7252653078797612, 0.7252653078797612, 0.7252653078797612, 0.7028834944889321, 0.7028834944889321, 0.7028834944889321, 0.12246633062596535, 0.12246633062596535, 0.12246633062596535, 0.1100012889912072, 0.1100012889912072, 0.1100012889912072, 0.13348470448409444, 0.13348470448409444, 0.13348470448409444, 0.2272378079684092, 0.2272378079684092, 0.2272378079684092, 0.17355467891902188, 0.17355467891902188, 0.17355467891902188, 0.1597304073660505, 0.1597304073660505, 0.1597304073660505, 0.4285196420272356, 0.4285196420272356, 0.4285196420272356, 0.43931748668192283, 0.43931748668192283, 0.43931748668192283, 0.46122599183633883, 0.46122599183633883, 0.46122599183633883, 0.32581325305677455, 0.32581325305677455, 0.32581325305677455, 0.3268577441924523, 0.3268577441924523, 0.3268577441924523, 0.381833851003904, 0.381833851003904, 0.381833851003904, 0.20847068064970364, 0.20847068064970364, 0.20847068064970364, 0.20284220929085373, 0.20284220929085373, 0.20284220929085373, 0.2099217485821343, 0.2099217485821343, 0.2099217485821343, 0.233921826338219, 0.233921826338219, 0.233921826338219, 0.2113423976790314, 0.2113423976790314, 0.2113423976790314, 0.19690791818590325, 0.19690791818590325, 0.19690791818590325, 0.8658617458410147, 0.8658617458410147, 0.8658617458410147, 0.1881112242337466, 0.1881112242337466, 0.1881112242337466, 0.6000625572966385, 0.6000625572966385, 0.6000625572966385, 0.2559332470961846, 0.2559332470961846, 0.2559332470961846, 0.19955772145116457, 0.19955772145116457, 0.19955772145116457, 0.20467659041819042, 0.20467659041819042, 0.20467659041819042, 0.17894734352877206, 0.17894734352877206, 0.17894734352877206, 0.18494557976513892, 0.18494557976513892, 0.18494557976513892, 0.18500210149747787, 0.18500210149747787, 0.18500210149747787, 0.08163327025694123, 0.08163327025694123, 0.08163327025694123, 0.0744242998144764, 0.0744242998144764, 0.0744242998144764, 0.07520319642562046, 0.07520319642562046, 0.07520319642562046]}, "mutation_prompt": null}
{"id": "770465dc-0d6d-4374-b0dd-b89478c7553e", "solution": "import numpy as np\n\nclass ADEL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 8)\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            population_std = np.std(population, axis=0)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                F_dynamic = self.F + 0.1 * (self.budget - eval_count) / self.budget \n                mutant = np.clip(x0 + F_dynamic * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            if eval_count % (self.population_size * 2) == 0:\n                self.F = 0.4 + 0.3 * (eval_count / self.budget)\n                self.CR = 0.9 - 0.4 * (eval_count / self.budget)\n\n            # Local search on the current best\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "ADEL", "description": "Introducing Adaptive Differential Evolution with Enhanced Mutation Strategy (ADEL-EMS) by incorporating a dynamic mutation factor based on population diversity to achieve faster convergence.", "configspace": "", "generation": 72, "fitness": 0.35121370392626433, "feedback": "The algorithm ADEL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.24.", "error": "", "parent_id": "404fb07c-4ac8-4f1c-b06f-540790445d1d", "metadata": {"aucs": [0.7768873767290501, 0.7768873767290501, 0.7768873767290501, 0.7706691239614403, 0.7706691239614403, 0.7706691239614403, 0.7787133781341881, 0.7787133781341881, 0.7787133781341881, 0.6059429113976011, 0.6059429113976011, 0.6059429113976011, 0.626988986873707, 0.626988986873707, 0.626988986873707, 0.6038337973738028, 0.6038337973738028, 0.6038337973738028, 0.12361940504416347, 0.12361940504416347, 0.12361940504416347, 0.10694326991970216, 0.10694326991970216, 0.10694326991970216, 0.1134596406190731, 0.1134596406190731, 0.1134596406190731, 0.11903991526572577, 0.11903991526572577, 0.11903991526572577, 0.10195085590971154, 0.10195085590971154, 0.10195085590971154, 0.09852998808016822, 0.09852998808016822, 0.09852998808016822, 0.9041499647474905, 0.9041499647474905, 0.9041499647474905, 0.8448717918295721, 0.8448717918295721, 0.8448717918295721, 0.7985780502259581, 0.7985780502259581, 0.7985780502259581, 0.4346158953465814, 0.4346158953465814, 0.4346158953465814, 0.43971412003633503, 0.43971412003633503, 0.43971412003633503, 0.42115543234212716, 0.42115543234212716, 0.42115543234212716, 0.752250243934917, 0.752250243934917, 0.752250243934917, 0.7624833827711269, 0.7624833827711269, 0.7624833827711269, 0.7485830338054257, 0.7485830338054257, 0.7485830338054257, 0.21154055518372494, 0.21154055518372494, 0.21154055518372494, 0.17746364387320135, 0.17746364387320135, 0.17746364387320135, 0.2147031998096407, 0.2147031998096407, 0.2147031998096407, 0.12330853567984956, 0.12330853567984956, 0.12330853567984956, 0.16091217639384936, 0.16091217639384936, 0.16091217639384936, 0.21049694286251464, 0.21049694286251464, 0.21049694286251464, 0.2880103788006926, 0.2880103788006926, 0.2880103788006926, 0.34483627896549185, 0.34483627896549185, 0.34483627896549185, 0.3275942930868707, 0.3275942930868707, 0.3275942930868707, 0.4988107368441246, 0.4988107368441246, 0.4988107368441246, 0.45953801687183937, 0.45953801687183937, 0.45953801687183937, 0.4864793405745461, 0.4864793405745461, 0.4864793405745461, 0.10610200260336589, 0.10610200260336589, 0.10610200260336589, 0.21757736224186874, 0.21757736224186874, 0.21757736224186874, 0.16179933763693966, 0.16179933763693966, 0.16179933763693966, 0.25775273794401043, 0.25775273794401043, 0.25775273794401043, 0.29115874568346456, 0.29115874568346456, 0.29115874568346456, 0.2643682011209263, 0.2643682011209263, 0.2643682011209263, 0.6326726132029677, 0.6326726132029677, 0.6326726132029677, 0.6478180233202643, 0.6478180233202643, 0.6478180233202643, 0.6595127917206756, 0.6595127917206756, 0.6595127917206756, 0.11896943980545971, 0.11896943980545971, 0.11896943980545971, 0.10738569640359874, 0.10738569640359874, 0.10738569640359874, 0.08632783778295039, 0.08632783778295039, 0.08632783778295039, 0.16877585467839906, 0.16877585467839906, 0.16877585467839906, 0.14814288005501808, 0.14814288005501808, 0.14814288005501808, 0.1437821107869569, 0.1437821107869569, 0.1437821107869569, 0.4074925207503194, 0.4074925207503194, 0.4074925207503194, 0.35478150155172217, 0.35478150155172217, 0.35478150155172217, 0.42983223560285877, 0.42983223560285877, 0.42983223560285877, 0.27966700413584944, 0.27966700413584944, 0.27966700413584944, 0.28186897485122875, 0.28186897485122875, 0.28186897485122875, 0.3083850702266695, 0.3083850702266695, 0.3083850702266695, 0.1914019141345511, 0.1914019141345511, 0.1914019141345511, 0.21862948080846778, 0.21862948080846778, 0.21862948080846778, 0.2094510077588545, 0.2094510077588545, 0.2094510077588545, 0.19535649811851408, 0.19535649811851408, 0.19535649811851408, 0.21514364341395853, 0.21514364341395853, 0.21514364341395853, 0.18314308821893321, 0.18314308821893321, 0.18314308821893321, 0.7972619046077466, 0.7972619046077466, 0.7972619046077466, 0.6033453867606015, 0.6033453867606015, 0.6033453867606015, 0.4637982421782645, 0.4637982421782645, 0.4637982421782645, 0.20183478296249546, 0.20183478296249546, 0.20183478296249546, 0.1924890605761682, 0.1924890605761682, 0.1924890605761682, 0.5085732999502803, 0.5085732999502803, 0.5085732999502803, 0.17931906699876632, 0.17931906699876632, 0.17931906699876632, 0.1856507935678855, 0.1856507935678855, 0.1856507935678855, 0.18391557709822626, 0.18391557709822626, 0.18391557709822626, 0.0772639131379339, 0.0772639131379339, 0.0772639131379339, 0.08562361816045938, 0.08562361816045938, 0.08562361816045938, 0.08433779883919557, 0.08433779883919557, 0.08433779883919557]}, "mutation_prompt": null}
{"id": "1b1a80cf-9f58-4fab-82bb-92d51cc4de59", "solution": "import numpy as np\n\nclass EM_ADEL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 8)\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                adaptive_F = self.F * (1 - eval_count / self.budget)  # Adaptive scaling\n                mutant = np.clip(x0 + adaptive_F * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            if eval_count % (self.population_size * 2) == 0:\n                self.F = 0.4 + 0.3 * (eval_count / self.budget)\n                self.CR = 0.9 - 0.4 * (eval_count / self.budget)\n\n            # Local search on the current best\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "EM_ADEL", "description": "Introducing Enhanced Mutation Strategy in Adaptive Differential Evolution with Local Search (EM-ADEL) for improved convergence through dynamic scaling of differential weight.", "configspace": "", "generation": 73, "fitness": 0.34908332589139734, "feedback": "The algorithm EM_ADEL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.25.", "error": "", "parent_id": "404fb07c-4ac8-4f1c-b06f-540790445d1d", "metadata": {"aucs": [0.8335592879951083, 0.8335592879951083, 0.8335592879951083, 0.8088217051556753, 0.8088217051556753, 0.8088217051556753, 0.8371892498964986, 0.8371892498964986, 0.8371892498964986, 0.6701285658309694, 0.6701285658309694, 0.6701285658309694, 0.6919963725038689, 0.6919963725038689, 0.6919963725038689, 0.7158845488399064, 0.7158845488399064, 0.7158845488399064, 0.17161981731727394, 0.17161981731727394, 0.17161981731727394, 0.15608306329090682, 0.15608306329090682, 0.15608306329090682, 0.23158623957943503, 0.23158623957943503, 0.23158623957943503, 0.2176909084309957, 0.2176909084309957, 0.2176909084309957, 0.1344874065878794, 0.1344874065878794, 0.1344874065878794, 0.13966322400804987, 0.13966322400804987, 0.13966322400804987, 0.9050712798858256, 0.9050712798858256, 0.9050712798858256, 0.8141581782477336, 0.8141581782477336, 0.8141581782477336, 0.8015332415863663, 0.8015332415863663, 0.8015332415863663, 0.22717082893803986, 0.22717082893803986, 0.22717082893803986, 0.19352360081614828, 0.19352360081614828, 0.19352360081614828, 0.23078835672856735, 0.23078835672856735, 0.23078835672856735, 0.8077389704234461, 0.8077389704234461, 0.8077389704234461, 0.8503997481192895, 0.8503997481192895, 0.8503997481192895, 0.8193078114531172, 0.8193078114531172, 0.8193078114531172, 0.14445958990043584, 0.14445958990043584, 0.14445958990043584, 0.13410113310308913, 0.13410113310308913, 0.13410113310308913, 0.15963370925531473, 0.15963370925531473, 0.15963370925531473, 0.14981681699993243, 0.14981681699993243, 0.14981681699993243, 0.20332768040258997, 0.20332768040258997, 0.20332768040258997, 0.17288686401649722, 0.17288686401649722, 0.17288686401649722, 0.3075169146029849, 0.3075169146029849, 0.3075169146029849, 0.22823447606818914, 0.22823447606818914, 0.22823447606818914, 0.1695139026820749, 0.1695139026820749, 0.1695139026820749, 0.330097760183102, 0.330097760183102, 0.330097760183102, 0.46647262507154585, 0.46647262507154585, 0.46647262507154585, 0.4339123116046395, 0.4339123116046395, 0.4339123116046395, 0.08004504405097668, 0.08004504405097668, 0.08004504405097668, 0.11216908604908804, 0.11216908604908804, 0.11216908604908804, 0.1406385510222946, 0.1406385510222946, 0.1406385510222946, 0.21283313987598795, 0.21283313987598795, 0.21283313987598795, 0.27873765402135264, 0.27873765402135264, 0.27873765402135264, 0.27688253833543597, 0.27688253833543597, 0.27688253833543597, 0.6558996608622356, 0.6558996608622356, 0.6558996608622356, 0.7451151807510954, 0.7451151807510954, 0.7451151807510954, 0.6182063538856643, 0.6182063538856643, 0.6182063538856643, 0.13710433769965424, 0.13710433769965424, 0.13710433769965424, 0.14516210552767372, 0.14516210552767372, 0.14516210552767372, 0.12983263921933197, 0.12983263921933197, 0.12983263921933197, 0.19146835192709455, 0.19146835192709455, 0.19146835192709455, 0.1849049693411704, 0.1849049693411704, 0.1849049693411704, 0.21806155722992093, 0.21806155722992093, 0.21806155722992093, 0.5015518839841604, 0.5015518839841604, 0.5015518839841604, 0.4144753772583367, 0.4144753772583367, 0.4144753772583367, 0.500488247497641, 0.500488247497641, 0.500488247497641, 0.4071287343149502, 0.4071287343149502, 0.4071287343149502, 0.33943422113524324, 0.33943422113524324, 0.33943422113524324, 0.3714309950331681, 0.3714309950331681, 0.3714309950331681, 0.21177077044014303, 0.21177077044014303, 0.21177077044014303, 0.22340412297371726, 0.22340412297371726, 0.22340412297371726, 0.19354865848372615, 0.19354865848372615, 0.19354865848372615, 0.2237156510379288, 0.2237156510379288, 0.2237156510379288, 0.25189741801176935, 0.25189741801176935, 0.25189741801176935, 0.20135773405397273, 0.20135773405397273, 0.20135773405397273, 0.8260582193960646, 0.8260582193960646, 0.8260582193960646, 0.19309067523562484, 0.19309067523562484, 0.19309067523562484, 0.16270374125960896, 0.16270374125960896, 0.16270374125960896, 0.6385401772092312, 0.6385401772092312, 0.6385401772092312, 0.16554462196508235, 0.16554462196508235, 0.16554462196508235, 0.20620594774305612, 0.20620594774305612, 0.20620594774305612, 0.18350163217980153, 0.18350163217980153, 0.18350163217980153, 0.17890406380448243, 0.17890406380448243, 0.17890406380448243, 0.19362356049174034, 0.19362356049174034, 0.19362356049174034, 0.09146202680176307, 0.09146202680176307, 0.09146202680176307, 0.07795889230814101, 0.07795889230814101, 0.07795889230814101, 0.09076473223677861, 0.09076473223677861, 0.09076473223677861]}, "mutation_prompt": null}
{"id": "6bc2ebf3-62b4-45ec-86a2-2b0e1c1e1484", "solution": "import numpy as np\n\nclass ADEL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 8)\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            if eval_count % (self.population_size * 2) == 0:\n                self.F = 0.4 + 0.25 * (eval_count / self.budget)  # Slightly adjusted for faster convergence\n                self.CR = 0.9 - 0.35 * (eval_count / self.budget)\n\n            # Local search is adjusted for a more refined exploration\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate * 0.8, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "ADEL", "description": "Enhanced Adaptive Differential Evolution with Local Search by fine-tuning mutation factor dynamics and local search strategy to improve convergence speed.", "configspace": "", "generation": 74, "fitness": 0.37431560321016744, "feedback": "The algorithm ADEL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.25.", "error": "", "parent_id": "404fb07c-4ac8-4f1c-b06f-540790445d1d", "metadata": {"aucs": [0.7996083380261908, 0.7996083380261908, 0.7996083380261908, 0.8095627557879489, 0.8095627557879489, 0.8095627557879489, 0.8273128795142437, 0.8273128795142437, 0.8273128795142437, 0.6420403841995486, 0.6420403841995486, 0.6420403841995486, 0.670777067285492, 0.670777067285492, 0.670777067285492, 0.6526863356644005, 0.6526863356644005, 0.6526863356644005, 0.1203424633527389, 0.1203424633527389, 0.1203424633527389, 0.12801443103844545, 0.12801443103844545, 0.12801443103844545, 0.13489504374367955, 0.13489504374367955, 0.13489504374367955, 0.11499381055815305, 0.11499381055815305, 0.11499381055815305, 0.11862763596724724, 0.11862763596724724, 0.11862763596724724, 0.11570961344128117, 0.11570961344128117, 0.11570961344128117, 0.9020196084976746, 0.9020196084976746, 0.9020196084976746, 0.7987564801604374, 0.7987564801604374, 0.7987564801604374, 0.8295462403259642, 0.8295462403259642, 0.8295462403259642, 0.3904619020023702, 0.3904619020023702, 0.3904619020023702, 0.4828587174018516, 0.4828587174018516, 0.4828587174018516, 0.40860444209024405, 0.40860444209024405, 0.40860444209024405, 0.755261480010526, 0.755261480010526, 0.755261480010526, 0.8134188767891044, 0.8134188767891044, 0.8134188767891044, 0.8048177112140725, 0.8048177112140725, 0.8048177112140725, 0.2292407661192436, 0.2292407661192436, 0.2292407661192436, 0.16283460027997987, 0.16283460027997987, 0.16283460027997987, 0.1675624306103093, 0.1675624306103093, 0.1675624306103093, 0.14907031124829462, 0.14907031124829462, 0.14907031124829462, 0.21715545209555465, 0.21715545209555465, 0.21715545209555465, 0.17825201795311618, 0.17825201795311618, 0.17825201795311618, 0.40404727848237176, 0.40404727848237176, 0.40404727848237176, 0.3370301627397285, 0.3370301627397285, 0.3370301627397285, 0.38005191887674616, 0.38005191887674616, 0.38005191887674616, 0.5503835022573658, 0.5503835022573658, 0.5503835022573658, 0.49103474188700835, 0.49103474188700835, 0.49103474188700835, 0.5748542664841539, 0.5748542664841539, 0.5748542664841539, 0.1742595174065218, 0.1742595174065218, 0.1742595174065218, 0.3020323947172535, 0.3020323947172535, 0.3020323947172535, 0.16911348405724635, 0.16911348405724635, 0.16911348405724635, 0.30502512778882085, 0.30502512778882085, 0.30502512778882085, 0.2615469293487638, 0.2615469293487638, 0.2615469293487638, 0.3279564829315905, 0.3279564829315905, 0.3279564829315905, 0.7107850479571274, 0.7107850479571274, 0.7107850479571274, 0.7223743554441561, 0.7223743554441561, 0.7223743554441561, 0.73312610726051, 0.73312610726051, 0.73312610726051, 0.09696267075788778, 0.09696267075788778, 0.09696267075788778, 0.135606707503365, 0.135606707503365, 0.135606707503365, 0.11698978828716355, 0.11698978828716355, 0.11698978828716355, 0.17739548455789167, 0.17739548455789167, 0.17739548455789167, 0.16449480642634806, 0.16449480642634806, 0.16449480642634806, 0.17028561032952472, 0.17028561032952472, 0.17028561032952472, 0.4432998235827096, 0.4432998235827096, 0.4432998235827096, 0.41259913250386004, 0.41259913250386004, 0.41259913250386004, 0.46661065298886684, 0.46661065298886684, 0.46661065298886684, 0.3366734057854971, 0.3366734057854971, 0.3366734057854971, 0.3329457502079891, 0.3329457502079891, 0.3329457502079891, 0.37432702817744035, 0.37432702817744035, 0.37432702817744035, 0.20429311560650953, 0.20429311560650953, 0.20429311560650953, 0.19635479498262587, 0.19635479498262587, 0.19635479498262587, 0.22961646493388455, 0.22961646493388455, 0.22961646493388455, 0.2043494897532565, 0.2043494897532565, 0.2043494897532565, 0.19829616892632662, 0.19829616892632662, 0.19829616892632662, 0.2170063425995712, 0.2170063425995712, 0.2170063425995712, 0.7986138449438493, 0.7986138449438493, 0.7986138449438493, 0.1903817891437607, 0.1903817891437607, 0.1903817891437607, 0.6437474548904434, 0.6437474548904434, 0.6437474548904434, 0.6913547881906245, 0.6913547881906245, 0.6913547881906245, 0.20169686835597045, 0.20169686835597045, 0.20169686835597045, 0.24396289380381841, 0.24396289380381841, 0.24396289380381841, 0.18782945726502043, 0.18782945726502043, 0.18782945726502043, 0.19777869055541542, 0.19777869055541542, 0.19777869055541542, 0.1927401810229762, 0.1927401810229762, 0.1927401810229762, 0.08558799747092871, 0.08558799747092871, 0.08558799747092871, 0.08874409499835023, 0.08874409499835023, 0.08874409499835023, 0.0821250195627039, 0.0821250195627039, 0.0821250195627039]}, "mutation_prompt": null}
{"id": "3af11317-69e6-41e1-ae1d-cd01ae9887c1", "solution": "import numpy as np\n\nclass ADEL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 8)\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            if eval_count % (self.population_size * 2) == 0:\n                self.F = 0.4 + 0.25 * (eval_count / self.budget)\n                self.CR = 0.9 - 0.35 * (eval_count / self.budget)\n\n            # Enhanced adaptive local search with dynamic adjustment\n            neighborhood_scale = np.clip(0.8 - 0.6 * (eval_count / self.budget), 0.2, 0.8)\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate * neighborhood_scale, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "ADEL", "description": "ADEL with Adaptive Neighborhood Search dynamically adjusts mutation factor and local search intensity based on progress to improve convergence speed.", "configspace": "", "generation": 75, "fitness": 0.37469864853518614, "feedback": "The algorithm ADEL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.25.", "error": "", "parent_id": "6bc2ebf3-62b4-45ec-86a2-2b0e1c1e1484", "metadata": {"aucs": [0.7996055321869336, 0.7996055321869336, 0.7996055321869336, 0.8096652802155034, 0.8096652802155034, 0.8096652802155034, 0.8272011264657775, 0.8272011264657775, 0.8272011264657775, 0.6420801828341935, 0.6420801828341935, 0.6420801828341935, 0.6376836132135282, 0.6376836132135282, 0.6376836132135282, 0.6526863356644005, 0.6526863356644005, 0.6526863356644005, 0.12205123841561838, 0.12205123841561838, 0.12205123841561838, 0.13870487701163836, 0.13870487701163836, 0.13870487701163836, 0.13884057254030135, 0.13884057254030135, 0.13884057254030135, 0.12548739034494005, 0.12548739034494005, 0.12548739034494005, 0.12162386659237234, 0.12162386659237234, 0.12162386659237234, 0.11970359884521553, 0.11970359884521553, 0.11970359884521553, 0.9019935722359934, 0.9019935722359934, 0.9019935722359934, 0.7987710476097967, 0.7987710476097967, 0.7987710476097967, 0.8295462191927276, 0.8295462191927276, 0.8295462191927276, 0.29966557558564977, 0.29966557558564977, 0.29966557558564977, 0.466247991488714, 0.466247991488714, 0.466247991488714, 0.45534272440517776, 0.45534272440517776, 0.45534272440517776, 0.7525786952053024, 0.7525786952053024, 0.7525786952053024, 0.8133867953358522, 0.8133867953358522, 0.8133867953358522, 0.8054178858783834, 0.8054178858783834, 0.8054178858783834, 0.22925275266617284, 0.22925275266617284, 0.22925275266617284, 0.1460681053726266, 0.1460681053726266, 0.1460681053726266, 0.16759563907247088, 0.16759563907247088, 0.16759563907247088, 0.14917838020229135, 0.14917838020229135, 0.14917838020229135, 0.21709597786573964, 0.21709597786573964, 0.21709597786573964, 0.184236746039243, 0.184236746039243, 0.184236746039243, 0.40408040017063496, 0.40408040017063496, 0.40408040017063496, 0.3370301627397285, 0.3370301627397285, 0.3370301627397285, 0.38005191887674616, 0.38005191887674616, 0.38005191887674616, 0.5504138213955514, 0.5504138213955514, 0.5504138213955514, 0.4910339238249206, 0.4910339238249206, 0.4910339238249206, 0.5748542664841539, 0.5748542664841539, 0.5748542664841539, 0.1742595174065218, 0.1742595174065218, 0.1742595174065218, 0.3020323947172535, 0.3020323947172535, 0.3020323947172535, 0.16911348405724635, 0.16911348405724635, 0.16911348405724635, 0.30504351634267324, 0.30504351634267324, 0.30504351634267324, 0.3393669265282536, 0.3393669265282536, 0.3393669265282536, 0.3279566718920117, 0.3279566718920117, 0.3279566718920117, 0.6991522117815403, 0.6991522117815403, 0.6991522117815403, 0.7223564600842216, 0.7223564600842216, 0.7223564600842216, 0.7331367515559677, 0.7331367515559677, 0.7331367515559677, 0.09966016196635696, 0.09966016196635696, 0.09966016196635696, 0.13971473277151525, 0.13971473277151525, 0.13971473277151525, 0.12148124494805057, 0.12148124494805057, 0.12148124494805057, 0.1964448348902722, 0.1964448348902722, 0.1964448348902722, 0.17453186616112448, 0.17453186616112448, 0.17453186616112448, 0.16706297728978026, 0.16706297728978026, 0.16706297728978026, 0.4432477350143915, 0.4432477350143915, 0.4432477350143915, 0.402979479333087, 0.402979479333087, 0.402979479333087, 0.4664283577457803, 0.4664283577457803, 0.4664283577457803, 0.33577966032486706, 0.33577966032486706, 0.33577966032486706, 0.34217507218826526, 0.34217507218826526, 0.34217507218826526, 0.3742412207628849, 0.3742412207628849, 0.3742412207628849, 0.20411477339092188, 0.20411477339092188, 0.20411477339092188, 0.19730488437968896, 0.19730488437968896, 0.19730488437968896, 0.21261554999942955, 0.21261554999942955, 0.21261554999942955, 0.2073429011835064, 0.2073429011835064, 0.2073429011835064, 0.19942157207557054, 0.19942157207557054, 0.19942157207557054, 0.22249904635788775, 0.22249904635788775, 0.22249904635788775, 0.7969991222469577, 0.7969991222469577, 0.7969991222469577, 0.19033870246753415, 0.19033870246753415, 0.19033870246753415, 0.6430286879635032, 0.6430286879635032, 0.6430286879635032, 0.6909550996880158, 0.6909550996880158, 0.6909550996880158, 0.20174161657358824, 0.20174161657358824, 0.20174161657358824, 0.2476510608421313, 0.2476510608421313, 0.2476510608421313, 0.18782945726502043, 0.18782945726502043, 0.18782945726502043, 0.19777869055541542, 0.19777869055541542, 0.19777869055541542, 0.19288778647690485, 0.19288778647690485, 0.19288778647690485, 0.08558799747092871, 0.08558799747092871, 0.08558799747092871, 0.08872249309519065, 0.08872249309519065, 0.08872249309519065, 0.0861417587608394, 0.0861417587608394, 0.0861417587608394]}, "mutation_prompt": null}
{"id": "5e52d48e-09ba-44cb-ae0b-c8ee693b4064", "solution": "import numpy as np\n\nclass ADEL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 8)\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                F_dynamic = self.F * (1 - eval_count / self.budget)  # Dynamic F\n                mutant = np.clip(x0 + F_dynamic * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            if eval_count % (self.population_size * 2) == 0:\n                self.F = 0.4 + 0.25 * (eval_count / self.budget)\n                self.CR = 0.9 - 0.35 * (eval_count / self.budget)\n\n            neighborhood_scale = np.clip(0.8 - 0.6 * (eval_count / self.budget), 0.2, 0.8)\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate * neighborhood_scale, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "ADEL", "description": "ADEL with Enhanced Mutation Strategy utilizes a dynamic mutation scaling factor to improve diversity and convergence speed.", "configspace": "", "generation": 76, "fitness": 0.3546348087601514, "feedback": "The algorithm ADEL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.25.", "error": "", "parent_id": "3af11317-69e6-41e1-ae1d-cd01ae9887c1", "metadata": {"aucs": [0.8263255051853778, 0.8263255051853778, 0.8263255051853778, 0.8245497241214508, 0.8245497241214508, 0.8245497241214508, 0.8379380223216972, 0.8379380223216972, 0.8379380223216972, 0.6798774979077016, 0.6798774979077016, 0.6798774979077016, 0.7029062222604089, 0.7029062222604089, 0.7029062222604089, 0.6760718075890777, 0.6760718075890777, 0.6760718075890777, 0.14082847373930873, 0.14082847373930873, 0.14082847373930873, 0.20784562074388335, 0.20784562074388335, 0.20784562074388335, 0.19264829230859637, 0.19264829230859637, 0.19264829230859637, 0.1373552032686004, 0.1373552032686004, 0.1373552032686004, 0.13349673958041153, 0.13349673958041153, 0.13349673958041153, 0.12637857857603862, 0.12637857857603862, 0.12637857857603862, 0.873351627536979, 0.873351627536979, 0.873351627536979, 0.7526290632666631, 0.7526290632666631, 0.7526290632666631, 0.793543064419763, 0.793543064419763, 0.793543064419763, 0.21097722562297627, 0.21097722562297627, 0.21097722562297627, 0.219626165661298, 0.219626165661298, 0.219626165661298, 0.29830398750081577, 0.29830398750081577, 0.29830398750081577, 0.7761285276106545, 0.7761285276106545, 0.7761285276106545, 0.8477364185733489, 0.8477364185733489, 0.8477364185733489, 0.8083919047120413, 0.8083919047120413, 0.8083919047120413, 0.2209528815515125, 0.2209528815515125, 0.2209528815515125, 0.13652713769913338, 0.13652713769913338, 0.13652713769913338, 0.21441850369200988, 0.21441850369200988, 0.21441850369200988, 0.1309859905803349, 0.1309859905803349, 0.1309859905803349, 0.16181664605612456, 0.16181664605612456, 0.16181664605612456, 0.2737519561198064, 0.2737519561198064, 0.2737519561198064, 0.2862552050342718, 0.2862552050342718, 0.2862552050342718, 0.29005821028742307, 0.29005821028742307, 0.29005821028742307, 0.06261965620269183, 0.06261965620269183, 0.06261965620269183, 0.4896020294511655, 0.4896020294511655, 0.4896020294511655, 0.18223894795671858, 0.18223894795671858, 0.18223894795671858, 0.254931785747024, 0.254931785747024, 0.254931785747024, 0.10595611416307382, 0.10595611416307382, 0.10595611416307382, 0.20675780102748553, 0.20675780102748553, 0.20675780102748553, 0.16987264286045267, 0.16987264286045267, 0.16987264286045267, 0.29512855736593635, 0.29512855736593635, 0.29512855736593635, 0.3208152133470955, 0.3208152133470955, 0.3208152133470955, 0.2119657507219972, 0.2119657507219972, 0.2119657507219972, 0.7594542446026469, 0.7594542446026469, 0.7594542446026469, 0.6800285381444916, 0.6800285381444916, 0.6800285381444916, 0.5630624604754532, 0.5630624604754532, 0.5630624604754532, 0.13938639124859487, 0.13938639124859487, 0.13938639124859487, 0.12856049910969836, 0.12856049910969836, 0.12856049910969836, 0.11916656698677364, 0.11916656698677364, 0.11916656698677364, 0.20817006441790664, 0.20817006441790664, 0.20817006441790664, 0.329791554648584, 0.329791554648584, 0.329791554648584, 0.21954903352271438, 0.21954903352271438, 0.21954903352271438, 0.4728725741520109, 0.4728725741520109, 0.4728725741520109, 0.5145101676656489, 0.5145101676656489, 0.5145101676656489, 0.5131204220343999, 0.5131204220343999, 0.5131204220343999, 0.3663822447283489, 0.3663822447283489, 0.3663822447283489, 0.2901379045057917, 0.2901379045057917, 0.2901379045057917, 0.3875400413908865, 0.3875400413908865, 0.3875400413908865, 0.2465508744466589, 0.2465508744466589, 0.2465508744466589, 0.19657670804486105, 0.19657670804486105, 0.19657670804486105, 0.21661370362855092, 0.21661370362855092, 0.21661370362855092, 0.22499961338824936, 0.22499961338824936, 0.22499961338824936, 0.4319109366427347, 0.4319109366427347, 0.4319109366427347, 0.35735694841904053, 0.35735694841904053, 0.35735694841904053, 0.8249485171025586, 0.8249485171025586, 0.8249485171025586, 0.5874292171010147, 0.5874292171010147, 0.5874292171010147, 0.17784135849743798, 0.17784135849743798, 0.17784135849743798, 0.2576824498404796, 0.2576824498404796, 0.2576824498404796, 0.20175853932191856, 0.20175853932191856, 0.20175853932191856, 0.20573972418946262, 0.20573972418946262, 0.20573972418946262, 0.18182091281699708, 0.18182091281699708, 0.18182091281699708, 0.19284131491233591, 0.19284131491233591, 0.19284131491233591, 0.20099393294562784, 0.20099393294562784, 0.20099393294562784, 0.08654257131980281, 0.08654257131980281, 0.08654257131980281, 0.08451188310936342, 0.08451188310936342, 0.08451188310936342, 0.08428961499850351, 0.08428961499850351, 0.08428961499850351]}, "mutation_prompt": null}
{"id": "c34eede9-26ea-4293-919f-0725cb1bac97", "solution": "import numpy as np\n\nclass ADEL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 8)\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                # Implementing a linearly decaying crossover probability\n                current_CR = self.CR * (1 - eval_count / self.budget)\n                cross_points = np.random.rand(self.dim) < current_CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            if eval_count % (self.population_size * 2) == 0:\n                self.F = 0.4 + 0.25 * (eval_count / self.budget)\n\n            # Enhanced adaptive local search with dynamic adjustment\n            neighborhood_scale = np.clip(0.8 - 0.6 * (eval_count / self.budget), 0.2, 0.8)\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate * neighborhood_scale, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "ADEL", "description": "ADEL with a Decaying Crossover Mechanism uses a linearly decaying crossover probability to balance exploration and exploitation, enhancing convergence speed.", "configspace": "", "generation": 77, "fitness": 0.2983225047262599, "feedback": "The algorithm ADEL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.23.", "error": "", "parent_id": "3af11317-69e6-41e1-ae1d-cd01ae9887c1", "metadata": {"aucs": [0.7882994873323096, 0.7882994873323096, 0.7882994873323096, 0.7923205927876822, 0.7923205927876822, 0.7923205927876822, 0.8017629059393407, 0.8017629059393407, 0.8017629059393407, 0.6322462273943537, 0.6322462273943537, 0.6322462273943537, 0.6150861543701345, 0.6150861543701345, 0.6150861543701345, 0.6399142507128233, 0.6399142507128233, 0.6399142507128233, 0.29767668313359275, 0.29767668313359275, 0.29767668313359275, 0.2232988611432889, 0.2232988611432889, 0.2232988611432889, 0.22155026682536505, 0.22155026682536505, 0.22155026682536505, 0.14744384730599325, 0.14744384730599325, 0.14744384730599325, 0.19795633319897343, 0.19795633319897343, 0.19795633319897343, 0.20139629302866524, 0.20139629302866524, 0.20139629302866524, 0.9023243302595018, 0.9023243302595018, 0.9023243302595018, 0.8998366592443509, 0.8998366592443509, 0.8998366592443509, 0.8798403917923323, 0.8798403917923323, 0.8798403917923323, 0.3228844000648684, 0.3228844000648684, 0.3228844000648684, 0.3407916441093677, 0.3407916441093677, 0.3407916441093677, 0.3178741916922134, 0.3178741916922134, 0.3178741916922134, 0.5729907649950821, 0.5729907649950821, 0.5729907649950821, 0.6321638095024307, 0.6321638095024307, 0.6321638095024307, 0.5556461462158404, 0.5556461462158404, 0.5556461462158404, 0.15392172927247572, 0.15392172927247572, 0.15392172927247572, 0.1536987992719372, 0.1536987992719372, 0.1536987992719372, 0.18007703440653278, 0.18007703440653278, 0.18007703440653278, 0.14825098318252095, 0.14825098318252095, 0.14825098318252095, 0.1717748679059128, 0.1717748679059128, 0.1717748679059128, 0.15225417606967817, 0.15225417606967817, 0.15225417606967817, 0.003796015262513386, 0.003796015262513386, 0.003796015262513386, 0.00985423791345108, 0.00985423791345108, 0.00985423791345108, 0.05551443178227433, 0.05551443178227433, 0.05551443178227433, 0.19122032204707873, 0.19122032204707873, 0.19122032204707873, 0.15737770377867089, 0.15737770377867089, 0.15737770377867089, 0.1326884671935581, 0.1326884671935581, 0.1326884671935581, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005133278122854246, 0.005133278122854246, 0.005133278122854246, 0.03895372511000239, 0.03895372511000239, 0.03895372511000239, 0.12582892738656815, 0.12582892738656815, 0.12582892738656815, 0.2052727375903478, 0.2052727375903478, 0.2052727375903478, 0.13570356704400544, 0.13570356704400544, 0.13570356704400544, 0.5076648970910307, 0.5076648970910307, 0.5076648970910307, 0.47749809800284715, 0.47749809800284715, 0.47749809800284715, 0.48561773775883577, 0.48561773775883577, 0.48561773775883577, 0.13822478793331228, 0.13822478793331228, 0.13822478793331228, 0.14724396387106775, 0.14724396387106775, 0.14724396387106775, 0.12133595222586169, 0.12133595222586169, 0.12133595222586169, 0.1936239969266218, 0.1936239969266218, 0.1936239969266218, 0.1744914688503637, 0.1744914688503637, 0.1744914688503637, 0.16633465871795527, 0.16633465871795527, 0.16633465871795527, 0.3293400229244665, 0.3293400229244665, 0.3293400229244665, 0.34585973561521954, 0.34585973561521954, 0.34585973561521954, 0.3836071288916162, 0.3836071288916162, 0.3836071288916162, 0.2380245457874528, 0.2380245457874528, 0.2380245457874528, 0.22442597875275272, 0.22442597875275272, 0.22442597875275272, 0.2548553049919279, 0.2548553049919279, 0.2548553049919279, 0.2147059925274345, 0.2147059925274345, 0.2147059925274345, 0.1891598911979181, 0.1891598911979181, 0.1891598911979181, 0.23532673656708325, 0.23532673656708325, 0.23532673656708325, 0.27688298805327494, 0.27688298805327494, 0.27688298805327494, 0.2579623871057448, 0.2579623871057448, 0.2579623871057448, 0.28048329130781635, 0.28048329130781635, 0.28048329130781635, 0.8111980578969697, 0.8111980578969697, 0.8111980578969697, 0.24411492809225843, 0.24411492809225843, 0.24411492809225843, 0.16847044240552023, 0.16847044240552023, 0.16847044240552023, 0.2668934009205033, 0.2668934009205033, 0.2668934009205033, 0.2688971223904534, 0.2688971223904534, 0.2688971223904534, 0.20529073320076374, 0.20529073320076374, 0.20529073320076374, 0.21445336789102887, 0.21445336789102887, 0.21445336789102887, 0.17976888919877732, 0.17976888919877732, 0.17976888919877732, 0.18232732976798016, 0.18232732976798016, 0.18232732976798016, 0.09317853405751375, 0.09317853405751375, 0.09317853405751375, 0.08782254432901737, 0.08782254432901737, 0.08782254432901737, 0.10941018065042951, 0.10941018065042951, 0.10941018065042951]}, "mutation_prompt": null}
{"id": "65133e5d-8c51-4e8c-93cb-257671f1cd6f", "solution": "import numpy as np\n\nclass ADEL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 8)\n        self.F = 0.5\n        self.CR = 0.9\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                # Adaptive differential weight\n                self.F = 0.5 + 0.3 * np.tanh((fitness[i] - fitness[best_idx]) / abs(fitness[best_idx]) + 1e-10)\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            if eval_count % (self.population_size * 3) == 0:\n                # Redistribute population\n                new_population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size // 4, self.dim))\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                eval_count += self.population_size // 4\n                # Replace worst individuals\n                worst_indices = np.argsort(fitness)[-self.population_size // 4:]\n                population[worst_indices] = new_population\n                fitness[worst_indices] = new_population_fitness\n\n            neighborhood_scale = np.clip(0.8 - 0.6 * (eval_count / self.budget), 0.2, 0.8)\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate * neighborhood_scale, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "ADEL", "description": "Modified ADEL with Adaptive Differential Weight and Population Redistribution to enhance convergence speed by dynamically adjusting mutation factor and redistributing population based on progress.", "configspace": "", "generation": 78, "fitness": 0.31878293315266126, "feedback": "The algorithm ADEL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.25.", "error": "", "parent_id": "3af11317-69e6-41e1-ae1d-cd01ae9887c1", "metadata": {"aucs": [0.7655599989977546, 0.7655599989977546, 0.7655599989977546, 0.7757831238850509, 0.7757831238850509, 0.7757831238850509, 0.7866632223989809, 0.7866632223989809, 0.7866632223989809, 0.5057772751788461, 0.5057772751788461, 0.5057772751788461, 0.49077004374828326, 0.49077004374828326, 0.49077004374828326, 0.5091760113150636, 0.5091760113150636, 0.5091760113150636, 0.131263412779425, 0.131263412779425, 0.131263412779425, 0.11094010473984295, 0.11094010473984295, 0.11094010473984295, 0.12555793736299492, 0.12555793736299492, 0.12555793736299492, 0.10896430432054272, 0.10896430432054272, 0.10896430432054272, 0.09653910000752641, 0.09653910000752641, 0.09653910000752641, 0.11608785647015196, 0.11608785647015196, 0.11608785647015196, 0.9469269869141352, 0.9469269869141352, 0.9469269869141352, 0.9291462415562842, 0.9291462415562842, 0.9291462415562842, 0.9769006007784586, 0.9769006007784586, 0.9769006007784586, 0.3569024489704675, 0.3569024489704675, 0.3569024489704675, 0.3411784719906289, 0.3411784719906289, 0.3411784719906289, 0.4267054102978506, 0.4267054102978506, 0.4267054102978506, 0.6890159269903973, 0.6890159269903973, 0.6890159269903973, 0.7276967722049559, 0.7276967722049559, 0.7276967722049559, 0.689627400163107, 0.689627400163107, 0.689627400163107, 0.18624547470731634, 0.18624547470731634, 0.18624547470731634, 0.24327692469774065, 0.24327692469774065, 0.24327692469774065, 0.14586492135292595, 0.14586492135292595, 0.14586492135292595, 0.10180724814936726, 0.10180724814936726, 0.10180724814936726, 0.1396635270651876, 0.1396635270651876, 0.1396635270651876, 0.16068718778823254, 0.16068718778823254, 0.16068718778823254, 0.10326455123212253, 0.10326455123212253, 0.10326455123212253, 0.1090344219884326, 0.1090344219884326, 0.1090344219884326, 0.1295102124880575, 0.1295102124880575, 0.1295102124880575, 0.29479835699717827, 0.29479835699717827, 0.29479835699717827, 0.2718175121391584, 0.2718175121391584, 0.2718175121391584, 0.3465691344318147, 0.3465691344318147, 0.3465691344318147, 0.013107856263309126, 0.013107856263309126, 0.013107856263309126, 0.007221929200540433, 0.007221929200540433, 0.007221929200540433, 0.02073457684106994, 0.02073457684106994, 0.02073457684106994, 0.1891671542872222, 0.1891671542872222, 0.1891671542872222, 0.18465678900666305, 0.18465678900666305, 0.18465678900666305, 0.25737773666963726, 0.25737773666963726, 0.25737773666963726, 0.6666887978359319, 0.6666887978359319, 0.6666887978359319, 0.6484192885183536, 0.6484192885183536, 0.6484192885183536, 0.6518859285544055, 0.6518859285544055, 0.6518859285544055, 0.10867505088742291, 0.10867505088742291, 0.10867505088742291, 0.10280756897166776, 0.10280756897166776, 0.10280756897166776, 0.12749112523543193, 0.12749112523543193, 0.12749112523543193, 0.18546627352993017, 0.18546627352993017, 0.18546627352993017, 0.22208462384516436, 0.22208462384516436, 0.22208462384516436, 0.17194534679157536, 0.17194534679157536, 0.17194534679157536, 0.3626574314123725, 0.3626574314123725, 0.3626574314123725, 0.3724918272906661, 0.3724918272906661, 0.3724918272906661, 0.41062787438117054, 0.41062787438117054, 0.41062787438117054, 0.2712594587936955, 0.2712594587936955, 0.2712594587936955, 0.2560075798356677, 0.2560075798356677, 0.2560075798356677, 0.32784311208713957, 0.32784311208713957, 0.32784311208713957, 0.1987035538916444, 0.1987035538916444, 0.1987035538916444, 0.20268124558112954, 0.20268124558112954, 0.20268124558112954, 0.19931305867592797, 0.19931305867592797, 0.19931305867592797, 0.18586699549195074, 0.18586699549195074, 0.18586699549195074, 0.18862913502442757, 0.18862913502442757, 0.18862913502442757, 0.19919037442032073, 0.19919037442032073, 0.19919037442032073, 0.6388846911901083, 0.6388846911901083, 0.6388846911901083, 0.4819989204558188, 0.4819989204558188, 0.4819989204558188, 0.25368144729537245, 0.25368144729537245, 0.25368144729537245, 0.26385039556206513, 0.26385039556206513, 0.26385039556206513, 0.1926330085957435, 0.1926330085957435, 0.1926330085957435, 0.7665256150577257, 0.7665256150577257, 0.7665256150577257, 0.19154236398821145, 0.19154236398821145, 0.19154236398821145, 0.17381163849553594, 0.17381163849553594, 0.17381163849553594, 0.18670077477202474, 0.18670077477202474, 0.18670077477202474, 0.0762149140271946, 0.0762149140271946, 0.0762149140271946, 0.07911174386201092, 0.07911174386201092, 0.07911174386201092, 0.0746918562570783, 0.0746918562570783, 0.0746918562570783]}, "mutation_prompt": null}
{"id": "cee7e7b9-89bb-4c81-a1c2-a089c8047c26", "solution": "import numpy as np\n\nclass ADEL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 8)\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                # Improved mutation strategy\n                dynamic_F = self.F + (np.random.rand() - 0.5) * 0.1 \n                mutant = np.clip(x0 + dynamic_F * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            if eval_count % (self.population_size * 2) == 0:\n                self.F = 0.4 + 0.25 * (eval_count / self.budget)\n                self.CR = 0.9 - 0.35 * (eval_count / self.budget)\n\n            # Enhanced adaptive local search with dynamic adjustment\n            neighborhood_scale = np.clip(0.8 - 0.6 * (eval_count / self.budget), 0.2, 0.8)\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate * neighborhood_scale, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "ADEL", "description": "ADEL with Improved Mutation Strategy uses a dynamic scaling factor to balance exploration and exploitation, enhancing convergence speed.", "configspace": "", "generation": 79, "fitness": 0.3720635410078068, "feedback": "The algorithm ADEL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.25.", "error": "", "parent_id": "3af11317-69e6-41e1-ae1d-cd01ae9887c1", "metadata": {"aucs": [0.803998198875733, 0.803998198875733, 0.803998198875733, 0.7942273222290489, 0.7942273222290489, 0.7942273222290489, 0.8164685953088682, 0.8164685953088682, 0.8164685953088682, 0.6704007458444645, 0.6704007458444645, 0.6704007458444645, 0.6768478541567757, 0.6768478541567757, 0.6768478541567757, 0.6559852934847699, 0.6559852934847699, 0.6559852934847699, 0.14092899138127946, 0.14092899138127946, 0.14092899138127946, 0.12430414320740368, 0.12430414320740368, 0.12430414320740368, 0.14428744777209646, 0.14428744777209646, 0.14428744777209646, 0.12582390016415723, 0.12582390016415723, 0.12582390016415723, 0.11620606596495597, 0.11620606596495597, 0.11620606596495597, 0.13014263826630212, 0.13014263826630212, 0.13014263826630212, 0.905877305095336, 0.905877305095336, 0.905877305095336, 0.8023877192782751, 0.8023877192782751, 0.8023877192782751, 0.8543474835086315, 0.8543474835086315, 0.8543474835086315, 0.5537812111605265, 0.5537812111605265, 0.5537812111605265, 0.5010896247812824, 0.5010896247812824, 0.5010896247812824, 0.25394168549177853, 0.25394168549177853, 0.25394168549177853, 0.7780801307171921, 0.7780801307171921, 0.7780801307171921, 0.8166833516388758, 0.8166833516388758, 0.8166833516388758, 0.8174696028744215, 0.8174696028744215, 0.8174696028744215, 0.2903885311384917, 0.2903885311384917, 0.2903885311384917, 0.16939222296619505, 0.16939222296619505, 0.16939222296619505, 0.19998845664766463, 0.19998845664766463, 0.19998845664766463, 0.1362435275436883, 0.1362435275436883, 0.1362435275436883, 0.16241902268836805, 0.16241902268836805, 0.16241902268836805, 0.18827864844870223, 0.18827864844870223, 0.18827864844870223, 0.41353469686968924, 0.41353469686968924, 0.41353469686968924, 0.3902994336736909, 0.3902994336736909, 0.3902994336736909, 0.38532241052045313, 0.38532241052045313, 0.38532241052045313, 0.4685532288208085, 0.4685532288208085, 0.4685532288208085, 0.5680276329325903, 0.5680276329325903, 0.5680276329325903, 0.5570109583731051, 0.5570109583731051, 0.5570109583731051, 0.12282731722777984, 0.12282731722777984, 0.12282731722777984, 0.1978544877756654, 0.1978544877756654, 0.1978544877756654, 0.1710630385637143, 0.1710630385637143, 0.1710630385637143, 0.3080541599390333, 0.3080541599390333, 0.3080541599390333, 0.3364518164667142, 0.3364518164667142, 0.3364518164667142, 0.32460978250065786, 0.32460978250065786, 0.32460978250065786, 0.7172024878473492, 0.7172024878473492, 0.7172024878473492, 0.736249962335512, 0.736249962335512, 0.736249962335512, 0.7288195967703263, 0.7288195967703263, 0.7288195967703263, 0.12872854536788658, 0.12872854536788658, 0.12872854536788658, 0.1272058143226159, 0.1272058143226159, 0.1272058143226159, 0.10187221909301503, 0.10187221909301503, 0.10187221909301503, 0.17273057251751323, 0.17273057251751323, 0.17273057251751323, 0.18522996785625723, 0.18522996785625723, 0.18522996785625723, 0.1668198435430811, 0.1668198435430811, 0.1668198435430811, 0.4695927915881828, 0.4695927915881828, 0.4695927915881828, 0.4020271768510384, 0.4020271768510384, 0.4020271768510384, 0.4580816062159523, 0.4580816062159523, 0.4580816062159523, 0.32726754339011854, 0.32726754339011854, 0.32726754339011854, 0.3197235045785184, 0.3197235045785184, 0.3197235045785184, 0.3355187065993007, 0.3355187065993007, 0.3355187065993007, 0.20216925430682176, 0.20216925430682176, 0.20216925430682176, 0.18138098301343042, 0.18138098301343042, 0.18138098301343042, 0.24611219961592867, 0.24611219961592867, 0.24611219961592867, 0.19472159930174315, 0.19472159930174315, 0.19472159930174315, 0.26682619130328755, 0.26682619130328755, 0.26682619130328755, 0.25680244607634617, 0.25680244607634617, 0.25680244607634617, 0.8504428309499434, 0.8504428309499434, 0.8504428309499434, 0.16393108585595895, 0.16393108585595895, 0.16393108585595895, 0.17755664757377032, 0.17755664757377032, 0.17755664757377032, 0.683635807626146, 0.683635807626146, 0.683635807626146, 0.19899948389628275, 0.19899948389628275, 0.19899948389628275, 0.30516167887578716, 0.30516167887578716, 0.30516167887578716, 0.18831174571813813, 0.18831174571813813, 0.18831174571813813, 0.18024079338482402, 0.18024079338482402, 0.18024079338482402, 0.1894234392090125, 0.1894234392090125, 0.1894234392090125, 0.08675371647654007, 0.08675371647654007, 0.08675371647654007, 0.0825149153888195, 0.0825149153888195, 0.0825149153888195, 0.08292111081345832, 0.08292111081345832, 0.08292111081345832]}, "mutation_prompt": null}
{"id": "4571e7f4-e965-47e3-9c0b-9566ebda2d01", "solution": "import numpy as np\n\nclass ADEL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 8)\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = np.clip(x0 + self.F * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            if eval_count % (self.population_size * 2) == 0:\n                self.F = 0.4 + 0.25 * (eval_count / self.budget)\n                self.CR = 0.9 - 0.35 * (eval_count / self.budget)\n\n            # Enhanced adaptive local search with dynamic adjustment\n            neighborhood_scale = np.clip(0.8 - 0.6 * (eval_count / self.budget), 0.2, 0.8)\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate * neighborhood_scale, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n            # Adaptive Opposition-Based Learning\n            opposition_factor = 0.5 * (1 - eval_count / self.budget)\n            opposite_population = self.lower_bound + self.upper_bound - population\n            opposite_population = np.clip(opposite_population, self.lower_bound, self.upper_bound)\n            f_opposite = np.array([func(ind) for ind in opposite_population])\n            eval_count += self.population_size\n            for i in range(self.population_size):\n                if f_opposite[i] < fitness[i]:\n                    population[i] = opposite_population[i]\n                    fitness[i] = f_opposite[i]\n                    if f_opposite[i] < fitness[best_idx]:\n                        best_idx = i\n                        best = opposite_population[i]\n\n        return best, fitness[best_idx]", "name": "ADEL", "description": "ADEL with Adaptive Opposition-Based Learning enhances the search by dynamically incorporating opposite solutions and improving convergence speed.", "configspace": "", "generation": 80, "fitness": 0.26381019848778514, "feedback": "The algorithm ADEL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.18.", "error": "", "parent_id": "3af11317-69e6-41e1-ae1d-cd01ae9887c1", "metadata": {"aucs": [0.6273089161911751, 0.6273089161911751, 0.6273089161911751, 0.6518763136970418, 0.6518763136970418, 0.6518763136970418, 0.6264821760057737, 0.6264821760057737, 0.6264821760057737, 0.3871989452187308, 0.3871989452187308, 0.3871989452187308, 0.346487227836517, 0.346487227836517, 0.346487227836517, 0.3210002843227212, 0.3210002843227212, 0.3210002843227212, 0.100566201978458, 0.100566201978458, 0.100566201978458, 0.11319604445889964, 0.11319604445889964, 0.11319604445889964, 0.09214526446677096, 0.09214526446677096, 0.09214526446677096, 0.09930200871113337, 0.09930200871113337, 0.09930200871113337, 0.08070177940391587, 0.08070177940391587, 0.08070177940391587, 0.09110169450698091, 0.09110169450698091, 0.09110169450698091, 0.6434332950242724, 0.6434332950242724, 0.6434332950242724, 0.7735907455967748, 0.7735907455967748, 0.7735907455967748, 0.7162010822432839, 0.7162010822432839, 0.7162010822432839, 0.2509249910450435, 0.2509249910450435, 0.2509249910450435, 0.24790404018926604, 0.24790404018926604, 0.24790404018926604, 0.2652310417304474, 0.2652310417304474, 0.2652310417304474, 0.5820567719809265, 0.5820567719809265, 0.5820567719809265, 0.6244268251278313, 0.6244268251278313, 0.6244268251278313, 0.6559727406732045, 0.6559727406732045, 0.6559727406732045, 0.19241019694529338, 0.19241019694529338, 0.19241019694529338, 0.17074005716204976, 0.17074005716204976, 0.17074005716204976, 0.1800277829324054, 0.1800277829324054, 0.1800277829324054, 0.1815303851823694, 0.1815303851823694, 0.1815303851823694, 0.20918957166669172, 0.20918957166669172, 0.20918957166669172, 0.22298943711552888, 0.22298943711552888, 0.22298943711552888, 0.15788367274869164, 0.15788367274869164, 0.15788367274869164, 0.15600377259689446, 0.15600377259689446, 0.15600377259689446, 0.1491721157873841, 0.1491721157873841, 0.1491721157873841, 0.3097413461502697, 0.3097413461502697, 0.3097413461502697, 0.2796352879846631, 0.2796352879846631, 0.2796352879846631, 0.2597630735761216, 0.2597630735761216, 0.2597630735761216, 0.025974777939878346, 0.025974777939878346, 0.025974777939878346, 0.049171808495234504, 0.049171808495234504, 0.049171808495234504, 0.06453462215910133, 0.06453462215910133, 0.06453462215910133, 0.148415532337261, 0.148415532337261, 0.148415532337261, 0.17515022566554816, 0.17515022566554816, 0.17515022566554816, 0.17711594884223736, 0.17711594884223736, 0.17711594884223736, 0.5185780416293472, 0.5185780416293472, 0.5185780416293472, 0.4832035405962718, 0.4832035405962718, 0.4832035405962718, 0.5034088956690774, 0.5034088956690774, 0.5034088956690774, 0.12243122964684827, 0.12243122964684827, 0.12243122964684827, 0.09393132412702943, 0.09393132412702943, 0.09393132412702943, 0.10345255914474816, 0.10345255914474816, 0.10345255914474816, 0.14234627193614247, 0.14234627193614247, 0.14234627193614247, 0.1857790684661884, 0.1857790684661884, 0.1857790684661884, 0.16123174031061738, 0.16123174031061738, 0.16123174031061738, 0.31216410355745106, 0.31216410355745106, 0.31216410355745106, 0.28683545993904824, 0.28683545993904824, 0.28683545993904824, 0.32960033511657216, 0.32960033511657216, 0.32960033511657216, 0.2574208730082429, 0.2574208730082429, 0.2574208730082429, 0.2467043762457264, 0.2467043762457264, 0.2467043762457264, 0.24022538173377384, 0.24022538173377384, 0.24022538173377384, 0.1989708043445073, 0.1989708043445073, 0.1989708043445073, 0.19576685016270778, 0.19576685016270778, 0.19576685016270778, 0.204347110609722, 0.204347110609722, 0.204347110609722, 0.1888631849522986, 0.1888631849522986, 0.1888631849522986, 0.19191893266470783, 0.19191893266470783, 0.19191893266470783, 0.1873432913871078, 0.1873432913871078, 0.1873432913871078, 0.6203586038099769, 0.6203586038099769, 0.6203586038099769, 0.15625356407501423, 0.15625356407501423, 0.15625356407501423, 0.17449327410469617, 0.17449327410469617, 0.17449327410469617, 0.16378429528941907, 0.16378429528941907, 0.16378429528941907, 0.3168013976414258, 0.3168013976414258, 0.3168013976414258, 0.2741476644547338, 0.2741476644547338, 0.2741476644547338, 0.16887913328614046, 0.16887913328614046, 0.16887913328614046, 0.17551170655078918, 0.17551170655078918, 0.17551170655078918, 0.17355535581282766, 0.17355535581282766, 0.17355535581282766, 0.07098734276017016, 0.07098734276017016, 0.07098734276017016, 0.07362327033089822, 0.07362327033089822, 0.07362327033089822, 0.06485730205950435, 0.06485730205950435, 0.06485730205950435]}, "mutation_prompt": null}
{"id": "7f16bfc1-5c88-4388-9ca9-612ab1b302bb", "solution": "import numpy as np\n\nclass GADEL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 8)\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                F_dynamic = self.F + np.random.normal(0, 0.05)  # Introduce Gaussian perturbation\n                mutant = np.clip(x0 + F_dynamic * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            if eval_count % (self.population_size * 2) == 0:\n                self.F = 0.4 + 0.25 * (eval_count / self.budget)\n                self.CR = 0.9 - 0.35 * (eval_count / self.budget)\n\n            neighborhood_scale = np.clip(0.8 - 0.6 * (eval_count / self.budget), 0.2, 0.8)\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate * neighborhood_scale, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "GADEL", "description": "G-ADEL enhances mutation diversity by dynamic scaling of F using Gaussian perturbation, improving convergence speed.", "configspace": "", "generation": 81, "fitness": 0.38069743604727485, "feedback": "The algorithm GADEL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.25.", "error": "", "parent_id": "3af11317-69e6-41e1-ae1d-cd01ae9887c1", "metadata": {"aucs": [0.8112937954438796, 0.8112937954438796, 0.8112937954438796, 0.7994164371726147, 0.7994164371726147, 0.7994164371726147, 0.8332891586055614, 0.8332891586055614, 0.8332891586055614, 0.6736193156369861, 0.6736193156369861, 0.6736193156369861, 0.6793249919790216, 0.6793249919790216, 0.6793249919790216, 0.6813740474165157, 0.6813740474165157, 0.6813740474165157, 0.15750337738378062, 0.15750337738378062, 0.15750337738378062, 0.14622200695637677, 0.14622200695637677, 0.14622200695637677, 0.11799126437682628, 0.11799126437682628, 0.11799126437682628, 0.10967485937445709, 0.10967485937445709, 0.10967485937445709, 0.11532676005026754, 0.11532676005026754, 0.11532676005026754, 0.11511040009244733, 0.11511040009244733, 0.11511040009244733, 0.8624073490731051, 0.8624073490731051, 0.8624073490731051, 0.8540059419272352, 0.8540059419272352, 0.8540059419272352, 0.7814789702850387, 0.7814789702850387, 0.7814789702850387, 0.5174043302792222, 0.5174043302792222, 0.5174043302792222, 0.37445218563171034, 0.37445218563171034, 0.37445218563171034, 0.28538184624721463, 0.28538184624721463, 0.28538184624721463, 0.874717948641499, 0.874717948641499, 0.874717948641499, 0.8454211239796086, 0.8454211239796086, 0.8454211239796086, 0.7735255753600557, 0.7735255753600557, 0.7735255753600557, 0.23038633274935438, 0.23038633274935438, 0.23038633274935438, 0.33627632258751783, 0.33627632258751783, 0.33627632258751783, 0.45917163527624194, 0.45917163527624194, 0.45917163527624194, 0.19304390115300785, 0.19304390115300785, 0.19304390115300785, 0.1830578950238969, 0.1830578950238969, 0.1830578950238969, 0.13540063518176138, 0.13540063518176138, 0.13540063518176138, 0.34108324778906873, 0.34108324778906873, 0.34108324778906873, 0.37083904240915455, 0.37083904240915455, 0.37083904240915455, 0.380128813097253, 0.380128813097253, 0.380128813097253, 0.5855700906032393, 0.5855700906032393, 0.5855700906032393, 0.4679073661619212, 0.4679073661619212, 0.4679073661619212, 0.5818235082840888, 0.5818235082840888, 0.5818235082840888, 0.14097777291214375, 0.14097777291214375, 0.14097777291214375, 0.2653247913459603, 0.2653247913459603, 0.2653247913459603, 0.14281133998721474, 0.14281133998721474, 0.14281133998721474, 0.28618815641030637, 0.28618815641030637, 0.28618815641030637, 0.323978024683683, 0.323978024683683, 0.323978024683683, 0.3081489494870422, 0.3081489494870422, 0.3081489494870422, 0.7149687330795902, 0.7149687330795902, 0.7149687330795902, 0.7279368080866321, 0.7279368080866321, 0.7279368080866321, 0.6900029389364042, 0.6900029389364042, 0.6900029389364042, 0.10749091112328546, 0.10749091112328546, 0.10749091112328546, 0.11576892290313767, 0.11576892290313767, 0.11576892290313767, 0.09988539194926505, 0.09988539194926505, 0.09988539194926505, 0.1843444365036876, 0.1843444365036876, 0.1843444365036876, 0.13585141976133364, 0.13585141976133364, 0.13585141976133364, 0.2044030360691209, 0.2044030360691209, 0.2044030360691209, 0.4193698511455416, 0.4193698511455416, 0.4193698511455416, 0.4030796287012409, 0.4030796287012409, 0.4030796287012409, 0.44669968780265434, 0.44669968780265434, 0.44669968780265434, 0.30467785524132474, 0.30467785524132474, 0.30467785524132474, 0.35109097889855034, 0.35109097889855034, 0.35109097889855034, 0.35831461681647647, 0.35831461681647647, 0.35831461681647647, 0.21491306969173407, 0.21491306969173407, 0.21491306969173407, 0.17636738117414497, 0.17636738117414497, 0.17636738117414497, 0.21375424255021702, 0.21375424255021702, 0.21375424255021702, 0.23487638455098436, 0.23487638455098436, 0.23487638455098436, 0.24139455058046155, 0.24139455058046155, 0.24139455058046155, 0.19406189581580857, 0.19406189581580857, 0.19406189581580857, 0.7914999860315217, 0.7914999860315217, 0.7914999860315217, 0.6660105000787415, 0.6660105000787415, 0.6660105000787415, 0.5495524405056575, 0.5495524405056575, 0.5495524405056575, 0.1653456706958043, 0.1653456706958043, 0.1653456706958043, 0.20251500312822235, 0.20251500312822235, 0.20251500312822235, 0.5350989868904876, 0.5350989868904876, 0.5350989868904876, 0.185874031631313, 0.185874031631313, 0.185874031631313, 0.18325164713054565, 0.18325164713054565, 0.18325164713054565, 0.18232629938632794, 0.18232629938632794, 0.18232629938632794, 0.08591690147383102, 0.08591690147383102, 0.08591690147383102, 0.10345960350194039, 0.10345960350194039, 0.10345960350194039, 0.07905207251152624, 0.07905207251152624, 0.07905207251152624]}, "mutation_prompt": null}
{"id": "ffc4cb72-a811-4df4-9659-1d3da2c82f2a", "solution": "import numpy as np\n\nclass GADEL_MA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 8)\n        self.base_F = 0.5  # Base differential weight\n        self.base_CR = 0.9  # Base crossover probability\n        self.learning_rate = 0.1\n        self.bandit_arms = 5\n        self.bandit_counts = np.zeros(self.bandit_arms)\n        self.bandit_rewards = np.zeros(self.bandit_arms)\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            arm_idx = np.argmax(self.bandit_rewards / (self.bandit_counts + 1e-5))\n            self.bandit_counts[arm_idx] += 1\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                F_dynamic = self.base_F + (0.1 * arm_idx / (self.bandit_arms - 1))\n                mutant = np.clip(x0 + F_dynamic * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < (self.base_CR - 0.1 * arm_idx / (self.bandit_arms - 1))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    self.bandit_rewards[arm_idx] += 1\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            neighborhood_scale = np.clip(0.8 - 0.6 * (eval_count / self.budget), 0.2, 0.8)\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate * neighborhood_scale, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "GADEL_MA", "description": "GADEL-MA employs multi-armed bandit strategy to adapt mutation strength and crossover probability dynamically, enhancing both exploration and exploitation.", "configspace": "", "generation": 82, "fitness": 0.350787446298173, "feedback": "The algorithm GADEL_MA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.24.", "error": "", "parent_id": "7f16bfc1-5c88-4388-9ca9-612ab1b302bb", "metadata": {"aucs": [0.7646571441652936, 0.7646571441652936, 0.7646571441652936, 0.7859510596221682, 0.7859510596221682, 0.7859510596221682, 0.7670211111515562, 0.7670211111515562, 0.7670211111515562, 0.6092881785643647, 0.6092881785643647, 0.6092881785643647, 0.6083237541072106, 0.6083237541072106, 0.6083237541072106, 0.5802574789083612, 0.5802574789083612, 0.5802574789083612, 0.1140671392567485, 0.1140671392567485, 0.1140671392567485, 0.12310598363999592, 0.12310598363999592, 0.12310598363999592, 0.1161073912407754, 0.1161073912407754, 0.1161073912407754, 0.10520506070064473, 0.10520506070064473, 0.10520506070064473, 0.11057264762568064, 0.11057264762568064, 0.11057264762568064, 0.11196741355756346, 0.11196741355756346, 0.11196741355756346, 0.9075265627622677, 0.9075265627622677, 0.9075265627622677, 0.8670601648309698, 0.8670601648309698, 0.8670601648309698, 0.8830751978338778, 0.8830751978338778, 0.8830751978338778, 0.3879855714988758, 0.3879855714988758, 0.3879855714988758, 0.4111481495213768, 0.4111481495213768, 0.4111481495213768, 0.46569075005165284, 0.46569075005165284, 0.46569075005165284, 0.7173103811011445, 0.7173103811011445, 0.7173103811011445, 0.7326233400292737, 0.7326233400292737, 0.7326233400292737, 0.7167754996307563, 0.7167754996307563, 0.7167754996307563, 0.2695437420419452, 0.2695437420419452, 0.2695437420419452, 0.23912189176041654, 0.23912189176041654, 0.23912189176041654, 0.19630732870303524, 0.19630732870303524, 0.19630732870303524, 0.22385999144124036, 0.22385999144124036, 0.22385999144124036, 0.19117399069475183, 0.19117399069475183, 0.19117399069475183, 0.21448980490201752, 0.21448980490201752, 0.21448980490201752, 0.2542679981105329, 0.2542679981105329, 0.2542679981105329, 0.35334161668630915, 0.35334161668630915, 0.35334161668630915, 0.3019519001037162, 0.3019519001037162, 0.3019519001037162, 0.4596452951623934, 0.4596452951623934, 0.4596452951623934, 0.4705267289710364, 0.4705267289710364, 0.4705267289710364, 0.5098856556492546, 0.5098856556492546, 0.5098856556492546, 0.20330990409498606, 0.20330990409498606, 0.20330990409498606, 0.15530603635596885, 0.15530603635596885, 0.15530603635596885, 0.18595748378692378, 0.18595748378692378, 0.18595748378692378, 0.2615444348272479, 0.2615444348272479, 0.2615444348272479, 0.28089395568073594, 0.28089395568073594, 0.28089395568073594, 0.2490125210532329, 0.2490125210532329, 0.2490125210532329, 0.6448841425262926, 0.6448841425262926, 0.6448841425262926, 0.6873044253779024, 0.6873044253779024, 0.6873044253779024, 0.6621244766239349, 0.6621244766239349, 0.6621244766239349, 0.1323565766762258, 0.1323565766762258, 0.1323565766762258, 0.11953736010052485, 0.11953736010052485, 0.11953736010052485, 0.13799725285699493, 0.13799725285699493, 0.13799725285699493, 0.1619452484140651, 0.1619452484140651, 0.1619452484140651, 0.18268217665090725, 0.18268217665090725, 0.18268217665090725, 0.19647778613716027, 0.19647778613716027, 0.19647778613716027, 0.41189474525159697, 0.41189474525159697, 0.41189474525159697, 0.38103750514931367, 0.38103750514931367, 0.38103750514931367, 0.3756562891470787, 0.3756562891470787, 0.3756562891470787, 0.2903351180210296, 0.2903351180210296, 0.2903351180210296, 0.2668933054898809, 0.2668933054898809, 0.2668933054898809, 0.3306233684966631, 0.3306233684966631, 0.3306233684966631, 0.19193178413658274, 0.19193178413658274, 0.19193178413658274, 0.1987620980328395, 0.1987620980328395, 0.1987620980328395, 0.18378753685793292, 0.18378753685793292, 0.18378753685793292, 0.21146466271257036, 0.21146466271257036, 0.21146466271257036, 0.19147761566346067, 0.19147761566346067, 0.19147761566346067, 0.2633504090374459, 0.2633504090374459, 0.2633504090374459, 0.7800116582996433, 0.7800116582996433, 0.7800116582996433, 0.19543956284227126, 0.19543956284227126, 0.19543956284227126, 0.712930267899396, 0.712930267899396, 0.712930267899396, 0.2057787790594804, 0.2057787790594804, 0.2057787790594804, 0.20083130962269502, 0.20083130962269502, 0.20083130962269502, 0.202988392484024, 0.202988392484024, 0.202988392484024, 0.19721242572090358, 0.19721242572090358, 0.19721242572090358, 0.19008693196196225, 0.19008693196196225, 0.19008693196196225, 0.18359848381096855, 0.18359848381096855, 0.18359848381096855, 0.08429471864266247, 0.08429471864266247, 0.08429471864266247, 0.08168952687729747, 0.08168952687729747, 0.08168952687729747, 0.09344993306044669, 0.09344993306044669, 0.09344993306044669]}, "mutation_prompt": null}
{"id": "d633c4a2-b243-4d73-8404-ad83830769f8", "solution": "import numpy as np\n\nclass GADEL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 8)\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                F_dynamic = self.F + np.random.normal(0, 0.05)  # Introduce Gaussian perturbation\n                mutant = np.clip(x0 + F_dynamic * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            if eval_count % (self.population_size * 2) == 0:\n                self.F = 0.4 + 0.25 * (eval_count / self.budget)\n                self.CR = 0.9 - 0.35 * (eval_count / self.budget)\n\n            neighborhood_scale = np.clip(0.8 - 0.6 * (eval_count / self.budget), 0.2, 0.8)\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate * neighborhood_scale, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n            # Adaptive crossover modification\n            self.CR = 0.9 - 0.15 * (eval_count / self.budget)  # Adjust CR based on progress\n\n        return best, fitness[best_idx]", "name": "GADEL", "description": "G-ADEL+ introduces adaptive crossover probability scaling to balance exploration and exploitation, enhancing convergence speed.", "configspace": "", "generation": 83, "fitness": 0.3684842356231182, "feedback": "The algorithm GADEL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.24.", "error": "", "parent_id": "7f16bfc1-5c88-4388-9ca9-612ab1b302bb", "metadata": {"aucs": [0.8022774560638087, 0.8022774560638087, 0.8022774560638087, 0.8014176584843242, 0.8014176584843242, 0.8014176584843242, 0.8181363438820322, 0.8181363438820322, 0.8181363438820322, 0.6665900186776924, 0.6665900186776924, 0.6665900186776924, 0.6545475275757588, 0.6545475275757588, 0.6545475275757588, 0.6845544274729009, 0.6845544274729009, 0.6845544274729009, 0.146168904867635, 0.146168904867635, 0.146168904867635, 0.1272989223897283, 0.1272989223897283, 0.1272989223897283, 0.14069377453993437, 0.14069377453993437, 0.14069377453993437, 0.11444556737251388, 0.11444556737251388, 0.11444556737251388, 0.12060578968300961, 0.12060578968300961, 0.12060578968300961, 0.1166553262558887, 0.1166553262558887, 0.1166553262558887, 0.7914114777094781, 0.7914114777094781, 0.7914114777094781, 0.9161591430697397, 0.9161591430697397, 0.9161591430697397, 0.8284217434083858, 0.8284217434083858, 0.8284217434083858, 0.42742659333609667, 0.42742659333609667, 0.42742659333609667, 0.4392890707374296, 0.4392890707374296, 0.4392890707374296, 0.4234124319943856, 0.4234124319943856, 0.4234124319943856, 0.7577742344463645, 0.7577742344463645, 0.7577742344463645, 0.7900717566948459, 0.7900717566948459, 0.7900717566948459, 0.7574772080495584, 0.7574772080495584, 0.7574772080495584, 0.161927261986745, 0.161927261986745, 0.161927261986745, 0.17005982002741693, 0.17005982002741693, 0.17005982002741693, 0.20652147848607305, 0.20652147848607305, 0.20652147848607305, 0.203919699638495, 0.203919699638495, 0.203919699638495, 0.2391260464247914, 0.2391260464247914, 0.2391260464247914, 0.23962982321811166, 0.23962982321811166, 0.23962982321811166, 0.283322036444118, 0.283322036444118, 0.283322036444118, 0.28404049017149025, 0.28404049017149025, 0.28404049017149025, 0.3046864124441827, 0.3046864124441827, 0.3046864124441827, 0.4679733123811002, 0.4679733123811002, 0.4679733123811002, 0.3831893054319998, 0.3831893054319998, 0.3831893054319998, 0.5034386735842701, 0.5034386735842701, 0.5034386735842701, 0.08962536489411066, 0.08962536489411066, 0.08962536489411066, 0.18888334938140228, 0.18888334938140228, 0.18888334938140228, 0.19039560637633113, 0.19039560637633113, 0.19039560637633113, 0.2686078829270072, 0.2686078829270072, 0.2686078829270072, 0.2831102818385993, 0.2831102818385993, 0.2831102818385993, 0.26865899244433844, 0.26865899244433844, 0.26865899244433844, 0.585202149833912, 0.585202149833912, 0.585202149833912, 0.6745356768677355, 0.6745356768677355, 0.6745356768677355, 0.7093514343976848, 0.7093514343976848, 0.7093514343976848, 0.10232907218566745, 0.10232907218566745, 0.10232907218566745, 0.11315429852309022, 0.11315429852309022, 0.11315429852309022, 0.10170338460963779, 0.10170338460963779, 0.10170338460963779, 0.17139828286215142, 0.17139828286215142, 0.17139828286215142, 0.2532130159306749, 0.2532130159306749, 0.2532130159306749, 0.20028705371322064, 0.20028705371322064, 0.20028705371322064, 0.4308058980787386, 0.4308058980787386, 0.4308058980787386, 0.4063862396356738, 0.4063862396356738, 0.4063862396356738, 0.476019699149103, 0.476019699149103, 0.476019699149103, 0.30605455957960614, 0.30605455957960614, 0.30605455957960614, 0.29609651017589744, 0.29609651017589744, 0.29609651017589744, 0.33755140708824416, 0.33755140708824416, 0.33755140708824416, 0.18231188273999577, 0.18231188273999577, 0.18231188273999577, 0.2010158559762003, 0.2010158559762003, 0.2010158559762003, 0.2039927585633593, 0.2039927585633593, 0.2039927585633593, 0.4499841507315435, 0.4499841507315435, 0.4499841507315435, 0.23590425682633553, 0.23590425682633553, 0.23590425682633553, 0.2539182627833917, 0.2539182627833917, 0.2539182627833917, 0.7768543960059975, 0.7768543960059975, 0.7768543960059975, 0.19464579868551968, 0.19464579868551968, 0.19464579868551968, 0.6639755572325399, 0.6639755572325399, 0.6639755572325399, 0.67632505007206, 0.67632505007206, 0.67632505007206, 0.20223660290120848, 0.20223660290120848, 0.20223660290120848, 0.4735593082218684, 0.4735593082218684, 0.4735593082218684, 0.17518908402242106, 0.17518908402242106, 0.17518908402242106, 0.18325164713054565, 0.18325164713054565, 0.18325164713054565, 0.19162565929105024, 0.19162565929105024, 0.19162565929105024, 0.08403924645937655, 0.08403924645937655, 0.08403924645937655, 0.07683243822360852, 0.07683243822360852, 0.07683243822360852, 0.07916311155435685, 0.07916311155435685, 0.07916311155435685]}, "mutation_prompt": null}
{"id": "918e0b05-f5d8-41de-ab01-94c536c7bddf", "solution": "import numpy as np\n\nclass GADELPlusPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 6)  # Adjusted population size for better exploration\n        self.F = 0.5\n        self.CR = 0.9\n        self.learning_rate = 0.1\n        self.alpha = 0.8  # New parameter for adaptive learning\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                F_dynamic = self.F + np.random.normal(0, 0.05) * self.alpha  # Adaptive scaling factor\n                mutant = np.clip(x0 + F_dynamic * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            if eval_count % (self.population_size * 2) == 0:\n                self.F = 0.4 + 0.3 * (eval_count / self.budget)  # Adjusted F for better adaptation\n                self.CR = 0.9 - 0.3 * (eval_count / self.budget)  # Optimized crossover rate\n\n            neighborhood_scale = np.clip(0.8 - 0.5 * (eval_count / self.budget), 0.2, 0.7)  # Adjusted scaling\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate * neighborhood_scale, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n            self.alpha = 0.8 - 0.7 * (eval_count / self.budget)  # Adaptive learning factor\n\n        return best, fitness[best_idx]", "name": "GADELPlusPlus", "description": "GADEL++ introduces adaptive learning and exploration strategies with neighborhood-based diversity to enhance convergence performance.", "configspace": "", "generation": 84, "fitness": 0.3683441796255748, "feedback": "The algorithm GADELPlusPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.25.", "error": "", "parent_id": "7f16bfc1-5c88-4388-9ca9-612ab1b302bb", "metadata": {"aucs": [0.8181049538937837, 0.8181049538937837, 0.8181049538937837, 0.8044626083182067, 0.8044626083182067, 0.8044626083182067, 0.8081211785176201, 0.8081211785176201, 0.8081211785176201, 0.6778747331499516, 0.6778747331499516, 0.6778747331499516, 0.6568169688819423, 0.6568169688819423, 0.6568169688819423, 0.6709285260171843, 0.6709285260171843, 0.6709285260171843, 0.1444716442354118, 0.1444716442354118, 0.1444716442354118, 0.15523040592469883, 0.15523040592469883, 0.15523040592469883, 0.114432060159677, 0.114432060159677, 0.114432060159677, 0.10760886344540344, 0.10760886344540344, 0.10760886344540344, 0.12084857726345033, 0.12084857726345033, 0.12084857726345033, 0.10833605528556922, 0.10833605528556922, 0.10833605528556922, 0.8983405605477008, 0.8983405605477008, 0.8983405605477008, 0.8387514751755916, 0.8387514751755916, 0.8387514751755916, 0.8552719880522689, 0.8552719880522689, 0.8552719880522689, 0.3943583742351545, 0.3943583742351545, 0.3943583742351545, 0.4205002917262417, 0.4205002917262417, 0.4205002917262417, 0.463638496393753, 0.463638496393753, 0.463638496393753, 0.7786041580606915, 0.7786041580606915, 0.7786041580606915, 0.7932792576214885, 0.7932792576214885, 0.7932792576214885, 0.8058089481360245, 0.8058089481360245, 0.8058089481360245, 0.18532085011571098, 0.18532085011571098, 0.18532085011571098, 0.1712489402671401, 0.1712489402671401, 0.1712489402671401, 0.21201281749005907, 0.21201281749005907, 0.21201281749005907, 0.29724763167333623, 0.29724763167333623, 0.29724763167333623, 0.19981536979755588, 0.19981536979755588, 0.19981536979755588, 0.17740962142417538, 0.17740962142417538, 0.17740962142417538, 0.2888246593969236, 0.2888246593969236, 0.2888246593969236, 0.40812389986253317, 0.40812389986253317, 0.40812389986253317, 0.10405783320360429, 0.10405783320360429, 0.10405783320360429, 0.516471956471863, 0.516471956471863, 0.516471956471863, 0.5300207947184783, 0.5300207947184783, 0.5300207947184783, 0.5650755011445902, 0.5650755011445902, 0.5650755011445902, 0.1635189525226548, 0.1635189525226548, 0.1635189525226548, 0.28267073692581013, 0.28267073692581013, 0.28267073692581013, 0.153937356698288, 0.153937356698288, 0.153937356698288, 0.3138946906752097, 0.3138946906752097, 0.3138946906752097, 0.33836518846532704, 0.33836518846532704, 0.33836518846532704, 0.321829445987053, 0.321829445987053, 0.321829445987053, 0.7110599942685824, 0.7110599942685824, 0.7110599942685824, 0.7462260400106474, 0.7462260400106474, 0.7462260400106474, 0.7606122592472048, 0.7606122592472048, 0.7606122592472048, 0.11958273466753544, 0.11958273466753544, 0.11958273466753544, 0.12132203638546712, 0.12132203638546712, 0.12132203638546712, 0.11941520629260138, 0.11941520629260138, 0.11941520629260138, 0.23309272444688867, 0.23309272444688867, 0.23309272444688867, 0.18783051866044587, 0.18783051866044587, 0.18783051866044587, 0.1476561307979577, 0.1476561307979577, 0.1476561307979577, 0.45275138799293924, 0.45275138799293924, 0.45275138799293924, 0.4294094530081265, 0.4294094530081265, 0.4294094530081265, 0.454290928539708, 0.454290928539708, 0.454290928539708, 0.32342943482597386, 0.32342943482597386, 0.32342943482597386, 0.3236068342126849, 0.3236068342126849, 0.3236068342126849, 0.34009284999509204, 0.34009284999509204, 0.34009284999509204, 0.22593462659782004, 0.22593462659782004, 0.22593462659782004, 0.23444234560820054, 0.23444234560820054, 0.23444234560820054, 0.20692394627273336, 0.20692394627273336, 0.20692394627273336, 0.23870775464174288, 0.23870775464174288, 0.23870775464174288, 0.19658326051357233, 0.19658326051357233, 0.19658326051357233, 0.20211050128525587, 0.20211050128525587, 0.20211050128525587, 0.7976352710358379, 0.7976352710358379, 0.7976352710358379, 0.19419204614434582, 0.19419204614434582, 0.19419204614434582, 0.36295044944088495, 0.36295044944088495, 0.36295044944088495, 0.16593789868619657, 0.16593789868619657, 0.16593789868619657, 0.6201286201906571, 0.6201286201906571, 0.6201286201906571, 0.15015795995873382, 0.15015795995873382, 0.15015795995873382, 0.18250255837618157, 0.18250255837618157, 0.18250255837618157, 0.1846564537280435, 0.1846564537280435, 0.1846564537280435, 0.18554864465606247, 0.18554864465606247, 0.18554864465606247, 0.0737461502088107, 0.0737461502088107, 0.0737461502088107, 0.07786128075000365, 0.07786128075000365, 0.07786128075000365, 0.0847462597123193, 0.0847462597123193, 0.0847462597123193]}, "mutation_prompt": null}
{"id": "493cb64c-67a5-4eec-9fd9-e8fa8d5324b6", "solution": "import numpy as np\n\nclass GDEARO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(80, budget // 6)  # Increased population size\n        self.base_F = 0.5\n        self.base_CR = 0.7  # Adjusted default crossover rate\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            fitness_std = np.std(fitness)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                F_dynamic = self.base_F + 0.1 * (fitness_std / (np.mean(fitness) + 1e-8))\n                mutant = np.clip(x0 + F_dynamic * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                CR_dynamic = self.base_CR + 0.2 * (fitness_std / (np.mean(fitness) + 1e-8))\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            if eval_count % (self.population_size * 3) == 0:\n                self.base_F = 0.5 + 0.3 * (eval_count / self.budget)\n                self.base_CR = 0.7 - 0.4 * (eval_count / self.budget)\n\n            neighborhood_scale = np.clip(0.9 - 0.7 * (eval_count / self.budget), 0.3, 0.9)\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate * neighborhood_scale, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "GDEARO", "description": "G-DEARO introduces adaptive crossover and mutation based on population diversity metrics to enhance convergence efficiency.", "configspace": "", "generation": 85, "fitness": 0.24175986873274266, "feedback": "The algorithm GDEARO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.21.", "error": "", "parent_id": "7f16bfc1-5c88-4388-9ca9-612ab1b302bb", "metadata": {"aucs": [0.6815207515295252, 0.6815207515295252, 0.6815207515295252, 0.6745226132410616, 0.6745226132410616, 0.6745226132410616, 0.6961396178674613, 0.6961396178674613, 0.6961396178674613, 0.024307300645489915, 0.024307300645489915, 0.024307300645489915, 0.10013438173818123, 0.10013438173818123, 0.10013438173818123, 0.12785440457865005, 0.12785440457865005, 0.12785440457865005, 0.12690553665379634, 0.12690553665379634, 0.12690553665379634, 0.1347608751758762, 0.1347608751758762, 0.1347608751758762, 0.11867590702107333, 0.11867590702107333, 0.11867590702107333, 0.10006671898497699, 0.10006671898497699, 0.10006671898497699, 0.10895309615578042, 0.10895309615578042, 0.10895309615578042, 0.10323828932683887, 0.10323828932683887, 0.10323828932683887, 0.8837693927439876, 0.8837693927439876, 0.8837693927439876, 0.881869570066849, 0.881869570066849, 0.881869570066849, 0.9604884377717369, 0.9604884377717369, 0.9604884377717369, 0.2524531583544265, 0.2524531583544265, 0.2524531583544265, 0.26205113536122404, 0.26205113536122404, 0.26205113536122404, 0.2331723844523843, 0.2331723844523843, 0.2331723844523843, 0.5209309566108975, 0.5209309566108975, 0.5209309566108975, 0.6182681793062204, 0.6182681793062204, 0.6182681793062204, 0.4868412153696765, 0.4868412153696765, 0.4868412153696765, 0.16425867471337552, 0.16425867471337552, 0.16425867471337552, 0.11767626673224241, 0.11767626673224241, 0.11767626673224241, 0.164316917129946, 0.164316917129946, 0.164316917129946, 0.140571878387859, 0.140571878387859, 0.140571878387859, 0.15571182733397204, 0.15571182733397204, 0.15571182733397204, 0.14861427406582917, 0.14861427406582917, 0.14861427406582917, 0.06291735489272854, 0.06291735489272854, 0.06291735489272854, 0.09573546732504656, 0.09573546732504656, 0.09573546732504656, 0.029210094807492926, 0.029210094807492926, 0.029210094807492926, 0.18081468813725987, 0.18081468813725987, 0.18081468813725987, 0.13497841537268773, 0.13497841537268773, 0.13497841537268773, 0.21212888140699593, 0.21212888140699593, 0.21212888140699593, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0109477279898047, 0.0109477279898047, 0.0109477279898047, 0.03277939884253955, 0.03277939884253955, 0.03277939884253955, 0.11286441332936359, 0.11286441332936359, 0.11286441332936359, 0.0742457378294128, 0.0742457378294128, 0.0742457378294128, 0.05948660831861252, 0.05948660831861252, 0.05948660831861252, 0.4448984043638913, 0.4448984043638913, 0.4448984043638913, 0.4566137585352966, 0.4566137585352966, 0.4566137585352966, 0.4487372290442897, 0.4487372290442897, 0.4487372290442897, 0.09720750927486821, 0.09720750927486821, 0.09720750927486821, 0.0968325775322657, 0.0968325775322657, 0.0968325775322657, 0.07612096143009661, 0.07612096143009661, 0.07612096143009661, 0.18387980226838185, 0.18387980226838185, 0.18387980226838185, 0.15912125901523322, 0.15912125901523322, 0.15912125901523322, 0.1658570599758461, 0.1658570599758461, 0.1658570599758461, 0.28116408305464513, 0.28116408305464513, 0.28116408305464513, 0.2969520607170245, 0.2969520607170245, 0.2969520607170245, 0.30740521166420476, 0.30740521166420476, 0.30740521166420476, 0.16515513687065975, 0.16515513687065975, 0.16515513687065975, 0.19604794861578878, 0.19604794861578878, 0.19604794861578878, 0.22830182200089333, 0.22830182200089333, 0.22830182200089333, 0.1905620948048583, 0.1905620948048583, 0.1905620948048583, 0.1808081511823184, 0.1808081511823184, 0.1808081511823184, 0.22390146341574169, 0.22390146341574169, 0.22390146341574169, 0.1611626220113671, 0.1611626220113671, 0.1611626220113671, 0.1874066793805691, 0.1874066793805691, 0.1874066793805691, 0.2307008333770495, 0.2307008333770495, 0.2307008333770495, 0.427345142543361, 0.427345142543361, 0.427345142543361, 0.25313810952855975, 0.25313810952855975, 0.25313810952855975, 0.28119134156421755, 0.28119134156421755, 0.28119134156421755, 0.2662338339521093, 0.2662338339521093, 0.2662338339521093, 0.28709845153191105, 0.28709845153191105, 0.28709845153191105, 0.3453521780634752, 0.3453521780634752, 0.3453521780634752, 0.1760375835515282, 0.1760375835515282, 0.1760375835515282, 0.18212866157677576, 0.18212866157677576, 0.18212866157677576, 0.18333225605459313, 0.18333225605459313, 0.18333225605459313, 0.07616402406296696, 0.07616402406296696, 0.07616402406296696, 0.0823783085516605, 0.0823783085516605, 0.0823783085516605, 0.07319143966974118, 0.07319143966974118, 0.07319143966974118]}, "mutation_prompt": null}
{"id": "20f7e403-df06-4bed-826a-e1edfc2d2c16", "solution": "import numpy as np\n\nclass GADEL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 8)\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                F_dynamic = self.F + np.random.normal(0, 0.05)  # Introduce Gaussian perturbation\n                mutant = np.clip(x0 + F_dynamic * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                CR_dynamic = self.CR + 0.1 * np.sin(eval_count / self.budget * np.pi)  # Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            if eval_count % (self.population_size * 2) == 0:\n                self.F = 0.4 + 0.25 * (eval_count / self.budget)\n                self.CR = 0.9 - 0.35 * (eval_count / self.budget)\n\n            neighborhood_scale = np.clip(0.8 - 0.6 * (eval_count / self.budget), 0.2, 0.8)\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate * neighborhood_scale, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "GADEL", "description": "G-ADEL enhances mutation diversity by introducing an adaptive crossover probability, improving convergence speed.", "configspace": "", "generation": 86, "fitness": 0.3901418861705392, "feedback": "The algorithm GADEL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.25.", "error": "", "parent_id": "7f16bfc1-5c88-4388-9ca9-612ab1b302bb", "metadata": {"aucs": [0.816087590935765, 0.816087590935765, 0.816087590935765, 0.8009497918950489, 0.8009497918950489, 0.8009497918950489, 0.8104635685045916, 0.8104635685045916, 0.8104635685045916, 0.6662418740547686, 0.6662418740547686, 0.6662418740547686, 0.6930966704415455, 0.6930966704415455, 0.6930966704415455, 0.6783375055632893, 0.6783375055632893, 0.6783375055632893, 0.12984663413741726, 0.12984663413741726, 0.12984663413741726, 0.12153058130124705, 0.12153058130124705, 0.12153058130124705, 0.1391865761831823, 0.1391865761831823, 0.1391865761831823, 0.1059869036956308, 0.1059869036956308, 0.1059869036956308, 0.09989577609101108, 0.09989577609101108, 0.09989577609101108, 0.11064354779838614, 0.11064354779838614, 0.11064354779838614, 0.8568379197238949, 0.8568379197238949, 0.8568379197238949, 0.8369160538190321, 0.8369160538190321, 0.8369160538190321, 0.7820717826539407, 0.7820717826539407, 0.7820717826539407, 0.4137530856789171, 0.4137530856789171, 0.4137530856789171, 0.2985027009872018, 0.2985027009872018, 0.2985027009872018, 0.20364139445760876, 0.20364139445760876, 0.20364139445760876, 0.8124926647719939, 0.8124926647719939, 0.8124926647719939, 0.8240471869689667, 0.8240471869689667, 0.8240471869689667, 0.8413424055906058, 0.8413424055906058, 0.8413424055906058, 0.1653665546336207, 0.1653665546336207, 0.1653665546336207, 0.1691554942262672, 0.1691554942262672, 0.1691554942262672, 0.26170048926071254, 0.26170048926071254, 0.26170048926071254, 0.20080783950655745, 0.20080783950655745, 0.20080783950655745, 0.16902557399374707, 0.16902557399374707, 0.16902557399374707, 0.2388406670563289, 0.2388406670563289, 0.2388406670563289, 0.601129239780488, 0.601129239780488, 0.601129239780488, 0.5873871967174064, 0.5873871967174064, 0.5873871967174064, 0.6052074570865236, 0.6052074570865236, 0.6052074570865236, 0.6518492250390415, 0.6518492250390415, 0.6518492250390415, 0.6780766736981662, 0.6780766736981662, 0.6780766736981662, 0.6963581245016344, 0.6963581245016344, 0.6963581245016344, 0.19691890078778707, 0.19691890078778707, 0.19691890078778707, 0.3070167028553745, 0.3070167028553745, 0.3070167028553745, 0.15975826115444847, 0.15975826115444847, 0.15975826115444847, 0.46504909136548533, 0.46504909136548533, 0.46504909136548533, 0.4353177527114782, 0.4353177527114782, 0.4353177527114782, 0.24952488446451948, 0.24952488446451948, 0.24952488446451948, 0.7682743672589263, 0.7682743672589263, 0.7682743672589263, 0.552010772339267, 0.552010772339267, 0.552010772339267, 0.7887419196574336, 0.7887419196574336, 0.7887419196574336, 0.11602765197297871, 0.11602765197297871, 0.11602765197297871, 0.11818289207939836, 0.11818289207939836, 0.11818289207939836, 0.11878169358762547, 0.11878169358762547, 0.11878169358762547, 0.2458786784206407, 0.2458786784206407, 0.2458786784206407, 0.2080434682600828, 0.2080434682600828, 0.2080434682600828, 0.16562589562946228, 0.16562589562946228, 0.16562589562946228, 0.4825005359709874, 0.4825005359709874, 0.4825005359709874, 0.4658697316369387, 0.4658697316369387, 0.4658697316369387, 0.4615716357825089, 0.4615716357825089, 0.4615716357825089, 0.3949494341572424, 0.3949494341572424, 0.3949494341572424, 0.39559669385972906, 0.39559669385972906, 0.39559669385972906, 0.4284968234165807, 0.4284968234165807, 0.4284968234165807, 0.19662987904539797, 0.19662987904539797, 0.19662987904539797, 0.19637635137269627, 0.19637635137269627, 0.19637635137269627, 0.21864868580558572, 0.21864868580558572, 0.21864868580558572, 0.3539902226420828, 0.3539902226420828, 0.3539902226420828, 0.22108710475053606, 0.22108710475053606, 0.22108710475053606, 0.42705199017352957, 0.42705199017352957, 0.42705199017352957, 0.8218713373940694, 0.8218713373940694, 0.8218713373940694, 0.1929129199158901, 0.1929129199158901, 0.1929129199158901, 0.3548731989059166, 0.3548731989059166, 0.3548731989059166, 0.20406682754892969, 0.20406682754892969, 0.20406682754892969, 0.2027716066144949, 0.2027716066144949, 0.2027716066144949, 0.28515880657399095, 0.28515880657399095, 0.28515880657399095, 0.18785380627362724, 0.18785380627362724, 0.18785380627362724, 0.19567033132141476, 0.19567033132141476, 0.19567033132141476, 0.17662209185049083, 0.17662209185049083, 0.17662209185049083, 0.08565720221599027, 0.08565720221599027, 0.08565720221599027, 0.09212644681389792, 0.09212644681389792, 0.09212644681389792, 0.08593245693684837, 0.08593245693684837, 0.08593245693684837]}, "mutation_prompt": null}
{"id": "ac4d925c-15b8-40d6-bb38-893c951e2212", "solution": "import numpy as np\n\nclass GADLEO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 8)\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                F_dynamic = self.F + np.random.uniform(-0.1, 0.1)  # Wider dynamic range for F\n                mutant = np.clip(x0 + F_dynamic * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                CR_dynamic = self.CR + 0.1 * np.sin(eval_count / self.budget * np.pi)  # Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            # Incorporate opposition-based learning\n            opposite_population = self.lower_bound + self.upper_bound - population\n            for opp in opposite_population:\n                f_opp = func(opp)\n                eval_count += 1\n                if f_opp < fitness[best_idx]:\n                    best_idx = np.argmin(fitness)\n                    best = opp\n\n            if eval_count % (self.population_size * 2) == 0:\n                self.F = 0.4 + 0.25 * (eval_count / self.budget)\n                self.CR = 0.9 - 0.35 * (eval_count / self.budget)\n\n            neighborhood_scale = np.clip(0.8 - 0.6 * (eval_count / self.budget), 0.2, 0.8)\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate * neighborhood_scale, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "GADLEO", "description": "G-ADLEO integrates opposition-based learning and enhanced mutation dynamics to accelerate convergence speed.", "configspace": "", "generation": 87, "fitness": 0.2564703606800976, "feedback": "The algorithm GADLEO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.17.", "error": "", "parent_id": "20f7e403-df06-4bed-826a-e1edfc2d2c16", "metadata": {"aucs": [0.5392309113544, 0.5392309113544, 0.5392309113544, 0.5647054971877539, 0.5647054971877539, 0.5647054971877539, 0.5390562868120696, 0.5390562868120696, 0.5390562868120696, 0.2478460688893689, 0.2478460688893689, 0.2478460688893689, 0.2597114387273276, 0.2597114387273276, 0.2597114387273276, 0.2773120400188953, 0.2773120400188953, 0.2773120400188953, 0.14146283722351183, 0.14146283722351183, 0.14146283722351183, 0.12739446935932341, 0.12739446935932341, 0.12739446935932341, 0.0853558560544394, 0.0853558560544394, 0.0853558560544394, 0.10690702911408534, 0.10690702911408534, 0.10690702911408534, 0.0828999904501947, 0.0828999904501947, 0.0828999904501947, 0.0758439501211966, 0.0758439501211966, 0.0758439501211966, 0.504067475553019, 0.504067475553019, 0.504067475553019, 0.8033834936506903, 0.8033834936506903, 0.8033834936506903, 0.71709574637761, 0.71709574637761, 0.71709574637761, 0.2508426424280198, 0.2508426424280198, 0.2508426424280198, 0.2435507944528571, 0.2435507944528571, 0.2435507944528571, 0.2021047530758061, 0.2021047530758061, 0.2021047530758061, 0.5802703774241031, 0.5802703774241031, 0.5802703774241031, 0.6216939620018272, 0.6216939620018272, 0.6216939620018272, 0.671732341979155, 0.671732341979155, 0.671732341979155, 0.12374178492531851, 0.12374178492531851, 0.12374178492531851, 0.12301789271673147, 0.12301789271673147, 0.12301789271673147, 0.19357857548231006, 0.19357857548231006, 0.19357857548231006, 0.17330859650128116, 0.17330859650128116, 0.17330859650128116, 0.15345568212350136, 0.15345568212350136, 0.15345568212350136, 0.1735233748128472, 0.1735233748128472, 0.1735233748128472, 0.20852566661587912, 0.20852566661587912, 0.20852566661587912, 0.1834671479058555, 0.1834671479058555, 0.1834671479058555, 0.20444014111473274, 0.20444014111473274, 0.20444014111473274, 0.29155697932173885, 0.29155697932173885, 0.29155697932173885, 0.3265247809544608, 0.3265247809544608, 0.3265247809544608, 0.3327137430805409, 0.3327137430805409, 0.3327137430805409, 0.05168856633329144, 0.05168856633329144, 0.05168856633329144, 0.12317599243677946, 0.12317599243677946, 0.12317599243677946, 0.07408926681304473, 0.07408926681304473, 0.07408926681304473, 0.17256180904632035, 0.17256180904632035, 0.17256180904632035, 0.17521368223929135, 0.17521368223929135, 0.17521368223929135, 0.17690995529476272, 0.17690995529476272, 0.17690995529476272, 0.48991362733868005, 0.48991362733868005, 0.48991362733868005, 0.4938111845889339, 0.4938111845889339, 0.4938111845889339, 0.4592331919590028, 0.4592331919590028, 0.4592331919590028, 0.09614753568847301, 0.09614753568847301, 0.09614753568847301, 0.09135966951965202, 0.09135966951965202, 0.09135966951965202, 0.12224195983152442, 0.12224195983152442, 0.12224195983152442, 0.19803926079923873, 0.19803926079923873, 0.19803926079923873, 0.1462503062291728, 0.1462503062291728, 0.1462503062291728, 0.1471320987445619, 0.1471320987445619, 0.1471320987445619, 0.2852372323477692, 0.2852372323477692, 0.2852372323477692, 0.28912158005102584, 0.28912158005102584, 0.28912158005102584, 0.2760963224081484, 0.2760963224081484, 0.2760963224081484, 0.23461631746240164, 0.23461631746240164, 0.23461631746240164, 0.2116395859574478, 0.2116395859574478, 0.2116395859574478, 0.23296983492434253, 0.23296983492434253, 0.23296983492434253, 0.19141314852211577, 0.19141314852211577, 0.19141314852211577, 0.19003230053840148, 0.19003230053840148, 0.19003230053840148, 0.1737166816880903, 0.1737166816880903, 0.1737166816880903, 0.17660528418203847, 0.17660528418203847, 0.17660528418203847, 0.18014759313599737, 0.18014759313599737, 0.18014759313599737, 0.1754542257637831, 0.1754542257637831, 0.1754542257637831, 0.5950457974095229, 0.5950457974095229, 0.5950457974095229, 0.3652194768546637, 0.3652194768546637, 0.3652194768546637, 0.15980081705856297, 0.15980081705856297, 0.15980081705856297, 0.19181598522225607, 0.19181598522225607, 0.19181598522225607, 0.4827645328221397, 0.4827645328221397, 0.4827645328221397, 0.1542436383650373, 0.1542436383650373, 0.1542436383650373, 0.16582430321149955, 0.16582430321149955, 0.16582430321149955, 0.18182397931852512, 0.18182397931852512, 0.18182397931852512, 0.1930049007512814, 0.1930049007512814, 0.1930049007512814, 0.06278556475675745, 0.06278556475675745, 0.06278556475675745, 0.06852022403049085, 0.06852022403049085, 0.06852022403049085, 0.07987620751114677, 0.07987620751114677, 0.07987620751114677]}, "mutation_prompt": null}
{"id": "03a3db29-033a-4c1f-bd51-0b4857f879ea", "solution": "import numpy as np\n\nclass GADEL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 8)\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.learning_rate = 0.1\n        self.momentum = np.zeros((self.population_size, self.dim))  # Added momentum term\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                F_dynamic = self.F + np.random.normal(0, 0.05)  # Introduce Gaussian perturbation\n                mutant = np.clip(x0 + F_dynamic * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                CR_dynamic = self.CR + 0.1 * np.sin(eval_count / self.budget * np.pi)  # Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    self.momentum[i] = 0.9 * self.momentum[i] + 0.1 * (trial - population[i])  # Apply momentum\n                    fitness[i] = f_trial\n                    population[i] = trial + self.momentum[i]  # Update with momentum\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            if eval_count % (self.population_size * 2) == 0:\n                self.F = 0.4 + 0.25 * (eval_count / self.budget)\n                self.CR = 0.9 - 0.35 * (eval_count / self.budget)\n\n            neighborhood_scale = np.clip(0.8 - 0.6 * (eval_count / self.budget), 0.2, 0.8)\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate * neighborhood_scale, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "GADEL", "description": "Enhanced GADEL by applying a momentum-based mutation strategy to accelerate convergence.", "configspace": "", "generation": 88, "fitness": 0.24684811580319016, "feedback": "The algorithm GADEL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.22.", "error": "", "parent_id": "20f7e403-df06-4bed-826a-e1edfc2d2c16", "metadata": {"aucs": [0.6035029643205074, 0.6035029643205074, 0.6035029643205074, 0.5831112035916002, 0.5831112035916002, 0.5831112035916002, 0.5969245902650775, 0.5969245902650775, 0.5969245902650775, 0.09438479655487986, 0.09438479655487986, 0.09438479655487986, 0.08001209969709411, 0.08001209969709411, 0.08001209969709411, 0.08091641520058312, 0.08091641520058312, 0.08091641520058312, 0.11262140918134078, 0.11262140918134078, 0.11262140918134078, 0.11959080240436704, 0.11959080240436704, 0.11959080240436704, 0.11490574497226114, 0.11490574497226114, 0.11490574497226114, 0.09133675746873793, 0.09133675746873793, 0.09133675746873793, 0.10088635282510272, 0.10088635282510272, 0.10088635282510272, 0.09753634150042012, 0.09753634150042012, 0.09753634150042012, 0.9492735665031303, 0.9492735665031303, 0.9492735665031303, 0.9418280686726854, 0.9418280686726854, 0.9418280686726854, 0.9526336155658488, 0.9526336155658488, 0.9526336155658488, 0.3051123227758792, 0.3051123227758792, 0.3051123227758792, 0.20643391623383534, 0.20643391623383534, 0.20643391623383534, 0.3118674454586017, 0.3118674454586017, 0.3118674454586017, 0.6745327812716229, 0.6745327812716229, 0.6745327812716229, 0.20894703399574566, 0.20894703399574566, 0.20894703399574566, 0.6488270279518652, 0.6488270279518652, 0.6488270279518652, 0.14912974764165432, 0.14912974764165432, 0.14912974764165432, 0.18010696104352064, 0.18010696104352064, 0.18010696104352064, 0.18768892135716808, 0.18768892135716808, 0.18768892135716808, 0.18313601547124525, 0.18313601547124525, 0.18313601547124525, 0.20066693600619478, 0.20066693600619478, 0.20066693600619478, 0.159818512230252, 0.159818512230252, 0.159818512230252, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01767402064524326, 0.01767402064524326, 0.01767402064524326, 0.036077989563793156, 0.036077989563793156, 0.036077989563793156, 0.09515493517424711, 0.09515493517424711, 0.09515493517424711, 0.12000495304420622, 0.12000495304420622, 0.12000495304420622, 0.0761092313090963, 0.0761092313090963, 0.0761092313090963, 0.03959312245778124, 0.03959312245778124, 0.03959312245778124, 0.024144449821075997, 0.024144449821075997, 0.024144449821075997, 0.049036207951284494, 0.049036207951284494, 0.049036207951284494, 0.16974823145684537, 0.16974823145684537, 0.16974823145684537, 0.14846339931987385, 0.14846339931987385, 0.14846339931987385, 0.14020582581999785, 0.14020582581999785, 0.14020582581999785, 0.4711981741355742, 0.4711981741355742, 0.4711981741355742, 0.4706453752503308, 0.4706453752503308, 0.4706453752503308, 0.4623323722892565, 0.4623323722892565, 0.4623323722892565, 0.10775714772287193, 0.10775714772287193, 0.10775714772287193, 0.12370365945896444, 0.12370365945896444, 0.12370365945896444, 0.0966658816331778, 0.0966658816331778, 0.0966658816331778, 0.1796195477649124, 0.1796195477649124, 0.1796195477649124, 0.23551536779921833, 0.23551536779921833, 0.23551536779921833, 0.20514589710528686, 0.20514589710528686, 0.20514589710528686, 0.2946314846213257, 0.2946314846213257, 0.2946314846213257, 0.31590529237389187, 0.31590529237389187, 0.31590529237389187, 0.30138457430083176, 0.30138457430083176, 0.30138457430083176, 0.2291861958433541, 0.2291861958433541, 0.2291861958433541, 0.2374802840017275, 0.2374802840017275, 0.2374802840017275, 0.2496134938063197, 0.2496134938063197, 0.2496134938063197, 0.20356226521573995, 0.20356226521573995, 0.20356226521573995, 0.19865639305316174, 0.19865639305316174, 0.19865639305316174, 0.2043411376533073, 0.2043411376533073, 0.2043411376533073, 0.18556835612172484, 0.18556835612172484, 0.18556835612172484, 0.21052619657920957, 0.21052619657920957, 0.21052619657920957, 0.2005682550960416, 0.2005682550960416, 0.2005682550960416, 0.7483210029190754, 0.7483210029190754, 0.7483210029190754, 0.3917437234844052, 0.3917437234844052, 0.3917437234844052, 0.1785738376406154, 0.1785738376406154, 0.1785738376406154, 0.18667960994662658, 0.18667960994662658, 0.18667960994662658, 0.2012496821103379, 0.2012496821103379, 0.2012496821103379, 0.2536689929989422, 0.2536689929989422, 0.2536689929989422, 0.20706859814526157, 0.20706859814526157, 0.20706859814526157, 0.16768451008162188, 0.16768451008162188, 0.16768451008162188, 0.1669259968895065, 0.1669259968895065, 0.1669259968895065, 0.0797972495818211, 0.0797972495818211, 0.0797972495818211, 0.07374844522755009, 0.07374844522755009, 0.07374844522755009, 0.08155062025303417, 0.08155062025303417, 0.08155062025303417]}, "mutation_prompt": null}
{"id": "cb233b34-4851-4a03-b51c-d2b5b2ccb4a6", "solution": "import numpy as np\n\nclass GADELPlusPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(80, budget // 6)\n        self.F = 0.6  # Initial differential weight\n        self.CR = 0.85  # Initial crossover probability\n        self.learning_rate = 0.15\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                F_dynamic = self.F * (1 + np.random.normal(0, 0.1))  # More robust perturbation\n                mutant = np.clip(x0 + F_dynamic * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                CR_dynamic = self.CR + 0.15 * np.sin(eval_count / self.budget * 2 * np.pi)  # Adaptive crossover\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n                        \n                # Introduce stochastic elitism\n                if np.random.rand() < 0.1 and f_trial < fitness[best_idx]:\n                    population[np.random.choice(self.population_size)] = trial\n\n            if eval_count % (self.population_size * 3) == 0:\n                self.F = 0.5 + 0.3 * (eval_count / self.budget)\n                self.CR = 0.88 - 0.4 * (eval_count / self.budget)\n\n            neighborhood_scale = np.clip(0.9 - 0.7 * (eval_count / self.budget), 0.25, 0.9)\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate * neighborhood_scale, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "GADELPlusPlus", "description": "G-ADEL++ combines stochastic elitism with adaptive neighborhood search for enhanced convergence.", "configspace": "", "generation": 89, "fitness": 0.2710226428603221, "feedback": "The algorithm GADELPlusPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.19.", "error": "", "parent_id": "20f7e403-df06-4bed-826a-e1edfc2d2c16", "metadata": {"aucs": [0.6190190035923784, 0.6190190035923784, 0.6190190035923784, 0.636740120320997, 0.636740120320997, 0.636740120320997, 0.6316149161573494, 0.6316149161573494, 0.6316149161573494, 0.3561547474016742, 0.3561547474016742, 0.3561547474016742, 0.3789600366283896, 0.3789600366283896, 0.3789600366283896, 0.377168509857031, 0.377168509857031, 0.377168509857031, 0.10737055433394505, 0.10737055433394505, 0.10737055433394505, 0.0992199743611234, 0.0992199743611234, 0.0992199743611234, 0.10114508671345224, 0.10114508671345224, 0.10114508671345224, 0.08441462266452149, 0.08441462266452149, 0.08441462266452149, 0.0830903943159419, 0.0830903943159419, 0.0830903943159419, 0.08186944553345621, 0.08186944553345621, 0.08186944553345621, 0.7001904117425205, 0.7001904117425205, 0.7001904117425205, 0.87591514058389, 0.87591514058389, 0.87591514058389, 0.9104332662147225, 0.9104332662147225, 0.9104332662147225, 0.2840586980969704, 0.2840586980969704, 0.2840586980969704, 0.28330172492848116, 0.28330172492848116, 0.28330172492848116, 0.25895456057421096, 0.25895456057421096, 0.25895456057421096, 0.4725302566081363, 0.4725302566081363, 0.4725302566081363, 0.6180930393609033, 0.6180930393609033, 0.6180930393609033, 0.5925562172716092, 0.5925562172716092, 0.5925562172716092, 0.1908513025114904, 0.1908513025114904, 0.1908513025114904, 0.15240426119291828, 0.15240426119291828, 0.15240426119291828, 0.20562116413137654, 0.20562116413137654, 0.20562116413137654, 0.22404622004347552, 0.22404622004347552, 0.22404622004347552, 0.19509324011923113, 0.19509324011923113, 0.19509324011923113, 0.1684705787883799, 0.1684705787883799, 0.1684705787883799, 0.18318094567146026, 0.18318094567146026, 0.18318094567146026, 0.14471594175208702, 0.14471594175208702, 0.14471594175208702, 0.18133845686141392, 0.18133845686141392, 0.18133845686141392, 0.359010940415176, 0.359010940415176, 0.359010940415176, 0.274847250457648, 0.274847250457648, 0.274847250457648, 0.27759389689489433, 0.27759389689489433, 0.27759389689489433, 0.036073382995522985, 0.036073382995522985, 0.036073382995522985, 0.041843992162868604, 0.041843992162868604, 0.041843992162868604, 0.07187905486593593, 0.07187905486593593, 0.07187905486593593, 0.16953032583709404, 0.16953032583709404, 0.16953032583709404, 0.1750883610989351, 0.1750883610989351, 0.1750883610989351, 0.16030965899539884, 0.16030965899539884, 0.16030965899539884, 0.46835701181722467, 0.46835701181722467, 0.46835701181722467, 0.46682450598969716, 0.46682450598969716, 0.46682450598969716, 0.4465350776581687, 0.4465350776581687, 0.4465350776581687, 0.08752419674502221, 0.08752419674502221, 0.08752419674502221, 0.11880122864611442, 0.11880122864611442, 0.11880122864611442, 0.09581677301390978, 0.09581677301390978, 0.09581677301390978, 0.1704967049429984, 0.1704967049429984, 0.1704967049429984, 0.19674801331295633, 0.19674801331295633, 0.19674801331295633, 0.1725218186516133, 0.1725218186516133, 0.1725218186516133, 0.279644855275877, 0.279644855275877, 0.279644855275877, 0.2692610215176904, 0.2692610215176904, 0.2692610215176904, 0.29342831532739877, 0.29342831532739877, 0.29342831532739877, 0.21891399407118384, 0.21891399407118384, 0.21891399407118384, 0.21809896464239642, 0.21809896464239642, 0.21809896464239642, 0.23886708077053276, 0.23886708077053276, 0.23886708077053276, 0.20969880412024933, 0.20969880412024933, 0.20969880412024933, 0.1790690381515314, 0.1790690381515314, 0.1790690381515314, 0.1958833720983827, 0.1958833720983827, 0.1958833720983827, 0.17694612690730627, 0.17694612690730627, 0.17694612690730627, 0.19913020380144963, 0.19913020380144963, 0.19913020380144963, 0.18269699006036633, 0.18269699006036633, 0.18269699006036633, 0.5382077006634634, 0.5382077006634634, 0.5382077006634634, 0.3977396100792626, 0.3977396100792626, 0.3977396100792626, 0.39533925653265356, 0.39533925653265356, 0.39533925653265356, 0.19854272787125116, 0.19854272787125116, 0.19854272787125116, 0.34858816676295457, 0.34858816676295457, 0.34858816676295457, 0.2014588710526306, 0.2014588710526306, 0.2014588710526306, 0.20317090073035693, 0.20317090073035693, 0.20317090073035693, 0.18089018728354744, 0.18089018728354744, 0.18089018728354744, 0.17274251211763803, 0.17274251211763803, 0.17274251211763803, 0.07532756813379471, 0.07532756813379471, 0.07532756813379471, 0.07489049335256437, 0.07489049335256437, 0.07489049335256437, 0.07676849178399336, 0.07676849178399336, 0.07676849178399336]}, "mutation_prompt": null}
{"id": "d14dadd5-d489-4dc3-8d81-a78728d82b4c", "solution": "import numpy as np\n\nclass GADEL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 8)\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                intensity_factor = 1 + 0.05 * np.sin(2 * np.pi * eval_count / self.budget)\n                F_dynamic = (self.F + np.random.normal(0, 0.05)) * intensity_factor\n                mutant = np.clip(x0 + F_dynamic * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                CR_dynamic = self.CR + 0.1 * np.sin(eval_count / self.budget * np.pi)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            if eval_count % (self.population_size * 2) == 0:\n                self.F = 0.4 + 0.25 * (eval_count / self.budget)\n                self.CR = 0.9 - 0.35 * (eval_count / self.budget)\n\n            neighborhood_scale = np.clip(0.8 - 0.6 * (eval_count / self.budget), 0.2, 0.8)\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate * neighborhood_scale, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "GADEL", "description": "GADEL-PI incorporates a periodic intensity factor to modulate mutation strength dynamically, enhancing exploration-exploitation balance.", "configspace": "", "generation": 90, "fitness": 0.3923033437427441, "feedback": "The algorithm GADEL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.26.", "error": "", "parent_id": "20f7e403-df06-4bed-826a-e1edfc2d2c16", "metadata": {"aucs": [0.8000115101593614, 0.8000115101593614, 0.8000115101593614, 0.7878767019892874, 0.7878767019892874, 0.7878767019892874, 0.8048412990649214, 0.8048412990649214, 0.8048412990649214, 0.6537717140889379, 0.6537717140889379, 0.6537717140889379, 0.639849248253022, 0.639849248253022, 0.639849248253022, 0.6575838857202254, 0.6575838857202254, 0.6575838857202254, 0.11572212046191122, 0.11572212046191122, 0.11572212046191122, 0.13146590440961403, 0.13146590440961403, 0.13146590440961403, 0.11111322348736885, 0.11111322348736885, 0.11111322348736885, 0.11115394532430023, 0.11115394532430023, 0.11115394532430023, 0.11283747196031768, 0.11283747196031768, 0.11283747196031768, 0.10130567998006967, 0.10130567998006967, 0.10130567998006967, 0.7344262126782819, 0.7344262126782819, 0.7344262126782819, 0.8334331786973287, 0.8334331786973287, 0.8334331786973287, 0.7865259698235169, 0.7865259698235169, 0.7865259698235169, 0.3112886682865631, 0.3112886682865631, 0.3112886682865631, 0.24171082825590118, 0.24171082825590118, 0.24171082825590118, 0.2527377369211693, 0.2527377369211693, 0.2527377369211693, 0.7998963197900942, 0.7998963197900942, 0.7998963197900942, 0.830486701667188, 0.830486701667188, 0.830486701667188, 0.8373882107076444, 0.8373882107076444, 0.8373882107076444, 0.16430322182886303, 0.16430322182886303, 0.16430322182886303, 0.20860220613610403, 0.20860220613610403, 0.20860220613610403, 0.22683922461750494, 0.22683922461750494, 0.22683922461750494, 0.304693574646577, 0.304693574646577, 0.304693574646577, 0.2864172081120724, 0.2864172081120724, 0.2864172081120724, 0.18370245708182809, 0.18370245708182809, 0.18370245708182809, 0.5776492366674733, 0.5776492366674733, 0.5776492366674733, 0.5731408666256884, 0.5731408666256884, 0.5731408666256884, 0.5454541470564842, 0.5454541470564842, 0.5454541470564842, 0.6534590482244949, 0.6534590482244949, 0.6534590482244949, 0.6720247670478676, 0.6720247670478676, 0.6720247670478676, 0.7020731007888458, 0.7020731007888458, 0.7020731007888458, 0.1547027498912179, 0.1547027498912179, 0.1547027498912179, 0.17363739649728305, 0.17363739649728305, 0.17363739649728305, 0.16981450137878018, 0.16981450137878018, 0.16981450137878018, 0.48033248026962605, 0.48033248026962605, 0.48033248026962605, 0.46911935729207044, 0.46911935729207044, 0.46911935729207044, 0.4552362341571542, 0.4552362341571542, 0.4552362341571542, 0.7733469490769442, 0.7733469490769442, 0.7733469490769442, 0.7593531085751879, 0.7593531085751879, 0.7593531085751879, 0.7862515521643785, 0.7862515521643785, 0.7862515521643785, 0.11096806248890478, 0.11096806248890478, 0.11096806248890478, 0.11026680944421219, 0.11026680944421219, 0.11026680944421219, 0.11555316495324075, 0.11555316495324075, 0.11555316495324075, 0.18383761066878979, 0.18383761066878979, 0.18383761066878979, 0.18887829810656076, 0.18887829810656076, 0.18887829810656076, 0.19152012336385993, 0.19152012336385993, 0.19152012336385993, 0.47128515482130795, 0.47128515482130795, 0.47128515482130795, 0.4920354833048022, 0.4920354833048022, 0.4920354833048022, 0.49035682696908944, 0.49035682696908944, 0.49035682696908944, 0.41608169203433243, 0.41608169203433243, 0.41608169203433243, 0.3854312783265793, 0.3854312783265793, 0.3854312783265793, 0.35639202744875964, 0.35639202744875964, 0.35639202744875964, 0.20759808992476825, 0.20759808992476825, 0.20759808992476825, 0.23002388778773286, 0.23002388778773286, 0.23002388778773286, 0.1908601394280176, 0.1908601394280176, 0.1908601394280176, 0.20641360459664004, 0.20641360459664004, 0.20641360459664004, 0.22332929436728766, 0.22332929436728766, 0.22332929436728766, 0.3596760145646689, 0.3596760145646689, 0.3596760145646689, 0.8434363597599588, 0.8434363597599588, 0.8434363597599588, 0.1936414724641149, 0.1936414724641149, 0.1936414724641149, 0.7251814336765902, 0.7251814336765902, 0.7251814336765902, 0.18974539981214278, 0.18974539981214278, 0.18974539981214278, 0.19930913054430854, 0.19930913054430854, 0.19930913054430854, 0.37920231725798426, 0.37920231725798426, 0.37920231725798426, 0.17929265446335907, 0.17929265446335907, 0.17929265446335907, 0.17503470885724293, 0.17503470885724293, 0.17503470885724293, 0.18380465446003047, 0.18380465446003047, 0.18380465446003047, 0.08010872827931048, 0.08010872827931048, 0.08010872827931048, 0.09348875026823245, 0.09348875026823245, 0.09348875026823245, 0.09750765717127974, 0.09750765717127974, 0.09750765717127974]}, "mutation_prompt": null}
{"id": "9cf8dc1d-489a-43a0-9fb6-b13b3519fab0", "solution": "import numpy as np\n\nclass GADEL_EL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 8)\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.elite_ratio = 0.1\n        self.adaptive_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        num_elites = max(1, int(self.elite_ratio * self.population_size))\n        elites = np.argpartition(fitness, num_elites)[:num_elites]\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                intensity_factor = 1 + 0.05 * np.cos(2 * np.pi * eval_count / self.budget)\n                F_dynamic = (self.F + np.random.normal(0, 0.03)) * intensity_factor\n                mutant = np.clip(x0 + F_dynamic * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                CR_dynamic = self.CR + 0.05 * np.sin(eval_count / self.budget * np.pi)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            adapt_factor = 0.2 * (1 - eval_count / self.budget)\n            self.F = max(0.4, self.F - self.adaptive_rate * adapt_factor)\n            self.CR = min(0.95, self.CR + self.adaptive_rate * adapt_factor)\n            \n            # Elite preservation and exploration\n            for e in elites:\n                neighborhood = np.clip(population[e] + np.random.normal(0, adapt_factor, self.dim), self.lower_bound, self.upper_bound)\n                f_neighborhood = func(neighborhood)\n                eval_count += 1\n                if f_neighborhood < fitness[e]:\n                    population[e] = neighborhood\n                    fitness[e] = f_neighborhood\n                    if f_neighborhood < fitness[best_idx]:\n                        best = neighborhood\n                        fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "GADEL_EL", "description": "GADEL-EL integrates an elite preservation mechanism and adaptive step size adjustments to enhance convergence speed and solution quality.", "configspace": "", "generation": 91, "fitness": 0.38650428609270154, "feedback": "The algorithm GADEL_EL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.26.", "error": "", "parent_id": "d14dadd5-d489-4dc3-8d81-a78728d82b4c", "metadata": {"aucs": [0.7816180551305293, 0.7816180551305293, 0.7816180551305293, 0.8002370930793813, 0.8002370930793813, 0.8002370930793813, 0.7960152283769497, 0.7960152283769497, 0.7960152283769497, 0.5988477496461817, 0.5988477496461817, 0.5988477496461817, 0.5078782544087106, 0.5078782544087106, 0.5078782544087106, 0.669074916423372, 0.669074916423372, 0.669074916423372, 0.25976797232342863, 0.25976797232342863, 0.25976797232342863, 0.10970694571911976, 0.10970694571911976, 0.10970694571911976, 0.11880139681873769, 0.11880139681873769, 0.11880139681873769, 0.10072337752436211, 0.10072337752436211, 0.10072337752436211, 0.09212081682652729, 0.09212081682652729, 0.09212081682652729, 0.09939103325012932, 0.09939103325012932, 0.09939103325012932, 0.7879212694952896, 0.7879212694952896, 0.7879212694952896, 0.8618684722217562, 0.8618684722217562, 0.8618684722217562, 0.8058916628106518, 0.8058916628106518, 0.8058916628106518, 0.3006945280494546, 0.3006945280494546, 0.3006945280494546, 0.3136414298826168, 0.3136414298826168, 0.3136414298826168, 0.3185824051179631, 0.3185824051179631, 0.3185824051179631, 0.8049212833900624, 0.8049212833900624, 0.8049212833900624, 0.8157831276454681, 0.8157831276454681, 0.8157831276454681, 0.8319732688664783, 0.8319732688664783, 0.8319732688664783, 0.1497789329153142, 0.1497789329153142, 0.1497789329153142, 0.24795862875283536, 0.24795862875283536, 0.24795862875283536, 0.177174773802257, 0.177174773802257, 0.177174773802257, 0.23221673792674413, 0.23221673792674413, 0.23221673792674413, 0.22184513252825855, 0.22184513252825855, 0.22184513252825855, 0.16010393716392168, 0.16010393716392168, 0.16010393716392168, 0.5405793514927062, 0.5405793514927062, 0.5405793514927062, 0.584424702745282, 0.584424702745282, 0.584424702745282, 0.6109752973707574, 0.6109752973707574, 0.6109752973707574, 0.7017690882785002, 0.7017690882785002, 0.7017690882785002, 0.675681123646463, 0.675681123646463, 0.675681123646463, 0.6834222105290857, 0.6834222105290857, 0.6834222105290857, 0.2057172846980967, 0.2057172846980967, 0.2057172846980967, 0.4037182866989638, 0.4037182866989638, 0.4037182866989638, 0.1329916910335367, 0.1329916910335367, 0.1329916910335367, 0.24083343785542188, 0.24083343785542188, 0.24083343785542188, 0.3119556947852886, 0.3119556947852886, 0.3119556947852886, 0.4780576983882956, 0.4780576983882956, 0.4780576983882956, 0.7740018728423378, 0.7740018728423378, 0.7740018728423378, 0.7577418610529179, 0.7577418610529179, 0.7577418610529179, 0.783904584809043, 0.783904584809043, 0.783904584809043, 0.13772205261055848, 0.13772205261055848, 0.13772205261055848, 0.12269079036464559, 0.12269079036464559, 0.12269079036464559, 0.11556736055467554, 0.11556736055467554, 0.11556736055467554, 0.16017148770890255, 0.16017148770890255, 0.16017148770890255, 0.15193253888294767, 0.15193253888294767, 0.15193253888294767, 0.23604144202770727, 0.23604144202770727, 0.23604144202770727, 0.47933432594102576, 0.47933432594102576, 0.47933432594102576, 0.47791798325371015, 0.47791798325371015, 0.47791798325371015, 0.49159888808260477, 0.49159888808260477, 0.49159888808260477, 0.4276782191854642, 0.4276782191854642, 0.4276782191854642, 0.4018574573908469, 0.4018574573908469, 0.4018574573908469, 0.38657595694846125, 0.38657595694846125, 0.38657595694846125, 0.20634996072504075, 0.20634996072504075, 0.20634996072504075, 0.20684730361606007, 0.20684730361606007, 0.20684730361606007, 0.21461610882121118, 0.21461610882121118, 0.21461610882121118, 0.21864113364400561, 0.21864113364400561, 0.21864113364400561, 0.1931805306147868, 0.1931805306147868, 0.1931805306147868, 0.18771866318186825, 0.18771866318186825, 0.18771866318186825, 0.8390621292063136, 0.8390621292063136, 0.8390621292063136, 0.18266340337476794, 0.18266340337476794, 0.18266340337476794, 0.16796405574429685, 0.16796405574429685, 0.16796405574429685, 0.7599950670942177, 0.7599950670942177, 0.7599950670942177, 0.20376449553283504, 0.20376449553283504, 0.20376449553283504, 0.20317169979697502, 0.20317169979697502, 0.20317169979697502, 0.18760119233344108, 0.18760119233344108, 0.18760119233344108, 0.18184435467097304, 0.18184435467097304, 0.18184435467097304, 0.19178326951968394, 0.19178326951968394, 0.19178326951968394, 0.07862827319180177, 0.07862827319180177, 0.07862827319180177, 0.0825762614659763, 0.0825762614659763, 0.0825762614659763, 0.08249957686550624, 0.08249957686550624, 0.08249957686550624]}, "mutation_prompt": null}
{"id": "2e9a81f7-3216-4b9f-82c7-a0a595fbd7e4", "solution": "import numpy as np\n\nclass GADEL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 8)\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                intensity_factor = 1 + 0.1 * np.sin(4 * np.pi * eval_count / self.budget)\n                F_dynamic = (self.F + np.random.normal(0, 0.05)) * intensity_factor\n                mutant = np.clip(x0 + F_dynamic * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                CR_dynamic = self.CR + 0.15 * np.cos(eval_count / self.budget * np.pi)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            if eval_count % (self.population_size * 2) == 0:\n                self.F = 0.4 + 0.3 * (eval_count / self.budget)\n                self.CR = 0.85 - 0.35 * (eval_count / self.budget)\n\n            neighborhood_scale = np.clip(0.7 - 0.5 * (eval_count / self.budget), 0.2, 0.7)\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate * neighborhood_scale, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "GADEL", "description": "GADEL-PII enhances convergence speed by dynamically adjusting mutation and crossover strategies using multi-phase adaptive factors. ", "configspace": "", "generation": 92, "fitness": 0.36502793316873056, "feedback": "The algorithm GADEL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.24.", "error": "", "parent_id": "d14dadd5-d489-4dc3-8d81-a78728d82b4c", "metadata": {"aucs": [0.815781706557918, 0.815781706557918, 0.815781706557918, 0.7909616708153824, 0.7909616708153824, 0.7909616708153824, 0.8185273792575891, 0.8185273792575891, 0.8185273792575891, 0.661513940431204, 0.661513940431204, 0.661513940431204, 0.6657544107179728, 0.6657544107179728, 0.6657544107179728, 0.6756503646756387, 0.6756503646756387, 0.6756503646756387, 0.14565492088304854, 0.14565492088304854, 0.14565492088304854, 0.14936385267582997, 0.14936385267582997, 0.14936385267582997, 0.150161046507456, 0.150161046507456, 0.150161046507456, 0.12705806422797172, 0.12705806422797172, 0.12705806422797172, 0.10715774423092395, 0.10715774423092395, 0.10715774423092395, 0.13037641582587167, 0.13037641582587167, 0.13037641582587167, 0.7513640271415163, 0.7513640271415163, 0.7513640271415163, 0.722888020503629, 0.722888020503629, 0.722888020503629, 0.7959718979209699, 0.7959718979209699, 0.7959718979209699, 0.37639230429249615, 0.37639230429249615, 0.37639230429249615, 0.3414834351162115, 0.3414834351162115, 0.3414834351162115, 0.32955181021971136, 0.32955181021971136, 0.32955181021971136, 0.8137940316059009, 0.8137940316059009, 0.8137940316059009, 0.8164457799510103, 0.8164457799510103, 0.8164457799510103, 0.8454207939126521, 0.8454207939126521, 0.8454207939126521, 0.14779651586197873, 0.14779651586197873, 0.14779651586197873, 0.20112201585493772, 0.20112201585493772, 0.20112201585493772, 0.223130121530422, 0.223130121530422, 0.223130121530422, 0.20314588648460374, 0.20314588648460374, 0.20314588648460374, 0.18006420540156343, 0.18006420540156343, 0.18006420540156343, 0.18482551346341525, 0.18482551346341525, 0.18482551346341525, 0.4606470666820496, 0.4606470666820496, 0.4606470666820496, 0.48119743301861395, 0.48119743301861395, 0.48119743301861395, 0.20622670651003672, 0.20622670651003672, 0.20622670651003672, 0.6387961633390038, 0.6387961633390038, 0.6387961633390038, 0.5773760573222997, 0.5773760573222997, 0.5773760573222997, 0.698810714914648, 0.698810714914648, 0.698810714914648, 0.13322593041135677, 0.13322593041135677, 0.13322593041135677, 0.15195226197300238, 0.15195226197300238, 0.15195226197300238, 0.22533181728807117, 0.22533181728807117, 0.22533181728807117, 0.3412222243739479, 0.3412222243739479, 0.3412222243739479, 0.33477392201991696, 0.33477392201991696, 0.33477392201991696, 0.3395129590614724, 0.3395129590614724, 0.3395129590614724, 0.7132062219002688, 0.7132062219002688, 0.7132062219002688, 0.7033346654801733, 0.7033346654801733, 0.7033346654801733, 0.6698276352578627, 0.6698276352578627, 0.6698276352578627, 0.1272710798979131, 0.1272710798979131, 0.1272710798979131, 0.11778962778995827, 0.11778962778995827, 0.11778962778995827, 0.1136810772627066, 0.1136810772627066, 0.1136810772627066, 0.23454053649700612, 0.23454053649700612, 0.23454053649700612, 0.17946304333387075, 0.17946304333387075, 0.17946304333387075, 0.16730859933962927, 0.16730859933962927, 0.16730859933962927, 0.4487348129026565, 0.4487348129026565, 0.4487348129026565, 0.43416344397514717, 0.43416344397514717, 0.43416344397514717, 0.47434025529865265, 0.47434025529865265, 0.47434025529865265, 0.3345404840388687, 0.3345404840388687, 0.3345404840388687, 0.33411750934009055, 0.33411750934009055, 0.33411750934009055, 0.35717422554037015, 0.35717422554037015, 0.35717422554037015, 0.20277738323881644, 0.20277738323881644, 0.20277738323881644, 0.20780919379291418, 0.20780919379291418, 0.20780919379291418, 0.19282493641523346, 0.19282493641523346, 0.19282493641523346, 0.32546437742884304, 0.32546437742884304, 0.32546437742884304, 0.2020125150872205, 0.2020125150872205, 0.2020125150872205, 0.347366962081158, 0.347366962081158, 0.347366962081158, 0.840838056942472, 0.840838056942472, 0.840838056942472, 0.18854487271711629, 0.18854487271711629, 0.18854487271711629, 0.17902161020234308, 0.17902161020234308, 0.17902161020234308, 0.2010803124339995, 0.2010803124339995, 0.2010803124339995, 0.20422862431939626, 0.20422862431939626, 0.20422862431939626, 0.20290713353067358, 0.20290713353067358, 0.20290713353067358, 0.1796993819080548, 0.1796993819080548, 0.1796993819080548, 0.18209128999961788, 0.18209128999961788, 0.18209128999961788, 0.1780051750761642, 0.1780051750761642, 0.1780051750761642, 0.08836951907025892, 0.08836951907025892, 0.08836951907025892, 0.09579442788847792, 0.09579442788847792, 0.09579442788847792, 0.0932510651784243, 0.0932510651784243, 0.0932510651784243]}, "mutation_prompt": null}
{"id": "b92e7cd9-b8fb-45bb-9fb0-6b4f64b018b9", "solution": "import numpy as np\n\nclass GADEL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 8)\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                decay_factor = np.exp(-eval_count / self.budget)\n                F_dynamic = self.F * (1 + 0.1 * np.sin(2 * np.pi * eval_count / self.budget)) * decay_factor\n                mutant = np.clip(x0 + F_dynamic * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                CR_dynamic = self.CR * (1 - 0.2 * np.cos(eval_count / self.budget * np.pi))\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            if eval_count % (self.population_size * 2) == 0:\n                self.F = 0.3 + 0.3 * (eval_count / self.budget)\n                self.CR = 0.8 - 0.4 * (eval_count / self.budget)\n\n            neighborhood_scale = np.clip(0.8 - 0.5 * (eval_count / self.budget), 0.2, 0.8)\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate * neighborhood_scale, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "GADEL", "description": "GADEL-PIF introduces adaptive scaling in differential evolution to enhance convergence by dynamically adjusting mutation and crossover parameters based on the evaluation progress.", "configspace": "", "generation": 93, "fitness": 0.33878780377423723, "feedback": "The algorithm GADEL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.24.", "error": "", "parent_id": "d14dadd5-d489-4dc3-8d81-a78728d82b4c", "metadata": {"aucs": [0.8098826502567213, 0.8098826502567213, 0.8098826502567213, 0.8057519584945393, 0.8057519584945393, 0.8057519584945393, 0.8350320200630375, 0.8350320200630375, 0.8350320200630375, 0.5341532203437546, 0.5341532203437546, 0.5341532203437546, 0.6822704020616355, 0.6822704020616355, 0.6822704020616355, 0.6737945487468568, 0.6737945487468568, 0.6737945487468568, 0.2277136633173109, 0.2277136633173109, 0.2277136633173109, 0.401171688645906, 0.401171688645906, 0.401171688645906, 0.27229914204910954, 0.27229914204910954, 0.27229914204910954, 0.1932288089220855, 0.1932288089220855, 0.1932288089220855, 0.13467382989572485, 0.13467382989572485, 0.13467382989572485, 0.131637028713658, 0.131637028713658, 0.131637028713658, 0.8775763035450812, 0.8775763035450812, 0.8775763035450812, 0.9119519800675262, 0.9119519800675262, 0.9119519800675262, 0.8305463670166993, 0.8305463670166993, 0.8305463670166993, 0.31874750808189833, 0.31874750808189833, 0.31874750808189833, 0.29330991586779054, 0.29330991586779054, 0.29330991586779054, 0.27244996757594653, 0.27244996757594653, 0.27244996757594653, 0.6535177752677217, 0.6535177752677217, 0.6535177752677217, 0.6602891562483009, 0.6602891562483009, 0.6602891562483009, 0.6823147197463006, 0.6823147197463006, 0.6823147197463006, 0.18385501288118333, 0.18385501288118333, 0.18385501288118333, 0.1527984963978426, 0.1527984963978426, 0.1527984963978426, 0.29525979598763774, 0.29525979598763774, 0.29525979598763774, 0.19301737210246261, 0.19301737210246261, 0.19301737210246261, 0.1474177307515383, 0.1474177307515383, 0.1474177307515383, 0.157890688056619, 0.157890688056619, 0.157890688056619, 0.06875954361519021, 0.06875954361519021, 0.06875954361519021, 0.04708331555039347, 0.04708331555039347, 0.04708331555039347, 0.0318305820732101, 0.0318305820732101, 0.0318305820732101, 0.1528175016895903, 0.1528175016895903, 0.1528175016895903, 0.11549843644617064, 0.11549843644617064, 0.11549843644617064, 0.17325796609531785, 0.17325796609531785, 0.17325796609531785, 0.08277525909202177, 0.08277525909202177, 0.08277525909202177, 0.058084424218950326, 0.058084424218950326, 0.058084424218950326, 0.11736393783129406, 0.11736393783129406, 0.11736393783129406, 0.19456034134527977, 0.19456034134527977, 0.19456034134527977, 0.2080833446302076, 0.2080833446302076, 0.2080833446302076, 0.22886633117142663, 0.22886633117142663, 0.22886633117142663, 0.5925355557027505, 0.5925355557027505, 0.5925355557027505, 0.5284954788912108, 0.5284954788912108, 0.5284954788912108, 0.5457175523549704, 0.5457175523549704, 0.5457175523549704, 0.12288133435817872, 0.12288133435817872, 0.12288133435817872, 0.1297306154153839, 0.1297306154153839, 0.1297306154153839, 0.12237333383966831, 0.12237333383966831, 0.12237333383966831, 0.1800765213573341, 0.1800765213573341, 0.1800765213573341, 0.15817961874865671, 0.15817961874865671, 0.15817961874865671, 0.17868589588107298, 0.17868589588107298, 0.17868589588107298, 0.41555198315960096, 0.41555198315960096, 0.41555198315960096, 0.42856447109892404, 0.42856447109892404, 0.42856447109892404, 0.4868542831345464, 0.4868542831345464, 0.4868542831345464, 0.31523119705770064, 0.31523119705770064, 0.31523119705770064, 0.3008964169285424, 0.3008964169285424, 0.3008964169285424, 0.3828176556938021, 0.3828176556938021, 0.3828176556938021, 0.2038853862606328, 0.2038853862606328, 0.2038853862606328, 0.20372452456273527, 0.20372452456273527, 0.20372452456273527, 0.20439933790028908, 0.20439933790028908, 0.20439933790028908, 0.24448090195164418, 0.24448090195164418, 0.24448090195164418, 0.40472827734621386, 0.40472827734621386, 0.40472827734621386, 0.4334622684596823, 0.4334622684596823, 0.4334622684596823, 0.766713652478771, 0.766713652478771, 0.766713652478771, 0.7029991301018796, 0.7029991301018796, 0.7029991301018796, 0.6598155442338816, 0.6598155442338816, 0.6598155442338816, 0.46184800825659866, 0.46184800825659866, 0.46184800825659866, 0.2021303088210583, 0.2021303088210583, 0.2021303088210583, 0.3949940942589395, 0.3949940942589395, 0.3949940942589395, 0.17932627709481863, 0.17932627709481863, 0.17932627709481863, 0.1921085636600085, 0.1921085636600085, 0.1921085636600085, 0.18385253405023338, 0.18385253405023338, 0.18385253405023338, 0.08990840426822233, 0.08990840426822233, 0.08990840426822233, 0.08112473463430747, 0.08112473463430747, 0.08112473463430747, 0.08309527491888025, 0.08309527491888025, 0.08309527491888025]}, "mutation_prompt": null}
{"id": "38508173-918c-4614-a2ff-cf6ef0713c78", "solution": "import numpy as np\n\nclass GADEL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 8)\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                intensity_factor = 1 + 0.05 * np.exp(-eval_count / (self.budget / 3))  # Exponential adjustment\n                F_dynamic = (self.F + np.random.normal(0, 0.05)) * intensity_factor\n                mutant = np.clip(x0 + F_dynamic * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                CR_dynamic = self.CR + 0.1 * np.sin(eval_count / self.budget * np.pi)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            if eval_count % (self.population_size * 2) == 0:\n                self.F = 0.4 + 0.25 * (eval_count / self.budget)\n                self.CR = 0.9 - 0.35 * (eval_count / self.budget)\n\n            neighborhood_scale = np.clip(0.8 - 0.6 * (eval_count / self.budget), 0.2, 0.8)\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate * neighborhood_scale, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "GADEL", "description": "GADEL-EI introduces an exponential intensity factor adjustment to enhance convergence speed dynamically.", "configspace": "", "generation": 94, "fitness": 0.4015655192892308, "feedback": "The algorithm GADEL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.26.", "error": "", "parent_id": "d14dadd5-d489-4dc3-8d81-a78728d82b4c", "metadata": {"aucs": [0.8100832181011646, 0.8100832181011646, 0.8100832181011646, 0.7972885869694009, 0.7972885869694009, 0.7972885869694009, 0.8086425010717018, 0.8086425010717018, 0.8086425010717018, 0.6203785784885356, 0.6203785784885356, 0.6203785784885356, 0.6714052536336776, 0.6714052536336776, 0.6714052536336776, 0.6652174656434665, 0.6652174656434665, 0.6652174656434665, 0.1279875985264629, 0.1279875985264629, 0.1279875985264629, 0.14888626320151632, 0.14888626320151632, 0.14888626320151632, 0.12337006152760988, 0.12337006152760988, 0.12337006152760988, 0.10973653892193747, 0.10973653892193747, 0.10973653892193747, 0.1122583219847586, 0.1122583219847586, 0.1122583219847586, 0.12217823581702392, 0.12217823581702392, 0.12217823581702392, 0.9073154453703386, 0.9073154453703386, 0.9073154453703386, 0.9383021205701818, 0.9383021205701818, 0.9383021205701818, 0.783117170371081, 0.783117170371081, 0.783117170371081, 0.44962717739911706, 0.44962717739911706, 0.44962717739911706, 0.41160202781003585, 0.41160202781003585, 0.41160202781003585, 0.31784002215614504, 0.31784002215614504, 0.31784002215614504, 0.8037593579162018, 0.8037593579162018, 0.8037593579162018, 0.811013882976348, 0.811013882976348, 0.811013882976348, 0.8052955034609306, 0.8052955034609306, 0.8052955034609306, 0.1228822071357567, 0.1228822071357567, 0.1228822071357567, 0.1434109336743653, 0.1434109336743653, 0.1434109336743653, 0.22788684668219417, 0.22788684668219417, 0.22788684668219417, 0.15231458418958443, 0.15231458418958443, 0.15231458418958443, 0.22020022458361632, 0.22020022458361632, 0.22020022458361632, 0.23565276635865084, 0.23565276635865084, 0.23565276635865084, 0.550067962293741, 0.550067962293741, 0.550067962293741, 0.6300342719193136, 0.6300342719193136, 0.6300342719193136, 0.5942716413960691, 0.5942716413960691, 0.5942716413960691, 0.6870086721962312, 0.6870086721962312, 0.6870086721962312, 0.6466631765087656, 0.6466631765087656, 0.6466631765087656, 0.6713368054148614, 0.6713368054148614, 0.6713368054148614, 0.17844192768596223, 0.17844192768596223, 0.17844192768596223, 0.24593985805306107, 0.24593985805306107, 0.24593985805306107, 0.19620346228769125, 0.19620346228769125, 0.19620346228769125, 0.5037527615440325, 0.5037527615440325, 0.5037527615440325, 0.45460697452503573, 0.45460697452503573, 0.45460697452503573, 0.1506796322320253, 0.1506796322320253, 0.1506796322320253, 0.7721200070219445, 0.7721200070219445, 0.7721200070219445, 0.772160094393954, 0.772160094393954, 0.772160094393954, 0.7761058244636341, 0.7761058244636341, 0.7761058244636341, 0.12026847356313697, 0.12026847356313697, 0.12026847356313697, 0.1289852994717572, 0.1289852994717572, 0.1289852994717572, 0.12725329384233042, 0.12725329384233042, 0.12725329384233042, 0.16066075233968424, 0.16066075233968424, 0.16066075233968424, 0.25118674031963806, 0.25118674031963806, 0.25118674031963806, 0.21656546049010117, 0.21656546049010117, 0.21656546049010117, 0.4663998379687966, 0.4663998379687966, 0.4663998379687966, 0.48645859619298104, 0.48645859619298104, 0.48645859619298104, 0.48763648190760067, 0.48763648190760067, 0.48763648190760067, 0.4011456047287154, 0.4011456047287154, 0.4011456047287154, 0.39639625640734366, 0.39639625640734366, 0.39639625640734366, 0.4218754627420601, 0.4218754627420601, 0.4218754627420601, 0.17959569398718744, 0.17959569398718744, 0.17959569398718744, 0.20666161431653507, 0.20666161431653507, 0.20666161431653507, 0.21948704182496726, 0.21948704182496726, 0.21948704182496726, 0.29776758317361585, 0.29776758317361585, 0.29776758317361585, 0.18335358537714408, 0.18335358537714408, 0.18335358537714408, 0.19824241489692396, 0.19824241489692396, 0.19824241489692396, 0.856371687295117, 0.856371687295117, 0.856371687295117, 0.6367201078792544, 0.6367201078792544, 0.6367201078792544, 0.4534721175013565, 0.4534721175013565, 0.4534721175013565, 0.31139175381008044, 0.31139175381008044, 0.31139175381008044, 0.1945304446101993, 0.1945304446101993, 0.1945304446101993, 0.4160527931302871, 0.4160527931302871, 0.4160527931302871, 0.18863973284530666, 0.18863973284530666, 0.18863973284530666, 0.19272658133418785, 0.19272658133418785, 0.19272658133418785, 0.17932130910838373, 0.17932130910838373, 0.17932130910838373, 0.08365199629745479, 0.08365199629745479, 0.08365199629745479, 0.08894938087064708, 0.08894938087064708, 0.08894938087064708, 0.0839033241136945, 0.0839033241136945, 0.0839033241136945]}, "mutation_prompt": null}
{"id": "0bc95821-9aef-4203-a318-8df4528e1f36", "solution": "import numpy as np\n\nclass DE_GADEL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(50, budget // 10)\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                F = 0.5 + 0.1 * np.sin(eval_count / self.budget * np.pi)  # Adaptive mutation factor\n                mutant = np.clip(x0 + F * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                CR = 0.9 - 0.4 * (eval_count / self.budget)  # Dynamic crossover probability\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            if eval_count % self.population_size == 0:\n                self.learning_rate = 0.05 + 0.15 * (eval_count / self.budget)\n\n            neighborhood_scale = np.clip(0.7 - 0.5 * (eval_count / self.budget), 0.2, 0.7)\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate * neighborhood_scale, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "DE_GADEL", "description": "DE-GADEL incorporates adaptive mutation strategies and dynamic parameter tuning to accelerate convergence speed in black box optimization.", "configspace": "", "generation": 95, "fitness": 0.30595097470784133, "feedback": "The algorithm DE_GADEL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.23.", "error": "", "parent_id": "38508173-918c-4614-a2ff-cf6ef0713c78", "metadata": {"aucs": [0.8025648684593526, 0.8025648684593526, 0.8025648684593526, 0.7839401694054756, 0.7839401694054756, 0.7839401694054756, 0.8057853571427381, 0.8057853571427381, 0.8057853571427381, 0.6341487224789163, 0.6341487224789163, 0.6341487224789163, 0.615615915863317, 0.615615915863317, 0.615615915863317, 0.6233027590737916, 0.6233027590737916, 0.6233027590737916, 0.14215694954048375, 0.14215694954048375, 0.14215694954048375, 0.13715805241545864, 0.13715805241545864, 0.13715805241545864, 0.13178846152794244, 0.13178846152794244, 0.13178846152794244, 0.11724201137284163, 0.11724201137284163, 0.11724201137284163, 0.12618920084289909, 0.12618920084289909, 0.12618920084289909, 0.1338376799363894, 0.1338376799363894, 0.1338376799363894, 0.8822662652489495, 0.8822662652489495, 0.8822662652489495, 0.8979987163126392, 0.8979987163126392, 0.8979987163126392, 0.8996184238686039, 0.8996184238686039, 0.8996184238686039, 0.4069022522381417, 0.4069022522381417, 0.4069022522381417, 0.3842439138452928, 0.3842439138452928, 0.3842439138452928, 0.41185616901877686, 0.41185616901877686, 0.41185616901877686, 0.62308826195283, 0.62308826195283, 0.62308826195283, 0.6528604680437342, 0.6528604680437342, 0.6528604680437342, 0.6638034979826315, 0.6638034979826315, 0.6638034979826315, 0.23796888501958124, 0.23796888501958124, 0.23796888501958124, 0.18216126600818616, 0.18216126600818616, 0.18216126600818616, 0.1830140763838609, 0.1830140763838609, 0.1830140763838609, 0.16024357667704658, 0.16024357667704658, 0.16024357667704658, 0.24002918472610912, 0.24002918472610912, 0.24002918472610912, 0.20832592614194978, 0.20832592614194978, 0.20832592614194978, 0.08439633955775061, 0.08439633955775061, 0.08439633955775061, 0.08605968104066797, 0.08605968104066797, 0.08605968104066797, 0.0905446594738063, 0.0905446594738063, 0.0905446594738063, 0.2075572884831376, 0.2075572884831376, 0.2075572884831376, 0.2101539718093286, 0.2101539718093286, 0.2101539718093286, 0.2527794945720926, 0.2527794945720926, 0.2527794945720926, 0.04466204568657117, 0.04466204568657117, 0.04466204568657117, 0.028384182730009755, 0.028384182730009755, 0.028384182730009755, 0.055934054442400516, 0.055934054442400516, 0.055934054442400516, 0.18132297926035845, 0.18132297926035845, 0.18132297926035845, 0.20719135924199095, 0.20719135924199095, 0.20719135924199095, 0.1726251066878951, 0.1726251066878951, 0.1726251066878951, 0.5403454770112993, 0.5403454770112993, 0.5403454770112993, 0.5304295584094674, 0.5304295584094674, 0.5304295584094674, 0.5302429489651896, 0.5302429489651896, 0.5302429489651896, 0.11564348351571174, 0.11564348351571174, 0.11564348351571174, 0.12312143290121236, 0.12312143290121236, 0.12312143290121236, 0.1204960278717292, 0.1204960278717292, 0.1204960278717292, 0.17278744361999565, 0.17278744361999565, 0.17278744361999565, 0.18212492339007635, 0.18212492339007635, 0.18212492339007635, 0.15126780769303128, 0.15126780769303128, 0.15126780769303128, 0.3564313472887449, 0.3564313472887449, 0.3564313472887449, 0.32246582436962, 0.32246582436962, 0.32246582436962, 0.36487844999968555, 0.36487844999968555, 0.36487844999968555, 0.23036473991689665, 0.23036473991689665, 0.23036473991689665, 0.2189732300828714, 0.2189732300828714, 0.2189732300828714, 0.25751321225656043, 0.25751321225656043, 0.25751321225656043, 0.18571341260510188, 0.18571341260510188, 0.18571341260510188, 0.18753675801912928, 0.18753675801912928, 0.18753675801912928, 0.19410295898915808, 0.19410295898915808, 0.19410295898915808, 0.19952009783129854, 0.19952009783129854, 0.19952009783129854, 0.19868397277524796, 0.19868397277524796, 0.19868397277524796, 0.19447301996093713, 0.19447301996093713, 0.19447301996093713, 0.6941708521800651, 0.6941708521800651, 0.6941708521800651, 0.19112671850483398, 0.19112671850483398, 0.19112671850483398, 0.25767107722840077, 0.25767107722840077, 0.25767107722840077, 0.5296598704578823, 0.5296598704578823, 0.5296598704578823, 0.27931153610953185, 0.27931153610953185, 0.27931153610953185, 0.1866325652546057, 0.1866325652546057, 0.1866325652546057, 0.18602175033136115, 0.18602175033136115, 0.18602175033136115, 0.194979038636239, 0.194979038636239, 0.194979038636239, 0.18626751586458445, 0.18626751586458445, 0.18626751586458445, 0.08167935547763738, 0.08167935547763738, 0.08167935547763738, 0.07889019266202357, 0.07889019266202357, 0.07889019266202357, 0.07522138427049396, 0.07522138427049396, 0.07522138427049396]}, "mutation_prompt": null}
{"id": "b8e9469b-641b-441e-9575-6b9dfedd768d", "solution": "import numpy as np\nfrom sklearn.ensemble import RandomForestRegressor\n\nclass GADEL_HE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 8)\n        self.F = 0.5\n        self.CR = 0.9\n        self.learning_rate = 0.1\n        self.model = RandomForestRegressor(n_estimators=10, random_state=42)\n\n    def __call__(self, func):\n        np.random.seed(42)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            # Train surrogate model intermittently\n            if eval_count % (self.population_size * 4) == 0:\n                self.model.fit(population, fitness)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                F_dynamic = (self.F + np.random.normal(0, 0.05)) * (1 + 0.05 * np.exp(-eval_count / (self.budget / 3)))\n                mutant = np.clip(x0 + F_dynamic * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                CR_dynamic = self.CR + 0.1 * np.cos(eval_count / self.budget * np.pi)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Use surrogate prediction with small probability\n                if np.random.rand() < 0.1 and hasattr(self.model, 'predict'):\n                    f_trial = self.model.predict(trial.reshape(1, -1))[0]\n                else:\n                    f_trial = func(trial)\n                    eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            if eval_count % (self.population_size * 2) == 0:\n                self.F = 0.4 + 0.25 * (eval_count / self.budget)\n                self.CR = 0.9 - 0.35 * (eval_count / self.budget)\n\n            neighborhood_scale = np.clip(0.8 - 0.6 * (eval_count / self.budget), 0.2, 0.8)\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate * neighborhood_scale, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "GADEL_HE", "description": "GADEL-HE adopts a hybrid exploration strategy combining adaptive differential evolution with random forest surrogate modeling for enhanced convergence.", "configspace": "", "generation": 96, "fitness": -Infinity, "feedback": "An exception occurred: ModuleNotFoundError(\"No module named 'sklearn'\").", "error": "ModuleNotFoundError(\"No module named 'sklearn'\")", "parent_id": "38508173-918c-4614-a2ff-cf6ef0713c78", "metadata": {}, "mutation_prompt": null}
{"id": "66f52a0d-0809-4c31-8d53-0ddabe9957c9", "solution": "import numpy as np\n\nclass GADEL_VC:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 8)\n        self.F = 0.5  # Differential weight\n        self.CR_min = 0.6\n        self.CR_max = 0.95\n        self.CR = self.CR_max\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                intensity_factor = 1 + 0.05 * np.exp(-eval_count / (self.budget / 3))  # Exponential adjustment\n                F_dynamic = (self.F + np.random.normal(0, 0.05)) * intensity_factor\n                mutant = np.clip(x0 + F_dynamic * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                CR_dynamic = self.CR_min + (self.CR_max - self.CR_min) * (1 - np.exp(-eval_count / self.budget))\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            if eval_count % (self.population_size * 2) == 0:\n                self.F = 0.4 + 0.25 * (eval_count / self.budget)\n                self.CR = self.CR_min + (self.CR_max - self.CR_min) * (1 - eval_count / self.budget)\n\n            neighborhood_scale = np.clip(0.8 - 0.6 * (eval_count / self.budget), 0.2, 0.8)\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate * neighborhood_scale, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "GADEL_VC", "description": "GADEL-VC introduces a variable crossover rate strategy to balance exploration and exploitation dynamically.", "configspace": "", "generation": 97, "fitness": 0.3152563911382195, "feedback": "The algorithm GADEL_VC got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.23.", "error": "", "parent_id": "38508173-918c-4614-a2ff-cf6ef0713c78", "metadata": {"aucs": [0.789660616215637, 0.789660616215637, 0.789660616215637, 0.7875732930004463, 0.7875732930004463, 0.7875732930004463, 0.7846197417483909, 0.7846197417483909, 0.7846197417483909, 0.60144159358989, 0.60144159358989, 0.60144159358989, 0.6110019064946903, 0.6110019064946903, 0.6110019064946903, 0.6160910579494986, 0.6160910579494986, 0.6160910579494986, 0.16056688390365526, 0.16056688390365526, 0.16056688390365526, 0.16517337430265522, 0.16517337430265522, 0.16517337430265522, 0.1634415991878193, 0.1634415991878193, 0.1634415991878193, 0.13863157551515382, 0.13863157551515382, 0.13863157551515382, 0.13869275497142408, 0.13869275497142408, 0.13869275497142408, 0.1159414986611721, 0.1159414986611721, 0.1159414986611721, 0.9197043912691406, 0.9197043912691406, 0.9197043912691406, 0.9301333048924503, 0.9301333048924503, 0.9301333048924503, 0.9515751767446924, 0.9515751767446924, 0.9515751767446924, 0.39121705589850075, 0.39121705589850075, 0.39121705589850075, 0.3870494363449095, 0.3870494363449095, 0.3870494363449095, 0.38349289777563667, 0.38349289777563667, 0.38349289777563667, 0.6480737161790902, 0.6480737161790902, 0.6480737161790902, 0.61544834779939, 0.61544834779939, 0.61544834779939, 0.6178432085920769, 0.6178432085920769, 0.6178432085920769, 0.19626461261733408, 0.19626461261733408, 0.19626461261733408, 0.18513712584768582, 0.18513712584768582, 0.18513712584768582, 0.22765249227650852, 0.22765249227650852, 0.22765249227650852, 0.16391873991393568, 0.16391873991393568, 0.16391873991393568, 0.17227035847977334, 0.17227035847977334, 0.17227035847977334, 0.19246265272296503, 0.19246265272296503, 0.19246265272296503, 0.07691975299409426, 0.07691975299409426, 0.07691975299409426, 0.10014395566823409, 0.10014395566823409, 0.10014395566823409, 0.0650534736234697, 0.0650534736234697, 0.0650534736234697, 0.18019895422496335, 0.18019895422496335, 0.18019895422496335, 0.21345566576182207, 0.21345566576182207, 0.21345566576182207, 0.22385301202951724, 0.22385301202951724, 0.22385301202951724, 0.030961551622654238, 0.030961551622654238, 0.030961551622654238, 0.057367953925127724, 0.057367953925127724, 0.057367953925127724, 0.08150168896436993, 0.08150168896436993, 0.08150168896436993, 0.1526124985241173, 0.1526124985241173, 0.1526124985241173, 0.18791319635550396, 0.18791319635550396, 0.18791319635550396, 0.17310632037488083, 0.17310632037488083, 0.17310632037488083, 0.563243234753658, 0.563243234753658, 0.563243234753658, 0.5489051707671417, 0.5489051707671417, 0.5489051707671417, 0.5599173744471408, 0.5599173744471408, 0.5599173744471408, 0.10766193074568986, 0.10766193074568986, 0.10766193074568986, 0.11339977772725329, 0.11339977772725329, 0.11339977772725329, 0.11613370023299485, 0.11613370023299485, 0.11613370023299485, 0.17166568873446963, 0.17166568873446963, 0.17166568873446963, 0.21378487752622055, 0.21378487752622055, 0.21378487752622055, 0.16562589562946228, 0.16562589562946228, 0.16562589562946228, 0.36357500044319546, 0.36357500044319546, 0.36357500044319546, 0.3464094319401805, 0.3464094319401805, 0.3464094319401805, 0.36685197575324124, 0.36685197575324124, 0.36685197575324124, 0.2449739864150261, 0.2449739864150261, 0.2449739864150261, 0.23861048506950566, 0.23861048506950566, 0.23861048506950566, 0.2493035003451527, 0.2493035003451527, 0.2493035003451527, 0.1895334455134865, 0.1895334455134865, 0.1895334455134865, 0.22351387129255695, 0.22351387129255695, 0.22351387129255695, 0.19487034848217621, 0.19487034848217621, 0.19487034848217621, 0.20779455820272008, 0.20779455820272008, 0.20779455820272008, 0.21612686633684552, 0.21612686633684552, 0.21612686633684552, 0.27409259624580595, 0.27409259624580595, 0.27409259624580595, 0.6820487924791383, 0.6820487924791383, 0.6820487924791383, 0.42548687580356004, 0.42548687580356004, 0.42548687580356004, 0.4597831716269176, 0.4597831716269176, 0.4597831716269176, 0.4791566485220161, 0.4791566485220161, 0.4791566485220161, 0.22344717392179492, 0.22344717392179492, 0.22344717392179492, 0.34454020024227827, 0.34454020024227827, 0.34454020024227827, 0.17915554587503446, 0.17915554587503446, 0.17915554587503446, 0.1924145313289829, 0.1924145313289829, 0.1924145313289829, 0.19904569293598195, 0.19904569293598195, 0.19904569293598195, 0.08256695949147308, 0.08256695949147308, 0.08256695949147308, 0.07687270948946456, 0.07687270948946456, 0.07687270948946456, 0.07978070666795922, 0.07978070666795922, 0.07978070666795922]}, "mutation_prompt": null}
{"id": "e8062d2c-0dce-4de9-8ac0-93456d50e556", "solution": "import numpy as np\n\nclass GADEL_AC:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 8)\n        self.F = 0.6  # Initial differential weight\n        self.CR = 0.8  # Initial crossover probability\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                \n                F_dynamic = self.F * np.cos(np.pi * eval_count / self.budget)\n                mutant = np.clip(x0 + F_dynamic * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                CR_dynamic = self.CR * np.exp(-0.5 * (eval_count / self.budget))\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            if eval_count % (self.population_size * 3) == 0:\n                self.F = 0.5 + 0.2 * np.sin(eval_count / self.budget * np.pi)\n                self.CR = 0.8 + 0.1 * np.cos(eval_count / self.budget * np.pi)\n\n            neighborhood_scale = np.clip(0.7 - 0.5 * (eval_count / self.budget), 0.1, 0.7)\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate * neighborhood_scale, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "GADEL_AC", "description": "GADEL-AC leverages adaptive crossover and mutation rates to balance exploration and exploitation dynamically.", "configspace": "", "generation": 98, "fitness": 0.3099491731410636, "feedback": "The algorithm GADEL_AC got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.23.", "error": "", "parent_id": "38508173-918c-4614-a2ff-cf6ef0713c78", "metadata": {"aucs": [0.7570192931160987, 0.7570192931160987, 0.7570192931160987, 0.7767020442225768, 0.7767020442225768, 0.7767020442225768, 0.7778235565372578, 0.7778235565372578, 0.7778235565372578, 0.5724235845813188, 0.5724235845813188, 0.5724235845813188, 0.6129531660999057, 0.6129531660999057, 0.6129531660999057, 0.5954673849729174, 0.5954673849729174, 0.5954673849729174, 0.3975297003460341, 0.3975297003460341, 0.3975297003460341, 0.43507087286918633, 0.43507087286918633, 0.43507087286918633, 0.3570201660487937, 0.3570201660487937, 0.3570201660487937, 0.14139555660413994, 0.14139555660413994, 0.14139555660413994, 0.33207821212158917, 0.33207821212158917, 0.33207821212158917, 0.346150075670989, 0.346150075670989, 0.346150075670989, 0.9580537724854452, 0.9580537724854452, 0.9580537724854452, 0.9569572189091358, 0.9569572189091358, 0.9569572189091358, 0.9319560746963036, 0.9319560746963036, 0.9319560746963036, 0.27189303189745306, 0.27189303189745306, 0.27189303189745306, 0.2726099642849038, 0.2726099642849038, 0.2726099642849038, 0.2725019002810344, 0.2725019002810344, 0.2725019002810344, 0.5459959652634815, 0.5459959652634815, 0.5459959652634815, 0.3254120354903496, 0.3254120354903496, 0.3254120354903496, 0.5976778433305949, 0.5976778433305949, 0.5976778433305949, 0.16849299762135417, 0.16849299762135417, 0.16849299762135417, 0.16380117675810035, 0.16380117675810035, 0.16380117675810035, 0.16233991991948038, 0.16233991991948038, 0.16233991991948038, 0.14137235054111008, 0.14137235054111008, 0.14137235054111008, 0.13578591515016503, 0.13578591515016503, 0.13578591515016503, 0.14459546813033408, 0.14459546813033408, 0.14459546813033408, 0.042007378195191625, 0.042007378195191625, 0.042007378195191625, 0.018054700126068246, 0.018054700126068246, 0.018054700126068246, 0.0330491715216602, 0.0330491715216602, 0.0330491715216602, 0.18036704105409496, 0.18036704105409496, 0.18036704105409496, 0.11345236854641405, 0.11345236854641405, 0.11345236854641405, 0.22423168371404256, 0.22423168371404256, 0.22423168371404256, 0.03747164327411012, 0.03747164327411012, 0.03747164327411012, 0.04109866591308475, 0.04109866591308475, 0.04109866591308475, 0.019272552450589342, 0.019272552450589342, 0.019272552450589342, 0.1651926178303642, 0.1651926178303642, 0.1651926178303642, 0.16940759183424958, 0.16940759183424958, 0.16940759183424958, 0.13916236034107132, 0.13916236034107132, 0.13916236034107132, 0.5354326987620444, 0.5354326987620444, 0.5354326987620444, 0.5130198294817461, 0.5130198294817461, 0.5130198294817461, 0.5272243499461118, 0.5272243499461118, 0.5272243499461118, 0.12225511180070026, 0.12225511180070026, 0.12225511180070026, 0.15194493692898925, 0.15194493692898925, 0.15194493692898925, 0.146096637495146, 0.146096637495146, 0.146096637495146, 0.16746696910969627, 0.16746696910969627, 0.16746696910969627, 0.2064633630963083, 0.2064633630963083, 0.2064633630963083, 0.1619726892100709, 0.1619726892100709, 0.1619726892100709, 0.3324696487330069, 0.3324696487330069, 0.3324696487330069, 0.3309248378827804, 0.3309248378827804, 0.3309248378827804, 0.43775067509563703, 0.43775067509563703, 0.43775067509563703, 0.2568277487342121, 0.2568277487342121, 0.2568277487342121, 0.24435158554649605, 0.24435158554649605, 0.24435158554649605, 0.28054403426588237, 0.28054403426588237, 0.28054403426588237, 0.19502209619512323, 0.19502209619512323, 0.19502209619512323, 0.1901862443761161, 0.1901862443761161, 0.1901862443761161, 0.19244811494541325, 0.19244811494541325, 0.19244811494541325, 0.34670239453457896, 0.34670239453457896, 0.34670239453457896, 0.34391381298240253, 0.34391381298240253, 0.34391381298240253, 0.4451349184493759, 0.4451349184493759, 0.4451349184493759, 0.5106182862957496, 0.5106182862957496, 0.5106182862957496, 0.40510782977783255, 0.40510782977783255, 0.40510782977783255, 0.361508521567775, 0.361508521567775, 0.361508521567775, 0.19404310042782302, 0.19404310042782302, 0.19404310042782302, 0.1935842219643077, 0.1935842219643077, 0.1935842219643077, 0.3871492022642129, 0.3871492022642129, 0.3871492022642129, 0.17877934769987258, 0.17877934769987258, 0.17877934769987258, 0.1831052296109622, 0.1831052296109622, 0.1831052296109622, 0.19073953932361443, 0.19073953932361443, 0.19073953932361443, 0.08180158291235606, 0.08180158291235606, 0.08180158291235606, 0.08643937324569995, 0.08643937324569995, 0.08643937324569995, 0.08146451074354188, 0.08146451074354188, 0.08146451074354188]}, "mutation_prompt": null}
{"id": "b5f1aa38-348b-405f-a8be-1d47ebe17a90", "solution": "import numpy as np\n\nclass GADEL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(60, budget // 8)\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                intensity_factor = 1 + 0.06 * np.exp(-eval_count / (self.budget / 2.8))  # Fine-tuned adjustment\n                F_dynamic = (self.F + np.random.normal(0, 0.05)) * intensity_factor\n                mutant = np.clip(x0 + F_dynamic * (x1 - x2), self.lower_bound, self.upper_bound)\n\n                CR_dynamic = self.CR + 0.1 * np.sin(eval_count / self.budget * np.pi)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                eval_count += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if f_trial < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n            if eval_count % (self.population_size * 2) == 0:\n                self.F = 0.4 + 0.25 * (eval_count / self.budget)\n                self.CR = 0.9 - 0.35 * (eval_count / self.budget)\n\n            neighborhood_scale = np.clip(0.75 - 0.55 * (eval_count / self.budget), 0.2, 0.8)  # Adjusted scale\n            neighborhood = np.clip(best + np.random.normal(0, self.learning_rate * neighborhood_scale, self.dim), self.lower_bound, self.upper_bound)\n            f_neighborhood = func(neighborhood)\n            eval_count += 1\n            if f_neighborhood < fitness[best_idx]:\n                best = neighborhood\n                fitness[best_idx] = f_neighborhood\n\n        return best, fitness[best_idx]", "name": "GADEL", "description": "GADEL-EI-Adapt refines intensity factor and neighborhood scale adjustments for enhanced search efficiency.", "configspace": "", "generation": 99, "fitness": 0.39440785079959867, "feedback": "The algorithm GADEL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.26.", "error": "", "parent_id": "38508173-918c-4614-a2ff-cf6ef0713c78", "metadata": {"aucs": [0.8004112346883723, 0.8004112346883723, 0.8004112346883723, 0.7896164217558009, 0.7896164217558009, 0.7896164217558009, 0.8208769260172661, 0.8208769260172661, 0.8208769260172661, 0.6571524957537365, 0.6571524957537365, 0.6571524957537365, 0.6654703131478539, 0.6654703131478539, 0.6654703131478539, 0.6616624048600686, 0.6616624048600686, 0.6616624048600686, 0.13581210788934894, 0.13581210788934894, 0.13581210788934894, 0.12024133448210816, 0.12024133448210816, 0.12024133448210816, 0.13673573618217394, 0.13673573618217394, 0.13673573618217394, 0.11904685516343705, 0.11904685516343705, 0.11904685516343705, 0.10276686200987228, 0.10276686200987228, 0.10276686200987228, 0.10834649048860323, 0.10834649048860323, 0.10834649048860323, 0.7366081460599759, 0.7366081460599759, 0.7366081460599759, 0.938494024715044, 0.938494024715044, 0.938494024715044, 0.7819464688885814, 0.7819464688885814, 0.7819464688885814, 0.32284338887841224, 0.32284338887841224, 0.32284338887841224, 0.3434462956336708, 0.3434462956336708, 0.3434462956336708, 0.29456234098217093, 0.29456234098217093, 0.29456234098217093, 0.7905251630241654, 0.7905251630241654, 0.7905251630241654, 0.8378700783559323, 0.8378700783559323, 0.8378700783559323, 0.784302807233956, 0.784302807233956, 0.784302807233956, 0.15330017722719258, 0.15330017722719258, 0.15330017722719258, 0.1345238041568888, 0.1345238041568888, 0.1345238041568888, 0.1928097735625427, 0.1928097735625427, 0.1928097735625427, 0.1518988103469292, 0.1518988103469292, 0.1518988103469292, 0.24361723285171222, 0.24361723285171222, 0.24361723285171222, 0.17557615357708178, 0.17557615357708178, 0.17557615357708178, 0.5916446491909813, 0.5916446491909813, 0.5916446491909813, 0.5855360107693107, 0.5855360107693107, 0.5855360107693107, 0.5905321903548388, 0.5905321903548388, 0.5905321903548388, 0.6929488174623062, 0.6929488174623062, 0.6929488174623062, 0.6499040688772999, 0.6499040688772999, 0.6499040688772999, 0.6721770185793821, 0.6721770185793821, 0.6721770185793821, 0.18655974404063247, 0.18655974404063247, 0.18655974404063247, 0.41966849846652043, 0.41966849846652043, 0.41966849846652043, 0.1678239180791845, 0.1678239180791845, 0.1678239180791845, 0.4215726904927458, 0.4215726904927458, 0.4215726904927458, 0.3595680368096563, 0.3595680368096563, 0.3595680368096563, 0.37660332146919995, 0.37660332146919995, 0.37660332146919995, 0.7776114559217137, 0.7776114559217137, 0.7776114559217137, 0.7658858699290634, 0.7658858699290634, 0.7658858699290634, 0.7836177909294537, 0.7836177909294537, 0.7836177909294537, 0.1242777864472695, 0.1242777864472695, 0.1242777864472695, 0.12513224643448084, 0.12513224643448084, 0.12513224643448084, 0.1259666275983714, 0.1259666275983714, 0.1259666275983714, 0.1603820504898955, 0.1603820504898955, 0.1603820504898955, 0.21832884387780105, 0.21832884387780105, 0.21832884387780105, 0.16525260922632756, 0.16525260922632756, 0.16525260922632756, 0.4370923226477126, 0.4370923226477126, 0.4370923226477126, 0.45983190021352893, 0.45983190021352893, 0.45983190021352893, 0.4432189948754274, 0.4432189948754274, 0.4432189948754274, 0.4035317719854985, 0.4035317719854985, 0.4035317719854985, 0.3694449487288026, 0.3694449487288026, 0.3694449487288026, 0.40897857420067374, 0.40897857420067374, 0.40897857420067374, 0.2119645838876203, 0.2119645838876203, 0.2119645838876203, 0.1971631117335667, 0.1971631117335667, 0.1971631117335667, 0.2185453392464234, 0.2185453392464234, 0.2185453392464234, 0.22104361049017407, 0.22104361049017407, 0.22104361049017407, 0.23921258648718735, 0.23921258648718735, 0.23921258648718735, 0.2337147655956101, 0.2337147655956101, 0.2337147655956101, 0.822211120126413, 0.822211120126413, 0.822211120126413, 0.6610448801384964, 0.6610448801384964, 0.6610448801384964, 0.702942097361495, 0.702942097361495, 0.702942097361495, 0.20377132560673727, 0.20377132560673727, 0.20377132560673727, 0.19641607456818932, 0.19641607456818932, 0.19641607456818932, 0.20130675860430147, 0.20130675860430147, 0.20130675860430147, 0.18882082475769157, 0.18882082475769157, 0.18882082475769157, 0.1743977891332732, 0.1743977891332732, 0.1743977891332732, 0.17623157995414152, 0.17623157995414152, 0.17623157995414152, 0.09351363002112123, 0.09351363002112123, 0.09351363002112123, 0.08367133072758337, 0.08367133072758337, 0.08367133072758337, 0.08783724310009988, 0.08783724310009988, 0.08783724310009988]}, "mutation_prompt": null}

{"id": "602f878f-4592-4d0e-94c6-92654bfd4701", "solution": "import numpy as np\n\nclass AdaptiveMemoryPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initialize_particles()\n\n    def initialize_particles(self):\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def update_velocities(self, w, c1, c2):\n        r1, r2 = np.random.rand(self.num_particles, self.dim), np.random.rand(self.num_particles, self.dim)\n        cognitive_component = c1 * r1 * (self.personal_best_positions - self.positions)\n        social_component = c2 * r2 * (self.global_best_position - self.positions)\n        self.velocities = w * self.velocities + cognitive_component + social_component\n\n    def update_positions(self):\n        self.positions += self.velocities\n        np.clip(self.positions, self.lower_bound, self.upper_bound, out=self.positions)\n\n    def evaluate_particles(self, func):\n        scores = np.apply_along_axis(func, 1, self.positions)\n        better_mask = scores < self.personal_best_scores\n        self.personal_best_positions[better_mask] = self.positions[better_mask]\n        self.personal_best_scores[better_mask] = scores[better_mask]\n        min_score_index = np.argmin(scores)\n        if scores[min_score_index] < self.global_best_score:\n            self.global_best_score = scores[min_score_index]\n            self.global_best_position = self.positions[min_score_index]\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            w = 0.9 - 0.7 * (evaluations / self.budget)\n            c1, c2 = 2.0, 2.0\n            self.update_velocities(w, c1, c2)\n            self.update_positions()\n            self.evaluate_particles(func)\n            evaluations += self.num_particles\n        return self.global_best_position", "name": "AdaptiveMemoryPSO", "description": "An adaptive memory-enhanced particle swarm optimization (PSO) leveraging historical best positions and a dynamic inertia weight strategy to efficiently explore and exploit the search space.", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/scratch/hyin/LLaMEA/llamea/llamea.py\", line 187, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/scratch/hyin/LLaMEA/llamea/llamea.py\", line 264, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"mutation_exp.py\", line 52, in evaluateBBOB\n    algorithm(problem)\n  File \"<string>\", line 45, in __call__\n  File \"<string>\", line 23, in update_velocities\nTypeError: unsupported operand type(s) for -: 'NoneType' and 'float'\n.", "error": "TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\")Traceback (most recent call last):\n  File \"/scratch/hyin/LLaMEA/llamea/llamea.py\", line 187, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/scratch/hyin/LLaMEA/llamea/llamea.py\", line 264, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"mutation_exp.py\", line 52, in evaluateBBOB\n    algorithm(problem)\n  File \"<string>\", line 45, in __call__\n  File \"<string>\", line 23, in update_velocities\nTypeError: unsupported operand type(s) for -: 'NoneType' and 'float'\n", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "00eb93c8-c436-45a2-b69a-083537e7bf15", "solution": "import numpy as np\n\nclass AdaptiveMemoryPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initialize_particles()\n\n    def initialize_particles(self):\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def update_velocities(self, w, c1, c2):\n        r1, r2 = np.random.rand(self.num_particles, self.dim), np.random.rand(self.num_particles, self.dim)\n        cognitive_component = c1 * r1 * (self.personal_best_positions - self.positions)\n        social_component = c2 * r2 * (self.global_best_position - self.positions)\n        self.velocities = w * self.velocities + cognitive_component + social_component\n\n    def update_positions(self):\n        self.positions += self.velocities\n        np.clip(self.positions, self.lower_bound, self.upper_bound, out=self.positions)\n\n    def evaluate_particles(self, func):\n        scores = np.apply_along_axis(func, 1, self.positions)\n        better_mask = scores < self.personal_best_scores\n        self.personal_best_positions[better_mask] = self.positions[better_mask]\n        self.personal_best_scores[better_mask] = scores[better_mask]\n        min_score_index = np.argmin(scores)\n        if scores[min_score_index] < self.global_best_score:\n            self.global_best_score = scores[min_score_index]\n            self.global_best_position = self.positions[min_score_index]\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            w = 0.9 - 0.5 * (np.sin((evaluations/self.budget) * np.pi))  # Nonlinear inertia weight\n            c1 = 1.5 + (2.0 - 1.5) * (evaluations / self.budget)         # Adaptive cognitive coefficient\n            c2 = 2.5 - (2.5 - 1.5) * (evaluations / self.budget)         # Adaptive social coefficient\n            self.update_velocities(w, c1, c2)\n            self.update_positions()\n            self.evaluate_particles(func)\n            evaluations += self.num_particles\n        return self.global_best_position", "name": "AdaptiveMemoryPSO", "description": "A modified adaptive memory-enhanced PSO utilizing a nonlinear inertia weight and adaptive cognitive and social coefficients for improved convergence.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\").", "error": "TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\")", "parent_id": "602f878f-4592-4d0e-94c6-92654bfd4701", "metadata": {}, "mutation_prompt": null}

{"id": "9d5c860a-1891-4c62-8858-28e77752a23b", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // (5 * dim))  # Adaptive population size\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.7    # Inertia weight\n        self.f = 0.5    # DE scaling factor\n        self.cr = 0.9   # DE crossover probability\n        \n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        population = np.random.uniform(\n            self.lower_bound, self.upper_bound, (self.population_size, self.dim)\n        )\n        velocities = np.random.uniform(\n            -(self.upper_bound - self.lower_bound), \n            self.upper_bound - self.lower_bound, \n            (self.population_size, self.dim)\n        )\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n                \n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < self.cr\n                trial[crossover] = mutant[crossover]\n                \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    \n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n            \n            # Particle Swarm Optimization update\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best[i] - population[i])\n                    + self.c2 * r2 * (global_best - population[i])\n                )\n                population[i] = np.clip(\n                    population[i] + velocities[i], self.lower_bound, self.upper_bound\n                )\n                score = func(population[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = score\n                    \n                    if score < global_best_score:\n                        global_best = population[i]\n                        global_best_score = score\n                \n                if evaluations >= self.budget:\n                    break\n                \n        return global_best, global_best_score", "name": "HybridDEPSO", "description": "The algorithm is a hybrid of Differential Evolution and Particle Swarm Optimization incorporating adaptive parameters for exploration and exploitation balance.", "configspace": "", "generation": 0, "fitness": 0.17622765305763163, "feedback": "", "error": "", "parent_id": null, "metadata": {"aucs": [0.434769408373638, 0.434769408373638, 0.434769408373638, 0.4015602382189114, 0.4015602382189114, 0.4015602382189114, 0.1742890041564158, 0.1742890041564158, 0.1742890041564158, 0.02293962590987053, 0.02293962590987053, 0.02293962590987053, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0009003408778497368, 0.0009003408778497368, 0.0009003408778497368, 0.09550151125617867, 0.09550151125617867, 0.09550151125617867, 0.08156292270598664, 0.08156292270598664, 0.08156292270598664, 0.07063109697936398, 0.07063109697936398, 0.07063109697936398, 0.08440549072682912, 0.08440549072682912, 0.08440549072682912, 0.06944120747611049, 0.06944120747611049, 0.06944120747611049, 0.07084216678743838, 0.07084216678743838, 0.07084216678743838, 0.9811592230303531, 0.9811592230303531, 0.9811592230303531, 0.9875328641063893, 0.9875328641063893, 0.9875328641063893, 0.9882169640529754, 0.9882169640529754, 0.9882169640529754, 0.096989332205762, 0.096989332205762, 0.096989332205762, 0.13450475109552085, 0.13450475109552085, 0.13450475109552085, 0.08812891090820707, 0.08812891090820707, 0.08812891090820707, 0.2266605599392315, 0.2266605599392315, 0.2266605599392315, 0.1819137368839573, 0.1819137368839573, 0.1819137368839573, 0.13547293587687326, 0.13547293587687326, 0.13547293587687326, 0.11332574423952213, 0.11332574423952213, 0.11332574423952213, 0.10769751877494327, 0.10769751877494327, 0.10769751877494327, 0.07750875742900587, 0.07750875742900587, 0.07750875742900587, 0.09534016473324503, 0.09534016473324503, 0.09534016473324503, 0.1153694182124313, 0.1153694182124313, 0.1153694182124313, 0.08839993255486955, 0.08839993255486955, 0.08839993255486955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06784585386428277, 0.06784585386428277, 0.06784585386428277, 0.04355616059475542, 0.04355616059475542, 0.04355616059475542, 0.022066747733763492, 0.022066747733763492, 0.022066747733763492, 0.0006867284673840457, 0.0006867284673840457, 0.0006867284673840457, 0.0009796352772456496, 0.0009796352772456496, 0.0009796352772456496, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08739966243211583, 0.08739966243211583, 0.08739966243211583, 0.09621597907051149, 0.09621597907051149, 0.09621597907051149, 0.03976523223130479, 0.03976523223130479, 0.03976523223130479, 0.3519732317547314, 0.3519732317547314, 0.3519732317547314, 0.3460264605554678, 0.3460264605554678, 0.3460264605554678, 0.3284795026062365, 0.3284795026062365, 0.3284795026062365, 0.08197847463701347, 0.08197847463701347, 0.08197847463701347, 0.07952588170630692, 0.07952588170630692, 0.07952588170630692, 0.0685012643029822, 0.0685012643029822, 0.0685012643029822, 0.1585502208155385, 0.1585502208155385, 0.1585502208155385, 0.1660037045337578, 0.1660037045337578, 0.1660037045337578, 0.17332006362950236, 0.17332006362950236, 0.17332006362950236, 0.21919156315363564, 0.21919156315363564, 0.21919156315363564, 0.23639487737778087, 0.23639487737778087, 0.23639487737778087, 0.21599444431156578, 0.21599444431156578, 0.21599444431156578, 0.19973965611309308, 0.19973965611309308, 0.19973965611309308, 0.16923050996277111, 0.16923050996277111, 0.16923050996277111, 0.169869800256372, 0.169869800256372, 0.169869800256372, 0.17562598322689338, 0.17562598322689338, 0.17562598322689338, 0.18920013662737478, 0.18920013662737478, 0.18920013662737478, 0.17778383062732628, 0.17778383062732628, 0.17778383062732628, 0.16533880598722028, 0.16533880598722028, 0.16533880598722028, 0.18085679289146706, 0.18085679289146706, 0.18085679289146706, 0.1684994247727738, 0.1684994247727738, 0.1684994247727738, 0.16582489451552296, 0.16582489451552296, 0.16582489451552296, 0.16240709346593307, 0.16240709346593307, 0.16240709346593307, 0.49186909268020484, 0.49186909268020484, 0.49186909268020484, 0.16533761792313018, 0.16533761792313018, 0.16533761792313018, 0.47205373272643303, 0.47205373272643303, 0.47205373272643303, 0.11387572729328799, 0.11387572729328799, 0.11387572729328799, 0.19002667909278248, 0.19002667909278248, 0.19002667909278248, 0.18562846448090253, 0.18562846448090253, 0.18562846448090253, 0.1905553189968785, 0.1905553189968785, 0.1905553189968785, 0.06609861552497565, 0.06609861552497565, 0.06609861552497565, 0.08605173765167051, 0.08605173765167051, 0.08605173765167051, 0.09249758876470315, 0.09249758876470315, 0.09249758876470315]}, "mutation_prompt": null}
{"id": "18c144b1-61b2-4703-b05f-5660a0983716", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, budget // (5 * dim))  # Adaptive population size\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.7    # Inertia weight\n        self.f = 0.5    # DE scaling factor\n        self.cr = 0.9   # DE crossover probability\n        \n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        population = np.random.uniform(\n            self.lower_bound, self.upper_bound, (self.population_size, self.dim)\n        )\n        velocities = np.random.uniform(\n            -(self.upper_bound - self.lower_bound), \n            self.upper_bound - self.lower_bound, \n            (self.population_size, self.dim)\n        )\n        personal_best = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best = personal_best[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n                \n                trial = np.copy(population[i])\n                crossover = np.random.rand(self.dim) < self.cr\n                trial[crossover] = mutant[crossover]\n                \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    \n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n            \n            # Particle Swarm Optimization update\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best[i] - population[i])\n                    + self.c2 * r2 * (global_best - population[i])\n                )\n                population[i] = np.clip(\n                    population[i] + velocities[i], self.lower_bound, self.upper_bound\n                )\n                score = func(population[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = score\n                    \n                    if score < global_best_score:\n                        global_best = population[i]\n                        global_best_score = score\n                \n                if evaluations >= self.budget:\n                    break\n                \n        return global_best, global_best_score", "name": "HybridDEPSO", "description": "The algorithm is a hybrid of Differential Evolution and Particle Swarm Optimization incorporating adaptive parameters for exploration and exploitation balance.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "9d5c860a-1891-4c62-8858-28e77752a23b", "metadata": {"aucs": [0.434769408373638, 0.434769408373638, 0.434769408373638, 0.4015602382189114, 0.4015602382189114, 0.4015602382189114, 0.1742890041564158, 0.1742890041564158, 0.1742890041564158, 0.02293962590987053, 0.02293962590987053, 0.02293962590987053, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0009003408778497368, 0.0009003408778497368, 0.0009003408778497368, 0.09550151125617867, 0.09550151125617867, 0.09550151125617867, 0.08156292270598664, 0.08156292270598664, 0.08156292270598664, 0.07063109697936398, 0.07063109697936398, 0.07063109697936398, 0.08440549072682912, 0.08440549072682912, 0.08440549072682912, 0.06944120747611049, 0.06944120747611049, 0.06944120747611049, 0.07084216678743838, 0.07084216678743838, 0.07084216678743838, 0.9811592230303531, 0.9811592230303531, 0.9811592230303531, 0.9875328641063893, 0.9875328641063893, 0.9875328641063893, 0.9882169640529754, 0.9882169640529754, 0.9882169640529754, 0.096989332205762, 0.096989332205762, 0.096989332205762, 0.13450475109552085, 0.13450475109552085, 0.13450475109552085, 0.08812891090820707, 0.08812891090820707, 0.08812891090820707, 0.2266605599392315, 0.2266605599392315, 0.2266605599392315, 0.1819137368839573, 0.1819137368839573, 0.1819137368839573, 0.13547293587687326, 0.13547293587687326, 0.13547293587687326, 0.11332574423952213, 0.11332574423952213, 0.11332574423952213, 0.10769751877494327, 0.10769751877494327, 0.10769751877494327, 0.07750875742900587, 0.07750875742900587, 0.07750875742900587, 0.09534016473324503, 0.09534016473324503, 0.09534016473324503, 0.1153694182124313, 0.1153694182124313, 0.1153694182124313, 0.08839993255486955, 0.08839993255486955, 0.08839993255486955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06784585386428277, 0.06784585386428277, 0.06784585386428277, 0.04355616059475542, 0.04355616059475542, 0.04355616059475542, 0.022066747733763492, 0.022066747733763492, 0.022066747733763492, 0.0006867284673840457, 0.0006867284673840457, 0.0006867284673840457, 0.0009796352772456496, 0.0009796352772456496, 0.0009796352772456496, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08739966243211583, 0.08739966243211583, 0.08739966243211583, 0.09621597907051149, 0.09621597907051149, 0.09621597907051149, 0.03976523223130479, 0.03976523223130479, 0.03976523223130479, 0.3519732317547314, 0.3519732317547314, 0.3519732317547314, 0.3460264605554678, 0.3460264605554678, 0.3460264605554678, 0.3284795026062365, 0.3284795026062365, 0.3284795026062365, 0.08197847463701347, 0.08197847463701347, 0.08197847463701347, 0.07952588170630692, 0.07952588170630692, 0.07952588170630692, 0.0685012643029822, 0.0685012643029822, 0.0685012643029822, 0.1585502208155385, 0.1585502208155385, 0.1585502208155385, 0.1660037045337578, 0.1660037045337578, 0.1660037045337578, 0.17332006362950236, 0.17332006362950236, 0.17332006362950236, 0.21919156315363564, 0.21919156315363564, 0.21919156315363564, 0.23639487737778087, 0.23639487737778087, 0.23639487737778087, 0.21599444431156578, 0.21599444431156578, 0.21599444431156578, 0.19973965611309308, 0.19973965611309308, 0.19973965611309308, 0.16923050996277111, 0.16923050996277111, 0.16923050996277111, 0.169869800256372, 0.169869800256372, 0.169869800256372, 0.17562598322689338, 0.17562598322689338, 0.17562598322689338, 0.18920013662737478, 0.18920013662737478, 0.18920013662737478, 0.17778383062732628, 0.17778383062732628, 0.17778383062732628, 0.16533880598722028, 0.16533880598722028, 0.16533880598722028, 0.18085679289146706, 0.18085679289146706, 0.18085679289146706, 0.1684994247727738, 0.1684994247727738, 0.1684994247727738, 0.16582489451552296, 0.16582489451552296, 0.16582489451552296, 0.16240709346593307, 0.16240709346593307, 0.16240709346593307, 0.49186909268020484, 0.49186909268020484, 0.49186909268020484, 0.16533761792313018, 0.16533761792313018, 0.16533761792313018, 0.47205373272643303, 0.47205373272643303, 0.47205373272643303, 0.11387572729328799, 0.11387572729328799, 0.11387572729328799, 0.19002667909278248, 0.19002667909278248, 0.19002667909278248, 0.18562846448090253, 0.18562846448090253, 0.18562846448090253, 0.1905553189968785, 0.1905553189968785, 0.1905553189968785, 0.06609861552497565, 0.06609861552497565, 0.06609861552497565, 0.08605173765167051, 0.08605173765167051, 0.08605173765167051, 0.09249758876470315, 0.09249758876470315, 0.09249758876470315]}, "mutation_prompt": null}

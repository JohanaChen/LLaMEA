{"id": "aa75e4f0-3284-4460-8a1d-0e5c500d7264", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20 + 5 * int(np.sqrt(dim))  # Adjusted for smaller populations in higher dimensions\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5 # Cognitive component for PSO\n        self.c2 = 1.5 # Social component for PSO\n\n    def __call__(self, func):\n        np.random.seed(42)\n        evaluations = 0\n        \n        # Initialize population for DE\n        de_population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        de_fitness = np.apply_along_axis(func, 1, de_population)\n        evaluations += self.population_size\n        \n        # Initialize velocity and personal bests for PSO\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = np.copy(de_population)\n        personal_best_fitness = np.copy(de_fitness)\n        global_best_idx = np.argmin(de_fitness)\n        global_best = de_population[global_best_idx]\n        global_best_fitness = de_fitness[global_best_idx]\n        \n        # Hybrid DE-PSO loop\n        while evaluations < self.budget:\n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                a, b, c = de_population[indices]\n                mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n                crossover = np.random.rand(self.dim) < self.cr\n                trial = np.where(crossover, mutant, de_population[i])\n                \n                # Evaluate trial\n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < de_fitness[i]:\n                    de_population[i] = trial\n                    de_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n            \n            # Particle Swarm Optimization Update\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - de_population[i]) +\n                               self.c2 * r2 * (global_best - de_population[i]))\n                de_population[i] = np.clip(de_population[i] + velocity[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_fitness = func(de_population[i])\n                evaluations += 1\n                \n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = de_population[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < global_best_fitness:\n                        global_best = de_population[i]\n                        global_best_fitness = new_fitness\n\n        return global_best, global_best_fitness", "name": "HybridDEPSO", "description": "A hybrid algorithm combining Differential Evolution and Particle Swarm Optimization to balance global exploration and local exploitation for effective black-box optimization.", "configspace": "", "generation": 0, "fitness": 0.26730866210825976, "feedback": "", "error": "", "parent_id": null, "metadata": {"aucs": [0.7285661163282866, 0.7285661163282866, 0.7285661163282866, 0.7682185499179277, 0.7682185499179277, 0.7682185499179277, 0.7768039892101597, 0.7768039892101597, 0.7768039892101597, 0.4961760018536242, 0.4961760018536242, 0.4961760018536242, 0.4529059653429799, 0.4529059653429799, 0.4529059653429799, 0.01700954582373415, 0.01700954582373415, 0.01700954582373415, 0.13479587736224874, 0.13479587736224874, 0.13479587736224874, 0.2618039292141079, 0.2618039292141079, 0.2618039292141079, 0.1617121573875504, 0.1617121573875504, 0.1617121573875504, 0.11691284133081681, 0.11691284133081681, 0.11691284133081681, 0.10462676550713479, 0.10462676550713479, 0.10462676550713479, 0.10291991276126189, 0.10291991276126189, 0.10291991276126189, 0.9827749876390441, 0.9827749876390441, 0.9827749876390441, 0.9869792934420487, 0.9869792934420487, 0.9869792934420487, 0.987684888048022, 0.987684888048022, 0.987684888048022, 0.5060906307992532, 0.5060906307992532, 0.5060906307992532, 0.4419851799182549, 0.4419851799182549, 0.4419851799182549, 0.4883025960855276, 0.4883025960855276, 0.4883025960855276, 0.368669103213649, 0.368669103213649, 0.368669103213649, 0.16015649834757972, 0.16015649834757972, 0.16015649834757972, 0.22660075731546026, 0.22660075731546026, 0.22660075731546026, 0.20047180539794796, 0.20047180539794796, 0.20047180539794796, 0.12354475899912432, 0.12354475899912432, 0.12354475899912432, 0.1969989338530106, 0.1969989338530106, 0.1969989338530106, 0.21752085704969382, 0.21752085704969382, 0.21752085704969382, 0.19331436130925073, 0.19331436130925073, 0.19331436130925073, 0.21696957810125284, 0.21696957810125284, 0.21696957810125284, 0.028936681485580262, 0.028936681485580262, 0.028936681485580262, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11271510645671046, 0.11271510645671046, 0.11271510645671046, 0.00013331946943795359, 0.00013331946943795359, 0.00013331946943795359, 0.11626155444767794, 0.11626155444767794, 0.11626155444767794, 0.04354456168795218, 0.04354456168795218, 0.04354456168795218, 0.07720978530363831, 0.07720978530363831, 0.07720978530363831, 0.16930018079528453, 0.16930018079528453, 0.16930018079528453, 0.14941943745899822, 0.14941943745899822, 0.14941943745899822, 0.12532494320031817, 0.12532494320031817, 0.12532494320031817, 0.05965991854930486, 0.05965991854930486, 0.05965991854930486, 0.5115213486219947, 0.5115213486219947, 0.5115213486219947, 0.556923623238315, 0.556923623238315, 0.556923623238315, 0.520132848094951, 0.520132848094951, 0.520132848094951, 0.08826714283532933, 0.08826714283532933, 0.08826714283532933, 0.09080812850623188, 0.09080812850623188, 0.09080812850623188, 0.16011469912206644, 0.16011469912206644, 0.16011469912206644, 0.17931571722576356, 0.17931571722576356, 0.17931571722576356, 0.19797870429311193, 0.19797870429311193, 0.19797870429311193, 0.14586942894970523, 0.14586942894970523, 0.14586942894970523, 0.2842489719622622, 0.2842489719622622, 0.2842489719622622, 0.4076665595530623, 0.4076665595530623, 0.4076665595530623, 0.2775094840652751, 0.2775094840652751, 0.2775094840652751, 0.2980658728051121, 0.2980658728051121, 0.2980658728051121, 0.19188737413536439, 0.19188737413536439, 0.19188737413536439, 0.1379326883744072, 0.1379326883744072, 0.1379326883744072, 0.2415727476248235, 0.2415727476248235, 0.2415727476248235, 0.21528669570064074, 0.21528669570064074, 0.21528669570064074, 0.20952833560462092, 0.20952833560462092, 0.20952833560462092, 0.19169402189264317, 0.19169402189264317, 0.19169402189264317, 0.242407763484341, 0.242407763484341, 0.242407763484341, 0.20133860556881744, 0.20133860556881744, 0.20133860556881744, 0.8496735682786913, 0.8496735682786913, 0.8496735682786913, 0.15809426205235833, 0.15809426205235833, 0.15809426205235833, 0.1988489337658581, 0.1988489337658581, 0.1988489337658581, 0.1690691157601938, 0.1690691157601938, 0.1690691157601938, 0.21906561452123074, 0.21906561452123074, 0.21906561452123074, 0.15343952373338032, 0.15343952373338032, 0.15343952373338032, 0.19163133066199967, 0.19163133066199967, 0.19163133066199967, 0.1932902153429411, 0.1932902153429411, 0.1932902153429411, 0.18595000613442236, 0.18595000613442236, 0.18595000613442236, 0.0835383946574848, 0.0835383946574848, 0.0835383946574848, 0.10199580284964127, 0.10199580284964127, 0.10199580284964127, 0.08833477196380846, 0.08833477196380846, 0.08833477196380846]}, "mutation_prompt": null}
{"id": "c1909752-c1f5-4c61-a155-506546b366d2", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20 + 5 * int(np.sqrt(dim))  # Adjusted for smaller populations in higher dimensions\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.w = 0.9  # Inertia weight for PSO\n        self.c1 = 1.5 # Cognitive component for PSO\n        self.c2 = 1.5 # Social component for PSO\n\n    def __call__(self, func):\n        np.random.seed(42)\n        evaluations = 0\n        \n        # Initialize population for DE\n        de_population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        de_fitness = np.apply_along_axis(func, 1, de_population)\n        evaluations += self.population_size\n        \n        # Initialize velocity and personal bests for PSO\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = np.copy(de_population)\n        personal_best_fitness = np.copy(de_fitness)\n        global_best_idx = np.argmin(de_fitness)\n        global_best = de_population[global_best_idx]\n        global_best_fitness = de_fitness[global_best_idx]\n        \n        # Hybrid DE-PSO loop\n        while evaluations < self.budget:\n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                a, b, c = de_population[indices]\n                mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n                crossover = np.random.rand(self.dim) < self.cr\n                trial = np.where(crossover, mutant, de_population[i])\n                \n                # Evaluate trial\n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < de_fitness[i]:\n                    de_population[i] = trial\n                    de_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n            \n            # Particle Swarm Optimization Update\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - de_population[i]) +\n                               self.c2 * r2 * (global_best - de_population[i]))\n                de_population[i] = np.clip(de_population[i] + velocity[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_fitness = func(de_population[i])\n                evaluations += 1\n                \n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = de_population[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < global_best_fitness:\n                        global_best = de_population[i]\n                        global_best_fitness = new_fitness\n\n        return global_best, global_best_fitness", "name": "HybridDEPSO", "description": "A refined hybrid algorithm enhancing local search by adjusting the PSO inertia weight dynamically based on the optimization progress for improved convergence.", "configspace": "", "generation": 1, "fitness": 0.1433434062154097, "feedback": "", "error": "", "parent_id": "aa75e4f0-3284-4460-8a1d-0e5c500d7264", "metadata": {"aucs": [0.22659793698214314, 0.22659793698214314, 0.22659793698214314, 0.25816719977355784, 0.25816719977355784, 0.25816719977355784, 0.2200109183163932, 0.2200109183163932, 0.2200109183163932, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10543826405418988, 0.10543826405418988, 0.10543826405418988, 0.05298881652564291, 0.05298881652564291, 0.05298881652564291, 0.05705518566404533, 0.05705518566404533, 0.05705518566404533, 0.03989563788264838, 0.03989563788264838, 0.03989563788264838, 0.04092277859109128, 0.04092277859109128, 0.04092277859109128, 0.037460899666941994, 0.037460899666941994, 0.037460899666941994, 0.9826587058605017, 0.9826587058605017, 0.9826587058605017, 0.9870946999483371, 0.9870946999483371, 0.9870946999483371, 0.9886218500551078, 0.9886218500551078, 0.9886218500551078, 0.10059548627393156, 0.10059548627393156, 0.10059548627393156, 0.1209214250090066, 0.1209214250090066, 0.1209214250090066, 0.14019124787740878, 0.14019124787740878, 0.14019124787740878, 0.16159731508050068, 0.16159731508050068, 0.16159731508050068, 0.1452997241129267, 0.1452997241129267, 0.1452997241129267, 0.1462185115504221, 0.1462185115504221, 0.1462185115504221, 0.03232651326433478, 0.03232651326433478, 0.03232651326433478, 0.04614846511177473, 0.04614846511177473, 0.04614846511177473, 0.01016929561032398, 0.01016929561032398, 0.01016929561032398, 0.007808973670190067, 0.007808973670190067, 0.007808973670190067, 0.09316172007342305, 0.09316172007342305, 0.09316172007342305, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08080776578344262, 0.08080776578344262, 0.08080776578344262, 0.023351202943792115, 0.023351202943792115, 0.023351202943792115, 0.047840088497199784, 0.047840088497199784, 0.047840088497199784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011870728135102926, 0.011870728135102926, 0.011870728135102926, 0.04017928706678686, 0.04017928706678686, 0.04017928706678686, 0.03211332787230037, 0.03211332787230037, 0.03211332787230037, 0.2727118611539139, 0.2727118611539139, 0.2727118611539139, 0.22046835343474214, 0.22046835343474214, 0.22046835343474214, 0.2173195744903883, 0.2173195744903883, 0.2173195744903883, 0.09184101147537715, 0.09184101147537715, 0.09184101147537715, 0.059869467295881496, 0.059869467295881496, 0.059869467295881496, 0.06430299146699414, 0.06430299146699414, 0.06430299146699414, 0.1357200576321702, 0.1357200576321702, 0.1357200576321702, 0.1559132904873619, 0.1559132904873619, 0.1559132904873619, 0.1343891440795404, 0.1343891440795404, 0.1343891440795404, 0.19108706556915378, 0.19108706556915378, 0.19108706556915378, 0.1857799095223941, 0.1857799095223941, 0.1857799095223941, 0.2093002453021191, 0.2093002453021191, 0.2093002453021191, 0.13677921430624795, 0.13677921430624795, 0.13677921430624795, 0.13525946468765593, 0.13525946468765593, 0.13525946468765593, 0.09961573056572903, 0.09961573056572903, 0.09961573056572903, 0.1459064167744929, 0.1459064167744929, 0.1459064167744929, 0.18107172654054937, 0.18107172654054937, 0.18107172654054937, 0.1583741338989616, 0.1583741338989616, 0.1583741338989616, 0.16982738025367694, 0.16982738025367694, 0.16982738025367694, 0.1410193616298817, 0.1410193616298817, 0.1410193616298817, 0.16179773608383297, 0.16179773608383297, 0.16179773608383297, 0.20887467023988315, 0.20887467023988315, 0.20887467023988315, 0.17687339137081814, 0.17687339137081814, 0.17687339137081814, 0.17198286010710107, 0.17198286010710107, 0.17198286010710107, 0.16405190811624526, 0.16405190811624526, 0.16405190811624526, 0.2014105534216344, 0.2014105534216344, 0.2014105534216344, 0.1388825417148546, 0.1388825417148546, 0.1388825417148546, 0.19207927684363135, 0.19207927684363135, 0.19207927684363135, 0.1824946062156818, 0.1824946062156818, 0.1824946062156818, 0.19242177836524643, 0.19242177836524643, 0.19242177836524643, 0.05294917055880033, 0.05294917055880033, 0.05294917055880033, 0.059888078577599146, 0.059888078577599146, 0.059888078577599146, 0.07194830407346875, 0.07194830407346875, 0.07194830407346875]}, "mutation_prompt": null}

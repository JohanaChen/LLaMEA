{"id": "99a47af9-5049-4d5e-ae52-895330c9d143", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Adaptive Swarm-Based Hybrid Optimization combines particle swarm optimization with differential evolution for enhanced exploration and exploitation in complex search spaces.", "configspace": "", "generation": 0, "fitness": 0.05691586578587541, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": null, "metadata": {"aucs": [0.0544795582866463, 0.05857268905453339, 0.057695350016446545]}, "mutation_prompt": null}
{"id": "04d3a0fa-af65-4ad4-9c2e-eee9d62fbf79", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial + np.random.normal(0, 0.01, self.dim)\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Improved global best selection by applying Gaussian noise to enhance exploration.", "configspace": "", "generation": 1, "fitness": 0.05676846767121835, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "99a47af9-5049-4d5e-ae52-895330c9d143", "metadata": {"aucs": [0.05375090239339608, 0.05886103051081115, 0.05769347010944781]}, "mutation_prompt": null}
{"id": "2457b7bd-d178-4540-8e83-1a56038c56d2", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            self.F = 0.5 + 0.5 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce adaptive mutation factor to balance exploration and exploitation dynamically.", "configspace": "", "generation": 2, "fitness": 0.05666182779362224, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "99a47af9-5049-4d5e-ae52-895330c9d143", "metadata": {"aucs": [0.05472012720828412, 0.0585244136650831, 0.0567409425074995]}, "mutation_prompt": null}
{"id": "7270c6ae-4f5e-4373-a8c9-5fc5fa7e0d51", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)  # Dynamic adjustment of the mutation factor\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Adaptive Swarm Hybrid with Dynamic Mutation enhances exploration by dynamically adjusting the mutation factor based on evaluation progress.", "configspace": "", "generation": 3, "fitness": 0.060298530167235, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "99a47af9-5049-4d5e-ae52-895330c9d143", "metadata": {"aucs": [0.058296334268011174, 0.05874253547395636, 0.06385672075973747]}, "mutation_prompt": null}
{"id": "52061620-3839-48f5-a812-41b93c19e0bd", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F * (1 - (eval_count / self.budget) ** 2)  # Non-linear dynamic mutation factor\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduced a non-linear dynamic mutation factor to enhance the adaptability of the algorithm.", "configspace": "", "generation": 4, "fitness": 0.05772869211782387, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "7270c6ae-4f5e-4373-a8c9-5fc5fa7e0d51", "metadata": {"aucs": [0.05719809509450391, 0.05901141026838541, 0.05697657099058229]}, "mutation_prompt": null}
{"id": "187a6c13-be44-4e3f-b8a8-ca4592fbf27c", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i] * (1 + 0.1 * (eval_count / self.budget))  # Amplify velocity influence\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)  # Dynamic adjustment of the mutation factor\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Improved global search by amplifying velocity influence during late-stage evaluations for enhanced convergence.", "configspace": "", "generation": 5, "fitness": 0.061234040110232514, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "7270c6ae-4f5e-4373-a8c9-5fc5fa7e0d51", "metadata": {"aucs": [0.058781496884997786, 0.061319960057024114, 0.06360066338867565]}, "mutation_prompt": null}
{"id": "9a829467-241b-4dc8-8f43-e49cad59edd4", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget) + 0.05\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i] * (1 + 0.1 * (eval_count / self.budget))  # Amplify velocity influence\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)  # Dynamic adjustment of the mutation factor\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Enhanced exploitation phase in AdaptiveSwarmHybrid with dynamic inertia adjustment for improved convergence.", "configspace": "", "generation": 6, "fitness": 0.06091261495883349, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "187a6c13-be44-4e3f-b8a8-ca4592fbf27c", "metadata": {"aucs": [0.0592427850001207, 0.061091300258489856, 0.06240375961788991]}, "mutation_prompt": null}
{"id": "542cf165-87d6-47e8-96e6-85947ed3a4a4", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))  # Sigmoid decay\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Enhanced global search by implementing a sigmoid decay for velocity amplification, improving convergence over the budget.", "configspace": "", "generation": 7, "fitness": 0.06152816557771997, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "187a6c13-be44-4e3f-b8a8-ca4592fbf27c", "metadata": {"aucs": [0.061184733224643906, 0.058517828925978566, 0.06488193458253744]}, "mutation_prompt": null}
{"id": "b91cb3bd-194c-4e68-9e04-ef794bb3876f", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))  # Sigmoid decay\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget) * np.cos(np.pi * eval_count / self.budget)  # Dynamic mutation with cosine\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Enhanced global search by introducing a dynamic mutation strategy influenced by a cosine function for better exploration vs. exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.06129203835917366, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "542cf165-87d6-47e8-96e6-85947ed3a4a4", "metadata": {"aucs": [0.06066761592054637, 0.05908100557475393, 0.0641274935822207]}, "mutation_prompt": null}
{"id": "fae4b2ca-37e7-401b-8c21-c5c3cddf484a", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            self.population_size = int(10 * self.dim * (1 - eval_count / self.budget)) + 1  # Dynamic population size\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))  # Sigmoid decay\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduced a dynamic population size adjustment to improve exploration/exploitation balance.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_id": "542cf165-87d6-47e8-96e6-85947ed3a4a4", "metadata": {}, "mutation_prompt": null}
{"id": "300f9098-77f6-413a-9c26-152b3f07a732", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.cos(np.pi * eval_count / (2 * self.budget))\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget)  # Dynamic crossover rate\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a dynamic crossover rate and adaptive inertia weight for improved exploitation and exploration balance.", "configspace": "", "generation": 10, "fitness": 0.06350148262399835, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "542cf165-87d6-47e8-96e6-85947ed3a4a4", "metadata": {"aucs": [0.06283361375515828, 0.061281773512181004, 0.06638906060465577]}, "mutation_prompt": null}
{"id": "2d650321-bd56-4bf8-961a-0a6b7b0bd7e6", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.cos(np.pi * eval_count / (2 * self.budget))\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]) * np.tanh(eval_count / self.budget))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget)  # Dynamic crossover rate\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce non-linear velocity update with adaptive sigmoid scaling for the improvement of exploration phase.", "configspace": "", "generation": 11, "fitness": 0.06286754107952974, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "300f9098-77f6-413a-9c26-152b3f07a732", "metadata": {"aucs": [0.0630263654486708, 0.0625787636513534, 0.06299749413856504]}, "mutation_prompt": null}
{"id": "8d289c22-27bf-476c-809f-8f5b15f62b9f", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.cos(np.pi * eval_count / (2 * self.budget))\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.sin(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Integrate time-varying component into the dynamic crossover strategy to improve adaptability.", "configspace": "", "generation": 12, "fitness": 0.06353453607658226, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "300f9098-77f6-413a-9c26-152b3f07a732", "metadata": {"aucs": [0.06228848032997214, 0.06406866189337312, 0.06424646600640149]}, "mutation_prompt": null}
{"id": "04e31bc2-f58d-4b34-8b1a-99b25feb9cea", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)  # Changed line\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.sin(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a dynamic inertia weight adjustment to enhance the balance between exploration and exploitation.", "configspace": "", "generation": 13, "fitness": 0.061706068473732945, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "8d289c22-27bf-476c-809f-8f5b15f62b9f", "metadata": {"aucs": [0.05923952672691424, 0.06303881964846803, 0.06283985904581657]}, "mutation_prompt": null}
{"id": "41cf3e71-3609-4ab0-aa66-4dea176c5158", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)**2  # Non-linear decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.sin(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a non-linear decay to the inertia weight to enhance exploitation in the latter stages of the search.", "configspace": "", "generation": 14, "fitness": 0.06138478085158846, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "8d289c22-27bf-476c-809f-8f5b15f62b9f", "metadata": {"aucs": [0.05847489820372764, 0.062223973428409796, 0.06345547092262793]}, "mutation_prompt": null}
{"id": "9093c7da-dcbe-4842-a633-5573d26d89ea", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.cos(np.pi * eval_count / (2 * self.budget))\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Adjusted the dynamic crossover strategy to enhance convergence by altering the sine wave modulation.", "configspace": "", "generation": 15, "fitness": 0.06379438064238145, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "8d289c22-27bf-476c-809f-8f5b15f62b9f", "metadata": {"aucs": [0.06327207183102468, 0.0634616243029753, 0.06464944579314436]}, "mutation_prompt": null}
{"id": "7bb8c1e2-207f-4ecd-b764-e7753736878e", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)  # Changed from cosine to linear decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduced adaptive inertia weight to enhance exploitation during later stages of optimization.", "configspace": "", "generation": 16, "fitness": 0.06292567150869473, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "9093c7da-dcbe-4842-a633-5573d26d89ea", "metadata": {"aucs": [0.06298204293747178, 0.060856319155261684, 0.06493865243335073]}, "mutation_prompt": null}
{"id": "ae8379f5-231f-4918-baff-95b716f5d4b1", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            # Change made here: Added a quadratic decay term to the inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * np.cos(np.pi * eval_count / (2 * self.budget)) * (1 - (eval_count / self.budget)**2)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Enhanced convergence by introducing a quadratic decay term to the inertia weight.", "configspace": "", "generation": 17, "fitness": 0.06367899677903244, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "9093c7da-dcbe-4842-a633-5573d26d89ea", "metadata": {"aucs": [0.06321058348719422, 0.06325850724487281, 0.06456789960503029]}, "mutation_prompt": null}
{"id": "8ed40fd3-7990-4087-8658-81377262ff03", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.cos(np.pi * eval_count / (2 * self.budget))\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                r = 1 / (1 + np.exp(-5 * (eval_count / self.budget - 0.5)))  # Sigmoid-modulated learning factor\n                dynamic_CR = self.CR * r * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduced a sigmoid-modulated learning factor to balance exploration and exploitation dynamically.", "configspace": "", "generation": 18, "fitness": 0.06376644100444033, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "9093c7da-dcbe-4842-a633-5573d26d89ea", "metadata": {"aucs": [0.06319892519217685, 0.06465332832964255, 0.06344706949150158]}, "mutation_prompt": null}
{"id": "602acd01-abbf-4f10-9f29-d8a0258e0fd3", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (1 + np.cos(np.pi * eval_count / self.budget)) / 2  # Changed line\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduced nonlinear inertia weight decay using a cosine function to enhance balance between exploration and exploitation.", "configspace": "", "generation": 19, "fitness": 0.0634207090692009, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "9093c7da-dcbe-4842-a633-5573d26d89ea", "metadata": {"aucs": [0.06319229509970459, 0.06302170743800883, 0.0640481246698893]}, "mutation_prompt": null}
{"id": "afb361cc-8014-4d01-9e42-1a016c5eb352", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5))))  # Updated line\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduced a sigmoid-based inertia weight adjustment to maintain balance between exploration and exploitation.", "configspace": "", "generation": 20, "fitness": 0.06275223499944611, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "9093c7da-dcbe-4842-a633-5573d26d89ea", "metadata": {"aucs": [0.0628913667695764, 0.06123813375809506, 0.06412720447066689]}, "mutation_prompt": null}
{"id": "afd333af-fca7-48b4-be46-b7a2084c9bfe", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (1 + np.cos(np.pi * eval_count / self.budget)) / 2  # Refined line\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduced a dynamic inertia weight w adjustment using a cosine function to refine convergence control.", "configspace": "", "generation": 21, "fitness": 0.0634207090692009, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "9093c7da-dcbe-4842-a633-5573d26d89ea", "metadata": {"aucs": [0.06319229509970459, 0.06302170743800883, 0.0640481246698893]}, "mutation_prompt": null}
{"id": "f34f1a1f-d5e6-404c-8e0f-50ede38f2f88", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_min + (self.w_max - self.w_min) / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a dynamic inertia weight adjustment using a sigmoid function to enhance convergence near the budget's end.", "configspace": "", "generation": 22, "fitness": 0.06364549444553717, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "9093c7da-dcbe-4842-a633-5573d26d89ea", "metadata": {"aucs": [0.06319165445862263, 0.06314553758763541, 0.06459929129035347]}, "mutation_prompt": null}
{"id": "bff68bb3-9b3c-4c66-b808-3d01505335cd", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max * np.exp(-5 * eval_count / self.budget) + self.w_min  # Modifying this line\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduced inertia weight adaptation based on the exponential decay strategy for improved balance between exploration and exploitation.", "configspace": "", "generation": 23, "fitness": 0.06378701497268706, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "9093c7da-dcbe-4842-a633-5573d26d89ea", "metadata": {"aucs": [0.06361650508146999, 0.06302033158607456, 0.06472420825051661]}, "mutation_prompt": null}
{"id": "3ab3b36e-06e9-483d-81c6-d3ce2f4f06e0", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.cos(np.pi * (eval_count**2) / (2 * self.budget**2))\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduced a nonlinear time-varying strategy for the inertia weight to enhance exploration and exploitation balance.", "configspace": "", "generation": 24, "fitness": 0.06361268721490691, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "9093c7da-dcbe-4842-a633-5573d26d89ea", "metadata": {"aucs": [0.06301812438895926, 0.06312190684859365, 0.06469803040716782]}, "mutation_prompt": null}
{"id": "e8d2a30d-c418-46f8-adeb-322f916b7e76", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.cos(np.pi * eval_count / (2 * self.budget))\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                adaptive_factor = 0.5 * (1 + np.cos(np.pi * eval_count / self.budget))\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 adaptive_factor * self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a dynamic adaptive factor in the velocity update formula to boost exploration in early iterations and exploit convergence in later iterations.", "configspace": "", "generation": 25, "fitness": 0.06292088947670531, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "9093c7da-dcbe-4842-a633-5573d26d89ea", "metadata": {"aucs": [0.06247902085828794, 0.06227884345857204, 0.06400480411325593]}, "mutation_prompt": null}
{"id": "89e206a6-55f6-4104-9940-48960fb29e84", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.cos(np.pi * eval_count / (2 * self.budget))**1.2  # Adaptive weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce an adaptive weight decay to enhance global exploration capabilities in the early stages of optimization.", "configspace": "", "generation": 26, "fitness": 0.06386726566911653, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "9093c7da-dcbe-4842-a633-5573d26d89ea", "metadata": {"aucs": [0.0632954687436692, 0.0636549040427612, 0.06465142422091918]}, "mutation_prompt": null}
{"id": "a852791a-c732-4a6f-a397-05bd24c5bbda", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.cos(np.pi * eval_count / (2 * self.budget))**1.2  # Adaptive weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.6)))  # Adjust center\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Fine-tune amplification factor to enhance adaptability with a sigmoidal function centered on 0.6.", "configspace": "", "generation": 27, "fitness": 0.06188663465861529, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "89e206a6-55f6-4104-9940-48960fb29e84", "metadata": {"aucs": [0.06103473147376126, 0.06268247193220988, 0.06194270056987472]}, "mutation_prompt": null}
{"id": "403153eb-8671-4e6a-9294-26526881e95b", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.cos(np.pi * eval_count / (2 * self.budget))**1.2  # Adaptive weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-15 * (eval_count / self.budget - 0.5)))  # Changed -10 to -15\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Enhance swarm exploration by adjusting amplification factor for improved convergence.", "configspace": "", "generation": 28, "fitness": 0.0603805104656171, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "89e206a6-55f6-4104-9940-48960fb29e84", "metadata": {"aucs": [0.059840862950427454, 0.05986112290655876, 0.06143954553986508]}, "mutation_prompt": null}
{"id": "0a670cc3-9a45-4263-8a15-d87d65c31957", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.cos(np.pi * eval_count / (2 * self.budget))**1.3  # Adaptive weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Enhance the adaptive weight decay by refining the exponent in the cosine term for improved balance between exploration and exploitation.", "configspace": "", "generation": 29, "fitness": 0.06385169662277002, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "89e206a6-55f6-4104-9940-48960fb29e84", "metadata": {"aucs": [0.06331823198306474, 0.06367244241443282, 0.06456441547081249]}, "mutation_prompt": null}
{"id": "f5f94eff-b17e-4839-977e-e8907ac1b578", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)  # Linear weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Modify the adaptive weight decay to incorporate a linear decay for smoother transitions in the swarm's exploration-exploitation dynamics.", "configspace": "", "generation": 30, "fitness": 0.06292567150869473, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "89e206a6-55f6-4104-9940-48960fb29e84", "metadata": {"aucs": [0.06298204293747178, 0.060856319155261684, 0.06493865243335073]}, "mutation_prompt": null}
{"id": "0a10f87a-6c28-4f3e-bccc-08bbb2d859c0", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (np.cos(np.pi * eval_count / (2 * self.budget))**1.2) * (1 - eval_count/self.budget)  # Non-linear time-varying inertia weight\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a non-linear time-varying inertia weight to enhance convergence in the final stages of optimization.", "configspace": "", "generation": 31, "fitness": 0.06315141200528611, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "89e206a6-55f6-4104-9940-48960fb29e84", "metadata": {"aucs": [0.06372942718447672, 0.0617397721674926, 0.063985036663889]}, "mutation_prompt": null}
{"id": "e07970f8-bd6c-4c3b-8190-79eec301a8d6", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.exp(-5 * eval_count / self.budget)  # Changed to exponential decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Enhance exploration by replacing cosine weight decay with exponential decay for better convergence.", "configspace": "", "generation": 32, "fitness": 0.06184837201901816, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "89e206a6-55f6-4104-9940-48960fb29e84", "metadata": {"aucs": [0.062403560093895694, 0.058900857115542826, 0.06424069884761596]}, "mutation_prompt": null}
{"id": "466dd5dd-3124-45a8-a176-30c25cc9c60a", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.cos(np.pi * eval_count / (2 * self.budget))**1.2  # Adaptive weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-12 * (eval_count / self.budget - 0.5)))  # Changed from -10 to -12\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a more dynamic update for the amplification factor to balance exploration and exploitation.", "configspace": "", "generation": 33, "fitness": 0.06230601883035969, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "89e206a6-55f6-4104-9940-48960fb29e84", "metadata": {"aucs": [0.06258375763524304, 0.0621889045205809, 0.06214539433525512]}, "mutation_prompt": null}
{"id": "6eaeb431-c932-4645-a305-0a91f262b15b", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.cos(np.pi * eval_count / (2 * self.budget))**1.2  # Adaptive weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Add a convergence acceleration factor to improve exploration-exploitation balance.", "configspace": "", "generation": 34, "fitness": 0.06386726566911653, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "89e206a6-55f6-4104-9940-48960fb29e84", "metadata": {"aucs": [0.0632954687436692, 0.0636549040427612, 0.06465142422091918]}, "mutation_prompt": null}
{"id": "667a7166-5551-45ec-b861-17418bf1881a", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.cos(np.pi * eval_count / (2 * self.budget))**1.2  # Adaptive weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F * np.sin(np.pi * eval_count / self.budget)  # Nonlinear dynamic F factor\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a nonlinear dynamic factor for F that enhances convergence speed in later stages.", "configspace": "", "generation": 35, "fitness": 0.06298940164456046, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "89e206a6-55f6-4104-9940-48960fb29e84", "metadata": {"aucs": [0.06442768577784208, 0.060197983458424975, 0.06434253569741433]}, "mutation_prompt": null}
{"id": "06e8856c-7a2f-4d51-8511-bfc5fb0ee711", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.cos(np.pi * eval_count / (2 * self.budget))**1.2  # Adaptive weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 (self.c1 * (1 - eval_count / self.budget)) * r1 * (personal_best[i] - pop[i]) +  # Dynamic learning rate\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce dynamic learning rates to improve convergence speed and diversity management in optimization.", "configspace": "", "generation": 36, "fitness": 0.06351009246682411, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "89e206a6-55f6-4104-9940-48960fb29e84", "metadata": {"aucs": [0.06344025339324122, 0.06303218764005503, 0.0640578363671761]}, "mutation_prompt": null}
{"id": "3d418ede-3634-43f7-bf1f-289e1b3b77ce", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.cos(np.pi * eval_count / (2 * self.budget))**1.2  # Adaptive weight decay\n            dynamic_velocity_scale = 0.5 + 0.5 * (eval_count / self.budget)  # Dynamic velocity scaling factor\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor * dynamic_velocity_scale\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a dynamic velocity scaling factor to enhance fine-tuning during the latter stages of optimization.", "configspace": "", "generation": 37, "fitness": 0.061808583327691013, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "89e206a6-55f6-4104-9940-48960fb29e84", "metadata": {"aucs": [0.06242547553791311, 0.060526251743963644, 0.062474022701196286]}, "mutation_prompt": null}
{"id": "b6fa9f03-3acb-4317-b213-3a08870da93a", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.cos(np.pi * eval_count / (2 * self.budget))**1.2  # Adaptive weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.sin(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Refine time-varying components in DE crossover for improved trial diversity.", "configspace": "", "generation": 38, "fitness": 0.0636346018716571, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "89e206a6-55f6-4104-9940-48960fb29e84", "metadata": {"aucs": [0.0621943977474253, 0.0645014186489884, 0.06420798921855764]}, "mutation_prompt": null}
{"id": "ff2945ab-d08f-4940-80e7-95fc54f0a24a", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.cos(np.pi * eval_count / (2 * self.budget))**1.05  # Adaptive weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a dynamic inertia weight scaling method to enhance convergence speed in later stages of optimization.", "configspace": "", "generation": 39, "fitness": 0.06380365227061506, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "89e206a6-55f6-4104-9940-48960fb29e84", "metadata": {"aucs": [0.06327065192255454, 0.06348458646207533, 0.06465571842721529]}, "mutation_prompt": null}
{"id": "a65fd209-e2c3-4c65-b7f3-2b9836f21a38", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            self.population_size = int(10 * self.dim * (1 - eval_count / self.budget))  # Dynamic population size\n            w = self.w_max - (self.w_max - self.w_min) * np.cos(np.pi * eval_count / (2 * self.budget))**1.2  # Adaptive weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Incorporate a dynamic population size scaling to adaptively adjust exploration and exploitation balance.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_id": "89e206a6-55f6-4104-9940-48960fb29e84", "metadata": {}, "mutation_prompt": null}
{"id": "c3a5a43d-9ec6-4503-9e96-36e9e0364a5b", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.cos(np.pi * eval_count / self.budget)**1.2  # Adjusted adaptive weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Enhance exploration by adjusting the adaptive weight decay function for improved convergence.", "configspace": "", "generation": 41, "fitness": 0.060365880120578606, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "89e206a6-55f6-4104-9940-48960fb29e84", "metadata": {"aucs": [0.0618703618845734, 0.05739715575441229, 0.061830122722750125]}, "mutation_prompt": null}
{"id": "537df48a-e707-45c5-b9fe-0c8e68770d51", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.cos(np.pi * eval_count / (2 * self.budget))**1.2  # Adaptive weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial + np.random.normal(0, 0.01, self.dim)  # Perturbation factor\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Enhance global best update mechanism by introducing a perturbation factor to increase diversity.", "configspace": "", "generation": 42, "fitness": 0.06354205348869561, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "89e206a6-55f6-4104-9940-48960fb29e84", "metadata": {"aucs": [0.06230193377517401, 0.06363124248132024, 0.06469298420959257]}, "mutation_prompt": null}
{"id": "3f654604-56f1-4c7d-ba3e-32ab8e4f2ae9", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.cos(np.pi * eval_count / (2 * self.budget))**1.2  # Adaptive weight decay\n            velocity_scale = 1 - eval_count / self.budget  # Dynamic scaling\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor * velocity_scale  # Apply scaling\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a dynamic velocity scaling factor to enhance convergence precision in the later stages of optimization.", "configspace": "", "generation": 43, "fitness": 0.06270007411058469, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "89e206a6-55f6-4104-9940-48960fb29e84", "metadata": {"aucs": [0.0626838512251282, 0.06278659937533637, 0.06262977173128947]}, "mutation_prompt": null}
{"id": "2194542b-eff8-4431-ab40-34226a3705a2", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.cos(np.pi * eval_count / (2 * self.budget))**1.2  # Adaptive weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-12 * (eval_count / self.budget - 0.5)))  # Adjusted sigmoid function\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Enhance convergence by adjusting the velocity amplification factor using a sigmoid function.", "configspace": "", "generation": 44, "fitness": 0.06230601883035969, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "89e206a6-55f6-4104-9940-48960fb29e84", "metadata": {"aucs": [0.06258375763524304, 0.0621889045205809, 0.06214539433525512]}, "mutation_prompt": null}
{"id": "d8f05119-2fba-45ba-b604-68a038ef8011", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Refine weight decay with a sinusoidal increase pattern to balance exploration and exploitation effectively.", "configspace": "", "generation": 45, "fitness": 0.06391643587724823, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "89e206a6-55f6-4104-9940-48960fb29e84", "metadata": {"aucs": [0.06357076573770148, 0.06375118088977783, 0.06442736100426538]}, "mutation_prompt": null}
{"id": "3b2e3949-f8a4-47b3-9ed3-413d2915ab8f", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-12 * (eval_count / self.budget - 0.5)))  # Changed from 10 to 12\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Modify the dynamic control parameter for better adaptation in Amplification Factor.", "configspace": "", "generation": 46, "fitness": 0.06231602834211044, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "d8f05119-2fba-45ba-b604-68a038ef8011", "metadata": {"aucs": [0.06275087490407805, 0.06212257625266504, 0.062074633869588225]}, "mutation_prompt": null}
{"id": "c9d58c98-99d1-4627-8505-75c345091b68", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a dynamic adjustment in the learning factors by slightly refining the calculation of c1 and c2 for enhanced convergence.", "configspace": "", "generation": 47, "fitness": 0.06405300809552168, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "d8f05119-2fba-45ba-b604-68a038ef8011", "metadata": {"aucs": [0.06370330913282807, 0.06405838839914202, 0.06439732675459497]}, "mutation_prompt": null}
{"id": "a79d8586-c690-4f3b-8897-4292d2844c4d", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            # Refined weight decay with sigmoid function\n            w = self.w_min + (self.w_max - self.w_min) / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a sigmoid function to dynamically adjust the inertia weight based on evaluation count for better balance between exploration and exploitation.", "configspace": "", "generation": 48, "fitness": 0.0634719313408536, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "c9d58c98-99d1-4627-8505-75c345091b68", "metadata": {"aucs": [0.06342813910745426, 0.06249778855163712, 0.06448986636346943]}, "mutation_prompt": null}
{"id": "c7719aa5-ada4-4c0e-8cc7-d0ac07849bb8", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                self.c2 = 1.5 + np.cos(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c2\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb, ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Refine velocity update by introducing a dynamic adjustment to the c2 factor for improved convergence.", "configspace": "", "generation": 49, "fitness": 0.06317105926859974, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "c9d58c98-99d1-4627-8505-75c345091b68", "metadata": {"aucs": [0.06302829611846217, 0.06331167957648498, 0.06317320211085209]}, "mutation_prompt": null}
{"id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce adaptive boundary control to enhance exploration and exploitation balance.", "configspace": "", "generation": 50, "fitness": 0.06445072924008, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "c9d58c98-99d1-4627-8505-75c345091b68", "metadata": {"aucs": [0.06415589587041481, 0.0642312015442904, 0.06496509030553477]}, "mutation_prompt": null}
{"id": "8f85ebae-49b9-4202-9b1f-a221c701339a", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] *= (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Nonlinear damping factor\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a nonlinear time-varying damping factor for velocity to improve convergence speed.", "configspace": "", "generation": 51, "fitness": 0.06410845964343881, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.06409587150047613, 0.0643354268054096, 0.0638940806244307]}, "mutation_prompt": null}
{"id": "768cb25c-5591-4358-b506-8b356bb0357c", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.exp(-5 * eval_count / self.budget)  # Dynamic inertia weight with exponential decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a dynamic inertia weight update using exponential decay to improve convergence speed.", "configspace": "", "generation": 52, "fitness": 0.063724047397769, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.06411339212055378, 0.06096822795241752, 0.06609052212033573]}, "mutation_prompt": null}
{"id": "08dd4baa-a8ef-4be5-8e71-3524bfddda98", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                airborne_factor = np.random.uniform(0.95, 1.05)  # Stochastic airborne factor\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i])) * airborne_factor\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Enhance exploration by introducing stochastic airborne factor in the velocity update.", "configspace": "", "generation": 53, "fitness": 0.05920931657389646, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.058337763295080336, 0.05845723164566308, 0.06083295478094597]}, "mutation_prompt": null}
{"id": "0f51ae2a-4a7c-425b-b2e0-98c2014d75c6", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget) * (global_best_score / (global_best_score + np.mean(personal_best_scores)))  # Dynamic weight scaling\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce dynamic inertia weight scaling based on convergence speed to enhance adaptability.", "configspace": "", "generation": 54, "fitness": 0.06386879351859805, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.06417611152813985, 0.061372153642425764, 0.06605811538522854]}, "mutation_prompt": null}
{"id": "bd5e0c52-2094-48ff-af0b-5cee86e57770", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (np.tan(eval_count / self.budget - 0.5))))  # Non-linear decay\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Enhance convergence by introducing a non-linear decay to the amplification factor.", "configspace": "", "generation": 55, "fitness": 0.0643959876475767, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.06411150361351092, 0.06431796897416797, 0.06475849035505121]}, "mutation_prompt": null}
{"id": "c56ecc3d-a369-4073-9d81-9f55b9e1c3ee", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (1 + np.cos(np.pi * eval_count / self.budget)) / 2  # Dynamic inertia weight adjustment\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce dynamic inertia weight adjustment using a cosine function to improve convergence rates.", "configspace": "", "generation": 56, "fitness": 0.06437902739200367, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.06413757304730117, 0.0643254732416424, 0.06467403588706744]}, "mutation_prompt": null}
{"id": "bd51c2a6-f199-42c8-a881-b6e995e044da", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (1 - np.cos(np.pi * eval_count / self.budget)) / 2  # Adjusted weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Enhance velocity update with a cosine-based dynamic inertia weight.", "configspace": "", "generation": 57, "fitness": 0.06338134809746909, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.0640917543164996, 0.059802255929340964, 0.06625003404656671]}, "mutation_prompt": null}
{"id": "3eadbeb3-1920-4a60-8c5f-8b4dca460428", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget) * 0.5  # Refined weight oscillation\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce an adaptive inertia weight oscillation to further enhance exploration capabilities.", "configspace": "", "generation": 58, "fitness": 0.06407185042263548, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.06420053134000014, 0.062083581807268806, 0.06593143812063751]}, "mutation_prompt": null}
{"id": "08b8935a-49b6-41e5-9d4c-ad06821d19c8", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if eval_count % (self.budget // 10) == 0:  # New line for periodic global best update\n                        global_best = pop[np.random.randint(self.population_size)]  # New line for periodic global best update\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Enhance exploration by dynamically updating the global best position with a random individual's position periodically.", "configspace": "", "generation": 59, "fitness": 0.0639265736040437, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.06398474160490064, 0.06416606616102227, 0.06362891304620821]}, "mutation_prompt": null}
{"id": "13457af5-ac67-4df2-8b86-114e43b787bc", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (1 - np.cos(np.pi * eval_count / self.budget))  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Enhance convergence speed by refining the dynamic adjustment of inertia weight.", "configspace": "", "generation": 60, "fitness": 0.06401795332003435, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.06420345018994644, 0.06185601161984777, 0.06599439815030883]}, "mutation_prompt": null}
{"id": "1490d0ad-448f-445d-955f-c8baea2d21e9", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = np.random.uniform(self.w_min, self.w_max)  # Stochastic inertia weight\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce stochastic inertia weight to enhance exploration capabilities.", "configspace": "", "generation": 61, "fitness": 0.06355795627847934, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.06353834251911394, 0.06350563766521344, 0.06362988865111063]}, "mutation_prompt": null}
{"id": "315a5a72-b5d8-4ccd-badf-dae0d0037ddc", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor * (1 + 0.5 * np.cos(2 * np.pi * eval_count / self.budget))  # Dynamic velocity scaling\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce dynamic particle velocity scaling for enhanced convergence precision.", "configspace": "", "generation": 62, "fitness": 0.06412382685382297, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.06435531233271563, 0.0632403022904966, 0.06477586593825668]}, "mutation_prompt": null}
{"id": "d1ed38d9-404e-4f15-9dd8-fd53ac7c81be", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)  # Dynamic inertia weight\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a dynamic inertia weight update for enhanced convergence speed.", "configspace": "", "generation": 63, "fitness": 0.0637598691562548, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.064154674418053, 0.06100868380219693, 0.06611624924851445]}, "mutation_prompt": null}
{"id": "5bcc183a-0eda-40d9-a5ad-d39bdb363890", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / (self.budget / 2))  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Use a time-dependent inertia weight to improve balance between exploration and exploitation.", "configspace": "", "generation": 64, "fitness": 0.06429632011566315, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.06409234833203126, 0.06453940098185396, 0.06425721103310422]}, "mutation_prompt": null}
{"id": "7070b599-4703-4b44-9c20-386471695b6f", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.exp(-5 * eval_count / self.budget)  # Dynamic inertia adjustment\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Integrate a dynamic inertia adjustment to further balance exploration and exploitation throughout the optimization process.", "configspace": "", "generation": 65, "fitness": 0.063724047397769, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.06411339212055378, 0.06096822795241752, 0.06609052212033573]}, "mutation_prompt": null}
{"id": "63f76118-447c-40b8-89c7-90b7a980d1b0", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i])) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Added cosine factor\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Enhance velocity update with cosine factor for improved convergence.", "configspace": "", "generation": 66, "fitness": 0.06410845964343881, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.06409587150047613, 0.0643354268054096, 0.0638940806244307]}, "mutation_prompt": null}
{"id": "9118a113-259f-4ea8-a254-d43794a30ebd", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Sinusoidal modulation\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Enhance global search capability by introducing a sinusoidal modulation to the dynamic adjustment of parameter F.", "configspace": "", "generation": 67, "fitness": 0.06387430923035393, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.06424805348412599, 0.06218664600666335, 0.06518822820027248]}, "mutation_prompt": null}
{"id": "68273d4f-a4a8-49bd-b92e-24e8de609194", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget) + 0.1 * np.exp(-eval_count/self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce an exponential component to dynamic CR for enhanced convergence.", "configspace": "", "generation": 68, "fitness": 0.06409440864200773, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.06451549968552783, 0.06291700121448551, 0.06485072502600986]}, "mutation_prompt": null}
{"id": "fe3bac54-0aef-4d8a-9b73-8f3e58870440", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * (1.2 + 0.8 * np.sin(np.pi * eval_count / self.budget)) * amplification_factor  # Adjusted line\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Enhance exploration with time-varying amplification scaling for improved convergence.", "configspace": "", "generation": 69, "fitness": 0.06292223359484624, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.06372266198835164, 0.05959434075206593, 0.06544969804412115]}, "mutation_prompt": null}
{"id": "10e9a752-135b-491c-b972-61756cbcff4c", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)  # Dynamic weight update\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a dynamic inertia weight update mechanism to improve convergence speed.", "configspace": "", "generation": 70, "fitness": 0.0637598691562548, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.064154674418053, 0.06100868380219693, 0.06611624924851445]}, "mutation_prompt": null}
{"id": "32bbd3dd-9381-450a-86d5-70415d99e84f", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]) +\n                                 np.cos((eval_count / self.budget) * np.pi))  # Added cosine term for smoother updates\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce cosine-based velocity update for smoother convergence in AdaptiveSwarmHybrid.", "configspace": "", "generation": 71, "fitness": 0.06443905914276553, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.0641611691890438, 0.06419588497260276, 0.06496012326665002]}, "mutation_prompt": null}
{"id": "a4e2f0ab-75df-4ece-aa38-7eb1dc4a7371", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = 0.8 * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Cosine decay for F\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Implement a cosine decay mechanism for the differentiation factor F to improve convergence.", "configspace": "", "generation": 72, "fitness": 0.06258140795573874, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.06425697512585749, 0.0583629106217487, 0.06512433811961005]}, "mutation_prompt": null}
{"id": "c0fdbc8c-9af1-4ef3-bbc9-9aa4a4f065cf", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                velocities[i] += np.random.normal(0, 0.1, self.dim)  # Additional random perturbation\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Incorporate an additional random perturbation in velocities for enhanced local search capability.", "configspace": "", "generation": 73, "fitness": 0.06243980383172776, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.06277031780470355, 0.05887995098135723, 0.0656691427091225]}, "mutation_prompt": null}
{"id": "078c4b3b-3028-470d-a48d-f48b17000370", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)\n            diversity_factor = np.std(personal_best_scores) / (np.mean(personal_best_scores) + 1e-6)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.abs(np.sin(np.pi * diversity_factor)), ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                chaotic_F = self.F * (0.5 + 0.5 * np.abs(np.cos(np.pi * eval_count / self.budget)))\n                mutant = np.clip(a + chaotic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Utilize entropy-based diversity control and chaotic maps for enhanced convergence stability.", "configspace": "", "generation": 74, "fitness": 0.06437564701728309, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.06503474363528183, 0.06383823037313674, 0.06425396704343067]}, "mutation_prompt": null}
{"id": "8236e46c-0ce2-4697-8944-05227ee06449", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count**2 / self.budget**2)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a adaptive non-linear weight decay to enhance convergence rate.", "configspace": "", "generation": 75, "fitness": 0.0636316340615094, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.064141150441126, 0.06057386503541429, 0.06617988670798791]}, "mutation_prompt": null}
{"id": "6c847b8e-fb83-407e-8d89-884747a20908", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (np.log1p(eval_count) / np.log1p(self.budget))  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Adjusted the dynamic weight decay to a more gradual logarithmic schedule for improved balance between exploration and exploitation.", "configspace": "", "generation": 76, "fitness": 0.06441447264289468, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.06414393812865116, 0.06430386458364146, 0.06479561521639143]}, "mutation_prompt": null}
{"id": "39ab0387-5809-4479-b594-ab65319a5774", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Refine swarm dynamics by modifying the velocity update rule to improve convergence.", "configspace": "", "generation": 77, "fitness": 0.06445072924008, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.06415589587041481, 0.0642312015442904, 0.06496509030553477]}, "mutation_prompt": null}
{"id": "ae0c016a-21c4-47d2-a8a1-a3dfe75c8235", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                self.c2 = 2.0 + np.cos(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c2\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Enhance velocity update strategy by introducing a dynamic component to c2 for improved exploration and exploitation.", "configspace": "", "generation": 78, "fitness": 0.06388242823538937, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.06436459763034519, 0.06144018215247249, 0.06584250492335042]}, "mutation_prompt": null}
{"id": "95487acc-1e72-4beb-af25-07551c14bc4a", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]) + (global_best - personal_best[i]) * (eval_count / self.budget))  # Dynamic component\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a dynamic component to the velocity update to enhance convergence speed.", "configspace": "", "generation": 79, "fitness": 0.06449055043617824, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "2ac25ff4-9052-4f2a-9755-ca2a96311ef6", "metadata": {"aucs": [0.06431858351368058, 0.06420649358212127, 0.06494657421273287]}, "mutation_prompt": null}
{"id": "b2977378-6558-480d-9e3d-fa0b6976e1b7", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * 0.5 * (1 + np.cos(np.pi * eval_count / self.budget))  # Dynamic weight decay using cosine\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]) + (global_best - personal_best[i]) * (eval_count / self.budget))  # Dynamic component\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a dynamic component to weight decay using a cosine function for smoother convergence.", "configspace": "", "generation": 80, "fitness": 0.06443035014590315, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "95487acc-1e72-4beb-af25-07551c14bc4a", "metadata": {"aucs": [0.0643000375800199, 0.06437809530342975, 0.0646129175542598]}, "mutation_prompt": null}
{"id": "5b2bc20c-beb9-47da-a7b2-07e1e0983dca", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]) + 1.2 * (global_best - personal_best[i]) * (eval_count / self.budget))  # Dynamic component\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Fine-tune the dynamic component in the velocity update for better convergence accuracy.", "configspace": "", "generation": 81, "fitness": 0.0644875324753446, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "95487acc-1e72-4beb-af25-07551c14bc4a", "metadata": {"aucs": [0.064341394387467, 0.06418109977055997, 0.06494010326800681]}, "mutation_prompt": null}
{"id": "ef1a1a60-3ad0-4be8-b049-3f0175255e66", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (1 + np.cos(np.pi * eval_count / self.budget)) / 2  # Nonlinear weight decay with cosine adjustment\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]) + (global_best - personal_best[i]) * (eval_count / self.budget))  # Dynamic component\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a dynamic inertia weight nonlinearly decreasing with cosine-based adjustment to enhance exploration and exploitation balance.", "configspace": "", "generation": 82, "fitness": 0.06443035014590315, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "95487acc-1e72-4beb-af25-07551c14bc4a", "metadata": {"aucs": [0.0643000375800199, 0.06437809530342975, 0.0646129175542598]}, "mutation_prompt": null}
{"id": "3d54b1a3-0e0c-44ad-a4ef-3d63f860ace5", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]) + (global_best - personal_best[i]) * (eval_count / self.budget)) * np.exp(-0.1 * eval_count / self.budget)  # Dynamic component with decay\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Adjusted the velocity update by including an additional exponential decay factor to enhance the convergence dynamics.", "configspace": "", "generation": 83, "fitness": 0.064485345156082, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "95487acc-1e72-4beb-af25-07551c14bc4a", "metadata": {"aucs": [0.06430224233341775, 0.06437344564886871, 0.06478034748595951]}, "mutation_prompt": null}
{"id": "83c1eef5-5058-4243-aeb6-73bd79496142", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]) + (global_best - personal_best[i]) * (eval_count / self.budget))  # Dynamic component\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.tanh(eval_count / self.budget * np.pi), ub)  # Adjusted boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Adjust boundary control with tanh for better exploration-exploitation balance.", "configspace": "", "generation": 84, "fitness": 0.06062730688861836, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "95487acc-1e72-4beb-af25-07551c14bc4a", "metadata": {"aucs": [0.06540379502690508, 0.06114325758686634, 0.05533486805208365]}, "mutation_prompt": null}
{"id": "45df2dca-b593-4646-9391-d8c0de2bc57a", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]) + (global_best - personal_best[i]) * (eval_count / self.budget) + np.sin(eval_count))  # Sinusoidal factor\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Enhance exploration by introducing a sinusoidal factor in the velocity update equation.", "configspace": "", "generation": 85, "fitness": 0.06449455950703391, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "95487acc-1e72-4beb-af25-07551c14bc4a", "metadata": {"aucs": [0.06431680472781431, 0.06421969480396739, 0.06494717898932001]}, "mutation_prompt": null}
{"id": "5ec44c12-82f0-4715-8666-ec4eb8b62103", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]) + (global_best - personal_best[i]) * (eval_count / self.budget) + np.sin(eval_count))  # Sinusoidal factor\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5))) * np.sin(np.pi * eval_count / self.budget)  # Modified\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a dynamic sinusoidal velocity amplification factor to enhance global search adaptability.", "configspace": "", "generation": 86, "fitness": 0.06426909323643111, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "45df2dca-b593-4646-9391-d8c0de2bc57a", "metadata": {"aucs": [0.06409146137998367, 0.06422594460814879, 0.06448987372116088]}, "mutation_prompt": null}
{"id": "976d39b1-d1db-4cc8-8e74-c79a243149de", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]) + (global_best - personal_best[i]) * (eval_count / self.budget) + np.sin(2 * np.pi * eval_count / self.budget))  # Slightly modified sinusoidal factor\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a slight variation in the factor for velocity update to enhance convergence.", "configspace": "", "generation": 87, "fitness": 0.06447168048295056, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "45df2dca-b593-4646-9391-d8c0de2bc57a", "metadata": {"aucs": [0.0643218502395494, 0.06415512597942519, 0.0649380652298771]}, "mutation_prompt": null}
{"id": "fa3732a1-01fa-4090-ad8c-a7fc1fdfa33c", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                self.c2 = 2.0 * np.exp(-eval_count/self.budget)  # Exponential decay of c2\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]) + (global_best - personal_best[i]) * (eval_count / self.budget) + np.sin(eval_count))  # Sinusoidal factor\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce exponential decay in the self.c2 coefficient to balance exploration and exploitation.", "configspace": "", "generation": 88, "fitness": 0.06448333125398624, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "45df2dca-b593-4646-9391-d8c0de2bc57a", "metadata": {"aucs": [0.06422908173239361, 0.06463708722041872, 0.06458382480914637]}, "mutation_prompt": null}
{"id": "16b44616-089d-445b-8046-285b17dbadc3", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.cos(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]) + (global_best - personal_best[i]) * (eval_count / self.budget) + np.sin(eval_count))  # Sinusoidal factor\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Enhance exploration by introducing a sinusoidal factor in the velocity update equation and refine the weight decay formula for improved convergence.", "configspace": "", "generation": 89, "fitness": 0.0644321704097887, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "45df2dca-b593-4646-9391-d8c0de2bc57a", "metadata": {"aucs": [0.06435707335471008, 0.0637534890334085, 0.06518594884124751]}, "mutation_prompt": null}
{"id": "3d7128ee-ab4e-4366-8a33-4cfc2fda1f54", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]) + (global_best - personal_best[i]) * (eval_count / self.budget) + np.sin(eval_count))  # Sinusoidal factor\n                amplification_factor = 1 / (1 + np.exp(-12 * (eval_count / self.budget - 0.5)))  # Slight adjustment in amplification factor\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Slightly adjusted the amplification factor to improve convergence performance.", "configspace": "", "generation": 90, "fitness": 0.06417177217380528, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "45df2dca-b593-4646-9391-d8c0de2bc57a", "metadata": {"aucs": [0.0640727887612218, 0.06448660474932788, 0.06395592301086617]}, "mutation_prompt": null}
{"id": "4ddfba7c-da2a-4b53-816e-7982562c0ab1", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget) * (1 - eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]) + (global_best - personal_best[i]) * (eval_count / self.budget) + np.sin(eval_count))  # Sinusoidal factor\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce dynamic cognitive scaling to refine exploration and exploitation balance.", "configspace": "", "generation": 91, "fitness": 0.06446183954861999, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "45df2dca-b593-4646-9391-d8c0de2bc57a", "metadata": {"aucs": [0.06433262332597067, 0.0642631848710914, 0.06478971044879789]}, "mutation_prompt": null}
{"id": "c0bb3b79-23e0-40d3-bb65-cacaa1807d23", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            harmonic_mean_factor = 2 / ((1 / self.c1) + (1 / self.c2))  # Harmonic mean factor\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]) + (global_best - personal_best[i]) * (eval_count / self.budget) + np.sin(eval_count)) * harmonic_mean_factor  # Sinusoidal factor\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Refinement by adding a harmonic mean factor to population velocity updates for better balance between exploration and exploitation.", "configspace": "", "generation": 92, "fitness": 0.06138787599034482, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "45df2dca-b593-4646-9391-d8c0de2bc57a", "metadata": {"aucs": [0.05786166574548968, 0.062244392507431745, 0.06405756971811305]}, "mutation_prompt": null}
{"id": "b0e25de0-d4ca-4569-917f-a2b670565cc1", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]) + (global_best - personal_best[i]) * (eval_count / self.budget) + np.sin(eval_count * 0.8))  # Adjusted sinusoidal factor\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Slightly adjust the sinusoidal factor in the velocity update equation to improve convergence stability.", "configspace": "", "generation": 93, "fitness": 0.0644912397056111, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "45df2dca-b593-4646-9391-d8c0de2bc57a", "metadata": {"aucs": [0.06431622051520602, 0.06421149504909573, 0.06494600355253155]}, "mutation_prompt": null}
{"id": "bdd60d4d-a0d5-46b7-bda5-971301bab510", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]) + (global_best - personal_best[i]) * (eval_count / self.budget) + np.sin(eval_count)) * np.exp(-eval_count / self.budget)  # Exponential decay factor\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Refine velocity update by introducing an exponential decay factor to enhance convergence speed.", "configspace": "", "generation": 94, "fitness": 0.06396153943439653, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "45df2dca-b593-4646-9391-d8c0de2bc57a", "metadata": {"aucs": [0.06416130239552953, 0.06450697636651281, 0.06321633954114725]}, "mutation_prompt": null}
{"id": "7e3a47af-e499-403e-8429-c1e52a69bcd9", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                adaptive_factor = 1 + 0.1 * np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adaptive factor\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]) + (global_best - personal_best[i]) * (eval_count / self.budget) + np.sin(eval_count)) * adaptive_factor  # Sinusoidal factor\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a dynamic adaptive factor in the velocity update to enhance exploration and convergence.", "configspace": "", "generation": 95, "fitness": 0.06428621406495678, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "45df2dca-b593-4646-9391-d8c0de2bc57a", "metadata": {"aucs": [0.06438615965294792, 0.06291848516077914, 0.06555399738114331]}, "mutation_prompt": null}
{"id": "c1092b6e-55dc-47fb-b9b8-f968c6ec3f11", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = (self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)) * (1 / (1 + np.log(1 + eval_count)))  # Logarithmic decay added\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]) + (global_best - personal_best[i]) * (eval_count / self.budget) + np.sin(eval_count))\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a logarithmic decay into the velocity update to enhance convergence rate.", "configspace": "", "generation": 96, "fitness": 0.06360940313202475, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "45df2dca-b593-4646-9391-d8c0de2bc57a", "metadata": {"aucs": [0.06396676791897749, 0.06492810284355433, 0.061933338633542445]}, "mutation_prompt": null}
{"id": "230cadfc-1b79-49a0-b2dd-b62510a2d1bf", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]) + (global_best - personal_best[i]) * (eval_count / self.budget) + np.cos(eval_count))  # Cosine factor\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Enhance exploration by introducing a cosine factor in the velocity update equation.", "configspace": "", "generation": 97, "fitness": 0.06449439447621608, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "45df2dca-b593-4646-9391-d8c0de2bc57a", "metadata": {"aucs": [0.06431547670173965, 0.06422017914172706, 0.06494752758518152]}, "mutation_prompt": null}
{"id": "7d711487-7591-4418-ae13-e54141d96cad", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]) + \n                                 (global_best - personal_best[i]) * (eval_count / self.budget) + \n                                 np.sin(eval_count * np.cos(np.pi * eval_count / self.budget)))  # Introduced cosine factor\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a nonlinear scaling factor to amplify velocity influence based on cosine function for enhanced diversity.", "configspace": "", "generation": 98, "fitness": 0.06449296202745762, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "45df2dca-b593-4646-9391-d8c0de2bc57a", "metadata": {"aucs": [0.06431874917956537, 0.0642139721447359, 0.06494616475807158]}, "mutation_prompt": null}
{"id": "d8f780bc-d13e-4ffc-bf76-edc898fd678a", "solution": "import numpy as np\n\nclass AdaptiveSwarmHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * np.sin(np.pi * eval_count / self.budget)  # Refined weight decay\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.c1 = 1.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Dynamic adjustment of c1\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]) + (global_best - personal_best[i]) * (eval_count / self.budget) + np.cos(eval_count))  # Cosine factor\n                amplification_factor = 1 / (1 + np.exp(-10 * (eval_count / self.budget - 0.5)))\n                pop[i] += velocities[i] * amplification_factor\n                pop[i] = np.clip(pop[i], lb + (ub - lb) * np.sin(np.pi * eval_count / (2 * self.budget)), ub)  # Adaptive boundary control\n\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                dynamic_F = self.F - (self.F * eval_count / self.budget)\n                mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                trial = np.copy(pop[i])\n                dynamic_CR = self.CR * (1 - eval_count / self.budget) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))  # Time-varying component\n                for j in range(self.dim):\n                    if np.random.rand() < dynamic_CR:\n                        trial[j] = mutant[j]\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best, global_best_score", "name": "AdaptiveSwarmHybrid", "description": "Introduce a cosine factor in the velocity update equation for smoother exploration.", "configspace": "", "generation": 99, "fitness": 0.06449439447621608, "feedback": "The algorithm AdaptiveSwarmHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "45df2dca-b593-4646-9391-d8c0de2bc57a", "metadata": {"aucs": [0.06431547670173965, 0.06422017914172706, 0.06494752758518152]}, "mutation_prompt": null}

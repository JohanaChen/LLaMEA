{"id": "79ab1cf2-b149-432a-927c-f873fb5e1fe3", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.5\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        # Scale positions to the search space bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                # Evaluate the fitness of each particle\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                # Update personal best\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                # Update global best\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                # Ensure particles remain within bounds\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "An Adaptive Quantum-Inspired Particle Swarm Optimizer utilizing dynamic quantum exploration and local search exploitation for efficient global optimization within constrained budgets.", "configspace": "", "generation": 0, "fitness": 0.27335564603928103, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": null, "metadata": {"aucs": [0.27328252097117467, 0.27329732881284385, 0.2734870883338245]}, "mutation_prompt": null}
{"id": "d4eba41a-a9b8-47e5-9d7d-36e6917dcbf6", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.7  # Changed from 0.5 to 0.7\n        self.cognitive_coef = 2.0  # Changed from 1.5 to 2.0\n        self.social_coef = 2.0  # Changed from 1.5 to 2.0\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.99  # New parameter\n        self.boundary_buffer = 0.01  # New parameter\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            # Update particles' velocities and positions with adaptive learning rates\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n                self.position[i] = np.clip(self.position[i], lb + self.boundary_buffer, ub - self.boundary_buffer)\n\n            self.inertia_weight *= self.learning_rate_decay  # Apply decay\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "An Enhanced Quantum-Inspired Particle Swarm Optimizer incorporating adaptive learning rates and dynamic boundary management to improve exploration and exploitation balance for constrained optimization problems.", "configspace": "", "generation": 1, "fitness": 0.27232552673616367, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "79ab1cf2-b149-432a-927c-f873fb5e1fe3", "metadata": {"aucs": [0.2725180948863578, 0.27286466278442656, 0.2715938225377067]}, "mutation_prompt": null}
{"id": "f31b9c8d-d3ac-4dfa-be96-526b4b4c3e6a", "solution": "import numpy as np\n\nclass HybridQuantumSimulatedAnnealingPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.5\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.temperature = 100.0  # Added temperature for simulated annealing\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            # Added temperature decay and stochastic tunneling\n            self.temperature *= 0.99\n            if np.random.rand() < np.exp(-np.abs(self.global_best_value - fitness_value) / self.temperature):\n                self.global_best_position = self.position[np.random.randint(self.population_size)]\n\n        return self.global_best_position, self.global_best_value", "name": "HybridQuantumSimulatedAnnealingPSO", "description": "A Hybrid Quantum-Simulated Annealing Particle Swarm Optimizer that introduces adaptive temperature control and stochastic tunneling for enhanced global exploration and convergence.", "configspace": "", "generation": 2, "fitness": 0.2679792748037174, "feedback": "The algorithm HybridQuantumSimulatedAnnealingPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "79ab1cf2-b149-432a-927c-f873fb5e1fe3", "metadata": {"aucs": [0.2654493649481996, 0.2687966935794397, 0.26969176588351296]}, "mutation_prompt": null}
{"id": "58a427d8-f6ba-40e7-9a15-03e45f5b2228", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Changed from 0.5 to 0.9 for adaptivity\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        # Scale positions to the search space bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                # Evaluate the fitness of each particle\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                # Update personal best\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                # Update global best\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                # Ensure particles remain within bounds\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Enhanced Quantum-Inspired Particle Swarm Optimizer with adaptive inertia weight for improved convergence under constrained budgets.", "configspace": "", "generation": 3, "fitness": 0.26310360071465866, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.00.", "error": "", "parent_id": "79ab1cf2-b149-432a-927c-f873fb5e1fe3", "metadata": {"aucs": [0.2619905631511228, 0.26540552074783874, 0.26191471824501444]}, "mutation_prompt": null}
{"id": "5ecb41b9-dd11-48fd-bafe-3c612831df3b", "solution": "import numpy as np\n\nclass EnhancedQuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Increased for exploration\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                dynamic_quantum_coef = self.quantum_coef * (1 - num_evaluations / func_budget)  # Dynamic quantum\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    dynamic_quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight = 0.9 - 0.4 * (num_evaluations / func_budget)  # Adaptive inertia\n\n        return self.global_best_position, self.global_best_value", "name": "EnhancedQuantumParticleSwarmOptimizer", "description": "Enhanced Quantum-Inspired Particle Swarm Optimizer using adaptive inertia and dynamic quantum coefficients for improved exploration and exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.2711154658047973, "feedback": "The algorithm EnhancedQuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "79ab1cf2-b149-432a-927c-f873fb5e1fe3", "metadata": {"aucs": [0.2733586893641283, 0.2706766492400656, 0.2693110588101979]}, "mutation_prompt": null}
{"id": "0cc4b0ad-e84e-4570-8d7a-e8308f15438b", "solution": "import numpy as np\n\nclass EnhancedQuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Adaptive inertia for dynamic balance\n        self.cognitive_coef = 2.0  # Strengthen cognitive learning\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n        \n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            # Adaptive inertia and diversity mechanism\n            if np.random.rand() < 0.5:  # Introduce randomness for diversity\n                self.inertia_weight = 0.9 - 0.5 * (num_evaluations / func_budget)\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n        return self.global_best_position, self.global_best_value", "name": "EnhancedQuantumParticleSwarmOptimizer", "description": "An Enhanced Quantum Particle Swarm Optimizer incorporating adaptive parameters and a diversity mechanism to improve exploration and exploitation balance within constrained evaluation budgets.", "configspace": "", "generation": 5, "fitness": 0.2710622498832758, "feedback": "The algorithm EnhancedQuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "79ab1cf2-b149-432a-927c-f873fb5e1fe3", "metadata": {"aucs": [0.2740952765275876, 0.2722922781566621, 0.2667991949655778]}, "mutation_prompt": null}
{"id": "e519380a-77ff-4a9a-ad81-54880f51d4b6", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.5\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        # Scale positions to the search space bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                # Evaluate the fitness of each particle\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                # Update personal best\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                # Update global best\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            # Update quantum_coef based on convergence progress\n            self.quantum_coef = max(0.05, 0.1 - 0.05 * (num_evaluations / func_budget))\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                # Ensure particles remain within bounds\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Enhanced Quantum Particle Swarm Optimizer by dynamically adjusting quantum_coef based on convergence progress for improved exploration and exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.27335524579370823, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "79ab1cf2-b149-432a-927c-f873fb5e1fe3", "metadata": {"aucs": [0.2732789600810269, 0.2732982281011488, 0.27348854919894905]}, "mutation_prompt": null}
{"id": "e6dec927-6682-4235-9d9b-8694b17506e1", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Increased initial inertia\n        self.cognitive_coef = 2.0  # Slightly increased cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        self.local_search_coef = 0.05\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            self.inertia_weight *= 0.99  # Gradually decreasing inertia weight\n\n            # Hybrid local search mechanism\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                r3 = np.random.uniform(0, 1, self.dim)  # Added for local search\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim) +\n                                    self.local_search_coef * r3 * (lb + np.random.uniform(0, 1, self.dim) * (ub - lb) - self.position[i]))\n                self.position[i] += self.velocity[i]\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Enhanced Adaptive Quantum-Inspired Particle Swarm Optimizer with dynamic inertia adjustment and hybrid local search for improved exploration and exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.27217467165688247, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "79ab1cf2-b149-432a-927c-f873fb5e1fe3", "metadata": {"aucs": [0.2725299941634671, 0.2722823394060304, 0.2717116814011499]}, "mutation_prompt": null}
{"id": "ddebd634-c8c7-486a-9a18-c748c56dade8", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Adjusted initial inertia weight for better exploration\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        # Scale positions to the search space bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                # Evaluate the fitness of each particle\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                # Update personal best\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                # Update global best\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            # Dynamic inertia weight adjustment\n            self.inertia_weight = max(0.4, 0.9 - 0.5 * (num_evaluations / func_budget))\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                # Ensure particles remain within bounds\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "A refined Quantum Particle Swarm Optimizer with dynamic inertia weight adjustment to enhance convergence speed and precision.", "configspace": "", "generation": 8, "fitness": 0.26976241740307044, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "79ab1cf2-b149-432a-927c-f873fb5e1fe3", "metadata": {"aucs": [0.27091283042498915, 0.267355172180367, 0.27101924960385526]}, "mutation_prompt": null}
{"id": "8d9bbce6-26cf-411e-b781-9db123284443", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Changed\n        self.cognitive_coef = 2.0  # Changed\n        self.social_coef = 2.0  # Changed\n        self.quantum_coef = 0.2   # Changed\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            # Adaptive inertia weight\n            self.inertia_weight *= 0.99  # New line\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]))\n\n                # Quantum tunneling\n                if np.random.rand() < 0.1:  # New line\n                    self.position[i] += self.quantum_coef * np.random.normal(0, 1, self.dim)  # Changed\n                else:  # New line\n                    self.position[i] += self.velocity[i]\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "A Hybrid Quantum Particle Swarm Optimizer with Enhanced Convergence through Adaptive Inertia and Quantum Tunneling Mechanisms.", "configspace": "", "generation": 9, "fitness": 0.27306812587832346, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "79ab1cf2-b149-432a-927c-f873fb5e1fe3", "metadata": {"aucs": [0.2741534525300495, 0.2715512024851947, 0.2734997226197262]}, "mutation_prompt": null}
{"id": "a12a5f9d-2bce-4a2b-83a1-7d56b143dcf9", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Increased for better exploration\n        self.cognitive_coef = 2.0  # Adjusted for improved local search\n        self.social_coef = 2.0     # Adjusted for improved global search\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        # Scale positions to the search space bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                # Evaluate the fitness of each particle\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                # Update personal best\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                # Update global best\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            # Adaptive inertia weight\n            self.inertia_weight = 0.9 - 0.5 * (num_evaluations / func_budget)\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                \n                # Introduce chaos perturbation\n                chaos_perturb = np.random.normal(0, 0.01, self.dim)\n                self.position[i] += self.velocity[i] + chaos_perturb\n\n                # Ensure particles remain within bounds\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Enhanced Quantum-Inspired Particle Swarm Optimizer with adaptive coefficients and chaos perturbation for improved exploration and exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.26736904409806284, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "79ab1cf2-b149-432a-927c-f873fb5e1fe3", "metadata": {"aucs": [0.2650651490639583, 0.27025149505895407, 0.26679048817127615]}, "mutation_prompt": null}
{"id": "65af270b-bf21-414b-b249-75f878f3cf17", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.5\n        self.cognitive_coef = 1.7  # Increased cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        # Scale positions to the search space bounds\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                # Evaluate the fitness of each particle\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                # Update personal best\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                # Update global best\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            # Update particles' velocities and positions\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                # Ensure particles remain within bounds\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Enhanced Quantum-Inspired Particle Swarm Optimizer with increased cognitive influence for improved local search.", "configspace": "", "generation": 11, "fitness": 0.2735280125432782, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "79ab1cf2-b149-432a-927c-f873fb5e1fe3", "metadata": {"aucs": [0.27344245394582933, 0.27358032641212426, 0.27356125727188096]}, "mutation_prompt": null}
{"id": "ba560c6b-2165-4767-be48-f421300fae50", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.1:  # Apply Lévy flight with a small probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Hybrid Quantum-Inspired Swarm Optimization with Dynamic Inertia and Lévy Flight for enhanced exploration and convergence.", "configspace": "", "generation": 12, "fitness": 0.2740602913592012, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "65af270b-bf21-414b-b249-75f878f3cf17", "metadata": {"aucs": [0.27699868688129525, 0.2685138836191102, 0.27666830357719807]}, "mutation_prompt": null}
{"id": "9c2747f9-3e06-4fb4-b2cd-8cfbd0ea647e", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.15:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Improve exploration by increasing the probability of Lévy flight to 15%.", "configspace": "", "generation": 13, "fitness": 0.27546634274200893, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "ba560c6b-2165-4767-be48-f421300fae50", "metadata": {"aucs": [0.2771564241248369, 0.27320461764308634, 0.2760379864581036]}, "mutation_prompt": null}
{"id": "9a902cd2-68db-422d-b351-b0d7db2345d2", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.7  # Increase social coefficient from 1.5 to 1.7\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.15:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Enhance convergence by increasing social coefficient to strengthen group influence in particle updates.", "configspace": "", "generation": 14, "fitness": 0.2691435530654284, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.01.", "error": "", "parent_id": "9c2747f9-3e06-4fb4-b2cd-8cfbd0ea647e", "metadata": {"aucs": [0.2770761912410089, 0.27236559792915704, 0.25798887002611937]}, "mutation_prompt": null}
{"id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Enhance exploration by slightly increasing the probability of Lévy flight to 16%.", "configspace": "", "generation": 15, "fitness": 0.2764589396322162, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "9c2747f9-3e06-4fb4-b2cd-8cfbd0ea647e", "metadata": {"aucs": [0.27710824622626173, 0.27593605185883374, 0.276332520811553]}, "mutation_prompt": null}
{"id": "f93c486d-baf2-42c4-ac5a-203c9bc9df91", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.15  # Increased quantum coefficient\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Increase velocity component randomness by boosting the quantum coefficient to 0.15.", "configspace": "", "generation": 16, "fitness": 0.2754129721104959, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27720967718149025, 0.2727082315024758, 0.27632100764752177]}, "mutation_prompt": null}
{"id": "b9cb8cc4-3d08-4d40-b96b-b5ea4004a62a", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.7  # Increase social coefficient for better convergence\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.18:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Enhance convergence by increasing the social coefficient to 1.7 and the probability of Lévy flight to 18%.", "configspace": "", "generation": 17, "fitness": 0.2723772660948504, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.01.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27652061272512396, 0.26463840064301236, 0.27597278491641486]}, "mutation_prompt": null}
{"id": "c02b2630-3dc4-425b-9c1b-b564b8b409fe", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.15  # Adjusted quantum coefficient\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.20:  # Apply Lévy flight with a higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Enhance exploration by increasing the frequency of Lévy flights to 20% and refining the quantum coefficient for better convergence.", "configspace": "", "generation": 18, "fitness": 0.27551838179751975, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2769750522959541, 0.2730015460467382, 0.27657854704986695]}, "mutation_prompt": null}
{"id": "6e033c4f-4c0e-4cac-a943-2531b2bcf27e", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.15  # Slightly enhanced quantum coefficient\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Slightly enhance quantum coefficient to improve convergence stability.", "configspace": "", "generation": 19, "fitness": 0.2754129721104959, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27720967718149025, 0.2727082315024758, 0.27632100764752177]}, "mutation_prompt": null}
{"id": "fe188648-5e28-409e-a3b3-f37c27689f04", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    (self.quantum_coef * (1 - num_evaluations/func_budget)) * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Introduce adaptive quantum coefficient based on iteration to balance exploration and exploitation.", "configspace": "", "generation": 20, "fitness": 0.27538331839908, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27710821215806136, 0.27269629762760594, 0.2763454454115727]}, "mutation_prompt": null}
{"id": "591825c5-1f42-4ea5-a730-41d63d2433fe", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.15  # Slightly increased quantum coefficient\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.14:  # Reduced Lévy flight probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Fine-tune exploration by reducing Lévy flight probability to 14% and increasing quantum influence slightly.", "configspace": "", "generation": 21, "fitness": 0.27536659148266446, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2769478948517171, 0.27285558844724855, 0.27629629114902765]}, "mutation_prompt": null}
{"id": "09ee6181-85e7-4182-9bba-f5c055f949c6", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.12  # Fine-tuned quantum coefficient\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Fine-tune the quantum coefficient to enhance convergence speed.", "configspace": "", "generation": 22, "fitness": 0.27540234370017913, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2771398853397563, 0.2726901538519112, 0.2763769919088699]}, "mutation_prompt": null}
{"id": "54235e70-f833-4da6-a7d7-e3857211780a", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.15  # Slight adjustment for improved exploration\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.18:  # Increase Lévy flight probability to 18%\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Fine-tune exploration by slightly increasing the probability of Lévy flight to 18% and adjusting the quantum coefficient for improved convergence.", "configspace": "", "generation": 23, "fitness": 0.27552957751100043, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2769167985390225, 0.27329489812041274, 0.276377035873566]}, "mutation_prompt": null}
{"id": "661a37cf-9699-4798-900b-383fbf6dc71e", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                progress = num_evaluations / func_budget\n                self.cognitive_coef = 1.5 - 0.5 * progress  # Adaptive cognitive coefficient\n                self.social_coef = 1.0 + 0.5 * progress  # Adaptive social coefficient\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Incorporate adaptive cognitive and social coefficients to dynamically balance exploration and exploitation.", "configspace": "", "generation": 24, "fitness": 0.2758676577617123, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27739911724025446, 0.27322477397619005, 0.2769790820686924]}, "mutation_prompt": null}
{"id": "e8aeaf9f-fdc5-415e-ac90-273890dc4aa7", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.12  # Adjusting quantum coefficient\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Enhance divergence by increasing the quantum coefficient to 0.12 to promote wider search exploration.", "configspace": "", "generation": 25, "fitness": 0.27540234370017913, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2771398853397563, 0.2726901538519112, 0.2763769919088699]}, "mutation_prompt": null}
{"id": "1748b955-1ce9-4cb8-a526-cc4225b31529", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.7  # Adjusted cognitive coefficient\n        self.social_coef = 1.7     # Adjusted social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Intensify exploitation by slightly increasing the cognitive and social coefficients to 1.7.", "configspace": "", "generation": 26, "fitness": 0.27372854147354536, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27322370838431653, 0.2719542351890455, 0.276007680847274]}, "mutation_prompt": null}
{"id": "7a0fd90b-e9d3-4106-b77a-cf47da4d7f07", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    (1.5 - (num_evaluations / func_budget)) * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Introduce adaptive cognitive coefficient to balance exploration and exploitation dynamically.", "configspace": "", "generation": 27, "fitness": 0.27535711927136824, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2771245573561584, 0.27272794161673775, 0.27621885884120867]}, "mutation_prompt": null}
{"id": "c36ac80b-1c1f-4c0d-a5da-fce82e5cecc9", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.7     # Enhanced social coefficient for better exploration\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Increase global exploration by enhancing social learning with a higher coefficient.", "configspace": "", "generation": 28, "fitness": 0.2746831817028346, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2766720808879606, 0.27178882178822894, 0.2755886424323144]}, "mutation_prompt": null}
{"id": "aec091a7-e5a9-4466-ac6e-7fe7a5f5a60a", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                if np.random.rand() < 0.05:  # Introduce a mutation step with a small probability\n                    self.position[i] += np.random.normal(0, 0.1, self.dim)  # Mutation step\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Increase diversity by introducing a mutation step to enhance exploration.", "configspace": "", "generation": 29, "fitness": 0.27030990969909036, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.01.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2580631661647187, 0.276399371825213, 0.2764671911073393]}, "mutation_prompt": null}
{"id": "0361ab8b-30d9-4d43-abcb-7a18d3b80f16", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 2, self.dim))  # Change made here\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Increase exploration by enhancing quantum randomness to improve particle diversity.", "configspace": "", "generation": 30, "fitness": 0.27548849596813263, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27704368225008225, 0.2727177040588896, 0.276704101595426]}, "mutation_prompt": null}
{"id": "74cd0d5d-a045-429c-bd1c-cfc0b999deb9", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n            self.quantum_coef = 0.1 + 0.9 * (num_evaluations / func_budget)  # Adaptive quantum coefficient\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Introduce adaptive quantum coefficient to balance exploration and exploitation dynamically.", "configspace": "", "generation": 31, "fitness": 0.2753568022567352, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2771177896937871, 0.27261386204055416, 0.27633875503586436]}, "mutation_prompt": null}
{"id": "760555e9-0653-4d29-bfcb-83d07093e2e6", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.15  # Increased quantum coefficient\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Increase the quantum coefficient to enhance quantum exploration movements.", "configspace": "", "generation": 32, "fitness": 0.2754129721104959, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27720967718149025, 0.2727082315024758, 0.27632100764752177]}, "mutation_prompt": null}
{"id": "aa78464f-e4d6-49e2-aecf-dfa0a499d475", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.2  # Increased quantum coefficient for enhanced local search\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Increase quantum coefficient to enhance local search capabilities.", "configspace": "", "generation": 33, "fitness": 0.27548849596813263, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27704368225008225, 0.2727177040588896, 0.276704101595426]}, "mutation_prompt": null}
{"id": "3ce79ecb-1c33-4720-8b36-9c45e9b0892b", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.7  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Increase the cognitive coefficient slightly to enhance local search capability.", "configspace": "", "generation": 34, "fitness": 0.26916427424311085, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.01.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27634131586730915, 0.2727283313692357, 0.2584231754927877]}, "mutation_prompt": null}
{"id": "6b799f60-955e-41f9-b354-75b7040a4e05", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            self.quantum_coef = 0.1 + 0.1 * (num_evaluations / func_budget)  # Adaptive quantum coef\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Introduce adaptive quantum_coef based on the generation count to improve exploration.", "configspace": "", "generation": 35, "fitness": 0.27534761336818697, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2771001885434139, 0.27258065552258404, 0.27636199603856304]}, "mutation_prompt": null}
{"id": "b8f1b507-1012-4a03-8fe3-55b65a7acf20", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 35  # Increased population size from 30 to 35\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Increase population size to enhance exploration and diversity.", "configspace": "", "generation": 36, "fitness": 0.2689686353550478, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.01.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27624055565447814, 0.2731757784599185, 0.25748957195074673]}, "mutation_prompt": null}
{"id": "261beaf6-70b6-4fdd-ab7e-749bdf18f725", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    (self.social_coef + 0.5 * (1 - num_evaluations/func_budget)) * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Introducing adaptive social coefficient to improve convergence dynamics.", "configspace": "", "generation": 37, "fitness": 0.265053726990355, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.01.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27652235330792196, 0.26806493135550413, 0.25057389630763893]}, "mutation_prompt": null}
{"id": "3fc45466-1ef0-4e30-8ff9-68a91cee30fc", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.12  # Slightly increased quantum coefficient\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Slightly increase the quantum coefficient to enhance exploration capabilities in the search space.", "configspace": "", "generation": 38, "fitness": 0.27540234370017913, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2771398853397563, 0.2726901538519112, 0.2763769919088699]}, "mutation_prompt": null}
{"id": "2622059f-38a4-4d3e-8259-3ecb59a23fcd", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    (self.social_coef * (1 - num_evaluations / func_budget)) * r2 * (self.global_best_position - self.position[i]) + # Adaptive scaling\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Introduce adaptive social coefficient scaling to enhance convergence speed.", "configspace": "", "generation": 39, "fitness": 0.27541890422113185, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2773707292808739, 0.2727383273445718, 0.2761476560379499]}, "mutation_prompt": null}
{"id": "8d95dac8-a9a7-48d5-beb1-dcfaa8b0b6c5", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Slightly increase dynamic inertia weight adjustment\n        self.inertia_damp = 0.995\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Further enhance performance by slightly increasing the inertia damping rate for a more effective balance between exploration and exploitation.", "configspace": "", "generation": 40, "fitness": 0.27494299838203906, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27685261744319634, 0.2723906838670911, 0.27558569383582976]}, "mutation_prompt": null}
{"id": "66b3d10c-c21a-43c9-94d1-c3f2f488fd7d", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                random_factor = 0.01 * np.random.normal(0, 1, self.dim)  # Added random factor\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim) +\n                                    random_factor)\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Refine velocity update by introducing a small random factor to enhance diversity.", "configspace": "", "generation": 41, "fitness": 0.27456593696489356, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27710719045351395, 0.2735581771249116, 0.2730324433162552]}, "mutation_prompt": null}
{"id": "66ab3e98-302f-4fe0-80dc-0f58c1b10a93", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.6  # Slightly increased social coefficient for better global convergence\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n            self.quantum_coef *= 1.01  # Introduce adaptive quantum coefficient adjustment\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Improve global convergence by slightly increasing social influence and introducing adaptive quantum coefficient adjustment.", "configspace": "", "generation": 42, "fitness": 0.2753542864893876, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27703170549671063, 0.27255027234266715, 0.2764808816287849]}, "mutation_prompt": null}
{"id": "01981911-163f-4672-bff4-f97b68eeeaa6", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.2  # Increased quantum coefficient\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Increase the quantum coefficient to 0.2 to enhance exploration capabilities and improve performance in diverse search spaces.", "configspace": "", "generation": 43, "fitness": 0.27548849596813263, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27704368225008225, 0.2727177040588896, 0.276704101595426]}, "mutation_prompt": null}
{"id": "54bdfe74-95fe-473b-b840-80c91d6c3a18", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.15  # Adjusted quantum coefficient\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.98  # Adjusted damping factor\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Fine-tune the inertia weight dynamics and adjust the quantum coefficient for enhanced convergence.", "configspace": "", "generation": 44, "fitness": 0.2758255867824383, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2773974955813423, 0.2729176159650267, 0.27716164880094585]}, "mutation_prompt": null}
{"id": "c5900386-fd7a-4da2-b7c3-9af3f87a131a", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i] + 0.01 * np.random.normal(0, 1, self.dim)  # Added Gaussian noise\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Increase diversity by introducing Gaussian noise to positions during velocity update.", "configspace": "", "generation": 45, "fitness": 0.27459211983849047, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2771733384554058, 0.27357631211845546, 0.2730267089416102]}, "mutation_prompt": null}
{"id": "a3a3fa6c-394d-40c4-981d-61e8fccb85dc", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.7  # Adjusted social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Adjust the social coefficient to enhance convergence speed.", "configspace": "", "generation": 46, "fitness": 0.2746831817028346, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2766720808879606, 0.27178882178822894, 0.2755886424323144]}, "mutation_prompt": null}
{"id": "a97afba9-117b-482b-bfe1-9bcd2833c897", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Enhance exploration by slightly increasing the probability of Lévy flight to 16%.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27710824622626173, 0.27593605185883374, 0.276332520811553]}, "mutation_prompt": null}
{"id": "35963aca-b47d-4267-a3d3-cfbc81aa0d32", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.17:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Enhance exploration by increasing the probability of Lévy flight to 17%.", "configspace": "", "generation": 48, "fitness": 0.2756365694074104, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2772998853810619, 0.272890338470439, 0.27671948437073024]}, "mutation_prompt": null}
{"id": "6f2f5249-458f-4694-98fb-bff79b5f0c1c", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 35  # Increased population size\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.98  # Adjusted inertia damp factor\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Increase the population size for better exploration and adjust the inertia weight damp factor for improved convergence.", "configspace": "", "generation": 49, "fitness": 0.275302191638029, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27628921847640453, 0.27352134519878557, 0.27609601123889693]}, "mutation_prompt": null}
{"id": "5a4fe4db-2ca1-4e4f-849d-4959130bd665", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.7  # Increased social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Increase the social coefficient to improve global exploration capability.", "configspace": "", "generation": 50, "fitness": 0.2746831817028346, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2766720808879606, 0.27178882178822894, 0.2755886424323144]}, "mutation_prompt": null}
{"id": "f80e4efc-1321-4953-a919-35958638cd36", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                # Update to use dynamic quantum coefficient\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            # Update inertia weight and quantum coefficient\n            self.inertia_weight *= self.inertia_damp\n            self.quantum_coef = 0.1 + 0.05 * np.exp(-0.1 * num_evaluations / func_budget)\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Introduce a dynamic quantum coefficient for a more adaptive exploration-exploitation balance.", "configspace": "", "generation": 51, "fitness": 0.27534926287564004, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2770989651903628, 0.27270957375039595, 0.2762392496861614]}, "mutation_prompt": null}
{"id": "2c4b841f-bf08-411e-adc4-ff72cfbd5a43", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            # Adaptive cognitive coefficient based on generations\n            self.cognitive_coef = 1.5 + 0.5 * (num_evaluations / func_budget)\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Introduce adaptive cognitive coefficient based on generation count to balance exploration and exploitation.", "configspace": "", "generation": 52, "fitness": 0.27542938603073847, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2771712588692531, 0.2726706631987801, 0.27644623602418217]}, "mutation_prompt": null}
{"id": "547a98c6-87ac-4812-99cb-bcddb424aedc", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.quantum_coef = 0.1 + 0.3 * (num_evaluations / func_budget)  # Adaptive quantum coef\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Introduce adaptive quantum coefficient to improve convergence speed by adjusting its value based on iteration progress.", "configspace": "", "generation": 53, "fitness": 0.27535971124974395, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27710531957358686, 0.2726081260928791, 0.27636568808276596]}, "mutation_prompt": null}
{"id": "f6edc253-6335-42af-a633-574707464789", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n            \n            self.quantum_coef *= 1.01  # Adaptive quantum coefficient\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Introduce adaptive quantum coefficient to enhance global search in later stages.", "configspace": "", "generation": 54, "fitness": 0.2753506593075586, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2771129254540321, 0.272610708774352, 0.2763283436942916]}, "mutation_prompt": null}
{"id": "f1604e78-a546-41f5-b4e6-ffbe95e38c75", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.7  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Increase the cognitive coefficient slightly for improved personal best exploration.", "configspace": "", "generation": 55, "fitness": 0.26916427424311085, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.01.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27634131586730915, 0.2727283313692357, 0.2584231754927877]}, "mutation_prompt": null}
{"id": "7eae8276-a61c-49c6-8dee-98f95c3ae5ed", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.7  # Increased social coefficient for improved exploration\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Enhance global exploration by increasing the social coefficient slightly.", "configspace": "", "generation": 56, "fitness": 0.2746831817028346, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2766720808879606, 0.27178882178822894, 0.2755886424323144]}, "mutation_prompt": null}
{"id": "675ae6aa-49d1-4ba2-92e3-3c527c524099", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.05  # Reduced quantum coefficient\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Slightly reduce quantum_coef to enhance convergence stability without sacrificing exploration.", "configspace": "", "generation": 57, "fitness": 0.2741669734607724, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27708275615241396, 0.2726560173662035, 0.2727621468636997]}, "mutation_prompt": null}
{"id": "0b45c486-0a1f-4daa-a982-31d363b42ccc", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.15  # Changed the quantum coefficient\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.17:  # Increased the probability of Lévy flight\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Refine exploration by further increasing the probability of Lévy flight to 17% and adjusting the quantum coefficient to 0.15.", "configspace": "", "generation": 58, "fitness": 0.2756704702634236, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2773039679567866, 0.27291732430222715, 0.2767901185312571]}, "mutation_prompt": null}
{"id": "712dd0fd-29c6-442a-af9c-e5fc836abea6", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n            self.quantum_coef *= (0.98 if self.quantum_coef > 0.05 else 1)  # Update quantum coefficient\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Introduce adaptive quantum coefficient to improve convergence speed.", "configspace": "", "generation": 59, "fitness": 0.275395256341778, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27706136274285253, 0.27268091334750333, 0.27644349293497816]}, "mutation_prompt": null}
{"id": "1f8166a3-4ee3-4a82-a54c-fb140b6acc59", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.7  # Increased social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Enhance convergence speed by increasing the social coefficient to 1.7.", "configspace": "", "generation": 60, "fitness": 0.2746831817028346, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2766720808879606, 0.27178882178822894, 0.2755886424323144]}, "mutation_prompt": null}
{"id": "ac505ef1-e059-4c8b-8df9-6683435c7663", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.7  # Adjusted cognitive coefficient (increased)\n        self.social_coef = 1.3  # Decreased social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Increase cognitive coefficient to enhance personal exploration and decrease social coefficient for balanced convergence.", "configspace": "", "generation": 61, "fitness": 0.27556092191839393, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27697623042132835, 0.2726411596877858, 0.2770653756460676]}, "mutation_prompt": null}
{"id": "cc6beb5e-07b8-4bbf-8746-e102fc55fffb", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        self.momentum = 0.1  # Add momentum term\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim) +\n                                    self.momentum * self.velocity[i])  # Add momentum to velocity update\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Introduce a momentum term in the velocity update to improve convergence speed and stability.", "configspace": "", "generation": 62, "fitness": 0.2748466839158629, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2763515187976805, 0.2724527489827566, 0.2757357839671516]}, "mutation_prompt": null}
{"id": "54f936eb-38a2-4535-9e3f-5721ee71ca15", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                # Change this line to use a dynamic probability for Lévy flight\n                if np.random.rand() < (0.16 + 0.3 * (1 - num_evaluations / func_budget)):  \n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Increase exploration by enhancing Lévy flight with a dynamic probability tied to the function evaluation stage.", "configspace": "", "generation": 63, "fitness": 0.2737636306890008, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27596497222441707, 0.26884254530875873, 0.27648337453382654]}, "mutation_prompt": null}
{"id": "25d0f1cc-a274-4c6a-b361-eba4054a6d9d", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.15  # Slight increase in quantum coefficient for better exploration\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Increased particle velocity by adjusting the quantum coefficient slightly to enhance exploration.", "configspace": "", "generation": 64, "fitness": 0.2754129721104959, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27720967718149025, 0.2727082315024758, 0.27632100764752177]}, "mutation_prompt": null}
{"id": "427a904a-a93e-447a-9acc-181876c93ef8", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.2  # Adjusted cognitive coefficient\n        self.social_coef = 1.8  # Enhanced social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Optimize exploration-exploitation balance by reducing cognitive coefficient and enhancing social component influence.", "configspace": "", "generation": 65, "fitness": 0.2747193516252365, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27649264863945333, 0.27242635343440824, 0.2752390528018478]}, "mutation_prompt": null}
{"id": "db35a938-355c-4169-8845-aa36d89a976f", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                # Adjust cognitive and social coefficients dynamically\n                self.cognitive_coef = 1.5 - 0.5 * (num_evaluations / func_budget)\n                self.social_coef = 1.5 + 0.5 * (num_evaluations / func_budget)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Improve convergence by dynamically adapting the cognitive and social coefficients over iterations.", "configspace": "", "generation": 66, "fitness": 0.27539451649885, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2771106610101369, 0.272678095384564, 0.2763947931018491]}, "mutation_prompt": null}
{"id": "62194cfe-7143-4ff5-8206-f149c19ca1a1", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.6  # Slightly increased social coefficient\n        self.quantum_coef = 0.15  # Slightly increased quantum coefficient\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Slightly enhance the social and quantum coefficients to improve convergence speed.", "configspace": "", "generation": 67, "fitness": 0.2753824681059704, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2770545447622407, 0.2725597381477539, 0.27653312140791664]}, "mutation_prompt": null}
{"id": "f7e39842-747e-407d-9a43-55347c76dfc5", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.2  # Changed quantum coefficient for enhanced exploration\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Increase the quantum coefficient for enhanced exploration while maintaining the same probability for Lévy flight.", "configspace": "", "generation": 68, "fitness": 0.27548849596813263, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27704368225008225, 0.2727177040588896, 0.276704101595426]}, "mutation_prompt": null}
{"id": "a1f647d5-17b9-4f96-a945-24a0375681d5", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.7  # Slightly increased social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Slightly adjust the social coefficient to enhance global best influence, improving convergence.", "configspace": "", "generation": 69, "fitness": 0.2746831817028346, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2766720808879606, 0.27178882178822894, 0.2755886424323144]}, "mutation_prompt": null}
{"id": "4dfb7f35-f602-45e6-aed1-568119932546", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        velocity_momentum = 0.5  # Added new momentum coefficient\n        \n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (velocity_momentum * self.velocity[i] +  # Applied momentum to velocity update\n                                    self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Introduce momentum to the velocity update for improved convergence speed.", "configspace": "", "generation": 70, "fitness": 0.27119707867532505, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2725036944059389, 0.26867443997503515, 0.2724131016450011]}, "mutation_prompt": null}
{"id": "4ea5cbcb-6494-4f9b-815a-2a02987fceb3", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.6  # Modified social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.98  # Modified inertia damping factor\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Improve convergence by modifying the social coefficient and damping factor for inertia weight.", "configspace": "", "generation": 71, "fitness": 0.2756029656553231, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2772533238008128, 0.2727275908743477, 0.27682798229080885]}, "mutation_prompt": null}
{"id": "0138dc34-77dd-44d1-9531-6f7fa7497e8c", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.7  # Adjusted cognitive coefficient for better local search\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Slightly increase the cognitive coefficient to enhance local search capabilities.", "configspace": "", "generation": 72, "fitness": 0.26916427424311085, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.01.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27634131586730915, 0.2727283313692357, 0.2584231754927877]}, "mutation_prompt": null}
{"id": "21983765-88b9-44b1-90fb-8976792d6b22", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    2 * self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    2 * self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Introduce adaptive dynamic coefficients for cognitive and social components to enhance convergence.", "configspace": "", "generation": 73, "fitness": 0.2544521861216598, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.2524103756991396, 0.25945965162501083, 0.25148653104082896]}, "mutation_prompt": null}
{"id": "d4c8ce81-c4bd-46c0-bb8d-366d56516115", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.7  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Improve convergence by increasing the cognitive coefficient to 1.7.", "configspace": "", "generation": 74, "fitness": 0.26916427424311085, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.01.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27634131586730915, 0.2727283313692357, 0.2584231754927877]}, "mutation_prompt": null}
{"id": "58b1ee57-b701-4c1f-9f63-a79df2686233", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.7  # Adjusted cognitive coefficient\n        self.social_coef = 1.5\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.16:  # Apply Lévy flight with a slightly higher probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Slightly increase the cognitive coefficient to 1.7 for better personal learning influence.", "configspace": "", "generation": 75, "fitness": 0.26916427424311085, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.01.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27634131586730915, 0.2727283313692357, 0.2584231754927877]}, "mutation_prompt": null}
{"id": "d552175d-2135-42f3-9d06-8214ba508154", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.6  # Slightly increased social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.17:  # Apply Lévy flight with a further increased probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Enhance global exploration by slightly increasing the probability of Lévy flight to 17% and adjusting social coefficient.", "configspace": "", "generation": 76, "fitness": 0.2766355253838492, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "58772adf-8a32-4bee-967c-2071c8eaa5cb", "metadata": {"aucs": [0.27708367056422933, 0.27637872190622925, 0.27644418368108914]}, "mutation_prompt": null}
{"id": "cd0a61a4-3314-4542-9db2-bb4c7bae1bd7", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.6  # Slightly increased social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    (self.quantum_coef + 0.05 * (self.global_best_value - self.personal_best_value[i])) * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.17:  # Apply Lévy flight with a further increased probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Introduce a dynamic quantum coefficient to enhance local search in the QuantumParticleSwarmOptimizer.", "configspace": "", "generation": 77, "fitness": 0.276722435166417, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "d552175d-2135-42f3-9d06-8214ba508154", "metadata": {"aucs": [0.2771141522789585, 0.276380521504915, 0.27667263171537737]}, "mutation_prompt": null}
{"id": "a75e6087-73e5-4a33-ac7d-8d332fcbc935", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.6  # Slightly increased social coefficient\n        self.quantum_coef = 0.1\n        self.momentum_coef = 0.2  # New momentum coefficient\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    (self.quantum_coef + 0.05 * (self.global_best_value - self.personal_best_value[i])) * np.random.normal(0, 1, self.dim) +\n                                    self.momentum_coef * (self.global_best_position - self.position[i]))  # Apply momentum component\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.17:  # Apply Lévy flight with a further increased probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Introduce a momentum coefficient to enhance global search dynamics in QuantumParticleSwarmOptimizer.", "configspace": "", "generation": 78, "fitness": 0.2616211085562859, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.01.", "error": "", "parent_id": "cd0a61a4-3314-4542-9db2-bb4c7bae1bd7", "metadata": {"aucs": [0.25855350153051204, 0.27260680549649374, 0.25370301864185185]}, "mutation_prompt": null}
{"id": "865dca1a-e9d7-47de-ae55-80145afefed1", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.6  # Slightly increased social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    (self.quantum_coef + 0.05 * (self.global_best_value - self.personal_best_value[i])) * np.random.normal(0, 1, self.dim) +\n                                    np.random.normal(0, 0.05, self.dim))  # Added noise factor for exploration\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.17:  # Apply Lévy flight with a further increased probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Enhance exploration by adjusting the velocity update formula to include a noise factor.", "configspace": "", "generation": 79, "fitness": 0.27423355159965607, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "cd0a61a4-3314-4542-9db2-bb4c7bae1bd7", "metadata": {"aucs": [0.2766427317268424, 0.273493782266349, 0.27256414080577684]}, "mutation_prompt": null}
{"id": "2074d538-1e61-44bf-ae31-e1ac9ae469b4", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.6  # Slightly increased social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                fitness_improvement = self.global_best_value - self.personal_best_value[i]\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    (self.quantum_coef + 0.05 * fitness_improvement) * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.17:  # Apply Lévy flight with a further increased probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Introduce a variable dynamic quantum coefficient based on fitness improvement to enhance scalability in the QuantumParticleSwarmOptimizer.", "configspace": "", "generation": 80, "fitness": 0.276722435166417, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "cd0a61a4-3314-4542-9db2-bb4c7bae1bd7", "metadata": {"aucs": [0.2771141522789585, 0.276380521504915, 0.27667263171537737]}, "mutation_prompt": null}
{"id": "95c3beb9-4593-448f-a247-7c28f0be39bc", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.6  # Slightly increased social coefficient\n        self.quantum_coef = 0.15  # Increased quantum coefficient\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    (self.quantum_coef + 0.05 * (self.global_best_value - self.personal_best_value[i])) * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.2:  # Further increased probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Enhance exploration by modifying the quantum coefficient and increasing the Lévy flight probability.", "configspace": "", "generation": 81, "fitness": 0.27499183399108157, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "cd0a61a4-3314-4542-9db2-bb4c7bae1bd7", "metadata": {"aucs": [0.27631734787137185, 0.2721225919472421, 0.2765355621546307]}, "mutation_prompt": null}
{"id": "2c2a7b9c-3077-4611-ae93-f324bf95cc18", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.6  # Slightly increased social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    (self.quantum_coef + 0.05 * (self.global_best_value - self.personal_best_value[i])) * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.2:  # Apply Lévy flight with a slightly increased probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Adjust the probability of applying Lévy flights to enhance exploration.", "configspace": "", "generation": 82, "fitness": 0.27491500120629403, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "cd0a61a4-3314-4542-9db2-bb4c7bae1bd7", "metadata": {"aucs": [0.27620226130724024, 0.27224473281678996, 0.27629800949485184]}, "mutation_prompt": null}
{"id": "a228ffe9-fe70-406b-a815-d75d14838b68", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.6  # Slightly increased social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    (self.quantum_coef + 0.05 * (self.global_best_value - self.personal_best_value[i])) * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.20:  # Slightly increased probability of Lévy flight\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Increase the probability of applying Lévy flight to enhance exploration capabilities.", "configspace": "", "generation": 83, "fitness": 0.27491500120629403, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "cd0a61a4-3314-4542-9db2-bb4c7bae1bd7", "metadata": {"aucs": [0.27620226130724024, 0.27224473281678996, 0.27629800949485184]}, "mutation_prompt": null}
{"id": "343775d6-6658-4c5c-8f3b-c09b75c06e26", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.6  # Slightly increased social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    (self.quantum_coef + 0.05 * (self.global_best_value - self.personal_best_value[i])) * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.17 + 0.03 * (self.global_best_value - self.personal_best_value[i]):  # Adjusted probability for Lévy flight\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Enhance Lévy flight strategy by adapting the probability based on fitness improvement.", "configspace": "", "generation": 84, "fitness": 0.2753264733766498, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "cd0a61a4-3314-4542-9db2-bb4c7bae1bd7", "metadata": {"aucs": [0.2768235837310221, 0.27232635301795427, 0.2768294833809729]}, "mutation_prompt": null}
{"id": "6aefb15e-18d7-4aa6-926e-09d5b7a22cdd", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.6\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        self.inertia_damp = 0.99\n        self.memory = np.copy(self.position)\n        self.memory_value = np.full(self.population_size, np.inf)\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n                    self.memory[i] = self.position[i]\n                    self.memory_value[i] = fitness_value\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    (self.quantum_coef + 0.05 * (self.global_best_value - self.personal_best_value[i])) * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.17:\n                    self.position[i] += self.levy_flight(self.dim)\n\n                # Apply opposition-based learning\n                new_position = lb + ub - self.position[i]\n                new_position = np.clip(new_position, lb, ub)\n                if func(new_position) < fitness_value:\n                    self.position[i] = new_position\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Introduce adaptive memory and opposition-based learning to enhance exploration and convergence in QuantumParticleSwarmOptimizer.", "configspace": "", "generation": 85, "fitness": 0.27136836285816873, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "cd0a61a4-3314-4542-9db2-bb4c7bae1bd7", "metadata": {"aucs": [0.2697964006978557, 0.2730570364028786, 0.27125165147377184]}, "mutation_prompt": null}
{"id": "f80a256f-6b84-43aa-9d48-2ad0e98799ee", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.6\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                velocity_scale = 1.0 - (num_evaluations / func_budget)\n                shrinkage_factor = 1 - (num_evaluations / (2 * func_budget))\n                self.velocity[i] = (velocity_scale * (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    (self.quantum_coef + 0.05 * (self.global_best_value - self.personal_best_value[i])) * np.random.normal(0, 1, self.dim)))\n                self.position[i] = (self.position[i] + self.velocity[i]) * shrinkage_factor\n\n                if np.random.rand() < 0.17:\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Enhance exploration by introducing adaptive velocity scaling and a dynamic swarm shrinkage mechanism.", "configspace": "", "generation": 86, "fitness": 0.2744943564475601, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "cd0a61a4-3314-4542-9db2-bb4c7bae1bd7", "metadata": {"aucs": [0.2768661257543774, 0.2715361933990875, 0.2750807501892154]}, "mutation_prompt": null}
{"id": "6685aabc-7426-4e75-bd5b-10cf8a3bf910", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.6  # Slightly increased social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                velocity_scale = 1 + np.random.rand() * 0.5  # Adaptive velocity scaling\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    (self.quantum_coef + 0.05 * (self.global_best_value - self.personal_best_value[i])) * np.random.normal(0, 1, self.dim))\n                self.position[i] += velocity_scale * self.velocity[i]  # Apply scaling\n\n                if np.random.rand() < 0.17:\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Integrate adaptive velocity scaling to enhance the balance between exploration and exploitation in QuantumParticleSwarmOptimizer.", "configspace": "", "generation": 87, "fitness": 0.274558852389126, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "cd0a61a4-3314-4542-9db2-bb4c7bae1bd7", "metadata": {"aucs": [0.2752282612309219, 0.27319927404488553, 0.2752490218915704]}, "mutation_prompt": null}
{"id": "aa0fb0d7-00ac-4768-aff6-3663211894ae", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.6  # Slightly increased social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n                self.quantum_coef = 0.1 + 0.9 * (num_evaluations / func_budget)  # Dynamic quantum coefficient adjustment\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    (self.quantum_coef + 0.05 * (self.global_best_value - self.personal_best_value[i])) * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.17:  # Apply Lévy flight with a further increased probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Adjust the quantum coefficient dynamically based on the current number of evaluations to enhance exploration.", "configspace": "", "generation": 88, "fitness": 0.27547742312938367, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "cd0a61a4-3314-4542-9db2-bb4c7bae1bd7", "metadata": {"aucs": [0.2770897603528568, 0.27271328296794095, 0.2766292260673533]}, "mutation_prompt": null}
{"id": "7ce666c5-63b0-4e0b-9538-d7ff70734ae5", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.6  # Slightly increased social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                decay_factor = 0.98  # Added decay factor\n                self.velocity[i] = (self.inertia_weight * decay_factor * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    (self.quantum_coef + 0.05 * (self.global_best_value - self.personal_best_value[i])) * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.17:  # Apply Lévy flight with a further increased probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Optimize QuantumParticleSwarmOptimizer by refining velocity update with a decay factor.", "configspace": "", "generation": 89, "fitness": 0.274032240305017, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "cd0a61a4-3314-4542-9db2-bb4c7bae1bd7", "metadata": {"aucs": [0.2767131217689781, 0.2688346973742949, 0.27654890177177793]}, "mutation_prompt": null}
{"id": "c8ab4244-0fdf-41b2-a13d-bc9f36f9c3c1", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.6  # Slightly increased social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                normalized_fitness_diff = (self.global_best_value - self.personal_best_value[i]) / (1 + abs(self.global_best_value))\n                self.quantum_coef = 0.1 + 0.2 * abs(normalized_fitness_diff)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.17:  # Apply Lévy flight with a further increased probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Enhance exploration by dynamically adjusting the quantum coefficient based on the normalized fitness difference.", "configspace": "", "generation": 90, "fitness": 0.27539982785625666, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "cd0a61a4-3314-4542-9db2-bb4c7bae1bd7", "metadata": {"aucs": [0.27709678944714977, 0.2726585735460846, 0.2764441205755357]}, "mutation_prompt": null}
{"id": "148f872a-a37a-4fe8-b213-9386d7356a81", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.7  # Adjusted cognitive coefficient\n        self.social_coef = 1.6  # Slightly increased social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    (self.quantum_coef + 0.05 * (self.global_best_value - self.personal_best_value[i])) * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.17:  # Apply Lévy flight with a further increased probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Increase the cognitive coefficient slightly and introduce a small mutation factor to diversify exploration.", "configspace": "", "generation": 91, "fitness": 0.27622132109070896, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "cd0a61a4-3314-4542-9db2-bb4c7bae1bd7", "metadata": {"aucs": [0.27677888885749125, 0.27611639347180683, 0.2757686809428288]}, "mutation_prompt": null}
{"id": "ef05291a-cfef-49cd-bf62-f5b65e26ad81", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.6  # Slightly increased social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    (self.quantum_coef * (1 - num_evaluations / func_budget) + 0.05 * (self.global_best_value - self.personal_best_value[i])) * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.17:  # Apply Lévy flight with a further increased probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Incorporate adaptive quantum coefficient scaling to better balance exploration and exploitation in the QuantumParticleSwarmOptimizer.", "configspace": "", "generation": 92, "fitness": 0.2754900310206371, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "cd0a61a4-3314-4542-9db2-bb4c7bae1bd7", "metadata": {"aucs": [0.27708530904975537, 0.2727075210564319, 0.27667726295572403]}, "mutation_prompt": null}
{"id": "e6843fb3-022c-4d9a-b2de-ab5b79a6ba5d", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 35  # Increased population size\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.6  # Adjusted cognitive coefficient\n        self.social_coef = 1.7  # Adjusted social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    (self.quantum_coef + 0.05 * (self.global_best_value - self.personal_best_value[i])) * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.17:  # Apply Lévy flight with a further increased probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Slightly increase the population size and adjust cognitive and social coefficients to improve convergence.", "configspace": "", "generation": 93, "fitness": 0.2706966868916547, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "cd0a61a4-3314-4542-9db2-bb4c7bae1bd7", "metadata": {"aucs": [0.2725563598869818, 0.26876098092112033, 0.270772719866862]}, "mutation_prompt": null}
{"id": "169662a8-8d4a-4cee-b74b-e29a389535d2", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.6  # Slightly increased social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    (self.quantum_coef + 0.05 * (self.global_best_value - self.personal_best_value[i])) * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.18:  # Apply Lévy flight with a slightly increased probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Enhance the exploration capability by slightly increasing the Lévy flight probability.", "configspace": "", "generation": 94, "fitness": 0.2752921243004804, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "cd0a61a4-3314-4542-9db2-bb4c7bae1bd7", "metadata": {"aucs": [0.2769339922152787, 0.27212950679497405, 0.27681287389118836]}, "mutation_prompt": null}
{"id": "87293032-dcc3-4842-9f78-ea130a97b3c4", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.6  # Slightly increased social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n        prev_global_best_value = self.global_best_value\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    relative_improvement = (prev_global_best_value - fitness_value) / abs(prev_global_best_value)\n                    self.quantum_coef *= (1 + 0.5 * relative_improvement)\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n                    prev_global_best_value = self.global_best_value\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    (self.quantum_coef + 0.05 * (self.global_best_value - self.personal_best_value[i])) * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.17:  # Apply Lévy flight with a further increased probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Add adaptive quantum coefficient scaling based on the relative improvement of the global best in the QuantumParticleSwarmOptimizer.", "configspace": "", "generation": 95, "fitness": 0.23471560744074652, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.00.", "error": "", "parent_id": "cd0a61a4-3314-4542-9db2-bb4c7bae1bd7", "metadata": {"aucs": [0.23256561019245903, 0.23830672215704463, 0.23327448997273592]}, "mutation_prompt": null}
{"id": "c2f518f0-a4ca-425d-996c-e0193569b59d", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.6  # Slightly increased social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                improvement = max(0, self.global_best_value - self.personal_best_value[i])\n                adaptive_quantum_coef = self.quantum_coef + 0.05 * improvement\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    adaptive_quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.17:  # Apply Lévy flight with a further increased probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Introduce adaptive quantum coefficient based on fitness improvement rate to enhance exploration.", "configspace": "", "generation": 96, "fitness": 0.2766355253838492, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "cd0a61a4-3314-4542-9db2-bb4c7bae1bd7", "metadata": {"aucs": [0.27708367056422933, 0.27637872190622925, 0.27644418368108914]}, "mutation_prompt": null}
{"id": "e722d3cb-57d2-4b27-b48c-e52a30605c3a", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.6  # Slightly increased social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    self.quantum_coef * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.17:  # Apply Lévy flight with a further increased probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n            self.quantum_coef = 0.1 * (1 - num_evaluations / func_budget)  # Adaptive quantum coefficient adjustment\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Introduce adaptive quantum coefficient adjustment to enhance convergence in QuantumParticleSwarmOptimizer.", "configspace": "", "generation": 97, "fitness": 0.2766386264834975, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "cd0a61a4-3314-4542-9db2-bb4c7bae1bd7", "metadata": {"aucs": [0.2770837947885708, 0.2763894567975902, 0.2764426278643315]}, "mutation_prompt": null}
{"id": "91941e88-a10b-46b4-a707-7fb78b3c8665", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.6  # Slightly increased social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    (self.quantum_coef + 0.05 * (self.global_best_value - self.personal_best_value[i])) * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.17:  # Apply Lévy flight with a further increased probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            self.quantum_coef *= (1 + 0.01 * np.tanh(0.1 * self.global_best_value))  # Adjust quantum coefficient\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Enhance exploration by dynamically adjusting quantum coefficient based on the global best value.", "configspace": "", "generation": 98, "fitness": 0.276722797359289, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "cd0a61a4-3314-4542-9db2-bb4c7bae1bd7", "metadata": {"aucs": [0.2771158701520058, 0.2763806038606125, 0.2766719180652488]}, "mutation_prompt": null}
{"id": "d52ebab3-5ef8-4bb1-932f-2f94d63eaf6d", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Dynamic inertia weight initialization\n        self.cognitive_coef = 1.5  # Adjusted cognitive coefficient\n        self.social_coef = 1.6  # Slightly increased social coefficient\n        self.quantum_coef = 0.1\n        self.position = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.population_size, np.inf)\n        self.global_best_position = np.zeros(self.dim)\n        self.global_best_value = np.inf\n        # Introduce dynamic inertia weight adjustment\n        self.inertia_damp = 0.99\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        func_budget = self.budget\n        num_evaluations = 0\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.position = lb + self.position * (ub - lb)\n\n        while num_evaluations < func_budget:\n            for i in range(self.population_size):\n                if num_evaluations >= func_budget:\n                    break\n                fitness_value = func(self.position[i])\n                num_evaluations += 1\n\n                if fitness_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = fitness_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if fitness_value < self.global_best_value:\n                    self.global_best_value = fitness_value\n                    self.global_best_position = self.position[i]\n\n            for i in range(self.population_size):\n                r1 = np.random.uniform(0, 1, self.dim)\n                r2 = np.random.uniform(0, 1, self.dim)\n                self.velocity[i] = (self.inertia_weight * self.velocity[i] +\n                                    self.cognitive_coef * r1 * (self.personal_best_position[i] - self.position[i]) +\n                                    self.social_coef * r2 * (self.global_best_position - self.position[i]) +\n                                    (self.quantum_coef + 0.05 * (self.global_best_value - self.personal_best_value[i])) * np.random.normal(0, 1, self.dim))\n                self.position[i] += self.velocity[i]\n\n                if np.random.rand() < 0.17:  # Apply Lévy flight with a further increased probability\n                    self.position[i] += self.levy_flight(self.dim)\n\n                self.position[i] = np.clip(self.position[i], lb, ub)\n\n            # New line: Replace a portion of the worst performers with the best position\n            num_replaced = int(self.population_size * 0.1)\n            worst_indices = np.argsort(self.personal_best_value)[-num_replaced:]\n            self.position[worst_indices] = self.global_best_position\n\n            self.quantum_coef *= (1 + 0.01 * np.tanh(0.1 * self.global_best_value))  # Adjust quantum coefficient\n            self.inertia_weight *= self.inertia_damp  # Update inertia weight\n\n        return self.global_best_position, self.global_best_value", "name": "QuantumParticleSwarmOptimizer", "description": "Introduce elite selection by updating a portion of the worst-performing particles with the best global position to improve convergence.", "configspace": "", "generation": 99, "fitness": 0.2755827268247698, "feedback": "The algorithm QuantumParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "91941e88-a10b-46b4-a707-7fb78b3c8665", "metadata": {"aucs": [0.2769352822383946, 0.27290167672761023, 0.2769112215083046]}, "mutation_prompt": null}

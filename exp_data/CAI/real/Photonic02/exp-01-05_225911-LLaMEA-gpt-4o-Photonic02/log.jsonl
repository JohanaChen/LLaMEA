{"id": "89b4ca81-c914-4f39-9e68-de9a1cd004e3", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Hybrid Particle Swarm Optimization with Differential Evolution for enhanced exploration and exploitation balance in high-dimensional spaces.", "configspace": "", "generation": 0, "fitness": 0.3519791768553981, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.03.", "error": "", "parent_id": null, "metadata": {"aucs": [0.31037028179046844, 0.3497656031716011, 0.39580164560412456]}, "mutation_prompt": null}
{"id": "7bdc280d-eb15-47b0-97a2-422db5ed932e", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)  # Adaptive inertia weight\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhanced Hybrid PSO-DE incorporating adaptive parameters for improved convergence and solution quality in high-dimensional optimization.", "configspace": "", "generation": 1, "fitness": 0.36893723194657335, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.02.", "error": "", "parent_id": "89b4ca81-c914-4f39-9e68-de9a1cd004e3", "metadata": {"aucs": [0.3458414745917231, 0.38230288472866547, 0.3786673365193314]}, "mutation_prompt": null}
{"id": "d1b955de-8a8c-4928-92eb-a377090a6ead", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)  # Adaptive inertia weight\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < (self.CR * (1 - evaluations / self.budget))  # Adapted crossover probability\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhanced Hybrid PSO-DE with improved crossover probability adaptation for better exploration-exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.3855646090415248, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.04.", "error": "", "parent_id": "7bdc280d-eb15-47b0-97a2-422db5ed932e", "metadata": {"aucs": [0.36671077708667765, 0.35266062550675736, 0.43732242453113945]}, "mutation_prompt": null}
{"id": "305a267c-24ac-4196-a11e-06f4c35d15cf", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)  # Adaptive inertia weight\n            self.c1 = 1.0 + 0.5 * (evaluations / self.budget)  # Adaptive cognitive parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < (self.CR * (1 - evaluations / self.budget))  # Adapted crossover probability\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduced adaptive personal and global learning rates to enhance convergence efficiency.", "configspace": "", "generation": 3, "fitness": 0.37670551865787066, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.03.", "error": "", "parent_id": "d1b955de-8a8c-4928-92eb-a377090a6ead", "metadata": {"aucs": [0.3628548057649913, 0.34384632249471203, 0.4234154277139086]}, "mutation_prompt": null}
{"id": "1a4a637b-dd1b-4a9e-aef7-451c23d379e6", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)  # Adaptive inertia weight\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduced adaptive differential evolution crossover probability based on population diversity to enhance exploration capabilities.", "configspace": "", "generation": 4, "fitness": 0.3901317801663596, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.03.", "error": "", "parent_id": "d1b955de-8a8c-4928-92eb-a377090a6ead", "metadata": {"aucs": [0.3797461198239902, 0.3629140527023972, 0.4277351679726914]}, "mutation_prompt": null}
{"id": "9b1a0436-d171-471b-8aef-8da882a16c4a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)  # Adaptive inertia weight\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand() * (1 - global_best_score / sum(personal_best_scores))  # Dynamic scaling factor adjustment\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduced a dynamic mechanism to adjust the DE scaling factor based on the current best score, enhancing convergence precision.", "configspace": "", "generation": 5, "fitness": 0.39010383459815495, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.03.", "error": "", "parent_id": "1a4a637b-dd1b-4a9e-aef7-451c23d379e6", "metadata": {"aucs": [0.3798089623524943, 0.3627691868515087, 0.4277333545904619]}, "mutation_prompt": null}
{"id": "32680c29-fd76-4f78-bd22-a33e11ab6b41", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)  # Adaptive inertia weight\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n            self.population_size = max(10, int(50 * (1 - evaluations / self.budget)))  # Dynamic population reduction\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduced dynamic population size reduction based on convergence to enhance exploration and exploitation balance.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (37,6) (50,6) ').", "error": "ValueError('operands could not be broadcast together with shapes (37,6) (50,6) ')", "parent_id": "1a4a637b-dd1b-4a9e-aef7-451c23d379e6", "metadata": {}, "mutation_prompt": null}
{"id": "bda9139f-c17b-4fce-b56f-64bbc0b91aa2", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)  # Adaptive inertia weight\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + (self.c2 * (1 + (global_best_score - np.min(personal_best_scores)) / np.abs(global_best_score))) * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduced adaptive social parameter adjustment based on current global best improvement to enhance convergence speed.", "configspace": "", "generation": 7, "fitness": 0.2878386867704996, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.02.", "error": "", "parent_id": "1a4a637b-dd1b-4a9e-aef7-451c23d379e6", "metadata": {"aucs": [0.2606825240455276, 0.2953556252494791, 0.30747791101649213]}, "mutation_prompt": null}
{"id": "a1c674b5-19fc-4be9-914c-cabea6cda4af", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)  # Adaptive inertia weight\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduced adaptive velocity clamping in the PSO part to prevent explosion of particle trajectories.", "configspace": "", "generation": 8, "fitness": 0.4028479717953714, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.02.", "error": "", "parent_id": "1a4a637b-dd1b-4a9e-aef7-451c23d379e6", "metadata": {"aucs": [0.42197281840128775, 0.4080804330358626, 0.3784906639489637]}, "mutation_prompt": null}
{"id": "249f1b09-2e03-435f-9e6d-4a60a4f9dc99", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)  # Adaptive inertia weight\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.5 + 0.5 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Modified adaptive scaling factor range to enhance exploration capability.", "configspace": "", "generation": 9, "fitness": 0.40186139377736113, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.01.", "error": "", "parent_id": "a1c674b5-19fc-4be9-914c-cabea6cda4af", "metadata": {"aucs": [0.40738460460460946, 0.41241723452987433, 0.38578234219759955]}, "mutation_prompt": null}
{"id": "d90a0f81-a47a-41b1-9d99-329594fd3f58", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.3 + 0.7 * (1 - evaluations / self.budget)  # Adaptive inertia weight, tweaked range\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Tweaked the inertia weight decay range to improve convergence speed.", "configspace": "", "generation": 10, "fitness": 0.39654718300899133, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.03.", "error": "", "parent_id": "a1c674b5-19fc-4be9-914c-cabea6cda4af", "metadata": {"aucs": [0.39320884120940036, 0.4330009314699288, 0.3634317763476449]}, "mutation_prompt": null}
{"id": "dd9f01d1-584d-4185-9374-a1809576c2be", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)  # Adaptive inertia weight\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                # Enhanced Mutation Strategy: Selecting a fourth random individual for better exploration\n                d = population[np.random.choice(indices, 1, replace=False)[0]]  \n                mutant_vector = np.clip(a + self.F * (b - c + d - a), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhanced the mutation strategy in the DE component to improve exploration capabilities.", "configspace": "", "generation": 11, "fitness": 0.39245744403751176, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.01.", "error": "", "parent_id": "a1c674b5-19fc-4be9-914c-cabea6cda4af", "metadata": {"aucs": [0.38772619804369246, 0.4027886385848425, 0.3868574954840004]}, "mutation_prompt": null}
{"id": "392b2e16-0ef8-4df4-ab1d-3ec972631aea", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)  # Adaptive inertia weight\n            population_diversity = np.std(population) / (ub - lb)\n            self.c1 = 1.5 + 1.0 * population_diversity  # Adaptive cognitive parameter\n            self.c2 = 1.5 + 1.0 * (1 - population_diversity)  # Adaptive social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_F = 0.5 + 0.5 * (1 - population_diversity)  # Diversity-based mutation strength\n                mutant_vector = np.clip(a + adaptive_F * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Integrate adaptive learning coefficients for cognitive and social components with diversity-based mutation strength to enhance exploration-exploitation balance.", "configspace": "", "generation": 12, "fitness": 0.3235289761608076, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.02.", "error": "", "parent_id": "a1c674b5-19fc-4be9-914c-cabea6cda4af", "metadata": {"aucs": [0.3006049813841978, 0.33501053385747526, 0.33497141324074975]}, "mutation_prompt": null}
{"id": "a69df564-73bc-4830-b59e-95fabc0a0cb7", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.5 + 0.4 * (1 - evaluations / self.budget)  # Modified adaptive inertia weight\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.25  # Adjusted adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population, axis=0) / (ub - lb)  # Updated diversity calculation\n                crossover = np.random.rand(self.dim) < (self.CR * np.mean(population_diversity))  # Improved crossover probability\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhanced adaptive inertia and diversity-based crossover to improve convergence.", "configspace": "", "generation": 13, "fitness": 0.3593614673216052, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.02.", "error": "", "parent_id": "a1c674b5-19fc-4be9-914c-cabea6cda4af", "metadata": {"aucs": [0.353353629536018, 0.33255425575911135, 0.3921765166696861]}, "mutation_prompt": null}
{"id": "8cc036ce-c7ae-4a81-9397-3ea3aa4aeee6", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)  # Adaptive inertia weight\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c) + np.random.normal(0, 0.1, self.dim), lb, ub)  # Gaussian mutation added\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduced Gaussian mutation in the DE part to enhance exploration.", "configspace": "", "generation": 14, "fitness": 0.39563807215773955, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.02.", "error": "", "parent_id": "a1c674b5-19fc-4be9-914c-cabea6cda4af", "metadata": {"aucs": [0.4049489975734698, 0.4095297205696359, 0.372435498330113]}, "mutation_prompt": null}
{"id": "300d119f-7001-4a83-893d-db4ab59df83f", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)  # Adaptive inertia weight\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduced a decay factor for the social parameter to reduce the influence of the global best solution over time.", "configspace": "", "generation": 15, "fitness": 0.41863213592573983, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42 with standard deviation 0.03.", "error": "", "parent_id": "a1c674b5-19fc-4be9-914c-cabea6cda4af", "metadata": {"aucs": [0.42274254801322575, 0.4538218385669617, 0.3793320211970319]}, "mutation_prompt": null}
{"id": "3d7dc6e1-956d-43a2-86ac-b7e0d403aeba", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)  # Adaptive inertia weight\n            self.c2 *= 0.99  # Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand() * (1 - evaluations/self.budget)  # Introduced stochastic deceleration\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduced a stochastic deceleration factor for the DE scaling factor to enhance exploration capabilities over time.", "configspace": "", "generation": 16, "fitness": 0.3934895476641545, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.02.", "error": "", "parent_id": "300d119f-7001-4a83-893d-db4ab59df83f", "metadata": {"aucs": [0.41726233295258075, 0.39174255688150506, 0.37146375315837776]}, "mutation_prompt": null}
{"id": "f1be0b43-6213-4aba-9f1e-7f4a059bf453", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)  # Adaptive inertia weight\n            self.c1 = 1.0 + 0.5 * (evaluations / self.budget)  # Linearly increasing cognitive parameter\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhanced exploration by introducing a linearly increasing cognitive parameter.", "configspace": "", "generation": 17, "fitness": 0.38879573577145, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.02.", "error": "", "parent_id": "300d119f-7001-4a83-893d-db4ab59df83f", "metadata": {"aucs": [0.40437138152090724, 0.39709122204905756, 0.36492460374438507]}, "mutation_prompt": null}
{"id": "528d092b-b66b-4e74-ac9c-6612533425d1", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)  # Adaptive inertia weight\n            self.c2 *= 0.99  # Decay factor for social parameter\n            self.c1 *= 0.99  # New line: Exponential decay for cognitive parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhanced the velocity update rule to include an exponential decay for the cognitive parameter to better balance exploration and exploitation.", "configspace": "", "generation": 18, "fitness": 0.3990652018163335, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.02.", "error": "", "parent_id": "300d119f-7001-4a83-893d-db4ab59df83f", "metadata": {"aucs": [0.4197502828763179, 0.4026522236893231, 0.37479309888335943]}, "mutation_prompt": null}
{"id": "725141bf-e026-48de-a61b-f3b7e6f1975a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # New line: Sinusoidal inertia weight adjustment\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Improved exploration by using a sinusoidal inertia weight adjustment instead of linear decay.", "configspace": "", "generation": 19, "fitness": 0.4118467996732214, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.03.", "error": "", "parent_id": "300d119f-7001-4a83-893d-db4ab59df83f", "metadata": {"aucs": [0.44448634096082673, 0.41060618907967716, 0.3804478689791603]}, "mutation_prompt": null}
{"id": "99941c2e-9daa-4171-af19-a5bc751d4eeb", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)  # Adaptive inertia weight\n            self.c2 *= (1 - evaluations / self.budget)**0.5  # New line: Non-linear decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Implement a non-linear decay for the social parameter to enhance exploration.", "configspace": "", "generation": 20, "fitness": 0.4031819986905076, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.01.", "error": "", "parent_id": "300d119f-7001-4a83-893d-db4ab59df83f", "metadata": {"aucs": [0.4201983785284692, 0.4052755098446926, 0.38407210769836087]}, "mutation_prompt": null}
{"id": "5fdfa738-1ecf-4dcb-95d5-849be6594041", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhanced exploration-exploitation balance by introducing an adaptive inertia weight decay factor.", "configspace": "", "generation": 21, "fitness": 0.4274642824122396, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.01.", "error": "", "parent_id": "300d119f-7001-4a83-893d-db4ab59df83f", "metadata": {"aucs": [0.43779065443673704, 0.4168292933778385, 0.42777289942214325]}, "mutation_prompt": null}
{"id": "fa02df4a-dc57-487a-875c-a92454bcc9be", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            self.c1 = 1.5 + 0.5 * np.cos(0.1 * evaluations)  # Updated line: Dynamic adjustment for cognitive parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduced a dynamic adjustment to the cognitive parameter to enhance convergence speed.", "configspace": "", "generation": 22, "fitness": 0.41240962301685524, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.00.", "error": "", "parent_id": "5fdfa738-1ecf-4dcb-95d5-849be6594041", "metadata": {"aucs": [0.40787168817130914, 0.4136796536074586, 0.4156775272717981]}, "mutation_prompt": null}
{"id": "37ec6bc4-b5a7-4e6f-870a-f1fc8e3b5d4f", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2 * (1 + np.std(population) / (ub - lb))  # Adaptive velocity scaling\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhanced exploration by introducing adaptive velocity scaling based on population diversity.", "configspace": "", "generation": 23, "fitness": 0.39744146098101135, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.03.", "error": "", "parent_id": "5fdfa738-1ecf-4dcb-95d5-849be6594041", "metadata": {"aucs": [0.39753805096768136, 0.4303302690294337, 0.36445606294591903]}, "mutation_prompt": null}
{"id": "25970b5e-c0c5-48da-818c-5e38af884c8c", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.std(velocities) / (ub - lb)  # Adaptive scaling factor based on velocity diversity\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduced adaptive mutation scaling based on velocity diversity to enhance exploration.  ", "configspace": "", "generation": 24, "fitness": 0.39830723006161656, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.02.", "error": "", "parent_id": "5fdfa738-1ecf-4dcb-95d5-849be6594041", "metadata": {"aucs": [0.3833072806996167, 0.39037659472192754, 0.42123781476330524]}, "mutation_prompt": null}
{"id": "d7e9123c-ec0c-4501-8481-8b7955ea985d", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Adjust population size based on convergence\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(10, int(self.initial_population_size * (1 - 0.5 * (evaluations / self.budget))))\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Improved adaptive behavior by incorporating a dynamic population size adjustment based on convergence.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (37,6) (50,6) ').", "error": "ValueError('operands could not be broadcast together with shapes (37,6) (50,6) ')", "parent_id": "5fdfa738-1ecf-4dcb-95d5-849be6594041", "metadata": {}, "mutation_prompt": null}
{"id": "8892f441-45b8-41a2-82bc-8d1919029779", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * (0.1 + 0.1 * np.std(population) / (ub - lb))  # Change made here for adaptive velocity clamping sensitivity\n            velocities = np.clip(velocities, -max_vel, max_vel)\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if np.random.rand() < 0.8:  # Change made here for tournament selection\n                new_global_best_index = np.random.choice(np.argsort(personal_best_scores)[:5])\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Improved population diversity maintenance by incorporating adaptive velocity clamping sensitivity and introducing tournament selection for global best updates.", "configspace": "", "generation": 26, "fitness": 0.35325439081629656, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.01.", "error": "", "parent_id": "5fdfa738-1ecf-4dcb-95d5-849be6594041", "metadata": {"aucs": [0.33309645008315847, 0.36503073975330536, 0.3616359826124259]}, "mutation_prompt": null}
{"id": "975d3614-3972-45ed-bd53-b32e355fb67f", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.7 + 0.3 * np.random.rand()  # Slightly adjusted adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Minor adjustment to adaptive DE scaling factor to enhance solution quality with minimal change.", "configspace": "", "generation": 27, "fitness": 0.3194640648102159, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.03.", "error": "", "parent_id": "5fdfa738-1ecf-4dcb-95d5-849be6594041", "metadata": {"aucs": [0.30800545200171936, 0.29575817080377453, 0.3546285716251538]}, "mutation_prompt": null}
{"id": "92991868-49fe-4ebb-8ba9-13145165d10c", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n            \n            # Adjust population size dynamically\n            self.population_size = max(20, int(self.population_size * 0.99))  # New line: dynamic population size adjustment\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduce dynamic population size adjustment to enhance convergence speed and solution quality.", "configspace": "", "generation": 28, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (49,6) (50,6) ').", "error": "ValueError('operands could not be broadcast together with shapes (49,6) (50,6) ')", "parent_id": "5fdfa738-1ecf-4dcb-95d5-849be6594041", "metadata": {}, "mutation_prompt": null}
{"id": "acb1644d-1ccf-4325-90d3-a00d3b80d421", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Local search enhancement\n            population += np.random.normal(0, 0.01 * (ub - lb), population.shape)  # New line: Gaussian perturbation\n            \n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Adaptive local search mechanism using Gaussian perturbation in the PSO phase to enhance local exploration.", "configspace": "", "generation": 29, "fitness": 0.36295799641258214, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.01.", "error": "", "parent_id": "5fdfa738-1ecf-4dcb-95d5-849be6594041", "metadata": {"aucs": [0.3774223526910918, 0.3490321817047648, 0.36241945484188964]}, "mutation_prompt": null}
{"id": "289678f7-4b27-42ef-a07a-0bcbcaf0802e", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.5 + 0.5 * np.random.rand()  # Adjusted scaling factor range\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * (0.5 + 0.5 * population_diversity))  # Modified crossover probability\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Improved exploration by introducing a self-adaptive DE scaling factor and selective perturbation for crossover.", "configspace": "", "generation": 30, "fitness": 0.3853054816570783, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.01.", "error": "", "parent_id": "5fdfa738-1ecf-4dcb-95d5-849be6594041", "metadata": {"aucs": [0.3895088560829415, 0.39054999032673365, 0.37585759856155965]}, "mutation_prompt": null}
{"id": "be81ee7d-6764-415d-81cd-df7e3df1361c", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                # Implement non-uniform selection mechanism\n                indices = np.random.choice(range(self.population_size), 3, replace=False, p=personal_best_scores / np.sum(personal_best_scores))\n                a, b, c = population[indices]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhanced exploration by introducing a non-uniform selection mechanism in the Differential Evolution step.", "configspace": "", "generation": 31, "fitness": 0.4058363548629213, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.01.", "error": "", "parent_id": "5fdfa738-1ecf-4dcb-95d5-849be6594041", "metadata": {"aucs": [0.4116744275842301, 0.3972845229893518, 0.4085501140151818]}, "mutation_prompt": null}
{"id": "782c95d2-5104-4037-8368-618914bdfa4c", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c2 *= 0.995  # Decay factor refined for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = 0.5 * (global_best_position + trial_vector)  # Refined global best update\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Improved global best position update with refined adaptive learning rates for enhanced convergence.", "configspace": "", "generation": 32, "fitness": 0.3947295982561736, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.00.", "error": "", "parent_id": "5fdfa738-1ecf-4dcb-95d5-849be6594041", "metadata": {"aucs": [0.3930413814052255, 0.3968838287392077, 0.3942635846240876]}, "mutation_prompt": null}
{"id": "59f2722b-f1c6-4c14-9384-4d7852137c1c", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99  # New line: Decay factor for cognitive parameter\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhanced exploration by adjusting the cognitive parameter decay for improved convergence.", "configspace": "", "generation": 33, "fitness": 0.4284986553335046, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.01.", "error": "", "parent_id": "5fdfa738-1ecf-4dcb-95d5-849be6594041", "metadata": {"aucs": [0.44194061323683165, 0.41854389281695237, 0.42501145994672984]}, "mutation_prompt": null}
{"id": "e3ba34b9-2123-46ab-b049-172e93351fb1", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 52  # Increased population size for better diversity\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99  # New line: Decay factor for cognitive parameter\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhanced exploration by increasing population size for better diversity.", "configspace": "", "generation": 34, "fitness": 0.4151650241236753, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42 with standard deviation 0.02.", "error": "", "parent_id": "59f2722b-f1c6-4c14-9384-4d7852137c1c", "metadata": {"aucs": [0.4224196867805622, 0.4341898679867562, 0.3888855176037075]}, "mutation_prompt": null}
{"id": "05b9ce87-b7ff-4529-bad0-51cacc9e30aa", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)\n            self.c1 *= 0.99\n            self.c2 *= 0.99\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2\n            velocities = np.clip(velocities, -max_vel, max_vel)\n            population = np.clip(population + velocities, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Adaptive tournament selection\n            tournament_size = max(2, int(self.population_size * 0.1)) # New line\n            winners = np.array([min(np.random.choice(self.population_size, tournament_size, replace=False), key=lambda idx: scores[idx]) for _ in range(self.population_size)]) # New line\n            for i in range(self.population_size): # New line\n                if scores[winners[i]] < personal_best_scores[i]: # New line\n                    personal_best_scores[i] = scores[winners[i]] # New line\n                    personal_best_positions[i] = population[winners[i]] # New line\n\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Integrates adaptive tournament selection and multi-phase exploration to enhance convergence robustness and diversity.", "configspace": "", "generation": 35, "fitness": 0.3162370926962353, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.01.", "error": "", "parent_id": "59f2722b-f1c6-4c14-9384-4d7852137c1c", "metadata": {"aucs": [0.3298132485808368, 0.3051189336988921, 0.3137790958089769]}, "mutation_prompt": null}
{"id": "f388a1a9-09f7-40d0-8fa0-fb9563db0eb6", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99  # Decay factor for cognitive parameter\n            self.c2 *= 0.99  # Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * (1 - evaluations / self.budget)  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduced adaptive mutation factor for DE based on iteration progress to enhance exploration and exploitation balance.", "configspace": "", "generation": 36, "fitness": 0.3565015687550712, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.04.", "error": "", "parent_id": "59f2722b-f1c6-4c14-9384-4d7852137c1c", "metadata": {"aucs": [0.3220739286803799, 0.3283248345443678, 0.419105943040466]}, "mutation_prompt": null}
{"id": "88fdb081-e204-4cb3-9ee4-4725d352125c", "solution": "import numpy as np\n\nclass HybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99  # Decay factor for cognitive parameter\n            self.c2 *= 0.99  # Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.8 + 0.2 * np.abs(np.sin(evaluations))  # Dynamic scaling based on sine wave\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE_Improved", "description": "Improve convergence by incorporating adaptive neighborhood search and dynamic parameter control.", "configspace": "", "generation": 37, "fitness": 0.3661023086684869, "feedback": "The algorithm HybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.03.", "error": "", "parent_id": "59f2722b-f1c6-4c14-9384-4d7852137c1c", "metadata": {"aucs": [0.35371089294328106, 0.3370624525228587, 0.407533580539321]}, "mutation_prompt": null}
{"id": "a328dbba-edc6-4164-a997-51b817d222c9", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99  # New line: Decay factor for cognitive parameter\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                population_diversity = np.std(population) / (ub - lb)\n\n                # Changed: Adaptive mutation strategy\n                self.F = 0.5 + 0.5 * population_diversity  # Adaptive scaling factor based on population diversity\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduced adaptive mutation strategy in DE for enhanced diversity maintenance.", "configspace": "", "generation": 38, "fitness": 0.3611040451702345, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.02.", "error": "", "parent_id": "59f2722b-f1c6-4c14-9384-4d7852137c1c", "metadata": {"aucs": [0.3705154698518013, 0.3270753078420413, 0.3857213578168609]}, "mutation_prompt": null}
{"id": "d959378b-71fc-4b1a-971f-5528e90be51f", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.3 + 0.7 * np.exp(-0.03 * evaluations)  # Adjusted adaptive inertia weight\n            self.c1 *= 0.98  # Modified decay factor for cognitive parameter\n            self.c2 *= 0.98  # Modified decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.3  # Slightly increased adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.5 + 0.5 * np.random.rand()  # Adjusted adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n                        # Trigger local optimization when diversity is low\n                        if population_diversity < 0.1:\n                            local_search = global_best_position + 0.01 * np.random.randn(self.dim)\n                            local_search = np.clip(local_search, lb, ub)\n                            local_score = func(local_search)\n                            evaluations += 1\n                            if local_score < global_best_score:\n                                global_best_score = local_score\n                                global_best_position = local_search\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Improved exploration and convergence through adaptive parameters and diversity-triggered local optimization.", "configspace": "", "generation": 39, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_id": "59f2722b-f1c6-4c14-9384-4d7852137c1c", "metadata": {}, "mutation_prompt": null}
{"id": "935fc900-2699-4f20-bd72-725889573eb8", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99  # New line: Decay factor for cognitive parameter\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c) + 0.1 * np.random.normal(size=self.dim), lb, ub)  # Added self-adaptive mutation\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhanced exploration by introducing a dynamic self-adaptive mutation operator for improved convergence.", "configspace": "", "generation": 40, "fitness": 0.37858763350821384, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.03.", "error": "", "parent_id": "59f2722b-f1c6-4c14-9384-4d7852137c1c", "metadata": {"aucs": [0.37541444780725175, 0.42151619704951604, 0.33883225566787367]}, "mutation_prompt": null}
{"id": "1660b356-c16b-4e08-842f-cd18d76c6d95", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * (np.std(population) / (ub - lb))  # Adaptive inertia weight based on population diversity\n            self.c1 *= 0.99  # New line: Decay factor for cognitive parameter\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduced adaptive inertia weight scaling based on the standard deviation of the population to balance exploration and exploitation dynamically.", "configspace": "", "generation": 41, "fitness": 0.38593534098623544, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.01.", "error": "", "parent_id": "59f2722b-f1c6-4c14-9384-4d7852137c1c", "metadata": {"aucs": [0.38235912330523836, 0.3742552929151406, 0.40119160673832754]}, "mutation_prompt": null}
{"id": "6338adaa-0ab6-408d-9b4c-16039848d5bc", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99  # New line: Decay factor for cognitive parameter\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhanced exploration by adjusting the cognitive parameter decay for improved convergence.", "configspace": "", "generation": 34, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "59f2722b-f1c6-4c14-9384-4d7852137c1c", "metadata": {"aucs": [0.44194061323683165, 0.41854389281695237, 0.42501145994672984]}, "mutation_prompt": null}
{"id": "a88b6331-d8d1-4c16-8116-da7f7a194221", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99  # New line: Decay factor for cognitive parameter\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n            if evaluations % (self.population_size * 10) == 0:  # Dynamic adjustment\n                self.population_size = max(10, int(self.population_size * 0.9))  # Change made here\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduce dynamic adjustment of the population size based on the convergence rate for enhanced exploration and exploitation balance.", "configspace": "", "generation": 43, "fitness": 0.3919868718315675, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.01.", "error": "", "parent_id": "59f2722b-f1c6-4c14-9384-4d7852137c1c", "metadata": {"aucs": [0.3947934855709412, 0.402929336678178, 0.37823779324558326]}, "mutation_prompt": null}
{"id": "b51be02d-e26a-4d99-afa9-327646244259", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60  # Changed from 50 to 60\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99  # New line: Decay factor for cognitive parameter\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Increase the population size to enhance solution diversity and potential convergence quality.", "configspace": "", "generation": 44, "fitness": 0.39355296640450604, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.02.", "error": "", "parent_id": "59f2722b-f1c6-4c14-9384-4d7852137c1c", "metadata": {"aucs": [0.40877714949636823, 0.4126070856065521, 0.35927466411059783]}, "mutation_prompt": null}
{"id": "af605129-1d65-4aed-8ace-e8db007ae7cf", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99  # New line: Decay factor for cognitive parameter\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhanced exploration by adjusting the cognitive parameter decay for improved convergence.", "configspace": "", "generation": 34, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "59f2722b-f1c6-4c14-9384-4d7852137c1c", "metadata": {"aucs": [0.44194061323683165, 0.41854389281695237, 0.42501145994672984]}, "mutation_prompt": null}
{"id": "e3b92cff-dabc-41e4-b294-ffddb6fec88b", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99  # New line: Decay factor for cognitive parameter\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * evaluations / self.budget  # Adaptive scaling factor based on evaluations\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhanced global exploration by introducing dynamic adjustment of the DE scaling factor based on evaluations.", "configspace": "", "generation": 46, "fitness": 0.4106779194363828, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.01.", "error": "", "parent_id": "59f2722b-f1c6-4c14-9384-4d7852137c1c", "metadata": {"aucs": [0.4199253015942962, 0.41030721217693467, 0.40180124453791766]}, "mutation_prompt": null}
{"id": "27b972f0-08fb-40ef-a39f-9ba5d60efdbf", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n    \n    def chaotic_sequence(self, size):\n        # New line: Generate chaotic sequence for randomization\n        r = 0.7  # Initial value for chaotic sequence\n        sequence = []\n        for _ in range(size):\n            r = 4 * r * (1 - r)\n            sequence.append(r)\n        return np.array(sequence)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99  # Decay factor for cognitive parameter\n            self.c2 *= 0.99  # Decay factor for social parameter\n            \n            # New line: Introduce chaos-based randomization for velocities\n            chaotic_r = self.chaotic_sequence(self.population_size * self.dim).reshape(self.population_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * chaotic_r * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduce chaos-based randomization to improve exploration and enhance convergence speed.", "configspace": "", "generation": 47, "fitness": 0.3684649823737242, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.03.", "error": "", "parent_id": "59f2722b-f1c6-4c14-9384-4d7852137c1c", "metadata": {"aucs": [0.33486018902202475, 0.3649568859039365, 0.40557787219521135]}, "mutation_prompt": null}
{"id": "53d8e70a-be87-42ad-afad-6a257f613dac", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99  # New line: Decay factor for cognitive parameter\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.2 * np.random.rand() + 0.2 * (global_best_score - scores[i]) / (np.max(scores) - np.min(scores) + 1e-8)  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhanced exploration by adjusting the cognitive parameter decay for improved convergence and adaptive mutation scaling.", "configspace": "", "generation": 48, "fitness": 0.40100916416164384, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.01.", "error": "", "parent_id": "59f2722b-f1c6-4c14-9384-4d7852137c1c", "metadata": {"aucs": [0.41065040718650636, 0.3893430797171916, 0.4030340055812335]}, "mutation_prompt": null}
{"id": "937d8e3f-d36a-4165-837a-50627ab29748", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99  # New line: Decay factor for cognitive parameter\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhanced exploration by adjusting the cognitive parameter decay for improved convergence.", "configspace": "", "generation": 34, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "59f2722b-f1c6-4c14-9384-4d7852137c1c", "metadata": {"aucs": [0.44194061323683165, 0.41854389281695237, 0.42501145994672984]}, "mutation_prompt": null}
{"id": "c4cf231d-9f51-4a11-b9c8-d8189b955598", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.6 * np.exp(-0.05 * evaluations)  # Adjusted inertia weight decay rate\n            self.c1 *= 0.99  # New line: Decay factor for cognitive parameter\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Adjusted inertia weight decay rate to enhance exploration-exploitation balance.", "configspace": "", "generation": 50, "fitness": 0.39596921888274367, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.01.", "error": "", "parent_id": "59f2722b-f1c6-4c14-9384-4d7852137c1c", "metadata": {"aucs": [0.40822055410539904, 0.40262522835474035, 0.37706187418809156]}, "mutation_prompt": null}
{"id": "fa01c30b-f733-40b7-bce7-6665e6ef538a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99  # New line: Decay factor for cognitive parameter\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n            # New line: Restart population if diversity is too low\n            if population_diversity < 0.01:\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduce population restart mechanism when diversity drops below a threshold for enhanced exploration.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_id": "59f2722b-f1c6-4c14-9384-4d7852137c1c", "metadata": {}, "mutation_prompt": null}
{"id": "d6d37fbe-a1b9-4a6e-8c27-764ad432c138", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99  # New line: Decay factor for cognitive parameter\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i] * 0.95  # Enhanced retention of personal-best positions\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduced adaptive personal-best retention to enhance solution quality.", "configspace": "", "generation": 52, "fitness": 0.4078729180184128, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.02.", "error": "", "parent_id": "59f2722b-f1c6-4c14-9384-4d7852137c1c", "metadata": {"aucs": [0.43780602011223324, 0.3860764770180726, 0.39973625692493264]}, "mutation_prompt": null}
{"id": "c2af5689-27bb-43e5-be73-cff9cd87e09b", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 = 1.5 * (1 - evaluations / self.budget)  # Linearly decreasing cognitive parameter\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduced a linearly decreasing cognitive parameter to enhance balance between exploration and exploitation.", "configspace": "", "generation": 53, "fitness": 0.4167216898117252, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42 with standard deviation 0.00.", "error": "", "parent_id": "59f2722b-f1c6-4c14-9384-4d7852137c1c", "metadata": {"aucs": [0.4174127040564989, 0.41074894785248295, 0.42200341752619375]}, "mutation_prompt": null}
{"id": "df3fbca2-45a2-4ca9-bd91-1f0bf96e6850", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.03 * evaluations)  # Changed line: Adaptive inertia weight with different exponential decay rate\n            self.c1 *= 0.99  # New line: Decay factor for cognitive parameter\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhanced exploration by adapting the inertia weight with a different decay rate.", "configspace": "", "generation": 54, "fitness": 0.41048706411345964, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.02.", "error": "", "parent_id": "59f2722b-f1c6-4c14-9384-4d7852137c1c", "metadata": {"aucs": [0.43965684699637464, 0.3997307334667043, 0.39207361187729994]}, "mutation_prompt": null}
{"id": "3f775483-ed8f-4ec1-93b2-5e392cb70474", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99  # New line: Decay factor for cognitive parameter\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + 1.1 * self.c2 * r2 * (global_best_position - population))  # Change made here\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhanced exploration by dynamically adjusting the PSO velocity update strategy.", "configspace": "", "generation": 55, "fitness": 0.42440356501216475, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42 with standard deviation 0.01.", "error": "", "parent_id": "59f2722b-f1c6-4c14-9384-4d7852137c1c", "metadata": {"aucs": [0.41916516599032505, 0.41936096885771623, 0.43468456018845314]}, "mutation_prompt": null}
{"id": "594c0cc0-f0f7-40ee-a169-f821bc33bfb1", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99  # Decay factor for cognitive parameter\n            self.c2 = 1.5 / (1 + np.exp(0.03 * evaluations))  # Sigmoid decay for the social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduced a sigmoid decay for the social parameter to enhance balanced exploration and exploitation.", "configspace": "", "generation": 56, "fitness": 0.38721235100973966, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.01.", "error": "", "parent_id": "59f2722b-f1c6-4c14-9384-4d7852137c1c", "metadata": {"aucs": [0.3887010886342065, 0.3803058384467545, 0.39263012594825797]}, "mutation_prompt": null}
{"id": "2cbbd706-8941-464b-a04b-4fa101e8ab35", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.5 + 0.3 * np.exp(-0.05 * evaluations)  # Modified inertia weight decay rate\n            self.c1 *= 0.99  # New line: Decay factor for cognitive parameter\n            self.c2 *= 0.99  # New line: Decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Improve the balance of exploration and exploitation by adjusting the inertia weight decay rate.", "configspace": "", "generation": 57, "fitness": 0.40823756851945214, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.02.", "error": "", "parent_id": "59f2722b-f1c6-4c14-9384-4d7852137c1c", "metadata": {"aucs": [0.44016448355830895, 0.40225225584741564, 0.38229596615263184]}, "mutation_prompt": null}
{"id": "983e202a-189d-441e-9b42-59e19716b924", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99  # New line: Decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhance the balance between exploration and exploitation by refining the update mechanism of the social parameter.", "configspace": "", "generation": 58, "fitness": 0.43198557984622576, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.01.", "error": "", "parent_id": "59f2722b-f1c6-4c14-9384-4d7852137c1c", "metadata": {"aucs": [0.4443877205733966, 0.43102460821358424, 0.42054441075169635]}, "mutation_prompt": null}
{"id": "d29df38f-3e1f-4be3-8c68-d4c5a3a606e1", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.cos((np.pi / self.budget) * evaluations)  # New line: Adaptive inertia weight using cosine annealing\n            self.c1 *= 0.99  # New line: Decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Refine the exploration-exploitation balance by dynamically adjusting the inertia weight using cosine annealing.", "configspace": "", "generation": 59, "fitness": 0.4165425312322389, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42 with standard deviation 0.03.", "error": "", "parent_id": "983e202a-189d-441e-9b42-59e19716b924", "metadata": {"aucs": [0.4437849582214284, 0.42416641102378005, 0.3816762244515083]}, "mutation_prompt": null}
{"id": "d5f89609-51a4-44dd-9fe9-65692b4590bf", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.98  # Changed line: Increased decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Slightly increase the cognitive parameter decay to foster better exploration and convergence.", "configspace": "", "generation": 60, "fitness": 0.4311641254261711, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.01.", "error": "", "parent_id": "983e202a-189d-441e-9b42-59e19716b924", "metadata": {"aucs": [0.44717776833610845, 0.4301053134290691, 0.41620929451333566]}, "mutation_prompt": null}
{"id": "27418bd9-e104-410d-971f-5ec0691bd83a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99  # New line: Decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.mean(np.std(population, axis=0)) / (ub - lb)  # Slightly different diversity measure\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Refine the adaptive crossover probability by incorporating a slightly different diversity measure.", "configspace": "", "generation": 61, "fitness": 0.39951257015263936, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.00.", "error": "", "parent_id": "983e202a-189d-441e-9b42-59e19716b924", "metadata": {"aucs": [0.3961626093852726, 0.3997797956345672, 0.4025953054380782]}, "mutation_prompt": null}
{"id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduce a random factor to the cognitive parameter decay for enhanced adaptability.", "configspace": "", "generation": 62, "fitness": 0.4323301850527923, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.01.", "error": "", "parent_id": "983e202a-189d-441e-9b42-59e19716b924", "metadata": {"aucs": [0.44337660877097984, 0.4309236898932305, 0.4226902564941666]}, "mutation_prompt": null}
{"id": "8d7092c5-af36-4895-802c-a354ae999223", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 51  # Slight increase in population size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Adjusted to increase population size to improve exploration capabilities slightly.", "configspace": "", "generation": 63, "fitness": 0.3846670641961967, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.02.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.39015512021825594, 0.4063833868846052, 0.3574626854857288]}, "mutation_prompt": null}
{"id": "399a7787-482a-48ce-ad25-ca2531faf37c", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.3 * np.exp(-0.05 * evaluations)  # 1. Changed exponential decay factor\n            self.c1 *= 0.99 + 0.01 * np.random.rand()\n            self.c2 *= 0.98\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.25  # 2. Increased max velocity clamping factor\n            velocities = np.clip(velocities, -max_vel, max_vel)\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.7 + 0.3 * np.random.rand()  # 3. Refined adaptive scaling factor range\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (0.8 * self.CR * population_diversity)  # 4. Adjusted crossover probability\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Refine the velocity update rule and DE mutation to enhance exploration and convergence balance.", "configspace": "", "generation": 64, "fitness": 0.3350489521996285, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.00.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.3331444108296655, 0.3324721618769163, 0.33953028389230366]}, "mutation_prompt": null}
{"id": "3d63e2b5-1252-415a-b9bb-e95c8e3fb8dc", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            population_diversity = np.std(population) / (ub - lb)  # Calculate population diversity\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations) * (1 + 0.5 * population_diversity)  # Adaptive inertia weight with diversity adjustment\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhance velocity adaptation by introducing diversity-based inertia weight adjustment for improved exploration.", "configspace": "", "generation": 65, "fitness": 0.3823801740192745, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.01.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.3836222543889508, 0.37047645038917887, 0.3930418172796938]}, "mutation_prompt": null}
{"id": "57bebedd-85d0-4db6-892c-445841d4dfb3", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduce a random factor to the cognitive parameter decay for enhanced adaptability.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.44337660877097984, 0.4309236898932305, 0.4226902564941666]}, "mutation_prompt": null}
{"id": "a399d95c-3124-41eb-afa6-f20083a36ab3", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / max((ub - lb), 1e-10)  # Adaptive crossover probability based on diversity\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Implement adaptive control of the population diversity to enhance convergence speed in HybridPSO_DE.", "configspace": "", "generation": 67, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {}, "mutation_prompt": null}
{"id": "8645b33e-9445-4652-b4cf-66b41bd7a585", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduce a random factor to the cognitive parameter decay for enhanced adaptability.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.44337660877097984, 0.4309236898932305, 0.4226902564941666]}, "mutation_prompt": null}
{"id": "9467c9ac-077b-45d7-9a68-5584efddecb1", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.3 + 0.7 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with expanded range for better exploration\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Increase the inertia weight adaptive range to enhance exploration capabilities.", "configspace": "", "generation": 69, "fitness": 0.3609878066198576, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.02.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.34352867186036784, 0.3911323023567289, 0.34830244564247603]}, "mutation_prompt": null}
{"id": "d569aea2-ccc2-4f6b-94bb-387824eede0d", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Use a dynamic population size for better exploration-exploitation balance.", "configspace": "", "generation": 70, "fitness": 0.4097613000359763, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.00.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.41541775276859305, 0.4093461111766733, 0.4045200361626623]}, "mutation_prompt": null}
{"id": "099751f0-91f4-4644-b120-0fc77381f8fc", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.5 + 0.5 * np.sin(0.1 * evaluations)  # Adaptive inertia weight with sinusoidal decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhanced the adaptive inertia weight by using a sinusoidal decay to improve exploration-exploitation balance.", "configspace": "", "generation": 71, "fitness": 0.41768748942097805, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42 with standard deviation 0.01.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.42197029404009845, 0.4075115075361021, 0.42358066668673366]}, "mutation_prompt": null}
{"id": "2fe26a6e-6b3f-4b75-b7c4-0a201799c494", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.04 * evaluations)  # Adjusted exponential decay for inertia weight\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Adjust the inertia weight's exponential decay rate for improved exploration and exploitation balance.", "configspace": "", "generation": 72, "fitness": 0.4069629516574966, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.01.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.40309951436008584, 0.4002854405760067, 0.41750390003639715]}, "mutation_prompt": null}
{"id": "8a40472d-2392-444a-afce-6b5b91750e5a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.5 + 0.3 * np.random.rand()  # Adaptive scaling factor range refined\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Improved the adaptive DE scaling factor range to enhance exploration-exploitation balance.", "configspace": "", "generation": 73, "fitness": 0.4062071463593398, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.00.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.4049218766603031, 0.4091851702128786, 0.40451439220483765]}, "mutation_prompt": null}
{"id": "25e8e999-43c3-4b7a-8e5a-157295bece53", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index] + 0.01 * np.random.randn(self.dim) # Add random perturbation\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduce adaptive random perturbation to the global best position to enhance exploration.", "configspace": "", "generation": 74, "fitness": 0.40683813756422965, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.01.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.3997865270803984, 0.39480317493472494, 0.42592471067756554]}, "mutation_prompt": null}
{"id": "28249361-3d8d-4f7c-9116-48ebab12f255", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Dynamic population size adjustment\n            if evaluations > self.budget * 0.5:\n                self.population_size = 30 + int(20 * np.random.rand())\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.5 + 0.5 * np.random.rand()  # More variation in scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhanced exploration by introducing dynamic population size and adaptive mutation strategy in HybridPSO_DE for improved convergence.", "configspace": "", "generation": 75, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (30,6) (50,6) ').", "error": "ValueError('operands could not be broadcast together with shapes (30,6) (50,6) ')", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {}, "mutation_prompt": null}
{"id": "1ea349b5-5b12-4949-8bf3-b784f2917793", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduced adaptive mutation probability based on the diversity of solutions to enhance exploration.", "configspace": "", "generation": 76, "fitness": 0.34987708402258494, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.03.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.316232037923023, 0.34119378853995186, 0.3922054256047799]}, "mutation_prompt": null}
{"id": "231fba08-a1c9-4112-bac2-3d5a4e025cbb", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * (0.2 + 0.1 * np.exp(-0.05 * (global_best_score - np.min(personal_best_scores))))  # Enhanced velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhanced adaptive velocity clamping factor to improve convergence by adding a learning component based on the best position achieved so far.", "configspace": "", "generation": 77, "fitness": 0.37617282730182877, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.01.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.39203722029528665, 0.3739032705262446, 0.36257799108395516]}, "mutation_prompt": null}
{"id": "7c339376-509a-4c2d-b8d7-34851a5f5a50", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98 + 0.02 * np.random.rand()  # Introduced randomness in the decay factor for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduce a random factor to the social parameter decay for enhanced adaptability.", "configspace": "", "generation": 78, "fitness": 0.3927399192174679, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.01.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.3894345868127098, 0.4111253759069169, 0.3776597949327771]}, "mutation_prompt": null}
{"id": "9f922a78-a3fb-45d5-9ddf-23f403229c3b", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.4 + 0.6 * (global_best_score - scores[i]) / (global_best_score + 1e-8)  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Integrate adaptive mutation scaling based on solution quality to enhance convergence.", "configspace": "", "generation": 79, "fitness": 0.30831489593072886, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.01.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.30635582295128383, 0.3225690741179771, 0.2960197907229257]}, "mutation_prompt": null}
{"id": "b83a4ff3-3c02-4143-a42b-1ccb6e426a74", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduce a random factor to the cognitive parameter decay for enhanced adaptability.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.44337660877097984, 0.4309236898932305, 0.4226902564941666]}, "mutation_prompt": null}
{"id": "fa627c0d-69f2-4487-a901-e778a6807cbd", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.5 * np.random.rand()  # Adjusted scaling factor range for more exploration\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhance exploration by increasing the randomness in the mutation process of DE.", "configspace": "", "generation": 81, "fitness": 0.3994419324975036, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.01.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.39041833377798085, 0.3903517679632478, 0.41755569575128204]}, "mutation_prompt": null}
{"id": "d49703a0-6160-4830-b4ac-ac97478079c4", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= (0.99 + 0.02 * np.random.rand())  # Increased randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhanced cognitive parameter randomness for improved exploration-exploitation balance.", "configspace": "", "generation": 82, "fitness": 0.4017506060767218, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.02.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.4159107571079077, 0.4089296963898281, 0.38041136473242954]}, "mutation_prompt": null}
{"id": "432c06a5-de11-47b9-ba80-43b647f821f1", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                self.CR = 0.7 + 0.3 * (1 - evaluations / self.budget)  # Adaptive crossover probability based on iteration progress\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduce dynamic adjustment to DE crossover probability based on iteration progress.", "configspace": "", "generation": 83, "fitness": 0.4091763084789153, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.00.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.41382371906120496, 0.4091851702128786, 0.4045200361626623]}, "mutation_prompt": null}
{"id": "b253c7a3-5aa5-44ac-836b-56d2b5163f9a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.97  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Adjust the decay rate of the social parameter for slightly enhanced adaptability.", "configspace": "", "generation": 84, "fitness": 0.4046578270432408, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.01.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.3885180886609282, 0.4139033275882882, 0.4115520648805062]}, "mutation_prompt": null}
{"id": "2e1a6e13-5e33-4c7a-bef3-47ac177f0c67", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.98 + 0.02 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Slightly increased the adaptive decay rate of the cognitive parameter to balance exploration and exploitation.", "configspace": "", "generation": 85, "fitness": 0.407733413683289, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.00.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.4096098487304106, 0.40991319339996257, 0.4036771989194937]}, "mutation_prompt": null}
{"id": "efae4518-5307-47ee-a910-87cf4c4c4fb1", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.4 * np.exp(-0.05 * evaluations)  # Adjusted adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Adjust the inertia weight's decay rate for improved balance between exploration and exploitation.", "configspace": "", "generation": 86, "fitness": 0.39533093847999307, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.01.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.3907744322237433, 0.409170764768801, 0.38604761844743496]}, "mutation_prompt": null}
{"id": "3aca171a-e166-4134-9e69-d01e33d41337", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity) * 1.01  # Improved crossover probability scaling\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhance the crossover probability by incorporating adaptive diversity scaling for improved exploration.", "configspace": "", "generation": 87, "fitness": 0.4068668111003562, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.00.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.4067342859617331, 0.4093461111766733, 0.4045200361626623]}, "mutation_prompt": null}
{"id": "d58d74ad-c52c-4db4-b01d-7ba49a3ecd65", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.98 + 0.04 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Adjust random factor in cognitive parameter decay for enhanced exploration.", "configspace": "", "generation": 88, "fitness": 0.4015923221429385, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.02.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.4155993481887438, 0.4091011611857245, 0.3800764570543472]}, "mutation_prompt": null}
{"id": "b504a9cc-11e3-48dc-9aaf-d4a191f61a6b", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations) * (0.7 + 0.3 * np.sin(evaluations)) # Chaotic factor for inertia weight\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhance global exploration by introducing a chaotic factor into the random generation of the inertia weight.", "configspace": "", "generation": 89, "fitness": 0.3878341789375888, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.02.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.3705579592484417, 0.4091250768183631, 0.3838195007459617]}, "mutation_prompt": null}
{"id": "d8bdef81-c255-4a91-82d1-fa0e59736bac", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduce a random factor to the cognitive parameter decay for enhanced adaptability.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.44337660877097984, 0.4309236898932305, 0.4226902564941666]}, "mutation_prompt": null}
{"id": "99cf23f6-2db9-46d4-8f20-91797dee84dd", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 * np.exp(-0.001 * evaluations) + 0.01 * np.random.rand()  # Changed line: Introduced time-varying factor\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhance adaptability by integrating a time-varying learning rate for the cognitive parameter and dynamic boundary adjustments to improve convergence.", "configspace": "", "generation": 91, "fitness": 0.3347457092198097, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.01.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.3215837492657837, 0.34946609067006407, 0.3331872877235813]}, "mutation_prompt": null}
{"id": "6661af74-5711-4751-9a8f-a8a657bea396", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations) * np.std(personal_best_scores)  # Change made here\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduce adaptive scaling for inertia weight with respect to the standard deviation of personal best scores.", "configspace": "", "generation": 92, "fitness": 0.40299989583166723, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.01.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.4176912932517669, 0.40869412115098414, 0.3826142730922507]}, "mutation_prompt": null}
{"id": "bb71a558-1f44-42b5-944a-d1145e5689e1", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.5 + 0.5 * np.random.rand()  # Adaptive scaling factor adjusted\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Slightly adjust the adaptive scaling factor in the DE step to improve diversity and exploration.", "configspace": "", "generation": 93, "fitness": 0.3979910692672379, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.02.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.3730777426791396, 0.4115494691822321, 0.4093459959403418]}, "mutation_prompt": null}
{"id": "8a1c3da0-5c2d-4f2b-a5de-c873a6d870c7", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            learning_rate = 0.05 + 0.95 * (1 - evaluations / self.budget)  # Adaptive learning rate\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduce adaptive learning rates for personal and global best updates to enhance convergence.", "configspace": "", "generation": 94, "fitness": 0.4097613000359763, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.00.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.41541775276859305, 0.4093461111766733, 0.4045200361626623]}, "mutation_prompt": null}
{"id": "c403fc68-5b10-4f1d-a6dc-1f31fec44408", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c) * (1 + np.random.rand()), lb, ub)  # Adaptive mutation strength\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduce adaptive mutation strength in the DE phase for increased exploration and exploitation balance.", "configspace": "", "generation": 95, "fitness": 0.4029888038139899, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.01.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.4103145902045934, 0.3963333050377128, 0.4023185161996633]}, "mutation_prompt": null}
{"id": "e5493ee2-306c-4b1a-b57b-8a37bd41d076", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.995 + 0.005 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Adjusting the cognitive parameter's rate of decay to enhance exploration in the early stages.", "configspace": "", "generation": 96, "fitness": 0.22873601944779146, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.01.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.21549080649886954, 0.234501017118945, 0.23621623472555986]}, "mutation_prompt": null}
{"id": "b9c1c681-7c3c-4ce4-a2ec-cd3a7bcde9a6", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.975  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Apply a slight increase in the social parameter's decay rate to foster exploration. ", "configspace": "", "generation": 97, "fitness": 0.40092678594188486, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.01.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.3894178945191583, 0.4120408783114292, 0.401321584995067]}, "mutation_prompt": null}
{"id": "fc7d5212-c98c-4867-bbb9-ed0cff431390", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.45 * np.random.rand()  # Randomized perturbation to scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Enhance adaptability by dynamically adjusting the DE scaling factor with randomized perturbation.", "configspace": "", "generation": 98, "fitness": 0.4041413704891901, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.01.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.39444426226302653, 0.4092953919947163, 0.40868445720982727]}, "mutation_prompt": null}
{"id": "d8a05e5a-5a60-4f17-96e9-9e47c9cfa9a3", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index]\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions - PSO part\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-0.05 * evaluations)  # Adaptive inertia weight with exponential decay\n            self.c1 *= 0.99 + 0.01 * np.random.rand()  # Introduced randomness in the decay factor for cognitive parameter\n            self.c2 *= 0.98 + 0.02 * np.random.rand()  # Slightly faster decay for social parameter\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (personal_best_positions - population) \n                          + self.c2 * r2 * (global_best_position - population))\n            max_vel = (ub - lb) * 0.2  # Adaptive velocity clamping\n            velocities = np.clip(velocities, -max_vel, max_vel)  # Change made here\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < global_best_score:\n                global_best_score = personal_best_scores[new_global_best_index]\n                global_best_position = personal_best_positions[new_global_best_index]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive scaling factor\n                mutant_vector = np.clip(a + self.F * (b - c), lb, ub)\n                population_diversity = np.std(population) / (ub - lb)\n                crossover = np.random.rand(self.dim) < (self.CR * population_diversity)  # Adaptive crossover probability based on diversity\n                trial_vector = np.where(crossover, mutant_vector, population[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSO_DE", "description": "Introduce a random factor to the social parameter decay for improved exploration.", "configspace": "", "generation": 99, "fitness": 0.3927399192174679, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.01.", "error": "", "parent_id": "2fc757dc-fcbb-489b-a388-5f421aaebf4a", "metadata": {"aucs": [0.3894345868127098, 0.4111253759069169, 0.3776597949327771]}, "mutation_prompt": null}

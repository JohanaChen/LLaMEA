{"id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "A novel Quantum-inspired Particle Swarm Optimization (QPSO) algorithm that mimics quantum behaviors for enhanced exploration and exploitation in high-dimensional search spaces.", "configspace": "", "generation": 0, "fitness": 0.08582361327881227, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.00.", "error": "", "parent_id": null, "metadata": {"aucs": [0.08582361327881227, 0.08582361327881227, 0.08582361327881227]}, "mutation_prompt": null}
{"id": "fad0e748-dda6-441c-97b4-8242c335d225", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n            \n            # Adjust gamma dynamically\n            self.gamma = 0.5 * (1 - evaluations / self.budget)\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhance QPSO by adapting the gamma parameter based on evaluations for a better exploration-exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "66347bd3-1bc8-460b-9ae3-234212ed0786", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n            # Adaptive gamma\n            self.gamma *= 0.99\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "A slightly enhanced Quantum-Inspired Particle Swarm Optimization with adaptive gamma for better exploration-exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "d8a92d83-9fd1-4b1b-8e7d-aef25fb91f5b", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + (self.gamma + evaluations/self.budget) * (self.personal_best_positions[i] - self.positions[i]) \n                                  + (self.gamma + evaluations/self.budget) * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced QPSO with adaptive gamma for improved balance between exploration and exploitation.", "configspace": "", "generation": 3, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "f74d4bbc-da7a-4f68-a248-d897bc4d1c84", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + (self.gamma * evaluations / self.budget) * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Improved Quantum-inspired PSO with adaptive gamma for enhanced balance between exploration and exploitation.", "configspace": "", "generation": 4, "fitness": 0.06627392164053474, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.01.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.07420924412360852, 0.06923296147473823, 0.05537955932325744]}, "mutation_prompt": null}
{"id": "ad7f9cc3-d1e4-4f62-a78f-900952b7d15b", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.6  # Balance between exploration and exploitation (adjusted)\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhance the balance between exploration and exploitation by adjusting the gamma parameter.", "configspace": "", "generation": 5, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "f8b137ad-4031-40e2-a65f-8b25c5a4fdab", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                self.gamma = 0.4 + 0.1 * np.random.rand()  # Adaptive gamma\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced Quantum-inspired PSO with adaptive gamma for improved balance between exploration and exploitation.", "configspace": "", "generation": 6, "fitness": 0.04977252082532221, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.01.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.06275975625083374]}, "mutation_prompt": null}
{"id": "fd0b206c-d338-4a7b-9265-f3dce7c17b88", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)\n        self.gamma = 0.5\n        self.alpha = 0.9  # Adaptive inertia weight\n        self.positions = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.normal(scale=0.1, size=(self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                score = func(self.positions[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    self.velocities[i] = (self.alpha * self.velocities[i] \n                                  + self.phi * (self.personal_best_positions[i] - self.positions[i])\n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    if evaluations / self.budget > 0.5:  # Multi-phase approach\n                        self.gamma *= 1.01  # Increase exploitation\n                    else:\n                        self.gamma *= 0.99  # Increase exploration\n                        \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced Quantum-Inspired PSO with adaptive velocities and multi-phase search for improved optimization performance.", "configspace": "", "generation": 7, "fitness": 0.049017568316102454, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.04678561788383995, 0.04989246017646576, 0.05037462688800165]}, "mutation_prompt": null}
{"id": "7063a256-0a38-4d2a-80bb-392a986a3237", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update with random perturbation\n                    random_perturbation = np.random.uniform(-0.1, 0.1, self.dim)  # Added line\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i])) + random_perturbation\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced the quantum-inspired velocity update by adding a random perturbation factor for increased diversity in the search space.", "configspace": "", "generation": 8, "fitness": 0.032059945507653086, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.02.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.06609467574819772, 0.013509124853497867, 0.016576035921263665]}, "mutation_prompt": null}
{"id": "3c038a73-0aeb-42ef-8fff-518e84cc5bf1", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.72  # Adjusted constriction factor for better convergence\n        self.gamma = np.linspace(0.4, 0.6, self.budget)  # Adaptive balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma[evaluations] * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma[evaluations] * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhancing the Quantum-inspired Particle Swarm Optimization (QPSO) algorithm by adjusting the constriction factor and introducing adaptive gamma for improved convergence and adaptability.", "configspace": "", "generation": 9, "fitness": 0.05449150277720801, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.0545992964150217, 0.05449661300939779, 0.054378598907204534]}, "mutation_prompt": null}
{"id": "f4b914ab-9ea7-4341-a83c-c7c65358d2d1", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.gamma = 0.9 - 0.4 * (evaluations / self.budget)  # Dynamically adjust gamma\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced QPSO with dynamic gamma adjustment to improve convergence by balancing exploration and exploitation more effectively.", "configspace": "", "generation": 10, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "523b050d-9db4-495a-9b7e-2ecb3bb009ee", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Adjust gamma dynamically based on evaluations\n                    self.gamma = 0.5 * (1 - evaluations / self.budget)\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced Quantum-inspired PSO with adaptive gamma for dynamic balance between exploration and exploitation.", "configspace": "", "generation": 11, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "b039569b-2247-4ed0-a58e-17b598c58c38", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.inertia = 0.9  # Added: Adaptive inertia weight for exploration\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.inertia * self.velocities[i] + self.phi * (\n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Introducing an adaptive inertia weight to enhance exploration in Quantum-inspired PSO for diverse search spaces.", "configspace": "", "generation": 12, "fitness": 0.046722861825327956, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.04762094890002433, 0.044989969198032664, 0.04755766737792688]}, "mutation_prompt": null}
{"id": "3cb13951-758b-48f1-bd98-ea6a19e02668", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                self.gamma = 0.5 + 0.5 * (evaluations / self.budget)  # Dynamic gamma adjustment\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Introduce a dynamic gamma adjustment based on evaluations to balance exploration and exploitation.", "configspace": "", "generation": 13, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "003cd799-2621-40df-a71e-1f1d9ab90cd8", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n            # Dynamic gamma update\n            self.gamma = 0.5 + (0.5 * evaluations / self.budget)\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Improved Quantum-inspired Particle Swarm Optimization with dynamic gamma adjustment for better balance between exploration and exploitation.", "configspace": "", "generation": 14, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "45053c8a-9fcb-4ca8-ac6c-d721e227839b", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + np.random.uniform(0.4, 0.6) * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced Quantum-inspired PSO with adaptive gamma for improved balance between exploration and exploitation.", "configspace": "", "generation": 15, "fitness": 0.06343455383158543, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.07357036854170351, 0.043278903112566436, 0.07345438984048636]}, "mutation_prompt": null}
{"id": "cf0818e7-15ad-4f4b-b1f7-f86cc8d97371", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + (self.gamma + np.random.rand() * 0.2) * (self.personal_best_positions[i] - self.positions[i]) \n                                  + (self.gamma + np.random.rand() * 0.2) * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced Quantum-inspired PSO with adaptive gamma for improved exploration-exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.03852319154179773, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.03852319154179773, 0.03852319154179773, 0.03852319154179773]}, "mutation_prompt": null}
{"id": "ef872c2f-14d9-481f-983b-57e6c8d0c33b", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n        damping_factor = 0.99  # New adaptive velocity damping factor\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = damping_factor * (self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i])))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced Quantum-Inspired PSO with Adaptive Velocity Damping for improved convergence.", "configspace": "", "generation": 17, "fitness": 0.04884310836760175, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.04884310836760175, 0.04884310836760175, 0.04884310836760175]}, "mutation_prompt": null}
{"id": "f005b7b5-55e9-4458-8f83-01baebaa0c2d", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n            # Adjust gamma dynamically\n            self.gamma = 0.5 + (0.5 * (1 - (evaluations / self.budget)))\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced QPSO with adaptive gamma for improved dynamic balance between exploration and exploitation.", "configspace": "", "generation": 18, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "f909ce18-c8aa-411b-838f-7b84e53716a2", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + (self.gamma * (1 - evaluations / self.budget)) * (self.personal_best_positions[i] - self.positions[i]) \n                                  + (self.gamma * (1 - evaluations / self.budget)) * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhance convergence by adjusting the gamma parameter dynamically based on evaluation progress.", "configspace": "", "generation": 19, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "4bb4a587-02da-4deb-be09-7cc742d2a0a3", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                self.gamma = 0.5 + (0.5 * evaluations / self.budget)  # Dynamic gamma update\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Improved exploration-exploitation balance by adjusting gamma dynamically based on budget utilization.", "configspace": "", "generation": 20, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "a2d467ec-24ce-4ec8-a958-e8032805aa07", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                self.gamma = 0.4 + 0.2 * (global_best_score / (np.min(self.personal_best_scores) + 1e-9))  # Adaptive gamma\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced Quantum-inspired Particle Swarm Optimization with adaptive gamma for improved dynamic balance between exploration and exploitation.", "configspace": "", "generation": 21, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "0c27ea89-2130-4183-8afd-a28a8dac2d92", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update with dynamic inertia weight\n                    inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)  # Dynamic inertia weight\n                    self.velocities[i] = inertia_weight * self.velocities[i] + self.phi * (self.gamma * (self.personal_best_positions[i] - self.positions[i]) + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced the QuantumInspiredPSO by adjusting the inertia weight dynamically to improve convergence and exploration balance.", "configspace": "", "generation": 22, "fitness": 0.04672611525133482, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.047625570526224736, 0.04499058076059148, 0.047562194467188235]}, "mutation_prompt": null}
{"id": "bed3a463-1b37-46c9-9ed4-aa2af8f98a38", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                self.gamma = 0.5 * (1 + evaluations / self.budget)  # Dynamic gamma\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Improved Quantum-inspired PSO with dynamic gamma for adaptive exploration-exploitation balance.", "configspace": "", "generation": 23, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "d57ac6b7-6a7f-418a-b13e-f1a45e587f5c", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + 1.2 * self.gamma * (self.personal_best_positions[i] - self.positions[i])  # Slight increase in exploitation factor\n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Improved convergence by enhancing the exploitation factor in velocity updates.", "configspace": "", "generation": 24, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "6ad359fc-7bbf-4a07-9266-a22c51a148c5", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update with adaptive gamma\n                    gamma_dynamic = np.random.rand()  # Adjust gamma dynamically\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + gamma_dynamic * (self.personal_best_positions[i] - self.positions[i]) \n                                  + gamma_dynamic * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhance QuantumInspiredPSO by introducing adaptive gamma for dynamic balance between exploration and exploitation.", "configspace": "", "generation": 25, "fitness": 0.0739687968173965, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.07408043413935561, 0.07405056665804721, 0.0737753896547867]}, "mutation_prompt": null}
{"id": "23a6353b-7665-4665-bc12-c7b1dfe0f81d", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.55  # Balance between exploration and exploitation (updated)\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhance exploration capability by slightly increasing the gamma factor to improve global search exploration.", "configspace": "", "generation": 26, "fitness": 0.03852319154179773, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.03852319154179773, 0.03852319154179773, 0.03852319154179773]}, "mutation_prompt": null}
{"id": "ee6f32e3-49b5-4167-add3-eabb0067ca8a", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.gamma = 0.5 + (evaluations / self.budget) * 0.5  # Adaptive gamma\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced version of QuantumInspiredPSO with an adaptive gamma factor for better exploration-exploitation balance.", "configspace": "", "generation": 27, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "61ed626b-0387-48a9-9038-aeff3e57165a", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + (0.2 + 0.8 * evaluations / self.budget) * (self.personal_best_positions[i] - self.positions[i]) \n                                  + (0.2 + 0.8 * evaluations / self.budget) * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Improved Quantum-inspired Particle Swarm Optimization (QPSO) with adaptive gamma for dynamic exploration-exploitation balance.", "configspace": "", "generation": 28, "fitness": 0.06307016026015784, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.06454233117767327, 0.07376236978079198, 0.05090577982200828]}, "mutation_prompt": null}
{"id": "83ea2d76-c4fd-419a-b754-6d51ad6d5628", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + (self.gamma + evaluations/self.budget) * (self.personal_best_positions[i] - self.positions[i]) \n                                  + (self.gamma + evaluations/self.budget) * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced Quantum-inspired PSO with adaptive gamma for improved exploration-exploitation balance.", "configspace": "", "generation": 29, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "dafdef6a-ffd0-4f5f-823b-5b1903d1ec45", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                decay_factor = 0.99  # Decay factor for phi\n                self.phi *= decay_factor  # Update phi with decay\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Introduced a decay factor to the constriction parameter phi for better convergence over iterations.", "configspace": "", "generation": 30, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "908288c2-9770-46ed-b6f8-cda3a232bd14", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                self.gamma = max(0.5, 1 - evaluations / self.budget)  # Adaptive gamma\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "A refined Quantum-inspired PSO with adaptive gamma to enhance convergence dynamics.", "configspace": "", "generation": 31, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "ea2e8c54-f9a1-4842-a440-535a9563e8bf", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                self.gamma = 0.5 + 0.5 * (evaluations / self.budget)  # Dynamic gamma adjustment\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced Quantum-inspired Particle Swarm Optimization (QPSO) with dynamic gamma adjustment based on budget utilization for improved exploration-exploitation balance.", "configspace": "", "generation": 32, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "10665c17-40ef-4acc-8b78-622eec46e029", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.4  # Adjusted balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "An enhanced Quantum-inspired PSO that adapts the balance factor to improve convergence speed.", "configspace": "", "generation": 33, "fitness": 0.058154530400157355, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.0739290102210931, 0.043278903112566436, 0.057255677866812515]}, "mutation_prompt": null}
{"id": "703883b0-41da-4d78-9b6b-d65e58709bc0", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + np.random.uniform(0.4, 0.6) * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced Quantum-inspired PSO with adaptive gamma for better balance between exploration and exploitation.", "configspace": "", "generation": 34, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "391aae67-aaf6-414c-8ec8-d30352baa47b", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.6  # Adjusted balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Slightly adjust the balance between exploration and exploitation by modifying the gamma parameter to enhance performance.", "configspace": "", "generation": 35, "fitness": 0.03852319154179773, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.03852319154179773, 0.03852319154179773, 0.03852319154179773]}, "mutation_prompt": null}
{"id": "107ed606-2fa3-4a98-9fbf-a4b7fc3bc8bd", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic gamma adjustment\n            self.gamma = 0.5 + 0.5 * (evaluations / self.budget)\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhance Quantum Inspired PSO by dynamically adjusting the gamma parameter based on budget utilization to improve balance between exploration and exploitation.", "configspace": "", "generation": 36, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "79c2eebe-1487-439c-b2b3-c27a750859cb", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                # Modify gamma adaptively\n                self.gamma = 0.5 * (1 - evaluations / self.budget)\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Introduce an adaptive gamma based on the number of remaining evaluations to dynamically adjust exploration and exploitation balance.", "configspace": "", "generation": 37, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "b7799f04-4455-419d-ad54-6e0a8ee5dc48", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + (self.gamma - 0.1 * (self.budget - evaluations) / self.budget) * (self.personal_best_positions[i] - self.positions[i])\n                                  + (self.gamma - 0.1 * (self.budget - evaluations) / self.budget) * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced Quantum-inspired PSO with dynamic gamma to improve balance between exploration and exploitation.", "configspace": "", "generation": 38, "fitness": 0.058208160199367844, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.07393337228946106, 0.043278903112566436, 0.05741220519607604]}, "mutation_prompt": null}
{"id": "0cf945c4-b28a-4c88-92d9-c9c7e5b2f8d4", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / 2  # Adjusted constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Modified the constriction factor to enhance convergence speed.", "configspace": "", "generation": 39, "fitness": 0.043741329373260474, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.04394417169957432, 0.04372316509353913, 0.04355665132666797]}, "mutation_prompt": null}
{"id": "df0b3766-390d-422f-848b-e5cfd7a2438c", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.4 + np.log(self.dim) / np.log(2)  # Slightly decreased constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced Quantum-inspired PSO by slightly decreasing the constriction factor to promote better convergence.", "configspace": "", "generation": 40, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "1e2c7387-0abb-4e47-98c7-5078709b1231", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update with adaptive gamma\n                    self.gamma = 0.5 * (1 - evaluations / self.budget)  # Adaptive gamma\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Introducing adaptive gamma for dynamic exploration-exploitation balance in QuantumInspiredPSO.", "configspace": "", "generation": 41, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "a48b0d5f-034f-4d69-926b-7793a05ca52b", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5 + 0.1 * np.log(self.dim)  # Adaptive gamma for exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Introduce adaptive gamma based on dimensionality to enhance exploration-exploitation balance.", "configspace": "", "generation": 42, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "1f4392fd-179f-4135-8b5a-34fd88805ce6", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = np.random.uniform(0.4, 0.6)  # Adaptive balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Quantum-inspired Particle Swarm Optimization with adaptive gamma for enhanced balance between exploration and exploitation.", "configspace": "", "generation": 43, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "6dbd3930-a3ba-4e15-b632-a6acc6f7bac0", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                self.gamma = 0.9 * (1 - evaluations / self.budget) + 0.1  # Adaptive gamma\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced Quantum-inspired Particle Swarm Optimization (QPSO) with adaptive gamma for improved balance between exploration and exploitation.", "configspace": "", "generation": 44, "fitness": 0.03210159851819402, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.03178245567399107, 0.03212933910754989, 0.03239300077304108]}, "mutation_prompt": null}
{"id": "d4553ccb-489a-42b4-8c4c-572332f01e7e", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.6  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Adjusted the gamma parameter to enhance the balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "d2e46c11-3fe9-4ea1-9732-9ee714f90d06", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    adaptive_gamma = self.gamma * (1 - evaluations / self.budget)\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + adaptive_gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + adaptive_gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced Quantum-inspired PSO with adaptive gamma for dynamic exploration-exploitation balance.", "configspace": "", "generation": 46, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "0b39ea71-126f-44ac-bb20-a2eff73b4330", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.gamma = 0.4 + 0.1 * np.random.rand()  # Adjust gamma dynamically\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Introduce adaptive gamma to enhance dynamic balance between exploration and exploitation.", "configspace": "", "generation": 47, "fitness": 0.05491977790127659, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.01.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.06437158575447, 0.043278903112566436, 0.05710884483679335]}, "mutation_prompt": null}
{"id": "88a9bad6-12ee-4c31-a55e-4bcaf30c2ade", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.55  # Balance between exploration and exploitation (adjusted)\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Slightly increase the gamma parameter to enhance the balance between exploration and exploitation for potential improvement in convergence.", "configspace": "", "generation": 48, "fitness": 0.03852319154179773, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.03852319154179773, 0.03852319154179773, 0.03852319154179773]}, "mutation_prompt": null}
{"id": "2bab182b-ed11-4437-a07d-dd907485ad64", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.gamma = 0.5 + 0.5 * (evaluations / self.budget)  # Adaptive gamma\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Introduced adaptive gamma based on evaluation ratio to enhance exploration and exploitation balance dynamically.", "configspace": "", "generation": 49, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "a2131e21-b7f7-49b9-a6e3-c8bfddbe31f7", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.7  # Balance between exploration and exploitation (changed from 0.5 to 0.7)\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced learning rate for better convergence in Quantum-inspired Particle Swarm Optimization.", "configspace": "", "generation": 50, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "344ca81b-a848-4063-a5fa-456e0f5cc68b", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update with adaptive gamma\n                    adaptive_gamma = self.gamma * (1 - evaluations / self.budget)\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + adaptive_gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + adaptive_gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Introduced adaptive gamma for a dynamic balance between exploration and exploitation based on budget usage.", "configspace": "", "generation": 51, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "a04d0c87-a336-49cd-b6c7-32dcbed798a9", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Initial balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                self.gamma = 0.5 + 0.5 * (evaluations / self.budget)  # Dynamically adjust gamma\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Improve the balance between exploration and exploitation by adjusting the gamma parameter dynamically.", "configspace": "", "generation": 52, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "6a69a5ba-19f8-45fc-82d8-3592a8b1ae34", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update with stochastic disturbance\n                    stochastic_disturbance = np.random.normal(0, 0.1, self.dim)\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i])\n                                  + stochastic_disturbance)\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhance exploration by introducing a stochastic disturbance term in the velocity update.", "configspace": "", "generation": 53, "fitness": 0.05075505432291535, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.01.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.06570735674361317]}, "mutation_prompt": null}
{"id": "1ce978a5-c7e4-41ab-a083-a35cfa8e5196", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.gamma = 0.5 + (0.5 * evaluations / self.budget)  # Dynamically adjust gamma\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhancing QPSO by dynamically adjusting the gamma parameter for improved balance between exploration and exploitation.", "configspace": "", "generation": 54, "fitness": 0.06147980155084287, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.06147980155084287, 0.06147980155084287, 0.06147980155084287]}, "mutation_prompt": null}
{"id": "5fb6a00d-b308-4361-8258-98a941352b12", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.gamma = 0.5 * (1 + evaluations / self.budget)  # Adaptive gamma\n\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Introduced an adaptive gamma parameter to dynamically balance exploration and exploitation based on current evaluations.", "configspace": "", "generation": 55, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "9376da28-a070-40d5-940d-5ada89c17313", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = max(0.5, 1.0 - (np.log(dim) / 10))  # Dynamically adjust the balance\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Improved the balance between exploration and exploitation by adjusting the gamma parameter dynamically.", "configspace": "", "generation": 56, "fitness": 0.044377003105797654, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.046573203092260096, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "fd4e362e-9334-4a2b-a74f-22142a8d847b", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.7  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Adjust the balance factor for enhanced global convergence in high-dimensional spaces.", "configspace": "", "generation": 57, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "33b9733f-f46e-4417-92a7-094818a3584d", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.gamma = 0.5 * (1 - evaluations / self.budget)  # Dynamic gamma adjustment\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Introduced a dynamic gamma adjustment based on the current evaluation ratio, enhancing the exploration-exploitation balance.", "configspace": "", "generation": 58, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "8aa4b0fa-2e8d-4ac6-b347-029345004a76", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.gamma = 0.5 + 0.5 * (1 - evaluations / self.budget)  # Adaptive gamma\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced QPSO with adaptive gamma for improved balance between exploration and exploitation.", "configspace": "", "generation": 59, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "f7acd6fb-20e8-44d4-a5fc-542626f42fea", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.gamma = 0.4 + 0.1 * np.sin(evaluations / self.budget * np.pi)  # Dynamic gamma\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Introduce a dynamic gamma for improved balance between exploration and exploitation.", "configspace": "", "generation": 60, "fitness": 0.058323181054545814, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.07393272940008455, 0.043278903112566436, 0.057757910650986455]}, "mutation_prompt": null}
{"id": "69c1bdd7-c430-4265-a351-ff54c982d56d", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update with adaptive gamma\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)) * (self.personal_best_positions[i] - self.positions[i]) \n                                  + (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)) * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Refined Quantum-inspired PSO algorithm with an adaptive gamma for improved balance between exploration and exploitation.", "configspace": "", "generation": 61, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "f7291cb3-a405-4092-8861-1f3704dd2bc3", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.gamma = 0.5 + 0.5 * evaluations / self.budget  # Dynamic gamma update\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Introduced dynamic gamma update based on evaluations to enhance convergence.", "configspace": "", "generation": 62, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "02c77771-da16-4853-b491-fe8cf6052059", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                self.gamma = 0.5 * (1 - evaluations / self.budget)  # Adaptive gamma\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhance the QuantumInspiredPSO by introducing adaptive gamma to dynamically balance exploration and exploitation.", "configspace": "", "generation": 63, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "35b497fc-5eb7-4d79-907a-bae46767cbb6", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + ((1 - evaluations/self.budget) * self.gamma) * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "A refined Quantum-inspired Particle Swarm Optimization (QPSO) with an adaptive balance parameter for better convergence control.", "configspace": "", "generation": 64, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "2ca484a9-7b7e-4e1c-8709-67564dd7b643", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                self.gamma = 0.5 + 0.5 * (1 - evaluations / self.budget)  # Adaptive gamma\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced QPSO with adaptive gamma for improved balance between exploration and exploitation.", "configspace": "", "generation": 65, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "67fea6dd-23ff-4049-94e6-780fd90e338a", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = (self.phi * (1 - evaluations / self.budget)) * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "A refined QPSO with an adaptive constriction factor for improved convergence.", "configspace": "", "generation": 66, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "d00a7918-c15d-4c1a-84be-b7526094e711", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n        adaptive_gamma = self.gamma\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                adaptive_gamma = self.gamma + (global_best_score / evaluations)  # Adaptive gamma\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + adaptive_gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + adaptive_gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced the particle velocity update rule by introducing an adaptive gamma to improve convergence speed and accuracy.", "configspace": "", "generation": 67, "fitness": 0.043679192924312514, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.044479772547804663, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "d0b5bb17-9d1b-4672-b40c-b5a011130aec", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    adaptive_weight = 0.5 * (1 - evaluations / self.budget)\n                    self.velocities[i] = self.phi * (adaptive_weight * self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Improved local exploration by adjusting velocities with an adaptive weight based on iteration progress.", "configspace": "", "generation": 68, "fitness": 0.044737835219100575, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.04765569943216885, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "da3582ab-bb8a-4c93-8fef-24461c687632", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + (self.gamma + 0.1 * (evaluations / self.budget)) * (self.personal_best_positions[i] - self.positions[i]) \n                                  + (self.gamma + 0.1 * (evaluations / self.budget)) * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Introduced a dynamic gamma factor based on evaluations to improve the balance between exploration and exploitation in Quantum-inspired PSO.", "configspace": "", "generation": 69, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "ca4f3b33-62a0-4ce6-9956-e2c4f3ad7100", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.phi = 0.5 + 0.5 * (evaluations / self.budget)  # Dynamic constriction factor\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Improved exploration by dynamically adjusting the constriction factor based on the iteration count.", "configspace": "", "generation": 70, "fitness": 0.04678733433360793, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.04765182882455521, 0.04508895394486101, 0.04762122023140758]}, "mutation_prompt": null}
{"id": "61cf09e0-a478-4005-84b6-c87a4286e5e3", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                self.gamma = 0.5 + (0.5 * evaluations) / self.budget  # Adaptive gamma\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Introducing adaptive gamma for balancing exploration and exploitation in Quantum-inspired PSO.", "configspace": "", "generation": 71, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "d43f1aee-1872-4afd-bf42-3597ba3cb359", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.6  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Slightly adjusted the gamma value to improve the balance between exploration and exploitation.", "configspace": "", "generation": 72, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "15095c79-46fd-4b69-a73d-2a7758828cad", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Adaptive gamma based on evaluations\n                    self.gamma = 0.4 + 0.1 * (evaluations / self.budget)\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Introducing an adaptive gamma parameter to enhance the balance between exploration and exploitation dynamically.", "configspace": "", "generation": 73, "fitness": 0.058208160199367844, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.07393337228946106, 0.043278903112566436, 0.05741220519607604]}, "mutation_prompt": null}
{"id": "02ed7d30-f31c-4762-aa3b-1c9fd513817c", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.gamma = 0.5 + 0.5 * (1 - evaluations / self.budget)  # Adaptive gamma\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Introduce adaptive gamma for dynamic exploration-exploitation trade-off.", "configspace": "", "generation": 74, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "cea86bdd-8394-429b-bd49-c79e271a46aa", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + (self.gamma + evaluations / self.budget) * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced convergence by adjusting the exploration-exploitation balance over iterations.", "configspace": "", "generation": 75, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "fed482f9-2324-4405-9e0e-a3d55e2d9e83", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.w = 0.9  # Initial inertia weight\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                self.w *= 0.99  # Decay inertia weight\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.w * self.velocities[i] + self.phi * (\n                        self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                        + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Introduce inertia weight decay for enhanced convergence in Quantum-Inspired PSO.", "configspace": "", "generation": 76, "fitness": 0.046753335999838476, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.04762728422312257, 0.04506778327678118, 0.047564940499611685]}, "mutation_prompt": null}
{"id": "6f493496-6f19-4ff6-a833-d2c61d3feac5", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                self.gamma = 0.5 * (1 + evaluations / self.budget)  # Dynamically update gamma\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "A refined Quantum-inspired PSO enhancing exploitation by dynamically adjusting the gamma parameter based on iterations.", "configspace": "", "generation": 77, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "eed20634-83b2-414b-ae86-a7959ff22d59", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                self.gamma = 0.3 + 0.7 * (1 - evaluations / self.budget)  # Dynamically adjust gamma\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced exploration by dynamically adjusting the gamma parameter based on evaluations.", "configspace": "", "generation": 78, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "814b1d1f-4326-4848-a2d4-9eb1e94b0a82", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.gamma = 0.5 * (1 + np.sin(2 * np.pi * evaluations / self.budget))  # Adaptive gamma\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "An enhanced QPSO algorithm with an adaptive gamma for improved balance between exploration and exploitation.", "configspace": "", "generation": 79, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "6ec89f20-fc7f-4789-b7e2-c7c0ee771019", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.3  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced Quantum PSO by reducing gamma for finer exploitation.", "configspace": "", "generation": 80, "fitness": 0.0647771153115058, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.06551364517710223, 0.07388926134648033, 0.05492843941093484]}, "mutation_prompt": null}
{"id": "9418def9-ffa0-49cf-9c05-136aaafce3c7", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = (0.729 * self.velocities[i]  # Modified inertia weight\n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "A refined Quantum-inspired PSO with enhanced inertia weight for better balance between exploration and exploitation.", "configspace": "", "generation": 81, "fitness": 0.04695299670718215, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.04772599021459878, 0.04561613597206138, 0.0475168639348863]}, "mutation_prompt": null}
{"id": "83648e8e-aa52-4ba6-b8ae-3e1f73bc1d7d", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update with adaptive velocity scaling\n                    velocity_scaling = (self.budget - evaluations) / self.budget\n                    self.velocities[i] = velocity_scaling * (self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i])))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Introduce adaptive velocity scaling based on remaining budget to balance exploration and exploitation dynamically.", "configspace": "", "generation": 82, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "1c4606a8-8e7d-4803-b287-09a4898a24c2", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + (0.9 - 0.7 * evaluations / self.budget) * (self.personal_best_positions[i] - self.positions[i]) \n                                  + (0.9 - 0.7 * evaluations / self.budget) * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced Quantum-inspired PSO with dynamic gamma for improved exploration-exploitation balance.", "configspace": "", "generation": 83, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "964f8f1b-f9a6-4546-9c0c-99ce34e0be7b", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Initial balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                self.gamma = 0.3 + 0.2 * (1 - evaluations / self.budget)  # Adaptive gamma\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "An improved Quantum-inspired Particle Swarm Optimization algorithm with adaptive gamma for better balance between exploration and exploitation.", "configspace": "", "generation": 84, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "58f658cc-3d45-431a-9a13-df5f4fcae2b6", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                self.gamma = 0.5 * (1 + evaluations / self.budget)  # Dynamic gamma adjustment\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Improved convergence by dynamically adjusting the gamma parameter for balancing exploration and exploitation.", "configspace": "", "generation": 85, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "4c4adc34-51ad-4eab-b978-a6328075069f", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.gamma = 0.5 + 0.5 * (global_best_score - score) / (global_best_score + 1e-9)  # Adaptive gamma\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhancement by adding adaptive gamma for improved balance between exploration and exploitation.", "configspace": "", "generation": 86, "fitness": 0.08050337144425668, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.01.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.07422267475785638, 0.07314383618688136, 0.0941436033880323]}, "mutation_prompt": null}
{"id": "eabfff2f-fa08-4ae7-a304-7ba6bb2b8f34", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n\n                self.gamma = 0.5 + 0.5 * (global_best_score / self.personal_best_scores.min())  # Adjust gamma\n\n                self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced Quantum-inspired PSO by dynamically adjusting the gamma parameter based on convergence rate.", "configspace": "", "generation": 87, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "b1c51630-972e-41cf-b64c-b5908a18bfae", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Initial balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                self.gamma = 0.5 * (1.0 - evaluations / self.budget)  # Dynamic gamma adjustment\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "The enhanced Quantum-inspired PSO algorithm now includes a dynamic gamma parameter to better balance exploration and exploitation over iterations.", "configspace": "", "generation": 88, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "3df26817-6ef4-47d6-915e-fafd96cf15a3", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.gamma = 0.5 + 0.5 * (global_best_score / (self.personal_best_scores[i] + 1e-10))  # Adaptive gamma\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced QPSO with adaptive gamma for improved balance between exploration and exploitation.", "configspace": "", "generation": 89, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "72fc3083-28c6-4303-9528-954a2176151a", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + 0.9 * self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced Quantum-inspired Particle Swarm Optimization with adaptive gamma for better exploration-exploitation balance.", "configspace": "", "generation": 90, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "f13cf8c1-d6c5-4666-b417-4c931b6444dc", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + np.random.uniform(0.4, 0.6) * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Introduce stochastic variance reduction to enhance exploitation by adjusting gamma dynamically.", "configspace": "", "generation": 91, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "182c0d28-80d9-4fa0-bae1-536a1ad675c3", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.6  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Slightly adjust the exploration-exploitation balance by modifying the gamma parameter within the velocity update formula.", "configspace": "", "generation": 92, "fitness": 0.03852319154179773, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.03852319154179773, 0.03852319154179773, 0.03852319154179773]}, "mutation_prompt": null}
{"id": "3c34b819-3b7c-449d-970e-5a03547dec6f", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + (self.gamma * (1 - evaluations/self.budget)) * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Improved the balance between exploration and exploitation by adjusting the gamma parameter dynamically based on performance.", "configspace": "", "generation": 93, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "9066fa0c-a3f1-4565-ac9b-98c812b4aed7", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n                    \n            # Adaptive gamma for improved convergence control\n            self.gamma = 0.5 + 0.4 * (1 - evaluations/self.budget)\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "An enhanced Quantum-inspired PSO incorporating adaptive gamma for improved convergence control in diverse search landscapes.", "configspace": "", "generation": 94, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "e4b610cf-97b8-4f1a-bc99-19fee0658045", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                self.gamma = 0.5 + 0.5 * (1 - evaluations / self.budget)  # Adaptive gamma adjustment\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced Quantum-inspired PSO with adaptive gamma for improved balance between exploration and exploitation.", "configspace": "", "generation": 95, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "62f75e4a-1d37-46ce-9acb-54dea1ba8946", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.6  # Adjusted balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Fine-tune the balance between exploration and exploitation by adjusting the gamma parameter to improve convergence.", "configspace": "", "generation": 96, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "dc88bf41-00d1-44fe-b930-ddfd63db285d", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update with random factor\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i])\n                                  + np.random.uniform(-0.1, 0.1, self.dim))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced exploration by introducing a random factor in velocity update to diversify search paths.", "configspace": "", "generation": 97, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}
{"id": "9254610c-3c39-44c7-af72-dd33eceff596", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update with adaptive gamma\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + (self.gamma * (1 - evaluations/self.budget) * (self.personal_best_positions[i] - self.positions[i]))\n                                  + (self.gamma * (1 - evaluations/self.budget) * (global_best_position - self.positions[i])))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Refined Quantum-inspired PSO with adaptive gamma for improved balance between exploration and exploitation.", "configspace": "", "generation": 98, "fitness": 0.04203886746721641, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.04203886746721641, 0.04203886746721641, 0.04203886746721641]}, "mutation_prompt": null}
{"id": "be31c1ca-3dca-4109-96f5-08af6b564589", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(30, self.budget // (2 * dim))  # Dynamic population size\n        self.phi = 0.5 + np.log(self.dim) / np.log(2)  # Constriction factor for convergence\n        self.gamma = 0.5  # Balance between exploration and exploitation\n        self.positions = np.random.rand(self.population_size, self.dim)  # Initialize particle positions\n        self.velocities = np.random.rand(self.population_size, self.dim)  # Initialize particle velocities\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def __call__(self, func):\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Boundary handling\n                self.positions[i] = np.clip(self.positions[i], func.bounds.lb, func.bounds.ub)\n\n                # Evaluate the fitness\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = self.positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            if evaluations < self.budget:\n                for i in range(self.population_size):\n                    # Quantum-inspired position update with dynamic gamma\n                    self.gamma = 0.5 + 0.5 * np.sin(evaluations / self.budget * np.pi)  # Dynamic gamma\n                    self.velocities[i] = self.phi * (self.velocities[i] \n                                  + self.gamma * (self.personal_best_positions[i] - self.positions[i]) \n                                  + self.gamma * (global_best_position - self.positions[i]))\n                    \n                    self.positions[i] += self.velocities[i]\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredPSO", "description": "Enhanced Quantum-inspired PSO with dynamic gamma for improved balance between exploration and exploitation.", "configspace": "", "generation": 99, "fitness": 0.043278903112566436, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.00.", "error": "", "parent_id": "9a14ad54-a0f4-412a-ba3a-716ec87f2d61", "metadata": {"aucs": [0.043278903112566436, 0.043278903112566436, 0.043278903112566436]}, "mutation_prompt": null}

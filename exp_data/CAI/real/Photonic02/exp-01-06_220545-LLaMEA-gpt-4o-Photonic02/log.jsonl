{"id": "6fbdb554-d260-4dfa-acf3-97bdc01a9834", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.8  # DE scaling factor\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "A hybrid Particle Swarm Optimization with Differential Evolution strategy for adaptive exploration and exploitation balance.", "configspace": "", "generation": 0, "fitness": 0.1492503453430514, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.01.", "error": "", "parent_id": null, "metadata": {"aucs": [0.1577533040558895, 0.1386909663937005, 0.15130676557956424]}, "mutation_prompt": null}
{"id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "An enhanced HybridPSO_DE algorithm with slightly increased DE scaling factor for improved exploration.", "configspace": "", "generation": 1, "fitness": 0.1912046479909284, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.01.", "error": "", "parent_id": "6fbdb554-d260-4dfa-acf3-97bdc01a9834", "metadata": {"aucs": [0.17807610203425417, 0.1947706918638482, 0.20076715007468282]}, "mutation_prompt": null}
{"id": "f5e46423-f700-4f05-ae09-8a6ffb401717", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.9  # DE scaling factor (fine-tuned for exploration-exploitation balance)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Fine-tune the DE scaling factor for better exploration-exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.1509930080493723, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.02.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.1393190687408432, 0.18317609431271087, 0.13048386109456278]}, "mutation_prompt": null}
{"id": "df48e24e-e9b0-4222-9139-c8fb20ecea26", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.92  # DE crossover probability (slightly increased for exploration-exploitation balance)\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Slightly increase the DE crossover probability for improved exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.15229554318509378, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.03.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.17707062148333796, 0.16546454840657843, 0.11435145966536497]}, "mutation_prompt": null}
{"id": "ce4694ab-d5c1-4444-b7e6-e0cd972e8a12", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.7, 1.5  # Adjusted cognitive (c1) and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Incrementally adjust PSO's cognitive component to enhance convergence.", "configspace": "", "generation": 4, "fitness": 0.16330407475273967, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.01.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.15081889336811882, 0.16261791415057925, 0.17647541673952094]}, "mutation_prompt": null}
{"id": "becd3b18-d1a6-4425-9a36-05bdf1187ba2", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.95  # DE crossover probability (slightly increased)\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Refined HybridPSO_DE by slightly increasing the DE crossover probability for enhanced exploration.", "configspace": "", "generation": 5, "fitness": 0.13087501253745437, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.03.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.16844304643858288, 0.1111699859746832, 0.11301200519909704]}, "mutation_prompt": null}
{"id": "4aa44e77-77d7-4fba-9a4c-3458b911733a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.85  # DE crossover probability (slightly decreased for better balance)\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Slightly decreased DE crossover probability for enhanced exploration-exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.1676220516707521, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.02.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.1706275566997979, 0.1362132799339013, 0.19602531837855708]}, "mutation_prompt": null}
{"id": "85f7a656-d5e5-439e-865c-9e927195bee7", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    CR = 0.9 - 0.4 * (evaluations / self.budget)  # Adaptive CR\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Introduced adaptive crossover probability CR to improve balance between exploration and exploitation.", "configspace": "", "generation": 7, "fitness": 0.1569784476356265, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.02.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.16074998349952407, 0.18131978152005168, 0.12886557788730368]}, "mutation_prompt": null}
{"id": "15f4dea6-367a-4647-8fbd-691a1c81dd95", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    # Adaptive scaling factor\n                    F_adaptive = F * (1 - (evaluations / self.budget))\n                    mutant_vector = personal_best[a] + F_adaptive * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Introduced adaptive scaling factor in DE to balance exploration and exploitation.", "configspace": "", "generation": 8, "fitness": 0.18799265223660622, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.00.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.18896562055387944, 0.19014843151277838, 0.18486390464316083]}, "mutation_prompt": null}
{"id": "694db33f-3b07-4be7-8bca-af6337b624d5", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.8 + 0.1 * np.random.rand()  # DE scaling factor (dynamically adjusted for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "A refined HybridPSO_DE algorithm with a dynamically adjusted DE scaling factor to further enhance exploration and exploitation balance.", "configspace": "", "generation": 9, "fitness": 0.1688329874899274, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.02.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.16821698136408503, 0.18786388677618915, 0.15041809432950803]}, "mutation_prompt": null}
{"id": "046ceba2-eadb-46fb-91f8-4f720d10107e", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.9  # DE scaling factor (adjusted for better exploration-exploitation balance)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Adjusted the DE scaling factor to 0.9 for slightly better exploration-exploitation balance. ", "configspace": "", "generation": 10, "fitness": 0.1509930080493723, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.02.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.1393190687408432, 0.18317609431271087, 0.13048386109456278]}, "mutation_prompt": null}
{"id": "d6aacdc3-33c7-407a-a139-f4b89c30e0e5", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.95  # DE crossover probability (slightly increased)\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Slightly increase the DE crossover probability to enhance the algorithm's ability to explore diverse solutions.", "configspace": "", "generation": 11, "fitness": 0.13087501253745437, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.03.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.16844304643858288, 0.1111699859746832, 0.11301200519909704]}, "mutation_prompt": null}
{"id": "e59aebb7-57a0-4989-bb1c-bdb8a7c1db3e", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    CR = 0.8 + 0.1 * np.random.rand()  # Adaptive CR modification\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Introduced adaptive crossover probability (CR) modulation for enhanced exploration-exploitation balance while retaining the rest of the algorithm.", "configspace": "", "generation": 12, "fitness": 0.17005138817009524, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.02.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.19020774641248184, 0.17292386761059042, 0.14702255048721347]}, "mutation_prompt": null}
{"id": "90ef65fd-161f-41d1-9a48-5dab33265b3c", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w_initial, w_final = 0.9, 0.4  # Adaptive inertia weight\n        c1_initial, c2_initial = 1.5, 1.5  # Adaptive cognitive and social constants\n        F = 0.85  # DE scaling factor\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                w = w_final + (w_initial - w_final) * (1 - evaluations / self.budget)\n                c1 = c1_initial + (2.0 - c1_initial) * (evaluations / self.budget)\n                c2 = c2_initial + (2.0 - c2_initial) * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    if np.linalg.norm(personal_best[a] - personal_best[i]) < np.linalg.norm(personal_best[b] - personal_best[c]):\n                        mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    else:\n                        mutant_vector = personal_best[c] + F * (personal_best[b] - personal_best[a])\n                        \n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduce adaptive PSO parameters and a proximity-based DE strategy for better exploration-exploitation balance.", "configspace": "", "generation": 13, "fitness": 0.17777710249246229, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.01.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.18562225332437632, 0.1578006218831859, 0.18990843226982468]}, "mutation_prompt": null}
{"id": "02d7cfe9-7592-4479-8841-e0186862ff84", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial value)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight and DE scaling factor\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n            F = max(0.5, 0.85 - 0.4 * (evaluations / self.budget))  # Adaptive DE scaling factor\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Introduced adaptive DE scaling factor (F) to balance exploration and exploitation dynamically.", "configspace": "", "generation": 14, "fitness": 0.1810617453296448, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.01.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.1806992761466537, 0.19090763542586664, 0.17157832441641407]}, "mutation_prompt": null}
{"id": "0d346e1b-fd65-4fc0-9275-71ee6e6bc9ee", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.7, 1.5  # Cognitive and social constants (c1 increased for enhanced local search)\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Increased cognitive constant to enhance local search capability.", "configspace": "", "generation": 15, "fitness": 0.16330407475273967, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.01.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.15081889336811882, 0.16261791415057925, 0.17647541673952094]}, "mutation_prompt": null}
{"id": "49e6950d-245f-4f82-9b3c-9417674b50ac", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    F = 0.6 + 0.3 * (evaluations / self.budget)  # Adaptive DE scaling factor\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Introduced adaptive DE scaling factor based on evaluations to improve exploration and exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.13832958626638933, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.03.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.17641828886148736, 0.11068727951052038, 0.12788319042716023]}, "mutation_prompt": null}
{"id": "e67dbef8-1a7b-4c5b-9178-b8ab61ee1662", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight and DE crossover probability\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n            CR = 0.8 + 0.1 * (global_best_value / np.max(personal_best_value))\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Introduced adaptive DE crossover probability to balance exploration and exploitation dynamically.", "configspace": "", "generation": 17, "fitness": 0.14658551854288085, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.01.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.16410500123603533, 0.14734348092737526, 0.128308073465232]}, "mutation_prompt": null}
{"id": "b3d16519-062e-4a5c-a7e2-94a376d6838a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.95  # DE crossover probability (slightly increased)\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Slightly increased the DE crossover probability to allow greater exploration of the search space.", "configspace": "", "generation": 18, "fitness": 0.13087501253745437, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.03.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.16844304643858288, 0.1111699859746832, 0.11301200519909704]}, "mutation_prompt": null}
{"id": "fdd86b44-080a-488e-b7d0-770019b7b30b", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight and DE scaling factor\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n            F = 0.85 + 0.1 * (global_best_value / (np.finfo(float).eps + np.mean(personal_best_value)))  # Change made here\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced PSO with adaptive DE scaling factor using environmental feedback for improved exploration-exploitation balance.", "configspace": "", "generation": 19, "fitness": 0.18000269327292742, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.01.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.16499014737613893, 0.19763976997791588, 0.17737816246472748]}, "mutation_prompt": null}
{"id": "24d344b6-de64-4a72-8397-487a0dfff9e2", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.6  # Inertia weight (adjusted for improved convergence)\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Slightly adjust PSO velocity update inertia weight for improved convergence.", "configspace": "", "generation": 20, "fitness": 0.16791993609801478, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.01.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.16987600193060826, 0.15308345056065187, 0.1808003558027842]}, "mutation_prompt": null}
{"id": "fea11be7-b0db-4e1e-a5fc-d30b9e5f44bb", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.85  # DE crossover probability, fine-tuned for balance\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Improved HybridPSO_DE by fine-tuning DE crossover probability for better exploitation-exploration balance.", "configspace": "", "generation": 21, "fitness": 0.1676220516707521, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.02.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.1706275566997979, 0.1362132799339013, 0.19602531837855708]}, "mutation_prompt": null}
{"id": "e4625963-3a08-4db2-93a8-a6e14f78287e", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    F = 0.5 + 0.35 * (1 - evaluations / self.budget)  # Adaptive F based on progress\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Introduced adaptive DE scaling factor `F` for improved exploration and exploitation balance. ", "configspace": "", "generation": 22, "fitness": 0.17317070096742768, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.02.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.15819026268857883, 0.20725441963699542, 0.15406742057670875]}, "mutation_prompt": null}
{"id": "64523ef5-9864-4c87-83d8-f7dce1e01a26", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = np.random.rand()  # Chaotic initialization of inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Introducing chaotic inertia weight initialization for improved exploration in early PSO iterations.", "configspace": "", "generation": 23, "fitness": 0.16723122761751072, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.01.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.15592137446771814, 0.18219472021405803, 0.16357758817075596]}, "mutation_prompt": null}
{"id": "992459be-e196-4e97-8c4a-1b409bf65275", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    F_adaptive = 0.5 + 0.4 * (1 - evaluations / self.budget)  # Adaptive F\n                    mutant_vector = personal_best[a] + F_adaptive * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "A slightly modified HybridPSO_DE algorithm with adaptive DE scaling factor for improved exploration and exploitation balance.", "configspace": "", "generation": 24, "fitness": 0.17347199186266105, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.03.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.19014976316644516, 0.20171545874064944, 0.12855075368088853]}, "mutation_prompt": null}
{"id": "89a7155f-1e5c-490c-bfeb-88293bbfe865", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.95  # DE crossover probability (slightly increased for better exploration)\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Improved exploration by slightly increasing DE crossover probability.", "configspace": "", "generation": 25, "fitness": 0.13087501253745437, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.03.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.16844304643858288, 0.1111699859746832, 0.11301200519909704]}, "mutation_prompt": null}
{"id": "358a6cb6-1560-494a-bc06-3c0c6d0aa4e7", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            num_particles = max(5, int(30 * (1 - evaluations / self.budget)))  # Dynamic population size\n\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE algorithm with dynamic population size for better exploitation in later stages.", "configspace": "", "generation": 26, "fitness": 0.15021866834723863, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.02.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.1716784835581664, 0.14946720683322312, 0.12951031465032636]}, "mutation_prompt": null}
{"id": "367c2aef-86d0-45c4-9945-eb3bcecd5173", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    F_dynamic = F * (1 - evaluations / self.budget) + 0.5 * (evaluations / self.budget)  # Dynamic F\n                    mutant_vector = personal_best[a] + F_dynamic * (personal_best[b] - personal_best[c])\n                    CR_dynamic = CR * (1 - evaluations / self.budget) + 0.1 * (evaluations / self.budget)  # Dynamic CR\n                    trial_vector = np.where(np.random.rand(self.dim) < CR_dynamic, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced exploration by dynamic adjustment of DE scaling factor and crossover probability for improved convergence.", "configspace": "", "generation": 27, "fitness": 0.15810370928725004, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.03.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.18080224827994051, 0.17802802772435533, 0.11548085185745427]}, "mutation_prompt": null}
{"id": "cc438807-8d80-4ca7-9ce9-466e4a75b7db", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.85  # DE crossover probability (slightly decreased for improved exploitation)\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Slight decrease in DE crossover probability to improve exploitation.", "configspace": "", "generation": 28, "fitness": 0.1676220516707521, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.02.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.1706275566997979, 0.1362132799339013, 0.19602531837855708]}, "mutation_prompt": null}
{"id": "b2d67903-1fac-416b-8da3-3fa0894de91f", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.85  # DE crossover probability (slightly decreased for enhanced exploitation)\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Slightly adjusted the DE crossover probability to enhance local exploitation.", "configspace": "", "generation": 29, "fitness": 0.1676220516707521, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.02.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.1706275566997979, 0.1362132799339013, 0.19602531837855708]}, "mutation_prompt": null}
{"id": "deaf120e-df62-49c1-a3f9-f8563b46892b", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n            CR = 0.9 - 0.4 * (evaluations / self.budget)  # Adaptive DE crossover probability\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE with adaptive DE crossover probability for improved convergence.", "configspace": "", "generation": 30, "fitness": 0.16647248963761122, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.01.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.17020538676144203, 0.15422589050220947, 0.17498619164918217]}, "mutation_prompt": null}
{"id": "15682463-ac13-4a9e-a572-bb38a8809089", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.85  # Slightly reduced DE crossover probability for better balance\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Fine-tune the DE crossover probability to enhance the balance between exploration and exploitation.", "configspace": "", "generation": 31, "fitness": 0.1676220516707521, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.02.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.1706275566997979, 0.1362132799339013, 0.19602531837855708]}, "mutation_prompt": null}
{"id": "45558168-1c1f-4118-bd8d-a59488f6d37d", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.95  # DE crossover probability (increased to improve exploration)\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Adjusted DE crossover probability to increase exploration capability.", "configspace": "", "generation": 32, "fitness": 0.13087501253745437, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.03.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.16844304643858288, 0.1111699859746832, 0.11301200519909704]}, "mutation_prompt": null}
{"id": "45cf789b-08f7-4cd7-97a0-11c720ebf24c", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor\n        CR = 0.92  # DE crossover probability (increased for enhanced exploration)\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "A refined version of HybridPSO_DE with increased DE crossover probability for enhanced exploration.", "configspace": "", "generation": 33, "fitness": 0.15229554318509378, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.03.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.17707062148333796, 0.16546454840657843, 0.11435145966536497]}, "mutation_prompt": null}
{"id": "38433da2-63ff-497e-94c2-bd334f3b0c97", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.90  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Slightly increased the DE scaling factor from 0.85 to 0.90 for further improved exploration.", "configspace": "", "generation": 34, "fitness": 0.1509930080493723, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.02.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.1393190687408432, 0.18317609431271087, 0.13048386109456278]}, "mutation_prompt": null}
{"id": "707a98fe-089d-4c50-81bb-3ba273c9c803", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    F_dynamic = F * (1 - evaluations / self.budget)  # Dynamic adjustment of F\n                    mutant_vector = personal_best[a] + F_dynamic * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Improved exploration by dynamically adjusting the DE scaling factor `F` based on remaining budget.", "configspace": "", "generation": 35, "fitness": 0.18799265223660622, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.00.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.18896562055387944, 0.19014843151277838, 0.18486390464316083]}, "mutation_prompt": null}
{"id": "ef4b60e6-76f2-4429-a215-4814bb0d4802", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.95  # DE crossover probability (adjusted for better exploration-exploitation balance)\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Adjusted DE crossover probability for enhanced exploration-exploitation balance.", "configspace": "", "generation": 36, "fitness": 0.13087501253745437, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.03.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.16844304643858288, 0.1111699859746832, 0.11301200519909704]}, "mutation_prompt": null}
{"id": "2d053de9-55b8-4942-a294-a318702876cb", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR * (1 - evaluations / self.budget), mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Introduced dynamic DE crossover probability to balance exploration and exploitation.", "configspace": "", "generation": 37, "fitness": 0.15621857149124407, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.01.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.1561663617764567, 0.1480392331856929, 0.16445011951158262]}, "mutation_prompt": null}
{"id": "0225f2d4-7514-4924-97da-39aa1af5c32f", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor\n        CR = 0.95  # DE crossover probability (increased to enhance diversity)\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Increased DE crossover probability to enhance the diversity of solutions.", "configspace": "", "generation": 38, "fitness": 0.13087501253745437, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.03.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.16844304643858288, 0.1111699859746832, 0.11301200519909704]}, "mutation_prompt": null}
{"id": "29670a84-4625-4951-abe8-ba05e1fd197c", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.92  # DE crossover probability (slightly increased for better balance)\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Slightly increase the DE crossover probability for better exploration-exploitation balance.", "configspace": "", "generation": 39, "fitness": 0.15229554318509378, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.03.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.17707062148333796, 0.16546454840657843, 0.11435145966536497]}, "mutation_prompt": null}
{"id": "7a99cbba-5acd-4517-bf61-3736cacaa6a3", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    F_adaptive = 0.5 + 0.35 * (1 - evaluations / self.budget)  # Adaptive F\n                    mutant_vector = personal_best[a] + F_adaptive * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "The enhanced HybridPSO_DE algorithm now includes an adaptive DE scaling factor to dynamically adjust exploration and exploitation.", "configspace": "", "generation": 40, "fitness": 0.17317070096742768, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.02.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.15819026268857883, 0.20725441963699542, 0.15406742057670875]}, "mutation_prompt": null}
{"id": "7402e436-4e8b-4403-9a2b-9d30e63cada3", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.92  # DE crossover probability (slightly increased for better exploration-exploitation balance)\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Slightly increased DE crossover probability for improved exploration-exploitation balance.", "configspace": "", "generation": 41, "fitness": 0.15229554318509378, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.03.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.17707062148333796, 0.16546454840657843, 0.11435145966536497]}, "mutation_prompt": null}
{"id": "66d2261b-bd6e-4078-af74-d1afa9798d56", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F_min, F_max = 0.5, 0.9  # Adaptive DE scaling factor range\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    F = F_min + (F_max - F_min) * (1 - evaluations / self.budget)  # Adaptive F\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Optimized HybridPSO_DE with adaptive DE scaling factor for dynamic exploration-exploitation balance.", "configspace": "", "generation": 42, "fitness": 0.17347199186266105, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.03.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.19014976316644516, 0.20171545874064944, 0.12855075368088853]}, "mutation_prompt": null}
{"id": "68f74c10-e2fc-49e4-b5f3-616d3d167c65", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.6  # Inertia weight (slightly increased for better exploration)\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Enhance exploration capability by slightly increasing inertia weight.", "configspace": "", "generation": 43, "fitness": 0.16791993609801478, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.01.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.16987600193060826, 0.15308345056065187, 0.1808003558027842]}, "mutation_prompt": null}
{"id": "bb1dbed8-4e84-4c4b-8210-d8fcf784a2e3", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight slightly differently\n            w = 0.9 - 0.6 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Fine-tune the inertia weight reduction strategy to enhance exploration and exploitation balance.", "configspace": "", "generation": 44, "fitness": 0.1727140847201891, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.00.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.17273342961344196, 0.17437063696119592, 0.17103818758592937]}, "mutation_prompt": null}
{"id": "1c968dc4-1d3d-47e4-b109-d7b346b8eb1a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n            F = 0.5 + 0.5 * (evaluations / self.budget)  # Dynamic adjustment of F\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE with adaptive DE scaling factor for dynamic exploration and exploitation.", "configspace": "", "generation": 45, "fitness": 0.16538874030344466, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.03.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.20335492756093376, 0.15191405163942784, 0.14089724170997242]}, "mutation_prompt": null}
{"id": "a225d594-63d5-48ab-85ee-e63ad3a0fbba", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.75  # DE scaling factor (slightly decreased for enhanced exploitation)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Slightly decreased DE scaling factor for better exploitation.", "configspace": "", "generation": 46, "fitness": 0.16821441141650484, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.01.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.16560999408813126, 0.16006423763999966, 0.1789690025213836]}, "mutation_prompt": null}
{"id": "1efc5e2f-80f3-4622-8336-684c533b749a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.92  # DE crossover probability (slightly increased)\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Slightly increased DE crossover probability to enhance the balance between exploration and exploitation.", "configspace": "", "generation": 47, "fitness": 0.15229554318509378, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.03.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.17707062148333796, 0.16546454840657843, 0.11435145966536497]}, "mutation_prompt": null}
{"id": "dd012639-ecf4-4277-8c4d-70a5e1799e26", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial value for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    F_dynamic = F * (1 - evaluations / self.budget)  # Dynamic DE scaling factor\n                    mutant_vector = personal_best[a] + F_dynamic * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Introduce a dynamic DE scaling factor that decreases linearly with evaluations to balance exploration and exploitation.", "configspace": "", "generation": 48, "fitness": 0.18799265223660622, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.00.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.18896562055387944, 0.19014843151277838, 0.18486390464316083]}, "mutation_prompt": null}
{"id": "7d82ba3c-0157-4b04-b085-8303b0eab2fa", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.95  # DE crossover probability (slightly increased for enhanced exploration)\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Slightly increase DE crossover probability to enhance exploration and convergence.", "configspace": "", "generation": 49, "fitness": 0.13087501253745437, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.03.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.16844304643858288, 0.1111699859746832, 0.11301200519909704]}, "mutation_prompt": null}
{"id": "6d88186b-0401-46f2-b351-81c37598c31c", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.7, 1.5  # Cognitive and social constants (c1 adjusted)\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Adjusted cognitive factor c1 to enhance individual learning and improve convergence.", "configspace": "", "generation": 50, "fitness": 0.16330407475273967, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.01.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.15081889336811882, 0.16261791415057925, 0.17647541673952094]}, "mutation_prompt": null}
{"id": "7bad5517-6a34-43f9-8de7-b4a1d01db473", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.8 + 0.1 * np.random.rand()  # DE scaling factor (adaptive for enhanced balance)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE with adaptive DE scaling factor for better exploration and exploitation balance.", "configspace": "", "generation": 51, "fitness": 0.1688329874899274, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.02.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.16821698136408503, 0.18786388677618915, 0.15041809432950803]}, "mutation_prompt": null}
{"id": "939fb319-b9f2-4410-9189-ec87caa369e8", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n            CR = 0.5 + 0.4 * (np.random.rand())  # Adaptive crossover probability\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Introduce adaptive crossover probability to improve the exploration-exploitation balance.", "configspace": "", "generation": 52, "fitness": 0.15458160579600155, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.03.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.16893206473202027, 0.18028836673061344, 0.11452438592537095]}, "mutation_prompt": null}
{"id": "e980d5a0-eaf5-47aa-99c1-c92c07663e21", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n            F = 0.5 + 0.4 * np.sin((evaluations / self.budget) * np.pi)  # Adaptive F adjustment\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Integrated adaptive DE scaling factor adjustment to enhance dynamic exploration capabilities.", "configspace": "", "generation": 53, "fitness": 0.14377846644550504, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.02.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.12201740476499878, 0.14201277195483242, 0.1673052226166839]}, "mutation_prompt": null}
{"id": "00706902-8958-4ca1-b96f-61eecffd1513", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    F = 0.85 - 0.3 * (evaluations / self.budget)  # Change to dynamic F\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Improved local convergence by adjusting the DE scaling factor dynamically based on evaluations.", "configspace": "", "generation": 54, "fitness": 0.17292544760206294, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.01.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.16233116429047745, 0.1926643088802933, 0.16378086963541805]}, "mutation_prompt": null}
{"id": "d49fbb79-49f3-44aa-a4ff-e090134ccb13", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 2.0, 2.0  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Increase cognitive and social constants for improved exploitation.", "configspace": "", "generation": 55, "fitness": 0.13581668462520657, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.01.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.14642410491151225, 0.14396809620466489, 0.11705785275944258]}, "mutation_prompt": null}
{"id": "0ef239dc-1690-4a0d-b853-307cc8945132", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    F_adaptive = 0.5 + (0.85 - 0.5) * (1 - evaluations / self.budget)  # Adaptive scaling factor\n                    mutant_vector = personal_best[a] + F_adaptive * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "HybridPSO_DE with adaptive DE scaling factor for dynamic exploration-exploitation balance.", "configspace": "", "generation": 56, "fitness": 0.17317070096742768, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.02.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.15819026268857883, 0.20725441963699542, 0.15406742057670875]}, "mutation_prompt": null}
{"id": "6ddf6810-8208-4792-9dff-099a89b20970", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    adaptive_CR = CR * (global_best_value / personal_best_value[i])\n                    trial_vector = np.where(np.random.rand(self.dim) < adaptive_CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Introduce adaptive crossover probability (CR) in the DE strategy for enhanced performance.", "configspace": "", "generation": 57, "fitness": 0.13453508739457398, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.02.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.16547103313933953, 0.10977231274243382, 0.1283619163019486]}, "mutation_prompt": null}
{"id": "f7985fe9-1989-4a49-bd80-6c42770caefd", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.4 * (evaluations / self.budget) ** 2  # Non-linear adjustment\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Incorporate adaptive inertia weight adjustment based on a non-linear function to balance exploration and exploitation.", "configspace": "", "generation": 58, "fitness": 0.1630208915749133, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.01.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.1491679386467768, 0.18042747682512195, 0.15946725925284122]}, "mutation_prompt": null}
{"id": "9dbf2663-a97c-4be8-9980-40dc4e2ab2d2", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.92  # DE crossover probability (slightly increased for enhanced exploration)\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Slightly increased the DE crossover probability to enhance exploration capabilities and convergence speed.", "configspace": "", "generation": 59, "fitness": 0.15229554318509378, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.03.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.17707062148333796, 0.16546454840657843, 0.11435145966536497]}, "mutation_prompt": null}
{"id": "4d7e8b8d-20c8-40ba-8683-28b0519fe10f", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.92  # DE crossover probability (enhanced for better exploration)\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "A refined HybridPSO_DE with enhanced DE crossover probability for better exploration.", "configspace": "", "generation": 60, "fitness": 0.15229554318509378, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.03.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.17707062148333796, 0.16546454840657843, 0.11435145966536497]}, "mutation_prompt": null}
{"id": "850a36a2-4dfc-4166-b62b-61521a88ef8b", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    F = 0.6 + 0.5 * (1 - evaluations / self.budget)  # Updated line: Dynamically adjust F\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE by dynamically adapting the DE scaling factor F based on remaining budget to balance exploration and exploitation.", "configspace": "", "generation": 61, "fitness": 0.1415754663929711, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.01.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.13989731316541865, 0.12572347762855418, 0.15910560838494048]}, "mutation_prompt": null}
{"id": "34241c92-54f4-458c-91eb-3c2ce203392c", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.6, 1.5  # Cognitive constant slightly increased\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced exploration in HybridPSO_DE by adjusting cognitive constant to improve convergence.", "configspace": "", "generation": 62, "fitness": 0.16177332461260976, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.01.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.1634848656503758, 0.1476985752411094, 0.17413653294634412]}, "mutation_prompt": null}
{"id": "65662ac0-1f6c-4502-8c91-eb42c2a46e6a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.92  # DE crossover probability (slightly increased)\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Slightly increase the DE crossover probability for improved exploration and diversity.", "configspace": "", "generation": 63, "fitness": 0.15229554318509378, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.03.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.17707062148333796, 0.16546454840657843, 0.11435145966536497]}, "mutation_prompt": null}
{"id": "8cd8dc2e-553f-417e-a090-1bfb3ea8c1c1", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.95  # DE crossover probability (slightly increased for better exploration)\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Slightly increase DE crossover probability to enhance exploration and convergence stability.", "configspace": "", "generation": 64, "fitness": 0.13087501253745437, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.03.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.16844304643858288, 0.1111699859746832, 0.11301200519909704]}, "mutation_prompt": null}
{"id": "e3a56af0-9c7b-4318-a794-baf92834e246", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    CR = 0.5 + 0.4 * np.cos(np.pi * evaluations / self.budget)  # Dynamic adjustment\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Introducing dynamic adjustment of DE crossover probability (CR) for better exploration-exploitation balance.", "configspace": "", "generation": 65, "fitness": 0.16351817728883086, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.01.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.16074998349952407, 0.18034818429143418, 0.1494563640755343]}, "mutation_prompt": null}
{"id": "5338dd11-b098-4a21-b4ad-73b2cb8fbea9", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.8 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Fine-tuned the inertia weight dynamic adjustment to enhance the convergence speed of the algorithm.", "configspace": "", "generation": 66, "fitness": 0.16542207179172116, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.03.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.19858941260138496, 0.1759142166373855, 0.12176258613639301]}, "mutation_prompt": null}
{"id": "aaff056a-c8cc-4d26-911b-57d0bb34cb99", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n            CR = 0.9 - 0.4 * (evaluations / self.budget)  # Change: dynamically adjust DE crossover probability\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE algorithm with dynamically adjusted DE crossover probability for improved exploration-exploitation balance.", "configspace": "", "generation": 67, "fitness": 0.16647248963761122, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.01.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.17020538676144203, 0.15422589050220947, 0.17498619164918217]}, "mutation_prompt": null}
{"id": "430c98cf-afac-45e5-8895-8dffee6c7880", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (slightly increased for enhanced exploration)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy with adaptive CR\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    CR = 0.5 + 0.4 * np.random.rand() # Adaptive DE crossover probability\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n                    \n            # Adjust inertia weight\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Introduced adaptive DE crossover probability to balance exploration and exploitation dynamically.", "configspace": "", "generation": 68, "fitness": 0.13913592796581428, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.02.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.1689390760022067, 0.13413077623253078, 0.11433793166270534]}, "mutation_prompt": null}
{"id": "76db28f6-f347-48a3-b8bc-1450ddc1c412", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n            F = 0.5 + 0.3 * np.sin(np.pi * evaluations / self.budget)  # Adaptive F\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE with adaptive DE scaling factor for better exploration and exploitation balance.", "configspace": "", "generation": 69, "fitness": 0.19201364748838967, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.01.", "error": "", "parent_id": "f91cbf9a-3c5e-4bd1-9be9-64d29da7842a", "metadata": {"aucs": [0.18568195062888115, 0.20481523155374237, 0.1855437602825455]}, "mutation_prompt": null}
{"id": "0a058e1d-9524-401d-8c31-215d3dd3dfb6", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                c1 = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Adaptive c1\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n            F = 0.5 + 0.3 * np.sin(np.pi * evaluations / self.budget)  # Adaptive F\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Introduce adaptive cognitive constant c1 to improve personal best exploration.", "configspace": "", "generation": 70, "fitness": 0.14840443831879654, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.01.", "error": "", "parent_id": "76db28f6-f347-48a3-b8bc-1450ddc1c412", "metadata": {"aucs": [0.16209979415420128, 0.1462349409585204, 0.1368785798436679]}, "mutation_prompt": null}
{"id": "f1a20215-bcd4-41d2-935b-cf8e6c1b3736", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n            F = 0.5 + 0.35 * np.sin(np.pi * evaluations / self.budget)  # Adaptive F\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Improved exploration by slightly modifying the DE scaling factor formula for better adaptive flexibility.", "configspace": "", "generation": 71, "fitness": 0.17040076705134843, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.01.", "error": "", "parent_id": "76db28f6-f347-48a3-b8bc-1450ddc1c412", "metadata": {"aucs": [0.15664324741985047, 0.1717416896566707, 0.18281736407752414]}, "mutation_prompt": null}
{"id": "daf073f8-e034-4009-b849-26101bb7f6c6", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n            F = 0.5 + 0.3 * np.sin(np.pi * evaluations / self.budget)  # Adaptive F\n            # Adaptive CR\n            CR = 0.8 + 0.1 * np.cos(np.pi * evaluations / self.budget)  # Added adaptive CR\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Fine-tune the DE crossover probability (CR) adaptively to balance exploration and exploitation.", "configspace": "", "generation": 72, "fitness": 0.1733686185170045, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.02.", "error": "", "parent_id": "76db28f6-f347-48a3-b8bc-1450ddc1c412", "metadata": {"aucs": [0.18503144948677375, 0.1853730125884845, 0.14970139347575528]}, "mutation_prompt": null}
{"id": "61cff134-4b48-4974-90dc-6e2c0405c4e8", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.9 - 0.4 * (evaluations / self.budget)  # Changed from 0.5 to 0.4 for smoother convergence\n            F = 0.5 + 0.3 * np.sin(np.pi * evaluations / self.budget)  # Adaptive F\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Improved inertia weight adaptation for smoother convergence in HybridPSO_DE.", "configspace": "", "generation": 73, "fitness": 0.16406818263741288, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.01.", "error": "", "parent_id": "76db28f6-f347-48a3-b8bc-1450ddc1c412", "metadata": {"aucs": [0.16373142626017667, 0.18038529931664127, 0.14808782233542073]}, "mutation_prompt": null}
{"id": "37156b08-5b2f-4380-ac2f-545fa828a253", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.9 - 0.6 * (evaluations / self.budget)  # Changed from 0.5 to 0.6\n            F = 0.5 + 0.3 * np.sin(np.pi * evaluations / self.budget)  # Adaptive F\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE with refined inertia weight adaptation for improved convergence.", "configspace": "", "generation": 74, "fitness": 0.18464771910747466, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.01.", "error": "", "parent_id": "76db28f6-f347-48a3-b8bc-1450ddc1c412", "metadata": {"aucs": [0.1931612417255284, 0.1919580087218894, 0.16882390687500615]}, "mutation_prompt": null}
{"id": "9628c37f-61b3-41e0-a5ae-74aa4143b1b5", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n            F = 0.5 + 0.3 * np.sin(2 * np.pi * evaluations / self.budget)  # Adaptive F (Modified)\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Refined HybridPSO_DE with improved adaptive DE scaling factor for enhanced balance between exploration and exploitation by modifying the sine function.", "configspace": "", "generation": 75, "fitness": 0.15547897126917445, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.03.", "error": "", "parent_id": "76db28f6-f347-48a3-b8bc-1450ddc1c412", "metadata": {"aucs": [0.15999817741404632, 0.11228260641585242, 0.19415612997762466]}, "mutation_prompt": null}
{"id": "f63fcca4-8485-43e4-9119-75371cd1425d", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n            F = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Adaptive F\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Adjusted DE scaling factor to improve exploration in early iterations.", "configspace": "", "generation": 76, "fitness": 0.14220287138392987, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.01.", "error": "", "parent_id": "76db28f6-f347-48a3-b8bc-1450ddc1c412", "metadata": {"aucs": [0.15054499426377288, 0.1471894274629606, 0.12887419242505616]}, "mutation_prompt": null}
{"id": "0858a327-5cb7-456d-84f7-da4ff293ff58", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n            F = 0.5 + 0.3 * np.sin(np.pi * evaluations / self.budget)  # Adaptive F\n            CR = 0.6 + 0.3 * np.cos(np.pi * evaluations / self.budget)  # Adaptive CR\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE with adaptive DE crossover probability (CR) for improved solution diversity.", "configspace": "", "generation": 77, "fitness": 0.18469131740281078, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.02.", "error": "", "parent_id": "76db28f6-f347-48a3-b8bc-1450ddc1c412", "metadata": {"aucs": [0.18574299708689268, 0.1637416564524431, 0.2045892986690966]}, "mutation_prompt": null}
{"id": "f1140fa8-baac-4190-ab61-55f5cd432ef3", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n            F = 0.5 + 0.4 * np.sin(np.pi * evaluations / self.budget)  # Adaptive F\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced exploration by adjusting the DE scaling factor to improve convergence.", "configspace": "", "generation": 78, "fitness": 0.18224734079143864, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.00.", "error": "", "parent_id": "76db28f6-f347-48a3-b8bc-1450ddc1c412", "metadata": {"aucs": [0.18183652599464328, 0.17693024740522434, 0.18797524897444828]}, "mutation_prompt": null}
{"id": "022eac62-c813-4f53-868d-27c5d938df40", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.92  # Adjusted DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n            F = 0.5 + 0.3 * np.sin(np.pi * evaluations / self.budget)  # Adaptive F\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Slightly adjust the DE crossover probability (CR) to enhance the balance between exploration and exploitation.", "configspace": "", "generation": 79, "fitness": 0.16699579747299553, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.04.", "error": "", "parent_id": "76db28f6-f347-48a3-b8bc-1450ddc1c412", "metadata": {"aucs": [0.20510471451725776, 0.18382902593386474, 0.1120536519678641]}, "mutation_prompt": null}
{"id": "c20e63f3-3d61-4111-bd0a-c290d2e46ce8", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n            F = 0.5 + 0.3 * np.sin(np.pi * evaluations / self.budget)  # Adaptive F\n            CR = 0.8 + 0.2 * np.cos(np.pi * evaluations / self.budget)  # Adaptive CR\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE with an adaptive DE crossover probability for improved diversification.", "configspace": "", "generation": 80, "fitness": 0.15189651249999533, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.02.", "error": "", "parent_id": "76db28f6-f347-48a3-b8bc-1450ddc1c412", "metadata": {"aucs": [0.17679957634849053, 0.1585397202481671, 0.12035024090332835]}, "mutation_prompt": null}
{"id": "e8bcdd95-4623-4b15-af6b-b6d5e0badcd3", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n            F = 0.5 + 0.3 * np.sin(np.pi * evaluations / self.budget) + 0.1 * (1 - evaluations / self.budget)  # Adaptive F with learning factor\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Introduced a learning factor to the DE scaling factor for improved convergence.", "configspace": "", "generation": 81, "fitness": 0.17515998419934395, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.00.", "error": "", "parent_id": "76db28f6-f347-48a3-b8bc-1450ddc1c412", "metadata": {"aucs": [0.17160068902356918, 0.17732783154324994, 0.1765514320312127]}, "mutation_prompt": null}
{"id": "522a7dd9-f9aa-4785-9a3f-dd305a4fe7cc", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.9 - 0.5 * (evaluations / self.budget)\n            F = 0.5 + 0.3 * np.sin(np.pi * evaluations / self.budget)  # Adaptive F\n            CR = 0.8 + 0.1 * np.cos(np.pi * evaluations / self.budget)  # Adaptive CR\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE by dynamically adjusting the DE crossover probability (CR) for improved balance between exploration and exploitation.", "configspace": "", "generation": 82, "fitness": 0.1733686185170045, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.02.", "error": "", "parent_id": "76db28f6-f347-48a3-b8bc-1450ddc1c412", "metadata": {"aucs": [0.18503144948677375, 0.1853730125884845, 0.14970139347575528]}, "mutation_prompt": null}
{"id": "13e1c5f0-033b-4b9d-8277-c1643ef2b97d", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.5 + 0.4 * (evaluations / self.budget)  # Changed line for improved performance\n            F = 0.5 + 0.3 * np.sin(np.pi * evaluations / self.budget)  # Adaptive F\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Improved inertia weight adaptation strategy to enhance the exploration-exploitation trade-off.", "configspace": "", "generation": 83, "fitness": 0.19606729732994174, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.01.", "error": "", "parent_id": "76db28f6-f347-48a3-b8bc-1450ddc1c412", "metadata": {"aucs": [0.19677980794838956, 0.20227425557803225, 0.1891478284634034]}, "mutation_prompt": null}
{"id": "cbcd2c7b-c291-42bb-baad-79b5745a0431", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.5 * np.exp(-3.0 * evaluations / self.budget)  # Modified line for exponential decay\n            F = 0.5 + 0.3 * np.sin(np.pi * evaluations / self.budget)  # Adaptive F\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Enhance the exploration capability by modifying the inertia weight decay to an exponential schedule.", "configspace": "", "generation": 84, "fitness": 0.22072812254948102, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.01.", "error": "", "parent_id": "13e1c5f0-033b-4b9d-8277-c1643ef2b97d", "metadata": {"aucs": [0.22570974178017267, 0.22709794650332427, 0.20937667936494608]}, "mutation_prompt": null}
{"id": "87a1b425-ae35-4985-8e73-f1bf5e8fb1f0", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.5 * np.exp(-3.0 * evaluations / self.budget)  # Modified line for exponential decay\n            F = 0.5 + 0.3 * np.sin(np.pi * evaluations / self.budget)  # Adaptive F\n            c1 = c1 + 0.1 * (global_best_value / (global_best_value + 1))  # Adaptively adjust c1\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Introduce adaptive learning factors in PSO's velocity update to improve convergence speed and solution quality.", "configspace": "", "generation": 85, "fitness": 0.17292678035840206, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.04.", "error": "", "parent_id": "cbcd2c7b-c291-42bb-baad-79b5745a0431", "metadata": {"aucs": [0.22059728217196528, 0.16728095453780134, 0.1309021043654396]}, "mutation_prompt": null}
{"id": "5ca66bae-6fdb-4aae-a818-dcabd402b93c", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.5 * np.exp(-3.0 * evaluations / self.budget)  # Modified line for exponential decay\n            CR = 0.9 - 0.4 * evaluations / self.budget  # Dynamically adjust CR\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Improve convergence by dynamically adjusting the DE crossover probability.", "configspace": "", "generation": 86, "fitness": 0.2300689847590145, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.01.", "error": "", "parent_id": "cbcd2c7b-c291-42bb-baad-79b5745a0431", "metadata": {"aucs": [0.21938134145614097, 0.2355795681502426, 0.2352460446706599]}, "mutation_prompt": null}
{"id": "54bf0ed8-cc5a-49b2-9366-761a2567270c", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.5 * np.exp(-3.0 * evaluations / self.budget)  # Modified line for exponential decay\n            CR = 0.9 - 0.4 * evaluations / self.budget  # Dynamically adjust CR\n            F = 0.85 - 0.35 * evaluations / self.budget  # Decrease F over time\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Incrementally reduce DE scaling factor F for smooth convergence.", "configspace": "", "generation": 87, "fitness": 0.21578144132615573, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.02.", "error": "", "parent_id": "5ca66bae-6fdb-4aae-a818-dcabd402b93c", "metadata": {"aucs": [0.2112652808892238, 0.19823350034332998, 0.2378455427459134]}, "mutation_prompt": null}
{"id": "1457f23e-9acf-4a64-8f2c-db24cc39e96b", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.5 * np.exp(-3.0 * evaluations / self.budget)  # Modified line for exponential decay\n            CR = 0.9 - 0.4 * evaluations / self.budget  # Dynamically adjust CR\n            F = 0.85 * (1 - evaluations / self.budget)  # Added decay factor to F\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Introduce a decay factor to the DE scaling factor (F) to balance exploration and exploitation over time.", "configspace": "", "generation": 88, "fitness": 0.19402144705289937, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.05.", "error": "", "parent_id": "5ca66bae-6fdb-4aae-a818-dcabd402b93c", "metadata": {"aucs": [0.23991497823188535, 0.20964914291955883, 0.13250022000725392]}, "mutation_prompt": null}
{"id": "fa0d6029-cc0f-46f9-bf7a-e3de44748720", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.5 * np.exp(-3.0 * evaluations / self.budget)  # Modified line for exponential decay\n            CR = 0.9 - 0.4 * evaluations / self.budget  # Dynamically adjust CR\n            F = 0.85 * (1 - evaluations / self.budget)  # New line for dynamic adjustment of F\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Improve convergence by dynamically adjusting the DE crossover probability and scaling factor with fine-tuned decay rates.", "configspace": "", "generation": 89, "fitness": 0.19402144705289937, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.05.", "error": "", "parent_id": "5ca66bae-6fdb-4aae-a818-dcabd402b93c", "metadata": {"aucs": [0.23991497823188535, 0.20964914291955883, 0.13250022000725392]}, "mutation_prompt": null}
{"id": "40e1bdb7-5572-48d9-ab84-c6a71eaafb45", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.5 * np.exp(-3.0 * evaluations / self.budget)  # Modified line for exponential decay\n            F = 0.85 - 0.4 * evaluations / self.budget  # Dynamically adjust F\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhance adaptive behavior by dynamically adjusting both the DE scaling factor and crossover probability based on evaluations.", "configspace": "", "generation": 90, "fitness": 0.22262785126410603, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.01.", "error": "", "parent_id": "5ca66bae-6fdb-4aae-a818-dcabd402b93c", "metadata": {"aucs": [0.21770946376622868, 0.23248632523501223, 0.2176877647910772]}, "mutation_prompt": null}
{"id": "625d629f-a2f0-43ce-94c6-6c3dcdc538cb", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.5 * np.exp(-3.0 * evaluations / self.budget)  # Modified line for exponential decay\n            F = 0.85 * (0.5 + 0.5 * np.cos(np.pi * evaluations / self.budget))  # Dynamically adjust F\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Enhance exploration by introducing a time-varying weight factor to the DE scaling factor.", "configspace": "", "generation": 91, "fitness": 0.20019921559174983, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.03.", "error": "", "parent_id": "5ca66bae-6fdb-4aae-a818-dcabd402b93c", "metadata": {"aucs": [0.22926353309519, 0.22025524486192039, 0.15107886881813914]}, "mutation_prompt": null}
{"id": "0e153bf3-b75d-4d92-9749-1637ee8204c7", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.5 * np.exp(-3.0 * evaluations / self.budget)  # Modified line for exponential decay\n            F = 0.85 * (1 - evaluations / self.budget)  # Dynamically adjust F factor\n            \n        return global_best", "name": "HybridPSO_DE", "description": "Introduce dynamic adjustment of the DE scaling factor for enhanced exploration-exploitation balance.", "configspace": "", "generation": 92, "fitness": 0.18117429346823374, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.04.", "error": "", "parent_id": "5ca66bae-6fdb-4aae-a818-dcabd402b93c", "metadata": {"aucs": [0.2402263847006595, 0.1707962756967878, 0.13250022000725392]}, "mutation_prompt": null}
{"id": "29c96f57-7a36-4729-8d21-435edc7407bc", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.5 * np.exp(-3.0 * evaluations / self.budget)  # Modified line for exponential decay\n            CR = 0.9 - 0.4 * evaluations / self.budget  # Dynamically adjust CR\n            F = 0.85 + 0.1 * (evaluations / self.budget)  # New line for dynamic F adjustment\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Enhance convergence by dynamically adjusting both the DE scaling factor and crossover probability.", "configspace": "", "generation": 93, "fitness": 0.19347756076046643, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.01.", "error": "", "parent_id": "5ca66bae-6fdb-4aae-a818-dcabd402b93c", "metadata": {"aucs": [0.21274707548596783, 0.1798819223739715, 0.18780368442146]}, "mutation_prompt": null}
{"id": "e404cada-531a-4460-9cad-ebb1a1c87b12", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.5 * np.exp(-3.0 * evaluations / self.budget)  # Modified line for exponential decay\n            CR = 0.9 - 0.4 * evaluations / self.budget  # Dynamically adjust CR\n            F = 0.85 * np.exp(-2.0 * evaluations / self.budget)  # Modified line to add exponential decay to F\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Enhance convergence by dynamically adjusting the DE scaling factor using exponential decay.", "configspace": "", "generation": 94, "fitness": 0.24322020020084897, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.02.", "error": "", "parent_id": "5ca66bae-6fdb-4aae-a818-dcabd402b93c", "metadata": {"aucs": [0.2746506730585623, 0.21712539004311127, 0.23788453750087335]}, "mutation_prompt": null}
{"id": "c2d17a9b-695c-4f14-be34-f7d941975779", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.5 * np.exp(-3.0 * evaluations / self.budget)  # Modified line for exponential decay\n            CR = 0.9 - 0.5 * evaluations / self.budget  # Dynamically adjust CR\n            F = 0.85 * np.exp(-2.0 * evaluations / self.budget)  # Modified line to add exponential decay to F\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Fine-tune the DE crossover probability (CR) to improve exploration-exploitation balance.", "configspace": "", "generation": 95, "fitness": 0.2487664906790761, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.03.", "error": "", "parent_id": "e404cada-531a-4460-9cad-ebb1a1c87b12", "metadata": {"aucs": [0.2917403141646294, 0.22001266273206, 0.23454649514053894]}, "mutation_prompt": null}
{"id": "b152f911-f548-4811-89ea-5426ae21bdc7", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.5 * np.exp(-3.0 * evaluations / self.budget)  # Modified line for exponential decay\n            CR = 0.9 - 0.5 * evaluations / self.budget  # Dynamically adjust CR\n            F = 0.85 * np.exp(-2.0 * evaluations / self.budget)  # Modified line to add exponential decay to F\n            F = F * (1 - evaluations/self.budget)  # New line for adaptive mutation scaling\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Incorporate adaptive mutation scaling in DE to enhance convergence speed.", "configspace": "", "generation": 96, "fitness": 0.2141523334089724, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.03.", "error": "", "parent_id": "c2d17a9b-695c-4f14-be34-f7d941975779", "metadata": {"aucs": [0.23591847743408967, 0.22875321857906128, 0.17778530421376626]}, "mutation_prompt": null}
{"id": "25bdd50b-5962-41be-9261-aad18f1b01d8", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.5 * np.exp(-3.0 * evaluations / self.budget)  # Modified line for exponential decay\n            CR = 0.9 - 0.5 * evaluations / self.budget  # Dynamically adjust CR\n            F = 0.85 * np.exp(-1.5 * evaluations / self.budget)  # Modified decay rate for F\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Adjust the exponential decay rate of the DE scaling factor F to enhance convergence speed.", "configspace": "", "generation": 97, "fitness": 0.19879131422081617, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.05.", "error": "", "parent_id": "c2d17a9b-695c-4f14-be34-f7d941975779", "metadata": {"aucs": [0.23731651526569808, 0.22612311323544465, 0.13293431416130574]}, "mutation_prompt": null}
{"id": "c94ca5db-1e8d-48f7-a101-3d3983bf1ae1", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.5 * np.exp(-3.0 * evaluations / self.budget)  # Modified line for exponential decay\n            CR = 0.9 - 0.5 * (evaluations/self.budget)**2  # Dynamically adjust CR using a quadratic decay\n            F = 0.85 * np.exp(-2.0 * evaluations / self.budget)  # Modified line to add exponential decay to F\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Introduce a non-linear decay to the DE crossover probability (CR) for improved convergence adaptability.", "configspace": "", "generation": 98, "fitness": 0.20874586105555235, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.03.", "error": "", "parent_id": "c2d17a9b-695c-4f14-be34-f7d941975779", "metadata": {"aucs": [0.22392885665427154, 0.16939068897777765, 0.23291803753460782]}, "mutation_prompt": null}
{"id": "34de8a04-8dc5-4f92-b6da-451dde1dd9b9", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        \n        # Parameters\n        num_particles = 30\n        w = 0.5  # Inertia weight\n        c1, c2 = 1.5, 1.5  # Cognitive and social constants\n        F = 0.85  # DE scaling factor (initial)\n        CR = 0.9  # DE crossover probability\n        \n        # Initialize particles\n        particles = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (num_particles, self.dim))\n        personal_best = particles.copy()\n        personal_best_value = np.array([func(p) for p in particles])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = num_particles\n        \n        while evaluations < self.budget:\n            for i in range(num_particles):\n                # Update velocity and position using PSO\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - particles[i]) +\n                                 c2 * r2 * (global_best - particles[i]))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                \n                # Evaluate new position\n                particle_value = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if particle_value < personal_best_value[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_value[i] = particle_value\n                    \n                    # Update global best\n                    if particle_value < global_best_value:\n                        global_best = particles[i]\n                        global_best_value = particle_value\n\n                # Apply Differential Evolution strategy\n                if evaluations < self.budget:\n                    indices = list(range(num_particles))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant_vector = personal_best[a] + F * (personal_best[b] - personal_best[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < CR, mutant_vector, particles[i])\n                    trial_vector = np.clip(trial_vector, lb, ub)\n                    \n                    trial_value = func(trial_vector)\n                    evaluations += 1\n\n                    # Update particle with trial vector if it's better\n                    if trial_value < particle_value:\n                        particles[i] = trial_vector\n                        personal_best[i] = trial_vector\n                        personal_best_value[i] = trial_value\n                        \n                        # Update global best\n                        if trial_value < global_best_value:\n                            global_best = trial_vector\n                            global_best_value = trial_value\n            \n            # Adjust inertia weight and DE scaling factor\n            w = 0.5 * np.exp(-3.0 * evaluations / self.budget)  # Modified line for exponential decay\n            CR = 0.9 - 0.5 * evaluations / self.budget  # Dynamically adjust CR\n            F = 0.85 * np.exp(-1.0 * evaluations / self.budget)  # Modified line to add exponential decay to F\n        \n        return global_best", "name": "HybridPSO_DE", "description": "Introduce adaptive scaling for F to enhance convergence speed over iterations.", "configspace": "", "generation": 99, "fitness": 0.18765090753824534, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.04.", "error": "", "parent_id": "c2d17a9b-695c-4f14-be34-f7d941975779", "metadata": {"aucs": [0.21852194686311655, 0.21269173426183396, 0.13173904148978555]}, "mutation_prompt": null}

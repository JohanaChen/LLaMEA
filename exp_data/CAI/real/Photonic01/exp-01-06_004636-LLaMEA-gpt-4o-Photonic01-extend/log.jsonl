{"id": "7f6c953f-2779-42a2-9be8-3d2f6ce04ef0", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = self.w * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "A hybrid particle swarm and differential evolution algorithm that dynamically adjusts strategies based on swarm diversity to optimize photonic structures effectively.", "configspace": "", "generation": 0, "fitness": 0.06920849633829218, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": null, "metadata": {"aucs": [0.0668232556856031, 0.06982651924696981, 0.07097571408230363]}, "mutation_prompt": null}
{"id": "3e0279c7-a2c5-4e04-b51e-3f19857edf09", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.w = 0.9 - 0.5 * (evals / self.budget)  # Adaptive inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = self.w * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Incorporate adaptive inertia weight adjustment to enhance exploration-exploitation balance in the hybrid PSO-DE algorithm.", "configspace": "", "generation": 1, "fitness": 0.06904085171862055, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "7f6c953f-2779-42a2-9be8-3d2f6ce04ef0", "metadata": {"aucs": [0.0666956426295624, 0.06989009643335609, 0.07053681609294316]}, "mutation_prompt": null}
{"id": "cbf097fe-de98-44df-a4bd-199ce73c0079", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.w = 0.9 - 0.5 * (evals / self.budget)  # Adaptive inertia weight\n\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = self.w * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "A hybrid particle swarm and differential evolution algorithm with adaptive inertia weight to optimize photonic structures effectively.", "configspace": "", "generation": 2, "fitness": 0.06904085171862055, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "7f6c953f-2779-42a2-9be8-3d2f6ce04ef0", "metadata": {"aucs": [0.0666956426295624, 0.06989009643335609, 0.07053681609294316]}, "mutation_prompt": null}
{"id": "18fbac82-78ca-4354-a215-7331b8515aca", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (evals / self.budget)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Enhanced hybrid PSO-DE algorithm with adaptive inertia weight adjustment to improve convergence speed and accuracy.", "configspace": "", "generation": 3, "fitness": 0.06942888365511675, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "7f6c953f-2779-42a2-9be8-3d2f6ce04ef0", "metadata": {"aucs": [0.06680998121063442, 0.0704913541423845, 0.07098531561233135]}, "mutation_prompt": null}
{"id": "ff724fa9-60e1-4bea-8c9f-8cfeaa462dc8", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.7  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (evals / self.budget)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Slightly increase the cognitive and social coefficients to enhance exploration and exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.06928026823571336, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "18fbac82-78ca-4354-a215-7331b8515aca", "metadata": {"aucs": [0.06680688077451036, 0.0704096946661944, 0.0706242292664353]}, "mutation_prompt": null}
{"id": "f9daf398-0482-48bc-b7d7-ca0f48613fdd", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (evals / self.budget)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                dynamic_cr = self.cr - 0.4 * (evals / self.budget)  # Change: Dynamic crossover probability\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < dynamic_cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Improved exploration by adjusting the crossover probability dynamically in the Differential Evolution phase.", "configspace": "", "generation": 5, "fitness": 0.06942888365511675, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "18fbac82-78ca-4354-a215-7331b8515aca", "metadata": {"aucs": [0.06680998121063442, 0.0704913541423845, 0.07098531561233135]}, "mutation_prompt": null}
{"id": "f158742e-654f-4688-a046-32ba4457dd41", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = ((self.w - 0.4 * (evals / self.budget)) * \n                                   self.velocities + \n                                   (self.c1 + 0.1 * (evals / self.budget)) * r1 * (pbests - pop) +  # Changed line\n                                   self.c2 * r2 * (gbest - pop))\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Incorporate a dynamic scaling factor in the PSO component to enhance exploration and exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.06941239071826093, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "18fbac82-78ca-4354-a215-7331b8515aca", "metadata": {"aucs": [0.06681078508747451, 0.0704448316785401, 0.07098155538876816]}, "mutation_prompt": null}
{"id": "5af9b893-4c5b-4cdc-bd7a-02a484413454", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (evals / self.budget)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                # dynamically adjust scaling factor\n                self.f = 0.5 + 0.5 * ((self.budget - evals) / self.budget)  \n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Hybrid PSO-DE algorithm with dynamic scaling factor for improved exploration-exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.06942888365511675, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "18fbac82-78ca-4354-a215-7331b8515aca", "metadata": {"aucs": [0.06680998121063442, 0.0704913541423845, 0.07098531561233135]}, "mutation_prompt": null}
{"id": "9ae22aa1-f45e-4fc8-9ac9-3af6e95b99fb", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.92  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (evals / self.budget)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Incremented the crossover probability for enhanced exploration in DE phase.", "configspace": "", "generation": 8, "fitness": 0.06942888365511675, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "18fbac82-78ca-4354-a215-7331b8515aca", "metadata": {"aucs": [0.06680998121063442, 0.0704913541423845, 0.07098531561233135]}, "mutation_prompt": null}
{"id": "b8de111c-8a0f-40ac-8b60-bd0124dd8e78", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.5 + 0.5 * (1 - evals / self.budget))  # cognitive coefficient decay\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (evals / self.budget)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduced a decay function for the cognitive coefficient to enhance exploration and exploitation balance over iterations.", "configspace": "", "generation": 9, "fitness": 0.0694610921431229, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "18fbac82-78ca-4354-a215-7331b8515aca", "metadata": {"aucs": [0.06682796333711383, 0.07056763958481616, 0.07098767350743873]}, "mutation_prompt": null}
{"id": "9c4ad49c-e787-4567-b34c-42e507706361", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.5 + 0.5 * (1 - evals / self.budget))  # cognitive coefficient decay\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (evals / self.budget)**2) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)  # Changed line\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Enhanced exploration by using a non-linear decay for the inertia weight.", "configspace": "", "generation": 10, "fitness": 0.06949031225459261, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "b8de111c-8a0f-40ac-8b60-bd0124dd8e78", "metadata": {"aucs": [0.06681884391553028, 0.07066861639399835, 0.07098347645424918]}, "mutation_prompt": null}
{"id": "e5ed0b59-680c-49d3-99a9-687096332c74", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.5 + 0.5 * (1 - evals / self.budget))  # cognitive coefficient decay\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.3 * (evals / self.budget)**2) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)  # Changed line\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Improved exploration by modifying the decay strategy of the inertia weight for better convergence.", "configspace": "", "generation": 11, "fitness": 0.06948964570866674, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "9c4ad49c-e787-4567-b34c-42e507706361", "metadata": {"aucs": [0.0668189012692405, 0.07066686031377534, 0.07098317554298439]}, "mutation_prompt": null}
{"id": "ecc712a2-7ca9-449e-bcad-11aaa06023c3", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.5 + 0.5 * (1 - evals / self.budget))  # cognitive coefficient decay\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (evals / self.budget)**2) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    self.f = 0.5 + 0.5 * (0.5 - evals / self.budget)  # Changed line\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Enhanced exploration by modifying the scaling factor dynamically based on evaluation progress.", "configspace": "", "generation": 12, "fitness": 0.06949031225459261, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "9c4ad49c-e787-4567-b34c-42e507706361", "metadata": {"aucs": [0.06681884391553028, 0.07066861639399835, 0.07098347645424918]}, "mutation_prompt": null}
{"id": "5e56046b-2a7d-40ca-a9aa-b25c4b2845ce", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.5 + 0.5 * (1 - evals / self.budget))  # cognitive coefficient decay\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (evals / self.budget)**2) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Adjusted inertia weight decay to quadratic for improved exploitation.", "configspace": "", "generation": 13, "fitness": 0.06949031225459261, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "9c4ad49c-e787-4567-b34c-42e507706361", "metadata": {"aucs": [0.06681884391553028, 0.07066861639399835, 0.07098347645424918]}, "mutation_prompt": null}
{"id": "30c4f07c-7a05-4d49-83fa-7049ff5ed5ec", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.5 + 0.5 * (1 - evals / self.budget))  # cognitive coefficient decay\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)  # Changed line\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Improved the inertia weight decay function for better convergence by using a quadratic function.", "configspace": "", "generation": 14, "fitness": 0.06962955333750565, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "9c4ad49c-e787-4567-b34c-42e507706361", "metadata": {"aucs": [0.06692982817401583, 0.0709096946879787, 0.07104913715052241]}, "mutation_prompt": null}
{"id": "2d978e70-9dd6-4d07-b390-83d26e87a63f", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.5 + 0.5 * (1 - evals / self.budget))  # cognitive coefficient decay\n            self.f = 0.5 + 0.5 * (1 - evals / self.budget)  # Adaptive scaling factor\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)  # Changed line\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce adaptive scaling for differential evolution to enhance exploration-exploitation balance.", "configspace": "", "generation": 15, "fitness": 0.06962955333750565, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "30c4f07c-7a05-4d49-83fa-7049ff5ed5ec", "metadata": {"aucs": [0.06692982817401583, 0.0709096946879787, 0.07104913715052241]}, "mutation_prompt": null}
{"id": "e4936fdb-1cda-4cc7-aa68-cb84b29fee8d", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.5 + 0.5 * (1 - evals / self.budget))  # cognitive coefficient decay\n            self.cr = 0.9 - 0.4 * (evals / self.budget)  # Adaptive crossover probability\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)  # Changed line\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduced adaptive crossover probability that decreases linearly to enhance exploration in early iterations and exploitation in later iterations.", "configspace": "", "generation": 16, "fitness": 0.06962955333750565, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "30c4f07c-7a05-4d49-83fa-7049ff5ed5ec", "metadata": {"aucs": [0.06692982817401583, 0.0709096946879787, 0.07104913715052241]}, "mutation_prompt": null}
{"id": "9a59fad2-debc-49db-ac29-3d253a29ca2c", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.5 + 0.5 * (1 - evals / self.budget))  # cognitive coefficient decay\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                diversity = np.mean(np.std(pop, axis=0))\n                self.f = 0.5 + 0.5 * diversity / (ub - lb)  # Changed line\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Enhance local exploration by dynamically adjusting the differential evolution's scaling factor based on diversity.", "configspace": "", "generation": 17, "fitness": 0.06962955333750565, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "30c4f07c-7a05-4d49-83fa-7049ff5ed5ec", "metadata": {"aucs": [0.06692982817401583, 0.0709096946879787, 0.07104913715052241]}, "mutation_prompt": null}
{"id": "b5a71d8e-650b-400a-867a-d27570efe48b", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.5 + 0.5 * (1 - evals / self.budget))  # cognitive coefficient decay\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (0.9 - 0.5 * (evals / self.budget)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)  # Changed line\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Adaptive inertia weight decay function for enhanced exploration-exploitation balance.", "configspace": "", "generation": 18, "fitness": 0.06913786742447785, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "30c4f07c-7a05-4d49-83fa-7049ff5ed5ec", "metadata": {"aucs": [0.06672218066342062, 0.07015980241700037, 0.07053161919301254]}, "mutation_prompt": null}
{"id": "ae5f7d3c-867a-4e51-9b19-f1c59a3b073d", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.5 + 0.5 * (1 - evals / self.budget))  # cognitive coefficient decay\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)  # Changed line\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                dynamic_f = self.f + 0.1 * np.sin(np.pi * evals / self.budget)  # Adjusted line\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + dynamic_f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce a dynamic scaling factor in the Differential Evolution phase to enhance exploration and exploitation balance.", "configspace": "", "generation": 19, "fitness": 0.06962955333750565, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "30c4f07c-7a05-4d49-83fa-7049ff5ed5ec", "metadata": {"aucs": [0.06692982817401583, 0.0709096946879787, 0.07104913715052241]}, "mutation_prompt": null}
{"id": "8b7ba0ba-7243-499e-a25a-ba400a207b35", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.5 + 0.5 * (1 - evals / self.budget))  # cognitive coefficient decay\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)  # Changed line\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < (self.cr * (1 - evals / self.budget))  # Changed line\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduced a dynamic crossover probability in Differential Evolution to enhance diversity and convergence.", "configspace": "", "generation": 20, "fitness": 0.06962955333750565, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "30c4f07c-7a05-4d49-83fa-7049ff5ed5ec", "metadata": {"aucs": [0.06692982817401583, 0.0709096946879787, 0.07104913715052241]}, "mutation_prompt": null}
{"id": "73d6c431-a28e-4c83-a1c4-e43d05ba5c15", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Enhanced the cognitive coefficient decay function for improved exploration and convergence.", "configspace": "", "generation": 21, "fitness": 0.06964863556935093, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "30c4f07c-7a05-4d49-83fa-7049ff5ed5ec", "metadata": {"aucs": [0.06693489637279992, 0.0709613889930194, 0.07104962134223347]}, "mutation_prompt": null}
{"id": "04f5c952-05f0-4446-b44d-747c6353f4f0", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.w = 0.9 - 0.5 * (evals / self.budget)  # Adaptive inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduced adaptive inertia weight to enhance balance between exploration and exploitation.", "configspace": "", "generation": 22, "fitness": 0.06956459805025805, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "73d6c431-a28e-4c83-a1c4-e43d05ba5c15", "metadata": {"aucs": [0.06686951574410571, 0.0708447856739729, 0.07097949273269555]}, "mutation_prompt": null}
{"id": "da2ff3ab-49b2-434a-80c7-e4b6583c5919", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.w = 0.9 - 0.5 * (evals / self.budget)  # Changed line for adaptive inertia weight \n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduced adaptive inertia weight to balance exploration and exploitation based on convergence.", "configspace": "", "generation": 23, "fitness": 0.06956459805025805, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "73d6c431-a28e-4c83-a1c4-e43d05ba5c15", "metadata": {"aucs": [0.06686951574410571, 0.0708447856739729, 0.07097949273269555]}, "mutation_prompt": null}
{"id": "d386f761-358e-4b8a-97d1-bf60c20c270c", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.w = 0.9 - 0.5 * (evals / self.budget)  # Changed line for adaptive inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduced an adaptive inertia weight update function for improved convergence dynamics.", "configspace": "", "generation": 24, "fitness": 0.06956459805025805, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "73d6c431-a28e-4c83-a1c4-e43d05ba5c15", "metadata": {"aucs": [0.06686951574410571, 0.0708447856739729, 0.07097949273269555]}, "mutation_prompt": null}
{"id": "aa359e2b-9c6d-4e8c-820e-25993a7c590a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.w = 0.9 - 0.5 * (evals / self.budget)  # Changed line for adaptive inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduced adaptive inertia weight decay to enhance convergence and exploration balance.", "configspace": "", "generation": 25, "fitness": 0.06956459805025805, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "73d6c431-a28e-4c83-a1c4-e43d05ba5c15", "metadata": {"aucs": [0.06686951574410571, 0.0708447856739729, 0.07097949273269555]}, "mutation_prompt": null}
{"id": "37b308da-6665-4623-9756-fdbb6986eb56", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w * 0.5 + 0.5 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Adjusted inertia weight decay for improved balance between exploration and exploitation.", "configspace": "", "generation": 26, "fitness": 0.06884515792029133, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "73d6c431-a28e-4c83-a1c4-e43d05ba5c15", "metadata": {"aucs": [0.06662961594792705, 0.06971721105380413, 0.07018864675914283]}, "mutation_prompt": null}
{"id": "20778819-c793-4cb8-a54e-a6b57e7204cc", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.w = 0.9 - 0.5 * (evals / self.budget)  # Dynamic inertia weight\n                self.velocities = self.w * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduced a dynamic inertia weight to improve the balance between exploration and exploitation.", "configspace": "", "generation": 27, "fitness": 0.06913995716021071, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "73d6c431-a28e-4c83-a1c4-e43d05ba5c15", "metadata": {"aucs": [0.06671101679377456, 0.07012149245693888, 0.07058736222991868]}, "mutation_prompt": null}
{"id": "aafd4b10-2d42-4047-93f2-ebdc761a2e3d", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.w = 0.9 - 0.4 * (evals / self.budget)  # Adaptive inertia weight change\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce adaptive inertia weight for better balance between exploration and exploitation.", "configspace": "", "generation": 28, "fitness": 0.06956470662814766, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "73d6c431-a28e-4c83-a1c4-e43d05ba5c15", "metadata": {"aucs": [0.06686931907491556, 0.07084256419313228, 0.07098223661639513]}, "mutation_prompt": null}
{"id": "ec69ca95-d3f7-4ada-b123-e6f14bfc9fcc", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.w = 0.9 - 0.5 * (evals / self.budget)  # Adaptive inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduced adaptive inertia weight for improved convergence balance.", "configspace": "", "generation": 29, "fitness": 0.06956459805025805, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "73d6c431-a28e-4c83-a1c4-e43d05ba5c15", "metadata": {"aucs": [0.06686951574410571, 0.0708447856739729, 0.07097949273269555]}, "mutation_prompt": null}
{"id": "7e066378-96ee-40e2-a35d-7c5a86c747ec", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.w = 0.9 - 0.5 * (evals / self.budget)  # Adaptive inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduced adaptive inertia weight to improve balance between exploration and exploitation.", "configspace": "", "generation": 30, "fitness": 0.06956459805025805, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "73d6c431-a28e-4c83-a1c4-e43d05ba5c15", "metadata": {"aucs": [0.06686951574410571, 0.0708447856739729, 0.07097949273269555]}, "mutation_prompt": null}
{"id": "989de84b-b779-4289-a655-cc3fcae71889", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w * (0.5 + 0.5 * (1 - evals / self.budget))) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Tweaked inertia weight decay function for better balance between exploration and exploitation.", "configspace": "", "generation": 31, "fitness": 0.06944683772766518, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "73d6c431-a28e-4c83-a1c4-e43d05ba5c15", "metadata": {"aucs": [0.0668244040470416, 0.07053050874739464, 0.07098560038855928]}, "mutation_prompt": null}
{"id": "97ff995f-4eb7-48b0-ba77-1f6f1351289d", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.w = 0.7 * (0.5 + 0.5 * (1 - evals / self.budget))  # Changed line for adaptive inertia weight decay\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduced adaptive inertia weight decay to balance exploration and exploitation dynamically.", "configspace": "", "generation": 32, "fitness": 0.06957270581993846, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "73d6c431-a28e-4c83-a1c4-e43d05ba5c15", "metadata": {"aucs": [0.06695133048769975, 0.07069874986103786, 0.07106803711107779]}, "mutation_prompt": null}
{"id": "cda8a26f-04e0-4c3f-a208-30e903c9d3b3", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Enhance the social coefficient decay function to improve convergence dynamics.", "configspace": "", "generation": 33, "fitness": 0.07052817417153338, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "73d6c431-a28e-4c83-a1c4-e43d05ba5c15", "metadata": {"aucs": [0.07111362660162002, 0.07112035701607133, 0.06935053889690879]}, "mutation_prompt": null}
{"id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Adjust the inertia weight for better exploration-exploitation balance.", "configspace": "", "generation": 34, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "cda8a26f-04e0-4c3f-a208-30e903c9d3b3", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "f30788c0-d4b1-4475-bcd4-5a72edec98ea", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.85  # crossover probability - Adjusted from 0.9 to 0.85\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Enhance the exploration-exploitation balance by slightly adjusting the crossover probability in DE.", "configspace": "", "generation": 35, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "ba7fe144-cef4-4c59-8d1f-ce4c9d1ebb58", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.f = 0.5 + 0.2 * (1 - evals / self.budget)  # Changed line for dynamic scaling factor\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduced dynamic scaling factor `f` for DE to balance exploration-exploitation.", "configspace": "", "generation": 36, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "31466cca-55a1-42a3-a6ad-799c72db0fee", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                adaptive_f = self.f + 0.3 * (1 - evals / self.budget)  # Change: Adaptive scaling factor\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + adaptive_f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce adaptive mutation scaling to improve exploration during Differential Evolution phases.", "configspace": "", "generation": 37, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "4440179e-d62e-4ce1-abd0-245f0cb6498f", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.f = 0.5 + 0.3 * (evals / self.budget)  # Adjust scaling factor evolution for DE\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Enhanced balance between local and global search by adjusting scaling factor's evolution based on the budget.", "configspace": "", "generation": 38, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "00c3c24e-486d-4368-9b1b-2fc2018f8e3d", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.f = 0.5 + 0.5 * (evals / self.budget)  # Change: adaptive scaling factor for DE\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduced adaptive scaling factor in differential evolution to improve convergence performance.", "configspace": "", "generation": 39, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "2e9e95b8-4b76-4259-993f-bcb978867464", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                self.f = 0.5 + (0.3 * (np.random.rand() - 0.5))  # Changed line for dynamic scaling factor\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce dynamic scaling factor adaptation in Differential Evolution for better exploration-exploitation balance.", "configspace": "", "generation": 40, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "6ed064f2-375e-43bc-8a9c-3171fcc85086", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.f = 0.4 + 0.6 * (evals / self.budget)  # Adaptive scaling factor\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce adaptive scaling factor to balance exploration and exploitation dynamically.", "configspace": "", "generation": 41, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "f16f8adc-1835-4c95-8bcd-13906b187cee", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.f = 0.5 + 0.5 * (1 - evals / self.budget)  # Changed line for dynamic DE scaling factor\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Enhance exploration by dynamically adjusting the scaling factor in DE based on the number of evaluations.", "configspace": "", "generation": 42, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "64978b83-5868-404d-96a0-24c0b5aec334", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.7 + 0.3 * (1 - evals / self.budget))  # Changed line for refined decay rate\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Fine-tune the decay rate of the cognitive coefficient for enhanced convergence.", "configspace": "", "generation": 43, "fitness": 0.07104077571352618, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111779844092814, 0.07101262807856212, 0.07099190062108829]}, "mutation_prompt": null}
{"id": "29b4173e-f04f-4d44-b721-6c774e660d69", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.f = 0.3 + 0.4 * (1 - evals / self.budget)  # Enhanced line for adaptive scaling factor\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Enhance convergence by adapting the scaling factor for differential evolution.", "configspace": "", "generation": 44, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "31997d59-a41c-469b-a42b-4950d4c7217d", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.cr = 0.8 + 0.2 * np.exp(-0.02 * evals)  # Adjusted line for adaptive crossover probability\n\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce an adaptive mechanism to dynamically adjust the crossover probability for better convergence.", "configspace": "", "generation": 45, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "ee9fc1ff-deaa-47ce-bca0-76dc3bae9050", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                self.f = 0.5 + 0.3 * np.sin(np.pi * evals / self.budget)  # Changed line for dynamic scaling factor\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce dynamic scaling factor to improve diversity during differential evolution phase.", "configspace": "", "generation": 46, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "791def76-aba5-4e60-8988-664517f2f57e", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.92  # crossover probability - modified\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Increase the crossover probability slightly to enhance diversity in the Differential Evolution phase.", "configspace": "", "generation": 47, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"'HybridPSO_DE' object has no attribute 'velocities'\").", "error": "AttributeError(\"'HybridPSO_DE' object has no attribute 'velocities'\")", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {}, "mutation_prompt": null}
{"id": "3e7852f6-aa00-47e2-8025-5cd3b492a260", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.f = 0.5 + 0.3 * np.sin(np.pi * evals / self.budget)  # Modified line for dynamic scaling factor\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce dynamic scaling factor in DE to enhance diversity and convergence.", "configspace": "", "generation": 48, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "8dfb50c4-6625-4a7f-912a-65dfa86435a3", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n            else:\n                pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))  # Random restart if no improvement\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce random restart strategy for enhanced exploration upon stagnation.", "configspace": "", "generation": 49, "fitness": 0.0654427019729766, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.06936218384983972, 0.06624020440736167, 0.06072571766172841]}, "mutation_prompt": null}
{"id": "b713a256-1d80-40f4-9b47-ed0bada82d3a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.8   # scaling factor for differential evolution  # Adjusted\n        self.cr = 0.95  # crossover probability  # Adjusted\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Fine-tune the scaling factor and crossover probability in the Differential Evolution phase for enhanced convergence.", "configspace": "", "generation": 50, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "611c7b19-ecba-4e58-8700-de834a1e2e18", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.cr = 0.9 * (1 - evals / self.budget)  # Adjusted line for dynamic crossover probability\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Dynamically adjust the crossover probability in Differential Evolution to improve diversity.", "configspace": "", "generation": 51, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "03103281-5dd7-471d-821c-866154ae51d3", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.f = 0.5 + 0.3 * (1 - evals / self.budget)  # Adaptive scaling factor for DE\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce adaptive scaling factor for DE to improve search efficiency.", "configspace": "", "generation": 52, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "4643c9f2-f6dd-4e1b-8073-00e32262427a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                self.f = 0.3 + 0.7 * (1 - evals / self.budget)  # Change: Adaptive scaling factor\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Use adaptive scaling factor in Differential Evolution to balance exploration and exploitation dynamically.", "configspace": "", "generation": 53, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "54ac1582-9287-4bba-864d-1d8b63918a3f", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                self.f = 0.5 + 0.3 * (1 - evals / self.budget)  # Adaptive scaling factor change\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce adaptive scaling for the differential evolution strategy based on evaluation progression for improved convergence.", "configspace": "", "generation": 54, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "50b7d00d-dd7d-4fa4-8e7a-e6d582c54b24", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.cr = 0.5 + 0.5 * (evals / self.budget)  # New dynamic crossover probability\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Adjusted the crossover probability dynamically based on evaluation progress for improved exploration-exploitation balance.", "configspace": "", "generation": 55, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "c5e83852-af21-49ed-80a2-ccfb0a717cd1", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    self.f = 0.5 + 0.5 * (1 - evals / self.budget)  # Changed line for adaptive scaling factor\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce adaptive scaling factor adjustment in Differential Evolution for improved exploration.", "configspace": "", "generation": 56, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "8e063ee5-12f8-4d13-9636-5b6c46f9f2c8", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.f = 0.5 + 0.3 * (1 - evals / self.budget)  # Modified line for adaptive scaling factor\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce adaptive scaling factor for differential evolution to enhance convergence speed.", "configspace": "", "generation": 57, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "1f1b4634-ba8e-4714-8e6e-90932269175b", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.f = 0.5 * (1 + 0.2 * (1 - evals / self.budget))  # Updated line for adaptive scaling factor\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Adaptive differential evolution scaling factor for improved convergence.", "configspace": "", "generation": 58, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "62ee30f7-a521-4cfc-ae0a-8322f92932cb", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                self.cr = 0.7 + 0.3 * (1 - evals / self.budget)  # Changed line for adaptive crossover probability\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Incorporate adaptive crossover probability to enhance exploration in Differential Evolution.", "configspace": "", "generation": 59, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "4505bb8e-78a7-4549-b086-f022c85ac352", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                self.cr = 0.9 * (0.5 + 0.5 * (evals / self.budget))  # Changed line for adaptive crossover probability\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduced adaptive crossover probability in Differential Evolution to enhance diversity and convergence.", "configspace": "", "generation": 60, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "1fb4dd44-b59e-4e79-b1f8-c2aef79e749f", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                self.f = 0.5 * (1 - evals / self.budget)  # Introduced decay of scaling factor\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce a mutation factor decay strategy to enhance exploration in DE over iterations.", "configspace": "", "generation": 61, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "d1dbd796-b350-4f3e-b5b5-23002e712361", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities * (1 - evals / self.budget), lb, ub)  # Modified line for improved control\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Enhance particle velocity update for improved convergence.", "configspace": "", "generation": 62, "fitness": 0.0709085667122041, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07112087579775173, 0.07103813572131668, 0.0705666886175439]}, "mutation_prompt": null}
{"id": "567b514d-176c-4289-9d2d-c0bfb8a0d0d5", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.f = 0.5 * (1 + 0.5 * np.sin(np.pi * evals / self.budget))  # Introduced time-varying scaling factor\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce time-varying scaling factor in DE for better adaptability.", "configspace": "", "generation": 63, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "0e3ac2f4-9282-4463-9fff-106cea92e99f", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.cr = 0.9 - 0.3 * (evals / self.budget)  # Adjusted crossover probability for better diversity\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Fine-tune the crossover probability to enhance diversity and prevent premature convergence.", "configspace": "", "generation": 64, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "5c5fa972-be68-48e9-a0b3-822a283b5560", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                self.cr = 0.8 + 0.2 * (evals / self.budget)  # New line for adaptive crossover probability\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Adaptively adjust the crossover probability for differential evolution to enhance solution diversity.", "configspace": "", "generation": 65, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "d8f22cd3-64de-4572-8d07-4c8028fece00", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.f = 0.5 * (1 + 0.5 * np.sin(np.pi * evals / self.budget))  # Changed line for scaling factor adaptation\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce dynamic adaptation of the scaling factor for differential evolution to improve convergence.", "configspace": "", "generation": 66, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "aa6640f7-2dda-4b1d-bb7e-0587ee9309da", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                self.f = 0.5 * (1 - evals / self.budget)  # Decaying scaling factor\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce a decaying scaling factor to improve the balance between exploration and exploitation during Differential Evolution.", "configspace": "", "generation": 67, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "27f2316d-7196-4f9f-be2c-3ed0cc686786", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.f = 0.4 + 0.6 * (evals / self.budget)  # Modified line for dynamic scaling factor\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Fine-tune the scaling factor dynamically based on the budget usage for enhanced exploration-exploitation trade-off.", "configspace": "", "generation": 68, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "878e9048-c411-4970-b590-612ac0289b1a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                self.cr = 0.9 * (0.5 + 0.5 * (evals / self.budget))  # Dynamic adjustment of crossover probability\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Enhanced convergence by adjusting the crossover probability dynamically.", "configspace": "", "generation": 69, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "b3aff842-fb50-4361-a75b-114383e0ef08", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.3 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Improved inertia weight update to enhance convergence speed and solution accuracy.", "configspace": "", "generation": 70, "fitness": 0.07006043519207805, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07110479796406, 0.07099115534031808, 0.06808535227185608]}, "mutation_prompt": null}
{"id": "1c969274-01de-4722-ab2b-ec02805361a5", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                self.f = 0.5 + 0.3 * np.cos(np.pi * evals / self.budget)  # Dynamic scaling factor introduced\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce dynamic scaling factor in Differential Evolution to enhance adaptability.", "configspace": "", "generation": 71, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "f7e5fec5-b75a-4a0e-97ee-a3d5232e1bc1", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.f = 0.5 + 0.2 * (1 - evals / self.budget)  # Changed line for adaptive scaling factor\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce adaptive scaling factor to enhance the exploration-exploitation trade-off.", "configspace": "", "generation": 72, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "32f8f9ff-9f31-44c5-9ff1-dfcfbec90b96", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            dynamic_f = self.f + 0.5 * (evals / self.budget)  # Dynamic scaling for mutation factor\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + dynamic_f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce dynamic scaling for the mutation factor in Differential Evolution to enhance adaptability.", "configspace": "", "generation": 73, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "86723be7-2925-4be8-8b31-ca4cf0d2cc36", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.f = 0.3 + 0.7 * (1 - evals / self.budget)  # Adjust DE scaling factor dynamically\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Implement a dynamic scaling factor to improve exploration-exploitation balance by adjusting the differential evolution scaling factor over iterations.", "configspace": "", "generation": 74, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "4ce28f1a-9e44-40f5-9af7-052418bf89ad", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + 0.6 * (b - c), lb, ub)  # Changed scaling factor\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Tweak the scaling factor in the Differential Evolution component to enhance convergence speed.", "configspace": "", "generation": 75, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "003282a6-0943-4c2a-b44f-e92313efc0f3", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.f = 0.5 + 0.3 * np.cos((evals / self.budget) * np.pi) # New line: Time-varying scaling factor for DE\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce time-varying scaling factor in Differential Evolution for enhanced convergence.", "configspace": "", "generation": 76, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "891b775b-71c4-4c1c-a787-8dc9fd69f536", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.92  # crossover probability, slightly increased\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Slightly increase the crossover probability to improve diversity in the Differential Evolution phase.", "configspace": "", "generation": 77, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"'HybridPSO_DE' object has no attribute 'velocities'\").", "error": "AttributeError(\"'HybridPSO_DE' object has no attribute 'velocities'\")", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {}, "mutation_prompt": null}
{"id": "09e03ef4-bda6-442a-bfd3-aaa32c4da471", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.cr = 0.9 * (0.5 + 0.5 * (evals / self.budget))  # Changed line for dynamic crossover probability\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce dynamic adaptation of the crossover probability to enhance solution diversity.", "configspace": "", "generation": 78, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "9a06a708-0e47-420c-8fef-af89cbfff32b", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))\n            self.w = 0.5 + 0.3 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Refine the inertia weight update formula for improved balance between exploration and exploitation.", "configspace": "", "generation": 79, "fitness": 0.07006043519207805, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07110479796406, 0.07099115534031808, 0.06808535227185608]}, "mutation_prompt": null}
{"id": "671e72cf-bf0b-4a38-af65-36d6db193ef5", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                self.cr = 0.4 + 0.5 * evals / self.budget  # Changed line for time-varying crossover probability\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Include a time-varying crossover probability in Differential Evolution for improved adaptability.", "configspace": "", "generation": 80, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "a4930244-643f-4f24-b554-6fe1d4429698", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.7   # scaling factor for differential evolution (changed from 0.5)\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Fine-tune the scaling factor for differential evolution to enhance exploration and convergence balance.", "configspace": "", "generation": 81, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "8a720468-7dbf-416a-a4d7-13a0e021ded8", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.f = 0.5 + 0.4 * np.sin(np.pi * evals / self.budget)  # Adaptive scaling factor for DE\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce adaptive scaling factor for DE to enhance exploration-exploitation transition.", "configspace": "", "generation": 82, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "4b11bb86-c4e6-43d6-8e7c-eca577f7587e", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.cr = 0.5 + 0.4 * (evals / self.budget)  # Adjust crossover probability adaptively\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Enhanced convergence by adjusting crossover probability adaptively based on evaluations.", "configspace": "", "generation": 83, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "3b7eb750-49f8-422d-9d76-2170468cac0c", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                self.cr = 0.9 * (1 - evals / self.budget)  # Adaptive crossover probability (line changed)\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce a dynamic crossover probability in Differential Evolution for adaptive exploration-exploitation balance.", "configspace": "", "generation": 84, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "b923abd1-025d-47be-8b76-e8bf4f85d646", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                self.cr = 0.9 - (0.5 * evals / self.budget)  # Changed line for adaptive crossover probability\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduced adaptive crossover probability for Differential Evolution to enhance diversity.", "configspace": "", "generation": 85, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "93953927-09f3-45b9-91f6-83ef9d65778d", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + (self.f + 0.1 * (evals / self.budget)) * (b - c), lb, ub)  # Changed line for adaptive mutation\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Integrate adaptive mutation scaling in Differential Evolution for dynamic exploration.", "configspace": "", "generation": 86, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "bee6164e-223f-4866-ad50-a5fd84ef51d2", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                self.cr = 0.9 * (1 - evals / self.budget)  # Updated line for adaptive crossover probability\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce adaptive crossover probability in Differential Evolution to enhance diversity and convergence.", "configspace": "", "generation": 87, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "23c76c19-9b09-439b-91e7-bf8cf88c0df5", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            # Change: Adjust inertia weight based on population diversity\n            self.w = 0.5 + 0.4 * (1 - np.std(pop, axis=0).mean() / (ub - lb).mean())\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Fine-tune the inertia weight to dynamically adapt based on population diversity for improved convergence.", "configspace": "", "generation": 88, "fitness": 0.07100089325776937, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07112116456519724, 0.07108728854480129, 0.07079422666330959]}, "mutation_prompt": null}
{"id": "dd1ebbfe-b7e9-4fee-89c4-3458845c707c", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.cr = 0.8 + 0.2 * (evals / self.budget)  # Change for dynamic crossover probability in DE\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Enhance the balance between exploration and exploitation by dynamically adjusting the crossover probability in DE.", "configspace": "", "generation": 89, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "2dca07ee-74fe-44ea-b9d4-e200dc60131e", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.cr = 0.7 + 0.2 * (1 - evals / self.budget)  # New line for dynamic crossover probability\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Dynamically adjust crossover probability for enhanced diversity in the evolutionary process.", "configspace": "", "generation": 90, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "6ba69664-81a0-4d15-b396-979b5f907423", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                self.f = 0.5 + 0.4 * np.sin(np.pi * evals / self.budget)  # Changed line for adaptive scaling factor\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduced adaptive scaling factor `f` within DE for improved diversity.", "configspace": "", "generation": 91, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "12cc99ef-7a78-484d-beb7-f704aa49434a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                self.f = 0.5 + 0.3 * (1 - evals / self.budget)  # Adaptive scaling factor\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce adaptive scaling factor in Differential Evolution component for better convergence.", "configspace": "", "generation": 92, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "eadf34b1-7738-48c1-a27d-58d9109049a1", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.92  # crossover probability, changed from 0.9 to 0.92\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Slightly increase the crossover probability in the DE phase for better exploration.", "configspace": "", "generation": 93, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "1cc866cc-d401-45b9-b676-0acccc5d8d42", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.8   # scaling factor for differential evolution  # Changed this line\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Fine-tune the DE scaling factor to improve convergence speed.", "configspace": "", "generation": 94, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "83207cb9-0dc6-4345-aa2b-4045e50be13f", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    self.f = 0.5 + 0.3 * (evals / self.budget)  # Changed line for dynamic mutation scaling factor\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Refine the mutation strategy dynamically based on the current evaluation ratio to improve the diversity of the search.", "configspace": "", "generation": 95, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "ad372171-cf6e-4388-a966-c4247396c0e6", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.f = 0.5 + 0.5 * (evals / self.budget)  # Adaptive scaling factor\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce adaptive scaling factor in Differential Evolution for enhanced convergence.", "configspace": "", "generation": 96, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "fad3ba4d-5333-404b-b4a4-cc86e072abd4", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < (self.cr * (1 - evals / self.budget))  # Modified line for adaptive crossover probability\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Fine-tuning crossover probability in Differential Evolution for better diversity.", "configspace": "", "generation": 97, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "d931c665-a4d3-40e8-9480-d389cbf60ba6", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.f = 0.5 + 0.3 * (1 - evals / self.budget)  # Changed line for dynamic scaling factor\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce a dynamic adaptation of the scaling factor in Differential Evolution to improve convergence.", "configspace": "", "generation": 98, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}
{"id": "356f32e8-c391-4be8-a5ea-f4408d928a79", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.f = 0.5   # scaling factor for differential evolution\n        self.cr = 0.9  # crossover probability\n        self.velocities = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        pbests = pop.copy()\n        pbest_scores = np.array([func(ind) for ind in pbests])\n        gbest = pbests[np.argmin(pbest_scores)].copy()\n        gbest_score = np.min(pbest_scores)\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            self.c1 = 1.5 * (0.6 + 0.4 * (1 - evals / self.budget))  # Changed line for enhanced decay\n            self.c2 = 1.5 * (0.6 + 0.4 * (evals / self.budget))  # Added line for social coefficient decay\n            self.w = 0.5 + 0.4 * (1 - evals / self.budget)  # Changed line for improved inertia weight\n            self.cr = 0.9 * (1 - (evals / self.budget))  # New line for varying crossover probability\n            if evals % self.population_size < self.population_size // 2:\n                # Particle Swarm Optimization\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                self.velocities = (self.w - 0.4 * (1 - (evals / self.budget)**2)) * self.velocities + self.c1 * r1 * (pbests - pop) + self.c2 * r2 * (gbest - pop)\n                pop = np.clip(pop + self.velocities, lb, ub)\n            else:\n                # Differential Evolution\n                for i in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    pop[i] = np.where(cross_points, mutant, pop[i])\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            evals += self.population_size\n\n            # Update personal bests\n            better_mask = scores < pbest_scores\n            pbests[better_mask] = pop[better_mask]\n            pbest_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            if np.min(pbest_scores) < gbest_score:\n                gbest = pbests[np.argmin(pbest_scores)].copy()\n                gbest_score = np.min(pbest_scores)\n\n        return gbest, gbest_score", "name": "HybridPSO_DE", "description": "Introduce a dynamic adjustment of the crossover probability in Differential Evolution based on current iteration progress.", "configspace": "", "generation": 99, "fitness": 0.07104160094693956, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "3c7ededb-56c3-4f34-bcc6-3faf2305ab23", "metadata": {"aucs": [0.07111842207052044, 0.07100704117797396, 0.0709993395923243]}, "mutation_prompt": null}

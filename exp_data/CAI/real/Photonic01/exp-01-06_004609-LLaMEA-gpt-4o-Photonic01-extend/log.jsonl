{"id": "5a2ecabd-16d1-4491-abdf-f166258902d2", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.9\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity)\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            if func(trial_vector) < func(self.particles[i]):\n                self.particles[i] = trial_vector\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds)\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Hybrid Swarm-Differential Metaheuristic combines swarm intelligence with differential evolution for efficient exploration and exploitation in black box optimization.", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 187, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 264, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 134, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 66, in __call__\n  File \"<string>\", line 56, in differential_evolution\nNameError: name 'func' is not defined\n.", "error": "NameError(\"name 'func' is not defined\")Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 187, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 264, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 134, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 66, in __call__\n  File \"<string>\", line 56, in differential_evolution\nNameError: name 'func' is not defined\n", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "ea5d28b7-1943-4b0d-929c-2d84532d1c7d", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.9\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity)\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):  # Added func as a parameter\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            if func(trial_vector) < func(self.particles[i]):\n                self.particles[i] = trial_vector\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)  # Passed func to the method\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Incremental refinement over the Hybrid Swarm-Differential Metaheuristic by ensuring correct scope of the func variable in the differential_evolution method.", "configspace": "", "generation": 1, "fitness": 0.068062077343838, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "5a2ecabd-16d1-4491-abdf-f166258902d2", "metadata": {"aucs": [0.06884571064972755, 0.06763782513984451, 0.06770269624194192]}, "mutation_prompt": null}
{"id": "0e8f3a9f-86ac-4427-88f0-99bce881a2c5", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.inertia_weight = 0.9  # increased\n        self.cognitive_coeff = 1.7  # increased\n        self.social_coeff = 1.3  # decreased\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.9\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity)\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):  # Added func as a parameter\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            if func(trial_vector) < func(self.particles[i]):\n                self.particles[i] = trial_vector\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)  # Passed func to the method\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Enhanced HybridSwarmDifferential by introducing adaptive parameters for better convergence in optimizing photonic structures.", "configspace": "", "generation": 2, "fitness": 0.06526362686901106, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "ea5d28b7-1943-4b0d-929c-2d84532d1c7d", "metadata": {"aucs": [0.06541099936880723, 0.06579430118501084, 0.06458558005321513]}, "mutation_prompt": null}
{"id": "f4733c3c-d75d-43bb-8443-eaea855accd6", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.9\n        self.evaluations = 0\n        self.adaptation_rate = 0.05  # New adaptation rate for control factors\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity)\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):  # Added func as a parameter\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            if func(trial_vector) < func(self.particles[i]):\n                self.particles[i] = trial_vector\n            self.evaluations += 1\n\n    def adapt_parameters(self):\n        self.cognitive_coeff = max(0.5, self.cognitive_coeff - self.adaptation_rate)\n        self.social_coeff = min(2.0, self.social_coeff + self.adaptation_rate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)  # Passed func to the method\n            self.adapt_parameters()  # Adapt parameters during the run\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Enhanced hybrid approach by introducing self-adaptive control factors and dynamic population size adjustment.", "configspace": "", "generation": 3, "fitness": 0.06793781254547926, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "ea5d28b7-1943-4b0d-929c-2d84532d1c7d", "metadata": {"aucs": [0.06863425048708827, 0.06793880942587849, 0.06724037772347102]}, "mutation_prompt": null}
{"id": "afdf575f-0c86-4a40-ba8c-46b4a09c8fab", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # population size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.diff_weight = 0.9  # Adjusted the differential weight\n        self.crossover_prob = 0.95  # Increased the crossover probability\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity)\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):  # Added func as a parameter\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)  # Calculate trial vector score\n            if trial_score < func(self.particles[i]):  # Use trial_score for comparison\n                self.particles[i] = trial_vector\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)  # Passed func to the method\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Enhanced mutation and selection strategies in PSO-DE hybrid to improve exploration-exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.06732234783727764, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "ea5d28b7-1943-4b0d-929c-2d84532d1c7d", "metadata": {"aucs": [0.0683164219074025, 0.06717340803257477, 0.06647721357185565]}, "mutation_prompt": null}
{"id": "29260eda-f724-46d1-93e7-52f23c25f7fd", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.9\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  cognitive_velocity + social_velocity)\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            if func(trial_vector) < func(self.particles[i]):\n                self.particles[i] = trial_vector\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Enhanced integration of particle swarm and differential evolution by dynamically adjusting parameters based on population diversity.", "configspace": "", "generation": 5, "fitness": 0.06940291373754015, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "ea5d28b7-1943-4b0d-929c-2d84532d1c7d", "metadata": {"aucs": [0.06972670294167471, 0.06903186089110602, 0.06945017737983972]}, "mutation_prompt": null}
{"id": "8b507483-44d8-473e-b242-864aefb1c5eb", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)  # Adaptive population size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7  # Initial crossover probability\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  cognitive_velocity + social_velocity)\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 2 else 0.7 # Adaptive crossover\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            if func(trial_vector) < func(self.particles[i]):\n                self.particles[i] = trial_vector\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Introduce adaptive crossover probability and dynamic population size to enhance exploration-exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.06948990061051419, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "29260eda-f724-46d1-93e7-52f23c25f7fd", "metadata": {"aucs": [0.06961996596336029, 0.06932766555762027, 0.06952207031056201]}, "mutation_prompt": null}
{"id": "c0b873fb-49a2-411f-a9f6-dc257652ed81", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)  # Adaptive population size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7  # Initial crossover probability\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  cognitive_velocity + social_velocity)\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5 # More adaptive crossover\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            if func(trial_vector) < func(self.particles[i]):\n                self.particles[i] = trial_vector\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Enhance diversity and adapt crossover more precisely for improved balance between exploration and exploitation.", "configspace": "", "generation": 7, "fitness": 0.06974381560221339, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "8b507483-44d8-473e-b242-864aefb1c5eb", "metadata": {"aucs": [0.0693895918763684, 0.07003024221368637, 0.06981161271658542]}, "mutation_prompt": null}
{"id": "402e7de3-13ed-4d4b-938e-cda5a1d2da4d", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)  \n        self.inertia_weight = 0.9  # Adjusted for better initial exploration\n        self.cognitive_coeff = 1.7  # Slightly increased for quick convergence\n        self.social_coeff = 1.3  # Reduced for more controlled exploitation\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7  \n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        progress = self.evaluations / self.budget\n        dynamic_inertia = self.inertia_weight - 0.5 * progress  # Adaptive inertia weight\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  cognitive_velocity + social_velocity)\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.95 if self.evaluations > self.budget // 2 else 0.6  # Adjusted for progress\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            if func(trial_vector) < func(self.particles[i]):\n                self.particles[i] = trial_vector\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Improve convergence by introducing adaptive dynamic parameters based on optimization progress.", "configspace": "", "generation": 8, "fitness": 0.06775314349001034, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "c0b873fb-49a2-411f-a9f6-dc257652ed81", "metadata": {"aucs": [0.06724074469717323, 0.06692834189344621, 0.0690903438794116]}, "mutation_prompt": null}
{"id": "48f05657-ad65-446f-bcc9-d594b74fd6de", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)  # Adaptive population size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7  # Initial crossover probability\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  cognitive_velocity + social_velocity)\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5 # More adaptive crossover\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutation_scale = 0.5 + (0.4 * (self.evaluations / self.budget))  # Adaptive mutation scaling\n            mutant_vector = np.clip(a + mutation_scale * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                self.personal_best_scores[i] = min(trial_score, self.personal_best_scores[i])  # Implement elitism\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Introduce adaptive mutation scaling and elitism to improve convergence in HybridSwarmDifferential.", "configspace": "", "generation": 9, "fitness": 0.06949647666334487, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "c0b873fb-49a2-411f-a9f6-dc257652ed81", "metadata": {"aucs": [0.06969428495174479, 0.06885265120173611, 0.06994249383655371]}, "mutation_prompt": null}
{"id": "271c76da-1a52-4fab-8e56-7666bf5954b3", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)  # Adaptive population size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7  # Initial crossover probability\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  cognitive_velocity + social_velocity)\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        diversity = np.var(self.particles)  # Compute overall diversity\n        self.diff_weight = 0.5 + 0.3 * (diversity / (diversity + 1e-10))  # Adaptive mutation scaling\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            if func(trial_vector) < func(self.particles[i]):\n                self.particles[i] = trial_vector\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Introduce adaptive mutation scaling based on diversity and adjust inertia dynamically for improved convergence.", "configspace": "", "generation": 10, "fitness": 0.06974381560221339, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "c0b873fb-49a2-411f-a9f6-dc257652ed81", "metadata": {"aucs": [0.0693895918763684, 0.07003024221368637, 0.06981161271658542]}, "mutation_prompt": null}
{"id": "af54dcd1-be0a-4196-8ff7-840f1aa0fc40", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)  # Adaptive population size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7  # Initial crossover probability\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  cognitive_velocity + social_velocity)\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5  # More adaptive crossover\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            dynamic_diff_weight = self.diff_weight + 0.2 * (diversity / (diversity + 1e-10))\n            mutant_vector = np.clip(a + dynamic_diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            if func(trial_vector) < func(self.particles[i]):\n                self.particles[i] = trial_vector\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Introduce adaptive mutation scaling and enhanced diversity control for balanced exploration-exploitation trade-off.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'diversity' is not defined\").", "error": "NameError(\"name 'diversity' is not defined\")", "parent_id": "c0b873fb-49a2-411f-a9f6-dc257652ed81", "metadata": {}, "mutation_prompt": null}
{"id": "666717d6-a673-4ecf-bbee-46f5c53d693e", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(15 * dim, 150)  # Adaptive population size\n        self.inertia_weight = 0.9  # Modified initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7  # Initial crossover probability\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight * (1 - 0.5 * np.sin(np.pi * diversity / (diversity + 1e-10)))\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  cognitive_velocity + social_velocity)\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5 # More adaptive crossover\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            if func(trial_vector) < func(self.particles[i]):\n                self.particles[i] = trial_vector\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Introduce a nonlinear dynamic inertia weight and adaptive population scaling for better convergence.", "configspace": "", "generation": 12, "fitness": 0.06527969954504775, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "c0b873fb-49a2-411f-a9f6-dc257652ed81", "metadata": {"aucs": [0.06476389840961716, 0.06510910343680887, 0.06596609678871723]}, "mutation_prompt": null}
{"id": "8bb78b2d-19eb-46a6-95e2-b3901618ff5f", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)  # Adaptive population size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7  # Initial crossover probability\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  cognitive_velocity + social_velocity)\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.diff_weight = 0.9 if self.evaluations > self.budget // 2 else 0.6 # More adaptive differential weight\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            if func(trial_vector) < func(self.particles[i]):\n                self.particles[i] = trial_vector\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Utilize adaptive differential weight for enhanced exploration in differential evolution.", "configspace": "", "generation": 13, "fitness": 0.06937568470140092, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "c0b873fb-49a2-411f-a9f6-dc257652ed81", "metadata": {"aucs": [0.0696700549939413, 0.06878294801626517, 0.06967405109399627]}, "mutation_prompt": null}
{"id": "16dce55a-3474-495b-9966-14288ea8904a", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)  # Adaptive population size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7  # Initial crossover probability\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  cognitive_velocity + social_velocity)\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5 # More adaptive crossover\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            local_search_boost = np.random.uniform(0.95, 1.05, self.dim)  \n            trial_vector *= local_search_boost  \n            if func(trial_vector) < func(self.particles[i]):\n                self.particles[i] = trial_vector\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Introduce adaptive mutation and crowding distance to enhance exploration and local search balance.", "configspace": "", "generation": 14, "fitness": 0.06956431471424751, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "c0b873fb-49a2-411f-a9f6-dc257652ed81", "metadata": {"aucs": [0.07010573155112843, 0.06858985293544173, 0.06999735965617238]}, "mutation_prompt": null}
{"id": "0a3102d7-d773-4917-8bd2-1a387bbc8480", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)  # Adaptive population size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7  # Initial crossover probability\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        self.social_coeff = 1.5 + 0.5 * (diversity / (diversity + 1e-10)) # Dynamically adjust social coefficient\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  cognitive_velocity + social_velocity)\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5 # More adaptive crossover\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            if func(trial_vector) < func(self.particles[i]):\n                self.particles[i] = trial_vector\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Increase exploration by dynamically adjusting social coefficient based on diversity.", "configspace": "", "generation": 15, "fitness": 0.06893338159727962, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "c0b873fb-49a2-411f-a9f6-dc257652ed81", "metadata": {"aucs": [0.06986700465045559, 0.06890215750425255, 0.0680309826371307]}, "mutation_prompt": null}
{"id": "c4f45209-6f51-4373-a10b-693eedcbf01e", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Integrate adaptive learning rates and elitism to enhance convergence speed and solution accuracy.", "configspace": "", "generation": 16, "fitness": 0.0699652589930313, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "c0b873fb-49a2-411f-a9f6-dc257652ed81", "metadata": {"aucs": [0.07039035396153959, 0.06971466181129415, 0.06979076120626015]}, "mutation_prompt": null}
{"id": "26102aec-c69d-4459-8316-51f47f723109", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(15 * dim, 150)  # Increased initial population size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Improve exploration by increasing the initial population size for better diversity.", "configspace": "", "generation": 17, "fitness": 0.06866974104823553, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "c4f45209-6f51-4373-a10b-693eedcbf01e", "metadata": {"aucs": [0.06925928224868794, 0.06748234626541205, 0.06926759463060661]}, "mutation_prompt": null}
{"id": "37cb268a-9ab6-4867-b42b-6ab1a7bbd218", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            if self.global_best_score < initial_global_score:\n                self.learning_rate *= 1.01\n            else:\n                self.learning_rate *= 0.99\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Enhance adaptive learning by dynamically adjusting the learning rate based on performance improvement.", "configspace": "", "generation": 18, "fitness": 0.06997846462779293, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "c4f45209-6f51-4373-a10b-693eedcbf01e", "metadata": {"aucs": [0.07037164386399652, 0.06974892040631542, 0.06981482961306684]}, "mutation_prompt": null}
{"id": "25a62a9d-835c-41ed-a67a-6e6149484b82", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            if self.global_best_score < initial_global_score:\n                self.learning_rate *= 1.02  # Increased adjustment rate\n            else:\n                self.learning_rate *= 0.98  # Increased adjustment rate\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Improved adaptive learning rate by increasing its change rate to enhance convergence speed.", "configspace": "", "generation": 19, "fitness": 0.06999630738680233, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "37cb268a-9ab6-4867-b42b-6ab1a7bbd218", "metadata": {"aucs": [0.0703924728037103, 0.06975035652095718, 0.0698460928357395]}, "mutation_prompt": null}
{"id": "69f67051-d98c-47ca-9096-862f3adc2229", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            # Changed line: dynamically adapt the differential weight\n            mutant_vector = np.clip(a + self.diff_weight * (b - c) * (0.5 + np.random.rand()), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            if self.global_best_score < initial_global_score:\n                self.learning_rate *= 1.02  # Increased adjustment rate\n            else:\n                self.learning_rate *= 0.98  # Increased adjustment rate\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Enhanced the mutation strategy in differential evolution by dynamically adapting the differential weight for better exploration.", "configspace": "", "generation": 20, "fitness": 0.06994274843628694, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "25a62a9d-835c-41ed-a67a-6e6149484b82", "metadata": {"aucs": [0.07024710993745797, 0.06946826525435779, 0.07011287011704503]}, "mutation_prompt": null}
{"id": "6c59c2b8-a2b7-4b9d-bd02-3528d0cbfe55", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.8 + 0.1 * (self.evaluations / self.budget)  # Adjusted adaptive crossover\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            perturbation = np.random.normal(0, 0.1, self.dim)  # Small random perturbation\n            mutant_vector += perturbation  # Apply perturbation\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            if self.global_best_score < initial_global_score:\n                self.learning_rate *= 1.02\n            else:\n                self.learning_rate *= 0.98\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Enhanced convergence through adaptive crossover probability and perturbation strategy.", "configspace": "", "generation": 21, "fitness": 0.06961647145271994, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "25a62a9d-835c-41ed-a67a-6e6149484b82", "metadata": {"aucs": [0.06994244899181401, 0.06930320931427214, 0.0696037560520737]}, "mutation_prompt": null}
{"id": "9ace7348-ab94-49b7-8eaf-45b7945c2f0a", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Enhanced learning rate adaptation to improve convergence efficiency.", "configspace": "", "generation": 22, "fitness": 0.07000664878406875, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "25a62a9d-835c-41ed-a67a-6e6149484b82", "metadata": {"aucs": [0.07035543960984703, 0.06979804860949068, 0.06986645813286851]}, "mutation_prompt": null}
{"id": "6997bb57-0a89-4daa-8a68-5226de4596d8", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        dynamic_diff_weight = self.diff_weight + 0.2 * (np.random.rand() - 0.5)  # Adjusted line\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + dynamic_diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Enhanced mutation strategy with dynamic differential weight for improved exploration.", "configspace": "", "generation": 23, "fitness": 0.06998930179929286, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "9ace7348-ab94-49b7-8eaf-45b7945c2f0a", "metadata": {"aucs": [0.07039142982549063, 0.06984554423179501, 0.06973093134059294]}, "mutation_prompt": null}
{"id": "b7f05ac6-e9af-4da6-a489-07d991d8d20c", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Slightly adjust the cognitive coefficient for improved convergence stability.", "configspace": "", "generation": 24, "fitness": 0.07001450357027898, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "9ace7348-ab94-49b7-8eaf-45b7945c2f0a", "metadata": {"aucs": [0.07039564909215001, 0.06980125104136237, 0.06984661057732455]}, "mutation_prompt": null}
{"id": "f1dc918e-aa8a-489b-80d7-c3780e165740", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.8  # Slightly increased for better exploration\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Slightly increase the cognitive coefficient to enhance exploration capabilities at early stages.", "configspace": "", "generation": 25, "fitness": 0.07000708725877203, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "b7f05ac6-e9af-4da6-a489-07d991d8d20c", "metadata": {"aucs": [0.07036063509988466, 0.06976703834546338, 0.06989358833096804]}, "mutation_prompt": null}
{"id": "9a8b5042-c20f-41cf-a09c-85334fff7dce", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.35 * (diversity / (diversity + 1e-10))  # Adjusted coefficient\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Introduced a small adjustment to the calculation of dynamic inertia for diversity to enhance convergence.", "configspace": "", "generation": 26, "fitness": 0.0699281023193344, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "b7f05ac6-e9af-4da6-a489-07d991d8d20c", "metadata": {"aucs": [0.07015670002665242, 0.06966680953456839, 0.0699607973967824]}, "mutation_prompt": null}
{"id": "b5e5c48c-a694-4456-82d9-c5f500d32acb", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        adaptive_cognitive_coeff = self.cognitive_coeff * (0.5 + 0.5 * np.random.rand())  # Adaptation added\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = adaptive_cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Incorporate an adaptive cognitive coefficient to enhance convergence speed and stability.", "configspace": "", "generation": 27, "fitness": 0.06907157735024165, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "b7f05ac6-e9af-4da6-a489-07d991d8d20c", "metadata": {"aucs": [0.06994834662793514, 0.06781987905166409, 0.0694465063711257]}, "mutation_prompt": null}
{"id": "8a2bad3d-6401-4299-bc5a-216a7729d253", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.5\n        self.diff_weight = 0.85  # Increased differential weight for enhanced exploration\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Slightly increase the differential weight for enhanced exploration.", "configspace": "", "generation": 28, "fitness": 0.07001134554389621, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "b7f05ac6-e9af-4da6-a489-07d991d8d20c", "metadata": {"aucs": [0.07036233629761846, 0.06971472721914562, 0.06995697311492455]}, "mutation_prompt": null}
{"id": "5a4687e1-9ff6-46f4-95fb-fd6e58f14305", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.5\n        self.diff_weight = 0.85  # Increased differential weight\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Slightly increase the differential weight for enhanced exploration.", "configspace": "", "generation": 29, "fitness": 0.07001134554389621, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "b7f05ac6-e9af-4da6-a489-07d991d8d20c", "metadata": {"aucs": [0.07036233629761846, 0.06971472721914562, 0.06995697311492455]}, "mutation_prompt": null}
{"id": "11c74290-017c-45d7-8225-d6d8b75219a4", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.8  # Slight adjustment for better convergence\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Improve convergence by dynamically adjusting the cognitive coefficient.", "configspace": "", "generation": 30, "fitness": 0.07000708725877203, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "b7f05ac6-e9af-4da6-a489-07d991d8d20c", "metadata": {"aucs": [0.07036063509988466, 0.06976703834546338, 0.06989358833096804]}, "mutation_prompt": null}
{"id": "e65f48cc-54ca-4a67-910b-ab7d4fc01e0b", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Slightly adjust the cognitive coefficient for improved convergence stability.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "b7f05ac6-e9af-4da6-a489-07d991d8d20c", "metadata": {"aucs": [0.07039564909215001, 0.06980125104136237, 0.06984661057732455]}, "mutation_prompt": null}
{"id": "06f70c11-0a07-4244-9149-7d9afa3c145f", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        adaptive_cognitive_coeff = self.cognitive_coeff * (0.5 + 0.5 * np.random.rand())  # Line changed\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = adaptive_cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])  # Line changed\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.5 + 0.4 * (1 - self.evaluations / self.budget)  # Line changed\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Introduce adaptive cognitive coefficients and dynamic crossover probability to enhance convergence.", "configspace": "", "generation": 32, "fitness": 0.06830139850567203, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "b7f05ac6-e9af-4da6-a489-07d991d8d20c", "metadata": {"aucs": [0.06988012222424544, 0.06686731713963534, 0.06815675615313532]}, "mutation_prompt": null}
{"id": "ce021a6e-adb2-4600-bcbf-109a802b6181", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        diversity = np.var(self.particles, axis=0).mean()  # New line to compute diversity\n        self.crossover_prob = 0.5 + 0.4 * (diversity / (diversity + 1e-10))  # Modified line for dynamic crossover prob\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Introduce a dynamic crossover probability based on diversity to balance exploration and exploitation more effectively in the population.", "configspace": "", "generation": 33, "fitness": 0.06986862312920643, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "b7f05ac6-e9af-4da6-a489-07d991d8d20c", "metadata": {"aucs": [0.07031065982611384, 0.06949234919528835, 0.06980286036621708]}, "mutation_prompt": null}
{"id": "6d9c99ed-ba4a-4fe2-a39b-8e7b25ab52f1", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.8  # Slight adjustment for better individual exploration\n        self.social_coeff = 1.5\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Slightly increase the cognitive coefficient to enhance individual exploration.", "configspace": "", "generation": 34, "fitness": 0.07000708725877203, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "b7f05ac6-e9af-4da6-a489-07d991d8d20c", "metadata": {"aucs": [0.07036063509988466, 0.06976703834546338, 0.06989358833096804]}, "mutation_prompt": null}
{"id": "ac2370bd-ddd9-447a-8147-027a791b48c2", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Slightly increase the social coefficient to enhance global exploration capabilities.", "configspace": "", "generation": 35, "fitness": 0.07002520782100637, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "b7f05ac6-e9af-4da6-a489-07d991d8d20c", "metadata": {"aucs": [0.07042704540102951, 0.06975045449586892, 0.06989812356612068]}, "mutation_prompt": null}
{"id": "4be17b55-157a-43b2-b234-91a7751c3cd0", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.85  # Slight increase for better performance\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Enhance the algorithm by slightly increasing the differential weight to improve exploration and exploitation balance.", "configspace": "", "generation": 36, "fitness": 0.06991820378573606, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "ac2370bd-ddd9-447a-8147-027a791b48c2", "metadata": {"aucs": [0.07010316668453354, 0.0696842218943704, 0.06996722277830425]}, "mutation_prompt": null}
{"id": "001e53b6-0df4-487b-98ab-ca5ad27d57b0", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.75  # Slight increase for improved convergence\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Increase inertia weight slightly to improve convergence speed and exploration balance.", "configspace": "", "generation": 37, "fitness": 0.06991545457657133, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "ac2370bd-ddd9-447a-8147-027a791b48c2", "metadata": {"aucs": [0.07013092556095701, 0.06972782784644493, 0.06988761032231205]}, "mutation_prompt": null}
{"id": "57bc3e5c-46e5-402a-96ff-56d7dd26e9f1", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.72  # Slight increase for better convergence\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Minor adjustment to inertia weight to enhance convergence speed.", "configspace": "", "generation": 38, "fitness": 0.06997629275897095, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "ac2370bd-ddd9-447a-8147-027a791b48c2", "metadata": {"aucs": [0.07031876816016347, 0.06970894666731287, 0.06990116344943653]}, "mutation_prompt": null}
{"id": "256b54a6-8358-432a-bcfd-801d0fd8fe8f", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.65  # Slightly decrease for better convergence speed\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Slightly decrease the inertia weight to improve convergence speed.", "configspace": "", "generation": 39, "fitness": 0.07001558095050527, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "ac2370bd-ddd9-447a-8147-027a791b48c2", "metadata": {"aucs": [0.07047187764688045, 0.06970664329407317, 0.06986822191056219]}, "mutation_prompt": null}
{"id": "a30fb1f9-8c45-476b-b00a-e2e7c4e6aff0", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.85  # Increased for better convergence\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Increase differential weight slightly to improve convergence speed.", "configspace": "", "generation": 40, "fitness": 0.06991820378573606, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "ac2370bd-ddd9-447a-8147-027a791b48c2", "metadata": {"aucs": [0.07010316668453354, 0.0696842218943704, 0.06996722277830425]}, "mutation_prompt": null}
{"id": "a76eb3d3-f2b0-428d-9347-c0a6be2c879d", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.9  # Minor adjustment for improved local exploitation\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Increase cognitive coefficient to enhance local search capability.", "configspace": "", "generation": 41, "fitness": 0.06999787702307814, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "ac2370bd-ddd9-447a-8147-027a791b48c2", "metadata": {"aucs": [0.0703773905261107, 0.0696980588394942, 0.06991818170362951]}, "mutation_prompt": null}
{"id": "a3a9d1cd-cb73-4c33-9b33-e7cc608c1801", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.75  # Slight adjustment for enhanced dynamic adaptability\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.6\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Introduce a slight adjustment to the inertia weight for enhanced dynamic adaptability.", "configspace": "", "generation": 42, "fitness": 0.06991545457657133, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "ac2370bd-ddd9-447a-8147-027a791b48c2", "metadata": {"aucs": [0.07013092556095701, 0.06972782784644493, 0.06988761032231205]}, "mutation_prompt": null}
{"id": "1aa17b14-a1c0-475a-bc2d-949e1f903f38", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.68  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Increase diversity and global search by slightly decreasing the inertia weight.", "configspace": "", "generation": 43, "fitness": 0.07004229399023006, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "ac2370bd-ddd9-447a-8147-027a791b48c2", "metadata": {"aucs": [0.0704767658987886, 0.06973411341423752, 0.06991600265766407]}, "mutation_prompt": null}
{"id": "cea4a22f-eac4-423c-a6bf-f6f612b2bc8c", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.68  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = 0.5 + 0.5 * (self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10)))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Enhance exploration by dynamically adjusting the inertia weight range.", "configspace": "", "generation": 44, "fitness": 0.0697348638990845, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "1aa17b14-a1c0-475a-bc2d-949e1f903f38", "metadata": {"aucs": [0.07000753461678888, 0.0692822196688786, 0.069914837411586]}, "mutation_prompt": null}
{"id": "4198e7ed-21cd-4245-9247-6a9ec9144d28", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.70  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Adjusted inertia weight to enhance exploration capabilities.", "configspace": "", "generation": 45, "fitness": 0.07002520782100637, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "1aa17b14-a1c0-475a-bc2d-949e1f903f38", "metadata": {"aucs": [0.07042704540102951, 0.06975045449586892, 0.06989812356612068]}, "mutation_prompt": null}
{"id": "40329aee-e048-4886-be24-05cd8b105494", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.68  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.75  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Enhance convergence by increasing the cognitive coefficient slightly.", "configspace": "", "generation": 46, "fitness": 0.07003120790255186, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "1aa17b14-a1c0-475a-bc2d-949e1f903f38", "metadata": {"aucs": [0.07047127177692425, 0.0697075327718909, 0.06991481915884046]}, "mutation_prompt": null}
{"id": "cb084aa0-3afe-405a-9533-dbf4b0a4acc5", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.68  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.85  # Increased for better convergence\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Enhance exploration by increasing differential weight slightly for better convergence.", "configspace": "", "generation": 47, "fitness": 0.06990944190722977, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "1aa17b14-a1c0-475a-bc2d-949e1f903f38", "metadata": {"aucs": [0.07013918264163599, 0.06971290583547074, 0.06987623724458258]}, "mutation_prompt": null}
{"id": "bac01761-267f-45f9-91af-0e40e6c930e0", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Fine-tuned the inertia weight for better balance between exploration and exploitation.", "configspace": "", "generation": 48, "fitness": 0.07005350697343253, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "1aa17b14-a1c0-475a-bc2d-949e1f903f38", "metadata": {"aucs": [0.07053330872796637, 0.06975435874191604, 0.06987285345041516]}, "mutation_prompt": null}
{"id": "dc3f17dd-de4c-4a98-92a4-617da860adc7", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.95 if self.evaluations > self.budget // 3 else 0.5  # Increased early crossover\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Slightly increased the crossover probability threshold for early exploration in the differential evolution step.", "configspace": "", "generation": 49, "fitness": 0.07005332105659019, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "bac01761-267f-45f9-91af-0e40e6c930e0", "metadata": {"aucs": [0.07053288384844802, 0.06975462294260448, 0.06987245637871808]}, "mutation_prompt": null}
{"id": "ebf38389-f024-49b4-aeb5-488a4d188c3e", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10)) + np.random.uniform(-0.05, 0.05)\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Introduced a random factor to the inertia weight for stochastic exploration.", "configspace": "", "generation": 50, "fitness": 0.07005075158126069, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "bac01761-267f-45f9-91af-0e40e6c930e0", "metadata": {"aucs": [0.0701290302834755, 0.06965556092741776, 0.07036766353288881]}, "mutation_prompt": null}
{"id": "7b6d0f87-71db-4794-a46e-8e9554591c6e", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.85  # Updated for better exploration-exploitation balance\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Introduced a small improvement by tweaking the differential weight for enhanced exploration.", "configspace": "", "generation": 51, "fitness": 0.0699578335090371, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "bac01761-267f-45f9-91af-0e40e6c930e0", "metadata": {"aucs": [0.07046996490697222, 0.06970483239503744, 0.06969870322510163]}, "mutation_prompt": null}
{"id": "2c6f6772-b649-482e-9644-772b1e54574b", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Fine-tuned the inertia weight for better balance between exploration and exploitation.", "configspace": "", "generation": 49, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "bac01761-267f-45f9-91af-0e40e6c930e0", "metadata": {"aucs": [0.07053330872796637, 0.06975435874191604, 0.06987285345041516]}, "mutation_prompt": null}
{"id": "996a4bf6-4032-48d8-bd52-543638e0d467", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.6\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement and convergence rate\n            improvement = initial_global_score - self.global_best_score\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)\n            if improvement > 0.01 * initial_global_score:\n                self.cognitive_coeff *= 0.98\n                self.social_coeff *= 1.02\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Enhanced adaptive exploration using dynamic coefficients based on convergence speed.", "configspace": "", "generation": 53, "fitness": 0.07005350697343253, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "bac01761-267f-45f9-91af-0e40e6c930e0", "metadata": {"aucs": [0.07053330872796637, 0.06975435874191604, 0.06987285345041516]}, "mutation_prompt": null}
{"id": "77d29c12-2aee-4cc2-b133-e5e2a2b19e9b", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.75  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Enhanced exploration by slightly increasing cognitive coefficient for better convergence.", "configspace": "", "generation": 54, "fitness": 0.07003965192210375, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "bac01761-267f-45f9-91af-0e40e6c930e0", "metadata": {"aucs": [0.07052027899373292, 0.0697404082865517, 0.06985826848602661]}, "mutation_prompt": null}
{"id": "4943454a-fd75-4636-af93-ef67304a0781", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.05 if self.global_best_score < initial_global_score else 0.95)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Improved the adaptation of the learning rate to enhance convergence speed by making it more sensitive to performance changes.", "configspace": "", "generation": 55, "fitness": 0.07001917934373891, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "bac01761-267f-45f9-91af-0e40e6c930e0", "metadata": {"aucs": [0.07046280761895585, 0.06974139208997687, 0.06985333832228402]}, "mutation_prompt": null}
{"id": "a5ad6f2c-6e5d-4f7b-81a2-7efd0c5eeca2", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.45 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Adjusted dynamic inertia calculation for improved balance between exploration and exploitation.", "configspace": "", "generation": 56, "fitness": 0.06998693192115091, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "bac01761-267f-45f9-91af-0e40e6c930e0", "metadata": {"aucs": [0.07055030971223242, 0.06972211756156066, 0.06968836848965965]}, "mutation_prompt": null}
{"id": "eca0a174-9167-4a81-9254-af78bd2d734e", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.diff_weight = 0.8 + 0.2 * (self.evaluations / self.budget)  # Dynamic differential weight\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.5\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Introduced a dynamic differential weight for improved convergence by adapting to the number of evaluations.", "configspace": "", "generation": 57, "fitness": 0.07001829932192916, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "bac01761-267f-45f9-91af-0e40e6c930e0", "metadata": {"aucs": [0.07050322547195376, 0.069710153016179, 0.06984151947765471]}, "mutation_prompt": null}
{"id": "b8f5bb51-7ad8-4792-aacb-2d44a36919ee", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.6\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Enhanced balance between exploration and exploitation by adjusting the crossover probability dynamically.", "configspace": "", "generation": 58, "fitness": 0.0701684512890236, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "bac01761-267f-45f9-91af-0e40e6c930e0", "metadata": {"aucs": [0.07051623148880015, 0.06997188633724971, 0.07001723604102095]}, "mutation_prompt": null}
{"id": "98d21b3f-584b-4e7f-bc7d-34dacddc4cab", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.6\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n            self.inertia_weight *= (1.01 if self.global_best_score < initial_global_score else 0.99)  # Adaptive inertia update\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Introduced adaptive inertia updating based on global best improvement for enhanced convergence.", "configspace": "", "generation": 59, "fitness": 0.07016708268694898, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "b8f5bb51-7ad8-4792-aacb-2d44a36919ee", "metadata": {"aucs": [0.07051441248761137, 0.06995632797368534, 0.0700305075995502]}, "mutation_prompt": null}
{"id": "86d3659b-dfbf-4346-acb4-bb66077b8361", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.diff_weight = 0.9 if self.evaluations > self.budget // 2 else 0.7  # Dynamic adjustment\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.6\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Introduce dynamic adjustment of differential evolution weight to enhance exploitation capabilities.", "configspace": "", "generation": 60, "fitness": 0.07010526157232184, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "b8f5bb51-7ad8-4792-aacb-2d44a36919ee", "metadata": {"aucs": [0.07055292426678672, 0.07005743346496396, 0.06970542698521487]}, "mutation_prompt": null}
{"id": "7cc7b667-6927-4cfd-bdff-55eecf1bc20e", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.6\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Enhanced balance between exploration and exploitation by adjusting the crossover probability dynamically.", "configspace": "", "generation": 59, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "b8f5bb51-7ad8-4792-aacb-2d44a36919ee", "metadata": {"aucs": [0.07051623148880015, 0.06997188633724971, 0.07001723604102095]}, "mutation_prompt": null}
{"id": "d9199620-30e1-4eeb-bb41-337312000330", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i] + np.random.normal(0, 0.1, self.dim)  # Random perturbation added\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.6\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            self.learning_rate *= (1.05 if self.global_best_score < initial_global_score else 0.95)  # Adjusted adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Fine-tuned exploration-exploitation balance by dynamically adjusting learning rates and introducing random search perturbations.", "configspace": "", "generation": 62, "fitness": 0.06962139771670221, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "b8f5bb51-7ad8-4792-aacb-2d44a36919ee", "metadata": {"aucs": [0.06962652767453426, 0.06949868474422505, 0.06973898073134732]}, "mutation_prompt": null}
{"id": "45b4e90c-13db-436d-ad32-59ad7b41296e", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(12 * dim, 120)  # Slight increase in population size\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.6\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Improved convergence by slightly increasing the population size for enhanced diversity.", "configspace": "", "generation": 63, "fitness": 0.0693254582579228, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "b8f5bb51-7ad8-4792-aacb-2d44a36919ee", "metadata": {"aucs": [0.06917966380277463, 0.0689832854488509, 0.06981342552214287]}, "mutation_prompt": null}
{"id": "a9e1b299-f826-4fc2-b1fa-1df8f935ec25", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.8  # Slight increase for enhanced convergence speed\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.55  # Slightly higher adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.6\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Slightly increase the cognitive coefficient and adjust the learning rate to enhance convergence speed while maintaining stability.", "configspace": "", "generation": 64, "fitness": 0.07015104986575844, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "b8f5bb51-7ad8-4792-aacb-2d44a36919ee", "metadata": {"aucs": [0.07034066418385798, 0.07015026737704666, 0.0699622180363707]}, "mutation_prompt": null}
{"id": "a6883aa3-8223-421f-ae93-ec738aefec96", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.85  # Slight adjustment for improved convergence\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.6\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.03 if self.global_best_score < initial_global_score else 0.97)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Slight adjustment to differential evolution weighting to improve convergence.", "configspace": "", "generation": 65, "fitness": 0.07016123283015967, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "b8f5bb51-7ad8-4792-aacb-2d44a36919ee", "metadata": {"aucs": [0.07055876526254468, 0.07009895458916238, 0.06982597863877194]}, "mutation_prompt": null}
{"id": "f3bb35bf-9767-4bad-84d8-79fba6205031", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = 0.9 if self.evaluations > self.budget // 3 else 0.6\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.05 if self.global_best_score < initial_global_score else 0.95)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Minor adjustment to learning rate adaptation for improved convergence speed.", "configspace": "", "generation": 66, "fitness": 0.0702065776175372, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "b8f5bb51-7ad8-4792-aacb-2d44a36919ee", "metadata": {"aucs": [0.07053736087861462, 0.07008152897468067, 0.0700008429993163]}, "mutation_prompt": null}
{"id": "050787a2-be02-4888-939e-c1e99d6245d7", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())  # Enhanced exploration\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.05 if self.global_best_score < initial_global_score else 0.95)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Adaptive modification of crossover probability for enhanced exploration during differential evolution.", "configspace": "", "generation": 67, "fitness": 0.07026154145519777, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "f3bb35bf-9767-4bad-84d8-79fba6205031", "metadata": {"aucs": [0.07044154634368383, 0.07024189437119366, 0.07010118365071583]}, "mutation_prompt": null}
{"id": "eba1c44e-aff7-4b41-b376-a8365032e471", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())  # Enhanced exploration\n        adaptive_diff_weight = self.diff_weight * (0.5 + 0.5 * np.random.rand())  # Adaptive factor\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + adaptive_diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.05 if self.global_best_score < initial_global_score else 0.95)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Introducing an adaptive mutation factor for differential evolution to enhance convergence speed.", "configspace": "", "generation": 68, "fitness": 0.06989419933808565, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "050787a2-be02-4888-939e-c1e99d6245d7", "metadata": {"aucs": [0.07003582822158216, 0.07029540773971543, 0.06935136205295933]}, "mutation_prompt": null}
{"id": "8b165003-1d55-444c-b1ba-9368dec18ca9", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.6\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5\n        self.evaluations = 0\n        self.velocity_clamp_factor = 0.1  # New: velocity clamping factor\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp_factor, self.velocity_clamp_factor)  # New: apply velocity clamping\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.dim += int(self.budget / 1000)  # New: dynamic dimensional scaling\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            self.learning_rate *= (1.05 if self.global_best_score < initial_global_score else 0.95)\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Introduce dynamic dimensional scaling and adaptive velocity clamping to enhance convergence and solution precision.", "configspace": "", "generation": 69, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (60, 9) and arg 1 with shape (6,).').", "error": "ValueError('shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (60, 9) and arg 1 with shape (6,).')", "parent_id": "050787a2-be02-4888-939e-c1e99d6245d7", "metadata": {}, "mutation_prompt": null}
{"id": "8cf1e530-45f4-46db-8703-4da6e448df31", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())  # Enhanced exploration\n        # Increase diversity with alternate mutation strategy\n        self.diff_weight = 0.9 if np.mean(self.personal_best_scores) < self.global_best_score else 0.7\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.05 if self.global_best_score < initial_global_score else 0.95)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Improved convergence by dynamically adjusting inertia weight and mutation strategy.", "configspace": "", "generation": 70, "fitness": 0.07005716378551856, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "050787a2-be02-4888-939e-c1e99d6245d7", "metadata": {"aucs": [0.07016328153595208, 0.06994071987150607, 0.0700674899490975]}, "mutation_prompt": null}
{"id": "a4bf76e8-399b-4157-be0c-ae0bc208032b", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.03 * (0.5 - np.random.rand())  # Enhanced exploration\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        initial_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adjust the learning rate based on performance improvement\n            self.learning_rate *= (1.05 if self.global_best_score < initial_global_score else 0.95)  # Enhanced adaptation\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Introduce a slight increase in the crossover probability's adjustment factor for better diversity in exploration.", "configspace": "", "generation": 71, "fitness": 0.07025375006739394, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "050787a2-be02-4888-939e-c1e99d6245d7", "metadata": {"aucs": [0.07043969631160796, 0.07022629850330375, 0.07009525538727013]}, "mutation_prompt": null}
{"id": "98261999-96b6-48c9-8af9-5bc3be96538a", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())  # Enhanced exploration\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score  # Track previous score for adaptive learning rate\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adapt learning rate based on consistent improvement or stagnation\n            if self.global_best_score < previous_global_score:\n                self.learning_rate *= 1.05\n            else:\n                self.learning_rate *= 0.95\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Adaptive learning rate adjustment based on performance consistency to enhance global search efficiency.", "configspace": "", "generation": 72, "fitness": 0.07027110488751916, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "050787a2-be02-4888-939e-c1e99d6245d7", "metadata": {"aucs": [0.07044040780150973, 0.07024189437119366, 0.0701310124898541]}, "mutation_prompt": null}
{"id": "3db9951a-2308-4dc2-a14b-754116c47db7", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.diff_weight = 0.5 + 0.3 * np.random.rand()  # Dynamic adjustment for better adaptability\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())  # Enhanced exploration\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score  # Track previous score for adaptive learning rate\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adapt learning rate based on consistent improvement or stagnation\n            if self.global_best_score < previous_global_score:\n                self.learning_rate *= 1.05\n            else:\n                self.learning_rate *= 0.95\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Introduced a dynamic adjustment to the differential weight for better adaptability in various search spaces.", "configspace": "", "generation": 73, "fitness": 0.06997427020456277, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "98261999-96b6-48c9-8af9-5bc3be96538a", "metadata": {"aucs": [0.07011740612538231, 0.07029926379819273, 0.0695061406901133]}, "mutation_prompt": null}
{"id": "acd3d866-f5ad-4e19-a927-1c21729fe265", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.6\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.diff_weight *= 0.95 + 0.1 * np.random.rand()  # Adaptive scaling for diversity\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adapt learning rate based on improvement or stagnation\n            if self.global_best_score < previous_global_score:\n                self.learning_rate = min(1.0, self.learning_rate * 1.1)  # Enhanced adaptation\n            else:\n                self.learning_rate = max(0.1, self.learning_rate * 0.9)\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Introduced adaptive differential weight scaling and enhanced learning rate adaptation to improve convergence.  ", "configspace": "", "generation": 74, "fitness": 0.07006119675984741, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "98261999-96b6-48c9-8af9-5bc3be96538a", "metadata": {"aucs": [0.07047373027628101, 0.07008798594297638, 0.06962187406028486]}, "mutation_prompt": null}
{"id": "f0b845fc-6dff-4c48-9ed7-9aa171c68689", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.6\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            F_adaptive = self.diff_weight * (0.5 + 0.5 * np.random.rand()) # Adaptive mutation factor\n            mutant_vector = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            if self.global_best_score < previous_global_score:\n                self.learning_rate *= 1.05\n            else:\n                self.learning_rate *= 0.95\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Improved hybrid swarm differential algorithm with adaptive mutation strategies for enhanced exploration and exploitation balance.", "configspace": "", "generation": 75, "fitness": 0.06988064701423465, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "98261999-96b6-48c9-8af9-5bc3be96538a", "metadata": {"aucs": [0.07047459103960285, 0.06917359369159326, 0.06999375631150784]}, "mutation_prompt": null}
{"id": "4d7b274b-35f2-4466-aa70-6c12ba2b065e", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.6\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            adaptive_diff_weight = self.diff_weight + 0.2 * (np.random.rand() - 0.5) * np.exp(-diversity)\n            mutant_vector = np.clip(a + adaptive_diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.pop_size = int(10 * self.dim * (1 - self.evaluations / self.budget)) + 1\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            if self.global_best_score < previous_global_score:\n                self.learning_rate *= 1.05\n            else:\n                self.learning_rate *= 0.95\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Enhance convergence using dynamic population size and adaptive differential weight based on diversity.", "configspace": "", "generation": 76, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 60 is out of bounds for axis 0 with size 60').", "error": "IndexError('index 60 is out of bounds for axis 0 with size 60')", "parent_id": "98261999-96b6-48c9-8af9-5bc3be96538a", "metadata": {}, "mutation_prompt": null}
{"id": "ab8910a3-eb2d-449f-bd66-22ac892f75dd", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.6\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())\n        self.diff_weight = 0.9  # Increased differential weight for diversity\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            if self.global_best_score < previous_global_score:\n                self.learning_rate *= 1.07  # Increased adjustment factor for learning rate\n            else:\n                self.learning_rate *= 0.93  # Decreased adjustment factor for learning rate\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Enhanced diversity management and adaptive learning rate for robust exploration and exploitation.", "configspace": "", "generation": 77, "fitness": 0.0702250596045146, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "98261999-96b6-48c9-8af9-5bc3be96538a", "metadata": {"aucs": [0.070367258953132, 0.07022972393196458, 0.07007819592844722]}, "mutation_prompt": null}
{"id": "1f542f94-cdaf-4167-9471-4ab49dc8ed6c", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand()) + 0.01 * (self.global_best_score / (self.global_best_score + 1e-10))\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score  # Track previous score for adaptive learning rate\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adapt learning rate based on consistent improvement or stagnation\n            if self.global_best_score < previous_global_score:\n                self.learning_rate *= 1.05\n            else:\n                self.learning_rate *= 0.95\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Introduced a small adaptive factor to the crossover probability to further enhance exploration and exploitation balance.", "configspace": "", "generation": 78, "fitness": 0.07006057614690604, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "98261999-96b6-48c9-8af9-5bc3be96538a", "metadata": {"aucs": [0.07043238521376527, 0.07013983367627208, 0.06960950955068079]}, "mutation_prompt": null}
{"id": "628ca74c-eb5d-4d91-ad0f-4ca0873362d6", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.85  # Adjusted for better mutation\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())  # Enhanced exploration\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score  # Track previous score for adaptive learning rate\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adapt learning rate based on consistent improvement or stagnation\n            if self.global_best_score < previous_global_score:\n                self.learning_rate *= 1.05\n            else:\n                self.learning_rate *= 0.95\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Enhanced exploration by slightly increasing the differential mutation weight.", "configspace": "", "generation": 79, "fitness": 0.07025668384551946, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "98261999-96b6-48c9-8af9-5bc3be96538a", "metadata": {"aucs": [0.07041784831907871, 0.0701550441486587, 0.07019715906882096]}, "mutation_prompt": null}
{"id": "d55e9c91-8437-4ccd-adf6-0f83f763bb1e", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.8  # Changed from 1.7 for better exploitation\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())  # Enhanced exploration\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score  # Track previous score for adaptive learning rate\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adapt learning rate based on consistent improvement or stagnation\n            if self.global_best_score < previous_global_score:\n                self.learning_rate *= 1.05\n            else:\n                self.learning_rate *= 0.95\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Slightly increased cognitive coefficient for enhanced exploitation and convergence in search.", "configspace": "", "generation": 80, "fitness": 0.07023598487193805, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "98261999-96b6-48c9-8af9-5bc3be96538a", "metadata": {"aucs": [0.07044442959945829, 0.07023924892983568, 0.07002427608652018]}, "mutation_prompt": null}
{"id": "54df7434-7edd-4ffe-87ab-bfaf74f5ab58", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())  # Enhanced exploration\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score  # Track previous score for adaptive learning rate\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adapt learning rate based on consistent improvement or stagnation\n            if self.global_best_score < previous_global_score:\n                self.learning_rate *= 1.05\n            else:\n                self.learning_rate *= 0.95\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Adaptive learning rate adjustment based on performance consistency to enhance global search efficiency.", "configspace": "", "generation": 73, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "98261999-96b6-48c9-8af9-5bc3be96538a", "metadata": {"aucs": [0.07044040780150973, 0.07024189437119366, 0.0701310124898541]}, "mutation_prompt": null}
{"id": "376f4d0b-2aa2-4041-855b-696493d20c80", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.6\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.3 * (diversity / (diversity + 1e-10))  # Change\n        adaptive_social_coeff = self.social_coeff * (0.6 + 0.4 * np.random.rand())  # Change\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Stochastic learning rate adaptation\n            if np.random.rand() < 0.5:  # Change\n                self.learning_rate *= 1.1\n            else:\n                self.learning_rate *= 0.9\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Enhanced particle diversity strategy with stochastic learning rate adaptation to improve convergence and exploration balance.", "configspace": "", "generation": 82, "fitness": 0.07004367603236587, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "98261999-96b6-48c9-8af9-5bc3be96538a", "metadata": {"aucs": [0.07032890240985568, 0.06959347382210124, 0.07020865186514069]}, "mutation_prompt": null}
{"id": "2cc60b8c-3c48-4371-a813-9cade5580715", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.6\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.diff_weight = 0.8 + 0.2 * np.random.rand()  # Adaptive differential weighting\n        self.crossover_prob = 0.6 + 0.3 * np.random.rand()  # Dynamic crossover probability\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            if self.global_best_score < previous_global_score:\n                self.learning_rate *= 1.05\n            else:\n                self.learning_rate *= 0.95\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Enhanced exploration through adaptive differential weighting and dynamic crossover probability to improve convergence.", "configspace": "", "generation": 83, "fitness": 0.0699296987471593, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "98261999-96b6-48c9-8af9-5bc3be96538a", "metadata": {"aucs": [0.07021461168114407, 0.06974774948107687, 0.06982673507925696]}, "mutation_prompt": null}
{"id": "d1592cda-d5ac-44ce-a0e3-1854dc06b699", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.75  # Adjusted for improved exploration\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7  # Further increase for enhanced exploration\n        self.diff_weight = 0.85  # Increased differential weight\n        self.crossover_prob = 0.75  # Slightly increased for better diversity\n        self.learning_rate = 0.5\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            if self.global_best_score < previous_global_score:\n                self.learning_rate *= 1.05\n            else:\n                self.learning_rate *= 0.95\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Enhanced particle swarm momentum and differential mutation to improve convergence speed and solution accuracy.", "configspace": "", "generation": 84, "fitness": 0.06961458126282409, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "98261999-96b6-48c9-8af9-5bc3be96538a", "metadata": {"aucs": [0.07012411009858455, 0.06870608313824278, 0.07001355055164493]}, "mutation_prompt": null}
{"id": "cdbdf648-412e-4880-b6d3-07a6f0a19c3a", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.68  # Changed from 0.66 to 0.68 for improved balance\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.6\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            if self.global_best_score < previous_global_score:\n                self.learning_rate *= 1.05\n            else:\n                self.learning_rate *= 0.95\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Slightly adjust the inertia weight to enhance balance between exploration and exploitation.", "configspace": "", "generation": 85, "fitness": 0.07014281723719488, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "98261999-96b6-48c9-8af9-5bc3be96538a", "metadata": {"aucs": [0.07042015189257833, 0.06995332208649219, 0.07005497773251412]}, "mutation_prompt": null}
{"id": "b7a4ebcc-7e8c-4464-bf1b-1070b5fc3ef9", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob = max(0.5, min(0.9, self.crossover_prob + 0.02 * (0.5 - np.random.rand())))  # Adaptive crossover\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score  # Track previous score for adaptive learning rate\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adapt learning rate based on consistent improvement or stagnation\n            if self.global_best_score < previous_global_score:\n                self.learning_rate *= 1.05\n            else:\n                self.learning_rate *= 0.95\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Introduced an adaptive crossover probability to enhance exploration and exploitation balance.", "configspace": "", "generation": 86, "fitness": 0.07027110488751916, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "98261999-96b6-48c9-8af9-5bc3be96538a", "metadata": {"aucs": [0.07044040780150973, 0.07024189437119366, 0.0701310124898541]}, "mutation_prompt": null}
{"id": "e03fadab-2983-4966-8fff-7caac0591529", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.7  # Slight adjustment for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.7 * np.random.rand())  # Change made here\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())  # Enhanced exploration\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score  # Track previous score for adaptive learning rate\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adapt learning rate based on consistent improvement or stagnation\n            if self.global_best_score < previous_global_score:\n                self.learning_rate *= 1.05\n            else:\n                self.learning_rate *= 0.95\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Improve exploration by increasing the range of random coefficients in the PSO update.", "configspace": "", "generation": 87, "fitness": 0.06994880688680576, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "98261999-96b6-48c9-8af9-5bc3be96538a", "metadata": {"aucs": [0.06970864162562185, 0.0700243326619191, 0.07011344637287631]}, "mutation_prompt": null}
{"id": "647ec49d-28cd-428f-87c4-d5de0ed15291", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.5  # Fine-tuned adjustment for enhanced stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())  # Enhanced exploration\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score  # Track previous score for adaptive learning rate\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adapt learning rate based on consistent improvement or stagnation\n            if self.global_best_score < previous_global_score:\n                self.learning_rate *= 1.05\n            else:\n                self.learning_rate *= 0.95\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Fine-tuned cognitive coefficient for enhanced stability and convergence in the search process.", "configspace": "", "generation": 88, "fitness": 0.07028337434813252, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "98261999-96b6-48c9-8af9-5bc3be96538a", "metadata": {"aucs": [0.07045570295362202, 0.07026091245546329, 0.07013350763531223]}, "mutation_prompt": null}
{"id": "7228afc9-35f3-4a31-bf3d-1205334bf062", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.5  # Fine-tuned adjustment for enhanced stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand() + diversity)  # Change here\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())  # Enhanced exploration\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score  # Track previous score for adaptive learning rate\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adapt learning rate based on consistent improvement or stagnation\n            if self.global_best_score < previous_global_score:\n                self.learning_rate *= 1.05\n            else:\n                self.learning_rate *= 0.95\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Adjusts social coefficient dynamically to enhance exploration in uncertain regions.", "configspace": "", "generation": 89, "fitness": 0.05917537515898308, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "647ec49d-28cd-428f-87c4-d5de0ed15291", "metadata": {"aucs": [0.05780721101567121, 0.057675180263877635, 0.06204373419740039]}, "mutation_prompt": null}
{"id": "cf35459b-0cd8-4975-8d83-834fd3273924", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.8  # Slight increase for enhanced exploration\n        self.diff_weight = 0.85  # Adjusted for better balance between exploration and exploitation\n        self.crossover_prob = 0.75  # Increase to promote diversity\n        self.learning_rate = 0.5\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.3 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.4 + 0.6 * np.random.rand())  # Enhanced adaptability\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            if self.global_best_score < previous_global_score:\n                self.learning_rate *= 1.05\n            else:\n                self.learning_rate *= 0.95\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Enhanced exploration by introducing dynamic parameters and diversity-driven adaptations.", "configspace": "", "generation": 90, "fitness": 0.06984252362647995, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "647ec49d-28cd-428f-87c4-d5de0ed15291", "metadata": {"aucs": [0.07004988528261957, 0.06958695450122365, 0.06989073109559663]}, "mutation_prompt": null}
{"id": "e852398f-66b8-4127-9702-136dd39eed14", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.6  # Adjusted for better exploration-convergence balance\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())  # Enhanced exploration\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score  # Track previous score for adaptive learning rate\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adapt learning rate based on consistent improvement or stagnation\n            if self.global_best_score < previous_global_score:\n                self.learning_rate *= 1.05\n            else:\n                self.learning_rate *= 0.95\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Adjusted cognitive coefficient to improve balance between exploration and convergence.", "configspace": "", "generation": 91, "fitness": 0.07028093625343923, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "647ec49d-28cd-428f-87c4-d5de0ed15291", "metadata": {"aucs": [0.0704469109704896, 0.07027446053910047, 0.07012143725072761]}, "mutation_prompt": null}
{"id": "65a68fe2-1525-411d-bf74-7cfaecf01ccc", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.5  # Fine-tuned adjustment for enhanced stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.5 * (diversity / (diversity + 1e-10))  # Changed 0.4 to 0.5 for better adaptability\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())  # Enhanced exploration\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score  # Track previous score for adaptive learning rate\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adapt learning rate based on consistent improvement or stagnation\n            if self.global_best_score < previous_global_score:\n                self.learning_rate *= 1.05\n            else:\n                self.learning_rate *= 0.95\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Enhanced dynamic inertia adjustment for improved adaptability to the search landscape.", "configspace": "", "generation": 92, "fitness": 0.07018772207428618, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "647ec49d-28cd-428f-87c4-d5de0ed15291", "metadata": {"aucs": [0.07031418099778541, 0.07023745121754144, 0.07001153400753168]}, "mutation_prompt": null}
{"id": "7beb6364-54e1-4d96-8612-ff4fb8c80ccb", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.5  # Fine-tuned adjustment for enhanced stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())  # Enhanced exploration\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score  # Track previous score for adaptive learning rate\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adapt learning rate based on consistent improvement or stagnation\n            if self.global_best_score < previous_global_score:\n                self.learning_rate *= 1.05\n            else:\n                self.learning_rate *= 0.95\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Fine-tuned cognitive coefficient for enhanced stability and convergence in the search process.", "configspace": "", "generation": 89, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "647ec49d-28cd-428f-87c4-d5de0ed15291", "metadata": {"aucs": [0.07045570295362202, 0.07026091245546329, 0.07013350763531223]}, "mutation_prompt": null}
{"id": "db890376-0fff-422c-aa41-a7a4ae995088", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.6\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.3 + 0.7 * np.random.rand())  # Adjusted range\n        adaptive_cognitive_coeff = self.cognitive_coeff * (0.5 + 0.5 * np.random.rand())  # Added adaptive cognitive\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = adaptive_cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            if self.global_best_score < previous_global_score:\n                self.learning_rate *= 1.05\n            else:\n                self.learning_rate *= 0.95\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Dynamic adjustment of cognitive and social coefficients for improved convergence and exploration balance.", "configspace": "", "generation": 94, "fitness": 0.06943584890244736, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "647ec49d-28cd-428f-87c4-d5de0ed15291", "metadata": {"aucs": [0.06987902369614407, 0.07011492336826786, 0.06831359964293016]}, "mutation_prompt": null}
{"id": "4195056e-de77-4e59-9a91-a6bdbe731c53", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.6\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5\n        self.evaluations = 0\n        self.success_counter = 0  # New attribute to track successful updates\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                    self.success_counter += 1\n\n    def pso_update(self):\n        success_ratio = self.success_counter / (self.evaluations + 1e-10)\n        dynamic_inertia = self.inertia_weight - 0.4 * success_ratio  # Adjusted inertia based on success\n        adaptive_cognitive_coeff = self.cognitive_coeff * (0.5 + 0.5 * success_ratio)  # Adaptive cognitive coeff\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = adaptive_cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            if self.global_best_score < previous_global_score:\n                self.learning_rate *= 1.05\n            else:\n                self.learning_rate *= 0.95\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Introduced adaptive cognitive and inertia coefficients based on success ratio for improved convergence dynamics.", "configspace": "", "generation": 95, "fitness": 0.06971112539715911, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "647ec49d-28cd-428f-87c4-d5de0ed15291", "metadata": {"aucs": [0.06974276464423323, 0.06968182789492716, 0.06970878365231692]}, "mutation_prompt": null}
{"id": "0ef601cc-9966-41ed-bdf7-3cbcdde0d074", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.68  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.5  # Fine-tuned adjustment for enhanced stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())  # Enhanced exploration\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score  # Track previous score for adaptive learning rate\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adapt learning rate based on consistent improvement or stagnation\n            if self.global_best_score < previous_global_score:\n                self.learning_rate *= 1.05\n            else:\n                self.learning_rate *= 0.95\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Introduced a slight increase in the inertia weight to improve exploration capabilities.", "configspace": "", "generation": 96, "fitness": 0.07012216427607021, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "647ec49d-28cd-428f-87c4-d5de0ed15291", "metadata": {"aucs": [0.07047341438544119, 0.06979895177109319, 0.07009412667167625]}, "mutation_prompt": null}
{"id": "decc7359-0bee-424e-ab82-c5ff75111c3c", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.52  # Slightly enhanced for improved convergence\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())  # Enhanced exploration\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score  # Track previous score for adaptive learning rate\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adapt learning rate based on consistent improvement or stagnation\n            if self.global_best_score < previous_global_score:\n                self.learning_rate *= 1.05\n            else:\n                self.learning_rate *= 0.95\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Slightly enhance the cognitive coefficient for improved convergence.", "configspace": "", "generation": 97, "fitness": 0.07027863486307218, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "647ec49d-28cd-428f-87c4-d5de0ed15291", "metadata": {"aucs": [0.07045489739347077, 0.07024427920390597, 0.07013672799183979]}, "mutation_prompt": null}
{"id": "6e3e3d65-9217-4e12-8f97-125dd055688a", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.55  # Minor tune for better stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.8\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())  # Enhanced exploration\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score  # Track previous score for adaptive learning rate\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adapt learning rate based on consistent improvement or stagnation\n            if self.global_best_score < previous_global_score:\n                self.learning_rate *= 1.05\n            else:\n                self.learning_rate *= 0.95\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Minor tune in cognitive coefficient for better stability and improved performance.", "configspace": "", "generation": 98, "fitness": 0.07028317037953298, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "647ec49d-28cd-428f-87c4-d5de0ed15291", "metadata": {"aucs": [0.0704461365587169, 0.07026876075442967, 0.07013461382545239]}, "mutation_prompt": null}
{"id": "f39effe2-e349-40f8-b259-e4d3d41ec11f", "solution": "import numpy as np\n\nclass HybridSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(10 * dim, 100)\n        self.inertia_weight = 0.66  # Slight adjustment for improved exploration\n        self.cognitive_coeff = 1.5  # Fine-tuned adjustment for enhanced stability\n        self.social_coeff = 1.6  # Slight increase for enhanced exploration\n        self.diff_weight = 0.82  # Slightly increased for better balance\n        self.crossover_prob = 0.7\n        self.learning_rate = 0.5  # Adaptive learning rate\n        self.evaluations = 0\n\n    def initialize_particles(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.full(self.pop_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def update_personal_bests(self, func):\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            score = func(self.particles[i])\n            self.evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.particles[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n    def pso_update(self):\n        diversity = np.var(self.particles, axis=0).mean()\n        dynamic_inertia = self.inertia_weight - 0.4 * (diversity / (diversity + 1e-10))\n        adaptive_social_coeff = self.social_coeff * (0.5 + 0.5 * np.random.rand())\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = adaptive_social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (dynamic_inertia * self.velocities[i] +\n                                  self.learning_rate * (cognitive_velocity + social_velocity))\n            self.particles[i] += self.velocities[i]\n\n    def differential_evolution(self, bounds, func):\n        self.crossover_prob += 0.02 * (0.5 - np.random.rand())  # Enhanced exploration\n        for i in range(self.pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = [idx for idx in range(self.pop_size) if idx != i]\n            a, b, c = self.particles[np.random.choice(indices, 3, replace=False)]\n            mutant_vector = np.clip(a + self.diff_weight * (b - c), bounds.lb, bounds.ub)\n            trial_vector = np.copy(self.particles[i])\n            crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n            trial_vector[crossover_mask] = mutant_vector[crossover_mask]\n            trial_score = func(trial_vector)\n            if trial_score < func(self.particles[i]):\n                self.particles[i] = trial_vector\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n            self.evaluations += 1\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_particles(bounds)\n        previous_global_score = self.global_best_score  # Track previous score for adaptive learning rate\n        while self.evaluations < self.budget:\n            self.update_personal_bests(func)\n            self.pso_update()\n            self.differential_evolution(bounds, func)\n            # Adapt learning rate based on consistent improvement or stagnation\n            if self.global_best_score < previous_global_score:\n                self.learning_rate *= 1.05\n            else:\n                self.learning_rate *= 0.95\n            previous_global_score = self.global_best_score\n        return self.global_best_position, self.global_best_score", "name": "HybridSwarmDifferential", "description": "Slightly increase the differential weight for better exploration-exploitation balance.", "configspace": "", "generation": 99, "fitness": 0.07030570062640285, "feedback": "The algorithm HybridSwarmDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "647ec49d-28cd-428f-87c4-d5de0ed15291", "metadata": {"aucs": [0.07045416483188227, 0.07019257137883639, 0.07027036566848988]}, "mutation_prompt": null}
